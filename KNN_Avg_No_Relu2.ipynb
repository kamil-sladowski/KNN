{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN_Avg_No_Relu2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6574df4f71dd45f6b8f7672c58f6aecd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c9fe6bfde87446f3b3fcc0a79cd30f42",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e7d91d8e44ba45a292da688db47ab39a",
              "IPY_MODEL_4527102e2f4e4179bd564943e1af316f"
            ]
          }
        },
        "c9fe6bfde87446f3b3fcc0a79cd30f42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e7d91d8e44ba45a292da688db47ab39a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6c1bf0a296fa400db8e27e234ac85c4b",
            "_dom_classes": [],
            "description": " 82%",
            "_model_name": "IntProgressModel",
            "bar_style": "danger",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 82,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1101b56c50f64831adf19f37a6b1895c"
          }
        },
        "4527102e2f4e4179bd564943e1af316f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_680b2d76f8664bff8d26b5631a58e9e6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 82/100 [08:01&lt;01:41,  5.62s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_57cf14edc2374adb85832079cda7fde0"
          }
        },
        "6c1bf0a296fa400db8e27e234ac85c4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1101b56c50f64831adf19f37a6b1895c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "680b2d76f8664bff8d26b5631a58e9e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "57cf14edc2374adb85832079cda7fde0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamilo116/KNN/blob/master/KNN_Avg_No_Relu2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7ReM7FU-xs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import sys\n",
        "from random import shuffle\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms as transforms\n",
        "import timeit\n",
        "\n",
        "np.random.seed(4) \n",
        "torch.manual_seed(4) \n",
        "torch.cuda.manual_seed(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYIMZ8QyYewD",
        "colab_type": "code",
        "outputId": "c4c40ae9-57c9-4b70-da64-9d0ca833b4b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "! git clone https://github.com/wang-chen/kervolution.git \n",
        "\n",
        "sys.path.append(\"kervolution/\")\n",
        "from kervolution import Kerv2d\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'kervolution' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvbKg4VJXKY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LIMIT_IMAGES_NUM = 500\n",
        "train_test_split_size = 0.2\n",
        "image_resize = (100, 100)\n",
        "batch_size = 64\n",
        "num_workers = 0\n",
        "\n",
        "in_channels = 3\n",
        "out_channels_1 = 16\n",
        "out_channels_2 = 24\n",
        "out_channels_3 = 32\n",
        "out_channels_4 = 48\n",
        "out_channels_5 = 64\n",
        "out_channels_6 = 128\n",
        "\n",
        "kernel_size = 3\n",
        "padding_1 = 1\n",
        "num_epochs = 80\n",
        "\n",
        "learning_rate = 0.0001\n",
        "weight_decay = 0\n",
        "\n",
        "MALIGNANT_DATASET = '/content/drive/My Drive/Colab_data/malignant/malignant/'\n",
        "BENIGN_DATASET = '/content/drive/My Drive/Colab_data/benign/benign/'\n",
        "DATA_FOLDER = '/content/drive/My Drive/Colab_data/'\n",
        "model_backup_path = os.path.join(DATA_FOLDER, 'backup_model') \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMOHez_kHZD6",
        "colab_type": "code",
        "outputId": "c1b2d045-f277-4e8a-8999-32851f2e0416",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b8P1NdXfVdX",
        "colab_type": "code",
        "outputId": "68363ab8-6621-418a-dc0a-1b4db340ff79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "benign_file_list = sorted(os.listdir(BENIGN_DATASET))\n",
        "malignant_file_list = sorted(os.listdir(MALIGNANT_DATASET))\n",
        "shuffle(benign_file_list)\n",
        "shuffle(malignant_file_list)\n",
        "benign_file_list = benign_file_list[:LIMIT_IMAGES_NUM]\n",
        "malignant_file_list = malignant_file_list[:LIMIT_IMAGES_NUM]\n",
        "\n",
        "print(f\"Number of benign {len(benign_file_list)} images\")\n",
        "print(f\"Number of malignant {len(malignant_file_list)} images\")\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize(image_resize),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of benign 500 images\n",
            "Number of malignant 500 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGDQfal74BLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "benign_dict = {filename: 0 for filename in benign_file_list}\n",
        "malignant_dict = {filename: 1 for filename in malignant_file_list}\n",
        "img_class_dict = {**benign_dict , **malignant_dict}\n",
        "labeled_data = pd.Series(img_class_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvAAOqmVfVll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IsicDataset(Dataset):\n",
        "    def __init__(self, data_folder, labeled_data, \n",
        "                 transform=transforms.Compose([transforms.ToTensor()])):\n",
        "        self.labeled_data = labeled_data\n",
        "        self.transform = transform\n",
        "        self.data_folder = data_folder\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labeled_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        label = self.labeled_data[index]\n",
        "        if label == 0:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"benign\", \"benign\", index ))\n",
        "        else:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"malignant\", \"malignant\", index ))\n",
        "        image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "    @property\n",
        "    def labels(self):\n",
        "      return self.labeled_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSuYqjLAYrWA",
        "colab_type": "code",
        "outputId": "ed5df0da-5a9e-4f55-d11d-b9d83fd01f1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        }
      },
      "source": [
        " \n",
        "dataset = IsicDataset(DATA_FOLDER, labeled_data, transform=data_transforms)\n",
        "print(dataset.labels)\n",
        "\n",
        "X_train, X_test = train_test_split(dataset.labels, test_size=train_test_split_size)\n",
        "print(\"number of training data: \",len(X_train))\n",
        "print(\"number of testing  data: \",len(X_test))\n",
        "\n",
        "train_sampler = SubsetRandomSampler(list(X_train.index))\n",
        "valid_sampler = SubsetRandomSampler(list(X_test.index))\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ISIC_0001283.jpeg    0\n",
            "ISIC_0000763.jpeg    0\n",
            "ISIC_0001336.jpeg    0\n",
            "ISIC_0001068.jpeg    0\n",
            "ISIC_0000372.jpeg    0\n",
            "                    ..\n",
            "ISIC_0000520.jpeg    1\n",
            "ISIC_0010741.jpeg    1\n",
            "ISIC_0011495.jpeg    1\n",
            "ISIC_0027021.jpg     1\n",
            "ISIC_0013588.jpeg    1\n",
            "Length: 1000, dtype: int64\n",
            "number of training data:  800\n",
            "number of testing  data:  200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e8nFBR6Yug5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "def train(model, train_loader ,loss_fn, optimizer, num_epochs=1, starting_from_epoch=1):\n",
        "    total_loss =0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
        "        model.train()\n",
        "\n",
        "        for t, (x, y) in enumerate(train_loader):\n",
        "            x_var = Variable(x.type(gpu_dtype))\n",
        "            y_var = Variable(y.type(gpu_dtype).long())\n",
        "            scores = model(x_var)\n",
        "            loss = loss_fn(scores, y_var)\n",
        "            total_loss += loss.data\n",
        "            \n",
        "            if (t + 1) % print_every == 0:\n",
        "                avg_loss = total_loss/print_every\n",
        "                print('t = %d, avg_loss = %.4f' % (t + 1, avg_loss) )\n",
        "                avg_loss_list.append(avg_loss)\n",
        "                total_loss = 0\n",
        "                \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        acc = check_accuracy(model_gpu, valid_loader)\n",
        "        print('acc = %f' %(acc))\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model_gpu.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            }, model_backup_path)\n",
        "            \n",
        "def check_accuracy(model, loader):\n",
        "    print('Checking accuracy on test set')   \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval() \n",
        "    for x, y in loader:\n",
        "        x_var = Variable(x.type(gpu_dtype))\n",
        "\n",
        "        scores = model(x_var)\n",
        "        _, preds = scores.data.cpu().max(1)\n",
        "        num_correct += (preds == y).sum()\n",
        "        num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    acc_list.append(acc)\n",
        "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "    return acc\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggvpMu36Yw2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.size()\n",
        "        return x.view(N, -1)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgmexhBRZAK6",
        "colab_type": "code",
        "outputId": "723187d5-de85-46f7-8722-4f3a37b8ba0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "gpu_dtype = torch.cuda.FloatTensor\n",
        "\n",
        "print_every = 1\n",
        "\n",
        "\n",
        "'''\n",
        "Kerv2d\n",
        "kervolution with following options:\n",
        "kernel_type: [linear, polynomial, gaussian, etc.]\n",
        "default is convolution:\n",
        "          kernel_type --> linear,\n",
        "balance, power, gamma is valid only when the kernel_type is specified\n",
        "if learnable_kernel = True,  they just be the initial value of learable parameters\n",
        "if learnable_kernel = False, they are the value of kernel_type's parameter\n",
        "the parameter [power] cannot be learned due to integer limitation\n",
        "dilation (int or tuple, optional): Spacing between kernel\n",
        "elements. Default: 1\n",
        "groups (int, optional): Number of blocked connections from input\n",
        "channels to output channels. Default: 1\n",
        "bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n",
        "kernel_type (str), Default: 'linear'\n",
        "learnable_kernel (bool): Learnable kernel parameters.  Default: False \n",
        "balance: 0, 1\n",
        "power: 3, 4, 5\n",
        "gamma:\n",
        "'''\n",
        "\n",
        "\n",
        "model_base = nn.Sequential( \n",
        "                nn.Kerv2d(in_channels , out_channels_1, padding=padding_1, dilation=1, groups=1, bias=True, \n",
        "                          kernel_type='polynomial', kernel_size=kernel_size, learnable_kernel=True,\n",
        "                          kernel_regularizer=True, stride=1, balance=1, power=5, gamma=1\n",
        "                          ),\n",
        "                nn.BatchNorm2d(out_channels_1),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_1 , out_channels_2, padding= padding_1, kernel_size=kernel_size, stride=1), \n",
        "                nn.BatchNorm2d(out_channels_2),\n",
        "                nn.AvgPool2d(2, stride=2), \n",
        "                nn.Conv2d(out_channels_2 , out_channels_3, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.BatchNorm2d(out_channels_3),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_3 , out_channels_4, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.BatchNorm2d(out_channels_4),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_4 , out_channels_5, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.BatchNorm2d(out_channels_5),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_5 , out_channels_6, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.BatchNorm2d(out_channels_6),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Dropout(0.5),\n",
        "                Flatten(),\n",
        "                nn.Linear(128,64),\n",
        "                nn.Linear(64,2)\n",
        "            )\n",
        "model_gpu = model_base.type(gpu_dtype)\n",
        "print(model_gpu)\n",
        "loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) \n",
        "\n",
        "train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs)\n",
        "check_accuracy(model_gpu, valid_loader)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Kerv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (3): Conv2d(16, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (6): Conv2d(24, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (8): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (9): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (10): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (11): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (12): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (13): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (14): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (15): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (18): Dropout(p=0.5, inplace=False)\n",
            "  (19): Flatten()\n",
            "  (20): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (21): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n",
            "Starting epoch 1 / 80\n",
            "t = 1, avg_loss = 0.7065\n",
            "t = 2, avg_loss = 0.7401\n",
            "t = 3, avg_loss = 0.6847\n",
            "t = 4, avg_loss = 0.6671\n",
            "t = 5, avg_loss = 0.7127\n",
            "t = 6, avg_loss = 0.6797\n",
            "t = 7, avg_loss = 0.6135\n",
            "t = 8, avg_loss = 0.5896\n",
            "t = 9, avg_loss = 0.6806\n",
            "t = 10, avg_loss = 0.5944\n",
            "t = 11, avg_loss = 0.5605\n",
            "t = 12, avg_loss = 0.6508\n",
            "t = 13, avg_loss = 0.7068\n",
            "Checking accuracy on test set\n",
            "Got 137 / 200 correct (68.50)\n",
            "acc = 0.685000\n",
            "Starting epoch 2 / 80\n",
            "t = 1, avg_loss = 0.7377\n",
            "t = 2, avg_loss = 0.5421\n",
            "t = 3, avg_loss = 0.6695\n",
            "t = 4, avg_loss = 0.5763\n",
            "t = 5, avg_loss = 0.6275\n",
            "t = 6, avg_loss = 0.5440\n",
            "t = 7, avg_loss = 0.6702\n",
            "t = 8, avg_loss = 0.5836\n",
            "t = 9, avg_loss = 0.6346\n",
            "t = 10, avg_loss = 0.6327\n",
            "t = 11, avg_loss = 0.6181\n",
            "t = 12, avg_loss = 0.7355\n",
            "t = 13, avg_loss = 0.6965\n",
            "Checking accuracy on test set\n",
            "Got 143 / 200 correct (71.50)\n",
            "acc = 0.715000\n",
            "Starting epoch 3 / 80\n",
            "t = 1, avg_loss = 0.6835\n",
            "t = 2, avg_loss = 0.5501\n",
            "t = 3, avg_loss = 0.6105\n",
            "t = 4, avg_loss = 0.6220\n",
            "t = 5, avg_loss = 0.6663\n",
            "t = 6, avg_loss = 0.6665\n",
            "t = 7, avg_loss = 0.5794\n",
            "t = 8, avg_loss = 0.5850\n",
            "t = 9, avg_loss = 0.6657\n",
            "t = 10, avg_loss = 0.6133\n",
            "t = 11, avg_loss = 0.5974\n",
            "t = 12, avg_loss = 0.6337\n",
            "t = 13, avg_loss = 0.6256\n",
            "Checking accuracy on test set\n",
            "Got 140 / 200 correct (70.00)\n",
            "acc = 0.700000\n",
            "Starting epoch 4 / 80\n",
            "t = 1, avg_loss = 0.6484\n",
            "t = 2, avg_loss = 0.6111\n",
            "t = 3, avg_loss = 0.5286\n",
            "t = 4, avg_loss = 0.5979\n",
            "t = 5, avg_loss = 0.6721\n",
            "t = 6, avg_loss = 0.5573\n",
            "t = 7, avg_loss = 0.6055\n",
            "t = 8, avg_loss = 0.7308\n",
            "t = 9, avg_loss = 0.6454\n",
            "t = 10, avg_loss = 0.5582\n",
            "t = 11, avg_loss = 0.5769\n",
            "t = 12, avg_loss = 0.5835\n",
            "t = 13, avg_loss = 0.7356\n",
            "Checking accuracy on test set\n",
            "Got 141 / 200 correct (70.50)\n",
            "acc = 0.705000\n",
            "Starting epoch 5 / 80\n",
            "t = 1, avg_loss = 0.6094\n",
            "t = 2, avg_loss = 0.6157\n",
            "t = 3, avg_loss = 0.5633\n",
            "t = 4, avg_loss = 0.5589\n",
            "t = 5, avg_loss = 0.5431\n",
            "t = 6, avg_loss = 0.5638\n",
            "t = 7, avg_loss = 0.6396\n",
            "t = 8, avg_loss = 0.6410\n",
            "t = 9, avg_loss = 0.5724\n",
            "t = 10, avg_loss = 0.7116\n",
            "t = 11, avg_loss = 0.5676\n",
            "t = 12, avg_loss = 0.5988\n",
            "t = 13, avg_loss = 0.5322\n",
            "Checking accuracy on test set\n",
            "Got 142 / 200 correct (71.00)\n",
            "acc = 0.710000\n",
            "Starting epoch 6 / 80\n",
            "t = 1, avg_loss = 0.5881\n",
            "t = 2, avg_loss = 0.6296\n",
            "t = 3, avg_loss = 0.6626\n",
            "t = 4, avg_loss = 0.6379\n",
            "t = 5, avg_loss = 0.4858\n",
            "t = 6, avg_loss = 0.7076\n",
            "t = 7, avg_loss = 0.6961\n",
            "t = 8, avg_loss = 0.6302\n",
            "t = 9, avg_loss = 0.6772\n",
            "t = 10, avg_loss = 0.5109\n",
            "t = 11, avg_loss = 0.4899\n",
            "t = 12, avg_loss = 0.5304\n",
            "t = 13, avg_loss = 0.6432\n",
            "Checking accuracy on test set\n",
            "Got 143 / 200 correct (71.50)\n",
            "acc = 0.715000\n",
            "Starting epoch 7 / 80\n",
            "t = 1, avg_loss = 0.6234\n",
            "t = 2, avg_loss = 0.5825\n",
            "t = 3, avg_loss = 0.5861\n",
            "t = 4, avg_loss = 0.5715\n",
            "t = 5, avg_loss = 0.6164\n",
            "t = 6, avg_loss = 0.6560\n",
            "t = 7, avg_loss = 0.6750\n",
            "t = 8, avg_loss = 0.5953\n",
            "t = 9, avg_loss = 0.5574\n",
            "t = 10, avg_loss = 0.5286\n",
            "t = 11, avg_loss = 0.6322\n",
            "t = 12, avg_loss = 0.6357\n",
            "t = 13, avg_loss = 0.5144\n",
            "Checking accuracy on test set\n",
            "Got 139 / 200 correct (69.50)\n",
            "acc = 0.695000\n",
            "Starting epoch 8 / 80\n",
            "t = 1, avg_loss = 0.5497\n",
            "t = 2, avg_loss = 0.6331\n",
            "t = 3, avg_loss = 0.5516\n",
            "t = 4, avg_loss = 0.6236\n",
            "t = 5, avg_loss = 0.6442\n",
            "t = 6, avg_loss = 0.5634\n",
            "t = 7, avg_loss = 0.5492\n",
            "t = 8, avg_loss = 0.5518\n",
            "t = 9, avg_loss = 0.6210\n",
            "t = 10, avg_loss = 0.6424\n",
            "t = 11, avg_loss = 0.5552\n",
            "t = 12, avg_loss = 0.6312\n",
            "t = 13, avg_loss = 0.6195\n",
            "Checking accuracy on test set\n",
            "Got 143 / 200 correct (71.50)\n",
            "acc = 0.715000\n",
            "Starting epoch 9 / 80\n",
            "t = 1, avg_loss = 0.6713\n",
            "t = 2, avg_loss = 0.5287\n",
            "t = 3, avg_loss = 0.5843\n",
            "t = 4, avg_loss = 0.6158\n",
            "t = 5, avg_loss = 0.5334\n",
            "t = 6, avg_loss = 0.5056\n",
            "t = 7, avg_loss = 0.5569\n",
            "t = 8, avg_loss = 0.6238\n",
            "t = 9, avg_loss = 0.6005\n",
            "t = 10, avg_loss = 0.6061\n",
            "t = 11, avg_loss = 0.6578\n",
            "t = 12, avg_loss = 0.5757\n",
            "t = 13, avg_loss = 0.5808\n",
            "Checking accuracy on test set\n",
            "Got 146 / 200 correct (73.00)\n",
            "acc = 0.730000\n",
            "Starting epoch 10 / 80\n",
            "t = 1, avg_loss = 0.5181\n",
            "t = 2, avg_loss = 0.6467\n",
            "t = 3, avg_loss = 0.5604\n",
            "t = 4, avg_loss = 0.6197\n",
            "t = 5, avg_loss = 0.5546\n",
            "t = 6, avg_loss = 0.5474\n",
            "t = 7, avg_loss = 0.5569\n",
            "t = 8, avg_loss = 0.6090\n",
            "t = 9, avg_loss = 0.5395\n",
            "t = 10, avg_loss = 0.4876\n",
            "t = 11, avg_loss = 0.5877\n",
            "t = 12, avg_loss = 0.6523\n",
            "t = 13, avg_loss = 0.6195\n",
            "Checking accuracy on test set\n",
            "Got 143 / 200 correct (71.50)\n",
            "acc = 0.715000\n",
            "Starting epoch 11 / 80\n",
            "t = 1, avg_loss = 0.5218\n",
            "t = 2, avg_loss = 0.6147\n",
            "t = 3, avg_loss = 0.6097\n",
            "t = 4, avg_loss = 0.5520\n",
            "t = 5, avg_loss = 0.6039\n",
            "t = 6, avg_loss = 0.6303\n",
            "t = 7, avg_loss = 0.5525\n",
            "t = 8, avg_loss = 0.6468\n",
            "t = 9, avg_loss = 0.5654\n",
            "t = 10, avg_loss = 0.5438\n",
            "t = 11, avg_loss = 0.5706\n",
            "t = 12, avg_loss = 0.5959\n",
            "t = 13, avg_loss = 0.6481\n",
            "Checking accuracy on test set\n",
            "Got 147 / 200 correct (73.50)\n",
            "acc = 0.735000\n",
            "Starting epoch 12 / 80\n",
            "t = 1, avg_loss = 0.5344\n",
            "t = 2, avg_loss = 0.4781\n",
            "t = 3, avg_loss = 0.5506\n",
            "t = 4, avg_loss = 0.6214\n",
            "t = 5, avg_loss = 0.6692\n",
            "t = 6, avg_loss = 0.5398\n",
            "t = 7, avg_loss = 0.6034\n",
            "t = 8, avg_loss = 0.5096\n",
            "t = 9, avg_loss = 0.5248\n",
            "t = 10, avg_loss = 0.5413\n",
            "t = 11, avg_loss = 0.6966\n",
            "t = 12, avg_loss = 0.5043\n",
            "t = 13, avg_loss = 0.6650\n",
            "Checking accuracy on test set\n",
            "Got 155 / 200 correct (77.50)\n",
            "acc = 0.775000\n",
            "Starting epoch 13 / 80\n",
            "t = 1, avg_loss = 0.5167\n",
            "t = 2, avg_loss = 0.5405\n",
            "t = 3, avg_loss = 0.6252\n",
            "t = 4, avg_loss = 0.5458\n",
            "t = 5, avg_loss = 0.6229\n",
            "t = 6, avg_loss = 0.6405\n",
            "t = 7, avg_loss = 0.5094\n",
            "t = 8, avg_loss = 0.5286\n",
            "t = 9, avg_loss = 0.5319\n",
            "t = 10, avg_loss = 0.6511\n",
            "t = 11, avg_loss = 0.7090\n",
            "t = 12, avg_loss = 0.4365\n",
            "t = 13, avg_loss = 0.5941\n",
            "Checking accuracy on test set\n",
            "Got 139 / 200 correct (69.50)\n",
            "acc = 0.695000\n",
            "Starting epoch 14 / 80\n",
            "t = 1, avg_loss = 0.4971\n",
            "t = 2, avg_loss = 0.6777\n",
            "t = 3, avg_loss = 0.5541\n",
            "t = 4, avg_loss = 0.5360\n",
            "t = 5, avg_loss = 0.5291\n",
            "t = 6, avg_loss = 0.5674\n",
            "t = 7, avg_loss = 0.6477\n",
            "t = 8, avg_loss = 0.6599\n",
            "t = 9, avg_loss = 0.5060\n",
            "t = 10, avg_loss = 0.5669\n",
            "t = 11, avg_loss = 0.5207\n",
            "t = 12, avg_loss = 0.5086\n",
            "t = 13, avg_loss = 0.4442\n",
            "Checking accuracy on test set\n",
            "Got 150 / 200 correct (75.00)\n",
            "acc = 0.750000\n",
            "Starting epoch 15 / 80\n",
            "t = 1, avg_loss = 0.5149\n",
            "t = 2, avg_loss = 0.5646\n",
            "t = 3, avg_loss = 0.5484\n",
            "t = 4, avg_loss = 0.6329\n",
            "t = 5, avg_loss = 0.6136\n",
            "t = 6, avg_loss = 0.5803\n",
            "t = 7, avg_loss = 0.5300\n",
            "t = 8, avg_loss = 0.6631\n",
            "t = 9, avg_loss = 0.5656\n",
            "t = 10, avg_loss = 0.5823\n",
            "t = 11, avg_loss = 0.5229\n",
            "t = 12, avg_loss = 0.5279\n",
            "t = 13, avg_loss = 0.6696\n",
            "Checking accuracy on test set\n",
            "Got 149 / 200 correct (74.50)\n",
            "acc = 0.745000\n",
            "Starting epoch 16 / 80\n",
            "t = 1, avg_loss = 0.5396\n",
            "t = 2, avg_loss = 0.5146\n",
            "t = 3, avg_loss = 0.6129\n",
            "t = 4, avg_loss = 0.4576\n",
            "t = 5, avg_loss = 0.4928\n",
            "t = 6, avg_loss = 0.5184\n",
            "t = 7, avg_loss = 0.7737\n",
            "t = 8, avg_loss = 0.6144\n",
            "t = 9, avg_loss = 0.4804\n",
            "t = 10, avg_loss = 0.5782\n",
            "t = 11, avg_loss = 0.5450\n",
            "t = 12, avg_loss = 0.6310\n",
            "t = 13, avg_loss = 0.5675\n",
            "Checking accuracy on test set\n",
            "Got 148 / 200 correct (74.00)\n",
            "acc = 0.740000\n",
            "Starting epoch 17 / 80\n",
            "t = 1, avg_loss = 0.4823\n",
            "t = 2, avg_loss = 0.4847\n",
            "t = 3, avg_loss = 0.4916\n",
            "t = 4, avg_loss = 0.6315\n",
            "t = 5, avg_loss = 0.6070\n",
            "t = 6, avg_loss = 0.6145\n",
            "t = 7, avg_loss = 0.5391\n",
            "t = 8, avg_loss = 0.5956\n",
            "t = 9, avg_loss = 0.5922\n",
            "t = 10, avg_loss = 0.5546\n",
            "t = 11, avg_loss = 0.5215\n",
            "t = 12, avg_loss = 0.5926\n",
            "t = 13, avg_loss = 0.5767\n",
            "Checking accuracy on test set\n",
            "Got 151 / 200 correct (75.50)\n",
            "acc = 0.755000\n",
            "Starting epoch 18 / 80\n",
            "t = 1, avg_loss = 0.6276\n",
            "t = 2, avg_loss = 0.4955\n",
            "t = 3, avg_loss = 0.5393\n",
            "t = 4, avg_loss = 0.5146\n",
            "t = 5, avg_loss = 0.5638\n",
            "t = 6, avg_loss = 0.6037\n",
            "t = 7, avg_loss = 0.5109\n",
            "t = 8, avg_loss = 0.5067\n",
            "t = 9, avg_loss = 0.4259\n",
            "t = 10, avg_loss = 0.5829\n",
            "t = 11, avg_loss = 0.6427\n",
            "t = 12, avg_loss = 0.6256\n",
            "t = 13, avg_loss = 0.5850\n",
            "Checking accuracy on test set\n",
            "Got 147 / 200 correct (73.50)\n",
            "acc = 0.735000\n",
            "Starting epoch 19 / 80\n",
            "t = 1, avg_loss = 0.6046\n",
            "t = 2, avg_loss = 0.6516\n",
            "t = 3, avg_loss = 0.5429\n",
            "t = 4, avg_loss = 0.6248\n",
            "t = 5, avg_loss = 0.5287\n",
            "t = 6, avg_loss = 0.5880\n",
            "t = 7, avg_loss = 0.5618\n",
            "t = 8, avg_loss = 0.4459\n",
            "t = 9, avg_loss = 0.5337\n",
            "t = 10, avg_loss = 0.5187\n",
            "t = 11, avg_loss = 0.6726\n",
            "t = 12, avg_loss = 0.4970\n",
            "t = 13, avg_loss = 0.4031\n",
            "Checking accuracy on test set\n",
            "Got 140 / 200 correct (70.00)\n",
            "acc = 0.700000\n",
            "Starting epoch 20 / 80\n",
            "t = 1, avg_loss = 0.5685\n",
            "t = 2, avg_loss = 0.5376\n",
            "t = 3, avg_loss = 0.5475\n",
            "t = 4, avg_loss = 0.4715\n",
            "t = 5, avg_loss = 0.5307\n",
            "t = 6, avg_loss = 0.5193\n",
            "t = 7, avg_loss = 0.6301\n",
            "t = 8, avg_loss = 0.6424\n",
            "t = 9, avg_loss = 0.6679\n",
            "t = 10, avg_loss = 0.5627\n",
            "t = 11, avg_loss = 0.4473\n",
            "t = 12, avg_loss = 0.4933\n",
            "t = 13, avg_loss = 0.4979\n",
            "Checking accuracy on test set\n",
            "Got 150 / 200 correct (75.00)\n",
            "acc = 0.750000\n",
            "Starting epoch 21 / 80\n",
            "t = 1, avg_loss = 0.4996\n",
            "t = 2, avg_loss = 0.5141\n",
            "t = 3, avg_loss = 0.5630\n",
            "t = 4, avg_loss = 0.5527\n",
            "t = 5, avg_loss = 0.5502\n",
            "t = 6, avg_loss = 0.5598\n",
            "t = 7, avg_loss = 0.5500\n",
            "t = 8, avg_loss = 0.5033\n",
            "t = 9, avg_loss = 0.5633\n",
            "t = 10, avg_loss = 0.5748\n",
            "t = 11, avg_loss = 0.5440\n",
            "t = 12, avg_loss = 0.6071\n",
            "t = 13, avg_loss = 0.6225\n",
            "Checking accuracy on test set\n",
            "Got 151 / 200 correct (75.50)\n",
            "acc = 0.755000\n",
            "Starting epoch 22 / 80\n",
            "t = 1, avg_loss = 0.5762\n",
            "t = 2, avg_loss = 0.5097\n",
            "t = 3, avg_loss = 0.4862\n",
            "t = 4, avg_loss = 0.6247\n",
            "t = 5, avg_loss = 0.4991\n",
            "t = 6, avg_loss = 0.4771\n",
            "t = 7, avg_loss = 0.5450\n",
            "t = 8, avg_loss = 0.5644\n",
            "t = 9, avg_loss = 0.4589\n",
            "t = 10, avg_loss = 0.6515\n",
            "t = 11, avg_loss = 0.5741\n",
            "t = 12, avg_loss = 0.5323\n",
            "t = 13, avg_loss = 0.4750\n",
            "Checking accuracy on test set\n",
            "Got 148 / 200 correct (74.00)\n",
            "acc = 0.740000\n",
            "Starting epoch 23 / 80\n",
            "t = 1, avg_loss = 0.5001\n",
            "t = 2, avg_loss = 0.5217\n",
            "t = 3, avg_loss = 0.5346\n",
            "t = 4, avg_loss = 0.4781\n",
            "t = 5, avg_loss = 0.5275\n",
            "t = 6, avg_loss = 0.6357\n",
            "t = 7, avg_loss = 0.5454\n",
            "t = 8, avg_loss = 0.4823\n",
            "t = 9, avg_loss = 0.4764\n",
            "t = 10, avg_loss = 0.5367\n",
            "t = 11, avg_loss = 0.4639\n",
            "t = 12, avg_loss = 0.6215\n",
            "t = 13, avg_loss = 0.7710\n",
            "Checking accuracy on test set\n",
            "Got 148 / 200 correct (74.00)\n",
            "acc = 0.740000\n",
            "Starting epoch 24 / 80\n",
            "t = 1, avg_loss = 0.5813\n",
            "t = 2, avg_loss = 0.4968\n",
            "t = 3, avg_loss = 0.5490\n",
            "t = 4, avg_loss = 0.5930\n",
            "t = 5, avg_loss = 0.5528\n",
            "t = 6, avg_loss = 0.5536\n",
            "t = 7, avg_loss = 0.4856\n",
            "t = 8, avg_loss = 0.4685\n",
            "t = 9, avg_loss = 0.6881\n",
            "t = 10, avg_loss = 0.4525\n",
            "t = 11, avg_loss = 0.5379\n",
            "t = 12, avg_loss = 0.5776\n",
            "t = 13, avg_loss = 0.4941\n",
            "Checking accuracy on test set\n",
            "Got 148 / 200 correct (74.00)\n",
            "acc = 0.740000\n",
            "Starting epoch 25 / 80\n",
            "t = 1, avg_loss = 0.4688\n",
            "t = 2, avg_loss = 0.6138\n",
            "t = 3, avg_loss = 0.5614\n",
            "t = 4, avg_loss = 0.5698\n",
            "t = 5, avg_loss = 0.6888\n",
            "t = 6, avg_loss = 0.4851\n",
            "t = 7, avg_loss = 0.5484\n",
            "t = 8, avg_loss = 0.4037\n",
            "t = 9, avg_loss = 0.5734\n",
            "t = 10, avg_loss = 0.5880\n",
            "t = 11, avg_loss = 0.4743\n",
            "t = 12, avg_loss = 0.4725\n",
            "t = 13, avg_loss = 0.5730\n",
            "Checking accuracy on test set\n",
            "Got 148 / 200 correct (74.00)\n",
            "acc = 0.740000\n",
            "Starting epoch 26 / 80\n",
            "t = 1, avg_loss = 0.5515\n",
            "t = 2, avg_loss = 0.4886\n",
            "t = 3, avg_loss = 0.4928\n",
            "t = 4, avg_loss = 0.4949\n",
            "t = 5, avg_loss = 0.5255\n",
            "t = 6, avg_loss = 0.6298\n",
            "t = 7, avg_loss = 0.4672\n",
            "t = 8, avg_loss = 0.5635\n",
            "t = 9, avg_loss = 0.5333\n",
            "t = 10, avg_loss = 0.5544\n",
            "t = 11, avg_loss = 0.5657\n",
            "t = 12, avg_loss = 0.7273\n",
            "t = 13, avg_loss = 0.4431\n",
            "Checking accuracy on test set\n",
            "Got 139 / 200 correct (69.50)\n",
            "acc = 0.695000\n",
            "Starting epoch 27 / 80\n",
            "t = 1, avg_loss = 0.5199\n",
            "t = 2, avg_loss = 0.5410\n",
            "t = 3, avg_loss = 0.4931\n",
            "t = 4, avg_loss = 0.5467\n",
            "t = 5, avg_loss = 0.6572\n",
            "t = 6, avg_loss = 0.5063\n",
            "t = 7, avg_loss = 0.5632\n",
            "t = 8, avg_loss = 0.6347\n",
            "t = 9, avg_loss = 0.5212\n",
            "t = 10, avg_loss = 0.5919\n",
            "t = 11, avg_loss = 0.4913\n",
            "t = 12, avg_loss = 0.5989\n",
            "t = 13, avg_loss = 0.5651\n",
            "Checking accuracy on test set\n",
            "Got 141 / 200 correct (70.50)\n",
            "acc = 0.705000\n",
            "Starting epoch 28 / 80\n",
            "t = 1, avg_loss = 0.6118\n",
            "t = 2, avg_loss = 0.5986\n",
            "t = 3, avg_loss = 0.5028\n",
            "t = 4, avg_loss = 0.5176\n",
            "t = 5, avg_loss = 0.5616\n",
            "t = 6, avg_loss = 0.5779\n",
            "t = 7, avg_loss = 0.5270\n",
            "t = 8, avg_loss = 0.5706\n",
            "t = 9, avg_loss = 0.5023\n",
            "t = 10, avg_loss = 0.5101\n",
            "t = 11, avg_loss = 0.5270\n",
            "t = 12, avg_loss = 0.5069\n",
            "t = 13, avg_loss = 0.4546\n",
            "Checking accuracy on test set\n",
            "Got 146 / 200 correct (73.00)\n",
            "acc = 0.730000\n",
            "Starting epoch 29 / 80\n",
            "t = 1, avg_loss = 0.4768\n",
            "t = 2, avg_loss = 0.6809\n",
            "t = 3, avg_loss = 0.4632\n",
            "t = 4, avg_loss = 0.4070\n",
            "t = 5, avg_loss = 0.5078\n",
            "t = 6, avg_loss = 0.6102\n",
            "t = 7, avg_loss = 0.4586\n",
            "t = 8, avg_loss = 0.6641\n",
            "t = 9, avg_loss = 0.4971\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-bbd027491826>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_gpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0mcheck_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-7b7c48cb9b8f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, loss_fn, optimizer, num_epochs, starting_from_epoch)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mx_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0my_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-50a9cd504daf>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m           \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"malignant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"malignant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \"\"\"\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   1871\u001b[0m                 )\n\u001b[1;32m   1872\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1873\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1875\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nr2sQUvYlXYm",
        "colab_type": "code",
        "outputId": "943f0e90-4980-44f1-bf25-39634f4853d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "check_accuracy(model_gpu, valid_loader)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking accuracy on test set\n",
            "Got 147 / 200 correct (73.50)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.735"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkR_h7GRTJv4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6574df4f71dd45f6b8f7672c58f6aecd",
            "c9fe6bfde87446f3b3fcc0a79cd30f42",
            "e7d91d8e44ba45a292da688db47ab39a",
            "4527102e2f4e4179bd564943e1af316f",
            "6c1bf0a296fa400db8e27e234ac85c4b",
            "1101b56c50f64831adf19f37a6b1895c",
            "680b2d76f8664bff8d26b5631a58e9e6",
            "57cf14edc2374adb85832079cda7fde0"
          ]
        },
        "outputId": "1492a4ec-f4a7-4f44-85be-88edff4c0505"
      },
      "source": [
        "! pip install torch-lr-finder -v --global-option=\"amp\"\n",
        "from torch_lr_finder import LRFinder\n",
        "\n",
        "lr_finder = LRFinder(model_gpu, optimizer, loss_fn, device=\"cuda\")\n",
        "\n",
        "lr_finder.range_test(train_loader, end_lr=1, num_iter=100, start_lr=1e-05)\n",
        "lr_finder.plot() "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pip/_internal/commands/install.py:283: UserWarning: Disabling all use of wheels due to the use of --build-options / --global-options / --install-options.\n",
            "  cmdoptions.check_install_build_global(options)\n",
            "Created temporary directory: /tmp/pip-ephem-wheel-cache-54aoghcg\n",
            "Created temporary directory: /tmp/pip-req-tracker-d0qghumx\n",
            "Created requirements tracker '/tmp/pip-req-tracker-d0qghumx'\n",
            "Created temporary directory: /tmp/pip-install-k7ezk3vx\n",
            "1 location(s) to search for versions of torch-lr-finder:\n",
            "* https://pypi.org/simple/torch-lr-finder/\n",
            "Getting page https://pypi.org/simple/torch-lr-finder/\n",
            "Found index url https://pypi.org/simple\n",
            "Looking up \"https://pypi.org/simple/torch-lr-finder/\" in the cache\n",
            "Request header has \"max_age\" as 0, cache bypassed\n",
            "Starting new HTTPS connection (1): pypi.org:443\n",
            "https://pypi.org:443 \"GET /simple/torch-lr-finder/ HTTP/1.1\" 200 1168\n",
            "Updating cache with response from \"https://pypi.org/simple/torch-lr-finder/\"\n",
            "Caching due to etag\n",
            "Analyzing links from page https://pypi.org/simple/torch-lr-finder/\n",
            "  Found link https://files.pythonhosted.org/packages/5d/cd/91f910b0b05cb72ad66db3b8a82b86f8e1ab4241398eef8dc4dfd033a7eb/torch-lr-finder-0.0.1.tar.gz#sha256=3d1f91f0232f069325b456348b97d7936921f77393cef10e8253b3cb7cc2932d (from https://pypi.org/simple/torch-lr-finder/) (requires-python:>=2.7), version: 0.0.1\n",
            "  Skipping link: No binaries permitted for torch-lr-finder: https://files.pythonhosted.org/packages/62/7c/397078ef7ca83880a35037285fd9d1f0e70ab5414db3a6f81e868c7230e4/torch_lr_finder-0.0.1-py3-none-any.whl#sha256=7f690a2e093b10c0e1935e013572c4be7225820c5be40af56139a6c28626db9e (from https://pypi.org/simple/torch-lr-finder/) (requires-python:>=2.7)\n",
            "  Found link https://files.pythonhosted.org/packages/0b/7b/a8ccefca947877cb0112dc3b1ceea38caa24b9f75d6601769075ab6d624b/torch-lr-finder-0.1.tar.gz#sha256=cfee0b94701cd51eb69856a2def48423f5c26cbe74514880a1f5eb09d90aa841 (from https://pypi.org/simple/torch-lr-finder/) (requires-python:>=2.7), version: 0.1\n",
            "  Skipping link: No binaries permitted for torch-lr-finder: https://files.pythonhosted.org/packages/c5/a8/1a003a5b3ff76d3ee55e814028f2fd4d79c555956c36eaebd663a9cf0935/torch_lr_finder-0.1-py3-none-any.whl#sha256=1f218b9704e6cbac26d754c72e088124411c7a495665517f91f05c050d55443e (from https://pypi.org/simple/torch-lr-finder/) (requires-python:>=2.7)\n",
            "  Found link https://files.pythonhosted.org/packages/6f/05/8384b9c02748b40d17a08c18cea7d090872423990934b1a95d0db0ea3481/torch-lr-finder-0.1.2.tar.gz#sha256=79b97995cab86b392230497313857891041861d6d63d1b608fb285e01f8bfafa (from https://pypi.org/simple/torch-lr-finder/) (requires-python:>=2.7), version: 0.1.2\n",
            "  Skipping link: No binaries permitted for torch-lr-finder: https://files.pythonhosted.org/packages/8d/5a/28e71a45ff80efb2ed0759ceef0d34a713f4376119746246c12671c0c807/torch_lr_finder-0.1.2-py3-none-any.whl#sha256=c2af8c2cd539d29738c8903b5f604c11367de8415a90fafdd3cdc179c5d13bcc (from https://pypi.org/simple/torch-lr-finder/) (requires-python:>=2.7)\n",
            "  Found link https://files.pythonhosted.org/packages/92/d5/893fc09e1a9fc72bcef256806edb911db8e3762dc3cb90fd0f817d45f8c6/torch-lr-finder-0.1.3.tar.gz#sha256=7ad4f78300c5a6754890765db51bcc2f0335b05208010c5e97a0f174ef0036d9 (from https://pypi.org/simple/torch-lr-finder/) (requires-python:>=2.7), version: 0.1.3\n",
            "  Skipping link: No binaries permitted for torch-lr-finder: https://files.pythonhosted.org/packages/cd/ff/38ec8729a7a0a4d8045f100705a5dc1ae259d169e6f5f67c6e21c3f9d5cf/torch_lr_finder-0.1.3-py3-none-any.whl#sha256=d9ed12a5ad5a37c8df1d6e88818ef06a9a9585187b3ea2abf58ace7670474df8 (from https://pypi.org/simple/torch-lr-finder/) (requires-python:>=2.7)\n",
            "  Found link https://files.pythonhosted.org/packages/c3/27/976e1a3bbf9721619a06304b8db7ab9c40207ab29e7e0ba84bbe3ff28ad0/torch-lr-finder-0.1.4.tar.gz#sha256=8329faef69f5638fc641813f13a2fdec3156d754e1fa484bb4ddf6cd28f2feef (from https://pypi.org/simple/torch-lr-finder/) (requires-python:>=2.7), version: 0.1.4\n",
            "  Skipping link: No binaries permitted for torch-lr-finder: https://files.pythonhosted.org/packages/68/06/7301400132b63f96c3b4f5fbb5033130b9d07b85c9e0e247d4ac03451d80/torch_lr_finder-0.1.4-py3-none-any.whl#sha256=fb9ec3599b913202540ff3b960c691c1a07abeab0c2b7e60b314704bc886193e (from https://pypi.org/simple/torch-lr-finder/) (requires-python:>=2.7)\n",
            "Given no hashes to check 5 links for project 'torch-lr-finder': discarding no candidates\n",
            "Using version 0.1.4 (newest of versions: 0.0.1, 0.1, 0.1.2, 0.1.3, 0.1.4)\n",
            "Collecting torch-lr-finder\n",
            "  Created temporary directory: /tmp/pip-unpack-3heani4y\n",
            "  Looking up \"https://files.pythonhosted.org/packages/c3/27/976e1a3bbf9721619a06304b8db7ab9c40207ab29e7e0ba84bbe3ff28ad0/torch-lr-finder-0.1.4.tar.gz\" in the cache\n",
            "  No cache entry available\n",
            "  Starting new HTTPS connection (1): files.pythonhosted.org:443\n",
            "  https://files.pythonhosted.org:443 \"GET /packages/c3/27/976e1a3bbf9721619a06304b8db7ab9c40207ab29e7e0ba84bbe3ff28ad0/torch-lr-finder-0.1.4.tar.gz HTTP/1.1\" 200 9783\n",
            "  Downloading https://files.pythonhosted.org/packages/c3/27/976e1a3bbf9721619a06304b8db7ab9c40207ab29e7e0ba84bbe3ff28ad0/torch-lr-finder-0.1.4.tar.gz\n",
            "  Ignoring unknown cache-control directive: immutable\n",
            "  Updating cache with response from \"https://files.pythonhosted.org/packages/c3/27/976e1a3bbf9721619a06304b8db7ab9c40207ab29e7e0ba84bbe3ff28ad0/torch-lr-finder-0.1.4.tar.gz\"\n",
            "  Caching due to etag\n",
            "  Added torch-lr-finder from https://files.pythonhosted.org/packages/c3/27/976e1a3bbf9721619a06304b8db7ab9c40207ab29e7e0ba84bbe3ff28ad0/torch-lr-finder-0.1.4.tar.gz#sha256=8329faef69f5638fc641813f13a2fdec3156d754e1fa484bb4ddf6cd28f2feef to build tracker '/tmp/pip-req-tracker-d0qghumx'\n",
            "    Running setup.py (path:/tmp/pip-install-k7ezk3vx/torch-lr-finder/setup.py) egg_info for package torch-lr-finder\n",
            "    Running command python setup.py egg_info\n",
            "    running egg_info\n",
            "    creating /tmp/pip-install-k7ezk3vx/torch-lr-finder/pip-egg-info/torch_lr_finder.egg-info\n",
            "    writing /tmp/pip-install-k7ezk3vx/torch-lr-finder/pip-egg-info/torch_lr_finder.egg-info/PKG-INFO\n",
            "    writing dependency_links to /tmp/pip-install-k7ezk3vx/torch-lr-finder/pip-egg-info/torch_lr_finder.egg-info/dependency_links.txt\n",
            "    writing requirements to /tmp/pip-install-k7ezk3vx/torch-lr-finder/pip-egg-info/torch_lr_finder.egg-info/requires.txt\n",
            "    writing top-level names to /tmp/pip-install-k7ezk3vx/torch-lr-finder/pip-egg-info/torch_lr_finder.egg-info/top_level.txt\n",
            "    writing manifest file '/tmp/pip-install-k7ezk3vx/torch-lr-finder/pip-egg-info/torch_lr_finder.egg-info/SOURCES.txt'\n",
            "    reading manifest file '/tmp/pip-install-k7ezk3vx/torch-lr-finder/pip-egg-info/torch_lr_finder.egg-info/SOURCES.txt'\n",
            "    writing manifest file '/tmp/pip-install-k7ezk3vx/torch-lr-finder/pip-egg-info/torch_lr_finder.egg-info/SOURCES.txt'\n",
            "  Source in /tmp/pip-install-k7ezk3vx/torch-lr-finder has version 0.1.4, which satisfies requirement torch-lr-finder from https://files.pythonhosted.org/packages/c3/27/976e1a3bbf9721619a06304b8db7ab9c40207ab29e7e0ba84bbe3ff28ad0/torch-lr-finder-0.1.4.tar.gz#sha256=8329faef69f5638fc641813f13a2fdec3156d754e1fa484bb4ddf6cd28f2feef\n",
            "  Removed torch-lr-finder from https://files.pythonhosted.org/packages/c3/27/976e1a3bbf9721619a06304b8db7ab9c40207ab29e7e0ba84bbe3ff28ad0/torch-lr-finder-0.1.4.tar.gz#sha256=8329faef69f5638fc641813f13a2fdec3156d754e1fa484bb4ddf6cd28f2feef from build tracker '/tmp/pip-req-tracker-d0qghumx'\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from torch-lr-finder) (3.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch-lr-finder) (1.18.2)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from torch-lr-finder) (1.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torch-lr-finder) (4.38.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->torch-lr-finder) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->torch-lr-finder) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->torch-lr-finder) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->torch-lr-finder) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->torch-lr-finder) (1.12.0)\n",
            "Skipping wheel build for torch-lr-finder, due to binaries being disabled for it.\n",
            "Installing collected packages: torch-lr-finder\n",
            "  Created temporary directory: /tmp/pip-record-8c2d09cb\n",
            "    Running command /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-k7ezk3vx/torch-lr-finder/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-k7ezk3vx/torch-lr-finder/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' amp install --record /tmp/pip-record-8c2d09cb/install-record.txt --single-version-externally-managed --compile\n",
            "    /usr/local/lib/python3.6/dist-packages/pip/_internal/commands/install.py:283: UserWarning: Disabling all use of wheels due to the use of --build-options / --global-options / --install-options.\n",
            "      cmdoptions.check_install_build_global(options)\n",
            "    Created temporary directory: /tmp/pip-ephem-wheel-cache-u1cib3fy\n",
            "    Re-using requirements tracker '/tmp/pip-req-tracker-d0qghumx'\n",
            "    Created temporary directory: /tmp/pip-install-m7746qs7\n",
            "    Collecting git+https://github.com/NVIDIA/apex\n",
            "      Created temporary directory: /tmp/pip-req-build-cw_lyszl\n",
            "      Cloning https://github.com/NVIDIA/apex to /tmp/pip-req-build-cw_lyszl\n",
            "      Running command git clone -q https://github.com/NVIDIA/apex /tmp/pip-req-build-cw_lyszl\n",
            "      Running command git submodule update --init --recursive -q\n",
            "      Added git+https://github.com/NVIDIA/apex to build tracker '/tmp/pip-req-tracker-d0qghumx'\n",
            "        Running setup.py (path:/tmp/pip-req-build-cw_lyszl/setup.py) egg_info for package from git+https://github.com/NVIDIA/apex\n",
            "        Running command python setup.py egg_info\n",
            "        torch.__version__  =  1.4.0\n",
            "        running egg_info\n",
            "        creating /tmp/pip-req-build-cw_lyszl/pip-egg-info/apex.egg-info\n",
            "        writing /tmp/pip-req-build-cw_lyszl/pip-egg-info/apex.egg-info/PKG-INFO\n",
            "        writing dependency_links to /tmp/pip-req-build-cw_lyszl/pip-egg-info/apex.egg-info/dependency_links.txt\n",
            "        writing top-level names to /tmp/pip-req-build-cw_lyszl/pip-egg-info/apex.egg-info/top_level.txt\n",
            "        writing manifest file '/tmp/pip-req-build-cw_lyszl/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
            "        writing manifest file '/tmp/pip-req-build-cw_lyszl/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
            "        /tmp/pip-req-build-cw_lyszl/setup.py:46: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "          warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "      Source in /tmp/pip-req-build-cw_lyszl has version 0.1, which satisfies requirement apex==0.1 from git+https://github.com/NVIDIA/apex\n",
            "      Removed apex==0.1 from git+https://github.com/NVIDIA/apex from build tracker '/tmp/pip-req-tracker-d0qghumx'\n",
            "    Skipping wheel build for apex, due to binaries being disabled for it.\n",
            "    Installing collected packages: apex\n",
            "      Created temporary directory: /tmp/pip-record-le7rzoff\n",
            "        Running setup.py install for apex: started\n",
            "        Running command /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-cw_lyszl/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-cw_lyszl/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' --cpp_ext --cuda_ext install --record /tmp/pip-record-le7rzoff/install-record.txt --single-version-externally-managed --compile\n",
            "        torch.__version__  =  1.4.0\n",
            "        /tmp/pip-req-build-cw_lyszl/setup.py:46: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "          warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "\n",
            "        Compiling cuda extensions with\n",
            "        nvcc: NVIDIA (R) Cuda compiler driver\n",
            "        Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "        Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "        Cuda compilation tools, release 10.1, V10.1.243\n",
            "        from /usr/local/cuda/bin\n",
            "\n",
            "        running install\n",
            "        running build\n",
            "        running build_py\n",
            "        creating build\n",
            "        creating build/lib.linux-x86_64-3.6\n",
            "        creating build/lib.linux-x86_64-3.6/apex\n",
            "        copying apex/__init__.py -> build/lib.linux-x86_64-3.6/apex\n",
            "        creating build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "        copying apex/fp16_utils/__init__.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "        copying apex/fp16_utils/loss_scaler.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "        copying apex/fp16_utils/fp16util.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "        copying apex/fp16_utils/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "        creating build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "        copying apex/reparameterization/__init__.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "        copying apex/reparameterization/reparameterization.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "        copying apex/reparameterization/weight_norm.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "        creating build/lib.linux-x86_64-3.6/apex/pyprof\n",
            "        copying apex/pyprof/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof\n",
            "        creating build/lib.linux-x86_64-3.6/apex/normalization\n",
            "        copying apex/normalization/__init__.py -> build/lib.linux-x86_64-3.6/apex/normalization\n",
            "        copying apex/normalization/fused_layer_norm.py -> build/lib.linux-x86_64-3.6/apex/normalization\n",
            "        creating build/lib.linux-x86_64-3.6/apex/parallel\n",
            "        copying apex/parallel/optimized_sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "        copying apex/parallel/__init__.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "        copying apex/parallel/LARC.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "        copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "        copying apex/parallel/sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "        copying apex/parallel/sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "        copying apex/parallel/multiproc.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "        copying apex/parallel/distributed.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "        creating build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
            "        copying apex/multi_tensor_apply/__init__.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
            "        copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
            "        creating build/lib.linux-x86_64-3.6/apex/amp\n",
            "        copying apex/amp/opt.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "        copying apex/amp/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "        copying apex/amp/scaler.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "        copying apex/amp/_amp_state.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "        copying apex/amp/_initialize.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "        copying apex/amp/frontend.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "        copying apex/amp/__version__.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "        copying apex/amp/_process_optimizer.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "        copying apex/amp/compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "        copying apex/amp/rnn_compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "        copying apex/amp/wrap.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "        copying apex/amp/utils.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "        copying apex/amp/amp.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "        copying apex/amp/handle.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "        creating build/lib.linux-x86_64-3.6/apex/contrib\n",
            "        copying apex/contrib/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib\n",
            "        creating build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "        copying apex/optimizers/__init__.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "        copying apex/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "        copying apex/optimizers/fused_novograd.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "        copying apex/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "        copying apex/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "        creating build/lib.linux-x86_64-3.6/apex/RNN\n",
            "        copying apex/RNN/__init__.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "        copying apex/RNN/cells.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "        copying apex/RNN/models.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "        copying apex/RNN/RNNBackend.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "        creating build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
            "        copying apex/pyprof/nvtx/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
            "        copying apex/pyprof/nvtx/nvmarker.py -> build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
            "        creating build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/data.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/recurrentCell.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/base.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/usage.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/dropout.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/embedding.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/output.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/randomSample.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/loss.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/reduction.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/normalization.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/misc.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/pooling.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/convert.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/linear.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/softmax.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/utility.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/conv.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/pointwise.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/index_slice_join_mutate.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/activation.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/blas.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/__main__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/prof.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/optim.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        creating build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "        copying apex/pyprof/parse/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "        copying apex/pyprof/parse/parse.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "        copying apex/pyprof/parse/nvvp.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "        copying apex/pyprof/parse/kernel.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "        copying apex/pyprof/parse/db.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "        copying apex/pyprof/parse/__main__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "        creating build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "        copying apex/amp/lists/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "        copying apex/amp/lists/functional_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "        copying apex/amp/lists/tensor_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "        copying apex/amp/lists/torch_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "        creating build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "        copying apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "        copying apex/contrib/multihead_attn/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "        copying apex/contrib/multihead_attn/self_multihead_attn.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "        copying apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "        copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "        copying apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "        copying apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "        copying apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "        copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "        creating build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n",
            "        copying apex/contrib/groupbn/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n",
            "        copying apex/contrib/groupbn/batch_norm.py -> build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n",
            "        creating build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "        copying apex/contrib/optimizers/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "        copying apex/contrib/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "        copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "        copying apex/contrib/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "        creating build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n",
            "        copying apex/contrib/xentropy/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n",
            "        copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n",
            "        running build_ext\n",
            "        building 'apex_C' extension\n",
            "        creating build/temp.linux-x86_64-3.6\n",
            "        creating build/temp.linux-x86_64-3.6/csrc\n",
            "        x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c csrc/flatten_unflatten.cpp -o build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=apex_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "        x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -o build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so\n",
            "        building 'amp_C' extension\n",
            "        x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/amp_C_frontend.cpp -o build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "        /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_sgd_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_sgd_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++11\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_scale_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++11\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_axpby_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++11\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_l2norm_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++11\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb_stage_1.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_1.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++11\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb_stage_2.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_2.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++11\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_adam.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adam.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++11\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_novograd.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_novograd.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++11\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++11\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_sgd_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_1.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_2.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adam.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_novograd.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so\n",
            "        building 'syncbn' extension\n",
            "        x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/syncbn.cpp -o build/temp.linux-x86_64-3.6/csrc/syncbn.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "        /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/welford.cu -o build/temp.linux-x86_64-3.6/csrc/welford.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++11\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/syncbn.o build/temp.linux-x86_64-3.6/csrc/welford.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so\n",
            "        building 'fused_layer_norm_cuda' extension\n",
            "        x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/layer_norm_cuda.cpp -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "        /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/layer_norm_cuda_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -maxrregcount=50 -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++11\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "        running install_lib\n",
            "        creating /usr/local/lib/python3.6/dist-packages/apex\n",
            "        creating /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
            "        copying build/lib.linux-x86_64-3.6/apex/fp16_utils/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
            "        copying build/lib.linux-x86_64-3.6/apex/fp16_utils/loss_scaler.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
            "        copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16util.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
            "        copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
            "        creating /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
            "        copying build/lib.linux-x86_64-3.6/apex/reparameterization/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
            "        copying build/lib.linux-x86_64-3.6/apex/reparameterization/reparameterization.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
            "        copying build/lib.linux-x86_64-3.6/apex/reparameterization/weight_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
            "        copying build/lib.linux-x86_64-3.6/apex/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex\n",
            "        creating /usr/local/lib/python3.6/dist-packages/apex/pyprof\n",
            "        creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/nvtx/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/nvtx/nvmarker.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof\n",
            "        creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/data.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/recurrentCell.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/base.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/usage.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/dropout.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/embedding.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/output.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/randomSample.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/loss.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/reduction.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/normalization.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/misc.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/pooling.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/convert.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/linear.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/softmax.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/utility.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/conv.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/pointwise.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/index_slice_join_mutate.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/activation.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/blas.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/__main__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/prof.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/optim.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/parse.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/nvvp.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/db.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/__main__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "        creating /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
            "        copying build/lib.linux-x86_64-3.6/apex/normalization/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
            "        copying build/lib.linux-x86_64-3.6/apex/normalization/fused_layer_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
            "        creating /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "        copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "        copying build/lib.linux-x86_64-3.6/apex/parallel/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "        copying build/lib.linux-x86_64-3.6/apex/parallel/LARC.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "        copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm_kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "        copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm_kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "        copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "        copying build/lib.linux-x86_64-3.6/apex/parallel/multiproc.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "        copying build/lib.linux-x86_64-3.6/apex/parallel/distributed.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "        creating /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
            "        copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
            "        copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/multi_tensor_apply.py -> /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
            "        creating /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "        copying build/lib.linux-x86_64-3.6/apex/amp/opt.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "        copying build/lib.linux-x86_64-3.6/apex/amp/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "        creating /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
            "        copying build/lib.linux-x86_64-3.6/apex/amp/lists/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
            "        copying build/lib.linux-x86_64-3.6/apex/amp/lists/functional_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
            "        copying build/lib.linux-x86_64-3.6/apex/amp/lists/tensor_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
            "        copying build/lib.linux-x86_64-3.6/apex/amp/lists/torch_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
            "        copying build/lib.linux-x86_64-3.6/apex/amp/scaler.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "        copying build/lib.linux-x86_64-3.6/apex/amp/_amp_state.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "        copying build/lib.linux-x86_64-3.6/apex/amp/_initialize.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "        copying build/lib.linux-x86_64-3.6/apex/amp/frontend.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "        copying build/lib.linux-x86_64-3.6/apex/amp/__version__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "        copying build/lib.linux-x86_64-3.6/apex/amp/_process_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "        copying build/lib.linux-x86_64-3.6/apex/amp/compat.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "        copying build/lib.linux-x86_64-3.6/apex/amp/rnn_compat.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "        copying build/lib.linux-x86_64-3.6/apex/amp/wrap.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "        copying build/lib.linux-x86_64-3.6/apex/amp/utils.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "        copying build/lib.linux-x86_64-3.6/apex/amp/amp.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "        copying build/lib.linux-x86_64-3.6/apex/amp/handle.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "        creating /usr/local/lib/python3.6/dist-packages/apex/contrib\n",
            "        copying build/lib.linux-x86_64-3.6/apex/contrib/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib\n",
            "        creating /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "        copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/self_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "        copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "        copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/self_multihead_attn.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "        copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "        copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "        copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "        copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "        copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/encdec_multihead_attn.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "        copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "        creating /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n",
            "        copying build/lib.linux-x86_64-3.6/apex/contrib/groupbn/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n",
            "        copying build/lib.linux-x86_64-3.6/apex/contrib/groupbn/batch_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n",
            "        creating /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "        copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "        copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "        copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fp16_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "        copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_sgd.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "        creating /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n",
            "        copying build/lib.linux-x86_64-3.6/apex/contrib/xentropy/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n",
            "        copying build/lib.linux-x86_64-3.6/apex/contrib/xentropy/softmax_xentropy.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n",
            "        creating /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "        copying build/lib.linux-x86_64-3.6/apex/optimizers/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "        copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "        copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_novograd.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "        copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_lamb.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "        copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_sgd.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "        creating /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
            "        copying build/lib.linux-x86_64-3.6/apex/RNN/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
            "        copying build/lib.linux-x86_64-3.6/apex/RNN/cells.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
            "        copying build/lib.linux-x86_64-3.6/apex/RNN/models.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
            "        copying build/lib.linux-x86_64-3.6/apex/RNN/RNNBackend.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
            "        copying build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
            "        copying build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
            "        copying build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
            "        copying build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/__init__.py to __init__.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/loss_scaler.py to loss_scaler.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/fp16util.py to fp16util.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/__init__.py to __init__.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/reparameterization.py to reparameterization.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/weight_norm.py to weight_norm.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/__init__.py to __init__.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx/__init__.py to __init__.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx/nvmarker.py to nvmarker.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/__init__.py to __init__.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/data.py to data.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/__init__.py to __init__.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/recurrentCell.py to recurrentCell.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/base.py to base.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/usage.py to usage.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/dropout.py to dropout.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/embedding.py to embedding.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/output.py to output.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/randomSample.py to randomSample.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/loss.py to loss.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/reduction.py to reduction.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/normalization.py to normalization.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/misc.py to misc.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/pooling.py to pooling.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/convert.py to convert.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/linear.py to linear.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/softmax.py to softmax.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/utility.py to utility.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/conv.py to conv.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/pointwise.py to pointwise.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/index_slice_join_mutate.py to index_slice_join_mutate.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/activation.py to activation.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/blas.py to blas.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/__main__.py to __main__.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/prof.py to prof.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/optim.py to optim.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/__init__.py to __init__.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/parse.py to parse.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/nvvp.py to nvvp.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/kernel.py to kernel.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/db.py to db.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/__main__.py to __main__.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/normalization/__init__.py to __init__.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/normalization/fused_layer_norm.py to fused_layer_norm.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/optimized_sync_batchnorm.py to optimized_sync_batchnorm.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/__init__.py to __init__.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/LARC.py to LARC.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/optimized_sync_batchnorm_kernel.py to optimized_sync_batchnorm_kernel.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/sync_batchnorm_kernel.py to sync_batchnorm_kernel.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/sync_batchnorm.py to sync_batchnorm.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/multiproc.py to multiproc.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/distributed.py to distributed.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply/__init__.py to __init__.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply/multi_tensor_apply.py to multi_tensor_apply.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/opt.py to opt.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/__init__.py to __init__.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/__init__.py to __init__.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/functional_overrides.py to functional_overrides.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/tensor_overrides.py to tensor_overrides.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/torch_overrides.py to torch_overrides.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/scaler.py to scaler.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_amp_state.py to _amp_state.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_initialize.py to _initialize.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/frontend.py to frontend.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/__version__.py to __version__.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_process_optimizer.py to _process_optimizer.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/compat.py to compat.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/rnn_compat.py to rnn_compat.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/wrap.py to wrap.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/utils.py to utils.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/amp.py to amp.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/handle.py to handle.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/__init__.py to __init__.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/self_multihead_attn_func.py to self_multihead_attn_func.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/__init__.py to __init__.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/self_multihead_attn.py to self_multihead_attn.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/encdec_multihead_attn_func.py to encdec_multihead_attn_func.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py to fast_encdec_multihead_attn_norm_add_func.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py to fast_self_multihead_attn_norm_add_func.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py to fast_self_multihead_attn_func.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/encdec_multihead_attn.py to encdec_multihead_attn.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py to fast_encdec_multihead_attn_func.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn/__init__.py to __init__.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn/batch_norm.py to batch_norm.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/__init__.py to __init__.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fused_sgd.py to fused_sgd.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy/__init__.py to __init__.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy/softmax_xentropy.py to softmax_xentropy.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/__init__.py to __init__.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_novograd.py to fused_novograd.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_lamb.py to fused_lamb.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_sgd.py to fused_sgd.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/__init__.py to __init__.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/cells.py to cells.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/models.py to models.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/RNNBackend.py to RNNBackend.cpython-36.pyc\n",
            "        running install_egg_info\n",
            "        running egg_info\n",
            "        creating apex.egg-info\n",
            "        writing apex.egg-info/PKG-INFO\n",
            "        writing dependency_links to apex.egg-info/dependency_links.txt\n",
            "        writing top-level names to apex.egg-info/top_level.txt\n",
            "        writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "        writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "        Copying apex.egg-info to /usr/local/lib/python3.6/dist-packages/apex-0.1-py3.6.egg-info\n",
            "        running install_scripts\n",
            "        writing list of installed files to '/tmp/pip-record-le7rzoff/install-record.txt'\n",
            "        Running setup.py install for apex: finished with status 'done'\n",
            "      Removing source in /tmp/pip-req-build-cw_lyszl\n",
            "    Successfully installed apex-0.1\n",
            "    Cleaning up...\n",
            "    Cleaned build tracker '/tmp/pip-req-tracker-d0qghumx'\n",
            "    running install\n",
            "    running build\n",
            "    running build_py\n",
            "    Generating grammar tables from /usr/lib/python3.6/lib2to3/Grammar.txt\n",
            "    Generating grammar tables from /usr/lib/python3.6/lib2to3/PatternGrammar.txt\n",
            "    creating build\n",
            "    creating build/lib\n",
            "    creating build/lib/torch_lr_finder\n",
            "    copying torch_lr_finder/__init__.py -> build/lib/torch_lr_finder\n",
            "    copying torch_lr_finder/lr_finder.py -> build/lib/torch_lr_finder\n",
            "    running install_lib\n",
            "    creating /usr/local/lib/python3.6/dist-packages/torch_lr_finder\n",
            "    copying build/lib/torch_lr_finder/__init__.py -> /usr/local/lib/python3.6/dist-packages/torch_lr_finder\n",
            "    copying build/lib/torch_lr_finder/lr_finder.py -> /usr/local/lib/python3.6/dist-packages/torch_lr_finder\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/torch_lr_finder/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/torch_lr_finder/lr_finder.py to lr_finder.cpython-36.pyc\n",
            "    running install_egg_info\n",
            "    running egg_info\n",
            "    writing torch_lr_finder.egg-info/PKG-INFO\n",
            "    writing dependency_links to torch_lr_finder.egg-info/dependency_links.txt\n",
            "    writing requirements to torch_lr_finder.egg-info/requires.txt\n",
            "    writing top-level names to torch_lr_finder.egg-info/top_level.txt\n",
            "    reading manifest file 'torch_lr_finder.egg-info/SOURCES.txt'\n",
            "    writing manifest file 'torch_lr_finder.egg-info/SOURCES.txt'\n",
            "    Copying torch_lr_finder.egg-info to /usr/local/lib/python3.6/dist-packages/torch_lr_finder-0.1.4-py3.6.egg-info\n",
            "    running install_scripts\n",
            "    writing list of installed files to '/tmp/pip-record-8c2d09cb/install-record.txt'\n",
            "    Running setup.py install for torch-lr-finder ... \u001b[?25l\u001b[?25hdone\n",
            "  Removing source in /tmp/pip-install-k7ezk3vx/torch-lr-finder\n",
            "Successfully installed torch-lr-finder-0.1.4\n",
            "Cleaning up...\n",
            "Removed build tracker '/tmp/pip-req-tracker-d0qghumx'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6574df4f71dd45f6b8f7672c58f6aecd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Stopping early, the loss has diverged\n",
            "Learning rate search finished. See the graph with {finder_name}.plot()\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f79ce0636d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzuX5gLEeJfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def retry_from_backup()\n",
        "  model_gpu = model_base.type(gpu_dtype)\n",
        "  print(model_gpu)\n",
        "  loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) \n",
        "\n",
        "\n",
        "\n",
        "  checkpoint = torch.load(model_backup_path)\n",
        "  model_gpu.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  epoch = checkpoint['epoch']\n",
        "  loss = checkpoint['loss']\n",
        "  print(\"starting from epoch: \" + str(epoch))\n",
        "  print(\"starting from loss: \" + str(loss))\n",
        "  print(checkpoint['model_state_dict'])\n",
        "  print(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "  train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs, starting_from_epoch=epoch)\n",
        "  check_accuracy(model_gpu, valid_loader)\n",
        "#retry_from_backup()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDn-2g-TLY3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot([print_every*batch_size*(i+1) for i in range((len(avg_loss_list)))],avg_loss_list)\n",
        "print(\"Loss:\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGer6hJv7-zR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot([i+1 for i in range((len(acc_list)))],acc_list)\n",
        "print(\"Accurancy:\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBTReWHxz4Ml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}