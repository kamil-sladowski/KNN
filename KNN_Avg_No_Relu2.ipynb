{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN_Avg_No_Relu2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamilo116/KNN/blob/master/KNN_Avg_No_Relu2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7ReM7FU-xs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import sys\n",
        "from random import shuffle\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms as transforms\n",
        "import timeit\n",
        "\n",
        "np.random.seed(4) \n",
        "torch.manual_seed(4) \n",
        "torch.cuda.manual_seed(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYIMZ8QyYewD",
        "colab_type": "code",
        "outputId": "246f960c-d9e3-43bc-b922-32fe7acdeeab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "! git clone https://github.com/wang-chen/kervolution.git \n",
        "\n",
        "sys.path.append(\"kervolution/\")\n",
        "from kervolution import Kerv2d\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'kervolution' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvbKg4VJXKY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LIMIT_IMAGES_NUM = 1000\n",
        "train_test_split_size = 0.2\n",
        "image_resize = (100, 100)\n",
        "batch_size = 64\n",
        "num_workers = 0\n",
        "\n",
        "in_channels = 3\n",
        "out_channels_1 = 16\n",
        "out_channels_2 = 24\n",
        "out_channels_3 = 32\n",
        "out_channels_4 = 48\n",
        "out_channels_5 = 64\n",
        "out_channels_6 = 128\n",
        "\n",
        "kernel_size = 3\n",
        "padding_1 = 1\n",
        "num_epochs = 50\n",
        "\n",
        "learning_rate = 0.00009\n",
        "weight_decay = 0.1\n",
        "\n",
        "MALIGNANT_DATASET = '/content/drive/My Drive/Colab_data/malignant/malignant/'\n",
        "BENIGN_DATASET = '/content/drive/My Drive/Colab_data/benign/benign/'\n",
        "DATA_FOLDER = '/content/drive/My Drive/Colab_data/'\n",
        "model_backup_path = os.path.join(DATA_FOLDER, 'backup_model_2') \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMOHez_kHZD6",
        "colab_type": "code",
        "outputId": "d5d8fa3f-50ef-4014-9fea-b151cc3ac231",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b8P1NdXfVdX",
        "colab_type": "code",
        "outputId": "4376a301-9b89-4c16-8159-63b96ff893bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "benign_file_list = sorted(os.listdir(BENIGN_DATASET))\n",
        "malignant_file_list = sorted(os.listdir(MALIGNANT_DATASET))\n",
        "shuffle(benign_file_list)\n",
        "shuffle(malignant_file_list)\n",
        "benign_file_list = benign_file_list[:LIMIT_IMAGES_NUM]\n",
        "malignant_file_list = malignant_file_list[:LIMIT_IMAGES_NUM]\n",
        "\n",
        "print(f\"Number of benign {len(benign_file_list)} images\")\n",
        "print(f\"Number of malignant {len(malignant_file_list)} images\")\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize(image_resize),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of benign 1000 images\n",
            "Number of malignant 1000 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGDQfal74BLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "benign_dict = {filename: 0 for filename in benign_file_list}\n",
        "malignant_dict = {filename: 1 for filename in malignant_file_list}\n",
        "img_class_dict = {**benign_dict , **malignant_dict}\n",
        "labeled_data = pd.Series(img_class_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvAAOqmVfVll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IsicDataset(Dataset):\n",
        "    def __init__(self, data_folder, labeled_data, \n",
        "                 transform=transforms.Compose([transforms.ToTensor()])):\n",
        "        self.labeled_data = labeled_data\n",
        "        self.transform = transform\n",
        "        self.data_folder = data_folder\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labeled_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        label = self.labeled_data[index]\n",
        "        if label == 0:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"benign\", \"benign\", index ))\n",
        "        else:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"malignant\", \"malignant\", index ))\n",
        "        image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "    @property\n",
        "    def labels(self):\n",
        "      return self.labeled_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSuYqjLAYrWA",
        "colab_type": "code",
        "outputId": "2abcc494-1681-4cb6-debf-292eabd9ca31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        " \n",
        "dataset = IsicDataset(DATA_FOLDER, labeled_data, transform=data_transforms)\n",
        "print(dataset.labels)\n",
        "\n",
        "X_train, X_test = train_test_split(dataset.labels, test_size=train_test_split_size)\n",
        "print(\"number of training data: \",len(X_train))\n",
        "print(\"number of testing  data: \",len(X_test))\n",
        "\n",
        "train_sampler = SubsetRandomSampler(list(X_train.index))\n",
        "valid_sampler = SubsetRandomSampler(list(X_test.index))\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ISIC_0000093.jpeg    0\n",
            "ISIC_0000900.jpeg    0\n",
            "ISIC_0000491.jpeg    0\n",
            "ISIC_0001402.jpeg    0\n",
            "ISIC_0000016.jpeg    0\n",
            "                    ..\n",
            "ISIC_0025081.jpg     1\n",
            "ISIC_0011904.jpeg    1\n",
            "ISIC_0000169.jpeg    1\n",
            "ISIC_0000520.jpeg    1\n",
            "ISIC_0013767.jpeg    1\n",
            "Length: 2000, dtype: int64\n",
            "number of training data:  1600\n",
            "number of testing  data:  400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e8nFBR6Yug5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "def train(model, train_loader ,loss_fn, optimizer, num_epochs=1, starting_from_epoch=1):\n",
        "    total_loss =0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
        "        model.train()\n",
        "\n",
        "        for t, (x, y) in enumerate(train_loader):\n",
        "            x_var = Variable(x.type(gpu_dtype))\n",
        "            y_var = Variable(y.type(gpu_dtype).long())\n",
        "            scores = model(x_var)\n",
        "            loss = loss_fn(scores, y_var)\n",
        "            total_loss += loss.data\n",
        "            \n",
        "            if (t + 1) % print_every == 0:\n",
        "                avg_loss = total_loss/print_every\n",
        "                print('t = %d, avg_loss = %.4f' % (t + 1, avg_loss) )\n",
        "                avg_loss_list.append(avg_loss)\n",
        "                total_loss = 0\n",
        "                \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        acc = check_accuracy(model_gpu, valid_loader)\n",
        "        print('acc = %f' %(acc))\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model_gpu.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            }, model_backup_path)\n",
        "            \n",
        "def check_accuracy(model, loader):\n",
        "    print('Checking accuracy on test set')   \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval() \n",
        "    for x, y in loader:\n",
        "        x_var = Variable(x.type(gpu_dtype))\n",
        "\n",
        "        scores = model(x_var)\n",
        "        _, preds = scores.data.cpu().max(1)\n",
        "        num_correct += (preds == y).sum()\n",
        "        num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    acc_list.append(acc)\n",
        "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "    return acc\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggvpMu36Yw2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.size()\n",
        "        return x.view(N, -1)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgmexhBRZAK6",
        "colab_type": "code",
        "outputId": "1e3f0b2a-35c7-4bbe-8739-88e580cdc91f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "gpu_dtype = torch.cuda.FloatTensor\n",
        "\n",
        "print_every = 1\n",
        "\n",
        "\n",
        "'''\n",
        "Kerv2d\n",
        "kervolution with following options:\n",
        "kernel_type: [linear, polynomial, gaussian, etc.]\n",
        "default is convolution:\n",
        "          kernel_type --> linear,\n",
        "balance, power, gamma is valid only when the kernel_type is specified\n",
        "if learnable_kernel = True,  they just be the initial value of learable parameters\n",
        "if learnable_kernel = False, they are the value of kernel_type's parameter\n",
        "the parameter [power] cannot be learned due to integer limitation\n",
        "dilation (int or tuple, optional): Spacing between kernel\n",
        "elements. Default: 1\n",
        "groups (int, optional): Number of blocked connections from input\n",
        "channels to output channels. Default: 1\n",
        "bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n",
        "kernel_type (str), Default: 'linear'\n",
        "learnable_kernel (bool): Learnable kernel parameters.  Default: False \n",
        "balance: 0, 1\n",
        "power: 3, 4, 5\n",
        "gamma:\n",
        "'''\n",
        "\n",
        "\n",
        "model_base = nn.Sequential( \n",
        "                nn.Kerv2d(in_channels , out_channels_1, padding=padding_1, dilation=1, groups=1, bias=True, \n",
        "                          kernel_type='polynomial', kernel_size=kernel_size, learnable_kernel=True,\n",
        "                          kernel_regularizer=True, stride=1, balance=1, power=3, gamma=1\n",
        "                          ),\n",
        "                nn.BatchNorm2d(out_channels_1),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_1 , out_channels_2, padding= padding_1, kernel_size=kernel_size, stride=1), \n",
        "                nn.Dropout(0.1),\n",
        "                nn.BatchNorm2d(out_channels_2),\n",
        "                nn.AvgPool2d(2, stride=2), \n",
        "                nn.Conv2d(out_channels_2 , out_channels_3, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.BatchNorm2d(out_channels_3),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_3 , out_channels_4, padding= padding_1, kernel_size=kernel_size, stride=1),\n",
        "                nn.Dropout(0.1),  \n",
        "                nn.BatchNorm2d(out_channels_4),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_4 , out_channels_5, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.BatchNorm2d(out_channels_5),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_5 , out_channels_6, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.BatchNorm2d(out_channels_6),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                Flatten(),\n",
        "                nn.Dropout(0.5),\n",
        "                nn.Linear(128,64),\n",
        "                nn.Linear(64,2)\n",
        "            )\n",
        "model_gpu = model_base.type(gpu_dtype)\n",
        "print(model_gpu)\n",
        "loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) \n",
        "\n",
        "train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs)\n",
        "check_accuracy(model_gpu, valid_loader)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Kerv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (3): Conv2d(16, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (4): Dropout(p=0.1, inplace=False)\n",
            "  (5): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (6): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (7): Conv2d(24, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (10): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (11): Dropout(p=0.1, inplace=False)\n",
            "  (12): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (14): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (15): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (16): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (17): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (18): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (19): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (20): Flatten()\n",
            "  (21): Dropout(p=0.5, inplace=False)\n",
            "  (22): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (23): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n",
            "Starting epoch 1 / 50\n",
            "t = 1, avg_loss = 0.6747\n",
            "t = 2, avg_loss = 0.7018\n",
            "t = 3, avg_loss = 0.7399\n",
            "t = 4, avg_loss = 0.7166\n",
            "t = 5, avg_loss = 0.6774\n",
            "t = 6, avg_loss = 0.7008\n",
            "t = 7, avg_loss = 0.6994\n",
            "t = 8, avg_loss = 0.6690\n",
            "t = 9, avg_loss = 0.6933\n",
            "t = 10, avg_loss = 0.6438\n",
            "t = 11, avg_loss = 0.6542\n",
            "t = 12, avg_loss = 0.6300\n",
            "t = 13, avg_loss = 0.6659\n",
            "t = 14, avg_loss = 0.7128\n",
            "t = 15, avg_loss = 0.6815\n",
            "t = 16, avg_loss = 0.6970\n",
            "t = 17, avg_loss = 0.7101\n",
            "t = 18, avg_loss = 0.6379\n",
            "t = 19, avg_loss = 0.6695\n",
            "t = 20, avg_loss = 0.6116\n",
            "t = 21, avg_loss = 0.6719\n",
            "t = 22, avg_loss = 0.6022\n",
            "t = 23, avg_loss = 0.6714\n",
            "t = 24, avg_loss = 0.6453\n",
            "t = 25, avg_loss = 0.6125\n",
            "Checking accuracy on test set\n",
            "Got 203 / 400 correct (50.75)\n",
            "acc = 0.507500\n",
            "Starting epoch 2 / 50\n",
            "t = 1, avg_loss = 0.6670\n",
            "t = 2, avg_loss = 0.6945\n",
            "t = 3, avg_loss = 0.7263\n",
            "t = 4, avg_loss = 0.6650\n",
            "t = 5, avg_loss = 0.6765\n",
            "t = 6, avg_loss = 0.5903\n",
            "t = 7, avg_loss = 0.7121\n",
            "t = 8, avg_loss = 0.6309\n",
            "t = 9, avg_loss = 0.6221\n",
            "t = 10, avg_loss = 0.6174\n",
            "t = 11, avg_loss = 0.6017\n",
            "t = 12, avg_loss = 0.6624\n",
            "t = 13, avg_loss = 0.6775\n",
            "t = 14, avg_loss = 0.6117\n",
            "t = 15, avg_loss = 0.6751\n",
            "t = 16, avg_loss = 0.6949\n",
            "t = 17, avg_loss = 0.6334\n",
            "t = 18, avg_loss = 0.5865\n",
            "t = 19, avg_loss = 0.6613\n",
            "t = 20, avg_loss = 0.6444\n",
            "t = 21, avg_loss = 0.7027\n",
            "t = 22, avg_loss = 0.5956\n",
            "t = 23, avg_loss = 0.6705\n",
            "t = 24, avg_loss = 0.5947\n",
            "t = 25, avg_loss = 0.6946\n",
            "Checking accuracy on test set\n",
            "Got 263 / 400 correct (65.75)\n",
            "acc = 0.657500\n",
            "Starting epoch 3 / 50\n",
            "t = 1, avg_loss = 0.6385\n",
            "t = 2, avg_loss = 0.6988\n",
            "t = 3, avg_loss = 0.5806\n",
            "t = 4, avg_loss = 0.6109\n",
            "t = 5, avg_loss = 0.6447\n",
            "t = 6, avg_loss = 0.6052\n",
            "t = 7, avg_loss = 0.6738\n",
            "t = 8, avg_loss = 0.7686\n",
            "t = 9, avg_loss = 0.6167\n",
            "t = 10, avg_loss = 0.6078\n",
            "t = 11, avg_loss = 0.6040\n",
            "t = 12, avg_loss = 0.6341\n",
            "t = 13, avg_loss = 0.6648\n",
            "t = 14, avg_loss = 0.6035\n",
            "t = 15, avg_loss = 0.6392\n",
            "t = 16, avg_loss = 0.6068\n",
            "t = 17, avg_loss = 0.6380\n",
            "t = 18, avg_loss = 0.6153\n",
            "t = 19, avg_loss = 0.6568\n",
            "t = 20, avg_loss = 0.7136\n",
            "t = 21, avg_loss = 0.6335\n",
            "t = 22, avg_loss = 0.6383\n",
            "t = 23, avg_loss = 0.6694\n",
            "t = 24, avg_loss = 0.6863\n",
            "t = 25, avg_loss = 0.6697\n",
            "Checking accuracy on test set\n",
            "Got 268 / 400 correct (67.00)\n",
            "acc = 0.670000\n",
            "Starting epoch 4 / 50\n",
            "t = 1, avg_loss = 0.6812\n",
            "t = 2, avg_loss = 0.6578\n",
            "t = 3, avg_loss = 0.6239\n",
            "t = 4, avg_loss = 0.6229\n",
            "t = 5, avg_loss = 0.6258\n",
            "t = 6, avg_loss = 0.6160\n",
            "t = 7, avg_loss = 0.6269\n",
            "t = 8, avg_loss = 0.6315\n",
            "t = 9, avg_loss = 0.6198\n",
            "t = 10, avg_loss = 0.6530\n",
            "t = 11, avg_loss = 0.6773\n",
            "t = 12, avg_loss = 0.6404\n",
            "t = 13, avg_loss = 0.5986\n",
            "t = 14, avg_loss = 0.7317\n",
            "t = 15, avg_loss = 0.6239\n",
            "t = 16, avg_loss = 0.6693\n",
            "t = 17, avg_loss = 0.6181\n",
            "t = 18, avg_loss = 0.6962\n",
            "t = 19, avg_loss = 0.6070\n",
            "t = 20, avg_loss = 0.6072\n",
            "t = 21, avg_loss = 0.6505\n",
            "t = 22, avg_loss = 0.6350\n",
            "t = 23, avg_loss = 0.5499\n",
            "t = 24, avg_loss = 0.6672\n",
            "t = 25, avg_loss = 0.6095\n",
            "Checking accuracy on test set\n",
            "Got 271 / 400 correct (67.75)\n",
            "acc = 0.677500\n",
            "Starting epoch 5 / 50\n",
            "t = 1, avg_loss = 0.6354\n",
            "t = 2, avg_loss = 0.6048\n",
            "t = 3, avg_loss = 0.7036\n",
            "t = 4, avg_loss = 0.6572\n",
            "t = 5, avg_loss = 0.6413\n",
            "t = 6, avg_loss = 0.6008\n",
            "t = 7, avg_loss = 0.5252\n",
            "t = 8, avg_loss = 0.6676\n",
            "t = 9, avg_loss = 0.5774\n",
            "t = 10, avg_loss = 0.6084\n",
            "t = 11, avg_loss = 0.6274\n",
            "t = 12, avg_loss = 0.6416\n",
            "t = 13, avg_loss = 0.7271\n",
            "t = 14, avg_loss = 0.6277\n",
            "t = 15, avg_loss = 0.6006\n",
            "t = 16, avg_loss = 0.6998\n",
            "t = 17, avg_loss = 0.7194\n",
            "t = 18, avg_loss = 0.6013\n",
            "t = 19, avg_loss = 0.6336\n",
            "t = 20, avg_loss = 0.5594\n",
            "t = 21, avg_loss = 0.6066\n",
            "t = 22, avg_loss = 0.7361\n",
            "t = 23, avg_loss = 0.6830\n",
            "t = 24, avg_loss = 0.6167\n",
            "t = 25, avg_loss = 0.6451\n",
            "Checking accuracy on test set\n",
            "Got 270 / 400 correct (67.50)\n",
            "acc = 0.675000\n",
            "Starting epoch 6 / 50\n",
            "t = 1, avg_loss = 0.5865\n",
            "t = 2, avg_loss = 0.6215\n",
            "t = 3, avg_loss = 0.6751\n",
            "t = 4, avg_loss = 0.6109\n",
            "t = 5, avg_loss = 0.7202\n",
            "t = 6, avg_loss = 0.6153\n",
            "t = 7, avg_loss = 0.6306\n",
            "t = 8, avg_loss = 0.5823\n",
            "t = 9, avg_loss = 0.6097\n",
            "t = 10, avg_loss = 0.7041\n",
            "t = 11, avg_loss = 0.7640\n",
            "t = 12, avg_loss = 0.6025\n",
            "t = 13, avg_loss = 0.6312\n",
            "t = 14, avg_loss = 0.5797\n",
            "t = 15, avg_loss = 0.5733\n",
            "t = 16, avg_loss = 0.6341\n",
            "t = 17, avg_loss = 0.6408\n",
            "t = 18, avg_loss = 0.6222\n",
            "t = 19, avg_loss = 0.5795\n",
            "t = 20, avg_loss = 0.6357\n",
            "t = 21, avg_loss = 0.6639\n",
            "t = 22, avg_loss = 0.6363\n",
            "t = 23, avg_loss = 0.6206\n",
            "t = 24, avg_loss = 0.6014\n",
            "t = 25, avg_loss = 0.7084\n",
            "Checking accuracy on test set\n",
            "Got 279 / 400 correct (69.75)\n",
            "acc = 0.697500\n",
            "Starting epoch 7 / 50\n",
            "t = 1, avg_loss = 0.6047\n",
            "t = 2, avg_loss = 0.5949\n",
            "t = 3, avg_loss = 0.6836\n",
            "t = 4, avg_loss = 0.6517\n",
            "t = 5, avg_loss = 0.6769\n",
            "t = 6, avg_loss = 0.6392\n",
            "t = 7, avg_loss = 0.5861\n",
            "t = 8, avg_loss = 0.7203\n",
            "t = 9, avg_loss = 0.6662\n",
            "t = 10, avg_loss = 0.6623\n",
            "t = 11, avg_loss = 0.6117\n",
            "t = 12, avg_loss = 0.6275\n",
            "t = 13, avg_loss = 0.6582\n",
            "t = 14, avg_loss = 0.6666\n",
            "t = 15, avg_loss = 0.6713\n",
            "t = 16, avg_loss = 0.5834\n",
            "t = 17, avg_loss = 0.6489\n",
            "t = 18, avg_loss = 0.6442\n",
            "t = 19, avg_loss = 0.5850\n",
            "t = 20, avg_loss = 0.5596\n",
            "t = 21, avg_loss = 0.6384\n",
            "t = 22, avg_loss = 0.6246\n",
            "t = 23, avg_loss = 0.6203\n",
            "t = 24, avg_loss = 0.5604\n",
            "t = 25, avg_loss = 0.5928\n",
            "Checking accuracy on test set\n",
            "Got 270 / 400 correct (67.50)\n",
            "acc = 0.675000\n",
            "Starting epoch 8 / 50\n",
            "t = 1, avg_loss = 0.6037\n",
            "t = 2, avg_loss = 0.6976\n",
            "t = 3, avg_loss = 0.7043\n",
            "t = 4, avg_loss = 0.5891\n",
            "t = 5, avg_loss = 0.5622\n",
            "t = 6, avg_loss = 0.6866\n",
            "t = 7, avg_loss = 0.6295\n",
            "t = 8, avg_loss = 0.5497\n",
            "t = 9, avg_loss = 0.6659\n",
            "t = 10, avg_loss = 0.6112\n",
            "t = 11, avg_loss = 0.5567\n",
            "t = 12, avg_loss = 0.6399\n",
            "t = 13, avg_loss = 0.5699\n",
            "t = 14, avg_loss = 0.6478\n",
            "t = 15, avg_loss = 0.6839\n",
            "t = 16, avg_loss = 0.6342\n",
            "t = 17, avg_loss = 0.5830\n",
            "t = 18, avg_loss = 0.5875\n",
            "t = 19, avg_loss = 0.6004\n",
            "t = 20, avg_loss = 0.6659\n",
            "t = 21, avg_loss = 0.6229\n",
            "t = 22, avg_loss = 0.6607\n",
            "t = 23, avg_loss = 0.6849\n",
            "t = 24, avg_loss = 0.6646\n",
            "t = 25, avg_loss = 0.6664\n",
            "Checking accuracy on test set\n",
            "Got 277 / 400 correct (69.25)\n",
            "acc = 0.692500\n",
            "Starting epoch 9 / 50\n",
            "t = 1, avg_loss = 0.6470\n",
            "t = 2, avg_loss = 0.5179\n",
            "t = 3, avg_loss = 0.5871\n",
            "t = 4, avg_loss = 0.5887\n",
            "t = 5, avg_loss = 0.6156\n",
            "t = 6, avg_loss = 0.6672\n",
            "t = 7, avg_loss = 0.5380\n",
            "t = 8, avg_loss = 0.6681\n",
            "t = 9, avg_loss = 0.6576\n",
            "t = 10, avg_loss = 0.5647\n",
            "t = 11, avg_loss = 0.6580\n",
            "t = 12, avg_loss = 0.6762\n",
            "t = 13, avg_loss = 0.5983\n",
            "t = 14, avg_loss = 0.6305\n",
            "t = 15, avg_loss = 0.6274\n",
            "t = 16, avg_loss = 0.6288\n",
            "t = 17, avg_loss = 0.6769\n",
            "t = 18, avg_loss = 0.6129\n",
            "t = 19, avg_loss = 0.6087\n",
            "t = 20, avg_loss = 0.6722\n",
            "t = 21, avg_loss = 0.6670\n",
            "t = 22, avg_loss = 0.6230\n",
            "t = 23, avg_loss = 0.5982\n",
            "t = 24, avg_loss = 0.5718\n",
            "t = 25, avg_loss = 0.6213\n",
            "Checking accuracy on test set\n",
            "Got 272 / 400 correct (68.00)\n",
            "acc = 0.680000\n",
            "Starting epoch 10 / 50\n",
            "t = 1, avg_loss = 0.5895\n",
            "t = 2, avg_loss = 0.5941\n",
            "t = 3, avg_loss = 0.5594\n",
            "t = 4, avg_loss = 0.6087\n",
            "t = 5, avg_loss = 0.6179\n",
            "t = 6, avg_loss = 0.6673\n",
            "t = 7, avg_loss = 0.6519\n",
            "t = 8, avg_loss = 0.5824\n",
            "t = 9, avg_loss = 0.6563\n",
            "t = 10, avg_loss = 0.6062\n",
            "t = 11, avg_loss = 0.6200\n",
            "t = 12, avg_loss = 0.5746\n",
            "t = 13, avg_loss = 0.6599\n",
            "t = 14, avg_loss = 0.6025\n",
            "t = 15, avg_loss = 0.6408\n",
            "t = 16, avg_loss = 0.7202\n",
            "t = 17, avg_loss = 0.5645\n",
            "t = 18, avg_loss = 0.5761\n",
            "t = 19, avg_loss = 0.6037\n",
            "t = 20, avg_loss = 0.5766\n",
            "t = 21, avg_loss = 0.6126\n",
            "t = 22, avg_loss = 0.6395\n",
            "t = 23, avg_loss = 0.5874\n",
            "t = 24, avg_loss = 0.6438\n",
            "t = 25, avg_loss = 0.6475\n",
            "Checking accuracy on test set\n",
            "Got 267 / 400 correct (66.75)\n",
            "acc = 0.667500\n",
            "Starting epoch 11 / 50\n",
            "t = 1, avg_loss = 0.6087\n",
            "t = 2, avg_loss = 0.5624\n",
            "t = 3, avg_loss = 0.6173\n",
            "t = 4, avg_loss = 0.5889\n",
            "t = 5, avg_loss = 0.6028\n",
            "t = 6, avg_loss = 0.5814\n",
            "t = 7, avg_loss = 0.5912\n",
            "t = 8, avg_loss = 0.5776\n",
            "t = 9, avg_loss = 0.6839\n",
            "t = 10, avg_loss = 0.6008\n",
            "t = 11, avg_loss = 0.6539\n",
            "t = 12, avg_loss = 0.5633\n",
            "t = 13, avg_loss = 0.5416\n",
            "t = 14, avg_loss = 0.6779\n",
            "t = 15, avg_loss = 0.6279\n",
            "t = 16, avg_loss = 0.6202\n",
            "t = 17, avg_loss = 0.5999\n",
            "t = 18, avg_loss = 0.5965\n",
            "t = 19, avg_loss = 0.6993\n",
            "t = 20, avg_loss = 0.5712\n",
            "t = 21, avg_loss = 0.7375\n",
            "t = 22, avg_loss = 0.5925\n",
            "t = 23, avg_loss = 0.6159\n",
            "t = 24, avg_loss = 0.5379\n",
            "t = 25, avg_loss = 0.6055\n",
            "Checking accuracy on test set\n",
            "Got 283 / 400 correct (70.75)\n",
            "acc = 0.707500\n",
            "Starting epoch 12 / 50\n",
            "t = 1, avg_loss = 0.6433\n",
            "t = 2, avg_loss = 0.6183\n",
            "t = 3, avg_loss = 0.5838\n",
            "t = 4, avg_loss = 0.6411\n",
            "t = 5, avg_loss = 0.6310\n",
            "t = 6, avg_loss = 0.6097\n",
            "t = 7, avg_loss = 0.6123\n",
            "t = 8, avg_loss = 0.5649\n",
            "t = 9, avg_loss = 0.6044\n",
            "t = 10, avg_loss = 0.5266\n",
            "t = 11, avg_loss = 0.6689\n",
            "t = 12, avg_loss = 0.6205\n",
            "t = 13, avg_loss = 0.5650\n",
            "t = 14, avg_loss = 0.6894\n",
            "t = 15, avg_loss = 0.5796\n",
            "t = 16, avg_loss = 0.7402\n",
            "t = 17, avg_loss = 0.5273\n",
            "t = 18, avg_loss = 0.5128\n",
            "t = 19, avg_loss = 0.6278\n",
            "t = 20, avg_loss = 0.5812\n",
            "t = 21, avg_loss = 0.6499\n",
            "t = 22, avg_loss = 0.6179\n",
            "t = 23, avg_loss = 0.6324\n",
            "t = 24, avg_loss = 0.6167\n",
            "t = 25, avg_loss = 0.5744\n",
            "Checking accuracy on test set\n",
            "Got 269 / 400 correct (67.25)\n",
            "acc = 0.672500\n",
            "Starting epoch 13 / 50\n",
            "t = 1, avg_loss = 0.5785\n",
            "t = 2, avg_loss = 0.5901\n",
            "t = 3, avg_loss = 0.6466\n",
            "t = 4, avg_loss = 0.5491\n",
            "t = 5, avg_loss = 0.6470\n",
            "t = 6, avg_loss = 0.6505\n",
            "t = 7, avg_loss = 0.6784\n",
            "t = 8, avg_loss = 0.6537\n",
            "t = 9, avg_loss = 0.6140\n",
            "t = 10, avg_loss = 0.6108\n",
            "t = 11, avg_loss = 0.6140\n",
            "t = 12, avg_loss = 0.5242\n",
            "t = 13, avg_loss = 0.5144\n",
            "t = 14, avg_loss = 0.6035\n",
            "t = 15, avg_loss = 0.5207\n",
            "t = 16, avg_loss = 0.6863\n",
            "t = 17, avg_loss = 0.6565\n",
            "t = 18, avg_loss = 0.6057\n",
            "t = 19, avg_loss = 0.6399\n",
            "t = 20, avg_loss = 0.6503\n",
            "t = 21, avg_loss = 0.5391\n",
            "t = 22, avg_loss = 0.7165\n",
            "t = 23, avg_loss = 0.6893\n",
            "t = 24, avg_loss = 0.7452\n",
            "t = 25, avg_loss = 0.7964\n",
            "Checking accuracy on test set\n",
            "Got 265 / 400 correct (66.25)\n",
            "acc = 0.662500\n",
            "Starting epoch 14 / 50\n",
            "t = 1, avg_loss = 0.6446\n",
            "t = 2, avg_loss = 0.6397\n",
            "t = 3, avg_loss = 0.6805\n",
            "t = 4, avg_loss = 0.6844\n",
            "t = 5, avg_loss = 0.6217\n",
            "t = 6, avg_loss = 0.6276\n",
            "t = 7, avg_loss = 0.6681\n",
            "t = 8, avg_loss = 0.6348\n",
            "t = 9, avg_loss = 0.5889\n",
            "t = 10, avg_loss = 0.6035\n",
            "t = 11, avg_loss = 0.6434\n",
            "t = 12, avg_loss = 0.5968\n",
            "t = 13, avg_loss = 0.6445\n",
            "t = 14, avg_loss = 0.6422\n",
            "t = 15, avg_loss = 0.6425\n",
            "t = 16, avg_loss = 0.6128\n",
            "t = 17, avg_loss = 0.6056\n",
            "t = 18, avg_loss = 0.6285\n",
            "t = 19, avg_loss = 0.5778\n",
            "t = 20, avg_loss = 0.5862\n",
            "t = 21, avg_loss = 0.5844\n",
            "t = 22, avg_loss = 0.6223\n",
            "t = 23, avg_loss = 0.5902\n",
            "t = 24, avg_loss = 0.5490\n",
            "t = 25, avg_loss = 0.5172\n",
            "Checking accuracy on test set\n",
            "Got 283 / 400 correct (70.75)\n",
            "acc = 0.707500\n",
            "Starting epoch 15 / 50\n",
            "t = 1, avg_loss = 0.5757\n",
            "t = 2, avg_loss = 0.5174\n",
            "t = 3, avg_loss = 0.7351\n",
            "t = 4, avg_loss = 0.6177\n",
            "t = 5, avg_loss = 0.5787\n",
            "t = 6, avg_loss = 0.6141\n",
            "t = 7, avg_loss = 0.5468\n",
            "t = 8, avg_loss = 0.6392\n",
            "t = 9, avg_loss = 0.6190\n",
            "t = 10, avg_loss = 0.6577\n",
            "t = 11, avg_loss = 0.6386\n",
            "t = 12, avg_loss = 0.5644\n",
            "t = 13, avg_loss = 0.5621\n",
            "t = 14, avg_loss = 0.5981\n",
            "t = 15, avg_loss = 0.5810\n",
            "t = 16, avg_loss = 0.6933\n",
            "t = 17, avg_loss = 0.6136\n",
            "t = 18, avg_loss = 0.5778\n",
            "t = 19, avg_loss = 0.5327\n",
            "t = 20, avg_loss = 0.5752\n",
            "t = 21, avg_loss = 0.6072\n",
            "t = 22, avg_loss = 0.5883\n",
            "t = 23, avg_loss = 0.6658\n",
            "t = 24, avg_loss = 0.5620\n",
            "t = 25, avg_loss = 0.6503\n",
            "Checking accuracy on test set\n",
            "Got 289 / 400 correct (72.25)\n",
            "acc = 0.722500\n",
            "Starting epoch 16 / 50\n",
            "t = 1, avg_loss = 0.5843\n",
            "t = 2, avg_loss = 0.5029\n",
            "t = 3, avg_loss = 0.6474\n",
            "t = 4, avg_loss = 0.6794\n",
            "t = 5, avg_loss = 0.6170\n",
            "t = 6, avg_loss = 0.6198\n",
            "t = 7, avg_loss = 0.6312\n",
            "t = 8, avg_loss = 0.5650\n",
            "t = 9, avg_loss = 0.5335\n",
            "t = 10, avg_loss = 0.5994\n",
            "t = 11, avg_loss = 0.5906\n",
            "t = 12, avg_loss = 0.5661\n",
            "t = 13, avg_loss = 0.6008\n",
            "t = 14, avg_loss = 0.4910\n",
            "t = 15, avg_loss = 0.5634\n",
            "t = 16, avg_loss = 0.6428\n",
            "t = 17, avg_loss = 0.6904\n",
            "t = 18, avg_loss = 0.5889\n",
            "t = 19, avg_loss = 0.6061\n",
            "t = 20, avg_loss = 0.5478\n",
            "t = 21, avg_loss = 0.6201\n",
            "t = 22, avg_loss = 0.5705\n",
            "t = 23, avg_loss = 0.5953\n",
            "t = 24, avg_loss = 0.6838\n",
            "t = 25, avg_loss = 0.5871\n",
            "Checking accuracy on test set\n",
            "Got 276 / 400 correct (69.00)\n",
            "acc = 0.690000\n",
            "Starting epoch 17 / 50\n",
            "t = 1, avg_loss = 0.5185\n",
            "t = 2, avg_loss = 0.6008\n",
            "t = 3, avg_loss = 0.5420\n",
            "t = 4, avg_loss = 0.5768\n",
            "t = 5, avg_loss = 0.5737\n",
            "t = 6, avg_loss = 0.7130\n",
            "t = 7, avg_loss = 0.5815\n",
            "t = 8, avg_loss = 0.5232\n",
            "t = 9, avg_loss = 0.6012\n",
            "t = 10, avg_loss = 0.6002\n",
            "t = 11, avg_loss = 0.5964\n",
            "t = 12, avg_loss = 0.4638\n",
            "t = 13, avg_loss = 0.5359\n",
            "t = 14, avg_loss = 0.5691\n",
            "t = 15, avg_loss = 0.6934\n",
            "t = 16, avg_loss = 0.6340\n",
            "t = 17, avg_loss = 0.5868\n",
            "t = 18, avg_loss = 0.5957\n",
            "t = 19, avg_loss = 0.6567\n",
            "t = 20, avg_loss = 0.5519\n",
            "t = 21, avg_loss = 0.5281\n",
            "t = 22, avg_loss = 0.6232\n",
            "t = 23, avg_loss = 0.6339\n",
            "t = 24, avg_loss = 0.6502\n",
            "t = 25, avg_loss = 0.5406\n",
            "Checking accuracy on test set\n",
            "Got 267 / 400 correct (66.75)\n",
            "acc = 0.667500\n",
            "Starting epoch 18 / 50\n",
            "t = 1, avg_loss = 0.6439\n",
            "t = 2, avg_loss = 0.5023\n",
            "t = 3, avg_loss = 0.5105\n",
            "t = 4, avg_loss = 0.6532\n",
            "t = 5, avg_loss = 0.5477\n",
            "t = 6, avg_loss = 0.6506\n",
            "t = 7, avg_loss = 0.6257\n",
            "t = 8, avg_loss = 0.6436\n",
            "t = 9, avg_loss = 0.6527\n",
            "t = 10, avg_loss = 0.5274\n",
            "t = 11, avg_loss = 0.5451\n",
            "t = 12, avg_loss = 0.5369\n",
            "t = 13, avg_loss = 0.5650\n",
            "t = 14, avg_loss = 0.5608\n",
            "t = 15, avg_loss = 0.5972\n",
            "t = 16, avg_loss = 0.6346\n",
            "t = 17, avg_loss = 0.5644\n",
            "t = 18, avg_loss = 0.7094\n",
            "t = 19, avg_loss = 0.5735\n",
            "t = 20, avg_loss = 0.6049\n",
            "t = 21, avg_loss = 0.5255\n",
            "t = 22, avg_loss = 0.5991\n",
            "t = 23, avg_loss = 0.6744\n",
            "t = 24, avg_loss = 0.5911\n",
            "t = 25, avg_loss = 0.5275\n",
            "Checking accuracy on test set\n",
            "Got 287 / 400 correct (71.75)\n",
            "acc = 0.717500\n",
            "Starting epoch 19 / 50\n",
            "t = 1, avg_loss = 0.5920\n",
            "t = 2, avg_loss = 0.5372\n",
            "t = 3, avg_loss = 0.5274\n",
            "t = 4, avg_loss = 0.7026\n",
            "t = 5, avg_loss = 0.5554\n",
            "t = 6, avg_loss = 0.5393\n",
            "t = 7, avg_loss = 0.5844\n",
            "t = 8, avg_loss = 0.6923\n",
            "t = 9, avg_loss = 0.5884\n",
            "t = 10, avg_loss = 0.5465\n",
            "t = 11, avg_loss = 0.5641\n",
            "t = 12, avg_loss = 0.5792\n",
            "t = 13, avg_loss = 0.5193\n",
            "t = 14, avg_loss = 0.5835\n",
            "t = 15, avg_loss = 0.5263\n",
            "t = 16, avg_loss = 0.6176\n",
            "t = 17, avg_loss = 0.5772\n",
            "t = 18, avg_loss = 0.6439\n",
            "t = 19, avg_loss = 0.6382\n",
            "t = 20, avg_loss = 0.5535\n",
            "t = 21, avg_loss = 0.5282\n",
            "t = 22, avg_loss = 0.5143\n",
            "t = 23, avg_loss = 0.6384\n",
            "t = 24, avg_loss = 0.6099\n",
            "t = 25, avg_loss = 0.6907\n",
            "Checking accuracy on test set\n",
            "Got 292 / 400 correct (73.00)\n",
            "acc = 0.730000\n",
            "Starting epoch 20 / 50\n",
            "t = 1, avg_loss = 0.5014\n",
            "t = 2, avg_loss = 0.6147\n",
            "t = 3, avg_loss = 0.5579\n",
            "t = 4, avg_loss = 0.5512\n",
            "t = 5, avg_loss = 0.5355\n",
            "t = 6, avg_loss = 0.6307\n",
            "t = 7, avg_loss = 0.5304\n",
            "t = 8, avg_loss = 0.5430\n",
            "t = 9, avg_loss = 0.5698\n",
            "t = 10, avg_loss = 0.6419\n",
            "t = 11, avg_loss = 0.5984\n",
            "t = 12, avg_loss = 0.6565\n",
            "t = 13, avg_loss = 0.6599\n",
            "t = 14, avg_loss = 0.6441\n",
            "t = 15, avg_loss = 0.5626\n",
            "t = 16, avg_loss = 0.6540\n",
            "t = 17, avg_loss = 0.5840\n",
            "t = 18, avg_loss = 0.5430\n",
            "t = 19, avg_loss = 0.6301\n",
            "t = 20, avg_loss = 0.4936\n",
            "t = 21, avg_loss = 0.5282\n",
            "t = 22, avg_loss = 0.5643\n",
            "t = 23, avg_loss = 0.5647\n",
            "t = 24, avg_loss = 0.5934\n",
            "t = 25, avg_loss = 0.5612\n",
            "Checking accuracy on test set\n",
            "Got 280 / 400 correct (70.00)\n",
            "acc = 0.700000\n",
            "Starting epoch 21 / 50\n",
            "t = 1, avg_loss = 0.5907\n",
            "t = 2, avg_loss = 0.5501\n",
            "t = 3, avg_loss = 0.4969\n",
            "t = 4, avg_loss = 0.6683\n",
            "t = 5, avg_loss = 0.6012\n",
            "t = 6, avg_loss = 0.5844\n",
            "t = 7, avg_loss = 0.5370\n",
            "t = 8, avg_loss = 0.5634\n",
            "t = 9, avg_loss = 0.6670\n",
            "t = 10, avg_loss = 0.5517\n",
            "t = 11, avg_loss = 0.6238\n",
            "t = 12, avg_loss = 0.5871\n",
            "t = 13, avg_loss = 0.5191\n",
            "t = 14, avg_loss = 0.5785\n",
            "t = 15, avg_loss = 0.6731\n",
            "t = 16, avg_loss = 0.6320\n",
            "t = 17, avg_loss = 0.6446\n",
            "t = 18, avg_loss = 0.5322\n",
            "t = 19, avg_loss = 0.6843\n",
            "t = 20, avg_loss = 0.5835\n",
            "t = 21, avg_loss = 0.6201\n",
            "t = 22, avg_loss = 0.5351\n",
            "t = 23, avg_loss = 0.6590\n",
            "t = 24, avg_loss = 0.5748\n",
            "t = 25, avg_loss = 0.5358\n",
            "Checking accuracy on test set\n",
            "Got 277 / 400 correct (69.25)\n",
            "acc = 0.692500\n",
            "Starting epoch 22 / 50\n",
            "t = 1, avg_loss = 0.6625\n",
            "t = 2, avg_loss = 0.5825\n",
            "t = 3, avg_loss = 0.6526\n",
            "t = 4, avg_loss = 0.5922\n",
            "t = 5, avg_loss = 0.5431\n",
            "t = 6, avg_loss = 0.5597\n",
            "t = 7, avg_loss = 0.6268\n",
            "t = 8, avg_loss = 0.5959\n",
            "t = 9, avg_loss = 0.5309\n",
            "t = 10, avg_loss = 0.5546\n",
            "t = 11, avg_loss = 0.5105\n",
            "t = 12, avg_loss = 0.6143\n",
            "t = 13, avg_loss = 0.5091\n",
            "t = 14, avg_loss = 0.6181\n",
            "t = 15, avg_loss = 0.6583\n",
            "t = 16, avg_loss = 0.6050\n",
            "t = 17, avg_loss = 0.4899\n",
            "t = 18, avg_loss = 0.5403\n",
            "t = 19, avg_loss = 0.5214\n",
            "t = 20, avg_loss = 0.5785\n",
            "t = 21, avg_loss = 0.5981\n",
            "t = 22, avg_loss = 0.5270\n",
            "t = 23, avg_loss = 0.5434\n",
            "t = 24, avg_loss = 0.5618\n",
            "t = 25, avg_loss = 0.6355\n",
            "Checking accuracy on test set\n",
            "Got 299 / 400 correct (74.75)\n",
            "acc = 0.747500\n",
            "Starting epoch 23 / 50\n",
            "t = 1, avg_loss = 0.5125\n",
            "t = 2, avg_loss = 0.5619\n",
            "t = 3, avg_loss = 0.5636\n",
            "t = 4, avg_loss = 0.5177\n",
            "t = 5, avg_loss = 0.5460\n",
            "t = 6, avg_loss = 0.5568\n",
            "t = 7, avg_loss = 0.7212\n",
            "t = 8, avg_loss = 0.6338\n",
            "t = 9, avg_loss = 0.5486\n",
            "t = 10, avg_loss = 0.5407\n",
            "t = 11, avg_loss = 0.5740\n",
            "t = 12, avg_loss = 0.6009\n",
            "t = 13, avg_loss = 0.6876\n",
            "t = 14, avg_loss = 0.5821\n",
            "t = 15, avg_loss = 0.6782\n",
            "t = 16, avg_loss = 0.5557\n",
            "t = 17, avg_loss = 0.5127\n",
            "t = 18, avg_loss = 0.6600\n",
            "t = 19, avg_loss = 0.4728\n",
            "t = 20, avg_loss = 0.6168\n",
            "t = 21, avg_loss = 0.5879\n",
            "t = 22, avg_loss = 0.5157\n",
            "t = 23, avg_loss = 0.5041\n",
            "t = 24, avg_loss = 0.5180\n",
            "t = 25, avg_loss = 0.6172\n",
            "Checking accuracy on test set\n",
            "Got 262 / 400 correct (65.50)\n",
            "acc = 0.655000\n",
            "Starting epoch 24 / 50\n",
            "t = 1, avg_loss = 0.6606\n",
            "t = 2, avg_loss = 0.6695\n",
            "t = 3, avg_loss = 0.6167\n",
            "t = 4, avg_loss = 0.5948\n",
            "t = 5, avg_loss = 0.5340\n",
            "t = 6, avg_loss = 0.4760\n",
            "t = 7, avg_loss = 0.6618\n",
            "t = 8, avg_loss = 0.6058\n",
            "t = 9, avg_loss = 0.6873\n",
            "t = 10, avg_loss = 0.6010\n",
            "t = 11, avg_loss = 0.6692\n",
            "t = 12, avg_loss = 0.5632\n",
            "t = 13, avg_loss = 0.5766\n",
            "t = 14, avg_loss = 0.5862\n",
            "t = 15, avg_loss = 0.5027\n",
            "t = 16, avg_loss = 0.5046\n",
            "t = 17, avg_loss = 0.6132\n",
            "t = 18, avg_loss = 0.5495\n",
            "t = 19, avg_loss = 0.5975\n",
            "t = 20, avg_loss = 0.6731\n",
            "t = 21, avg_loss = 0.6314\n",
            "t = 22, avg_loss = 0.4776\n",
            "t = 23, avg_loss = 0.5991\n",
            "t = 24, avg_loss = 0.5160\n",
            "t = 25, avg_loss = 0.6299\n",
            "Checking accuracy on test set\n",
            "Got 282 / 400 correct (70.50)\n",
            "acc = 0.705000\n",
            "Starting epoch 25 / 50\n",
            "t = 1, avg_loss = 0.6337\n",
            "t = 2, avg_loss = 0.5943\n",
            "t = 3, avg_loss = 0.4889\n",
            "t = 4, avg_loss = 0.5585\n",
            "t = 5, avg_loss = 0.5921\n",
            "t = 6, avg_loss = 0.4995\n",
            "t = 7, avg_loss = 0.5980\n",
            "t = 8, avg_loss = 0.4636\n",
            "t = 9, avg_loss = 0.5512\n",
            "t = 10, avg_loss = 0.5968\n",
            "t = 11, avg_loss = 0.7224\n",
            "t = 12, avg_loss = 0.6405\n",
            "t = 13, avg_loss = 0.6510\n",
            "t = 14, avg_loss = 0.5164\n",
            "t = 15, avg_loss = 0.6246\n",
            "t = 16, avg_loss = 0.5420\n",
            "t = 17, avg_loss = 0.5020\n",
            "t = 18, avg_loss = 0.5877\n",
            "t = 19, avg_loss = 0.5555\n",
            "t = 20, avg_loss = 0.6048\n",
            "t = 21, avg_loss = 0.5464\n",
            "t = 22, avg_loss = 0.5912\n",
            "t = 23, avg_loss = 0.5460\n",
            "t = 24, avg_loss = 0.5484\n",
            "t = 25, avg_loss = 0.5702\n",
            "Checking accuracy on test set\n",
            "Got 297 / 400 correct (74.25)\n",
            "acc = 0.742500\n",
            "Starting epoch 26 / 50\n",
            "t = 1, avg_loss = 0.6685\n",
            "t = 2, avg_loss = 0.5886\n",
            "t = 3, avg_loss = 0.4645\n",
            "t = 4, avg_loss = 0.5533\n",
            "t = 5, avg_loss = 0.5935\n",
            "t = 6, avg_loss = 0.5946\n",
            "t = 7, avg_loss = 0.5688\n",
            "t = 8, avg_loss = 0.4329\n",
            "t = 9, avg_loss = 0.5743\n",
            "t = 10, avg_loss = 0.5657\n",
            "t = 11, avg_loss = 0.6501\n",
            "t = 12, avg_loss = 0.6652\n",
            "t = 13, avg_loss = 0.5252\n",
            "t = 14, avg_loss = 0.5424\n",
            "t = 15, avg_loss = 0.6134\n",
            "t = 16, avg_loss = 0.5491\n",
            "t = 17, avg_loss = 0.5379\n",
            "t = 18, avg_loss = 0.4764\n",
            "t = 19, avg_loss = 0.5948\n",
            "t = 20, avg_loss = 0.5884\n",
            "t = 21, avg_loss = 0.5118\n",
            "t = 22, avg_loss = 0.6641\n",
            "t = 23, avg_loss = 0.6075\n",
            "t = 24, avg_loss = 0.5948\n",
            "t = 25, avg_loss = 0.4950\n",
            "Checking accuracy on test set\n",
            "Got 291 / 400 correct (72.75)\n",
            "acc = 0.727500\n",
            "Starting epoch 27 / 50\n",
            "t = 1, avg_loss = 0.4629\n",
            "t = 2, avg_loss = 0.5641\n",
            "t = 3, avg_loss = 0.6023\n",
            "t = 4, avg_loss = 0.5596\n",
            "t = 5, avg_loss = 0.6644\n",
            "t = 6, avg_loss = 0.5539\n",
            "t = 7, avg_loss = 0.8092\n",
            "t = 8, avg_loss = 0.6236\n",
            "t = 9, avg_loss = 0.6647\n",
            "t = 10, avg_loss = 0.4798\n",
            "t = 11, avg_loss = 0.4385\n",
            "t = 12, avg_loss = 0.5798\n",
            "t = 13, avg_loss = 0.5665\n",
            "t = 14, avg_loss = 0.5758\n",
            "t = 15, avg_loss = 0.5100\n",
            "t = 16, avg_loss = 0.5137\n",
            "t = 17, avg_loss = 0.5402\n",
            "t = 18, avg_loss = 0.7116\n",
            "t = 19, avg_loss = 0.5650\n",
            "t = 20, avg_loss = 0.5890\n",
            "t = 21, avg_loss = 0.4980\n",
            "t = 22, avg_loss = 0.5717\n",
            "t = 23, avg_loss = 0.5443\n",
            "t = 24, avg_loss = 0.5934\n",
            "t = 25, avg_loss = 0.4846\n",
            "Checking accuracy on test set\n",
            "Got 309 / 400 correct (77.25)\n",
            "acc = 0.772500\n",
            "Starting epoch 28 / 50\n",
            "t = 1, avg_loss = 0.5094\n",
            "t = 2, avg_loss = 0.5294\n",
            "t = 3, avg_loss = 0.5817\n",
            "t = 4, avg_loss = 0.6015\n",
            "t = 5, avg_loss = 0.5695\n",
            "t = 6, avg_loss = 0.5419\n",
            "t = 7, avg_loss = 0.5360\n",
            "t = 8, avg_loss = 0.5781\n",
            "t = 9, avg_loss = 0.4713\n",
            "t = 10, avg_loss = 0.5487\n",
            "t = 11, avg_loss = 0.6090\n",
            "t = 12, avg_loss = 0.6034\n",
            "t = 13, avg_loss = 0.5610\n",
            "t = 14, avg_loss = 0.5649\n",
            "t = 15, avg_loss = 0.5579\n",
            "t = 16, avg_loss = 0.6596\n",
            "t = 17, avg_loss = 0.6351\n",
            "t = 18, avg_loss = 0.6360\n",
            "t = 19, avg_loss = 0.5279\n",
            "t = 20, avg_loss = 0.5494\n",
            "t = 21, avg_loss = 0.6031\n",
            "t = 22, avg_loss = 0.5653\n",
            "t = 23, avg_loss = 0.4786\n",
            "t = 24, avg_loss = 0.4861\n",
            "t = 25, avg_loss = 0.5738\n",
            "Checking accuracy on test set\n",
            "Got 277 / 400 correct (69.25)\n",
            "acc = 0.692500\n",
            "Starting epoch 29 / 50\n",
            "t = 1, avg_loss = 0.6250\n",
            "t = 2, avg_loss = 0.5236\n",
            "t = 3, avg_loss = 0.5958\n",
            "t = 4, avg_loss = 0.5853\n",
            "t = 5, avg_loss = 0.5944\n",
            "t = 6, avg_loss = 0.6477\n",
            "t = 7, avg_loss = 0.5544\n",
            "t = 8, avg_loss = 0.5467\n",
            "t = 9, avg_loss = 0.4735\n",
            "t = 10, avg_loss = 0.6001\n",
            "t = 11, avg_loss = 0.5627\n",
            "t = 12, avg_loss = 0.6011\n",
            "t = 13, avg_loss = 0.5684\n",
            "t = 14, avg_loss = 0.5340\n",
            "t = 15, avg_loss = 0.4539\n",
            "t = 16, avg_loss = 0.5646\n",
            "t = 17, avg_loss = 0.5420\n",
            "t = 18, avg_loss = 0.5197\n",
            "t = 19, avg_loss = 0.5575\n",
            "t = 20, avg_loss = 0.6979\n",
            "t = 21, avg_loss = 0.5406\n",
            "t = 22, avg_loss = 0.5510\n",
            "t = 23, avg_loss = 0.5468\n",
            "t = 24, avg_loss = 0.5149\n",
            "t = 25, avg_loss = 0.5469\n",
            "Checking accuracy on test set\n",
            "Got 313 / 400 correct (78.25)\n",
            "acc = 0.782500\n",
            "Starting epoch 30 / 50\n",
            "t = 1, avg_loss = 0.5975\n",
            "t = 2, avg_loss = 0.5201\n",
            "t = 3, avg_loss = 0.6090\n",
            "t = 4, avg_loss = 0.5748\n",
            "t = 5, avg_loss = 0.5152\n",
            "t = 6, avg_loss = 0.6082\n",
            "t = 7, avg_loss = 0.6385\n",
            "t = 8, avg_loss = 0.4939\n",
            "t = 9, avg_loss = 0.6211\n",
            "t = 10, avg_loss = 0.6501\n",
            "t = 11, avg_loss = 0.4845\n",
            "t = 12, avg_loss = 0.5628\n",
            "t = 13, avg_loss = 0.5829\n",
            "t = 14, avg_loss = 0.6858\n",
            "t = 15, avg_loss = 0.5200\n",
            "t = 16, avg_loss = 0.6347\n",
            "t = 17, avg_loss = 0.6754\n",
            "t = 18, avg_loss = 0.6445\n",
            "t = 19, avg_loss = 0.5007\n",
            "t = 20, avg_loss = 0.6148\n",
            "t = 21, avg_loss = 0.5586\n",
            "t = 22, avg_loss = 0.5566\n",
            "t = 23, avg_loss = 0.4990\n",
            "t = 24, avg_loss = 0.4600\n",
            "t = 25, avg_loss = 0.4562\n",
            "Checking accuracy on test set\n",
            "Got 309 / 400 correct (77.25)\n",
            "acc = 0.772500\n",
            "Starting epoch 31 / 50\n",
            "t = 1, avg_loss = 0.5391\n",
            "t = 2, avg_loss = 0.5655\n",
            "t = 3, avg_loss = 0.5499\n",
            "t = 4, avg_loss = 0.6100\n",
            "t = 5, avg_loss = 0.5055\n",
            "t = 6, avg_loss = 0.5396\n",
            "t = 7, avg_loss = 0.5004\n",
            "t = 8, avg_loss = 0.5123\n",
            "t = 9, avg_loss = 0.5752\n",
            "t = 10, avg_loss = 0.5414\n",
            "t = 11, avg_loss = 0.5507\n",
            "t = 12, avg_loss = 0.5610\n",
            "t = 13, avg_loss = 0.4532\n",
            "t = 14, avg_loss = 0.5806\n",
            "t = 15, avg_loss = 0.4932\n",
            "t = 16, avg_loss = 0.5670\n",
            "t = 17, avg_loss = 0.6777\n",
            "t = 18, avg_loss = 0.4138\n",
            "t = 19, avg_loss = 0.5698\n",
            "t = 20, avg_loss = 0.5061\n",
            "t = 21, avg_loss = 0.4317\n",
            "t = 22, avg_loss = 0.6987\n",
            "t = 23, avg_loss = 0.6268\n",
            "t = 24, avg_loss = 0.5549\n",
            "t = 25, avg_loss = 0.5143\n",
            "Checking accuracy on test set\n",
            "Got 303 / 400 correct (75.75)\n",
            "acc = 0.757500\n",
            "Starting epoch 32 / 50\n",
            "t = 1, avg_loss = 0.5193\n",
            "t = 2, avg_loss = 0.5313\n",
            "t = 3, avg_loss = 0.7064\n",
            "t = 4, avg_loss = 0.6136\n",
            "t = 5, avg_loss = 0.5802\n",
            "t = 6, avg_loss = 0.6425\n",
            "t = 7, avg_loss = 0.5729\n",
            "t = 8, avg_loss = 0.5086\n",
            "t = 9, avg_loss = 0.6052\n",
            "t = 10, avg_loss = 0.5241\n",
            "t = 11, avg_loss = 0.6521\n",
            "t = 12, avg_loss = 0.5389\n",
            "t = 13, avg_loss = 0.5850\n",
            "t = 14, avg_loss = 0.5446\n",
            "t = 15, avg_loss = 0.4872\n",
            "t = 16, avg_loss = 0.5125\n",
            "t = 17, avg_loss = 0.5524\n",
            "t = 18, avg_loss = 0.4782\n",
            "t = 19, avg_loss = 0.6155\n",
            "t = 20, avg_loss = 0.6708\n",
            "t = 21, avg_loss = 0.5112\n",
            "t = 22, avg_loss = 0.6178\n",
            "t = 23, avg_loss = 0.5727\n",
            "t = 24, avg_loss = 0.5651\n",
            "t = 25, avg_loss = 0.7259\n",
            "Checking accuracy on test set\n",
            "Got 289 / 400 correct (72.25)\n",
            "acc = 0.722500\n",
            "Starting epoch 33 / 50\n",
            "t = 1, avg_loss = 0.6038\n",
            "t = 2, avg_loss = 0.6479\n",
            "t = 3, avg_loss = 0.4731\n",
            "t = 4, avg_loss = 0.5573\n",
            "t = 5, avg_loss = 0.5694\n",
            "t = 6, avg_loss = 0.5686\n",
            "t = 7, avg_loss = 0.6046\n",
            "t = 8, avg_loss = 0.5821\n",
            "t = 9, avg_loss = 0.5123\n",
            "t = 10, avg_loss = 0.6998\n",
            "t = 11, avg_loss = 0.5625\n",
            "t = 12, avg_loss = 0.5619\n",
            "t = 13, avg_loss = 0.5472\n",
            "t = 14, avg_loss = 0.5583\n",
            "t = 15, avg_loss = 0.4967\n",
            "t = 16, avg_loss = 0.5180\n",
            "t = 17, avg_loss = 0.6266\n",
            "t = 18, avg_loss = 0.5854\n",
            "t = 19, avg_loss = 0.5187\n",
            "t = 20, avg_loss = 0.5038\n",
            "t = 21, avg_loss = 0.5404\n",
            "t = 22, avg_loss = 0.6325\n",
            "t = 23, avg_loss = 0.5171\n",
            "t = 24, avg_loss = 0.5208\n",
            "t = 25, avg_loss = 0.4738\n",
            "Checking accuracy on test set\n",
            "Got 297 / 400 correct (74.25)\n",
            "acc = 0.742500\n",
            "Starting epoch 34 / 50\n",
            "t = 1, avg_loss = 0.5199\n",
            "t = 2, avg_loss = 0.5240\n",
            "t = 3, avg_loss = 0.5913\n",
            "t = 4, avg_loss = 0.5003\n",
            "t = 5, avg_loss = 0.5423\n",
            "t = 6, avg_loss = 0.5213\n",
            "t = 7, avg_loss = 0.5017\n",
            "t = 8, avg_loss = 0.5955\n",
            "t = 9, avg_loss = 0.5400\n",
            "t = 10, avg_loss = 0.5065\n",
            "t = 11, avg_loss = 0.4977\n",
            "t = 12, avg_loss = 0.5592\n",
            "t = 13, avg_loss = 0.5729\n",
            "t = 14, avg_loss = 0.5349\n",
            "t = 15, avg_loss = 0.5074\n",
            "t = 16, avg_loss = 0.5732\n",
            "t = 17, avg_loss = 0.7118\n",
            "t = 18, avg_loss = 0.5600\n",
            "t = 19, avg_loss = 0.5228\n",
            "t = 20, avg_loss = 0.8214\n",
            "t = 21, avg_loss = 0.5158\n",
            "t = 22, avg_loss = 0.6751\n",
            "t = 23, avg_loss = 0.6415\n",
            "t = 24, avg_loss = 0.7676\n",
            "t = 25, avg_loss = 0.4883\n",
            "Checking accuracy on test set\n",
            "Got 276 / 400 correct (69.00)\n",
            "acc = 0.690000\n",
            "Starting epoch 35 / 50\n",
            "t = 1, avg_loss = 0.4853\n",
            "t = 2, avg_loss = 0.5464\n",
            "t = 3, avg_loss = 0.5799\n",
            "t = 4, avg_loss = 0.5259\n",
            "t = 5, avg_loss = 0.6005\n",
            "t = 6, avg_loss = 0.5309\n",
            "t = 7, avg_loss = 0.6150\n",
            "t = 8, avg_loss = 0.5204\n",
            "t = 9, avg_loss = 0.5326\n",
            "t = 10, avg_loss = 0.6119\n",
            "t = 11, avg_loss = 0.5815\n",
            "t = 12, avg_loss = 0.5731\n",
            "t = 13, avg_loss = 0.6063\n",
            "t = 14, avg_loss = 0.4713\n",
            "t = 15, avg_loss = 0.4818\n",
            "t = 16, avg_loss = 0.5911\n",
            "t = 17, avg_loss = 0.5401\n",
            "t = 18, avg_loss = 0.5262\n",
            "t = 19, avg_loss = 0.7454\n",
            "t = 20, avg_loss = 0.5650\n",
            "t = 21, avg_loss = 0.5645\n",
            "t = 22, avg_loss = 0.6589\n",
            "t = 23, avg_loss = 0.5805\n",
            "t = 24, avg_loss = 0.4696\n",
            "t = 25, avg_loss = 0.4551\n",
            "Checking accuracy on test set\n",
            "Got 296 / 400 correct (74.00)\n",
            "acc = 0.740000\n",
            "Starting epoch 36 / 50\n",
            "t = 1, avg_loss = 0.5288\n",
            "t = 2, avg_loss = 0.5333\n",
            "t = 3, avg_loss = 0.5132\n",
            "t = 4, avg_loss = 0.5742\n",
            "t = 5, avg_loss = 0.5451\n",
            "t = 6, avg_loss = 0.5806\n",
            "t = 7, avg_loss = 0.4919\n",
            "t = 8, avg_loss = 0.5375\n",
            "t = 9, avg_loss = 0.5761\n",
            "t = 10, avg_loss = 0.5180\n",
            "t = 11, avg_loss = 0.5887\n",
            "t = 12, avg_loss = 0.6279\n",
            "t = 13, avg_loss = 0.5190\n",
            "t = 14, avg_loss = 0.4712\n",
            "t = 15, avg_loss = 0.5187\n",
            "t = 16, avg_loss = 0.4613\n",
            "t = 17, avg_loss = 0.6838\n",
            "t = 18, avg_loss = 0.5571\n",
            "t = 19, avg_loss = 0.5756\n",
            "t = 20, avg_loss = 0.6295\n",
            "t = 21, avg_loss = 0.4893\n",
            "t = 22, avg_loss = 0.6075\n",
            "t = 23, avg_loss = 0.5520\n",
            "t = 24, avg_loss = 0.4683\n",
            "t = 25, avg_loss = 0.5781\n",
            "Checking accuracy on test set\n",
            "Got 277 / 400 correct (69.25)\n",
            "acc = 0.692500\n",
            "Starting epoch 37 / 50\n",
            "t = 1, avg_loss = 0.6682\n",
            "t = 2, avg_loss = 0.5421\n",
            "t = 3, avg_loss = 0.5232\n",
            "t = 4, avg_loss = 0.5805\n",
            "t = 5, avg_loss = 0.5468\n",
            "t = 6, avg_loss = 0.5590\n",
            "t = 7, avg_loss = 0.6063\n",
            "t = 8, avg_loss = 0.5036\n",
            "t = 9, avg_loss = 0.6361\n",
            "t = 10, avg_loss = 0.5718\n",
            "t = 11, avg_loss = 0.5430\n",
            "t = 12, avg_loss = 0.5069\n",
            "t = 13, avg_loss = 0.5308\n",
            "t = 14, avg_loss = 0.5084\n",
            "t = 15, avg_loss = 0.5466\n",
            "t = 16, avg_loss = 0.5206\n",
            "t = 17, avg_loss = 0.4502\n",
            "t = 18, avg_loss = 0.4609\n",
            "t = 19, avg_loss = 0.4749\n",
            "t = 20, avg_loss = 0.4879\n",
            "t = 21, avg_loss = 0.5348\n",
            "t = 22, avg_loss = 0.4988\n",
            "t = 23, avg_loss = 0.5182\n",
            "t = 24, avg_loss = 0.5541\n",
            "t = 25, avg_loss = 0.5695\n",
            "Checking accuracy on test set\n",
            "Got 320 / 400 correct (80.00)\n",
            "acc = 0.800000\n",
            "Starting epoch 38 / 50\n",
            "t = 1, avg_loss = 0.6031\n",
            "t = 2, avg_loss = 0.5518\n",
            "t = 3, avg_loss = 0.5793\n",
            "t = 4, avg_loss = 0.5834\n",
            "t = 5, avg_loss = 0.4767\n",
            "t = 6, avg_loss = 0.5348\n",
            "t = 7, avg_loss = 0.5918\n",
            "t = 8, avg_loss = 0.5313\n",
            "t = 9, avg_loss = 0.5641\n",
            "t = 10, avg_loss = 0.4806\n",
            "t = 11, avg_loss = 0.6051\n",
            "t = 12, avg_loss = 0.4882\n",
            "t = 13, avg_loss = 0.5445\n",
            "t = 14, avg_loss = 0.5060\n",
            "t = 15, avg_loss = 0.6001\n",
            "t = 16, avg_loss = 0.4389\n",
            "t = 17, avg_loss = 0.5624\n",
            "t = 18, avg_loss = 0.4749\n",
            "t = 19, avg_loss = 0.6143\n",
            "t = 20, avg_loss = 0.5832\n",
            "t = 21, avg_loss = 0.5027\n",
            "t = 22, avg_loss = 0.5216\n",
            "t = 23, avg_loss = 0.5347\n",
            "t = 24, avg_loss = 0.5557\n",
            "t = 25, avg_loss = 0.5989\n",
            "Checking accuracy on test set\n",
            "Got 277 / 400 correct (69.25)\n",
            "acc = 0.692500\n",
            "Starting epoch 39 / 50\n",
            "t = 1, avg_loss = 0.4669\n",
            "t = 2, avg_loss = 0.5976\n",
            "t = 3, avg_loss = 0.6313\n",
            "t = 4, avg_loss = 0.5777\n",
            "t = 5, avg_loss = 0.5013\n",
            "t = 6, avg_loss = 0.7294\n",
            "t = 7, avg_loss = 0.4987\n",
            "t = 8, avg_loss = 0.5651\n",
            "t = 9, avg_loss = 0.5693\n",
            "t = 10, avg_loss = 0.6251\n",
            "t = 11, avg_loss = 0.6549\n",
            "t = 12, avg_loss = 0.5339\n",
            "t = 13, avg_loss = 0.5907\n",
            "t = 14, avg_loss = 0.6073\n",
            "t = 15, avg_loss = 0.5482\n",
            "t = 16, avg_loss = 0.5174\n",
            "t = 17, avg_loss = 0.5127\n",
            "t = 18, avg_loss = 0.5250\n",
            "t = 19, avg_loss = 0.5553\n",
            "t = 20, avg_loss = 0.5665\n",
            "t = 21, avg_loss = 0.5394\n",
            "t = 22, avg_loss = 0.5537\n",
            "t = 23, avg_loss = 0.5613\n",
            "t = 24, avg_loss = 0.5895\n",
            "t = 25, avg_loss = 0.5246\n",
            "Checking accuracy on test set\n",
            "Got 309 / 400 correct (77.25)\n",
            "acc = 0.772500\n",
            "Starting epoch 40 / 50\n",
            "t = 1, avg_loss = 0.5148\n",
            "t = 2, avg_loss = 0.5949\n",
            "t = 3, avg_loss = 0.6569\n",
            "t = 4, avg_loss = 0.5402\n",
            "t = 5, avg_loss = 0.4744\n",
            "t = 6, avg_loss = 0.5323\n",
            "t = 7, avg_loss = 0.5216\n",
            "t = 8, avg_loss = 0.5169\n",
            "t = 9, avg_loss = 0.4729\n",
            "t = 10, avg_loss = 0.4801\n",
            "t = 11, avg_loss = 0.5452\n",
            "t = 12, avg_loss = 0.5683\n",
            "t = 13, avg_loss = 0.5245\n",
            "t = 14, avg_loss = 0.4994\n",
            "t = 15, avg_loss = 0.6179\n",
            "t = 16, avg_loss = 0.4893\n",
            "t = 17, avg_loss = 0.5514\n",
            "t = 18, avg_loss = 0.5941\n",
            "t = 19, avg_loss = 0.5745\n",
            "t = 20, avg_loss = 0.5514\n",
            "t = 21, avg_loss = 0.5643\n",
            "t = 22, avg_loss = 0.5752\n",
            "t = 23, avg_loss = 0.5280\n",
            "t = 24, avg_loss = 0.5451\n",
            "t = 25, avg_loss = 0.6426\n",
            "Checking accuracy on test set\n",
            "Got 311 / 400 correct (77.75)\n",
            "acc = 0.777500\n",
            "Starting epoch 41 / 50\n",
            "t = 1, avg_loss = 0.5893\n",
            "t = 2, avg_loss = 0.5129\n",
            "t = 3, avg_loss = 0.5816\n",
            "t = 4, avg_loss = 0.5764\n",
            "t = 5, avg_loss = 0.6437\n",
            "t = 6, avg_loss = 0.5104\n",
            "t = 7, avg_loss = 0.4893\n",
            "t = 8, avg_loss = 0.6522\n",
            "t = 9, avg_loss = 0.5447\n",
            "t = 10, avg_loss = 0.6277\n",
            "t = 11, avg_loss = 0.6221\n",
            "t = 12, avg_loss = 0.5510\n",
            "t = 13, avg_loss = 0.4462\n",
            "t = 14, avg_loss = 0.5248\n",
            "t = 15, avg_loss = 0.5220\n",
            "t = 16, avg_loss = 0.5618\n",
            "t = 17, avg_loss = 0.5606\n",
            "t = 18, avg_loss = 0.5555\n",
            "t = 19, avg_loss = 0.6334\n",
            "t = 20, avg_loss = 0.4658\n",
            "t = 21, avg_loss = 0.4954\n",
            "t = 22, avg_loss = 0.5036\n",
            "t = 23, avg_loss = 0.5152\n",
            "t = 24, avg_loss = 0.5181\n",
            "t = 25, avg_loss = 0.5379\n",
            "Checking accuracy on test set\n",
            "Got 300 / 400 correct (75.00)\n",
            "acc = 0.750000\n",
            "Starting epoch 42 / 50\n",
            "t = 1, avg_loss = 0.5397\n",
            "t = 2, avg_loss = 0.5076\n",
            "t = 3, avg_loss = 0.6251\n",
            "t = 4, avg_loss = 0.4427\n",
            "t = 5, avg_loss = 0.4825\n",
            "t = 6, avg_loss = 0.5014\n",
            "t = 7, avg_loss = 0.5486\n",
            "t = 8, avg_loss = 0.5535\n",
            "t = 9, avg_loss = 0.5355\n",
            "t = 10, avg_loss = 0.4882\n",
            "t = 11, avg_loss = 0.4744\n",
            "t = 12, avg_loss = 0.4790\n",
            "t = 13, avg_loss = 0.6058\n",
            "t = 14, avg_loss = 0.5069\n",
            "t = 15, avg_loss = 0.6690\n",
            "t = 16, avg_loss = 0.4481\n",
            "t = 17, avg_loss = 0.5223\n",
            "t = 18, avg_loss = 0.4882\n",
            "t = 19, avg_loss = 0.5397\n",
            "t = 20, avg_loss = 0.6807\n",
            "t = 21, avg_loss = 0.4273\n",
            "t = 22, avg_loss = 0.4912\n",
            "t = 23, avg_loss = 0.5027\n",
            "t = 24, avg_loss = 0.5088\n",
            "t = 25, avg_loss = 0.5782\n",
            "Checking accuracy on test set\n",
            "Got 282 / 400 correct (70.50)\n",
            "acc = 0.705000\n",
            "Starting epoch 43 / 50\n",
            "t = 1, avg_loss = 0.5123\n",
            "t = 2, avg_loss = 0.5866\n",
            "t = 3, avg_loss = 0.4450\n",
            "t = 4, avg_loss = 0.5489\n",
            "t = 5, avg_loss = 0.5320\n",
            "t = 6, avg_loss = 0.5234\n",
            "t = 7, avg_loss = 0.6740\n",
            "t = 8, avg_loss = 0.6250\n",
            "t = 9, avg_loss = 0.4834\n",
            "t = 10, avg_loss = 0.5047\n",
            "t = 11, avg_loss = 0.5659\n",
            "t = 12, avg_loss = 0.5121\n",
            "t = 13, avg_loss = 0.5374\n",
            "t = 14, avg_loss = 0.4838\n",
            "t = 15, avg_loss = 0.5497\n",
            "t = 16, avg_loss = 0.4990\n",
            "t = 17, avg_loss = 0.5470\n",
            "t = 18, avg_loss = 0.5764\n",
            "t = 19, avg_loss = 0.5441\n",
            "t = 20, avg_loss = 0.5088\n",
            "t = 21, avg_loss = 0.5253\n",
            "t = 22, avg_loss = 0.4429\n",
            "t = 23, avg_loss = 0.5822\n",
            "t = 24, avg_loss = 0.5109\n",
            "t = 25, avg_loss = 0.4175\n",
            "Checking accuracy on test set\n",
            "Got 303 / 400 correct (75.75)\n",
            "acc = 0.757500\n",
            "Starting epoch 44 / 50\n",
            "t = 1, avg_loss = 0.4867\n",
            "t = 2, avg_loss = 0.5259\n",
            "t = 3, avg_loss = 0.4773\n",
            "t = 4, avg_loss = 0.5287\n",
            "t = 5, avg_loss = 0.5955\n",
            "t = 6, avg_loss = 0.4549\n",
            "t = 7, avg_loss = 0.5108\n",
            "t = 8, avg_loss = 0.5076\n",
            "t = 9, avg_loss = 0.4095\n",
            "t = 10, avg_loss = 0.5847\n",
            "t = 11, avg_loss = 0.6035\n",
            "t = 12, avg_loss = 0.4473\n",
            "t = 13, avg_loss = 0.4470\n",
            "t = 14, avg_loss = 0.5419\n",
            "t = 15, avg_loss = 0.5111\n",
            "t = 16, avg_loss = 0.5620\n",
            "t = 17, avg_loss = 0.5783\n",
            "t = 18, avg_loss = 0.4182\n",
            "t = 19, avg_loss = 0.4785\n",
            "t = 20, avg_loss = 0.6045\n",
            "t = 21, avg_loss = 0.5219\n",
            "t = 22, avg_loss = 0.5618\n",
            "t = 23, avg_loss = 0.4670\n",
            "t = 24, avg_loss = 0.5252\n",
            "t = 25, avg_loss = 0.5384\n",
            "Checking accuracy on test set\n",
            "Got 288 / 400 correct (72.00)\n",
            "acc = 0.720000\n",
            "Starting epoch 45 / 50\n",
            "t = 1, avg_loss = 0.6661\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-0fc3e7a84818>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_gpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0mcheck_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-7b7c48cb9b8f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, loss_fn, optimizer, num_epochs, starting_from_epoch)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mx_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0my_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-50a9cd504daf>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m           \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"malignant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"malignant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \"\"\"\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   1856\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1858\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreducing_gap\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresample\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mNEAREST\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nr2sQUvYlXYm",
        "colab_type": "code",
        "outputId": "02769270-9fd1-4a10-f8b7-334c28b1905c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "check_accuracy(model_gpu, valid_loader)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking accuracy on test set\n",
            "Got 297 / 400 correct (74.25)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7425"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkR_h7GRTJv4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#! pip install torch-lr-finder -v --global-option=\"amp\"\n",
        "#from torch_lr_finder import LRFinder\n",
        "\n",
        "#lr_finder = LRFinder(model_gpu, optimizer, loss_fn, device=\"cuda\")\n",
        "\n",
        "#lr_finder.range_test(train_loader, end_lr=1, num_iter=100, start_lr=1e-05)\n",
        "#lr_finder.plot() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzuX5gLEeJfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def retry_from_backup():\n",
        "  model_gpu = model_base.type(gpu_dtype)\n",
        "  print(model_gpu)\n",
        "  loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) \n",
        "\n",
        "\n",
        "\n",
        "  checkpoint = torch.load(model_backup_path)\n",
        "  model_gpu.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  epoch = checkpoint['epoch']\n",
        "  loss = checkpoint['loss']\n",
        "  print(\"starting from epoch: \" + str(epoch))\n",
        "  print(\"starting from loss: \" + str(loss))\n",
        "  print(checkpoint['model_state_dict'])\n",
        "  print(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "  train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs, starting_from_epoch=epoch)\n",
        "  check_accuracy(model_gpu, valid_loader)\n",
        "#retry_from_backup()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDn-2g-TLY3k",
        "colab_type": "code",
        "outputId": "dacf1307-75b6-4c21-b89c-5c13964dbb85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot([print_every*batch_size*(i+1) for i in range((len(avg_loss_list)))],avg_loss_list)\n",
        "print(\"Loss:\")\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGer6hJv7-zR",
        "colab_type": "code",
        "outputId": "db8286b9-95ba-485a-b44a-2ecd4c7d8bdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "plt.plot([i+1 for i in range((len(acc_list)))],acc_list)\n",
        "print(\"Accurancy:\")\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accurancy:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBTReWHxz4Ml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}