{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN_Avg_No_Relu2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamilo116/KNN/blob/master/KNN_Avg_No_Relu2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7ReM7FU-xs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import sys\n",
        "from random import shuffle\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms as transforms\n",
        "import timeit\n",
        "\n",
        "np.random.seed(4) \n",
        "torch.manual_seed(4) \n",
        "torch.cuda.manual_seed(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYIMZ8QyYewD",
        "colab_type": "code",
        "outputId": "1c4e1fea-49c2-4c43-812e-12e389fa1ae0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "! git clone https://github.com/wang-chen/kervolution.git \n",
        "\n",
        "sys.path.append(\"kervolution/\")\n",
        "from kervolution import Kerv2d\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'kervolution'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects:  16% (1/6)\u001b[K\rremote: Counting objects:  33% (2/6)\u001b[K\rremote: Counting objects:  50% (3/6)\u001b[K\rremote: Counting objects:  66% (4/6)\u001b[K\rremote: Counting objects:  83% (5/6)\u001b[K\rremote: Counting objects: 100% (6/6)\u001b[K\rremote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 53 (delta 2), reused 0 (delta 0), pack-reused 47\u001b[K\n",
            "Unpacking objects: 100% (53/53), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvbKg4VJXKY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LIMIT_IMAGES_NUM = 1000\n",
        "train_test_split_size = 0.2\n",
        "image_resize = (100, 100)\n",
        "batch_size = 64\n",
        "num_workers = 0\n",
        "\n",
        "in_channels = 3\n",
        "out_channels_1 = 16\n",
        "out_channels_2 = 24\n",
        "out_channels_3 = 32\n",
        "out_channels_4 = 48\n",
        "out_channels_5 = 64\n",
        "out_channels_6 = 128\n",
        "\n",
        "kernel_size = 3\n",
        "padding_1 = 1\n",
        "num_epochs = 50\n",
        "\n",
        "learning_rate = 0.00009\n",
        "weight_decay = 0.1\n",
        "\n",
        "MALIGNANT_DATASET = '/content/drive/My Drive/Colab_data/malignant/malignant/'\n",
        "BENIGN_DATASET = '/content/drive/My Drive/Colab_data/benign/benign/'\n",
        "DATA_FOLDER = '/content/drive/My Drive/Colab_data/'\n",
        "model_backup_path = os.path.join(DATA_FOLDER, 'backup_model_2') \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMOHez_kHZD6",
        "colab_type": "code",
        "outputId": "8c35c090-f6b0-4b91-a32c-3674401e6d93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b8P1NdXfVdX",
        "colab_type": "code",
        "outputId": "9402206c-118f-4753-a5f4-8f581cf76b75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "benign_file_list = sorted(os.listdir(BENIGN_DATASET))\n",
        "malignant_file_list = sorted(os.listdir(MALIGNANT_DATASET))\n",
        "shuffle(benign_file_list)\n",
        "shuffle(malignant_file_list)\n",
        "benign_file_list = benign_file_list[:LIMIT_IMAGES_NUM]\n",
        "malignant_file_list = malignant_file_list[:LIMIT_IMAGES_NUM]\n",
        "\n",
        "print(f\"Number of benign {len(benign_file_list)} images\")\n",
        "print(f\"Number of malignant {len(malignant_file_list)} images\")\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize(image_resize),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of benign 1000 images\n",
            "Number of malignant 1000 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGDQfal74BLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "benign_dict = {filename: 0 for filename in benign_file_list}\n",
        "malignant_dict = {filename: 1 for filename in malignant_file_list}\n",
        "img_class_dict = {**benign_dict , **malignant_dict}\n",
        "labeled_data = pd.Series(img_class_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvAAOqmVfVll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IsicDataset(Dataset):\n",
        "    def __init__(self, data_folder, labeled_data, \n",
        "                 transform=transforms.Compose([transforms.ToTensor()])):\n",
        "        self.labeled_data = labeled_data\n",
        "        self.transform = transform\n",
        "        self.data_folder = data_folder\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labeled_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        label = self.labeled_data[index]\n",
        "        if label == 0:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"benign\", \"benign\", index ))\n",
        "        else:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"malignant\", \"malignant\", index ))\n",
        "        image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "    @property\n",
        "    def labels(self):\n",
        "      return self.labeled_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSuYqjLAYrWA",
        "colab_type": "code",
        "outputId": "b8fba8f4-471b-41a7-e123-e4f7f868818c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        " \n",
        "dataset = IsicDataset(DATA_FOLDER, labeled_data, transform=data_transforms)\n",
        "print(dataset.labels)\n",
        "\n",
        "X_train, X_test = train_test_split(dataset.labels, test_size=train_test_split_size)\n",
        "print(\"number of training data: \",len(X_train))\n",
        "print(\"number of testing  data: \",len(X_test))\n",
        "\n",
        "train_sampler = SubsetRandomSampler(list(X_train.index))\n",
        "valid_sampler = SubsetRandomSampler(list(X_test.index))\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ISIC_0000129.jpeg    0\n",
            "ISIC_0002375.jpeg    0\n",
            "ISIC_0000701.jpeg    0\n",
            "ISIC_0001337.jpeg    0\n",
            "ISIC_0000988.jpeg    0\n",
            "                    ..\n",
            "ISIC_0010288.jpeg    1\n",
            "ISIC_0012382.jpeg    1\n",
            "ISIC_0000077.jpeg    1\n",
            "ISIC_0011726.jpeg    1\n",
            "ISIC_0000146.jpeg    1\n",
            "Length: 2000, dtype: int64\n",
            "number of training data:  1600\n",
            "number of testing  data:  400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e8nFBR6Yug5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "def train(model, train_loader ,loss_fn, optimizer, num_epochs=1, starting_from_epoch=1):\n",
        "    total_loss =0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
        "        model.train()\n",
        "\n",
        "        for t, (x, y) in enumerate(train_loader):\n",
        "            x_var = Variable(x.type(gpu_dtype))\n",
        "            y_var = Variable(y.type(gpu_dtype).long())\n",
        "            scores = model(x_var)\n",
        "            loss = loss_fn(scores, y_var)\n",
        "            total_loss += loss.data\n",
        "            \n",
        "            if (t + 1) % print_every == 0:\n",
        "                avg_loss = total_loss/print_every\n",
        "                print('t = %d, avg_loss = %.4f' % (t + 1, avg_loss) )\n",
        "                avg_loss_list.append(avg_loss)\n",
        "                total_loss = 0\n",
        "                \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        acc = check_accuracy(model_gpu, valid_loader)\n",
        "        print('acc = %f' %(acc))\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model_gpu.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            }, model_backup_path)\n",
        "            \n",
        "def check_accuracy(model, loader):\n",
        "    print('Checking accuracy on test set')   \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval() \n",
        "    for x, y in loader:\n",
        "        x_var = Variable(x.type(gpu_dtype))\n",
        "\n",
        "        scores = model(x_var)\n",
        "        _, preds = scores.data.cpu().max(1)\n",
        "        num_correct += (preds == y).sum()\n",
        "        num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    acc_list.append(acc)\n",
        "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "    return acc\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggvpMu36Yw2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.size()\n",
        "        return x.view(N, -1)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgmexhBRZAK6",
        "colab_type": "code",
        "outputId": "9bfc8240-a79e-4c6d-cc01-8eeb506e9b6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "gpu_dtype = torch.cuda.FloatTensor\n",
        "\n",
        "print_every = 1\n",
        "\n",
        "\n",
        "'''\n",
        "Kerv2d\n",
        "kervolution with following options:\n",
        "kernel_type: [linear, polynomial, gaussian, etc.]\n",
        "default is convolution:\n",
        "          kernel_type --> linear,\n",
        "balance, power, gamma is valid only when the kernel_type is specified\n",
        "if learnable_kernel = True,  they just be the initial value of learable parameters\n",
        "if learnable_kernel = False, they are the value of kernel_type's parameter\n",
        "the parameter [power] cannot be learned due to integer limitation\n",
        "dilation (int or tuple, optional): Spacing between kernel\n",
        "elements. Default: 1\n",
        "groups (int, optional): Number of blocked connections from input\n",
        "channels to output channels. Default: 1\n",
        "bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n",
        "kernel_type (str), Default: 'linear'\n",
        "learnable_kernel (bool): Learnable kernel parameters.  Default: False \n",
        "balance: 0, 1\n",
        "power: 3, 4, 5\n",
        "gamma:\n",
        "'''\n",
        "\n",
        "\n",
        "model_base = nn.Sequential( \n",
        "                nn.Kerv2d(in_channels , out_channels_1, padding=padding_1, dilation=1, groups=1, bias=True, \n",
        "                          kernel_type='polynomial', kernel_size=kernel_size, learnable_kernel=True,\n",
        "                          kernel_regularizer=True, stride=1, balance=1, power=3, gamma=1\n",
        "                          ),\n",
        "                nn.BatchNorm2d(out_channels_1),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_1 , out_channels_2, padding= padding_1, kernel_size=kernel_size, stride=1), \n",
        "                nn.BatchNorm2d(out_channels_2),\n",
        "                nn.AvgPool2d(2, stride=2), \n",
        "                nn.Conv2d(out_channels_2 , out_channels_3, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.BatchNorm2d(out_channels_3),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_3 , out_channels_4, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.BatchNorm2d(out_channels_4),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_4 , out_channels_5, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.BatchNorm2d(out_channels_5),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_5 , out_channels_6, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.BatchNorm2d(out_channels_6),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Dropout(0.5),\n",
        "                Flatten(),\n",
        "                nn.Linear(128,64),\n",
        "                nn.Linear(64,2)\n",
        "            )\n",
        "model_gpu = model_base.type(gpu_dtype)\n",
        "print(model_gpu)\n",
        "loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) \n",
        "\n",
        "train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs)\n",
        "check_accuracy(model_gpu, valid_loader)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Kerv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (3): Conv2d(16, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (6): Conv2d(24, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (8): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (9): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (10): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (11): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (12): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (13): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (14): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (15): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (18): Dropout(p=0.5, inplace=False)\n",
            "  (19): Flatten()\n",
            "  (20): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (21): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n",
            "Starting epoch 1 / 50\n",
            "t = 1, avg_loss = 0.7464\n",
            "t = 2, avg_loss = 0.6847\n",
            "t = 3, avg_loss = 0.6826\n",
            "t = 4, avg_loss = 0.6629\n",
            "t = 5, avg_loss = 0.6292\n",
            "t = 6, avg_loss = 0.6845\n",
            "t = 7, avg_loss = 0.7024\n",
            "t = 8, avg_loss = 0.8078\n",
            "t = 9, avg_loss = 0.6076\n",
            "t = 10, avg_loss = 0.7182\n",
            "t = 11, avg_loss = 0.6232\n",
            "t = 12, avg_loss = 0.6810\n",
            "t = 13, avg_loss = 0.6512\n",
            "t = 14, avg_loss = 0.6128\n",
            "t = 15, avg_loss = 0.6129\n",
            "t = 16, avg_loss = 0.7054\n",
            "t = 17, avg_loss = 0.6250\n",
            "t = 18, avg_loss = 0.6825\n",
            "t = 19, avg_loss = 0.6528\n",
            "t = 20, avg_loss = 0.6829\n",
            "t = 21, avg_loss = 0.6899\n",
            "t = 22, avg_loss = 0.7166\n",
            "t = 23, avg_loss = 0.5993\n",
            "t = 24, avg_loss = 0.6310\n",
            "t = 25, avg_loss = 0.6109\n",
            "Checking accuracy on test set\n",
            "Got 220 / 400 correct (55.00)\n",
            "acc = 0.550000\n",
            "Starting epoch 2 / 50\n",
            "t = 1, avg_loss = 0.7360\n",
            "t = 2, avg_loss = 0.6651\n",
            "t = 3, avg_loss = 0.5953\n",
            "t = 4, avg_loss = 0.6391\n",
            "t = 5, avg_loss = 0.6681\n",
            "t = 6, avg_loss = 0.5914\n",
            "t = 7, avg_loss = 0.5461\n",
            "t = 8, avg_loss = 0.6576\n",
            "t = 9, avg_loss = 0.5418\n",
            "t = 10, avg_loss = 0.5977\n",
            "t = 11, avg_loss = 0.6429\n",
            "t = 12, avg_loss = 0.7459\n",
            "t = 13, avg_loss = 0.6803\n",
            "t = 14, avg_loss = 0.6389\n",
            "t = 15, avg_loss = 0.8174\n",
            "t = 16, avg_loss = 0.7363\n",
            "t = 17, avg_loss = 0.6192\n",
            "t = 18, avg_loss = 0.7068\n",
            "t = 19, avg_loss = 0.5905\n",
            "t = 20, avg_loss = 0.6366\n",
            "t = 21, avg_loss = 0.6648\n",
            "t = 22, avg_loss = 0.6656\n",
            "t = 23, avg_loss = 0.6782\n",
            "t = 24, avg_loss = 0.7076\n",
            "t = 25, avg_loss = 0.6353\n",
            "Checking accuracy on test set\n",
            "Got 238 / 400 correct (59.50)\n",
            "acc = 0.595000\n",
            "Starting epoch 3 / 50\n",
            "t = 1, avg_loss = 0.6856\n",
            "t = 2, avg_loss = 0.6549\n",
            "t = 3, avg_loss = 0.6905\n",
            "t = 4, avg_loss = 0.6278\n",
            "t = 5, avg_loss = 0.6312\n",
            "t = 6, avg_loss = 0.6298\n",
            "t = 7, avg_loss = 0.6776\n",
            "t = 8, avg_loss = 0.6688\n",
            "t = 9, avg_loss = 0.6632\n",
            "t = 10, avg_loss = 0.6409\n",
            "t = 11, avg_loss = 0.5733\n",
            "t = 12, avg_loss = 0.6646\n",
            "t = 13, avg_loss = 0.5884\n",
            "t = 14, avg_loss = 0.6834\n",
            "t = 15, avg_loss = 0.6199\n",
            "t = 16, avg_loss = 0.6307\n",
            "t = 17, avg_loss = 0.5907\n",
            "t = 18, avg_loss = 0.6949\n",
            "t = 19, avg_loss = 0.6678\n",
            "t = 20, avg_loss = 0.6224\n",
            "t = 21, avg_loss = 0.5805\n",
            "t = 22, avg_loss = 0.6474\n",
            "t = 23, avg_loss = 0.6442\n",
            "t = 24, avg_loss = 0.7204\n",
            "t = 25, avg_loss = 0.6388\n",
            "Checking accuracy on test set\n",
            "Got 261 / 400 correct (65.25)\n",
            "acc = 0.652500\n",
            "Starting epoch 4 / 50\n",
            "t = 1, avg_loss = 0.6978\n",
            "t = 2, avg_loss = 0.6226\n",
            "t = 3, avg_loss = 0.5975\n",
            "t = 4, avg_loss = 0.5578\n",
            "t = 5, avg_loss = 0.5822\n",
            "t = 6, avg_loss = 0.6331\n",
            "t = 7, avg_loss = 0.6264\n",
            "t = 8, avg_loss = 0.5732\n",
            "t = 9, avg_loss = 0.7239\n",
            "t = 10, avg_loss = 0.6329\n",
            "t = 11, avg_loss = 0.6484\n",
            "t = 12, avg_loss = 0.5917\n",
            "t = 13, avg_loss = 0.6486\n",
            "t = 14, avg_loss = 0.6616\n",
            "t = 15, avg_loss = 0.6414\n",
            "t = 16, avg_loss = 0.6134\n",
            "t = 17, avg_loss = 0.5874\n",
            "t = 18, avg_loss = 0.6514\n",
            "t = 19, avg_loss = 0.7013\n",
            "t = 20, avg_loss = 0.7136\n",
            "t = 21, avg_loss = 0.6574\n",
            "t = 22, avg_loss = 0.5349\n",
            "t = 23, avg_loss = 0.6777\n",
            "t = 24, avg_loss = 0.7072\n",
            "t = 25, avg_loss = 0.6223\n",
            "Checking accuracy on test set\n",
            "Got 245 / 400 correct (61.25)\n",
            "acc = 0.612500\n",
            "Starting epoch 5 / 50\n",
            "t = 1, avg_loss = 0.6710\n",
            "t = 2, avg_loss = 0.5969\n",
            "t = 3, avg_loss = 0.6749\n",
            "t = 4, avg_loss = 0.5932\n",
            "t = 5, avg_loss = 0.6460\n",
            "t = 6, avg_loss = 0.6171\n",
            "t = 7, avg_loss = 0.6010\n",
            "t = 8, avg_loss = 0.6410\n",
            "t = 9, avg_loss = 0.6789\n",
            "t = 10, avg_loss = 0.6199\n",
            "t = 11, avg_loss = 0.6313\n",
            "t = 12, avg_loss = 0.6828\n",
            "t = 13, avg_loss = 0.5835\n",
            "t = 14, avg_loss = 0.7774\n",
            "t = 15, avg_loss = 0.6534\n",
            "t = 16, avg_loss = 0.5904\n",
            "t = 17, avg_loss = 0.5997\n",
            "t = 18, avg_loss = 0.6203\n",
            "t = 19, avg_loss = 0.6668\n",
            "t = 20, avg_loss = 0.6134\n",
            "t = 21, avg_loss = 0.7597\n",
            "t = 22, avg_loss = 0.7302\n",
            "t = 23, avg_loss = 0.5932\n",
            "t = 24, avg_loss = 0.6285\n",
            "t = 25, avg_loss = 0.5900\n",
            "Checking accuracy on test set\n",
            "Got 254 / 400 correct (63.50)\n",
            "acc = 0.635000\n",
            "Starting epoch 6 / 50\n",
            "t = 1, avg_loss = 0.6592\n",
            "t = 2, avg_loss = 0.6292\n",
            "t = 3, avg_loss = 0.7133\n",
            "t = 4, avg_loss = 0.5908\n",
            "t = 5, avg_loss = 0.5825\n",
            "t = 6, avg_loss = 0.6484\n",
            "t = 7, avg_loss = 0.6161\n",
            "t = 8, avg_loss = 0.6311\n",
            "t = 9, avg_loss = 0.5745\n",
            "t = 10, avg_loss = 0.6266\n",
            "t = 11, avg_loss = 0.7157\n",
            "t = 12, avg_loss = 0.6793\n",
            "t = 13, avg_loss = 0.6620\n",
            "t = 14, avg_loss = 0.6335\n",
            "t = 15, avg_loss = 0.5866\n",
            "t = 16, avg_loss = 0.5864\n",
            "t = 17, avg_loss = 0.6053\n",
            "t = 18, avg_loss = 0.5968\n",
            "t = 19, avg_loss = 0.6569\n",
            "t = 20, avg_loss = 0.6056\n",
            "t = 21, avg_loss = 0.6525\n",
            "t = 22, avg_loss = 0.7539\n",
            "t = 23, avg_loss = 0.5756\n",
            "t = 24, avg_loss = 0.6922\n",
            "t = 25, avg_loss = 0.5826\n",
            "Checking accuracy on test set\n",
            "Got 252 / 400 correct (63.00)\n",
            "acc = 0.630000\n",
            "Starting epoch 7 / 50\n",
            "t = 1, avg_loss = 0.7078\n",
            "t = 2, avg_loss = 0.6111\n",
            "t = 3, avg_loss = 0.6728\n",
            "t = 4, avg_loss = 0.6463\n",
            "t = 5, avg_loss = 0.6634\n",
            "t = 6, avg_loss = 0.6822\n",
            "t = 7, avg_loss = 0.6154\n",
            "t = 8, avg_loss = 0.6022\n",
            "t = 9, avg_loss = 0.6890\n",
            "t = 10, avg_loss = 0.6698\n",
            "t = 11, avg_loss = 0.6350\n",
            "t = 12, avg_loss = 0.6153\n",
            "t = 13, avg_loss = 0.5859\n",
            "t = 14, avg_loss = 0.5885\n",
            "t = 15, avg_loss = 0.6284\n",
            "t = 16, avg_loss = 0.6386\n",
            "t = 17, avg_loss = 0.6407\n",
            "t = 18, avg_loss = 0.6120\n",
            "t = 19, avg_loss = 0.6765\n",
            "t = 20, avg_loss = 0.6178\n",
            "t = 21, avg_loss = 0.6413\n",
            "t = 22, avg_loss = 0.5854\n",
            "t = 23, avg_loss = 0.6244\n",
            "t = 24, avg_loss = 0.5923\n",
            "t = 25, avg_loss = 0.6271\n",
            "Checking accuracy on test set\n",
            "Got 256 / 400 correct (64.00)\n",
            "acc = 0.640000\n",
            "Starting epoch 8 / 50\n",
            "t = 1, avg_loss = 0.6317\n",
            "t = 2, avg_loss = 0.6294\n",
            "t = 3, avg_loss = 0.5732\n",
            "t = 4, avg_loss = 0.6187\n",
            "t = 5, avg_loss = 0.6297\n",
            "t = 6, avg_loss = 0.5608\n",
            "t = 7, avg_loss = 0.6359\n",
            "t = 8, avg_loss = 0.6068\n",
            "t = 9, avg_loss = 0.5994\n",
            "t = 10, avg_loss = 0.6967\n",
            "t = 11, avg_loss = 0.6171\n",
            "t = 12, avg_loss = 0.6819\n",
            "t = 13, avg_loss = 0.5950\n",
            "t = 14, avg_loss = 0.7373\n",
            "t = 15, avg_loss = 0.5839\n",
            "t = 16, avg_loss = 0.6667\n",
            "t = 17, avg_loss = 0.6262\n",
            "t = 18, avg_loss = 0.6032\n",
            "t = 19, avg_loss = 0.6300\n",
            "t = 20, avg_loss = 0.5540\n",
            "t = 21, avg_loss = 0.5724\n",
            "t = 22, avg_loss = 0.5509\n",
            "t = 23, avg_loss = 0.6719\n",
            "t = 24, avg_loss = 0.6239\n",
            "t = 25, avg_loss = 0.6448\n",
            "Checking accuracy on test set\n",
            "Got 271 / 400 correct (67.75)\n",
            "acc = 0.677500\n",
            "Starting epoch 9 / 50\n",
            "t = 1, avg_loss = 0.5631\n",
            "t = 2, avg_loss = 0.5918\n",
            "t = 3, avg_loss = 0.6616\n",
            "t = 4, avg_loss = 0.5380\n",
            "t = 5, avg_loss = 0.6656\n",
            "t = 6, avg_loss = 0.5935\n",
            "t = 7, avg_loss = 0.6950\n",
            "t = 8, avg_loss = 0.6003\n",
            "t = 9, avg_loss = 0.6157\n",
            "t = 10, avg_loss = 0.6319\n",
            "t = 11, avg_loss = 0.5423\n",
            "t = 12, avg_loss = 0.6523\n",
            "t = 13, avg_loss = 0.6557\n",
            "t = 14, avg_loss = 0.6029\n",
            "t = 15, avg_loss = 0.6185\n",
            "t = 16, avg_loss = 0.6523\n",
            "t = 17, avg_loss = 0.6149\n",
            "t = 18, avg_loss = 0.6076\n",
            "t = 19, avg_loss = 0.5862\n",
            "t = 20, avg_loss = 0.5885\n",
            "t = 21, avg_loss = 0.5720\n",
            "t = 22, avg_loss = 0.6223\n",
            "t = 23, avg_loss = 0.6214\n",
            "t = 24, avg_loss = 0.6045\n",
            "t = 25, avg_loss = 0.6332\n",
            "Checking accuracy on test set\n",
            "Got 265 / 400 correct (66.25)\n",
            "acc = 0.662500\n",
            "Starting epoch 10 / 50\n",
            "t = 1, avg_loss = 0.5897\n",
            "t = 2, avg_loss = 0.6675\n",
            "t = 3, avg_loss = 0.5703\n",
            "t = 4, avg_loss = 0.5761\n",
            "t = 5, avg_loss = 0.6387\n",
            "t = 6, avg_loss = 0.6504\n",
            "t = 7, avg_loss = 0.6355\n",
            "t = 8, avg_loss = 0.6918\n",
            "t = 9, avg_loss = 0.5602\n",
            "t = 10, avg_loss = 0.6191\n",
            "t = 11, avg_loss = 0.6197\n",
            "t = 12, avg_loss = 0.6391\n",
            "t = 13, avg_loss = 0.5438\n",
            "t = 14, avg_loss = 0.6031\n",
            "t = 15, avg_loss = 0.7016\n",
            "t = 16, avg_loss = 0.5337\n",
            "t = 17, avg_loss = 0.6627\n",
            "t = 18, avg_loss = 0.5935\n",
            "t = 19, avg_loss = 0.5691\n",
            "t = 20, avg_loss = 0.5956\n",
            "t = 21, avg_loss = 0.6184\n",
            "t = 22, avg_loss = 0.6543\n",
            "t = 23, avg_loss = 0.6344\n",
            "t = 24, avg_loss = 0.6578\n",
            "t = 25, avg_loss = 0.6571\n",
            "Checking accuracy on test set\n",
            "Got 260 / 400 correct (65.00)\n",
            "acc = 0.650000\n",
            "Starting epoch 11 / 50\n",
            "t = 1, avg_loss = 0.6643\n",
            "t = 2, avg_loss = 0.5895\n",
            "t = 3, avg_loss = 0.5639\n",
            "t = 4, avg_loss = 0.6375\n",
            "t = 5, avg_loss = 0.5583\n",
            "t = 6, avg_loss = 0.7209\n",
            "t = 7, avg_loss = 0.6089\n",
            "t = 8, avg_loss = 0.6047\n",
            "t = 9, avg_loss = 0.5884\n",
            "t = 10, avg_loss = 0.5400\n",
            "t = 11, avg_loss = 0.7149\n",
            "t = 12, avg_loss = 0.6100\n",
            "t = 13, avg_loss = 0.6651\n",
            "t = 14, avg_loss = 0.5788\n",
            "t = 15, avg_loss = 0.6097\n",
            "t = 16, avg_loss = 0.6335\n",
            "t = 17, avg_loss = 0.6381\n",
            "t = 18, avg_loss = 0.5699\n",
            "t = 19, avg_loss = 0.5341\n",
            "t = 20, avg_loss = 0.6410\n",
            "t = 21, avg_loss = 0.6460\n",
            "t = 22, avg_loss = 0.6141\n",
            "t = 23, avg_loss = 0.6252\n",
            "t = 24, avg_loss = 0.6144\n",
            "t = 25, avg_loss = 0.5895\n",
            "Checking accuracy on test set\n",
            "Got 265 / 400 correct (66.25)\n",
            "acc = 0.662500\n",
            "Starting epoch 12 / 50\n",
            "t = 1, avg_loss = 0.5970\n",
            "t = 2, avg_loss = 0.5056\n",
            "t = 3, avg_loss = 0.6515\n",
            "t = 4, avg_loss = 0.5800\n",
            "t = 5, avg_loss = 0.7190\n",
            "t = 6, avg_loss = 0.6745\n",
            "t = 7, avg_loss = 0.7198\n",
            "t = 8, avg_loss = 0.5455\n",
            "t = 9, avg_loss = 0.6666\n",
            "t = 10, avg_loss = 0.5968\n",
            "t = 11, avg_loss = 0.6062\n",
            "t = 12, avg_loss = 0.6408\n",
            "t = 13, avg_loss = 0.6440\n",
            "t = 14, avg_loss = 0.6612\n",
            "t = 15, avg_loss = 0.6922\n",
            "t = 16, avg_loss = 0.7439\n",
            "t = 17, avg_loss = 0.6199\n",
            "t = 18, avg_loss = 0.5305\n",
            "t = 19, avg_loss = 0.5513\n",
            "t = 20, avg_loss = 0.6425\n",
            "t = 21, avg_loss = 0.6454\n",
            "t = 22, avg_loss = 0.5771\n",
            "t = 23, avg_loss = 0.6135\n",
            "t = 24, avg_loss = 0.6400\n",
            "t = 25, avg_loss = 0.5387\n",
            "Checking accuracy on test set\n",
            "Got 257 / 400 correct (64.25)\n",
            "acc = 0.642500\n",
            "Starting epoch 13 / 50\n",
            "t = 1, avg_loss = 0.5233\n",
            "t = 2, avg_loss = 0.6242\n",
            "t = 3, avg_loss = 0.6326\n",
            "t = 4, avg_loss = 0.5578\n",
            "t = 5, avg_loss = 0.5905\n",
            "t = 6, avg_loss = 0.5289\n",
            "t = 7, avg_loss = 0.6371\n",
            "t = 8, avg_loss = 0.6604\n",
            "t = 9, avg_loss = 0.6298\n",
            "t = 10, avg_loss = 0.6282\n",
            "t = 11, avg_loss = 0.7045\n",
            "t = 12, avg_loss = 0.5851\n",
            "t = 13, avg_loss = 0.5708\n",
            "t = 14, avg_loss = 0.6044\n",
            "t = 15, avg_loss = 0.6354\n",
            "t = 16, avg_loss = 0.6165\n",
            "t = 17, avg_loss = 0.6038\n",
            "t = 18, avg_loss = 0.5905\n",
            "t = 19, avg_loss = 0.6417\n",
            "t = 20, avg_loss = 0.6502\n",
            "t = 21, avg_loss = 0.5507\n",
            "t = 22, avg_loss = 0.6205\n",
            "t = 23, avg_loss = 0.6186\n",
            "t = 24, avg_loss = 0.5737\n",
            "t = 25, avg_loss = 0.5820\n",
            "Checking accuracy on test set\n",
            "Got 267 / 400 correct (66.75)\n",
            "acc = 0.667500\n",
            "Starting epoch 14 / 50\n",
            "t = 1, avg_loss = 0.6677\n",
            "t = 2, avg_loss = 0.6516\n",
            "t = 3, avg_loss = 0.6073\n",
            "t = 4, avg_loss = 0.6367\n",
            "t = 5, avg_loss = 0.6013\n",
            "t = 6, avg_loss = 0.5713\n",
            "t = 7, avg_loss = 0.5857\n",
            "t = 8, avg_loss = 0.6123\n",
            "t = 9, avg_loss = 0.6038\n",
            "t = 10, avg_loss = 0.5208\n",
            "t = 11, avg_loss = 0.6716\n",
            "t = 12, avg_loss = 0.6235\n",
            "t = 13, avg_loss = 0.5482\n",
            "t = 14, avg_loss = 0.6358\n",
            "t = 15, avg_loss = 0.5315\n",
            "t = 16, avg_loss = 0.5905\n",
            "t = 17, avg_loss = 0.5978\n",
            "t = 18, avg_loss = 0.6124\n",
            "t = 19, avg_loss = 0.5618\n",
            "t = 20, avg_loss = 0.5694\n",
            "t = 21, avg_loss = 0.6165\n",
            "t = 22, avg_loss = 0.6413\n",
            "t = 23, avg_loss = 0.5857\n",
            "t = 24, avg_loss = 0.5820\n",
            "t = 25, avg_loss = 0.5120\n",
            "Checking accuracy on test set\n",
            "Got 279 / 400 correct (69.75)\n",
            "acc = 0.697500\n",
            "Starting epoch 15 / 50\n",
            "t = 1, avg_loss = 0.4883\n",
            "t = 2, avg_loss = 0.5155\n",
            "t = 3, avg_loss = 0.5946\n",
            "t = 4, avg_loss = 0.6221\n",
            "t = 5, avg_loss = 0.5969\n",
            "t = 6, avg_loss = 0.7152\n",
            "t = 7, avg_loss = 0.5976\n",
            "t = 8, avg_loss = 0.7577\n",
            "t = 9, avg_loss = 0.5630\n",
            "t = 10, avg_loss = 0.7093\n",
            "t = 11, avg_loss = 0.5640\n",
            "t = 12, avg_loss = 0.5908\n",
            "t = 13, avg_loss = 0.6122\n",
            "t = 14, avg_loss = 0.6050\n",
            "t = 15, avg_loss = 0.6072\n",
            "t = 16, avg_loss = 0.5774\n",
            "t = 17, avg_loss = 0.5717\n",
            "t = 18, avg_loss = 0.5745\n",
            "t = 19, avg_loss = 0.5991\n",
            "t = 20, avg_loss = 0.6081\n",
            "t = 21, avg_loss = 0.5885\n",
            "t = 22, avg_loss = 0.5872\n",
            "t = 23, avg_loss = 0.5516\n",
            "t = 24, avg_loss = 0.6050\n",
            "t = 25, avg_loss = 0.6413\n",
            "Checking accuracy on test set\n",
            "Got 280 / 400 correct (70.00)\n",
            "acc = 0.700000\n",
            "Starting epoch 16 / 50\n",
            "t = 1, avg_loss = 0.5726\n",
            "t = 2, avg_loss = 0.6311\n",
            "t = 3, avg_loss = 0.5813\n",
            "t = 4, avg_loss = 0.6636\n",
            "t = 5, avg_loss = 0.5740\n",
            "t = 6, avg_loss = 0.5462\n",
            "t = 7, avg_loss = 0.5757\n",
            "t = 8, avg_loss = 0.5058\n",
            "t = 9, avg_loss = 0.6835\n",
            "t = 10, avg_loss = 0.6291\n",
            "t = 11, avg_loss = 0.5251\n",
            "t = 12, avg_loss = 0.6430\n",
            "t = 13, avg_loss = 0.5809\n",
            "t = 14, avg_loss = 0.4850\n",
            "t = 15, avg_loss = 0.5754\n",
            "t = 16, avg_loss = 0.6111\n",
            "t = 17, avg_loss = 0.5807\n",
            "t = 18, avg_loss = 0.5487\n",
            "t = 19, avg_loss = 0.6284\n",
            "t = 20, avg_loss = 0.5692\n",
            "t = 21, avg_loss = 0.5110\n",
            "t = 22, avg_loss = 0.6679\n",
            "t = 23, avg_loss = 0.5595\n",
            "t = 24, avg_loss = 0.6025\n",
            "t = 25, avg_loss = 0.5326\n",
            "Checking accuracy on test set\n",
            "Got 285 / 400 correct (71.25)\n",
            "acc = 0.712500\n",
            "Starting epoch 17 / 50\n",
            "t = 1, avg_loss = 0.6312\n",
            "t = 2, avg_loss = 0.4956\n",
            "t = 3, avg_loss = 0.6224\n",
            "t = 4, avg_loss = 0.6159\n",
            "t = 5, avg_loss = 0.5854\n",
            "t = 6, avg_loss = 0.5543\n",
            "t = 7, avg_loss = 0.5544\n",
            "t = 8, avg_loss = 0.6228\n",
            "t = 9, avg_loss = 0.5841\n",
            "t = 10, avg_loss = 0.5302\n",
            "t = 11, avg_loss = 0.6134\n",
            "t = 12, avg_loss = 0.6554\n",
            "t = 13, avg_loss = 0.5555\n",
            "t = 14, avg_loss = 0.6030\n",
            "t = 15, avg_loss = 0.5728\n",
            "t = 16, avg_loss = 0.5597\n",
            "t = 17, avg_loss = 0.4780\n",
            "t = 18, avg_loss = 0.6139\n",
            "t = 19, avg_loss = 0.5611\n",
            "t = 20, avg_loss = 0.6588\n",
            "t = 21, avg_loss = 0.5283\n",
            "t = 22, avg_loss = 0.6688\n",
            "t = 23, avg_loss = 0.5559\n",
            "t = 24, avg_loss = 0.4927\n",
            "t = 25, avg_loss = 0.6432\n",
            "Checking accuracy on test set\n",
            "Got 272 / 400 correct (68.00)\n",
            "acc = 0.680000\n",
            "Starting epoch 18 / 50\n",
            "t = 1, avg_loss = 0.6210\n",
            "t = 2, avg_loss = 0.4995\n",
            "t = 3, avg_loss = 0.5463\n",
            "t = 4, avg_loss = 0.5700\n",
            "t = 5, avg_loss = 0.6186\n",
            "t = 6, avg_loss = 0.5659\n",
            "t = 7, avg_loss = 0.7044\n",
            "t = 8, avg_loss = 0.5623\n",
            "t = 9, avg_loss = 0.6098\n",
            "t = 10, avg_loss = 0.6838\n",
            "t = 11, avg_loss = 0.5766\n",
            "t = 12, avg_loss = 0.5951\n",
            "t = 13, avg_loss = 0.6456\n",
            "t = 14, avg_loss = 0.6064\n",
            "t = 15, avg_loss = 0.5551\n",
            "t = 16, avg_loss = 0.6164\n",
            "t = 17, avg_loss = 0.4987\n",
            "t = 18, avg_loss = 0.5332\n",
            "t = 19, avg_loss = 0.4537\n",
            "t = 20, avg_loss = 0.6670\n",
            "t = 21, avg_loss = 0.6477\n",
            "t = 22, avg_loss = 0.5263\n",
            "t = 23, avg_loss = 0.4397\n",
            "t = 24, avg_loss = 0.5140\n",
            "t = 25, avg_loss = 0.6747\n",
            "Checking accuracy on test set\n",
            "Got 286 / 400 correct (71.50)\n",
            "acc = 0.715000\n",
            "Starting epoch 19 / 50\n",
            "t = 1, avg_loss = 0.5493\n",
            "t = 2, avg_loss = 0.5609\n",
            "t = 3, avg_loss = 0.5505\n",
            "t = 4, avg_loss = 0.5874\n",
            "t = 5, avg_loss = 0.5724\n",
            "t = 6, avg_loss = 0.6165\n",
            "t = 7, avg_loss = 0.6225\n",
            "t = 8, avg_loss = 0.5430\n",
            "t = 9, avg_loss = 0.5348\n",
            "t = 10, avg_loss = 0.5326\n",
            "t = 11, avg_loss = 0.6380\n",
            "t = 12, avg_loss = 0.5940\n",
            "t = 13, avg_loss = 0.5189\n",
            "t = 14, avg_loss = 0.6347\n",
            "t = 15, avg_loss = 0.5613\n",
            "t = 16, avg_loss = 0.4792\n",
            "t = 17, avg_loss = 0.5736\n",
            "t = 18, avg_loss = 0.5370\n",
            "t = 19, avg_loss = 0.6144\n",
            "t = 20, avg_loss = 0.5241\n",
            "t = 21, avg_loss = 0.5649\n",
            "t = 22, avg_loss = 0.6590\n",
            "t = 23, avg_loss = 0.5846\n",
            "t = 24, avg_loss = 0.6799\n",
            "t = 25, avg_loss = 0.6008\n",
            "Checking accuracy on test set\n",
            "Got 289 / 400 correct (72.25)\n",
            "acc = 0.722500\n",
            "Starting epoch 20 / 50\n",
            "t = 1, avg_loss = 0.5974\n",
            "t = 2, avg_loss = 0.5708\n",
            "t = 3, avg_loss = 0.6374\n",
            "t = 4, avg_loss = 0.6359\n",
            "t = 5, avg_loss = 0.5907\n",
            "t = 6, avg_loss = 0.5767\n",
            "t = 7, avg_loss = 0.5867\n",
            "t = 8, avg_loss = 0.5267\n",
            "t = 9, avg_loss = 0.5681\n",
            "t = 10, avg_loss = 0.6626\n",
            "t = 11, avg_loss = 0.5297\n",
            "t = 12, avg_loss = 0.6490\n",
            "t = 13, avg_loss = 0.5923\n",
            "t = 14, avg_loss = 0.5514\n",
            "t = 15, avg_loss = 0.4977\n",
            "t = 16, avg_loss = 0.5422\n",
            "t = 17, avg_loss = 0.6074\n",
            "t = 18, avg_loss = 0.6257\n",
            "t = 19, avg_loss = 0.4587\n",
            "t = 20, avg_loss = 0.5305\n",
            "t = 21, avg_loss = 0.6329\n",
            "t = 22, avg_loss = 0.6588\n",
            "t = 23, avg_loss = 0.6120\n",
            "t = 24, avg_loss = 0.5706\n",
            "t = 25, avg_loss = 0.5088\n",
            "Checking accuracy on test set\n",
            "Got 272 / 400 correct (68.00)\n",
            "acc = 0.680000\n",
            "Starting epoch 21 / 50\n",
            "t = 1, avg_loss = 0.4601\n",
            "t = 2, avg_loss = 0.6444\n",
            "t = 3, avg_loss = 0.6194\n",
            "t = 4, avg_loss = 0.5512\n",
            "t = 5, avg_loss = 0.6018\n",
            "t = 6, avg_loss = 0.6305\n",
            "t = 7, avg_loss = 0.5433\n",
            "t = 8, avg_loss = 0.5874\n",
            "t = 9, avg_loss = 0.4978\n",
            "t = 10, avg_loss = 0.5262\n",
            "t = 11, avg_loss = 0.6232\n",
            "t = 12, avg_loss = 0.5421\n",
            "t = 13, avg_loss = 0.6635\n",
            "t = 14, avg_loss = 0.5398\n",
            "t = 15, avg_loss = 0.5919\n",
            "t = 16, avg_loss = 0.5627\n",
            "t = 17, avg_loss = 0.5640\n",
            "t = 18, avg_loss = 0.6862\n",
            "t = 19, avg_loss = 0.5310\n",
            "t = 20, avg_loss = 0.5195\n",
            "t = 21, avg_loss = 0.6422\n",
            "t = 22, avg_loss = 0.6355\n",
            "t = 23, avg_loss = 0.4643\n",
            "t = 24, avg_loss = 0.8132\n",
            "t = 25, avg_loss = 0.5407\n",
            "Checking accuracy on test set\n",
            "Got 279 / 400 correct (69.75)\n",
            "acc = 0.697500\n",
            "Starting epoch 22 / 50\n",
            "t = 1, avg_loss = 0.5683\n",
            "t = 2, avg_loss = 0.6007\n",
            "t = 3, avg_loss = 0.5999\n",
            "t = 4, avg_loss = 0.4991\n",
            "t = 5, avg_loss = 0.5668\n",
            "t = 6, avg_loss = 0.6668\n",
            "t = 7, avg_loss = 0.5302\n",
            "t = 8, avg_loss = 0.5954\n",
            "t = 9, avg_loss = 0.4925\n",
            "t = 10, avg_loss = 0.5713\n",
            "t = 11, avg_loss = 0.6000\n",
            "t = 12, avg_loss = 0.5941\n",
            "t = 13, avg_loss = 0.5943\n",
            "t = 14, avg_loss = 0.5229\n",
            "t = 15, avg_loss = 0.5071\n",
            "t = 16, avg_loss = 0.6163\n",
            "t = 17, avg_loss = 0.5569\n",
            "t = 18, avg_loss = 0.5268\n",
            "t = 19, avg_loss = 0.5618\n",
            "t = 20, avg_loss = 0.5487\n",
            "t = 21, avg_loss = 0.4564\n",
            "t = 22, avg_loss = 0.5749\n",
            "t = 23, avg_loss = 0.5268\n",
            "t = 24, avg_loss = 0.5436\n",
            "t = 25, avg_loss = 0.5767\n",
            "Checking accuracy on test set\n",
            "Got 293 / 400 correct (73.25)\n",
            "acc = 0.732500\n",
            "Starting epoch 23 / 50\n",
            "t = 1, avg_loss = 0.4979\n",
            "t = 2, avg_loss = 0.6085\n",
            "t = 3, avg_loss = 0.5718\n",
            "t = 4, avg_loss = 0.6210\n",
            "t = 5, avg_loss = 0.5350\n",
            "t = 6, avg_loss = 0.5078\n",
            "t = 7, avg_loss = 0.5406\n",
            "t = 8, avg_loss = 0.5801\n",
            "t = 9, avg_loss = 0.4887\n",
            "t = 10, avg_loss = 0.5610\n",
            "t = 11, avg_loss = 0.5682\n",
            "t = 12, avg_loss = 0.5445\n",
            "t = 13, avg_loss = 0.5530\n",
            "t = 14, avg_loss = 0.5493\n",
            "t = 15, avg_loss = 0.5286\n",
            "t = 16, avg_loss = 0.6697\n",
            "t = 17, avg_loss = 0.6155\n",
            "t = 18, avg_loss = 0.5461\n",
            "t = 19, avg_loss = 0.6299\n",
            "t = 20, avg_loss = 0.6019\n",
            "t = 21, avg_loss = 0.6038\n",
            "t = 22, avg_loss = 0.5318\n",
            "t = 23, avg_loss = 0.6527\n",
            "t = 24, avg_loss = 0.4886\n",
            "t = 25, avg_loss = 0.5325\n",
            "Checking accuracy on test set\n",
            "Got 291 / 400 correct (72.75)\n",
            "acc = 0.727500\n",
            "Starting epoch 24 / 50\n",
            "t = 1, avg_loss = 0.5620\n",
            "t = 2, avg_loss = 0.4827\n",
            "t = 3, avg_loss = 0.5427\n",
            "t = 4, avg_loss = 0.5240\n",
            "t = 5, avg_loss = 0.5853\n",
            "t = 6, avg_loss = 0.6548\n",
            "t = 7, avg_loss = 0.6871\n",
            "t = 8, avg_loss = 0.6817\n",
            "t = 9, avg_loss = 0.6085\n",
            "t = 10, avg_loss = 0.5313\n",
            "t = 11, avg_loss = 0.5337\n",
            "t = 12, avg_loss = 0.5355\n",
            "t = 13, avg_loss = 0.5133\n",
            "t = 14, avg_loss = 0.7457\n",
            "t = 15, avg_loss = 0.5925\n",
            "t = 16, avg_loss = 0.5514\n",
            "t = 17, avg_loss = 0.5106\n",
            "t = 18, avg_loss = 0.5694\n",
            "t = 19, avg_loss = 0.5477\n",
            "t = 20, avg_loss = 0.5165\n",
            "t = 21, avg_loss = 0.4705\n",
            "t = 22, avg_loss = 0.6449\n",
            "t = 23, avg_loss = 0.6448\n",
            "t = 24, avg_loss = 0.5885\n",
            "t = 25, avg_loss = 0.4965\n",
            "Checking accuracy on test set\n",
            "Got 251 / 400 correct (62.75)\n",
            "acc = 0.627500\n",
            "Starting epoch 25 / 50\n",
            "t = 1, avg_loss = 0.6546\n",
            "t = 2, avg_loss = 0.5234\n",
            "t = 3, avg_loss = 0.5292\n",
            "t = 4, avg_loss = 0.4767\n",
            "t = 5, avg_loss = 0.6284\n",
            "t = 6, avg_loss = 0.5620\n",
            "t = 7, avg_loss = 0.4845\n",
            "t = 8, avg_loss = 0.6041\n",
            "t = 9, avg_loss = 0.5796\n",
            "t = 10, avg_loss = 0.5439\n",
            "t = 11, avg_loss = 0.5504\n",
            "t = 12, avg_loss = 0.5184\n",
            "t = 13, avg_loss = 0.4689\n",
            "t = 14, avg_loss = 0.5738\n",
            "t = 15, avg_loss = 0.6610\n",
            "t = 16, avg_loss = 0.5965\n",
            "t = 17, avg_loss = 0.4940\n",
            "t = 18, avg_loss = 0.5477\n",
            "t = 19, avg_loss = 0.5282\n",
            "t = 20, avg_loss = 0.6436\n",
            "t = 21, avg_loss = 0.6188\n",
            "t = 22, avg_loss = 0.5908\n",
            "t = 23, avg_loss = 0.6250\n",
            "t = 24, avg_loss = 0.5069\n",
            "t = 25, avg_loss = 0.5878\n",
            "Checking accuracy on test set\n",
            "Got 285 / 400 correct (71.25)\n",
            "acc = 0.712500\n",
            "Starting epoch 26 / 50\n",
            "t = 1, avg_loss = 0.4962\n",
            "t = 2, avg_loss = 0.5424\n",
            "t = 3, avg_loss = 0.5364\n",
            "t = 4, avg_loss = 0.4814\n",
            "t = 5, avg_loss = 0.5227\n",
            "t = 6, avg_loss = 0.6254\n",
            "t = 7, avg_loss = 0.5023\n",
            "t = 8, avg_loss = 0.5071\n",
            "t = 9, avg_loss = 0.7301\n",
            "t = 10, avg_loss = 0.4920\n",
            "t = 11, avg_loss = 0.5319\n",
            "t = 12, avg_loss = 0.6829\n",
            "t = 13, avg_loss = 0.4930\n",
            "t = 14, avg_loss = 0.5457\n",
            "t = 15, avg_loss = 0.6758\n",
            "t = 16, avg_loss = 0.5687\n",
            "t = 17, avg_loss = 0.6095\n",
            "t = 18, avg_loss = 0.5462\n",
            "t = 19, avg_loss = 0.5167\n",
            "t = 20, avg_loss = 0.5142\n",
            "t = 21, avg_loss = 0.5905\n",
            "t = 22, avg_loss = 0.6849\n",
            "t = 23, avg_loss = 0.5700\n",
            "t = 24, avg_loss = 0.4917\n",
            "t = 25, avg_loss = 0.5326\n",
            "Checking accuracy on test set\n",
            "Got 291 / 400 correct (72.75)\n",
            "acc = 0.727500\n",
            "Starting epoch 27 / 50\n",
            "t = 1, avg_loss = 0.4667\n",
            "t = 2, avg_loss = 0.5016\n",
            "t = 3, avg_loss = 0.5503\n",
            "t = 4, avg_loss = 0.5127\n",
            "t = 5, avg_loss = 0.6159\n",
            "t = 6, avg_loss = 0.5420\n",
            "t = 7, avg_loss = 0.5500\n",
            "t = 8, avg_loss = 0.5194\n",
            "t = 9, avg_loss = 0.6590\n",
            "t = 10, avg_loss = 0.4494\n",
            "t = 11, avg_loss = 0.4667\n",
            "t = 12, avg_loss = 0.5454\n",
            "t = 13, avg_loss = 0.6380\n",
            "t = 14, avg_loss = 0.5653\n",
            "t = 15, avg_loss = 0.5898\n",
            "t = 16, avg_loss = 0.5535\n",
            "t = 17, avg_loss = 0.5141\n",
            "t = 18, avg_loss = 0.5098\n",
            "t = 19, avg_loss = 0.5378\n",
            "t = 20, avg_loss = 0.6118\n",
            "t = 21, avg_loss = 0.5842\n",
            "t = 22, avg_loss = 0.6974\n",
            "t = 23, avg_loss = 0.5843\n",
            "t = 24, avg_loss = 0.5440\n",
            "t = 25, avg_loss = 0.6958\n",
            "Checking accuracy on test set\n",
            "Got 276 / 400 correct (69.00)\n",
            "acc = 0.690000\n",
            "Starting epoch 28 / 50\n",
            "t = 1, avg_loss = 0.5702\n",
            "t = 2, avg_loss = 0.6303\n",
            "t = 3, avg_loss = 0.6704\n",
            "t = 4, avg_loss = 0.5989\n",
            "t = 5, avg_loss = 0.5261\n",
            "t = 6, avg_loss = 0.5522\n",
            "t = 7, avg_loss = 0.4831\n",
            "t = 8, avg_loss = 0.5220\n",
            "t = 9, avg_loss = 0.7918\n",
            "t = 10, avg_loss = 0.6088\n",
            "t = 11, avg_loss = 0.5215\n",
            "t = 12, avg_loss = 0.5623\n",
            "t = 13, avg_loss = 0.6465\n",
            "t = 14, avg_loss = 0.4663\n",
            "t = 15, avg_loss = 0.5605\n",
            "t = 16, avg_loss = 0.5827\n",
            "t = 17, avg_loss = 0.5786\n",
            "t = 18, avg_loss = 0.4738\n",
            "t = 19, avg_loss = 0.5464\n",
            "t = 20, avg_loss = 0.5343\n",
            "t = 21, avg_loss = 0.5255\n",
            "t = 22, avg_loss = 0.5031\n",
            "t = 23, avg_loss = 0.4938\n",
            "t = 24, avg_loss = 0.6473\n",
            "t = 25, avg_loss = 0.4871\n",
            "Checking accuracy on test set\n",
            "Got 284 / 400 correct (71.00)\n",
            "acc = 0.710000\n",
            "Starting epoch 29 / 50\n",
            "t = 1, avg_loss = 0.4770\n",
            "t = 2, avg_loss = 0.4375\n",
            "t = 3, avg_loss = 0.5049\n",
            "t = 4, avg_loss = 0.4935\n",
            "t = 5, avg_loss = 0.6411\n",
            "t = 6, avg_loss = 0.5035\n",
            "t = 7, avg_loss = 0.5266\n",
            "t = 8, avg_loss = 0.5400\n",
            "t = 9, avg_loss = 0.4688\n",
            "t = 10, avg_loss = 0.4638\n",
            "t = 11, avg_loss = 0.5337\n",
            "t = 12, avg_loss = 0.7309\n",
            "t = 13, avg_loss = 0.5289\n",
            "t = 14, avg_loss = 0.6390\n",
            "t = 15, avg_loss = 0.6755\n",
            "t = 16, avg_loss = 0.5933\n",
            "t = 17, avg_loss = 0.5770\n",
            "t = 18, avg_loss = 0.5107\n",
            "t = 19, avg_loss = 0.4729\n",
            "t = 20, avg_loss = 0.7596\n",
            "t = 21, avg_loss = 0.5375\n",
            "t = 22, avg_loss = 0.4997\n",
            "t = 23, avg_loss = 0.5061\n",
            "t = 24, avg_loss = 0.5735\n",
            "t = 25, avg_loss = 0.5843\n",
            "Checking accuracy on test set\n",
            "Got 283 / 400 correct (70.75)\n",
            "acc = 0.707500\n",
            "Starting epoch 30 / 50\n",
            "t = 1, avg_loss = 0.5327\n",
            "t = 2, avg_loss = 0.5651\n",
            "t = 3, avg_loss = 0.5150\n",
            "t = 4, avg_loss = 0.5949\n",
            "t = 5, avg_loss = 0.5408\n",
            "t = 6, avg_loss = 0.6229\n",
            "t = 7, avg_loss = 0.5762\n",
            "t = 8, avg_loss = 0.5155\n",
            "t = 9, avg_loss = 0.6547\n",
            "t = 10, avg_loss = 0.5674\n",
            "t = 11, avg_loss = 0.5197\n",
            "t = 12, avg_loss = 0.5810\n",
            "t = 13, avg_loss = 0.5336\n",
            "t = 14, avg_loss = 0.5766\n",
            "t = 15, avg_loss = 0.6411\n",
            "t = 16, avg_loss = 0.6453\n",
            "t = 17, avg_loss = 0.6652\n",
            "t = 18, avg_loss = 0.5283\n",
            "t = 19, avg_loss = 0.5561\n",
            "t = 20, avg_loss = 0.5148\n",
            "t = 21, avg_loss = 0.5026\n",
            "t = 22, avg_loss = 0.5604\n",
            "t = 23, avg_loss = 0.4953\n",
            "t = 24, avg_loss = 0.6307\n",
            "t = 25, avg_loss = 0.4620\n",
            "Checking accuracy on test set\n",
            "Got 280 / 400 correct (70.00)\n",
            "acc = 0.700000\n",
            "Starting epoch 31 / 50\n",
            "t = 1, avg_loss = 0.4939\n",
            "t = 2, avg_loss = 0.4936\n",
            "t = 3, avg_loss = 0.5470\n",
            "t = 4, avg_loss = 0.5441\n",
            "t = 5, avg_loss = 0.5955\n",
            "t = 6, avg_loss = 0.5942\n",
            "t = 7, avg_loss = 0.5360\n",
            "t = 8, avg_loss = 0.5939\n",
            "t = 9, avg_loss = 0.5151\n",
            "t = 10, avg_loss = 0.5230\n",
            "t = 11, avg_loss = 0.4631\n",
            "t = 12, avg_loss = 0.6187\n",
            "t = 13, avg_loss = 0.5516\n",
            "t = 14, avg_loss = 0.4905\n",
            "t = 15, avg_loss = 0.5017\n",
            "t = 16, avg_loss = 0.5247\n",
            "t = 17, avg_loss = 0.5130\n",
            "t = 18, avg_loss = 0.5007\n",
            "t = 19, avg_loss = 0.4234\n",
            "t = 20, avg_loss = 0.7757\n",
            "t = 21, avg_loss = 0.6467\n",
            "t = 22, avg_loss = 0.4790\n",
            "t = 23, avg_loss = 0.5466\n",
            "t = 24, avg_loss = 0.5886\n",
            "t = 25, avg_loss = 0.5674\n",
            "Checking accuracy on test set\n",
            "Got 276 / 400 correct (69.00)\n",
            "acc = 0.690000\n",
            "Starting epoch 32 / 50\n",
            "t = 1, avg_loss = 0.5189\n",
            "t = 2, avg_loss = 0.5611\n",
            "t = 3, avg_loss = 0.4468\n",
            "t = 4, avg_loss = 0.6413\n",
            "t = 5, avg_loss = 0.5744\n",
            "t = 6, avg_loss = 0.6129\n",
            "t = 7, avg_loss = 0.5900\n",
            "t = 8, avg_loss = 0.5019\n",
            "t = 9, avg_loss = 0.5418\n",
            "t = 10, avg_loss = 0.5295\n",
            "t = 11, avg_loss = 0.5363\n",
            "t = 12, avg_loss = 0.5324\n",
            "t = 13, avg_loss = 0.5995\n",
            "t = 14, avg_loss = 0.4886\n",
            "t = 15, avg_loss = 0.6175\n",
            "t = 16, avg_loss = 0.4405\n",
            "t = 17, avg_loss = 0.6665\n",
            "t = 18, avg_loss = 0.4776\n",
            "t = 19, avg_loss = 0.5849\n",
            "t = 20, avg_loss = 0.5470\n",
            "t = 21, avg_loss = 0.5076\n",
            "t = 22, avg_loss = 0.5935\n",
            "t = 23, avg_loss = 0.5898\n",
            "t = 24, avg_loss = 0.6003\n",
            "t = 25, avg_loss = 0.5696\n",
            "Checking accuracy on test set\n",
            "Got 287 / 400 correct (71.75)\n",
            "acc = 0.717500\n",
            "Starting epoch 33 / 50\n",
            "t = 1, avg_loss = 0.6005\n",
            "t = 2, avg_loss = 0.5094\n",
            "t = 3, avg_loss = 0.5543\n",
            "t = 4, avg_loss = 0.5273\n",
            "t = 5, avg_loss = 0.5578\n",
            "t = 6, avg_loss = 0.5144\n",
            "t = 7, avg_loss = 0.5712\n",
            "t = 8, avg_loss = 0.5738\n",
            "t = 9, avg_loss = 0.6483\n",
            "t = 10, avg_loss = 0.4290\n",
            "t = 11, avg_loss = 0.5362\n",
            "t = 12, avg_loss = 0.5653\n",
            "t = 13, avg_loss = 0.5000\n",
            "t = 14, avg_loss = 0.6179\n",
            "t = 15, avg_loss = 0.4897\n",
            "t = 16, avg_loss = 0.6527\n",
            "t = 17, avg_loss = 0.6068\n",
            "t = 18, avg_loss = 0.5361\n",
            "t = 19, avg_loss = 0.4271\n",
            "t = 20, avg_loss = 0.5860\n",
            "t = 21, avg_loss = 0.5693\n",
            "t = 22, avg_loss = 0.5479\n",
            "t = 23, avg_loss = 0.5575\n",
            "t = 24, avg_loss = 0.4800\n",
            "t = 25, avg_loss = 0.4822\n",
            "Checking accuracy on test set\n",
            "Got 296 / 400 correct (74.00)\n",
            "acc = 0.740000\n",
            "Starting epoch 34 / 50\n",
            "t = 1, avg_loss = 0.5499\n",
            "t = 2, avg_loss = 0.4476\n",
            "t = 3, avg_loss = 0.5237\n",
            "t = 4, avg_loss = 0.5968\n",
            "t = 5, avg_loss = 0.6227\n",
            "t = 6, avg_loss = 0.6298\n",
            "t = 7, avg_loss = 0.5347\n",
            "t = 8, avg_loss = 0.6013\n",
            "t = 9, avg_loss = 0.5208\n",
            "t = 10, avg_loss = 0.6156\n",
            "t = 11, avg_loss = 0.5253\n",
            "t = 12, avg_loss = 0.5055\n",
            "t = 13, avg_loss = 0.5751\n",
            "t = 14, avg_loss = 0.5496\n",
            "t = 15, avg_loss = 0.4796\n",
            "t = 16, avg_loss = 0.4937\n",
            "t = 17, avg_loss = 0.4123\n",
            "t = 18, avg_loss = 0.6450\n",
            "t = 19, avg_loss = 0.6137\n",
            "t = 20, avg_loss = 0.5481\n",
            "t = 21, avg_loss = 0.6075\n",
            "t = 22, avg_loss = 0.5580\n",
            "t = 23, avg_loss = 0.5328\n",
            "t = 24, avg_loss = 0.4998\n",
            "t = 25, avg_loss = 0.5159\n",
            "Checking accuracy on test set\n",
            "Got 297 / 400 correct (74.25)\n",
            "acc = 0.742500\n",
            "Starting epoch 35 / 50\n",
            "t = 1, avg_loss = 0.4420\n",
            "t = 2, avg_loss = 0.5747\n",
            "t = 3, avg_loss = 0.4859\n",
            "t = 4, avg_loss = 0.4395\n",
            "t = 5, avg_loss = 0.4798\n",
            "t = 6, avg_loss = 0.5147\n",
            "t = 7, avg_loss = 0.6028\n",
            "t = 8, avg_loss = 0.6346\n",
            "t = 9, avg_loss = 0.7690\n",
            "t = 10, avg_loss = 0.6119\n",
            "t = 11, avg_loss = 0.5258\n",
            "t = 12, avg_loss = 0.3836\n",
            "t = 13, avg_loss = 0.5332\n",
            "t = 14, avg_loss = 0.5125\n",
            "t = 15, avg_loss = 0.7040\n",
            "t = 16, avg_loss = 0.5960\n",
            "t = 17, avg_loss = 0.6498\n",
            "t = 18, avg_loss = 0.5412\n",
            "t = 19, avg_loss = 0.5228\n",
            "t = 20, avg_loss = 0.5993\n",
            "t = 21, avg_loss = 0.5091\n",
            "t = 22, avg_loss = 0.6213\n",
            "t = 23, avg_loss = 0.5490\n",
            "t = 24, avg_loss = 0.5175\n",
            "t = 25, avg_loss = 0.5436\n",
            "Checking accuracy on test set\n",
            "Got 294 / 400 correct (73.50)\n",
            "acc = 0.735000\n",
            "Starting epoch 36 / 50\n",
            "t = 1, avg_loss = 0.5058\n",
            "t = 2, avg_loss = 0.6777\n",
            "t = 3, avg_loss = 0.5659\n",
            "t = 4, avg_loss = 0.4559\n",
            "t = 5, avg_loss = 0.5996\n",
            "t = 6, avg_loss = 0.5681\n",
            "t = 7, avg_loss = 0.5352\n",
            "t = 8, avg_loss = 0.5907\n",
            "t = 9, avg_loss = 0.5031\n",
            "t = 10, avg_loss = 0.4769\n",
            "t = 11, avg_loss = 0.5236\n",
            "t = 12, avg_loss = 0.6148\n",
            "t = 13, avg_loss = 0.4616\n",
            "t = 14, avg_loss = 0.5802\n",
            "t = 15, avg_loss = 0.5438\n",
            "t = 16, avg_loss = 0.4455\n",
            "t = 17, avg_loss = 0.5050\n",
            "t = 18, avg_loss = 0.4596\n",
            "t = 19, avg_loss = 0.5870\n",
            "t = 20, avg_loss = 0.4999\n",
            "t = 21, avg_loss = 0.5079\n",
            "t = 22, avg_loss = 0.4786\n",
            "t = 23, avg_loss = 0.5486\n",
            "t = 24, avg_loss = 0.5688\n",
            "t = 25, avg_loss = 0.5104\n",
            "Checking accuracy on test set\n",
            "Got 306 / 400 correct (76.50)\n",
            "acc = 0.765000\n",
            "Starting epoch 37 / 50\n",
            "t = 1, avg_loss = 0.5713\n",
            "t = 2, avg_loss = 0.5237\n",
            "t = 3, avg_loss = 0.4609\n",
            "t = 4, avg_loss = 0.5495\n",
            "t = 5, avg_loss = 0.4849\n",
            "t = 6, avg_loss = 0.5088\n",
            "t = 7, avg_loss = 0.4879\n",
            "t = 8, avg_loss = 0.5232\n",
            "t = 9, avg_loss = 0.5755\n",
            "t = 10, avg_loss = 0.4373\n",
            "t = 11, avg_loss = 0.5690\n",
            "t = 12, avg_loss = 0.7198\n",
            "t = 13, avg_loss = 0.5997\n",
            "t = 14, avg_loss = 0.5669\n",
            "t = 15, avg_loss = 0.4713\n",
            "t = 16, avg_loss = 0.5550\n",
            "t = 17, avg_loss = 0.5731\n",
            "t = 18, avg_loss = 0.5317\n",
            "t = 19, avg_loss = 0.5997\n",
            "t = 20, avg_loss = 0.5007\n",
            "t = 21, avg_loss = 0.5890\n",
            "t = 22, avg_loss = 0.5433\n",
            "t = 23, avg_loss = 0.5542\n",
            "t = 24, avg_loss = 0.5414\n",
            "t = 25, avg_loss = 0.5459\n",
            "Checking accuracy on test set\n",
            "Got 294 / 400 correct (73.50)\n",
            "acc = 0.735000\n",
            "Starting epoch 38 / 50\n",
            "t = 1, avg_loss = 0.4828\n",
            "t = 2, avg_loss = 0.5032\n",
            "t = 3, avg_loss = 0.5470\n",
            "t = 4, avg_loss = 0.6649\n",
            "t = 5, avg_loss = 0.5698\n",
            "t = 6, avg_loss = 0.6444\n",
            "t = 7, avg_loss = 0.5415\n",
            "t = 8, avg_loss = 0.4275\n",
            "t = 9, avg_loss = 0.4506\n",
            "t = 10, avg_loss = 0.5258\n",
            "t = 11, avg_loss = 0.4283\n",
            "t = 12, avg_loss = 0.5449\n",
            "t = 13, avg_loss = 0.4731\n",
            "t = 14, avg_loss = 0.4537\n",
            "t = 15, avg_loss = 0.5519\n",
            "t = 16, avg_loss = 0.4903\n",
            "t = 17, avg_loss = 0.6586\n",
            "t = 18, avg_loss = 0.5926\n",
            "t = 19, avg_loss = 0.5603\n",
            "t = 20, avg_loss = 0.5488\n",
            "t = 21, avg_loss = 0.4453\n",
            "t = 22, avg_loss = 0.5218\n",
            "t = 23, avg_loss = 0.5019\n",
            "t = 24, avg_loss = 0.5359\n",
            "t = 25, avg_loss = 0.5929\n",
            "Checking accuracy on test set\n",
            "Got 302 / 400 correct (75.50)\n",
            "acc = 0.755000\n",
            "Starting epoch 39 / 50\n",
            "t = 1, avg_loss = 0.4735\n",
            "t = 2, avg_loss = 0.5335\n",
            "t = 3, avg_loss = 0.5100\n",
            "t = 4, avg_loss = 0.4646\n",
            "t = 5, avg_loss = 0.5844\n",
            "t = 6, avg_loss = 0.6500\n",
            "t = 7, avg_loss = 0.4506\n",
            "t = 8, avg_loss = 0.4759\n",
            "t = 9, avg_loss = 0.5590\n",
            "t = 10, avg_loss = 0.6560\n",
            "t = 11, avg_loss = 0.4553\n",
            "t = 12, avg_loss = 0.4807\n",
            "t = 13, avg_loss = 0.5351\n",
            "t = 14, avg_loss = 0.5058\n",
            "t = 15, avg_loss = 0.5823\n",
            "t = 16, avg_loss = 0.5052\n",
            "t = 17, avg_loss = 0.5194\n",
            "t = 18, avg_loss = 0.4964\n",
            "t = 19, avg_loss = 0.4902\n",
            "t = 20, avg_loss = 0.5405\n",
            "t = 21, avg_loss = 0.7267\n",
            "t = 22, avg_loss = 0.6162\n",
            "t = 23, avg_loss = 0.5379\n",
            "t = 24, avg_loss = 0.4409\n",
            "t = 25, avg_loss = 0.5594\n",
            "Checking accuracy on test set\n",
            "Got 288 / 400 correct (72.00)\n",
            "acc = 0.720000\n",
            "Starting epoch 40 / 50\n",
            "t = 1, avg_loss = 0.5128\n",
            "t = 2, avg_loss = 0.5170\n",
            "t = 3, avg_loss = 0.4041\n",
            "t = 4, avg_loss = 0.5404\n",
            "t = 5, avg_loss = 0.4145\n",
            "t = 6, avg_loss = 0.5203\n",
            "t = 7, avg_loss = 0.6006\n",
            "t = 8, avg_loss = 0.5385\n",
            "t = 9, avg_loss = 0.4402\n",
            "t = 10, avg_loss = 0.5883\n",
            "t = 11, avg_loss = 0.3994\n",
            "t = 12, avg_loss = 0.6173\n",
            "t = 13, avg_loss = 0.5149\n",
            "t = 14, avg_loss = 0.4764\n",
            "t = 15, avg_loss = 0.7232\n",
            "t = 16, avg_loss = 0.4529\n",
            "t = 17, avg_loss = 0.5136\n",
            "t = 18, avg_loss = 0.5012\n",
            "t = 19, avg_loss = 0.4607\n",
            "t = 20, avg_loss = 0.4947\n",
            "t = 21, avg_loss = 0.4134\n",
            "t = 22, avg_loss = 0.6241\n",
            "t = 23, avg_loss = 0.4976\n",
            "t = 24, avg_loss = 0.5689\n",
            "t = 25, avg_loss = 0.4614\n",
            "Checking accuracy on test set\n",
            "Got 296 / 400 correct (74.00)\n",
            "acc = 0.740000\n",
            "Starting epoch 41 / 50\n",
            "t = 1, avg_loss = 0.5119\n",
            "t = 2, avg_loss = 0.5262\n",
            "t = 3, avg_loss = 0.5070\n",
            "t = 4, avg_loss = 0.5163\n",
            "t = 5, avg_loss = 0.5068\n",
            "t = 6, avg_loss = 0.6069\n",
            "t = 7, avg_loss = 0.4380\n",
            "t = 8, avg_loss = 0.5131\n",
            "t = 9, avg_loss = 0.5960\n",
            "t = 10, avg_loss = 0.6692\n",
            "t = 11, avg_loss = 0.4777\n",
            "t = 12, avg_loss = 0.4490\n",
            "t = 13, avg_loss = 0.5834\n",
            "t = 14, avg_loss = 0.5959\n",
            "t = 15, avg_loss = 0.5714\n",
            "t = 16, avg_loss = 0.5382\n",
            "t = 17, avg_loss = 0.7318\n",
            "t = 18, avg_loss = 0.5711\n",
            "t = 19, avg_loss = 0.5238\n",
            "t = 20, avg_loss = 0.5696\n",
            "t = 21, avg_loss = 0.5530\n",
            "t = 22, avg_loss = 0.5478\n",
            "t = 23, avg_loss = 0.5297\n",
            "t = 24, avg_loss = 0.5953\n",
            "t = 25, avg_loss = 0.6690\n",
            "Checking accuracy on test set\n",
            "Got 265 / 400 correct (66.25)\n",
            "acc = 0.662500\n",
            "Starting epoch 42 / 50\n",
            "t = 1, avg_loss = 0.5658\n",
            "t = 2, avg_loss = 0.5221\n",
            "t = 3, avg_loss = 0.5433\n",
            "t = 4, avg_loss = 0.5705\n",
            "t = 5, avg_loss = 0.5345\n",
            "t = 6, avg_loss = 0.6373\n",
            "t = 7, avg_loss = 0.5643\n",
            "t = 8, avg_loss = 0.6451\n",
            "t = 9, avg_loss = 0.5707\n",
            "t = 10, avg_loss = 0.5551\n",
            "t = 11, avg_loss = 0.5864\n",
            "t = 12, avg_loss = 0.5466\n",
            "t = 13, avg_loss = 0.5431\n",
            "t = 14, avg_loss = 0.6065\n",
            "t = 15, avg_loss = 0.6153\n",
            "t = 16, avg_loss = 0.4776\n",
            "t = 17, avg_loss = 0.4834\n",
            "t = 18, avg_loss = 0.4102\n",
            "t = 19, avg_loss = 0.5404\n",
            "t = 20, avg_loss = 0.5095\n",
            "t = 21, avg_loss = 0.5133\n",
            "t = 22, avg_loss = 0.5376\n",
            "t = 23, avg_loss = 0.6088\n",
            "t = 24, avg_loss = 0.3975\n",
            "t = 25, avg_loss = 0.5666\n",
            "Checking accuracy on test set\n",
            "Got 282 / 400 correct (70.50)\n",
            "acc = 0.705000\n",
            "Starting epoch 43 / 50\n",
            "t = 1, avg_loss = 0.4128\n",
            "t = 2, avg_loss = 0.5920\n",
            "t = 3, avg_loss = 0.6033\n",
            "t = 4, avg_loss = 0.5286\n",
            "t = 5, avg_loss = 0.6351\n",
            "t = 6, avg_loss = 0.5700\n",
            "t = 7, avg_loss = 0.4417\n",
            "t = 8, avg_loss = 0.5678\n",
            "t = 9, avg_loss = 0.5155\n",
            "t = 10, avg_loss = 0.5704\n",
            "t = 11, avg_loss = 0.5249\n",
            "t = 12, avg_loss = 0.4645\n",
            "t = 13, avg_loss = 0.4799\n",
            "t = 14, avg_loss = 0.4951\n",
            "t = 15, avg_loss = 0.6809\n",
            "t = 16, avg_loss = 0.6043\n",
            "t = 17, avg_loss = 0.3997\n",
            "t = 18, avg_loss = 0.4389\n",
            "t = 19, avg_loss = 0.5493\n",
            "t = 20, avg_loss = 0.5432\n",
            "t = 21, avg_loss = 0.5677\n",
            "t = 22, avg_loss = 0.4722\n",
            "t = 23, avg_loss = 0.5633\n",
            "t = 24, avg_loss = 0.5512\n",
            "t = 25, avg_loss = 0.5626\n",
            "Checking accuracy on test set\n",
            "Got 294 / 400 correct (73.50)\n",
            "acc = 0.735000\n",
            "Starting epoch 44 / 50\n",
            "t = 1, avg_loss = 0.5704\n",
            "t = 2, avg_loss = 0.6152\n",
            "t = 3, avg_loss = 0.5053\n",
            "t = 4, avg_loss = 0.5155\n",
            "t = 5, avg_loss = 0.5240\n",
            "t = 6, avg_loss = 0.5171\n",
            "t = 7, avg_loss = 0.5288\n",
            "t = 8, avg_loss = 0.5638\n",
            "t = 9, avg_loss = 0.6840\n",
            "t = 10, avg_loss = 0.6938\n",
            "t = 11, avg_loss = 0.4789\n",
            "t = 12, avg_loss = 0.6297\n",
            "t = 13, avg_loss = 0.5002\n",
            "t = 14, avg_loss = 0.4324\n",
            "t = 15, avg_loss = 0.5146\n",
            "t = 16, avg_loss = 0.5242\n",
            "t = 17, avg_loss = 0.5416\n",
            "t = 18, avg_loss = 0.5023\n",
            "t = 19, avg_loss = 0.4933\n",
            "t = 20, avg_loss = 0.5176\n",
            "t = 21, avg_loss = 0.5365\n",
            "t = 22, avg_loss = 0.5363\n",
            "t = 23, avg_loss = 0.4717\n",
            "t = 24, avg_loss = 0.4162\n",
            "t = 25, avg_loss = 0.5318\n",
            "Checking accuracy on test set\n",
            "Got 275 / 400 correct (68.75)\n",
            "acc = 0.687500\n",
            "Starting epoch 45 / 50\n",
            "t = 1, avg_loss = 0.5474\n",
            "t = 2, avg_loss = 0.3429\n",
            "t = 3, avg_loss = 0.4535\n",
            "t = 4, avg_loss = 0.5948\n",
            "t = 5, avg_loss = 0.5569\n",
            "t = 6, avg_loss = 0.5257\n",
            "t = 7, avg_loss = 0.5734\n",
            "t = 8, avg_loss = 0.4420\n",
            "t = 9, avg_loss = 0.4656\n",
            "t = 10, avg_loss = 0.4886\n",
            "t = 11, avg_loss = 0.4878\n",
            "t = 12, avg_loss = 0.4518\n",
            "t = 13, avg_loss = 0.4677\n",
            "t = 14, avg_loss = 0.4675\n",
            "t = 15, avg_loss = 0.4498\n",
            "t = 16, avg_loss = 0.5124\n",
            "t = 17, avg_loss = 0.6285\n",
            "t = 18, avg_loss = 0.5102\n",
            "t = 19, avg_loss = 0.5894\n",
            "t = 20, avg_loss = 0.6176\n",
            "t = 21, avg_loss = 0.6934\n",
            "t = 22, avg_loss = 0.6037\n",
            "t = 23, avg_loss = 0.6296\n",
            "t = 24, avg_loss = 0.5055\n",
            "t = 25, avg_loss = 0.4275\n",
            "Checking accuracy on test set\n",
            "Got 267 / 400 correct (66.75)\n",
            "acc = 0.667500\n",
            "Starting epoch 46 / 50\n",
            "t = 1, avg_loss = 0.4396\n",
            "t = 2, avg_loss = 0.4380\n",
            "t = 3, avg_loss = 0.4518\n",
            "t = 4, avg_loss = 0.5582\n",
            "t = 5, avg_loss = 0.5184\n",
            "t = 6, avg_loss = 0.5664\n",
            "t = 7, avg_loss = 0.5289\n",
            "t = 8, avg_loss = 0.5994\n",
            "t = 9, avg_loss = 0.5320\n",
            "t = 10, avg_loss = 0.4565\n",
            "t = 11, avg_loss = 0.4976\n",
            "t = 12, avg_loss = 0.5836\n",
            "t = 13, avg_loss = 0.4722\n",
            "t = 14, avg_loss = 0.5250\n",
            "t = 15, avg_loss = 0.7003\n",
            "t = 16, avg_loss = 0.4582\n",
            "t = 17, avg_loss = 0.4933\n",
            "t = 18, avg_loss = 0.5157\n",
            "t = 19, avg_loss = 0.4610\n",
            "t = 20, avg_loss = 0.6551\n",
            "t = 21, avg_loss = 0.4955\n",
            "t = 22, avg_loss = 0.5506\n",
            "t = 23, avg_loss = 0.4495\n",
            "t = 24, avg_loss = 0.5502\n",
            "t = 25, avg_loss = 0.5649\n",
            "Checking accuracy on test set\n",
            "Got 302 / 400 correct (75.50)\n",
            "acc = 0.755000\n",
            "Starting epoch 47 / 50\n",
            "t = 1, avg_loss = 0.4817\n",
            "t = 2, avg_loss = 0.4265\n",
            "t = 3, avg_loss = 0.4547\n",
            "t = 4, avg_loss = 0.6394\n",
            "t = 5, avg_loss = 0.5943\n",
            "t = 6, avg_loss = 0.4965\n",
            "t = 7, avg_loss = 0.5566\n",
            "t = 8, avg_loss = 0.5267\n",
            "t = 9, avg_loss = 0.5936\n",
            "t = 10, avg_loss = 0.4271\n",
            "t = 11, avg_loss = 0.4508\n",
            "t = 12, avg_loss = 0.5902\n",
            "t = 13, avg_loss = 0.5421\n",
            "t = 14, avg_loss = 0.6988\n",
            "t = 15, avg_loss = 0.5939\n",
            "t = 16, avg_loss = 0.5389\n",
            "t = 17, avg_loss = 0.4992\n",
            "t = 18, avg_loss = 0.4881\n",
            "t = 19, avg_loss = 0.5407\n",
            "t = 20, avg_loss = 0.5688\n",
            "t = 21, avg_loss = 0.5837\n",
            "t = 22, avg_loss = 0.5390\n",
            "t = 23, avg_loss = 0.5783\n",
            "t = 24, avg_loss = 0.4935\n",
            "t = 25, avg_loss = 0.4928\n",
            "Checking accuracy on test set\n",
            "Got 271 / 400 correct (67.75)\n",
            "acc = 0.677500\n",
            "Starting epoch 48 / 50\n",
            "t = 1, avg_loss = 0.5563\n",
            "t = 2, avg_loss = 0.5689\n",
            "t = 3, avg_loss = 0.5604\n",
            "t = 4, avg_loss = 0.5830\n",
            "t = 5, avg_loss = 0.4628\n",
            "t = 6, avg_loss = 0.5411\n",
            "t = 7, avg_loss = 0.6510\n",
            "t = 8, avg_loss = 0.6316\n",
            "t = 9, avg_loss = 0.4900\n",
            "t = 10, avg_loss = 0.5109\n",
            "t = 11, avg_loss = 0.5131\n",
            "t = 12, avg_loss = 0.5745\n",
            "t = 13, avg_loss = 0.5073\n",
            "t = 14, avg_loss = 0.5172\n",
            "t = 15, avg_loss = 0.5478\n",
            "t = 16, avg_loss = 0.5720\n",
            "t = 17, avg_loss = 0.5533\n",
            "t = 18, avg_loss = 0.5287\n",
            "t = 19, avg_loss = 0.4582\n",
            "t = 20, avg_loss = 0.4784\n",
            "t = 21, avg_loss = 0.4905\n",
            "t = 22, avg_loss = 0.4921\n",
            "t = 23, avg_loss = 0.5165\n",
            "t = 24, avg_loss = 0.5277\n",
            "t = 25, avg_loss = 0.5321\n",
            "Checking accuracy on test set\n",
            "Got 295 / 400 correct (73.75)\n",
            "acc = 0.737500\n",
            "Starting epoch 49 / 50\n",
            "t = 1, avg_loss = 0.4588\n",
            "t = 2, avg_loss = 0.4764\n",
            "t = 3, avg_loss = 0.4630\n",
            "t = 4, avg_loss = 0.4259\n",
            "t = 5, avg_loss = 0.4711\n",
            "t = 6, avg_loss = 0.4853\n",
            "t = 7, avg_loss = 0.4450\n",
            "t = 8, avg_loss = 0.5543\n",
            "t = 9, avg_loss = 0.5419\n",
            "t = 10, avg_loss = 0.5066\n",
            "t = 11, avg_loss = 0.5138\n",
            "t = 12, avg_loss = 0.4672\n",
            "t = 13, avg_loss = 0.5374\n",
            "t = 14, avg_loss = 0.4428\n",
            "t = 15, avg_loss = 0.5106\n",
            "t = 16, avg_loss = 0.5227\n",
            "t = 17, avg_loss = 0.5882\n",
            "t = 18, avg_loss = 0.5137\n",
            "t = 19, avg_loss = 0.5815\n",
            "t = 20, avg_loss = 0.7783\n",
            "t = 21, avg_loss = 0.5201\n",
            "t = 22, avg_loss = 0.5443\n",
            "t = 23, avg_loss = 0.5763\n",
            "t = 24, avg_loss = 0.4922\n",
            "t = 25, avg_loss = 0.5831\n",
            "Checking accuracy on test set\n",
            "Got 275 / 400 correct (68.75)\n",
            "acc = 0.687500\n",
            "Starting epoch 50 / 50\n",
            "t = 1, avg_loss = 0.4688\n",
            "t = 2, avg_loss = 0.5890\n",
            "t = 3, avg_loss = 0.5270\n",
            "t = 4, avg_loss = 0.4325\n",
            "t = 5, avg_loss = 0.4658\n",
            "t = 6, avg_loss = 0.4813\n",
            "t = 7, avg_loss = 0.4934\n",
            "t = 8, avg_loss = 0.5366\n",
            "t = 9, avg_loss = 0.4177\n",
            "t = 10, avg_loss = 0.4973\n",
            "t = 11, avg_loss = 0.4988\n",
            "t = 12, avg_loss = 0.5984\n",
            "t = 13, avg_loss = 0.4464\n",
            "t = 14, avg_loss = 0.5406\n",
            "t = 15, avg_loss = 0.6196\n",
            "t = 16, avg_loss = 0.4109\n",
            "t = 17, avg_loss = 0.6349\n",
            "t = 18, avg_loss = 0.5089\n",
            "t = 19, avg_loss = 0.4326\n",
            "t = 20, avg_loss = 0.5124\n",
            "t = 21, avg_loss = 0.4243\n",
            "t = 22, avg_loss = 0.5145\n",
            "t = 23, avg_loss = 0.5184\n",
            "t = 24, avg_loss = 0.5545\n",
            "t = 25, avg_loss = 0.5045\n",
            "Checking accuracy on test set\n",
            "Got 295 / 400 correct (73.75)\n",
            "acc = 0.737500\n",
            "Checking accuracy on test set\n",
            "Got 297 / 400 correct (74.25)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7425"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nr2sQUvYlXYm",
        "colab_type": "code",
        "outputId": "cb08fa9c-0bee-4839-9be5-f7ca47a670d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "check_accuracy(model_gpu, valid_loader)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking accuracy on test set\n",
            "Got 298 / 400 correct (74.50)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.745"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkR_h7GRTJv4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#! pip install torch-lr-finder -v --global-option=\"amp\"\n",
        "#from torch_lr_finder import LRFinder\n",
        "\n",
        "#lr_finder = LRFinder(model_gpu, optimizer, loss_fn, device=\"cuda\")\n",
        "\n",
        "#lr_finder.range_test(train_loader, end_lr=1, num_iter=100, start_lr=1e-05)\n",
        "#lr_finder.plot() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzuX5gLEeJfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def retry_from_backup():\n",
        "  model_gpu = model_base.type(gpu_dtype)\n",
        "  print(model_gpu)\n",
        "  loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) \n",
        "\n",
        "\n",
        "\n",
        "  checkpoint = torch.load(model_backup_path)\n",
        "  model_gpu.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  epoch = checkpoint['epoch']\n",
        "  loss = checkpoint['loss']\n",
        "  print(\"starting from epoch: \" + str(epoch))\n",
        "  print(\"starting from loss: \" + str(loss))\n",
        "  print(checkpoint['model_state_dict'])\n",
        "  print(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "  train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs, starting_from_epoch=epoch)\n",
        "  check_accuracy(model_gpu, valid_loader)\n",
        "#retry_from_backup()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDn-2g-TLY3k",
        "colab_type": "code",
        "outputId": "4e5c5150-7b7e-417c-bbd0-6484ff99f8c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot([print_every*batch_size*(i+1) for i in range((len(avg_loss_list)))],avg_loss_list)\n",
        "print(\"Loss:\")\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO2dd5wV1dnHf+feLbDL0pcibelVQFgRRQzYwBI1MSpqTGwxscUWDUZfY0wzJhqjQYMtGhv2rqAIKorSe5MOi5Slg8DW8/5xZ+6dO3Nm5ky7d+7s8/18YO+dOXPOM3fOPPPMc57zHMY5B0EQBJH7xLItAEEQBOEPpNAJgiAiAil0giCIiEAKnSAIIiKQQicIgogIedlquHXr1rysrCxbzRMEQeQk8+bN28k5LxXty5pCLysrw9y5c7PVPEEQRE7CGNtoto9cLgRBEBGBFDpBEEREIIVOEAQREUihEwRBRARS6ARBEBGBFDpBEEREIIVOEAQRESKr0Kev2oGKPYeyLQZBEETGiKxCv+K/czD24RnZFoMgCCJjRFahA8DBqtpsi0D4COccf/1wBRZX7M22KAQRSiKt0IloUVvPMfGLdfjRYzOzLQpBhJKcVeiLNu/Fos1kqREEQahIKXTG2FjG2CrG2BrG2HjB/s6MsemMsQWMscWMsTP9FzWdcyd8hXMnfBV0MwRBEDmDrUJnjMUBTABwBoB+AC5mjPXTFbsbwKuc82MAjAPwmN+CEgRBENbIWOjDAKzhnK/jnFcDmATgXF0ZDqCp8rkZgO/8E5EgCIKQQUahdwCwWfO9Qtmm5V4AP2WMVQD4EMCNoooYY9cwxuYyxuZWVla6EJcgCIIww69B0YsBPMs57wjgTADPM8YMdXPOn+Ccl3POy0tLhQtuEIQpnGdbAoIINzIKfQuATprvHZVtWq4C8CoAcM6/BtAIQGs/BCQIgiDkkFHocwD0ZIx1ZYwVIDHo+a6uzCYApwAAY6wvEgqdfCpEg4Fzjqufm4MvV+/MtihEA8ZWoXPOawHcAGAKgBVIRLMsY4zdxxg7Ryl2G4BfMMYWAXgZwOWc0wsy4S8c4e1Sh2vqMHXFDvzif7ROLpE9pBaJ5px/iMRgp3bbPZrPywGM8Fc0ghBDtgJBiMnZmaJEwyMX9HiY3yKI6BNJhU4WHJFpGFi2RSCIqCr0bEtANFSo7xH19Rw7D1Zlpe1IKnQ/ue7FeXht7mb7ggQRADV19fTGmWM8PPVblP9pKnbsP5LxtiOp0P3s/h8u2YbbX1/sY40EIceBIzXoeddHeHTammyLQjjgkxU7AAA7DmTeSo+mQieLJpI0tMu691ANAOCVOfSGSMgRTYWebQGIBkcuRbfU1NVj6ZZ92RaDCIBoKvTcubcIB+SC0gy/hMADk1fi7Ee/xJodB7ItSqRhWQh8iqZCz4nbiogSQRgRqkLw24W4qCJhne88WO1rvUT2iaRCJ6JJQ3vzYgGbeA3t92wIRFKhB9FRP1i8FXX1dAeEgTBeBRmZ6us5Ji/dhnqH/cjv86UpUNElkgo9CK5/aT6e+GJdtsUIlE27DuHJiJ9j4Fho31fnbsavXpiHl+dskqoqKMUbxgdilMhmlJ1Ucq5cI6jfc8veQ8FUHBIueeobVOw5jAvKO6J5UUG2xTEQZkUkcxNvUyaabN/nbMJJUP05G4N2DYlspIOIpIUe1KCoyOXS6+6P8OuXFwTSXqY5WFULgHyrXvCz7yUHRQPqz3Sdo0c0FXpAHbW2zlhxdW093l1Ea2JngjBPGAtCsqAsPDLMo0skFXpQRH1QNMT6MhK4VdB0XQhZck6hP/3levS/Z7JlmSnLtgXSdm3EFbpKWH2rXn/92rp6/G3ySuw95H/8tYzSdeo6Cet1IMJLzin0uvp6fF9dZ1nm1lcXBdR2uBX6b19fjL9+tCLbYoSWqSu24/HP1uK+95b7X3mAXSOoqmkCXrDQTFEJYlk0W2rq6rPWtgyvzN2MiZ9HN+zQq+uhRhkDqQrwOlrJ6NTlElRPJ8s/upBCd4AXC72mrh5VtdZvFkSGCMAwDdLaJR86IUsOKnTx9r2HqvHEF2sDjYTw4kM/b8JX6H23te8/24Q5ikSLWzFzzjJNyuvvdcmRy0y4IOcmFsVMNPrv3lqCD5dsw8COzQNr24uFvuy7/T5KEiyhXR8zxIrIiZIM8WkQPpDNB2YOWuhiZbP/cGJSTHVtcP7R2vpw+9D9IuqDZbLn58ZFJqqZc473F3+HOpf9pyFZ1DdNWoBnvlyfbTFylsgo9NSsuuAIe5SLX4RVgXh90Dh581i6ZR963z0ZnyzfLlXeSrIpy7bjhpcW4N/THS4l1wCn/L+z8Dvc934AUUgNhJxT6HETidVUo/Vh1UZETrFg814AwGerdjg6TjQOsUeJe3drD+Ryj66v57j33WVYV3kw26JkHApblMAsR7Tb8aOauno88cVaikDREFYF4tezOohnfhADymG9Dk5YW3kQz87cgF8+Py+5raq2Dht2fp9FqYIlmy7LnFPocRuXi1Mmzd6Ev3y4MvTx25xzrNyWmYHVXIl2cUqQFpP6iwWxKEVg1yODl1n75vzb1xdj1D8+w4EjNZkTIAtQtkUJYjYSyz4dL/jPTPT43YfJWadqpsGw8sxXGzD24RmYs2F32vYd+4+gbPwHmLx0q29tRVOdZwYZ5etUP/u/wIVzRfP5t5X48WNfOR5HEj3fvlyzEwBwpCbaQQbZsNRzT6HreshXa3biSE0dPltVCUD+ZpmzYY/ruPK6ep5xF426SvumXek52X/2zGwAwK9emO+5jbArcr/kC8blkht1uuWmSQswf9Ne7D/szqoO0alEmpxX6As378UfNaPiTm8CtTbOOQ5X12GbZvEBvbVVV89xqLoWN7w0P+OThFQ5b3ttUVK5A8CWvYd9a+PAkWjnQ3dkl7r8EcRhi66q8u14Q30ZVa/G8LOo9i895HKRQBS2+J1GqTntK9rqfvr0LAz/66emZedv2ot+90zBR0uDyeYoy2/fWBxo/WGNQ8+Gb1/WJR7EbxbW6+CETIQThw2aWOQAUdiiH2ltOQfmbdxj2BZ6ApBx615nS6TlGlKKUtFEfvQBr+Okfj/IvFiOjg0m0bYQx8HnOjmn0EVRBNqVhPSd/4VvNuLVuZvN61O6nPaotxdsMWyz46VZcgv/ukZz2tpTDCLu/twJX/lepx94PVNHiiTbI5eZqVoarzo4qpFTYUNKoTPGxjLGVjHG1jDGxgv2/5MxtlD59y1jbK//oibQu1z+PmUVvl63K/ldb6zf/fZS3PG6uYtCdJPf/MpCAPadULv/d28tsSwbFHa3ycy1O7F5d2YXtz5YVYsZqysz2mZQOLUmRV1Gv03WlRK0Dqw8WIVD1cFGd6kGWENU56GcWMQYiwOYAOAMAP0AXMwY66ctwzm/hXM+mHM+GMCjAN4MQljAfKaoRhpX9bq5eWoEa4z6iZki1rZqJ/clT87CSX+f7p9QEtz08gJc9vRsbN8fTteN1LV26HIJtCcEVPlNkxbiJ49/HUzlCqmgg9Q2MtaDQ8ZCHwZgDed8Hee8GsAkAOdalL8YwMt+CCfCbuKG284isprsqgoyWdfMNTsx8oHpeGtBBQBzv6eMtZfpG2j1jsQ07yM1/oZ2ej8PByaTw8YsF7bQNSvrww7qsmnlWb7V2WQ1p66T1KBouLX445+tjcRbpYxC7wBA64SuULYZYIx1AdAVwDST/dcwxuYyxuZWVrr78cxmirpl7yHzuFq7vitroX/vYtLSim0HAACLNidCFFmaD107ZuC46gaPk5/MrrtNW7ndsUvLqXILwyV2OwM2tKmYdfxt8kpc9vTstG2Hq+tQNv4DTHCaVE0hG/em34Oi4wC8zjkXmmac8yc45+Wc8/LS0lJXDditWCTzG76zcEvys5oBT+j7tKlNdkm6sx6ZYdhWW1ePSbM32c68s7uPwnCzZwrP2RYD0C1XPjsXIx+Yjk0WSt31W2MIn9ZuJQrhqdiyT5lE9b+vNzg6LpunKqPQtwDopPneUdkmYhwCdLcAElP/bX7NRZv34qZJC32RpVbSQt+wy3izPztzA8a/uQQvzTZGx+w7VGOYiWqqi0J4o4T99ToInpoRXC6gMCl2xxP3BB03yMHCr9fuQtn4D7Bxl3nyr/cWfYfLnp4lXaefbtygkVmxaA6Anoyxrkgo8nEALtEXYoz1AdACQKCjLPYWuvhHnL5yB0b3aePIr2vvcnHvQ1dTqu5T/moZdN/Hyc+iV9a0AaaGpDzDnG3R/yozUrdT3Pa3TA2KqgbSws170aVVsbDMjS8vkKrL+/wBb8e7wT5mhPNaADcAmAJgBYBXOefLGGP3McbO0RQdB2ASD9icsFXoJq1f8ewcAEBe3GRw0YXYeoVeNv4D3P/RSsf1WGHrcvFNyfl32cLoN0289WQnGZRbxRAiw1wYrSKDWj5TbxlqBseSRv6trhmiy2CL1Flzzj8E8KFu2z267/f6J5Y5dmGLdj9+3M5no63LxaDofz5fi/Fn9JFuww71RkobFNWcpV+dLeyLMX3xbSX+9IH7lWy0bz1uWLXtADq3LELjgrhwv1VfCVsuFy84n2+VWeHVfERNCvM91+V9MpVnERyTczNFC+LiG0rFyhLgnONfU78V7xNss0up68XlkpLJ6/H+9BqreuqUVWe+c5gI7K63lnoVK8m1L8zDt9v9WvVG/jebvrIS31fVYszDX+CmSVav6vJ1hklBO8VxhI5qoQcgi4iDikIvzPNPtTl/K8neBc45hd67XYnrY5ds2Yfpq8ThkqJrcPvriyzr86LQZd0SmYpysapnzobdeHbmBtz2qvXvoUfNe23Flr2HQzXop2fL3sPYq0Q7zNblotcS5CmEYZxE7YdO3+SClLy2rh5//WgF9mrGoWqUuSEy7dr2O7fLoCWPyvx1yzmFXmDz5LW6RnssYs71HK5O5Vg3I+iZokAq/lf7AAhigMlyYozy1+9Fsudt3I0R90/Da/MqfK3Xb+o9nnfYfOgiedZWHrScL+HVFy46zOug4+Rl2zDx83X40wcrBO15n3CXzPOU/eepNDmn0L3w82dmm+7TP02nSywObLbIxacrtuPaF+YJ9/mBbP9ycvNZJfmKxYJZgFt1oczXZbkU4WfLTk9jUYV9aiKrKnPBh37Kg5/jSiVwwE9Z1D4YhLWqGhiiwW6Z1uz6cySjXHINP8KqAOC6F+1XADpcLVboVz0317ec6aI+pVXUTS1G8/3qUKoMbhX6kZrEjLsnvlgr3C9TbTatpBteSvjOre7vIN1GmTr1WevNXUpuUWWXSVrmuo30OF7542zrdSVOVomeQs/ARchXQh8Pu8hVMm3ldpz20OdJX58ep6/35w/tCAAY1LGZsS6LH+PRT1fj1TmpjA7WuUi8ZcxTIw+e+CJ98k34ghudoVUk3wWQQz4MvnOVlA/dv0FR7zN/jf3S6gGix+5cVPmcSpnNq+ZfsGZIWOEw2ZCKk4uQH4+hpq7O1EJP1sm5IQfG+DeWYMeBKgzu1Fx4jKGTKYenhy1qd5srW9Gz4XB1HRoXxPHgJ4lonwuP7aQcb+FyUW9mpcId+4+gaeN8NMpPjziavHQr2jdrbFpPJvnpU7NQXBjHxMvKA2tDe6lWbT8gf5zjhpwe4LB6B0raucEkd8D0VTswR/OG8MyX6zGoUzMM7dLS9JhYMjjeXbu255IDrjI9kVPoT85YH3gb+fEYgDpbC72unhsmMu04UAUA2HmwylD+jXkVuO219EgSu2gYVREvrthn2Kd/OMxcsxOXPDULL/9iuKCseRvqZC61zLC/fIrh3Vpi0jXHp5VTF6ru3LIouW3rvsP44aPWC2a4sdSufHYOHrn4GDQpFHdhmQgbr/gWYaRcJ/3D30whfLl6Jw5W1WLsgHY+SSCP23MWnotm2xX/Tfff36esE7zh/rNM61TvDW0/9/PhlLL2w/OmZEfkXC5ucXLN8pXZTbYK3aJSNXxSW0KU14UxYO6G3ZikcY+sq0zlqXAyoUUNu/t6rVHZmXXaqto6TFuZGCDW3jjfrJPzt740a1Py4WV4+ZD0uWzadcjwW09buQMfLP5OrgKfMCpcf270rnd+iKufm2u6X//A++nTs/ArHwfdnZyGes7frEvkTKnYY51pMlW3/0oxmZpX4EL3xeXi1UKnsMXs8bJAmZqR9KHbulycySBSEI9/thY/+Y+79Dj6fO1qyKeTqIC/fbQK//p0tSKfXLvajlygmdprdjjnwCOfrkbZ+A+E+/1eoEMkx9rKg9i2z5kf3M8ozk9XGqOqMqUO5NpJf0t7RTEwZtsMpFoOikq1ayeRWHH6EeXi1oeeTSc6KXQXxBXnnV1uEL/jtkVYWYkXTvwm7XthXsLnLVToJtVs2p16G7C6AcySnlnNG1ixNeV3fuiT1AzerfsOY/4m+1BGP3PGnPLg5xj+10+lyr61oAL7j9RkzALz+41f/7s5e9NIL6seumDTHtQKJtoFochVhBZ6iKJcKGwxR1AVul2Yl0xEwJGaOlTXys9u02N1jH6AuNDKQvc4EeOvHxond2jbFPHszA2JenXbJ36+DtdLhI3K4mZikNkRy77bh1teWYTxbyzO2A0bdDOO1LlSWPtIWFKxDz96bCb+qUmrsfNgFXZ/X21p5Xr9/ayir6RCYW0mejtx31gdn0lIobtAHSRctNl6wonMCnWPfbYWP3z0S9eyOOlsqrVc7cBC1966ogfUzDU7UTb+A9OUCgV5qUgYWUuwqtZ+wFknmiX6sQzOOQ5V1+L37yx1tJoUQ8rNtn1/lWeF9PzXG/DJ8u2m+zM1GOfVqt1xIOGqWv5dyoAo/9NUDPnjJ5o2AvChC+pOPkAk2hP1Z22+nlwaDFUhhe4C2cE82ZjdVdsPYM2OA64UxOItxugWM1IWulFZmjed2iM6n7eV1Z+0K/ZoX+nzTdIVp7WQ9srMUVfPfXNXHfeXqZgqUJrPfLkez329EU+aLEwhnNAFfcyzNxn/751l+MX/zAdDk+1IdozrX5yPf09b7VgOmfMwi0Pnmn1WlrI4yMXb75e00H10ubyzMDXQLqrrSE1dMkWvbf1ZeCCQQneB7EpFVlEueq6yiHKwwu4tQeVfU1cnBzdFScXculzs9G5hvnV2TD3fV9ehnnvPn6KyfX8V7n1vWdo2DkD9CczasRrABRIKP+j71Wn1HyzZin98LM4matmOoygX5YPmiadXrNol21I5YDTlXbQrwioM3Y9B0WRdmnKnPvQ5jr7XOhVzNu16UugusFo/UosTpcS5s45gZsUWmCSM/+fUb5Phjm4Uc6KMsZDdTWEmjxbtG8+1L8xDPedSD0PZIVG/xqa17TFmfu5HaupQeaAKf5+yUtgHHEc/2ey/660lphFCMmywWK7NIItAGH1qiHveST1A3UagyJAaFHX3G7sJW6zYI59CmnzoESPIIJcfP/YVet/9kWF7dV09brbM2y2WS+b1V3iczWHPKQOfVmjrmLV+NzgHjtTU4+Nl/uTD0SvVIzV1aQN4ImQeFman/pvXFuHONxdjwvS1+HrdLjkhrdqx+Y1fnGUdcnuwqhZ/en+5aSSSk2ghfT/ZuOt7y1XEUha6O8X+0CffmkY8xURT/5MuHplRUbvd5gO6YYUUeoDo48CtYA7f4RdV7EOtyRPj7YXWE270N9eBIzWmvVa7yMem3YcMSkH0lqB9g9EqNJmzU33oAHDN8/OwWCLToR16S0w7eKdHtXTNXS6aATiTQt+s240jNfXCts0oFqyEpD30cHWd6/z7j3+2Bk99uR4vfLNRuF9mTMjMTfLotDVSeV7cKsVHPl2NHz8201Iot4aT3XEUtkik8WdBnuZMMcdqMQbN5w07v8fR934svNnfWbjFMCN05bb0nCV+pNTVWlN19Tytzt3fGxfRdor+xvXjRmNgUlrqsqdn43dvLbEt10mTLkFE33smmys2G9Tz92NN1dQYQuopEBMMThoPFNXlcVDUqh4PLpf9R2qwaPPeVBWuxaRB0YwTj8m/bjrFrxS6brjAYnbpVs2MyLWViZzkn6wwzlScLpi9aIhycNhn11UexNXPzUmz9N+cv0VTf3qdVgPQ+qn4ZuhdLtzksx3a5mZv2I31Jr5nN11KvFZpunRLHEQ0aclTBFJ/Sy95vkWuDKv0ylZRLl6xuv5Sb4Mm269+di7OnfCVcKJU2MlJhe6nDi5tUuhfZQIWSMx4BDKbSlY74egbxSUiGrsURg/oblqnFvq97y3H1BU7TF//9XU6cVuZIYpD94O73xZb3m4UppUf2iuq0VJn8ls6aVn40wlmbCbLWwXEurwMy77bh4+WbBW6gRwt6mLic1mouPmsViSTUfZ6USYv3YpdgqR8fpKjCt2/zr9tv/95rLVop7TbsUiQMTFo1OyUooExUX/Xb3Oq0NWHsWjZMBWtX77aykKXbFMvo5fBau2hZs8a2QyZ6ccIyvlk1qoWuvpg81Kv+ltqb0GrFM5Wg6JuOeuRL3Hti/M1g6KacQ1du1aYlUmmi1Z/L0GZaguFLjrXvYeq8asX5uNKl+HJsjQIhT6kszj3eCaYsVoujaus+yAoRG89oo6ptWqe+XK9I+XIudy109b54Mer5BuQqA/wPqElVa9/Sqqmrh53vrlEmFbZLfM27kZ9PUc8lrjNVZeLfiDbyVmIylrnJXfehizJwViBbt19yH7sxWwJyThT32jUB6BR+qoaCQtd81kNYKiQDHl2S04qdLPFIcyYv8l7pETUiQk0uugmfE+Tsva+95c7zD/Npdxl2jo37jK/AaRn7OoVmObro9PWYJ9u8XCvs1TdPJsXVezDy7M34S8mOXGc8umK7Tj/8a/x4uxNKR+6cl56F5STB5MwDj2ZL1/gQ7c4zr+JRcbIo1+/LA7d/XRFatbwHW8sFpaJ6X4vkZgyv5lwMpXtUd7ISYX+1OXOVqH543kD0Cg/J081Y4gsZ5GyfuGb9Jhnp7pP5k1ElErWCwYfum7/y3PSz2nb/iP4XJibhqXdpGY3tad3LS786JilWxLjJNv2Hdb40MUWurNhCoG7yHLqf4AqzMJ3b4Z2RvYCxdDTyxjTWeginJ5VajZtsCo9J7Vc00b5jspfNrwLFv9+TEDS+IPZpI9M4VYJTXOgfDkHvnWwVJsdspaw4R6yCWMccf80qYeK2f0u89CyWxjCK3sUl0OLooLkqlnqALN+/oKMtZmKNVe+a/bFkorVwkIXqMBLnvoGFz/xjWG7U9KjlpwrTL3Y6vmoA59u3y7cTqbyQk4qdD0DBQsk6wkwOtEXtjpcXMFv5m40RuP4bUwcqKq1dKF4ZcqybXh9XoVtOf1N79anbmZtyTxoTn7wc4n6nUqUQl2Yu2njfOQpPnTV4tS7oC6aKL+AirXLxby82TR6P2bSpr3VuPjN9IfEdS4X8THurPegJxtFYk3RfIl8IUHGm0cVPwf9MsEvn08sy/aToR0ty/k10cj1r8PFKYy1PPjxKnQvbeK2haQ1XhCPQU38rYbh6RXV9zYrb2kRPcQsJ/io+zSffXsbVSr1u58y/aCocFaUfT3aIrcrawWTy0UC0QW99LjOad+zHUWSi+SCPn9qxjpMW2meU1yE25uKsfSlCs2qYcxbJE11bT0enbYGN7+y0LBvnuBNSoQa0TJ1xfbkG4OZha5Fm3pBS2pBZuW7KNuiuMa0Pyu37cchBw8QlWXfGUN6ue7v+p3yScbS6tFdSDXKxSrVgtOr6/e4kBmRUOiiG6tjC+up1IQ9YdfnDAx/+mAFrnzWWWyvwaUuqeArD1Th3UWpKB/zQVEb48Fut8V+dWavHaqF/v7irXhemcSlKmqryVq3vLIQ3X/3oel+YfZEi/h2/bZlW8zz6Fhx1iNfGh7c2hj3yUu3YvQ/PsOOA/Jhn2aDufpBZBFu49zJhy7BgA5NDdvyyMXiiYWb9+bkii0y6E/L7WmajQfYvgzatGclj6wVqlVGO/ZXpW2zUlR2id2svA9WqXLVfV5elLftS1fW2myIyywSrpkRT0aepG9XZaypt3hQSahmt64aL+S8D/2L20ejnnNDOF2UfOYF8ZjlzLQgePGbjVi9Q84azBZa5eDl4eP3Pea151kpC1U526H1k+tnPjpZeMUom2Cb6ssWdFE/bYIYA/4pmHnNuTs/umimqXa7WaoEtU03+4ImZxX6wI7NsLhiHzq3KsI6wWtonsTSZ7lCQV7mFfprEtEiYWKqILmYLH7fgJ7Ga5i1PFZKJr1cqhJVHjVZnJv0OPoUueluJa75X0wyS6Pgp5kimfd+wmdrsHl3aoEJrcvFzVyw1AIZ6dvjumRmoqqlHiBhdbkwxsYyxlYxxtYwxsablLmQMbacMbaMMfaSv2Iaef6q4/DuDSMAiH9cNVQrCqiLOxPm7D8st86jiGdnrvdRkmATrUmufmg5oOcl4Zm1ZWruX7dSgGp0kh36yCDtoKgbC93sLT4Zh+7Rhy4+LliVbmuhM8biACYAOA1ABYA5jLF3OefLNWV6ArgTwAjO+R7GWJugBFZp1jgfAzsmUgCIfvgo+dBllnFr6Hhxse055P5hIMRGFKtbmulmo+rRRqjU1XPT8Md0C918n1PUI9PdXel/ReWBhOxqfLwb9M8orRJ3oydP6lkq3G6IQ/cxrDVoC13G5TIMwBrO+ToAYIxNAnAugOWaMr8AMIFzvgcAOOeZidFREOXMzrQP/Qe9StGmpDAQV0UhpS0QctOkVFifKBdNtgjSh/7x8pR7wioaRau0/TQK/z1tNZbq8rKr1dvlQ58wfQ0edJB9VI++/jo1vzvcPaS6lhZj5tqdWLQ5/XySPnTLjIrm9QaRMlgWGU3RAcBmzfcKZZuWXgB6Mca+Yox9wxgbK6qIMXYNY2wuY2xuZaUoV4Y7erUtwUm90p+2fij0M49uJ102P87w2zP6uGqnQ/PGlvtlLfSGHGofIn3uec6DlW6yytGtxcxdwDl3pVRUJTdnwx78fUp6BkxuYchqldtkj2vEGtMgp3zcblwunAOXPDkLf5u8Mm27ev1qLSYWSUW5KEXe1yS08yvTpxl+mX55AHoCGAXgYgBPMsYMKRE5509wzss55+Wlpfj5Pc4AACAASURBVOLXHTcU5MXwvyuHpW3zw2JrlCdaRUYM50C+S799oY2PXGYmLABcMqyzfaGIEg/R08xOEqtVmN6YX4EBv5/iWQYzBefW3aI3kEQRRpYzRX3QY/oJUbIul3cWbsFjn60RyCQ+SL3d9G8i6cdaCKqWUZT3Upex926Q0RRbAHTSfO+obNNSAeBdznkN53w9gG+RUPAZ5Z8XDUp+9uMGb9WkwFF5t5E1dgpbtt6yVsWu2o8CoXK52Iiy40DweXu0CkeruOq4OxvR6o1XrW/T7kPJRbYNO+H9DVL/LFItaAZrC/2mSQvxwGRjXn2zI9S3ETUm388JQmFwucwB0JMx1pUxVgBgHIB3dWXeRsI6B2OsNRIumHU+yinFSM0gh6oj25Q4X2KuY4vGeOWa4clBVwA4sUdry2MYs1a8R3cwTyBmF8Ui+wofIiM14wS5hJtT7GaKZjoNRfrApLs69PpcW4+qpETuIO0W2xm0Nhh86BoN78blYpYCQS+leGzAvr1t+45g8+5DwhWVgsJWoXPOawHcAGAKgBUAXuWcL2OM3ccYO0cpNgXALsbYcgDTAdzOOfchjZoztFY5Ywz/veJYvHvDiVLHahM65cdjOK5bqzQFOfGyoeh/lHFGqooXl0ulzXRlWcO/IeerCVMgkN1lCPoq1ddznYWe+iw7qWjm2p1YtS2V6lhvob8n6Rfmvlro7lwuZsgeIswiaVJ2+/4jyVj5219fjJEPTHfXqEukbgPO+Yec816c8+6c8z8r2+7hnL+rfOac81s55/0450dzzicFKbQZWistzhhG926Dds0aGcr1bW9UzL8+uSd6tElkt9M/fc88uh2KC/Pw70uGWLevdPrWgoWnrTq9nYUuG1MfIq9DxgmThW7Hgs1yCbbcculTs0z31dVzKevykidnYczDXyS/x3V9MC3BlmTEh9crpH+70AahuLLQrbKr6TisSyhmdujKbYJ8/5qyQWcwDZFd4x2mORsrn59oT+uSAjx+abrCLlUUc9fWCd9000apKM8WRfn4avzJhnpe+sVxmHzzSDxx2VC01vjgf9DLfBD4Z8d3Md0HAPl5ki4XqVLRJEypHlZuO2CZUVA72zEI9DnGtUq1vt6dD93tvI53tLlhPD50DUvnaV0uLlxJTnRr33sm48352pBk8ygiK0ihO0DrcrEaJCsqMEavMDBDfzuuWyu8cNVxuOXUXgASq7/0U6z7eCyWFm74+x/2BwCc0L01WjcpxOn922GExu9+62m98cBPBgrlsYtykbXQG7TLRXPuH3sMj/ODBVlex1arNty4XPRY3U9WNWoXHPFsoet96Jrv7sIW5XzoKre+ukhzrIN2TD4HQaQUuva128qgePSSY/Drk3ugd9uS5LbEocaDTuzZGnmKgzYWY3j2imOFdXZuZUzXq73o8RjDUc2s483NyJd0oofISM042kUarpGcSt4Q0fvXZbGy0DOVjErfTm3aoKiL+ky2y9hFuRzlkjNoDVkrn2r7Zo1x6+m9DU/15NqIQQgH9wpXfy4ljUwm+DZgC/0X/3OWEz3qaK1PbY7wGat34mCVs+n3R2rqLBfWkHXi+N09tS4XP9YSVZER02xtXOHkqgymX4yWQk+LcrEvr1XodfVcymXRRFGmalTM/64chj+e299EnvTvZvXbXW59OKRZCGVDttAJOW57bZHjyUXv2uRIl9VXfndP7f1rtQqTina1Kf3xTrnhpQVYuDm7bjURkVLoaWGLgu7z8EWD8dLVxyW/q33glD5tUFQQl+pwRQV5WHHfWNwxpjcA4KRepbjs+DJh2bvP7pf23Uzh2vUrvYXuxdL517jB7g8mGhxl4z/AJyusl/iTVYt+j/E8Oi01+1PmGXXnm0vSvpu7XOTkPG/CV1Lro2YyP3qkFLr2OoiU53nHdMAJGutWfUKPP6OPo87WuCAuNTNRH75odcySe0/H7LtOEbpTOrWUW05P1HEGdGiKX/2gO5oUJuod0aM1rh3V3baud64fIdWmV4oK4ji9X9uMtEW445PlNgpdUmP5baHv/r4aALB8637MXr/b8fFOB0VFZHqdAjsiptDlolxUVIWun3of1BPVqt6SRvloU9IIS+4dY9inz9HiZMZd55ZFiQeW8j3GGM4YYJ90bFAnQyqeQOjRpgl+o7ztELlHt9bFWV97tqaOY9t+5+kUDlaJrWsnK3XV6NMX+5gmwA2RUuhaZFSeGruqxjAHPaZoteiAFYb0uQ7k1GfCi7HwTcIJmzxRIGORJ8n/7AnbZd64S7w+6z4Hi6WQhZ4hZFwoqoWeqcRObi9+m5L02a5OpDUugGt+dDdlAtV9JoO8QcAYo8HcHMZJBIfXXC5+48dDz2yBEb/bkSWyCl1GSagKPcjUq/ec3Q8jeyb89obXMwX9TaGmIPCD5Mro6sNLcKpqLvnOrYqw4f6z8DOTQV4nPHThIPtCijxhmuUZFYLOu61Sz+Xbmr3BuZ87SNbvFFvoTpBR6JkksgpdxkIfd2zCN920cXBrZV95Ylc8f1UiskZ2cYLJN400bJOxmsUxsOnfGTPOiFUtcz/VardSuYdSjDFyuQTAt9vl/cBe4HA3USkMOI3HF1FlWOdUlHGS4tA9I2P03XxqT6z+8xkoKkhX6EFdANlp13mC1IE/O74Mw7u1dNwm1/1lML76qvrUT8WaH2cY0tl+YDXGwpXLnHAG55l1KYQN1Y26/Lv9GP6XT7H7e3v/e9n4D7DdxSCuDBFW6PZKgjGWFuEStI9vbH9xdIns/ZAavJWXU7+AL2PGwSn1t/IzTrgwL4aHLzrGthz50HMbzoF/TzeuBtRQUF0uT85Yh237j2D6KuNyyqIH3oJNwWTcjKxCDyMFeTGceXQ7y8UurEgqXpP94tlyiW2XjygDkAjRNCr09L8qD14wCE//vNyVrPnxmNTi1jEWruXjCGdwzkM5YzJTqAq9sZLwT59m15xg+nxwzuMsE1Yd8dilQ1FXzy1XbDfDzoIWhUWq1sEdY3rjjjG9hXWoLg/9W835mkU/nJIfjxm67Kl922DqinQLJsZYg84SmeuE3dvy6tzN9oU8oCr0ovyEQj9ULeeXD6rLR9ZC9+IPDtonqJdMtj3VgjY7NaslwJhGcepdS+pv5XLBJSF5cWY40TOPbm8oF2OMolxymK37gl8f1QsTP18baP2qD1210K3y4GsJqsdHTqH3apuIrnCj0DNlKOrbEeVnP3fwUYZtZi6XC4Z2xOJ7Tzex0I1K3szlYmYp92lXItxuRVwQvSJS3IzlflIx0QpYRPZ5a0EFjtQEG1ZYo1PoosgZ8T0YTKePnEL/50WDcebR7dC9tNjxsZkarddezLvP6osLyjsZyvxrnHFAUV0Bqagw3VNWXJiHpo3yxQpd1L7ue9JC97GT5cWMLpemjfMN5WKM5XyUyxvXHp9tESLN2y7zCt3yyiJDWKHfqPUXKMEVVZIPkKC6fOQUev+jmuGxS4cKQ//CRv+jmuLqkd2kXQ6//2F//PG8ARhpkj5XNBNV9JDS622WVOjidt1YE7GY8bhGecY3EdlUBIMzlFvGDRRHHywtiwrsC5mw86D1AuxeUX3o6j28Za9xecHnvt5o2EY+9Ayg/siN842Kx2/euX4EXrp6uKNjigvzcNnwLqYWba2FD90Ku+eJG2siHjOGI4o6cYwxqSiXq07s6lyIDEH6PFjC/PvqFbosQYVIk0LX0LFFY9x2Wi88c7l4mTk/GdSpOZoVGV0Qes4eaBxIPEaZsHNKnzZp22V96Hqni2phmrmc3FigMcaME5hEkghmrooI88ApWejBYTZ3IyzsOVSNByavFBpTlgTUZSIbtugGxhhuPKVntsVIsvQPY9BIsIB0m5JG2HD/WfjvV+vx6codSaXdQvLVVKt/ftCr1NYCd6Ov8mIMVYLj3rj2BJz/+Mzkd9lcLmFV6CyE2SujxC2n9Qq1ha4usuF0FjdFuTRAmhTmWY4FqJ1CtQ2uH90DD14wKC2X+RiBhaMe17V1MZ67cpjtoKTV3id/Vo6bTzU+BOMxo+XNGMPQLi3StsnmcikucG57nCV4u/EbhtyP0gkzccFYTBhppVvMxo6gAjBIoecw+o5ekBfD+UM7Jq36Zy4vx6XHdRYdCkCbgdG9iX5av7bCNU6ZQFELfegxOYVoujC2Cc9fNQwPXpCe8bGRxMxVp/gxMUoUokokSLjuwk+hwyAMp+u6ykIKPQLon/ZdleyJTRvlC5WNuk276IUVdjeUmT7TbxYVG927DRhjStreLqZtNJcYb9DSuWURGukGt/UrU/mBH8ZjpxZySww2RERvem4J0h8vm3jPbXlZyIeew6gdXZ8d8vc/7I/ju7dCeZnYr1eoWPClymuinYVub0GLCxhdLunfh3drKYzBF9G8sbPQNf05tW5SEMhrrmo/tiouwC5ljUunhHV8IBucNbA9bjm1J+Zv3Is73liM0pJC7D/sPc0toMxeDginFrc475J3SKHnMGbds3FBHOcO7mB63FHNG+MfFwzCqN6JhS3sXAZ2Ct/cQre20UsayVvdRYXOQkn1MjVtnI9DJmtIeiH1UHXPEN24gl/0aVeCldsOBFJ3UOTFGHq0KUGPNiW48NjEw/7AEX8UepDzBp0q9KAsdHK5RAA3feMnQzuiddJCV+oxKWvrYpc8Tv3++x/2S7Sna9DqPPJiDFc7iEUXPYTy8/y30NR26l3eoD3aNEH7Zo3sC7qgbdNg6g0SYWirX5UHqNEdK3TyoRMGfHIu2qXldTssZVDoyt+jmjd2UZczX6phQBZAM0HqAa+olpabV+gx/dti4mVDA/HtA+GekOMEv6Jcglw5yLHLhSx0wgyvXSOVPtekgMv7ySyrYyYQZY6ceJm73O7nWUShqDMFnV6D9X89ExMvK0f30iYo1iVn04d2NnT86jZB5mqqdWyhByMHKfQcJhmH7rGjFiiDRWaWkH7rTbrJV6bH6TbbvQnYWVBOLDVjyCRDh+aN8f6NJ0rXoaJPhqblnEEJZe/0GmjPRV+/00FSdU1YQxsSx5bnwMPDLzOgnnO0LE4MrrcpcRY3LlO3lrZNresPalBUSqEzxsYyxlYxxtYwxsYL9l/OGKtkjC1U/l3tv6iEHr8slzzFnBWnCTAqx1tO65Uuh0m9MnHoQSFyuQDAABerRZnp11V/GouHLxoMwNsrtD53UL5kNEazxvmYcvNJOLVfW9dt//uSIYYUEmHDN5cLT4T0ntijdTK01y/0U//t3JRZGxRljMUBTABwBoB+AC5mjPUTFH2Fcz5Y+feUz3ISAsb2b4dupcX4xUhviatU94RZF7v//KMtJ7/IxqEbXS7eO/WMO0YLt8skBhNxal+jctQmD9Naz4V58aS7yotC11vkccmVRibfPBK925WYPogZY7azZYsL43hIeSiFAeG8CQfH//IH3Uz3cSR83aJ1dZ3SrXUxSjVWvl5B29WfzUHRYQDWcM7Xcc6rAUwCcG4g0hCOaNWkENNuG4VupU081WNnTXRpVSzMz253vMHlElO3i8vb6UTRUZ1aiifluLXqWhYbB061deWZmOt+3p/5ki4X9Xe3+t3+cE5/6zoYC2Sw2E9kL+XXd56My08oM93PeeItVDbdhBUtigvSjAa9C8WuftHsaj+QUegdAGgX5qtQtuk5nzG2mDH2OmNMOFuEMXYNY2wuY2xuZWWlC3GJIHFrZJpa6Lod+k4e5CCVwUL34InVym0akeLxXI7ShC6aTYAxU7ym4aaQmEMgI5yOggyvNSB77ezLcdRzf2af5sfTHwpOB0XLfHb5qPh1Zd4DUMY5HwjgEwDPiQpxzp/gnJdzzstLS0t9aprwih+TY7SYWYXJpe5Mjjupl7FPDOmsWdhCOVDGuvEzokb7cDCr1onL5fPbRxm2FWr86HkmLpeBHZulveYnr5tF01p3UalgINDNz/SFiZvLD4TiSMoYY9a/BecJV4fsoipW5MdjaXXor3+2QkZlFPoWAFqLu6OyLQnnfBfnXF0a5CkAQ/0Rj8gkZr5YEUM6N8eADuK1NM3W2LRzg4zp3w7jjk1/uXvzuhFY/9cz07ad0KOV8PgN95+VTMDl9oYa3ds4QKjNRmkeoSNPO8FEIu0YhVmUC+e6h4tNO4wBTHOHtxNMNHLz5hJopgJB3bLX0q5/cSQUrx8P+8K8WJpcep+4VRNB/n4yCn0OgJ6Msa6MsQIA4wC8qy3AGNOOvJwDYIV/IhJh5M3rRuD9G0cCMHZes5Atg8tFUKZQkP9dvVG1ysduzVjD4hoSN1HX1sU4rV9b9GyTPiYxsmfqjcBMaTix0EVKVBsKWmwRJik61jzcM90tIBLdjW7LdDpb2dbsxKrnPKnQ/bDQtQvK6BV6zzbmC6sHOR/DVqFzzmsB3ABgChKK+lXO+TLG2H2MsXOUYr9mjC1jjC0C8GsAlwclMOE/Xm9QVcn0atsEM+4YjS6txMo26XKxaE5GLXIOvHX9CKHrwotf/ndn9kVePJaU4Ten98Knt/0AI3uW4pGLE4PCZtaV1/EAmYFXDu5YAae7i/xRJJlOJiYrt15R/vKk9IiXz1ZVYu+hGlc+9L7tm+KBnwxMfu9/VFNs359ar1Sv0P81zjxyKKsKHQA45x9yzntxzrtzzv+sbLuHc/6u8vlOznl/zvkgzvlozvnKwCQmfGegEpt99kB3ebnV/hljzDTqRN2vReTisVKM2sObNsoXPjj+fsEglLUqSlr6+lmYVqhWtirXmP7t0F2JIDpa+Y38UIp2VVjpy9+c3ltTUeKP2W/GdL5iUbVuTseJPn/65+WGNx6nyDYXY+kGgWhweceBqrTfRfbhNLZ/O7RSJiU1a5yP60b1SNt/qDo98Ztl4rksu1yIiFPWuhgb7j8LYwfY54u2inCwDTuU6Mhe822cM+gofHb76KTf+5VfHq+0be16AFLyc0E5dXAxE7ap1UPjvGNSAWZ694toUFlbldDl4uKMnAR0FBfmCccMnCDtQ9edi1k8v3bRDJkFypfcezpuPDmlwId2aWFY5WvL3sNyQiLYPkTpcwlp3rruBOHNaZaXXY9oOr4ev+dbNFUspb7tUj7NGGNpE0EK4jFU19Wn3hiSu4wPATNle2rfNpi6YoeUTDKDmSI4Tz9WJgum9jcXveq7sdCd5BV36l4QPWCk69AVM4vnT7hcNBa6TVZlJ2meZci6y4UgAOCYzi3QvpkxU6KslefZ5SLVSjqdWxVh0jXD8ZcfH53cprfKTlamvqtNjz+jD0oa5aFji9S5qhaZ2b3470uG4Js7T5GSyc5tY/Z7ci5uP7WUoHFfukIXteWcpo3y8f6NJ+LXEguqZzJknbH0PhU3efBoZ4pmY3GRINskC53wTNPGiW40sGNzy3JqPx7WtSW6lRbj1tN6C0rZm+hOwisBYHi39DBHsxmsarWn92+HJbrlyuxi6Bvlx9GumbNFOMywut9Fg6dJF5GhbLryED0o3I4JDOjQDF+stp8c6EdqYCcWbWvNYs1mx8UZS/7GTpSrXxPhgnyEkIVOeKZ9s0QWwz+dN8CynKo8ShrlY9pto3B0R2OiLNlBUS+oN/H/nd0P3VoXJxWdTOihH6/LTl0uN4zuISzXvCgxSKeKbWv5O7TQ+5nMJ1CRUXBOFbroYV0gCGU1o1F+HKcrycrMdHXCh84sywhlU/567QFBRn2SQid8YUCHZoZFmfXI3DwyStWrpaQq5QvLO2Lab0ZJzZStTypNuTYGCh5WaoY/O/GN8fo87a8edbvBQpfIR6/fpKYDFu1zg1OF7nQKvRVmD99YTJwvP1PoB1R9rTuwmglCh4x1a3U/e8nHoqWbMikpOWFJ+WvlylH3yUrwzvUjDNte+eVwPPmzcvvXfJsoHLPttoOkIgvdMFBtXYdT/6/TvC+19e5WfhjapQVKdBOyTBW6xkLPBkEOipIPncgYMh05yIRdKs9eMQzzN+5BE0UBnNq3Dd5b9B36tDN3Mci6NVRE5dqUNMJp/exD+PS/k7zRaq2cZUS3m1m6/L4xyc8yYxn5ecyRn16fV1yWf40bbGjH7OGz+/tqTwOTXvUx+dCJSMAkeptMHLpXnd+yuCBtUYhzB3fA8vvGoHc78+narZok/NVXSixUreaTcYv+hjdEU+r3K3/tcsDLWKV2JQrznA38OnW5uM0TLnoQmSneFVv3uxoMdjoY/9CFg4Tbg0ydQAqdyBheLfRRvRMTZ07s6X8u6aIC65fVooI8bLj/LFxlo9AX3XM65t59midZTOOeA3C5eEF0rY7WrQjlVKHXuFToaROokO5KM7RRx10lyFL7r1k2TD3Ni8TXMchISXK5EBlDpiNbWUHlZS2x4f6zfJTIf5oJbuKF95yGaslVgX9+fBdcdWJXMAbMWF2Jr9bskp49a0hI5mKR7pG9WuPNBYlkqm4WMu7UsjG27z+CHQcSeU6c+tDrHPjQj+vaErPW7wZgNiFJfFxNXX1qPV4Hso3qXYorR3TFtaO6S5U3eyMiHzoRCWQ6spr4/8fHdEBRoT9x3dlGDS+0Q/uw+tUPumO2oqxSLhdrp4ud4SijR84b3AG3vLIIAHD5CV0wtEsL7P6+BhdO/NqkVV0bYGlZCPPj9o6eC8s74tW5FQDc+9BFyttsWn9NXb0rpZoXj+GeH4pW3xRj5j4iC52IBDL30A2je2BolxYY2VN+AZTEDEEPgoUU2fvedMBWP4HK4gK0blKInQer0uq46NjOUu3q0Splu8HHksK8NLeMEx962ukImjE735q6VA6F0iaF2HuoBkM6N8cVI7rixpcXSLf/wlXHoY5z3PfeMqyt/N6w32wh6CB96KTQiUDp1LIxNu9OJC6SsYry4jFHyhwA5tx1Kg4eqXUlX5iRCad0gpVufeu6EzB3427vjTCgRnGbnNq3jdSiE9qzcxuHLp4FKy5brbHQu5UWY8KlQ9CtdTHy4jFHCl0dyxnQoZlQoevXGVUJMgaeBkWJQHnjVyckPwflO2zdpDCwNRqzSXLCE0//qydpoeuPN9Zo2lanlkX40TEdHUqY4tbTeiU/qxb6Y5cmFi6zuuyc87Tzch/lkvqsTecsQutDjzGGXm1LkOchRYHZ6ZmdSpAx8KTQiUBpo1n2LAt5kALDLILBT9TfS9UL5h50NTmX86n/XtC6FNQHKgPwxrUn4KoTuyLfIivja79KpDXmmv+BxBudG0RvAmaW8BUndE3+Vnazm71g5nIJEnK5EBkj00uXBcXM8Sej2CbM0Q9US66lsrBC/6PEE5/0YYuqm+v8oekWt98P1FrN4KfWLTSoU3MM6mSdqC0ZZcJT8p/aty0e+Ik4dtsOWQt93V/OBGPAnW8uAQA01i2AMuOO0Rj5wHSHbYt/WDOXS5C3ASl0gnDIUc3dWZFOUS3MslbFePv6EabJsvRJozo2L8KMO042lJN91b/v3P74aMk223Jaf/ewri0BAJce10WqjeT4ALhGobdJzt51imwe9VQa5MTfIp2Frs3W6KBxIWbuoyANd3K5EERIUZVOPecY3Km5bdZBuzegXm3lloL72fFlePma4bbltOGJ7Zs1xob7z8Lx3VsZyomkSrqTeCohm1PLta3GnSdqRKa+Ip2F7sZ6Vh8mD5w/EG2bFuInyptRNlwupNCJwCnv0iLbIuQkqm7RZ6BsXpSPW05NDULqB0XN4tVvONl+QQonyMaM3322MXY7lozg0b5hyGvTf140CH/+UWrREtFMUS1lrYrwxe2jk9+nr0ysLrV4yz6hXG6IxRhm/e5U/OOChNvIzOUSJORyIQLnuSuHYefBKvuCEaND88aO1prUY6ZcFt5zetr3pAK30UXxGMPsu05B5YEqnPXIl47l6atz+dRITiXtXtoEQ7u0wLyNe5LbYhqXy3mDO+D1eRU4VnHbyKCPyMmzGSBo16wROrdKLWC+bf8RAMDxusVP3IwzpKKR0hU4DYoSkaS4MA/FLn2juczHt5yEIzU2C1ZaoCoK2xzxym6t1SusD4mMj21KnC/a/Pnto5KDsyo1DmZ1GkIqNS6XE3u29pzSQfTws/rZ8mIMtfUcP9Isug24Wx7OLI1ANix0crkQREAUF+ahlZtBNgU7Ba3HThV5ia7o0qrYkDTMbe5yrSx+qTythd5HyZrZXrCguYo6oFukMzT8jMTKxtwIUugEEVJSPnTrctnKeuBldSHVz+3XLFitZX3d6B5487oTUF6WcuGY+ef1US567Fw5gOZBqTuVkT1L8d4NJ9oe7yek0AkipMhO/b/zjD44b/BR+PGQhF+5hUkyML/nAXRpWWRfKNl2+vfkwtw+yaI9t3iMYUjnFrr96eW7KP50u+XgOrSwD1FNPpwEZ9O3vXmO/SBoeI5NgsgRtKF9VrRp2ggPjzsGnHP88bwBOGfgUdYH+MQtp/XC8G6tcFIvZ7l3AOfuJL9589oTTAesx/Rvix8d0xGHqmuFYZh6fjjoKLwydzOGdjEO6gpnsNLEIoJoeJxxdDu8Nq8Cgztbz7pUYYzhsuFyE3v8ID8ec6XMgeyngWjVpNB0fGPiZeWO6rIa1NWfZn6c4enLj3VUvxNIoRNESDm5T9vQL+jhlqikgbBDf5p3ndkX3UvlJni5gXzoBEFknEyr82w9PzL94CKFThBExsm0ogsyZa0d/738WJwxoF1G2iKFThBE4BjXO01wYg//F/zW8t8A/dWyjO7TBm1K3M9HcAL50Aki4rx9/QhMW7E922IY+OL20SgNWNHFk9kVA23Glt7tEmkTugQ82YgUOkFEnMGdmmOwTX7yTMOBtNwqdky99SS8Pm8L/vP5WnTNwdWpLh7WCQM7NsOADs0CbUfK5cIYG8sYW8UYW8MYG29R7nzGGGeMOYv7IQgi2ni0kHu0KcEF5c6XyAvL2uGMscCVOSCh0BljcQATAJwBoB+AixljhnyYjLESADcBmOW3kARB5DbqoGCBh7U7WwTW+QAACBNJREFUVZw8G/xKLZAryPy6wwCs4Zyv45xXA5gE4FxBuT8C+BuAIz7KRxBEBLj8hDIs+8MYtG/uPNOjHjcquqHEvcso9A4ANmu+VyjbkjDGhgDoxDn/wKoixtg1jLG5jLG5lZWVjoUlCCI3YYyhuDAPF5Z3AgBDKl63/PiYDhgiOZO2IeB5UJQxFgPwEIDL7cpyzp8A8AQAlJeXN6x3IYIgcN2o7rjmpG7Id+F66dC8MVoWF+B3Z/ZNbnvoosF+ipfzyCj0LQA6ab53VLaplAAYAOAz5bWmHYB3GWPncM7n+iUoQRC5D2MM+XF37o9G+XHM/7/THB2jX0A76sg8JucA6MkY68oYKwAwDsC76k7O+T7OeWvOeRnnvAzANwBImRMEkX3U1fkaiEa3Veic81oANwCYAmAFgFc558sYY/cxxs4JWkCCIAhCDikfOuf8QwAf6rbdY1J2lHexCIIgvCNadCLKUC4XgiAiTwPxuNDUf4JoiLx49XGo2HMo22IETgObV0QKnSAaIiMCznIYNmhiEUEQRI7T0Cx0UugEQUSehmGfk0InCIKIDKTQCYKILA3M40IKnSCI6KKmz20gY6Kk0AmCaAg0DI1OCp0gCCIikEInCCKykA+dIAgiYpAPnSAIIsehiUUEQRARo4EY6KTQCYKIMg3LRCeFThBE5CEfOkEQBJFTkEInCCKyxGMJFVeYF8+yJJmB8qETBBFZTu7TBteO6o5rRnbLtigZgRQ6QRCRJR5j+O3YPtkWI2OQy4UgCCIikEInCIKICKTQCYIgIgIpdIIgiIhACp0gCCIikEInCIKICKTQCYIgIgIpdIIgiIjAeJYSBjPGKgFsdHl4awA7fRTHL0guZ5BczgirXEB4ZYuiXF0456WiHVlT6F5gjM3lnJdnWw49JJczSC5nhFUuILyyNTS5yOVCEAQREUihEwRBRIRcVehPZFsAE0guZ5BczgirXEB4ZWtQcuWkD50gCIIwkqsWOkEQBKGDFDpBEERU4Jzn1D8AYwGsArAGwPiA2ngGwA4ASzXbWgL4BMBq5W8LZTsD8Igiz2IAQzTH/FwpvxrAzzXbhwJYohzzCBTXl41MnQBMB7AcwDIAN4VErkYAZgNYpMj1B2V7VwCzlLpeAVCgbC9Uvq9R9pdp6rpT2b4KwBg/rjmAOIAFAN4PmVwblN96IYC5YbiWynHNAbwOYCWAFQCOz7ZcAHorv5P6bz+Am7Mtl3LcLUj0+6UAXkbifshaHwtcAfv5D4mbcy2AbgAKkFAi/QJo5yQAQ5Cu0B9Qf1AA4wH8Tfl8JoCPlE40HMAszc25TvnbQvmsdrjZSlmmHHuGhEzt1Y4JoATAtwD6hUAuBqCJ8jlf6ajDAbwKYJyy/T8ArlU+XwfgP8rncQBeUT73U65noXJDrFWut6drDuBWAC8hpdDDItcGAK1127J6LZXjngNwtfK5AAkFn3W5dDpgG4Au2ZYLQAcA6wE01vSty7PZx7KupB1ezOMBTNF8vxPAnQG1VYZ0hb4KQHvlc3sAq5TPEwFcrC8H4GIAEzXbJyrb2gNYqdmeVs6BfO8AOC1McgEoAjAfwHFIzILL0183AFMAHK98zlPKMf21VMt5ueYAOgL4FMDJAN5X2sm6XEr5DTAq9KxeSwDNkFBQLExy6WQ5HcBXYZALCYW+GYkHRJ7Sx8Zks4/lmg9d/QFVKpRtmaAt53yr8nkbgLY2MlltrxBsl4YxVgbgGCSs4azLxRiLM8YWIuGm+gQJq2Iv57xWUFeyfWX/PgCtXMgrw8MA7gBQr3xvFRK5AIAD+JgxNo8xdo2yLdvXsiuASgD/ZYwtYIw9xRgrDoFcWsYh4dpAtuXinG8B8A8AmwBsRaLPzEMW+1iuKfRQwBOPS56NthljTQC8AeBmzvn+MMjFOa/jnA9GwiIeBiDrq/Iyxs4GsINzPi/bsphwIud8CIAzAFzPGDtJuzNL1zIPCVfj45zzYwB8j4QrI9tyAQAYYwUAzgHwmn5fNuRijLUAcC4SD8KjABQj4fPOGrmm0LcgMTio0lHZlgm2M8baA4Dyd4eNTFbbOwq228IYy0dCmb/IOX8zLHKpcM73IjFwezyA5oyxPEFdyfaV/c0A7HIhrx0jAJzDGNsAYBISbpd/hUAuAEnrDpzzHQDeQuJBmO1rWQGggnM+S/n+OhIKPttyqZwBYD7nfLvyPdtynQpgPee8knNeA+BNJPpd9vqYE/9Vtv8hYUGsQ+KJqA4S9A+orTKk+9D/jvQBmAeUz2chfQBmtrK9JRL+yBbKv/UAWir79AMwZ0rIwwD8D8DDuu3ZlqsUQHPlc2MAMwCcjYQVpR0Yuk75fD3SB4ZeVT73R/rA0DokBoU8X3MAo5AaFM26XEhYciWazzORsOyyei2V42YA6K18vleRKetyKcdOAnBFiPr+cUhEuBQpxz0H4MZs9rGsK2mn/5AYwf4WCT/tXQG18TISPrEaJKyWq5DwdX2KRLjTVE1HYAAmKPIsAVCuqedKJMKN1ug6YjkSYU5rAfwbcqFbJyLxSrkYqfCtM0Mg10AkwgIXK8feo2zvptwka5QOXqhsb6R8X6Ps76ap6y6l7VXQRBl4veZIV+hZl0uRYRFSoZ53Kduzei2V4wYDmKtcz7eRUHxhkKsYCWu2mWZbGOT6AxIhnksBPI+EUs5aH6Op/wRBEBEh13zoBEEQhAmk0AmCICICKXSCIIiIQAqdIAgiIpBCJwiCiAik0AmCICICKXSCIIiI8P8PbkzA30YRGAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGer6hJv7-zR",
        "colab_type": "code",
        "outputId": "2fd67156-f81b-487b-d3cc-76e3ecf304b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "plt.plot([i+1 for i in range((len(acc_list)))],acc_list)\n",
        "print(\"Accurancy:\")\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accurancy:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBTReWHxz4Ml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}