{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN_Avg_No_Relu2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamilo116/KNN/blob/master/KNN_Avg_No_Relu2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7ReM7FU-xs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import sys\n",
        "from random import shuffle\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms as transforms\n",
        "import timeit\n",
        "\n",
        "np.random.seed(4) \n",
        "torch.manual_seed(4) \n",
        "torch.cuda.manual_seed(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYIMZ8QyYewD",
        "colab_type": "code",
        "outputId": "27e34472-8674-419a-85d4-c74da5954514",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "! git clone https://github.com/wang-chen/kervolution.git \n",
        "\n",
        "sys.path.append(\"kervolution/\")\n",
        "from kervolution import Kerv2d\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'kervolution'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects:  16% (1/6)\u001b[K\rremote: Counting objects:  33% (2/6)\u001b[K\rremote: Counting objects:  50% (3/6)\u001b[K\rremote: Counting objects:  66% (4/6)\u001b[K\rremote: Counting objects:  83% (5/6)\u001b[K\rremote: Counting objects: 100% (6/6)\u001b[K\rremote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects:  16% (1/6)\u001b[K\rremote: Compressing objects:  33% (2/6)\u001b[K\rremote: Compressing objects:  50% (3/6)\u001b[K\rremote: Compressing objects:  66% (4/6)\u001b[K\rremote: Compressing objects:  83% (5/6)\u001b[K\rremote: Compressing objects: 100% (6/6)\u001b[K\rremote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "Unpacking objects:   1% (1/53)   \rUnpacking objects:   3% (2/53)   \rUnpacking objects:   5% (3/53)   \rUnpacking objects:   7% (4/53)   \rUnpacking objects:   9% (5/53)   \rUnpacking objects:  11% (6/53)   \rUnpacking objects:  13% (7/53)   \rUnpacking objects:  15% (8/53)   \rUnpacking objects:  16% (9/53)   \rremote: Total 53 (delta 2), reused 0 (delta 0), pack-reused 47\u001b[K\n",
            "Unpacking objects:  18% (10/53)   \rUnpacking objects:  20% (11/53)   \rUnpacking objects:  22% (12/53)   \rUnpacking objects:  24% (13/53)   \rUnpacking objects:  26% (14/53)   \rUnpacking objects:  28% (15/53)   \rUnpacking objects:  30% (16/53)   \rUnpacking objects:  32% (17/53)   \rUnpacking objects:  33% (18/53)   \rUnpacking objects:  35% (19/53)   \rUnpacking objects:  37% (20/53)   \rUnpacking objects:  39% (21/53)   \rUnpacking objects:  41% (22/53)   \rUnpacking objects:  43% (23/53)   \rUnpacking objects:  45% (24/53)   \rUnpacking objects:  47% (25/53)   \rUnpacking objects:  49% (26/53)   \rUnpacking objects:  50% (27/53)   \rUnpacking objects:  52% (28/53)   \rUnpacking objects:  54% (29/53)   \rUnpacking objects:  56% (30/53)   \rUnpacking objects:  58% (31/53)   \rUnpacking objects:  60% (32/53)   \rUnpacking objects:  62% (33/53)   \rUnpacking objects:  64% (34/53)   \rUnpacking objects:  66% (35/53)   \rUnpacking objects:  67% (36/53)   \rUnpacking objects:  69% (37/53)   \rUnpacking objects:  71% (38/53)   \rUnpacking objects:  73% (39/53)   \rUnpacking objects:  75% (40/53)   \rUnpacking objects:  77% (41/53)   \rUnpacking objects:  79% (42/53)   \rUnpacking objects:  81% (43/53)   \rUnpacking objects:  83% (44/53)   \rUnpacking objects:  84% (45/53)   \rUnpacking objects:  86% (46/53)   \rUnpacking objects:  88% (47/53)   \rUnpacking objects:  90% (48/53)   \rUnpacking objects:  92% (49/53)   \rUnpacking objects:  94% (50/53)   \rUnpacking objects:  96% (51/53)   \rUnpacking objects:  98% (52/53)   \rUnpacking objects: 100% (53/53)   \rUnpacking objects: 100% (53/53), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvbKg4VJXKY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LIMIT_IMAGES_NUM = 1000\n",
        "train_test_split_size = 0.2\n",
        "image_resize = (100, 100)\n",
        "batch_size = 64\n",
        "num_workers = 0\n",
        "\n",
        "in_channels = 3\n",
        "out_channels_1 = 16\n",
        "out_channels_2 = 24\n",
        "out_channels_3 = 32\n",
        "out_channels_4 = 48\n",
        "out_channels_5 = 64\n",
        "out_channels_6 = 128\n",
        "\n",
        "kernel_size = 3\n",
        "padding_1 = 1\n",
        "num_epochs = 80\n",
        "\n",
        "learning_rate = 0.0001\n",
        "weight_decay = 0.1\n",
        "\n",
        "MALIGNANT_DATASET = '/content/drive/My Drive/Colab_data/malignant/malignant/'\n",
        "BENIGN_DATASET = '/content/drive/My Drive/Colab_data/benign/benign/'\n",
        "DATA_FOLDER = '/content/drive/My Drive/Colab_data/'\n",
        "model_backup_path = os.path.join(DATA_FOLDER, 'backup_model_2') \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMOHez_kHZD6",
        "colab_type": "code",
        "outputId": "a6c53e96-4afe-4183-f6f3-5ecaed7352c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b8P1NdXfVdX",
        "colab_type": "code",
        "outputId": "9f419879-89ad-4eec-8a00-77f132a8a122",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "benign_file_list = sorted(os.listdir(BENIGN_DATASET))\n",
        "malignant_file_list = sorted(os.listdir(MALIGNANT_DATASET))\n",
        "shuffle(benign_file_list)\n",
        "shuffle(malignant_file_list)\n",
        "benign_file_list = benign_file_list[:LIMIT_IMAGES_NUM]\n",
        "malignant_file_list = malignant_file_list[:LIMIT_IMAGES_NUM]\n",
        "\n",
        "print(f\"Number of benign {len(benign_file_list)} images\")\n",
        "print(f\"Number of malignant {len(malignant_file_list)} images\")\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize(image_resize),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of benign 1000 images\n",
            "Number of malignant 1000 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGDQfal74BLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "benign_dict = {filename: 0 for filename in benign_file_list}\n",
        "malignant_dict = {filename: 1 for filename in malignant_file_list}\n",
        "img_class_dict = {**benign_dict , **malignant_dict}\n",
        "labeled_data = pd.Series(img_class_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvAAOqmVfVll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IsicDataset(Dataset):\n",
        "    def __init__(self, data_folder, labeled_data, \n",
        "                 transform=transforms.Compose([transforms.ToTensor()])):\n",
        "        self.labeled_data = labeled_data\n",
        "        self.transform = transform\n",
        "        self.data_folder = data_folder\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labeled_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        label = self.labeled_data[index]\n",
        "        if label == 0:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"benign\", \"benign\", index ))\n",
        "        else:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"malignant\", \"malignant\", index ))\n",
        "        image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "    @property\n",
        "    def labels(self):\n",
        "      return self.labeled_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSuYqjLAYrWA",
        "colab_type": "code",
        "outputId": "b4098b1f-2674-45ae-c373-a05d01abfc01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        " \n",
        "dataset = IsicDataset(DATA_FOLDER, labeled_data, transform=data_transforms)\n",
        "print(dataset.labels)\n",
        "\n",
        "X_train, X_test = train_test_split(dataset.labels, test_size=train_test_split_size)\n",
        "print(\"number of training data: \",len(X_train))\n",
        "print(\"number of testing  data: \",len(X_test))\n",
        "\n",
        "train_sampler = SubsetRandomSampler(list(X_train.index))\n",
        "valid_sampler = SubsetRandomSampler(list(X_test.index))\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ISIC_0002829.jpeg    0\n",
            "ISIC_0000233.jpeg    0\n",
            "ISIC_0000097.jpeg    0\n",
            "ISIC_0000750.jpeg    0\n",
            "ISIC_0001355.jpeg    0\n",
            "                    ..\n",
            "ISIC_0011733.jpeg    1\n",
            "ISIC_0011944.jpeg    1\n",
            "ISIC_0011456.jpeg    1\n",
            "ISIC_0010349.jpeg    1\n",
            "ISIC_0013414.jpeg    1\n",
            "Length: 2000, dtype: int64\n",
            "number of training data:  1600\n",
            "number of testing  data:  400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e8nFBR6Yug5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "def train(model, train_loader ,loss_fn, optimizer, num_epochs=1, starting_from_epoch=1):\n",
        "    total_loss =0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
        "        model.train()\n",
        "\n",
        "        for t, (x, y) in enumerate(train_loader):\n",
        "            x_var = Variable(x.type(gpu_dtype))\n",
        "            y_var = Variable(y.type(gpu_dtype).long())\n",
        "            scores = model(x_var)\n",
        "            loss = loss_fn(scores, y_var)\n",
        "            total_loss += loss.data\n",
        "            \n",
        "            if (t + 1) % print_every == 0:\n",
        "                avg_loss = total_loss/print_every\n",
        "                print('t = %d, avg_loss = %.4f' % (t + 1, avg_loss) )\n",
        "                avg_loss_list.append(avg_loss)\n",
        "                total_loss = 0\n",
        "                \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        acc = check_accuracy(model_gpu, valid_loader)\n",
        "        print('acc = %f' %(acc))\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model_gpu.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            }, model_backup_path)\n",
        "            \n",
        "def check_accuracy(model, loader):\n",
        "    print('Checking accuracy on test set')   \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval() \n",
        "    for x, y in loader:\n",
        "        x_var = Variable(x.type(gpu_dtype))\n",
        "\n",
        "        scores = model(x_var)\n",
        "        _, preds = scores.data.cpu().max(1)\n",
        "        num_correct += (preds == y).sum()\n",
        "        num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    acc_list.append(acc)\n",
        "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "    return acc\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggvpMu36Yw2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.size()\n",
        "        return x.view(N, -1)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgmexhBRZAK6",
        "colab_type": "code",
        "outputId": "eee67158-7a83-44d6-df79-08e33d364412",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "gpu_dtype = torch.cuda.FloatTensor\n",
        "\n",
        "print_every = 1\n",
        "\n",
        "\n",
        "'''\n",
        "Kerv2d\n",
        "kervolution with following options:\n",
        "kernel_type: [linear, polynomial, gaussian, etc.]\n",
        "default is convolution:\n",
        "          kernel_type --> linear,\n",
        "balance, power, gamma is valid only when the kernel_type is specified\n",
        "if learnable_kernel = True,  they just be the initial value of learable parameters\n",
        "if learnable_kernel = False, they are the value of kernel_type's parameter\n",
        "the parameter [power] cannot be learned due to integer limitation\n",
        "dilation (int or tuple, optional): Spacing between kernel\n",
        "elements. Default: 1\n",
        "groups (int, optional): Number of blocked connections from input\n",
        "channels to output channels. Default: 1\n",
        "bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n",
        "kernel_type (str), Default: 'linear'\n",
        "learnable_kernel (bool): Learnable kernel parameters.  Default: False \n",
        "balance: 0, 1\n",
        "power: 3, 4, 5\n",
        "gamma:\n",
        "'''\n",
        "\n",
        "\n",
        "model_base = nn.Sequential( \n",
        "                nn.Kerv2d(in_channels , out_channels_1, padding=padding_1, dilation=1, groups=1, bias=True, \n",
        "                          kernel_type='polynomial', kernel_size=kernel_size, learnable_kernel=True,\n",
        "                          kernel_regularizer=True, stride=1, balance=1, power=3, gamma=1\n",
        "                          ),\n",
        "                nn.BatchNorm2d(out_channels_1),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                #nn.Conv2d(out_channels_1 , out_channels_2, padding= padding_1, kernel_size=kernel_size, stride=1), \n",
        "                nn.Kerv2d(out_channels_1 , out_channels_2, padding=padding_1, dilation=1, groups=1, bias=True, \n",
        "                          kernel_type='polynomial', kernel_size=kernel_size, learnable_kernel=True,\n",
        "                          kernel_regularizer=True, stride=1, balance=1, power=3, gamma=1\n",
        "                          ),\n",
        "                nn.Dropout(0.1),\n",
        "                nn.BatchNorm2d(out_channels_2),\n",
        "                nn.AvgPool2d(2, stride=2), \n",
        "                #nn.Conv2d(out_channels_2 , out_channels_3, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.Kerv2d(out_channels_2 , out_channels_3, padding=padding_1, dilation=1, groups=1, bias=True, \n",
        "                          kernel_type='polynomial', kernel_size=kernel_size, learnable_kernel=True,\n",
        "                          kernel_regularizer=True, stride=1, balance=1, power=3, gamma=1\n",
        "                          ),\n",
        "                nn.BatchNorm2d(out_channels_3),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_3 , out_channels_4, padding= padding_1, kernel_size=kernel_size, stride=1),\n",
        "                nn.Dropout(0.1),  \n",
        "                nn.BatchNorm2d(out_channels_4),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_4 , out_channels_5, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.BatchNorm2d(out_channels_5),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_5 , out_channels_6, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.BatchNorm2d(out_channels_6),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                Flatten(),\n",
        "                nn.Dropout(0.5),\n",
        "                nn.Linear(128,64),\n",
        "                nn.Linear(64,2)\n",
        "            )\n",
        "model_gpu = model_base.type(gpu_dtype)\n",
        "print(model_gpu)\n",
        "loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) \n",
        "\n",
        "train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs)\n",
        "check_accuracy(model_gpu, valid_loader)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Kerv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (3): Kerv2d(16, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (4): Dropout(p=0.1, inplace=False)\n",
            "  (5): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (6): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (7): Kerv2d(24, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (10): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (11): Dropout(p=0.1, inplace=False)\n",
            "  (12): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (14): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (15): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (16): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (17): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (18): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (19): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (20): Flatten()\n",
            "  (21): Dropout(p=0.5, inplace=False)\n",
            "  (22): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (23): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n",
            "Starting epoch 1 / 80\n",
            "t = 1, avg_loss = 0.7739\n",
            "t = 2, avg_loss = 0.6728\n",
            "t = 3, avg_loss = 0.6799\n",
            "t = 4, avg_loss = 0.6793\n",
            "t = 5, avg_loss = 0.6699\n",
            "t = 6, avg_loss = 0.7013\n",
            "t = 7, avg_loss = 0.6807\n",
            "t = 8, avg_loss = 0.6593\n",
            "t = 9, avg_loss = 0.6496\n",
            "t = 10, avg_loss = 0.6316\n",
            "t = 11, avg_loss = 0.6839\n",
            "t = 12, avg_loss = 0.6367\n",
            "t = 13, avg_loss = 0.6801\n",
            "t = 14, avg_loss = 0.6715\n",
            "t = 15, avg_loss = 0.6606\n",
            "t = 16, avg_loss = 0.7511\n",
            "t = 17, avg_loss = 0.7042\n",
            "t = 18, avg_loss = 0.5819\n",
            "t = 19, avg_loss = 0.6569\n",
            "t = 20, avg_loss = 0.6130\n",
            "t = 21, avg_loss = 0.5977\n",
            "t = 22, avg_loss = 0.6560\n",
            "t = 23, avg_loss = 0.7071\n",
            "t = 24, avg_loss = 0.6088\n",
            "t = 25, avg_loss = 0.6090\n",
            "Checking accuracy on test set\n",
            "Got 217 / 400 correct (54.25)\n",
            "acc = 0.542500\n",
            "Starting epoch 2 / 80\n",
            "t = 1, avg_loss = 0.6995\n",
            "t = 2, avg_loss = 0.5574\n",
            "t = 3, avg_loss = 0.6172\n",
            "t = 4, avg_loss = 0.6341\n",
            "t = 5, avg_loss = 0.6256\n",
            "t = 6, avg_loss = 0.6379\n",
            "t = 7, avg_loss = 0.6020\n",
            "t = 8, avg_loss = 0.5794\n",
            "t = 9, avg_loss = 0.5608\n",
            "t = 10, avg_loss = 0.6081\n",
            "t = 11, avg_loss = 0.5910\n",
            "t = 12, avg_loss = 0.7354\n",
            "t = 13, avg_loss = 0.6175\n",
            "t = 14, avg_loss = 0.5961\n",
            "t = 15, avg_loss = 0.6806\n",
            "t = 16, avg_loss = 0.5319\n",
            "t = 17, avg_loss = 0.6443\n",
            "t = 18, avg_loss = 0.6336\n",
            "t = 19, avg_loss = 0.6095\n",
            "t = 20, avg_loss = 0.5537\n",
            "t = 21, avg_loss = 0.5744\n",
            "t = 22, avg_loss = 0.6385\n",
            "t = 23, avg_loss = 0.5857\n",
            "t = 24, avg_loss = 0.5777\n",
            "t = 25, avg_loss = 0.5928\n",
            "Checking accuracy on test set\n",
            "Got 277 / 400 correct (69.25)\n",
            "acc = 0.692500\n",
            "Starting epoch 3 / 80\n",
            "t = 1, avg_loss = 0.5702\n",
            "t = 2, avg_loss = 0.5197\n",
            "t = 3, avg_loss = 0.6338\n",
            "t = 4, avg_loss = 0.6021\n",
            "t = 5, avg_loss = 0.6030\n",
            "t = 6, avg_loss = 0.6079\n",
            "t = 7, avg_loss = 0.6144\n",
            "t = 8, avg_loss = 0.5598\n",
            "t = 9, avg_loss = 0.5470\n",
            "t = 10, avg_loss = 0.4946\n",
            "t = 11, avg_loss = 0.5618\n",
            "t = 12, avg_loss = 0.5517\n",
            "t = 13, avg_loss = 0.5286\n",
            "t = 14, avg_loss = 0.5559\n",
            "t = 15, avg_loss = 0.6288\n",
            "t = 16, avg_loss = 0.7431\n",
            "t = 17, avg_loss = 0.5640\n",
            "t = 18, avg_loss = 0.6782\n",
            "t = 19, avg_loss = 0.5683\n",
            "t = 20, avg_loss = 0.5881\n",
            "t = 21, avg_loss = 0.6706\n",
            "t = 22, avg_loss = 0.6106\n",
            "t = 23, avg_loss = 0.5682\n",
            "t = 24, avg_loss = 0.5357\n",
            "t = 25, avg_loss = 0.6210\n",
            "Checking accuracy on test set\n",
            "Got 284 / 400 correct (71.00)\n",
            "acc = 0.710000\n",
            "Starting epoch 4 / 80\n",
            "t = 1, avg_loss = 0.5737\n",
            "t = 2, avg_loss = 0.6521\n",
            "t = 3, avg_loss = 0.6636\n",
            "t = 4, avg_loss = 0.5822\n",
            "t = 5, avg_loss = 0.5691\n",
            "t = 6, avg_loss = 0.6009\n",
            "t = 7, avg_loss = 0.5545\n",
            "t = 8, avg_loss = 0.5790\n",
            "t = 9, avg_loss = 0.5261\n",
            "t = 10, avg_loss = 0.5556\n",
            "t = 11, avg_loss = 0.5769\n",
            "t = 12, avg_loss = 0.5534\n",
            "t = 13, avg_loss = 0.5245\n",
            "t = 14, avg_loss = 0.4536\n",
            "t = 15, avg_loss = 0.5264\n",
            "t = 16, avg_loss = 0.6423\n",
            "t = 17, avg_loss = 0.5857\n",
            "t = 18, avg_loss = 0.6011\n",
            "t = 19, avg_loss = 0.5788\n",
            "t = 20, avg_loss = 0.5237\n",
            "t = 21, avg_loss = 0.5463\n",
            "t = 22, avg_loss = 0.5589\n",
            "t = 23, avg_loss = 0.6234\n",
            "t = 24, avg_loss = 0.5232\n",
            "t = 25, avg_loss = 0.5245\n",
            "Checking accuracy on test set\n",
            "Got 309 / 400 correct (77.25)\n",
            "acc = 0.772500\n",
            "Starting epoch 5 / 80\n",
            "t = 1, avg_loss = 0.5984\n",
            "t = 2, avg_loss = 0.5406\n",
            "t = 3, avg_loss = 0.5438\n",
            "t = 4, avg_loss = 0.6462\n",
            "t = 5, avg_loss = 0.5427\n",
            "t = 6, avg_loss = 0.5160\n",
            "t = 7, avg_loss = 0.6310\n",
            "t = 8, avg_loss = 0.5064\n",
            "t = 9, avg_loss = 0.5685\n",
            "t = 10, avg_loss = 0.4399\n",
            "t = 11, avg_loss = 0.5936\n",
            "t = 12, avg_loss = 0.6187\n",
            "t = 13, avg_loss = 0.5197\n",
            "t = 14, avg_loss = 0.6263\n",
            "t = 15, avg_loss = 0.5971\n",
            "t = 16, avg_loss = 0.5195\n",
            "t = 17, avg_loss = 0.5140\n",
            "t = 18, avg_loss = 0.5177\n",
            "t = 19, avg_loss = 0.6278\n",
            "t = 20, avg_loss = 0.4227\n",
            "t = 21, avg_loss = 0.5761\n",
            "t = 22, avg_loss = 0.6129\n",
            "t = 23, avg_loss = 0.5513\n",
            "t = 24, avg_loss = 0.6417\n",
            "t = 25, avg_loss = 0.5619\n",
            "Checking accuracy on test set\n",
            "Got 302 / 400 correct (75.50)\n",
            "acc = 0.755000\n",
            "Starting epoch 6 / 80\n",
            "t = 1, avg_loss = 0.6010\n",
            "t = 2, avg_loss = 0.4365\n",
            "t = 3, avg_loss = 0.5740\n",
            "t = 4, avg_loss = 0.5159\n",
            "t = 5, avg_loss = 0.5266\n",
            "t = 6, avg_loss = 0.4967\n",
            "t = 7, avg_loss = 0.5544\n",
            "t = 8, avg_loss = 0.5823\n",
            "t = 9, avg_loss = 0.4867\n",
            "t = 10, avg_loss = 0.5248\n",
            "t = 11, avg_loss = 0.6226\n",
            "t = 12, avg_loss = 0.4665\n",
            "t = 13, avg_loss = 0.5894\n",
            "t = 14, avg_loss = 0.5163\n",
            "t = 15, avg_loss = 0.5067\n",
            "t = 16, avg_loss = 0.5125\n",
            "t = 17, avg_loss = 0.4838\n",
            "t = 18, avg_loss = 0.5292\n",
            "t = 19, avg_loss = 0.5970\n",
            "t = 20, avg_loss = 0.5786\n",
            "t = 21, avg_loss = 0.5258\n",
            "t = 22, avg_loss = 0.4482\n",
            "t = 23, avg_loss = 0.4635\n",
            "t = 24, avg_loss = 0.5042\n",
            "t = 25, avg_loss = 0.6432\n",
            "Checking accuracy on test set\n",
            "Got 300 / 400 correct (75.00)\n",
            "acc = 0.750000\n",
            "Starting epoch 7 / 80\n",
            "t = 1, avg_loss = 0.5343\n",
            "t = 2, avg_loss = 0.4760\n",
            "t = 3, avg_loss = 0.4637\n",
            "t = 4, avg_loss = 0.5785\n",
            "t = 5, avg_loss = 0.5451\n",
            "t = 6, avg_loss = 0.5111\n",
            "t = 7, avg_loss = 0.5577\n",
            "t = 8, avg_loss = 0.7037\n",
            "t = 9, avg_loss = 0.4337\n",
            "t = 10, avg_loss = 0.4866\n",
            "t = 11, avg_loss = 0.4494\n",
            "t = 12, avg_loss = 0.4920\n",
            "t = 13, avg_loss = 0.5925\n",
            "t = 14, avg_loss = 0.5343\n",
            "t = 15, avg_loss = 0.4713\n",
            "t = 16, avg_loss = 0.4325\n",
            "t = 17, avg_loss = 0.4897\n",
            "t = 18, avg_loss = 0.7135\n",
            "t = 19, avg_loss = 0.5321\n",
            "t = 20, avg_loss = 0.5164\n",
            "t = 21, avg_loss = 0.5521\n",
            "t = 22, avg_loss = 0.5233\n",
            "t = 23, avg_loss = 0.5300\n",
            "t = 24, avg_loss = 0.5324\n",
            "t = 25, avg_loss = 0.5921\n",
            "Checking accuracy on test set\n",
            "Got 322 / 400 correct (80.50)\n",
            "acc = 0.805000\n",
            "Starting epoch 8 / 80\n",
            "t = 1, avg_loss = 0.4999\n",
            "t = 2, avg_loss = 0.3558\n",
            "t = 3, avg_loss = 0.6057\n",
            "t = 4, avg_loss = 0.4141\n",
            "t = 5, avg_loss = 0.4691\n",
            "t = 6, avg_loss = 0.5305\n",
            "t = 7, avg_loss = 0.5092\n",
            "t = 8, avg_loss = 0.5455\n",
            "t = 9, avg_loss = 0.4721\n",
            "t = 10, avg_loss = 0.5193\n",
            "t = 11, avg_loss = 0.5960\n",
            "t = 12, avg_loss = 0.6031\n",
            "t = 13, avg_loss = 0.5156\n",
            "t = 14, avg_loss = 0.4614\n",
            "t = 15, avg_loss = 0.4926\n",
            "t = 16, avg_loss = 0.5280\n",
            "t = 17, avg_loss = 0.4710\n",
            "t = 18, avg_loss = 0.5088\n",
            "t = 19, avg_loss = 0.5620\n",
            "t = 20, avg_loss = 0.4801\n",
            "t = 21, avg_loss = 0.6140\n",
            "t = 22, avg_loss = 0.4762\n",
            "t = 23, avg_loss = 0.4999\n",
            "t = 24, avg_loss = 0.4409\n",
            "t = 25, avg_loss = 0.5001\n",
            "Checking accuracy on test set\n",
            "Got 315 / 400 correct (78.75)\n",
            "acc = 0.787500\n",
            "Starting epoch 9 / 80\n",
            "t = 1, avg_loss = 0.5326\n",
            "t = 2, avg_loss = 0.4585\n",
            "t = 3, avg_loss = 0.4412\n",
            "t = 4, avg_loss = 0.5242\n",
            "t = 5, avg_loss = 0.4761\n",
            "t = 6, avg_loss = 0.4399\n",
            "t = 7, avg_loss = 0.4776\n",
            "t = 8, avg_loss = 0.4587\n",
            "t = 9, avg_loss = 0.4094\n",
            "t = 10, avg_loss = 0.5706\n",
            "t = 11, avg_loss = 0.5020\n",
            "t = 12, avg_loss = 0.4778\n",
            "t = 13, avg_loss = 0.5871\n",
            "t = 14, avg_loss = 0.4799\n",
            "t = 15, avg_loss = 0.5382\n",
            "t = 16, avg_loss = 0.5727\n",
            "t = 17, avg_loss = 0.5967\n",
            "t = 18, avg_loss = 0.4974\n",
            "t = 19, avg_loss = 0.4378\n",
            "t = 20, avg_loss = 0.5211\n",
            "t = 21, avg_loss = 0.4732\n",
            "t = 22, avg_loss = 0.4886\n",
            "t = 23, avg_loss = 0.4565\n",
            "t = 24, avg_loss = 0.4804\n",
            "t = 25, avg_loss = 0.5808\n",
            "Checking accuracy on test set\n",
            "Got 309 / 400 correct (77.25)\n",
            "acc = 0.772500\n",
            "Starting epoch 10 / 80\n",
            "t = 1, avg_loss = 0.5197\n",
            "t = 2, avg_loss = 0.4694\n",
            "t = 3, avg_loss = 0.4132\n",
            "t = 4, avg_loss = 0.4816\n",
            "t = 5, avg_loss = 0.4829\n",
            "t = 6, avg_loss = 0.4611\n",
            "t = 7, avg_loss = 0.5194\n",
            "t = 8, avg_loss = 0.3500\n",
            "t = 9, avg_loss = 0.4811\n",
            "t = 10, avg_loss = 0.4714\n",
            "t = 11, avg_loss = 0.5493\n",
            "t = 12, avg_loss = 0.4221\n",
            "t = 13, avg_loss = 0.4054\n",
            "t = 14, avg_loss = 0.4991\n",
            "t = 15, avg_loss = 0.4334\n",
            "t = 16, avg_loss = 0.4193\n",
            "t = 17, avg_loss = 0.5059\n",
            "t = 18, avg_loss = 0.4629\n",
            "t = 19, avg_loss = 0.5192\n",
            "t = 20, avg_loss = 0.4376\n",
            "t = 21, avg_loss = 0.5902\n",
            "t = 22, avg_loss = 0.5529\n",
            "t = 23, avg_loss = 0.5782\n",
            "t = 24, avg_loss = 0.3987\n",
            "t = 25, avg_loss = 0.4005\n",
            "Checking accuracy on test set\n",
            "Got 319 / 400 correct (79.75)\n",
            "acc = 0.797500\n",
            "Starting epoch 11 / 80\n",
            "t = 1, avg_loss = 0.2991\n",
            "t = 2, avg_loss = 0.4595\n",
            "t = 3, avg_loss = 0.5177\n",
            "t = 4, avg_loss = 0.4228\n",
            "t = 5, avg_loss = 0.6884\n",
            "t = 6, avg_loss = 0.4170\n",
            "t = 7, avg_loss = 0.4753\n",
            "t = 8, avg_loss = 0.3976\n",
            "t = 9, avg_loss = 0.4248\n",
            "t = 10, avg_loss = 0.4669\n",
            "t = 11, avg_loss = 0.4668\n",
            "t = 12, avg_loss = 0.4133\n",
            "t = 13, avg_loss = 0.3968\n",
            "t = 14, avg_loss = 0.5307\n",
            "t = 15, avg_loss = 0.4856\n",
            "t = 16, avg_loss = 0.3570\n",
            "t = 17, avg_loss = 0.4725\n",
            "t = 18, avg_loss = 0.5066\n",
            "t = 19, avg_loss = 0.4914\n",
            "t = 20, avg_loss = 0.5674\n",
            "t = 21, avg_loss = 0.5427\n",
            "t = 22, avg_loss = 0.3993\n",
            "t = 23, avg_loss = 0.4197\n",
            "t = 24, avg_loss = 0.4043\n",
            "t = 25, avg_loss = 0.4940\n",
            "Checking accuracy on test set\n",
            "Got 321 / 400 correct (80.25)\n",
            "acc = 0.802500\n",
            "Starting epoch 12 / 80\n",
            "t = 1, avg_loss = 0.5706\n",
            "t = 2, avg_loss = 0.5256\n",
            "t = 3, avg_loss = 0.4965\n",
            "t = 4, avg_loss = 0.3743\n",
            "t = 5, avg_loss = 0.5155\n",
            "t = 6, avg_loss = 0.3876\n",
            "t = 7, avg_loss = 0.5110\n",
            "t = 8, avg_loss = 0.3805\n",
            "t = 9, avg_loss = 0.5507\n",
            "t = 10, avg_loss = 0.4841\n",
            "t = 11, avg_loss = 0.4689\n",
            "t = 12, avg_loss = 0.4852\n",
            "t = 13, avg_loss = 0.4994\n",
            "t = 14, avg_loss = 0.4870\n",
            "t = 15, avg_loss = 0.4877\n",
            "t = 16, avg_loss = 0.3989\n",
            "t = 17, avg_loss = 0.6266\n",
            "t = 18, avg_loss = 0.4862\n",
            "t = 19, avg_loss = 0.3690\n",
            "t = 20, avg_loss = 0.4422\n",
            "t = 21, avg_loss = 0.4417\n",
            "t = 22, avg_loss = 0.4436\n",
            "t = 23, avg_loss = 0.3705\n",
            "t = 24, avg_loss = 0.5102\n",
            "t = 25, avg_loss = 0.6252\n",
            "Checking accuracy on test set\n",
            "Got 316 / 400 correct (79.00)\n",
            "acc = 0.790000\n",
            "Starting epoch 13 / 80\n",
            "t = 1, avg_loss = 0.3410\n",
            "t = 2, avg_loss = 0.4124\n",
            "t = 3, avg_loss = 0.3559\n",
            "t = 4, avg_loss = 0.6036\n",
            "t = 5, avg_loss = 0.5044\n",
            "t = 6, avg_loss = 0.4536\n",
            "t = 7, avg_loss = 0.4576\n",
            "t = 8, avg_loss = 0.5352\n",
            "t = 9, avg_loss = 0.4856\n",
            "t = 10, avg_loss = 0.3807\n",
            "t = 11, avg_loss = 0.4650\n",
            "t = 12, avg_loss = 0.5232\n",
            "t = 13, avg_loss = 0.5532\n",
            "t = 14, avg_loss = 0.3982\n",
            "t = 15, avg_loss = 0.3956\n",
            "t = 16, avg_loss = 0.4540\n",
            "t = 17, avg_loss = 0.4295\n",
            "t = 18, avg_loss = 0.4494\n",
            "t = 19, avg_loss = 0.5118\n",
            "t = 20, avg_loss = 0.3677\n",
            "t = 21, avg_loss = 0.4735\n",
            "t = 22, avg_loss = 0.4023\n",
            "t = 23, avg_loss = 0.4769\n",
            "t = 24, avg_loss = 0.5161\n",
            "t = 25, avg_loss = 0.5612\n",
            "Checking accuracy on test set\n",
            "Got 332 / 400 correct (83.00)\n",
            "acc = 0.830000\n",
            "Starting epoch 14 / 80\n",
            "t = 1, avg_loss = 0.4352\n",
            "t = 2, avg_loss = 0.4093\n",
            "t = 3, avg_loss = 0.5253\n",
            "t = 4, avg_loss = 0.3206\n",
            "t = 5, avg_loss = 0.3766\n",
            "t = 6, avg_loss = 0.3394\n",
            "t = 7, avg_loss = 0.5248\n",
            "t = 8, avg_loss = 0.3866\n",
            "t = 9, avg_loss = 0.4630\n",
            "t = 10, avg_loss = 0.7508\n",
            "t = 11, avg_loss = 0.4344\n",
            "t = 12, avg_loss = 0.4625\n",
            "t = 13, avg_loss = 0.3681\n",
            "t = 14, avg_loss = 0.4228\n",
            "t = 15, avg_loss = 0.5799\n",
            "t = 16, avg_loss = 0.5208\n",
            "t = 17, avg_loss = 0.6002\n",
            "t = 18, avg_loss = 0.4376\n",
            "t = 19, avg_loss = 0.5177\n",
            "t = 20, avg_loss = 0.3590\n",
            "t = 21, avg_loss = 0.4767\n",
            "t = 22, avg_loss = 0.6458\n",
            "t = 23, avg_loss = 0.5100\n",
            "t = 24, avg_loss = 0.4104\n",
            "t = 25, avg_loss = 0.4065\n",
            "Checking accuracy on test set\n",
            "Got 318 / 400 correct (79.50)\n",
            "acc = 0.795000\n",
            "Starting epoch 15 / 80\n",
            "t = 1, avg_loss = 0.5122\n",
            "t = 2, avg_loss = 0.4123\n",
            "t = 3, avg_loss = 0.5535\n",
            "t = 4, avg_loss = 0.4832\n",
            "t = 5, avg_loss = 0.4253\n",
            "t = 6, avg_loss = 0.4948\n",
            "t = 7, avg_loss = 0.4439\n",
            "t = 8, avg_loss = 0.4963\n",
            "t = 9, avg_loss = 0.4125\n",
            "t = 10, avg_loss = 0.5177\n",
            "t = 11, avg_loss = 0.4339\n",
            "t = 12, avg_loss = 0.5455\n",
            "t = 13, avg_loss = 0.4139\n",
            "t = 14, avg_loss = 0.3941\n",
            "t = 15, avg_loss = 0.4637\n",
            "t = 16, avg_loss = 0.5613\n",
            "t = 17, avg_loss = 0.4037\n",
            "t = 18, avg_loss = 0.3566\n",
            "t = 19, avg_loss = 0.4869\n",
            "t = 20, avg_loss = 0.4701\n",
            "t = 21, avg_loss = 0.5405\n",
            "t = 22, avg_loss = 0.4204\n",
            "t = 23, avg_loss = 0.3867\n",
            "t = 24, avg_loss = 0.5748\n",
            "t = 25, avg_loss = 0.3853\n",
            "Checking accuracy on test set\n",
            "Got 337 / 400 correct (84.25)\n",
            "acc = 0.842500\n",
            "Starting epoch 16 / 80\n",
            "t = 1, avg_loss = 0.4056\n",
            "t = 2, avg_loss = 0.3491\n",
            "t = 3, avg_loss = 0.5328\n",
            "t = 4, avg_loss = 0.4169\n",
            "t = 5, avg_loss = 0.5372\n",
            "t = 6, avg_loss = 0.3884\n",
            "t = 7, avg_loss = 0.4473\n",
            "t = 8, avg_loss = 0.4901\n",
            "t = 9, avg_loss = 0.4332\n",
            "t = 10, avg_loss = 0.3911\n",
            "t = 11, avg_loss = 0.5072\n",
            "t = 12, avg_loss = 0.4720\n",
            "t = 13, avg_loss = 0.5207\n",
            "t = 14, avg_loss = 0.4726\n",
            "t = 15, avg_loss = 0.5344\n",
            "t = 16, avg_loss = 0.4144\n",
            "t = 17, avg_loss = 0.4615\n",
            "t = 18, avg_loss = 0.4219\n",
            "t = 19, avg_loss = 0.4415\n",
            "t = 20, avg_loss = 0.4405\n",
            "t = 21, avg_loss = 0.3982\n",
            "t = 22, avg_loss = 0.3677\n",
            "t = 23, avg_loss = 0.4889\n",
            "t = 24, avg_loss = 0.5068\n",
            "t = 25, avg_loss = 0.4009\n",
            "Checking accuracy on test set\n",
            "Got 329 / 400 correct (82.25)\n",
            "acc = 0.822500\n",
            "Starting epoch 17 / 80\n",
            "t = 1, avg_loss = 0.3480\n",
            "t = 2, avg_loss = 0.4560\n",
            "t = 3, avg_loss = 0.4349\n",
            "t = 4, avg_loss = 0.4499\n",
            "t = 5, avg_loss = 0.5859\n",
            "t = 6, avg_loss = 0.6225\n",
            "t = 7, avg_loss = 0.4203\n",
            "t = 8, avg_loss = 0.7032\n",
            "t = 9, avg_loss = 0.4571\n",
            "t = 10, avg_loss = 0.4712\n",
            "t = 11, avg_loss = 0.3646\n",
            "t = 12, avg_loss = 0.5234\n",
            "t = 13, avg_loss = 0.3919\n",
            "t = 14, avg_loss = 0.4405\n",
            "t = 15, avg_loss = 0.4512\n",
            "t = 16, avg_loss = 0.4871\n",
            "t = 17, avg_loss = 0.3646\n",
            "t = 18, avg_loss = 0.4093\n",
            "t = 19, avg_loss = 0.3882\n",
            "t = 20, avg_loss = 0.4054\n",
            "t = 21, avg_loss = 0.5014\n",
            "t = 22, avg_loss = 0.5307\n",
            "t = 23, avg_loss = 0.5969\n",
            "t = 24, avg_loss = 0.5480\n",
            "t = 25, avg_loss = 0.4982\n",
            "Checking accuracy on test set\n",
            "Got 331 / 400 correct (82.75)\n",
            "acc = 0.827500\n",
            "Starting epoch 18 / 80\n",
            "t = 1, avg_loss = 0.3877\n",
            "t = 2, avg_loss = 0.3698\n",
            "t = 3, avg_loss = 0.4240\n",
            "t = 4, avg_loss = 0.4502\n",
            "t = 5, avg_loss = 0.6642\n",
            "t = 6, avg_loss = 0.5470\n",
            "t = 7, avg_loss = 0.5756\n",
            "t = 8, avg_loss = 0.5158\n",
            "t = 9, avg_loss = 0.4815\n",
            "t = 10, avg_loss = 0.5237\n",
            "t = 11, avg_loss = 0.3894\n",
            "t = 12, avg_loss = 0.4451\n",
            "t = 13, avg_loss = 0.4821\n",
            "t = 14, avg_loss = 0.4008\n",
            "t = 15, avg_loss = 0.4304\n",
            "t = 16, avg_loss = 0.4507\n",
            "t = 17, avg_loss = 0.4321\n",
            "t = 18, avg_loss = 0.3810\n",
            "t = 19, avg_loss = 0.4194\n",
            "t = 20, avg_loss = 0.4650\n",
            "t = 21, avg_loss = 0.4985\n",
            "t = 22, avg_loss = 0.3715\n",
            "t = 23, avg_loss = 0.4049\n",
            "t = 24, avg_loss = 0.4460\n",
            "t = 25, avg_loss = 0.3632\n",
            "Checking accuracy on test set\n",
            "Got 339 / 400 correct (84.75)\n",
            "acc = 0.847500\n",
            "Starting epoch 19 / 80\n",
            "t = 1, avg_loss = 0.3417\n",
            "t = 2, avg_loss = 0.4309\n",
            "t = 3, avg_loss = 0.3939\n",
            "t = 4, avg_loss = 0.4746\n",
            "t = 5, avg_loss = 0.4095\n",
            "t = 6, avg_loss = 0.3998\n",
            "t = 7, avg_loss = 0.4053\n",
            "t = 8, avg_loss = 0.4057\n",
            "t = 9, avg_loss = 0.5197\n",
            "t = 10, avg_loss = 0.7131\n",
            "t = 11, avg_loss = 0.3889\n",
            "t = 12, avg_loss = 0.5194\n",
            "t = 13, avg_loss = 0.4888\n",
            "t = 14, avg_loss = 0.3393\n",
            "t = 15, avg_loss = 0.4065\n",
            "t = 16, avg_loss = 0.3772\n",
            "t = 17, avg_loss = 0.4086\n",
            "t = 18, avg_loss = 0.5274\n",
            "t = 19, avg_loss = 0.4967\n",
            "t = 20, avg_loss = 0.4722\n",
            "t = 21, avg_loss = 0.4243\n",
            "t = 22, avg_loss = 0.4563\n",
            "t = 23, avg_loss = 0.3551\n",
            "t = 24, avg_loss = 0.4602\n",
            "t = 25, avg_loss = 0.3285\n",
            "Checking accuracy on test set\n",
            "Got 339 / 400 correct (84.75)\n",
            "acc = 0.847500\n",
            "Starting epoch 20 / 80\n",
            "t = 1, avg_loss = 0.4958\n",
            "t = 2, avg_loss = 0.5036\n",
            "t = 3, avg_loss = 0.4308\n",
            "t = 4, avg_loss = 0.4812\n",
            "t = 5, avg_loss = 0.3308\n",
            "t = 6, avg_loss = 0.4158\n",
            "t = 7, avg_loss = 0.4327\n",
            "t = 8, avg_loss = 0.3968\n",
            "t = 9, avg_loss = 0.3754\n",
            "t = 10, avg_loss = 0.4032\n",
            "t = 11, avg_loss = 0.4184\n",
            "t = 12, avg_loss = 0.5624\n",
            "t = 13, avg_loss = 0.4400\n",
            "t = 14, avg_loss = 0.4583\n",
            "t = 15, avg_loss = 0.3753\n",
            "t = 16, avg_loss = 0.3919\n",
            "t = 17, avg_loss = 0.4151\n",
            "t = 18, avg_loss = 0.4261\n",
            "t = 19, avg_loss = 0.3901\n",
            "t = 20, avg_loss = 0.5571\n",
            "t = 21, avg_loss = 0.3685\n",
            "t = 22, avg_loss = 0.3665\n",
            "t = 23, avg_loss = 0.3601\n",
            "t = 24, avg_loss = 0.4968\n",
            "t = 25, avg_loss = 0.4250\n",
            "Checking accuracy on test set\n",
            "Got 329 / 400 correct (82.25)\n",
            "acc = 0.822500\n",
            "Starting epoch 21 / 80\n",
            "t = 1, avg_loss = 0.3124\n",
            "t = 2, avg_loss = 0.5157\n",
            "t = 3, avg_loss = 0.5448\n",
            "t = 4, avg_loss = 0.5013\n",
            "t = 5, avg_loss = 0.3568\n",
            "t = 6, avg_loss = 0.4029\n",
            "t = 7, avg_loss = 0.4751\n",
            "t = 8, avg_loss = 0.4529\n",
            "t = 9, avg_loss = 0.4435\n",
            "t = 10, avg_loss = 0.5433\n",
            "t = 11, avg_loss = 0.3849\n",
            "t = 12, avg_loss = 0.4478\n",
            "t = 13, avg_loss = 0.3310\n",
            "t = 14, avg_loss = 0.3264\n",
            "t = 15, avg_loss = 0.4407\n",
            "t = 16, avg_loss = 0.5100\n",
            "t = 17, avg_loss = 0.4028\n",
            "t = 18, avg_loss = 0.3274\n",
            "t = 19, avg_loss = 0.3867\n",
            "t = 20, avg_loss = 0.3722\n",
            "t = 21, avg_loss = 0.4215\n",
            "t = 22, avg_loss = 0.4192\n",
            "t = 23, avg_loss = 0.4710\n",
            "t = 24, avg_loss = 0.3232\n",
            "t = 25, avg_loss = 0.4253\n",
            "Checking accuracy on test set\n",
            "Got 332 / 400 correct (83.00)\n",
            "acc = 0.830000\n",
            "Starting epoch 22 / 80\n",
            "t = 1, avg_loss = 0.4509\n",
            "t = 2, avg_loss = 0.5083\n",
            "t = 3, avg_loss = 0.4293\n",
            "t = 4, avg_loss = 0.4656\n",
            "t = 5, avg_loss = 0.4445\n",
            "t = 6, avg_loss = 0.3741\n",
            "t = 7, avg_loss = 0.4996\n",
            "t = 8, avg_loss = 0.4275\n",
            "t = 9, avg_loss = 0.5628\n",
            "t = 10, avg_loss = 0.3020\n",
            "t = 11, avg_loss = 0.4631\n",
            "t = 12, avg_loss = 0.4900\n",
            "t = 13, avg_loss = 0.4350\n",
            "t = 14, avg_loss = 0.3755\n",
            "t = 15, avg_loss = 0.3731\n",
            "t = 16, avg_loss = 0.3997\n",
            "t = 17, avg_loss = 0.4272\n",
            "t = 18, avg_loss = 0.4267\n",
            "t = 19, avg_loss = 0.4833\n",
            "t = 20, avg_loss = 0.3976\n",
            "t = 21, avg_loss = 0.4631\n",
            "t = 22, avg_loss = 0.3164\n",
            "t = 23, avg_loss = 0.3527\n",
            "t = 24, avg_loss = 0.4746\n",
            "t = 25, avg_loss = 0.3479\n",
            "Checking accuracy on test set\n",
            "Got 334 / 400 correct (83.50)\n",
            "acc = 0.835000\n",
            "Starting epoch 23 / 80\n",
            "t = 1, avg_loss = 0.3388\n",
            "t = 2, avg_loss = 0.4770\n",
            "t = 3, avg_loss = 0.4336\n",
            "t = 4, avg_loss = 0.3891\n",
            "t = 5, avg_loss = 0.5116\n",
            "t = 6, avg_loss = 0.3424\n",
            "t = 7, avg_loss = 0.3434\n",
            "t = 8, avg_loss = 0.4586\n",
            "t = 9, avg_loss = 0.4591\n",
            "t = 10, avg_loss = 0.4239\n",
            "t = 11, avg_loss = 0.5076\n",
            "t = 12, avg_loss = 0.4652\n",
            "t = 13, avg_loss = 0.3862\n",
            "t = 14, avg_loss = 0.4012\n",
            "t = 15, avg_loss = 0.4919\n",
            "t = 16, avg_loss = 0.3997\n",
            "t = 17, avg_loss = 0.3757\n",
            "t = 18, avg_loss = 0.4387\n",
            "t = 19, avg_loss = 0.3185\n",
            "t = 20, avg_loss = 0.3341\n",
            "t = 21, avg_loss = 0.4182\n",
            "t = 22, avg_loss = 0.2945\n",
            "t = 23, avg_loss = 0.3555\n",
            "t = 24, avg_loss = 0.4252\n",
            "t = 25, avg_loss = 0.2913\n",
            "Checking accuracy on test set\n",
            "Got 341 / 400 correct (85.25)\n",
            "acc = 0.852500\n",
            "Starting epoch 24 / 80\n",
            "t = 1, avg_loss = 0.3631\n",
            "t = 2, avg_loss = 0.3115\n",
            "t = 3, avg_loss = 0.3837\n",
            "t = 4, avg_loss = 0.2970\n",
            "t = 5, avg_loss = 0.3153\n",
            "t = 6, avg_loss = 0.3162\n",
            "t = 7, avg_loss = 0.4085\n",
            "t = 8, avg_loss = 0.3473\n",
            "t = 9, avg_loss = 0.3837\n",
            "t = 10, avg_loss = 0.3950\n",
            "t = 11, avg_loss = 0.4038\n",
            "t = 12, avg_loss = 0.5341\n",
            "t = 13, avg_loss = 0.3672\n",
            "t = 14, avg_loss = 0.4950\n",
            "t = 15, avg_loss = 0.4065\n",
            "t = 16, avg_loss = 0.4872\n",
            "t = 17, avg_loss = 0.4201\n",
            "t = 18, avg_loss = 0.3975\n",
            "t = 19, avg_loss = 0.4489\n",
            "t = 20, avg_loss = 0.6362\n",
            "t = 21, avg_loss = 0.4121\n",
            "t = 22, avg_loss = 0.3389\n",
            "t = 23, avg_loss = 0.4202\n",
            "t = 24, avg_loss = 0.5222\n",
            "t = 25, avg_loss = 0.5289\n",
            "Checking accuracy on test set\n",
            "Got 338 / 400 correct (84.50)\n",
            "acc = 0.845000\n",
            "Starting epoch 25 / 80\n",
            "t = 1, avg_loss = 0.4475\n",
            "t = 2, avg_loss = 0.2965\n",
            "t = 3, avg_loss = 0.3789\n",
            "t = 4, avg_loss = 0.5732\n",
            "t = 5, avg_loss = 0.4196\n",
            "t = 6, avg_loss = 0.4402\n",
            "t = 7, avg_loss = 0.5639\n",
            "t = 8, avg_loss = 0.4268\n",
            "t = 9, avg_loss = 0.5068\n",
            "t = 10, avg_loss = 0.3369\n",
            "t = 11, avg_loss = 0.4344\n",
            "t = 12, avg_loss = 0.4434\n",
            "t = 13, avg_loss = 0.4658\n",
            "t = 14, avg_loss = 0.3740\n",
            "t = 15, avg_loss = 0.3547\n",
            "t = 16, avg_loss = 0.4368\n",
            "t = 17, avg_loss = 0.3557\n",
            "t = 18, avg_loss = 0.4740\n",
            "t = 19, avg_loss = 0.4843\n",
            "t = 20, avg_loss = 0.6173\n",
            "t = 21, avg_loss = 0.3385\n",
            "t = 22, avg_loss = 0.3156\n",
            "t = 23, avg_loss = 0.3364\n",
            "t = 24, avg_loss = 0.3979\n",
            "t = 25, avg_loss = 0.4288\n",
            "Checking accuracy on test set\n",
            "Got 333 / 400 correct (83.25)\n",
            "acc = 0.832500\n",
            "Starting epoch 26 / 80\n",
            "t = 1, avg_loss = 0.3689\n",
            "t = 2, avg_loss = 0.3491\n",
            "t = 3, avg_loss = 0.3998\n",
            "t = 4, avg_loss = 0.4248\n",
            "t = 5, avg_loss = 0.3596\n",
            "t = 6, avg_loss = 0.3331\n",
            "t = 7, avg_loss = 0.3605\n",
            "t = 8, avg_loss = 0.3959\n",
            "t = 9, avg_loss = 0.4445\n",
            "t = 10, avg_loss = 0.4598\n",
            "t = 11, avg_loss = 0.4764\n",
            "t = 12, avg_loss = 0.3553\n",
            "t = 13, avg_loss = 0.3094\n",
            "t = 14, avg_loss = 0.4502\n",
            "t = 15, avg_loss = 0.4153\n",
            "t = 16, avg_loss = 0.7052\n",
            "t = 17, avg_loss = 0.4138\n",
            "t = 18, avg_loss = 0.3914\n",
            "t = 19, avg_loss = 0.4559\n",
            "t = 20, avg_loss = 0.4028\n",
            "t = 21, avg_loss = 0.4650\n",
            "t = 22, avg_loss = 0.3933\n",
            "t = 23, avg_loss = 0.4906\n",
            "t = 24, avg_loss = 0.5116\n",
            "t = 25, avg_loss = 0.3698\n",
            "Checking accuracy on test set\n",
            "Got 330 / 400 correct (82.50)\n",
            "acc = 0.825000\n",
            "Starting epoch 27 / 80\n",
            "t = 1, avg_loss = 0.4216\n",
            "t = 2, avg_loss = 0.3363\n",
            "t = 3, avg_loss = 0.4084\n",
            "t = 4, avg_loss = 0.4342\n",
            "t = 5, avg_loss = 0.4819\n",
            "t = 6, avg_loss = 0.4952\n",
            "t = 7, avg_loss = 0.3377\n",
            "t = 8, avg_loss = 0.3374\n",
            "t = 9, avg_loss = 0.4141\n",
            "t = 10, avg_loss = 0.3570\n",
            "t = 11, avg_loss = 0.3516\n",
            "t = 12, avg_loss = 0.4464\n",
            "t = 13, avg_loss = 0.3782\n",
            "t = 14, avg_loss = 0.5154\n",
            "t = 15, avg_loss = 0.3786\n",
            "t = 16, avg_loss = 0.3097\n",
            "t = 17, avg_loss = 0.5300\n",
            "t = 18, avg_loss = 0.4444\n",
            "t = 19, avg_loss = 0.3587\n",
            "t = 20, avg_loss = 0.3373\n",
            "t = 21, avg_loss = 0.4213\n",
            "t = 22, avg_loss = 0.3106\n",
            "t = 23, avg_loss = 0.6104\n",
            "t = 24, avg_loss = 0.5023\n",
            "t = 25, avg_loss = 0.4242\n",
            "Checking accuracy on test set\n",
            "Got 340 / 400 correct (85.00)\n",
            "acc = 0.850000\n",
            "Starting epoch 28 / 80\n",
            "t = 1, avg_loss = 0.3814\n",
            "t = 2, avg_loss = 0.4187\n",
            "t = 3, avg_loss = 0.3428\n",
            "t = 4, avg_loss = 0.3716\n",
            "t = 5, avg_loss = 0.5092\n",
            "t = 6, avg_loss = 0.4707\n",
            "t = 7, avg_loss = 0.3907\n",
            "t = 8, avg_loss = 0.3912\n",
            "t = 9, avg_loss = 0.5353\n",
            "t = 10, avg_loss = 0.3796\n",
            "t = 11, avg_loss = 0.3493\n",
            "t = 12, avg_loss = 0.5265\n",
            "t = 13, avg_loss = 0.4463\n",
            "t = 14, avg_loss = 0.4070\n",
            "t = 15, avg_loss = 0.4017\n",
            "t = 16, avg_loss = 0.4655\n",
            "t = 17, avg_loss = 0.3710\n",
            "t = 18, avg_loss = 0.4797\n",
            "t = 19, avg_loss = 0.3562\n",
            "t = 20, avg_loss = 0.3258\n",
            "t = 21, avg_loss = 0.3682\n",
            "t = 22, avg_loss = 0.3636\n",
            "t = 23, avg_loss = 0.4452\n",
            "t = 24, avg_loss = 0.4504\n",
            "t = 25, avg_loss = 0.4616\n",
            "Checking accuracy on test set\n",
            "Got 339 / 400 correct (84.75)\n",
            "acc = 0.847500\n",
            "Starting epoch 29 / 80\n",
            "t = 1, avg_loss = 0.3577\n",
            "t = 2, avg_loss = 0.4662\n",
            "t = 3, avg_loss = 0.3871\n",
            "t = 4, avg_loss = 0.5489\n",
            "t = 5, avg_loss = 0.4095\n",
            "t = 6, avg_loss = 0.4760\n",
            "t = 7, avg_loss = 0.4183\n",
            "t = 8, avg_loss = 0.4096\n",
            "t = 9, avg_loss = 0.4455\n",
            "t = 10, avg_loss = 0.3266\n",
            "t = 11, avg_loss = 0.4246\n",
            "t = 12, avg_loss = 0.3398\n",
            "t = 13, avg_loss = 0.3919\n",
            "t = 14, avg_loss = 0.3534\n",
            "t = 15, avg_loss = 0.3944\n",
            "t = 16, avg_loss = 0.4733\n",
            "t = 17, avg_loss = 0.4634\n",
            "t = 18, avg_loss = 0.5530\n",
            "t = 19, avg_loss = 0.5601\n",
            "t = 20, avg_loss = 0.4212\n",
            "t = 21, avg_loss = 0.3799\n",
            "t = 22, avg_loss = 0.4803\n",
            "t = 23, avg_loss = 0.2772\n",
            "t = 24, avg_loss = 0.3857\n",
            "t = 25, avg_loss = 0.3780\n",
            "Checking accuracy on test set\n",
            "Got 332 / 400 correct (83.00)\n",
            "acc = 0.830000\n",
            "Starting epoch 30 / 80\n",
            "t = 1, avg_loss = 0.4004\n",
            "t = 2, avg_loss = 0.3719\n",
            "t = 3, avg_loss = 0.3272\n",
            "t = 4, avg_loss = 0.4018\n",
            "t = 5, avg_loss = 0.3837\n",
            "t = 6, avg_loss = 0.3868\n",
            "t = 7, avg_loss = 0.4289\n",
            "t = 8, avg_loss = 0.5030\n",
            "t = 9, avg_loss = 0.4419\n",
            "t = 10, avg_loss = 0.5234\n",
            "t = 11, avg_loss = 0.4881\n",
            "t = 12, avg_loss = 0.3911\n",
            "t = 13, avg_loss = 0.3732\n",
            "t = 14, avg_loss = 0.5501\n",
            "t = 15, avg_loss = 0.3814\n",
            "t = 16, avg_loss = 0.4148\n",
            "t = 17, avg_loss = 0.3055\n",
            "t = 18, avg_loss = 0.3974\n",
            "t = 19, avg_loss = 0.5954\n",
            "t = 20, avg_loss = 0.4237\n",
            "t = 21, avg_loss = 0.4326\n",
            "t = 22, avg_loss = 0.3491\n",
            "t = 23, avg_loss = 0.3733\n",
            "t = 24, avg_loss = 0.3866\n",
            "t = 25, avg_loss = 0.4108\n",
            "Checking accuracy on test set\n",
            "Got 343 / 400 correct (85.75)\n",
            "acc = 0.857500\n",
            "Starting epoch 31 / 80\n",
            "t = 1, avg_loss = 0.4096\n",
            "t = 2, avg_loss = 0.3159\n",
            "t = 3, avg_loss = 0.3031\n",
            "t = 4, avg_loss = 0.3776\n",
            "t = 5, avg_loss = 0.3631\n",
            "t = 6, avg_loss = 0.3902\n",
            "t = 7, avg_loss = 0.3474\n",
            "t = 8, avg_loss = 0.4287\n",
            "t = 9, avg_loss = 0.3615\n",
            "t = 10, avg_loss = 0.4824\n",
            "t = 11, avg_loss = 0.2932\n",
            "t = 12, avg_loss = 0.4757\n",
            "t = 13, avg_loss = 0.3260\n",
            "t = 14, avg_loss = 0.4986\n",
            "t = 15, avg_loss = 0.2646\n",
            "t = 16, avg_loss = 0.4895\n",
            "t = 17, avg_loss = 0.5281\n",
            "t = 18, avg_loss = 0.4138\n",
            "t = 19, avg_loss = 0.3273\n",
            "t = 20, avg_loss = 0.5002\n",
            "t = 21, avg_loss = 0.4718\n",
            "t = 22, avg_loss = 0.4201\n",
            "t = 23, avg_loss = 0.4276\n",
            "t = 24, avg_loss = 0.3117\n",
            "t = 25, avg_loss = 0.4442\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 32 / 80\n",
            "t = 1, avg_loss = 0.4310\n",
            "t = 2, avg_loss = 0.2943\n",
            "t = 3, avg_loss = 0.3702\n",
            "t = 4, avg_loss = 0.4375\n",
            "t = 5, avg_loss = 0.6104\n",
            "t = 6, avg_loss = 0.4182\n",
            "t = 7, avg_loss = 0.3559\n",
            "t = 8, avg_loss = 0.3765\n",
            "t = 9, avg_loss = 0.3291\n",
            "t = 10, avg_loss = 0.3776\n",
            "t = 11, avg_loss = 0.4778\n",
            "t = 12, avg_loss = 0.3545\n",
            "t = 13, avg_loss = 0.3404\n",
            "t = 14, avg_loss = 0.3664\n",
            "t = 15, avg_loss = 0.3458\n",
            "t = 16, avg_loss = 0.4296\n",
            "t = 17, avg_loss = 0.4915\n",
            "t = 18, avg_loss = 0.3952\n",
            "t = 19, avg_loss = 0.4128\n",
            "t = 20, avg_loss = 0.4772\n",
            "t = 21, avg_loss = 0.4483\n",
            "t = 22, avg_loss = 0.3542\n",
            "t = 23, avg_loss = 0.3981\n",
            "t = 24, avg_loss = 0.3310\n",
            "t = 25, avg_loss = 0.4588\n",
            "Checking accuracy on test set\n",
            "Got 340 / 400 correct (85.00)\n",
            "acc = 0.850000\n",
            "Starting epoch 33 / 80\n",
            "t = 1, avg_loss = 0.5237\n",
            "t = 2, avg_loss = 0.3392\n",
            "t = 3, avg_loss = 0.2795\n",
            "t = 4, avg_loss = 0.5532\n",
            "t = 5, avg_loss = 0.4450\n",
            "t = 6, avg_loss = 0.3948\n",
            "t = 7, avg_loss = 0.5643\n",
            "t = 8, avg_loss = 0.3811\n",
            "t = 9, avg_loss = 0.3682\n",
            "t = 10, avg_loss = 0.2336\n",
            "t = 11, avg_loss = 0.3438\n",
            "t = 12, avg_loss = 0.4292\n",
            "t = 13, avg_loss = 0.4506\n",
            "t = 14, avg_loss = 0.4799\n",
            "t = 15, avg_loss = 0.4233\n",
            "t = 16, avg_loss = 0.4189\n",
            "t = 17, avg_loss = 0.3956\n",
            "t = 18, avg_loss = 0.4325\n",
            "t = 19, avg_loss = 0.3297\n",
            "t = 20, avg_loss = 0.2960\n",
            "t = 21, avg_loss = 0.5135\n",
            "t = 22, avg_loss = 0.3439\n",
            "t = 23, avg_loss = 0.4857\n",
            "t = 24, avg_loss = 0.4205\n",
            "t = 25, avg_loss = 0.4216\n",
            "Checking accuracy on test set\n",
            "Got 346 / 400 correct (86.50)\n",
            "acc = 0.865000\n",
            "Starting epoch 34 / 80\n",
            "t = 1, avg_loss = 0.3307\n",
            "t = 2, avg_loss = 0.3575\n",
            "t = 3, avg_loss = 0.3962\n",
            "t = 4, avg_loss = 0.3185\n",
            "t = 5, avg_loss = 0.2624\n",
            "t = 6, avg_loss = 0.3944\n",
            "t = 7, avg_loss = 0.4018\n",
            "t = 8, avg_loss = 0.4510\n",
            "t = 9, avg_loss = 0.5336\n",
            "t = 10, avg_loss = 0.4396\n",
            "t = 11, avg_loss = 0.2708\n",
            "t = 12, avg_loss = 0.4495\n",
            "t = 13, avg_loss = 0.3196\n",
            "t = 14, avg_loss = 0.3433\n",
            "t = 15, avg_loss = 0.4466\n",
            "t = 16, avg_loss = 0.3526\n",
            "t = 17, avg_loss = 0.4510\n",
            "t = 18, avg_loss = 0.3673\n",
            "t = 19, avg_loss = 0.3853\n",
            "t = 20, avg_loss = 0.3320\n",
            "t = 21, avg_loss = 0.3407\n",
            "t = 22, avg_loss = 0.4716\n",
            "t = 23, avg_loss = 0.3456\n",
            "t = 24, avg_loss = 0.3640\n",
            "t = 25, avg_loss = 0.5111\n",
            "Checking accuracy on test set\n",
            "Got 342 / 400 correct (85.50)\n",
            "acc = 0.855000\n",
            "Starting epoch 35 / 80\n",
            "t = 1, avg_loss = 0.3910\n",
            "t = 2, avg_loss = 0.4072\n",
            "t = 3, avg_loss = 0.3598\n",
            "t = 4, avg_loss = 0.4113\n",
            "t = 5, avg_loss = 0.4605\n",
            "t = 6, avg_loss = 0.4790\n",
            "t = 7, avg_loss = 0.4579\n",
            "t = 8, avg_loss = 0.3140\n",
            "t = 9, avg_loss = 0.3011\n",
            "t = 10, avg_loss = 0.4075\n",
            "t = 11, avg_loss = 0.4092\n",
            "t = 12, avg_loss = 0.3546\n",
            "t = 13, avg_loss = 0.6482\n",
            "t = 14, avg_loss = 0.5422\n",
            "t = 15, avg_loss = 0.3530\n",
            "t = 16, avg_loss = 0.3017\n",
            "t = 17, avg_loss = 0.3927\n",
            "t = 18, avg_loss = 0.3469\n",
            "t = 19, avg_loss = 0.2765\n",
            "t = 20, avg_loss = 0.3821\n",
            "t = 21, avg_loss = 0.3943\n",
            "t = 22, avg_loss = 0.5141\n",
            "t = 23, avg_loss = 0.3453\n",
            "t = 24, avg_loss = 0.2555\n",
            "t = 25, avg_loss = 0.4482\n",
            "Checking accuracy on test set\n",
            "Got 336 / 400 correct (84.00)\n",
            "acc = 0.840000\n",
            "Starting epoch 36 / 80\n",
            "t = 1, avg_loss = 0.4560\n",
            "t = 2, avg_loss = 0.3897\n",
            "t = 3, avg_loss = 0.4480\n",
            "t = 4, avg_loss = 0.4630\n",
            "t = 5, avg_loss = 0.3955\n",
            "t = 6, avg_loss = 0.4946\n",
            "t = 7, avg_loss = 0.3153\n",
            "t = 8, avg_loss = 0.3331\n",
            "t = 9, avg_loss = 0.3378\n",
            "t = 10, avg_loss = 0.5606\n",
            "t = 11, avg_loss = 0.4127\n",
            "t = 12, avg_loss = 0.4184\n",
            "t = 13, avg_loss = 0.3884\n",
            "t = 14, avg_loss = 0.3765\n",
            "t = 15, avg_loss = 0.3907\n",
            "t = 16, avg_loss = 0.4925\n",
            "t = 17, avg_loss = 0.3713\n",
            "t = 18, avg_loss = 0.4202\n",
            "t = 19, avg_loss = 0.5777\n",
            "t = 20, avg_loss = 0.2985\n",
            "t = 21, avg_loss = 0.3863\n",
            "t = 22, avg_loss = 0.4691\n",
            "t = 23, avg_loss = 0.3117\n",
            "t = 24, avg_loss = 0.3090\n",
            "t = 25, avg_loss = 0.3905\n",
            "Checking accuracy on test set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 37 / 80\n",
            "t = 1, avg_loss = 0.3131\n",
            "t = 2, avg_loss = 0.3110\n",
            "t = 3, avg_loss = 0.4343\n",
            "t = 4, avg_loss = 0.4318\n",
            "t = 5, avg_loss = 0.3435\n",
            "t = 6, avg_loss = 0.3255\n",
            "t = 7, avg_loss = 0.3726\n",
            "t = 8, avg_loss = 0.4935\n",
            "t = 9, avg_loss = 0.4964\n",
            "t = 10, avg_loss = 0.5570\n",
            "t = 11, avg_loss = 0.3478\n",
            "t = 12, avg_loss = 0.3531\n",
            "t = 13, avg_loss = 0.4168\n",
            "t = 14, avg_loss = 0.3399\n",
            "t = 15, avg_loss = 0.2955\n",
            "t = 16, avg_loss = 0.6035\n",
            "t = 17, avg_loss = 0.3549\n",
            "t = 18, avg_loss = 0.3783\n",
            "t = 19, avg_loss = 0.3229\n",
            "t = 20, avg_loss = 0.3901\n",
            "t = 21, avg_loss = 0.3382\n",
            "t = 22, avg_loss = 0.4784\n",
            "t = 23, avg_loss = 0.5512\n",
            "t = 24, avg_loss = 0.4291\n",
            "t = 25, avg_loss = 0.3866\n",
            "Checking accuracy on test set\n",
            "Got 343 / 400 correct (85.75)\n",
            "acc = 0.857500\n",
            "Starting epoch 38 / 80\n",
            "t = 1, avg_loss = 0.3800\n",
            "t = 2, avg_loss = 0.3537\n",
            "t = 3, avg_loss = 0.3600\n",
            "t = 4, avg_loss = 0.4030\n",
            "t = 5, avg_loss = 0.4404\n",
            "t = 6, avg_loss = 0.3552\n",
            "t = 7, avg_loss = 0.4003\n",
            "t = 8, avg_loss = 0.3934\n",
            "t = 9, avg_loss = 0.3731\n",
            "t = 10, avg_loss = 0.2850\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-6c327c4fa08a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_gpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0mcheck_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-7b7c48cb9b8f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, loss_fn, optimizer, num_epochs, starting_from_epoch)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mx_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0my_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-50a9cd504daf>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m           \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"malignant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"malignant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \"\"\"\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   1871\u001b[0m                 )\n\u001b[1;32m   1872\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1873\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1875\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nr2sQUvYlXYm",
        "colab_type": "code",
        "outputId": "cfb35976-4953-4c75-e5fc-0f0d2d94cd00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "check_accuracy(model_gpu, valid_loader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking accuracy on test set\n",
            "Got 341 / 400 correct (85.25)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8525"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkR_h7GRTJv4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#! pip install torch-lr-finder -v --global-option=\"amp\"\n",
        "#from torch_lr_finder import LRFinder\n",
        "\n",
        "#lr_finder = LRFinder(model_gpu, optimizer, loss_fn, device=\"cuda\")\n",
        "\n",
        "#lr_finder.range_test(train_loader, end_lr=1, num_iter=100, start_lr=1e-05)\n",
        "#lr_finder.plot() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzuX5gLEeJfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def retry_from_backup():\n",
        "  model_gpu = model_base.type(gpu_dtype)\n",
        "  print(model_gpu)\n",
        "  loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) \n",
        "\n",
        "\n",
        "\n",
        "  checkpoint = torch.load(model_backup_path)\n",
        "  model_gpu.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  epoch = checkpoint['epoch']\n",
        "  loss = checkpoint['loss']\n",
        "  print(\"starting from epoch: \" + str(epoch))\n",
        "  print(\"starting from loss: \" + str(loss))\n",
        "\n",
        "  train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs, starting_from_epoch=epoch)\n",
        "  check_accuracy(model_gpu, valid_loader)\n",
        "#retry_from_backup()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDn-2g-TLY3k",
        "colab_type": "code",
        "outputId": "48311d5a-c61b-4c57-8a6e-c1aaefd4c5b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot([print_every*batch_size*(i+1) for i in range((len(avg_loss_list)))],avg_loss_list)\n",
        "print(\"Loss:\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGer6hJv7-zR",
        "colab_type": "code",
        "outputId": "c1d1a315-a24a-43f5-ddae-e99577e34a4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "plt.plot([i+1 for i in range((len(acc_list)))],acc_list)\n",
        "print(\"Accurancy:\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accurancy:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBTReWHxz4Ml",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3eb9488a-a258-4fab-b0a0-b842a5228629"
      },
      "source": [
        "gpu_dtype = torch.cuda.FloatTensor\n",
        "\n",
        "print_every = 1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model_base = nn.Sequential( \n",
        "                nn.Kerv2d(in_channels , out_channels_1, padding=padding_1, dilation=1, groups=1, bias=True, \n",
        "                          kernel_type='polynomial', kernel_size=kernel_size, learnable_kernel=True,\n",
        "                          kernel_regularizer=True, stride=1, balance=1, power=3, gamma=1\n",
        "                          ),\n",
        "                nn.BatchNorm2d(out_channels_1),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                #nn.Conv2d(out_channels_1 , out_channels_2, padding= padding_1, kernel_size=kernel_size, stride=1), \n",
        "                nn.Kerv2d(out_channels_1 , out_channels_2, padding=padding_1, dilation=1, groups=1, bias=True, \n",
        "                          kernel_type='polynomial', kernel_size=kernel_size, learnable_kernel=True,\n",
        "                          kernel_regularizer=True, stride=1, balance=1, power=3, gamma=1\n",
        "                          ),\n",
        "                nn.Dropout(0.1),\n",
        "                nn.BatchNorm2d(out_channels_2),\n",
        "                nn.AvgPool2d(2, stride=2), \n",
        "                #nn.Conv2d(out_channels_2 , out_channels_3, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.Kerv2d(out_channels_2 , out_channels_3, padding=padding_1, dilation=1, groups=1, bias=True, \n",
        "                          kernel_type='polynomial', kernel_size=kernel_size, learnable_kernel=True,\n",
        "                          kernel_regularizer=True, stride=1, balance=1, power=3, gamma=1\n",
        "                          ),\n",
        "                nn.BatchNorm2d(out_channels_3),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_3 , out_channels_4, padding= padding_1, kernel_size=kernel_size, stride=1),\n",
        "                nn.Dropout(0.1),  \n",
        "                nn.BatchNorm2d(out_channels_4),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_4 , out_channels_5, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.BatchNorm2d(out_channels_5),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_5 , out_channels_6, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.BatchNorm2d(out_channels_6),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                Flatten(),\n",
        "                nn.Dropout(0.5),\n",
        "                nn.Linear(128,64),\n",
        "                nn.Linear(64,2)\n",
        "            )\n",
        "model_gpu = model_base.type(gpu_dtype)\n",
        "print(model_gpu)\n",
        "loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) \n",
        "\n",
        "\n",
        "retry_from_backup()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Kerv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (3): Kerv2d(16, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (4): Dropout(p=0.1, inplace=False)\n",
            "  (5): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (6): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (7): Kerv2d(24, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (10): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (11): Dropout(p=0.1, inplace=False)\n",
            "  (12): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (14): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (15): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (16): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (17): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (18): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (19): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (20): Flatten()\n",
            "  (21): Dropout(p=0.5, inplace=False)\n",
            "  (22): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (23): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n",
            "Sequential(\n",
            "  (0): Kerv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (3): Kerv2d(16, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (4): Dropout(p=0.1, inplace=False)\n",
            "  (5): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (6): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (7): Kerv2d(24, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (10): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (11): Dropout(p=0.1, inplace=False)\n",
            "  (12): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (14): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (15): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (16): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (17): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (18): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (19): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (20): Flatten()\n",
            "  (21): Dropout(p=0.5, inplace=False)\n",
            "  (22): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (23): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n",
            "starting from epoch: 36\n",
            "starting from loss: tensor(0.3866, device='cuda:0', requires_grad=True)\n",
            "Starting epoch 1 / 80\n",
            "t = 1, avg_loss = 0.4937\n",
            "t = 2, avg_loss = 0.3795\n",
            "t = 3, avg_loss = 0.3437\n",
            "t = 4, avg_loss = 0.4156\n",
            "t = 5, avg_loss = 0.4706\n",
            "t = 6, avg_loss = 0.4035\n",
            "t = 7, avg_loss = 0.3682\n",
            "t = 8, avg_loss = 0.5157\n",
            "t = 9, avg_loss = 0.3482\n",
            "t = 10, avg_loss = 0.3443\n",
            "t = 11, avg_loss = 0.3952\n",
            "t = 12, avg_loss = 0.4167\n",
            "t = 13, avg_loss = 0.5121\n",
            "t = 14, avg_loss = 0.3617\n",
            "t = 15, avg_loss = 0.3599\n",
            "t = 16, avg_loss = 0.5070\n",
            "t = 17, avg_loss = 0.3640\n",
            "t = 18, avg_loss = 0.6593\n",
            "t = 19, avg_loss = 0.5508\n",
            "t = 20, avg_loss = 0.4138\n",
            "t = 21, avg_loss = 0.2965\n",
            "t = 22, avg_loss = 0.3778\n",
            "t = 23, avg_loss = 0.3488\n",
            "t = 24, avg_loss = 0.4193\n",
            "t = 25, avg_loss = 0.3700\n",
            "Checking accuracy on test set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 2 / 80\n",
            "t = 1, avg_loss = 0.4188\n",
            "t = 2, avg_loss = 0.4321\n",
            "t = 3, avg_loss = 0.3769\n",
            "t = 4, avg_loss = 0.4222\n",
            "t = 5, avg_loss = 0.4333\n",
            "t = 6, avg_loss = 0.3564\n",
            "t = 7, avg_loss = 0.4807\n",
            "t = 8, avg_loss = 0.4056\n",
            "t = 9, avg_loss = 0.4648\n",
            "t = 10, avg_loss = 0.4910\n",
            "t = 11, avg_loss = 0.3821\n",
            "t = 12, avg_loss = 0.5302\n",
            "t = 13, avg_loss = 0.4833\n",
            "t = 14, avg_loss = 0.3097\n",
            "t = 15, avg_loss = 0.3795\n",
            "t = 16, avg_loss = 0.6034\n",
            "t = 17, avg_loss = 0.4144\n",
            "t = 18, avg_loss = 0.3325\n",
            "t = 19, avg_loss = 0.3841\n",
            "t = 20, avg_loss = 0.5785\n",
            "t = 21, avg_loss = 0.3827\n",
            "t = 22, avg_loss = 0.3285\n",
            "t = 23, avg_loss = 0.4103\n",
            "t = 24, avg_loss = 0.3377\n",
            "t = 25, avg_loss = 0.3299\n",
            "Checking accuracy on test set\n",
            "Got 338 / 400 correct (84.50)\n",
            "acc = 0.845000\n",
            "Starting epoch 3 / 80\n",
            "t = 1, avg_loss = 0.3373\n",
            "t = 2, avg_loss = 0.2563\n",
            "t = 3, avg_loss = 0.3751\n",
            "t = 4, avg_loss = 0.3634\n",
            "t = 5, avg_loss = 0.3856\n",
            "t = 6, avg_loss = 0.3717\n",
            "t = 7, avg_loss = 0.5282\n",
            "t = 8, avg_loss = 0.5507\n",
            "t = 9, avg_loss = 0.3140\n",
            "t = 10, avg_loss = 0.5524\n",
            "t = 11, avg_loss = 0.3908\n",
            "t = 12, avg_loss = 0.2991\n",
            "t = 13, avg_loss = 0.4523\n",
            "t = 14, avg_loss = 0.4697\n",
            "t = 15, avg_loss = 0.4677\n",
            "t = 16, avg_loss = 0.5427\n",
            "t = 17, avg_loss = 0.3751\n",
            "t = 18, avg_loss = 0.4105\n",
            "t = 19, avg_loss = 0.4551\n",
            "t = 20, avg_loss = 0.4216\n",
            "t = 21, avg_loss = 0.3409\n",
            "t = 22, avg_loss = 0.3694\n",
            "t = 23, avg_loss = 0.4041\n",
            "t = 24, avg_loss = 0.3997\n",
            "t = 25, avg_loss = 0.3785\n",
            "Checking accuracy on test set\n",
            "Got 327 / 400 correct (81.75)\n",
            "acc = 0.817500\n",
            "Starting epoch 4 / 80\n",
            "t = 1, avg_loss = 0.4053\n",
            "t = 2, avg_loss = 0.3515\n",
            "t = 3, avg_loss = 0.3334\n",
            "t = 4, avg_loss = 0.3933\n",
            "t = 5, avg_loss = 0.4591\n",
            "t = 6, avg_loss = 0.3356\n",
            "t = 7, avg_loss = 0.5191\n",
            "t = 8, avg_loss = 0.4234\n",
            "t = 9, avg_loss = 0.4078\n",
            "t = 10, avg_loss = 0.3219\n",
            "t = 11, avg_loss = 0.4016\n",
            "t = 12, avg_loss = 0.2507\n",
            "t = 13, avg_loss = 0.2738\n",
            "t = 14, avg_loss = 0.4968\n",
            "t = 15, avg_loss = 0.3875\n",
            "t = 16, avg_loss = 0.5081\n",
            "t = 17, avg_loss = 0.4448\n",
            "t = 18, avg_loss = 0.3775\n",
            "t = 19, avg_loss = 0.3999\n",
            "t = 20, avg_loss = 0.3816\n",
            "t = 21, avg_loss = 0.3953\n",
            "t = 22, avg_loss = 0.4007\n",
            "t = 23, avg_loss = 0.3445\n",
            "t = 24, avg_loss = 0.5071\n",
            "t = 25, avg_loss = 0.3559\n",
            "Checking accuracy on test set\n",
            "Got 342 / 400 correct (85.50)\n",
            "acc = 0.855000\n",
            "Starting epoch 5 / 80\n",
            "t = 1, avg_loss = 0.5876\n",
            "t = 2, avg_loss = 0.2945\n",
            "t = 3, avg_loss = 0.3243\n",
            "t = 4, avg_loss = 0.3453\n",
            "t = 5, avg_loss = 0.3945\n",
            "t = 6, avg_loss = 0.3265\n",
            "t = 7, avg_loss = 0.3422\n",
            "t = 8, avg_loss = 0.3859\n",
            "t = 9, avg_loss = 0.4193\n",
            "t = 10, avg_loss = 0.3951\n",
            "t = 11, avg_loss = 0.3774\n",
            "t = 12, avg_loss = 0.4933\n",
            "t = 13, avg_loss = 0.4435\n",
            "t = 14, avg_loss = 0.3852\n",
            "t = 15, avg_loss = 0.3326\n",
            "t = 16, avg_loss = 0.3578\n",
            "t = 17, avg_loss = 0.4220\n",
            "t = 18, avg_loss = 0.4473\n",
            "t = 19, avg_loss = 0.4017\n",
            "t = 20, avg_loss = 0.3566\n",
            "t = 21, avg_loss = 0.4566\n",
            "t = 22, avg_loss = 0.4048\n",
            "t = 23, avg_loss = 0.4370\n",
            "t = 24, avg_loss = 0.3635\n",
            "t = 25, avg_loss = 0.3739\n",
            "Checking accuracy on test set\n",
            "Got 342 / 400 correct (85.50)\n",
            "acc = 0.855000\n",
            "Starting epoch 6 / 80\n",
            "t = 1, avg_loss = 0.3652\n",
            "t = 2, avg_loss = 0.4196\n",
            "t = 3, avg_loss = 0.5016\n",
            "t = 4, avg_loss = 0.3607\n",
            "t = 5, avg_loss = 0.3250\n",
            "t = 6, avg_loss = 0.3735\n",
            "t = 7, avg_loss = 0.4299\n",
            "t = 8, avg_loss = 0.3256\n",
            "t = 9, avg_loss = 0.3290\n",
            "t = 10, avg_loss = 0.6262\n",
            "t = 11, avg_loss = 0.3000\n",
            "t = 12, avg_loss = 0.5019\n",
            "t = 13, avg_loss = 0.2817\n",
            "t = 14, avg_loss = 0.4134\n",
            "t = 15, avg_loss = 0.3466\n",
            "t = 16, avg_loss = 0.3489\n",
            "t = 17, avg_loss = 0.6020\n",
            "t = 18, avg_loss = 0.3229\n",
            "t = 19, avg_loss = 0.3778\n",
            "t = 20, avg_loss = 0.3363\n",
            "t = 21, avg_loss = 0.4517\n",
            "t = 22, avg_loss = 0.3584\n",
            "t = 23, avg_loss = 0.3413\n",
            "t = 24, avg_loss = 0.2829\n",
            "t = 25, avg_loss = 0.3417\n",
            "Checking accuracy on test set\n",
            "Got 334 / 400 correct (83.50)\n",
            "acc = 0.835000\n",
            "Starting epoch 7 / 80\n",
            "t = 1, avg_loss = 0.3395\n",
            "t = 2, avg_loss = 0.3082\n",
            "t = 3, avg_loss = 0.3756\n",
            "t = 4, avg_loss = 0.3590\n",
            "t = 5, avg_loss = 0.3739\n",
            "t = 6, avg_loss = 0.4517\n",
            "t = 7, avg_loss = 0.4024\n",
            "t = 8, avg_loss = 0.3574\n",
            "t = 9, avg_loss = 0.3509\n",
            "t = 10, avg_loss = 0.4431\n",
            "t = 11, avg_loss = 0.3096\n",
            "t = 12, avg_loss = 0.2981\n",
            "t = 13, avg_loss = 0.3764\n",
            "t = 14, avg_loss = 0.4836\n",
            "t = 15, avg_loss = 0.2832\n",
            "t = 16, avg_loss = 0.3807\n",
            "t = 17, avg_loss = 0.3034\n",
            "t = 18, avg_loss = 0.4217\n",
            "t = 19, avg_loss = 0.6321\n",
            "t = 20, avg_loss = 0.3292\n",
            "t = 21, avg_loss = 0.4387\n",
            "t = 22, avg_loss = 0.2870\n",
            "t = 23, avg_loss = 0.4000\n",
            "t = 24, avg_loss = 0.3299\n",
            "t = 25, avg_loss = 0.4551\n",
            "Checking accuracy on test set\n",
            "Got 336 / 400 correct (84.00)\n",
            "acc = 0.840000\n",
            "Starting epoch 8 / 80\n",
            "t = 1, avg_loss = 0.3175\n",
            "t = 2, avg_loss = 0.5676\n",
            "t = 3, avg_loss = 0.4584\n",
            "t = 4, avg_loss = 0.4566\n",
            "t = 5, avg_loss = 0.5330\n",
            "t = 6, avg_loss = 0.4226\n",
            "t = 7, avg_loss = 0.3509\n",
            "t = 8, avg_loss = 0.3626\n",
            "t = 9, avg_loss = 0.3717\n",
            "t = 10, avg_loss = 0.3064\n",
            "t = 11, avg_loss = 0.3177\n",
            "t = 12, avg_loss = 0.4684\n",
            "t = 13, avg_loss = 0.3195\n",
            "t = 14, avg_loss = 0.4244\n",
            "t = 15, avg_loss = 0.3772\n",
            "t = 16, avg_loss = 0.4645\n",
            "t = 17, avg_loss = 0.3202\n",
            "t = 18, avg_loss = 0.3639\n",
            "t = 19, avg_loss = 0.2651\n",
            "t = 20, avg_loss = 0.3302\n",
            "t = 21, avg_loss = 0.3181\n",
            "t = 22, avg_loss = 0.3943\n",
            "t = 23, avg_loss = 0.3745\n",
            "t = 24, avg_loss = 0.4587\n",
            "t = 25, avg_loss = 0.4489\n",
            "Checking accuracy on test set\n",
            "Got 329 / 400 correct (82.25)\n",
            "acc = 0.822500\n",
            "Starting epoch 9 / 80\n",
            "t = 1, avg_loss = 0.2916\n",
            "t = 2, avg_loss = 0.4140\n",
            "t = 3, avg_loss = 0.4056\n",
            "t = 4, avg_loss = 0.2806\n",
            "t = 5, avg_loss = 0.3515\n",
            "t = 6, avg_loss = 0.3520\n",
            "t = 7, avg_loss = 0.5194\n",
            "t = 8, avg_loss = 0.3084\n",
            "t = 9, avg_loss = 0.5532\n",
            "t = 10, avg_loss = 0.4203\n",
            "t = 11, avg_loss = 0.4409\n",
            "t = 12, avg_loss = 0.6334\n",
            "t = 13, avg_loss = 0.3521\n",
            "t = 14, avg_loss = 0.3016\n",
            "t = 15, avg_loss = 0.4982\n",
            "t = 16, avg_loss = 0.5262\n",
            "t = 17, avg_loss = 0.3085\n",
            "t = 18, avg_loss = 0.3868\n",
            "t = 19, avg_loss = 0.3008\n",
            "t = 20, avg_loss = 0.3529\n",
            "t = 21, avg_loss = 0.4540\n",
            "t = 22, avg_loss = 0.3833\n",
            "t = 23, avg_loss = 0.4619\n",
            "t = 24, avg_loss = 0.3669\n",
            "t = 25, avg_loss = 0.3855\n",
            "Checking accuracy on test set\n",
            "Got 341 / 400 correct (85.25)\n",
            "acc = 0.852500\n",
            "Starting epoch 10 / 80\n",
            "t = 1, avg_loss = 0.4136\n",
            "t = 2, avg_loss = 0.4089\n",
            "t = 3, avg_loss = 0.3774\n",
            "t = 4, avg_loss = 0.3879\n",
            "t = 5, avg_loss = 0.3641\n",
            "t = 6, avg_loss = 0.3801\n",
            "t = 7, avg_loss = 0.2717\n",
            "t = 8, avg_loss = 0.4017\n",
            "t = 9, avg_loss = 0.4204\n",
            "t = 10, avg_loss = 0.4076\n",
            "t = 11, avg_loss = 0.2772\n",
            "t = 12, avg_loss = 0.2925\n",
            "t = 13, avg_loss = 0.3635\n",
            "t = 14, avg_loss = 0.4890\n",
            "t = 15, avg_loss = 0.3040\n",
            "t = 16, avg_loss = 0.4963\n",
            "t = 17, avg_loss = 0.2216\n",
            "t = 18, avg_loss = 0.5376\n",
            "t = 19, avg_loss = 0.3140\n",
            "t = 20, avg_loss = 0.4067\n",
            "t = 21, avg_loss = 0.4516\n",
            "t = 22, avg_loss = 0.3471\n",
            "t = 23, avg_loss = 0.3435\n",
            "t = 24, avg_loss = 0.4493\n",
            "t = 25, avg_loss = 0.2420\n",
            "Checking accuracy on test set\n",
            "Got 336 / 400 correct (84.00)\n",
            "acc = 0.840000\n",
            "Starting epoch 11 / 80\n",
            "t = 1, avg_loss = 0.3518\n",
            "t = 2, avg_loss = 0.4776\n",
            "t = 3, avg_loss = 0.2575\n",
            "t = 4, avg_loss = 0.3811\n",
            "t = 5, avg_loss = 0.3878\n",
            "t = 6, avg_loss = 0.3231\n",
            "t = 7, avg_loss = 0.4224\n",
            "t = 8, avg_loss = 0.3400\n",
            "t = 9, avg_loss = 0.2987\n",
            "t = 10, avg_loss = 0.3406\n",
            "t = 11, avg_loss = 0.3913\n",
            "t = 12, avg_loss = 0.3416\n",
            "t = 13, avg_loss = 0.4518\n",
            "t = 14, avg_loss = 0.5420\n",
            "t = 15, avg_loss = 0.4880\n",
            "t = 16, avg_loss = 0.4138\n",
            "t = 17, avg_loss = 0.3212\n",
            "t = 18, avg_loss = 0.3436\n",
            "t = 19, avg_loss = 0.4573\n",
            "t = 20, avg_loss = 0.3582\n",
            "t = 21, avg_loss = 0.4494\n",
            "t = 22, avg_loss = 0.3472\n",
            "t = 23, avg_loss = 0.4293\n",
            "t = 24, avg_loss = 0.3061\n",
            "t = 25, avg_loss = 0.3407\n",
            "Checking accuracy on test set\n",
            "Got 341 / 400 correct (85.25)\n",
            "acc = 0.852500\n",
            "Starting epoch 12 / 80\n",
            "t = 1, avg_loss = 0.3918\n",
            "t = 2, avg_loss = 0.4182\n",
            "t = 3, avg_loss = 0.4819\n",
            "t = 4, avg_loss = 0.3413\n",
            "t = 5, avg_loss = 0.3409\n",
            "t = 6, avg_loss = 0.4197\n",
            "t = 7, avg_loss = 0.3859\n",
            "t = 8, avg_loss = 0.3837\n",
            "t = 9, avg_loss = 0.3661\n",
            "t = 10, avg_loss = 0.2577\n",
            "t = 11, avg_loss = 0.3379\n",
            "t = 12, avg_loss = 0.2860\n",
            "t = 13, avg_loss = 0.3853\n",
            "t = 14, avg_loss = 0.5698\n",
            "t = 15, avg_loss = 0.3696\n",
            "t = 16, avg_loss = 0.3985\n",
            "t = 17, avg_loss = 0.4666\n",
            "t = 18, avg_loss = 0.4341\n",
            "t = 19, avg_loss = 0.4297\n",
            "t = 20, avg_loss = 0.4600\n",
            "t = 21, avg_loss = 0.3444\n",
            "t = 22, avg_loss = 0.3182\n",
            "t = 23, avg_loss = 0.4620\n",
            "t = 24, avg_loss = 0.3914\n",
            "t = 25, avg_loss = 0.3480\n",
            "Checking accuracy on test set\n",
            "Got 330 / 400 correct (82.50)\n",
            "acc = 0.825000\n",
            "Starting epoch 13 / 80\n",
            "t = 1, avg_loss = 0.4329\n",
            "t = 2, avg_loss = 0.3326\n",
            "t = 3, avg_loss = 0.3267\n",
            "t = 4, avg_loss = 0.4890\n",
            "t = 5, avg_loss = 0.2783\n",
            "t = 6, avg_loss = 0.4113\n",
            "t = 7, avg_loss = 0.3664\n",
            "t = 8, avg_loss = 0.3617\n",
            "t = 9, avg_loss = 0.3119\n",
            "t = 10, avg_loss = 0.4444\n",
            "t = 11, avg_loss = 0.4760\n",
            "t = 12, avg_loss = 0.3519\n",
            "t = 13, avg_loss = 0.2414\n",
            "t = 14, avg_loss = 0.3818\n",
            "t = 15, avg_loss = 0.3849\n",
            "t = 16, avg_loss = 0.5380\n",
            "t = 17, avg_loss = 0.5605\n",
            "t = 18, avg_loss = 0.3069\n",
            "t = 19, avg_loss = 0.3521\n",
            "t = 20, avg_loss = 0.4183\n",
            "t = 21, avg_loss = 0.4384\n",
            "t = 22, avg_loss = 0.3398\n",
            "t = 23, avg_loss = 0.3679\n",
            "t = 24, avg_loss = 0.6063\n",
            "t = 25, avg_loss = 0.4158\n",
            "Checking accuracy on test set\n",
            "Got 342 / 400 correct (85.50)\n",
            "acc = 0.855000\n",
            "Starting epoch 14 / 80\n",
            "t = 1, avg_loss = 0.4829\n",
            "t = 2, avg_loss = 0.5068\n",
            "t = 3, avg_loss = 0.3268\n",
            "t = 4, avg_loss = 0.3751\n",
            "t = 5, avg_loss = 0.3520\n",
            "t = 6, avg_loss = 0.4345\n",
            "t = 7, avg_loss = 0.3440\n",
            "t = 8, avg_loss = 0.3414\n",
            "t = 9, avg_loss = 0.4215\n",
            "t = 10, avg_loss = 0.4585\n",
            "t = 11, avg_loss = 0.4819\n",
            "t = 12, avg_loss = 0.4370\n",
            "t = 13, avg_loss = 0.4474\n",
            "t = 14, avg_loss = 0.3486\n",
            "t = 15, avg_loss = 0.3064\n",
            "t = 16, avg_loss = 0.5683\n",
            "t = 17, avg_loss = 0.3704\n",
            "t = 18, avg_loss = 0.3927\n",
            "t = 19, avg_loss = 0.2883\n",
            "t = 20, avg_loss = 0.3583\n",
            "t = 21, avg_loss = 0.3935\n",
            "t = 22, avg_loss = 0.4337\n",
            "t = 23, avg_loss = 0.4609\n",
            "t = 24, avg_loss = 0.2845\n",
            "t = 25, avg_loss = 0.3088\n",
            "Checking accuracy on test set\n",
            "Got 344 / 400 correct (86.00)\n",
            "acc = 0.860000\n",
            "Starting epoch 15 / 80\n",
            "t = 1, avg_loss = 0.4662\n",
            "t = 2, avg_loss = 0.4243\n",
            "t = 3, avg_loss = 0.4668\n",
            "t = 4, avg_loss = 0.3327\n",
            "t = 5, avg_loss = 0.4572\n",
            "t = 6, avg_loss = 0.5100\n",
            "t = 7, avg_loss = 0.4055\n",
            "t = 8, avg_loss = 0.4776\n",
            "t = 9, avg_loss = 0.3292\n",
            "t = 10, avg_loss = 0.2334\n",
            "t = 11, avg_loss = 0.3158\n",
            "t = 12, avg_loss = 0.3551\n",
            "t = 13, avg_loss = 0.2844\n",
            "t = 14, avg_loss = 0.3771\n",
            "t = 15, avg_loss = 0.3223\n",
            "t = 16, avg_loss = 0.3599\n",
            "t = 17, avg_loss = 0.3691\n",
            "t = 18, avg_loss = 0.4121\n",
            "t = 19, avg_loss = 0.4253\n",
            "t = 20, avg_loss = 0.3771\n",
            "t = 21, avg_loss = 0.3476\n",
            "t = 22, avg_loss = 0.3540\n",
            "t = 23, avg_loss = 0.3673\n",
            "t = 24, avg_loss = 0.3992\n",
            "t = 25, avg_loss = 0.4030\n",
            "Checking accuracy on test set\n",
            "Got 342 / 400 correct (85.50)\n",
            "acc = 0.855000\n",
            "Starting epoch 16 / 80\n",
            "t = 1, avg_loss = 0.3537\n",
            "t = 2, avg_loss = 0.3509\n",
            "t = 3, avg_loss = 0.6056\n",
            "t = 4, avg_loss = 0.2518\n",
            "t = 5, avg_loss = 0.3296\n",
            "t = 6, avg_loss = 0.3420\n",
            "t = 7, avg_loss = 0.4201\n",
            "t = 8, avg_loss = 0.4505\n",
            "t = 9, avg_loss = 0.3323\n",
            "t = 10, avg_loss = 0.3560\n",
            "t = 11, avg_loss = 0.4179\n",
            "t = 12, avg_loss = 0.3452\n",
            "t = 13, avg_loss = 0.4204\n",
            "t = 14, avg_loss = 0.3246\n",
            "t = 15, avg_loss = 0.3793\n",
            "t = 16, avg_loss = 0.2524\n",
            "t = 17, avg_loss = 0.4751\n",
            "t = 18, avg_loss = 0.3346\n",
            "t = 19, avg_loss = 0.3659\n",
            "t = 20, avg_loss = 0.3670\n",
            "t = 21, avg_loss = 0.2334\n",
            "t = 22, avg_loss = 0.3827\n",
            "t = 23, avg_loss = 0.4606\n",
            "t = 24, avg_loss = 0.3615\n",
            "t = 25, avg_loss = 0.3074\n",
            "Checking accuracy on test set\n",
            "Got 336 / 400 correct (84.00)\n",
            "acc = 0.840000\n",
            "Starting epoch 17 / 80\n",
            "t = 1, avg_loss = 0.2156\n",
            "t = 2, avg_loss = 0.3231\n",
            "t = 3, avg_loss = 0.2874\n",
            "t = 4, avg_loss = 0.2930\n",
            "t = 5, avg_loss = 0.4003\n",
            "t = 6, avg_loss = 0.4728\n",
            "t = 7, avg_loss = 0.3151\n",
            "t = 8, avg_loss = 0.3564\n",
            "t = 9, avg_loss = 0.3419\n",
            "t = 10, avg_loss = 0.3800\n",
            "t = 11, avg_loss = 0.4209\n",
            "t = 12, avg_loss = 0.5782\n",
            "t = 13, avg_loss = 0.4493\n",
            "t = 14, avg_loss = 0.4192\n",
            "t = 15, avg_loss = 0.3315\n",
            "t = 16, avg_loss = 0.3053\n",
            "t = 17, avg_loss = 0.3248\n",
            "t = 18, avg_loss = 0.3334\n",
            "t = 19, avg_loss = 0.3344\n",
            "t = 20, avg_loss = 0.2983\n",
            "t = 21, avg_loss = 0.3807\n",
            "t = 22, avg_loss = 0.3455\n",
            "t = 23, avg_loss = 0.3773\n",
            "t = 24, avg_loss = 0.3360\n",
            "t = 25, avg_loss = 0.4549\n",
            "Checking accuracy on test set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 18 / 80\n",
            "t = 1, avg_loss = 0.3274\n",
            "t = 2, avg_loss = 0.3223\n",
            "t = 3, avg_loss = 0.3562\n",
            "t = 4, avg_loss = 0.3601\n",
            "t = 5, avg_loss = 0.3411\n",
            "t = 6, avg_loss = 0.3562\n",
            "t = 7, avg_loss = 0.2339\n",
            "t = 8, avg_loss = 0.6122\n",
            "t = 9, avg_loss = 0.4699\n",
            "t = 10, avg_loss = 0.4508\n",
            "t = 11, avg_loss = 0.2236\n",
            "t = 12, avg_loss = 0.4672\n",
            "t = 13, avg_loss = 0.5573\n",
            "t = 14, avg_loss = 0.3799\n",
            "t = 15, avg_loss = 0.4413\n",
            "t = 16, avg_loss = 0.3409\n",
            "t = 17, avg_loss = 0.4577\n",
            "t = 18, avg_loss = 0.3364\n",
            "t = 19, avg_loss = 0.3111\n",
            "t = 20, avg_loss = 0.3966\n",
            "t = 21, avg_loss = 0.3310\n",
            "t = 22, avg_loss = 0.3899\n",
            "t = 23, avg_loss = 0.3889\n",
            "t = 24, avg_loss = 0.4008\n",
            "t = 25, avg_loss = 0.2762\n",
            "Checking accuracy on test set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 19 / 80\n",
            "t = 1, avg_loss = 0.3530\n",
            "t = 2, avg_loss = 0.2976\n",
            "t = 3, avg_loss = 0.3821\n",
            "t = 4, avg_loss = 0.3078\n",
            "t = 5, avg_loss = 0.3020\n",
            "t = 6, avg_loss = 0.3774\n",
            "t = 7, avg_loss = 0.3693\n",
            "t = 8, avg_loss = 0.3398\n",
            "t = 9, avg_loss = 0.5078\n",
            "t = 10, avg_loss = 0.3946\n",
            "t = 11, avg_loss = 0.2910\n",
            "t = 12, avg_loss = 0.3383\n",
            "t = 13, avg_loss = 0.3937\n",
            "t = 14, avg_loss = 0.4352\n",
            "t = 15, avg_loss = 0.3313\n",
            "t = 16, avg_loss = 0.2839\n",
            "t = 17, avg_loss = 0.4052\n",
            "t = 18, avg_loss = 0.3107\n",
            "t = 19, avg_loss = 0.4217\n",
            "t = 20, avg_loss = 0.3499\n",
            "t = 21, avg_loss = 0.2993\n",
            "t = 22, avg_loss = 0.3722\n",
            "t = 23, avg_loss = 0.3450\n",
            "t = 24, avg_loss = 0.5017\n",
            "t = 25, avg_loss = 0.4835\n",
            "Checking accuracy on test set\n",
            "Got 330 / 400 correct (82.50)\n",
            "acc = 0.825000\n",
            "Starting epoch 20 / 80\n",
            "t = 1, avg_loss = 0.3474\n",
            "t = 2, avg_loss = 0.4223\n",
            "t = 3, avg_loss = 0.3572\n",
            "t = 4, avg_loss = 0.4521\n",
            "t = 5, avg_loss = 0.3443\n",
            "t = 6, avg_loss = 0.3785\n",
            "t = 7, avg_loss = 0.2747\n",
            "t = 8, avg_loss = 0.3883\n",
            "t = 9, avg_loss = 0.2154\n",
            "t = 10, avg_loss = 0.3625\n",
            "t = 11, avg_loss = 0.3279\n",
            "t = 12, avg_loss = 0.2627\n",
            "t = 13, avg_loss = 0.4208\n",
            "t = 14, avg_loss = 0.3982\n",
            "t = 15, avg_loss = 0.3684\n",
            "t = 16, avg_loss = 0.2550\n",
            "t = 17, avg_loss = 0.4354\n",
            "t = 18, avg_loss = 0.4635\n",
            "t = 19, avg_loss = 0.5870\n",
            "t = 20, avg_loss = 0.5691\n",
            "t = 21, avg_loss = 0.3229\n",
            "t = 22, avg_loss = 0.3051\n",
            "t = 23, avg_loss = 0.3504\n",
            "t = 24, avg_loss = 0.3685\n",
            "t = 25, avg_loss = 0.4083\n",
            "Checking accuracy on test set\n",
            "Got 336 / 400 correct (84.00)\n",
            "acc = 0.840000\n",
            "Starting epoch 21 / 80\n",
            "t = 1, avg_loss = 0.3910\n",
            "t = 2, avg_loss = 0.3923\n",
            "t = 3, avg_loss = 0.3567\n",
            "t = 4, avg_loss = 0.3400\n",
            "t = 5, avg_loss = 0.2792\n",
            "t = 6, avg_loss = 0.4427\n",
            "t = 7, avg_loss = 0.3963\n",
            "t = 8, avg_loss = 0.4227\n",
            "t = 9, avg_loss = 0.2756\n",
            "t = 10, avg_loss = 0.2679\n",
            "t = 11, avg_loss = 0.3190\n",
            "t = 12, avg_loss = 0.3173\n",
            "t = 13, avg_loss = 0.3885\n",
            "t = 14, avg_loss = 0.2904\n",
            "t = 15, avg_loss = 0.3187\n",
            "t = 16, avg_loss = 0.3191\n",
            "t = 17, avg_loss = 0.3323\n",
            "t = 18, avg_loss = 0.2588\n",
            "t = 19, avg_loss = 0.3281\n",
            "t = 20, avg_loss = 0.4199\n",
            "t = 21, avg_loss = 0.3590\n",
            "t = 22, avg_loss = 0.4444\n",
            "t = 23, avg_loss = 0.3491\n",
            "t = 24, avg_loss = 0.3267\n",
            "t = 25, avg_loss = 0.3490\n",
            "Checking accuracy on test set\n",
            "Got 335 / 400 correct (83.75)\n",
            "acc = 0.837500\n",
            "Starting epoch 22 / 80\n",
            "t = 1, avg_loss = 0.3434\n",
            "t = 2, avg_loss = 0.3680\n",
            "t = 3, avg_loss = 0.5085\n",
            "t = 4, avg_loss = 0.6066\n",
            "t = 5, avg_loss = 0.3538\n",
            "t = 6, avg_loss = 0.3759\n",
            "t = 7, avg_loss = 0.4798\n",
            "t = 8, avg_loss = 0.2658\n",
            "t = 9, avg_loss = 0.3705\n",
            "t = 10, avg_loss = 0.3166\n",
            "t = 11, avg_loss = 0.3585\n",
            "t = 12, avg_loss = 0.2551\n",
            "t = 13, avg_loss = 0.3158\n",
            "t = 14, avg_loss = 0.4088\n",
            "t = 15, avg_loss = 0.2674\n",
            "t = 16, avg_loss = 0.3987\n",
            "t = 17, avg_loss = 0.3230\n",
            "t = 18, avg_loss = 0.3163\n",
            "t = 19, avg_loss = 0.3861\n",
            "t = 20, avg_loss = 0.4302\n",
            "t = 21, avg_loss = 0.3037\n",
            "t = 22, avg_loss = 0.3865\n",
            "t = 23, avg_loss = 0.4880\n",
            "t = 24, avg_loss = 0.4258\n",
            "t = 25, avg_loss = 0.3787\n",
            "Checking accuracy on test set\n",
            "Got 328 / 400 correct (82.00)\n",
            "acc = 0.820000\n",
            "Starting epoch 23 / 80\n",
            "t = 1, avg_loss = 0.5310\n",
            "t = 2, avg_loss = 0.4671\n",
            "t = 3, avg_loss = 0.4313\n",
            "t = 4, avg_loss = 0.3224\n",
            "t = 5, avg_loss = 0.2444\n",
            "t = 6, avg_loss = 0.4596\n",
            "t = 7, avg_loss = 0.3234\n",
            "t = 8, avg_loss = 0.3233\n",
            "t = 9, avg_loss = 0.2860\n",
            "t = 10, avg_loss = 0.3793\n",
            "t = 11, avg_loss = 0.4247\n",
            "t = 12, avg_loss = 0.2639\n",
            "t = 13, avg_loss = 0.4008\n",
            "t = 14, avg_loss = 0.3349\n",
            "t = 15, avg_loss = 0.3662\n",
            "t = 16, avg_loss = 0.3322\n",
            "t = 17, avg_loss = 0.5283\n",
            "t = 18, avg_loss = 0.4051\n",
            "t = 19, avg_loss = 0.3445\n",
            "t = 20, avg_loss = 0.3772\n",
            "t = 21, avg_loss = 0.2801\n",
            "t = 22, avg_loss = 0.2600\n",
            "t = 23, avg_loss = 0.4446\n",
            "t = 24, avg_loss = 0.4055\n",
            "t = 25, avg_loss = 0.2965\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 24 / 80\n",
            "t = 1, avg_loss = 0.2935\n",
            "t = 2, avg_loss = 0.3053\n",
            "t = 3, avg_loss = 0.4258\n",
            "t = 4, avg_loss = 0.4478\n",
            "t = 5, avg_loss = 0.3406\n",
            "t = 6, avg_loss = 0.3622\n",
            "t = 7, avg_loss = 0.4162\n",
            "t = 8, avg_loss = 0.3677\n",
            "t = 9, avg_loss = 0.3447\n",
            "t = 10, avg_loss = 0.4110\n",
            "t = 11, avg_loss = 0.4638\n",
            "t = 12, avg_loss = 0.2061\n",
            "t = 13, avg_loss = 0.5562\n",
            "t = 14, avg_loss = 0.2993\n",
            "t = 15, avg_loss = 0.3934\n",
            "t = 16, avg_loss = 0.3625\n",
            "t = 17, avg_loss = 0.3466\n",
            "t = 18, avg_loss = 0.2892\n",
            "t = 19, avg_loss = 0.3260\n",
            "t = 20, avg_loss = 0.3283\n",
            "t = 21, avg_loss = 0.3322\n",
            "t = 22, avg_loss = 0.3233\n",
            "t = 23, avg_loss = 0.2929\n",
            "t = 24, avg_loss = 0.3976\n",
            "t = 25, avg_loss = 0.4292\n",
            "Checking accuracy on test set\n",
            "Got 341 / 400 correct (85.25)\n",
            "acc = 0.852500\n",
            "Starting epoch 25 / 80\n",
            "t = 1, avg_loss = 0.3736\n",
            "t = 2, avg_loss = 0.3720\n",
            "t = 3, avg_loss = 0.3840\n",
            "t = 4, avg_loss = 0.3677\n",
            "t = 5, avg_loss = 0.4721\n",
            "t = 6, avg_loss = 0.4789\n",
            "t = 7, avg_loss = 0.2999\n",
            "t = 8, avg_loss = 0.3124\n",
            "t = 9, avg_loss = 0.3249\n",
            "t = 10, avg_loss = 0.3599\n",
            "t = 11, avg_loss = 0.4425\n",
            "t = 12, avg_loss = 0.2681\n",
            "t = 13, avg_loss = 0.4959\n",
            "t = 14, avg_loss = 0.4342\n",
            "t = 15, avg_loss = 0.3602\n",
            "t = 16, avg_loss = 0.3730\n",
            "t = 17, avg_loss = 0.3736\n",
            "t = 18, avg_loss = 0.3152\n",
            "t = 19, avg_loss = 0.2895\n",
            "t = 20, avg_loss = 0.4087\n",
            "t = 21, avg_loss = 0.4039\n",
            "t = 22, avg_loss = 0.3393\n",
            "t = 23, avg_loss = 0.4639\n",
            "t = 24, avg_loss = 0.3471\n",
            "t = 25, avg_loss = 0.4507\n",
            "Checking accuracy on test set\n",
            "Got 337 / 400 correct (84.25)\n",
            "acc = 0.842500\n",
            "Starting epoch 26 / 80\n",
            "t = 1, avg_loss = 0.3693\n",
            "t = 2, avg_loss = 0.3960\n",
            "t = 3, avg_loss = 0.3063\n",
            "t = 4, avg_loss = 0.2430\n",
            "t = 5, avg_loss = 0.2851\n",
            "t = 6, avg_loss = 0.4198\n",
            "t = 7, avg_loss = 0.2557\n",
            "t = 8, avg_loss = 0.4485\n",
            "t = 9, avg_loss = 0.2075\n",
            "t = 10, avg_loss = 0.3576\n",
            "t = 11, avg_loss = 0.3129\n",
            "t = 12, avg_loss = 0.3809\n",
            "t = 13, avg_loss = 0.5027\n",
            "t = 14, avg_loss = 0.3868\n",
            "t = 15, avg_loss = 0.3405\n",
            "t = 16, avg_loss = 0.4181\n",
            "t = 17, avg_loss = 0.4779\n",
            "t = 18, avg_loss = 0.3818\n",
            "t = 19, avg_loss = 0.3087\n",
            "t = 20, avg_loss = 0.2912\n",
            "t = 21, avg_loss = 0.4173\n",
            "t = 22, avg_loss = 0.4262\n",
            "t = 23, avg_loss = 0.4349\n",
            "t = 24, avg_loss = 0.3336\n",
            "t = 25, avg_loss = 0.4212\n",
            "Checking accuracy on test set\n",
            "Got 333 / 400 correct (83.25)\n",
            "acc = 0.832500\n",
            "Starting epoch 27 / 80\n",
            "t = 1, avg_loss = 0.2755\n",
            "t = 2, avg_loss = 0.3065\n",
            "t = 3, avg_loss = 0.5787\n",
            "t = 4, avg_loss = 0.2579\n",
            "t = 5, avg_loss = 0.4887\n",
            "t = 6, avg_loss = 0.3130\n",
            "t = 7, avg_loss = 0.3520\n",
            "t = 8, avg_loss = 0.4423\n",
            "t = 9, avg_loss = 0.3778\n",
            "t = 10, avg_loss = 0.3587\n",
            "t = 11, avg_loss = 0.2982\n",
            "t = 12, avg_loss = 0.3594\n",
            "t = 13, avg_loss = 0.3502\n",
            "t = 14, avg_loss = 0.3699\n",
            "t = 15, avg_loss = 0.3612\n",
            "t = 16, avg_loss = 0.2778\n",
            "t = 17, avg_loss = 0.3590\n",
            "t = 18, avg_loss = 0.4042\n",
            "t = 19, avg_loss = 0.3082\n",
            "t = 20, avg_loss = 0.3359\n",
            "t = 21, avg_loss = 0.3258\n",
            "t = 22, avg_loss = 0.3593\n",
            "t = 23, avg_loss = 0.3661\n",
            "t = 24, avg_loss = 0.3929\n",
            "t = 25, avg_loss = 0.2205\n",
            "Checking accuracy on test set\n",
            "Got 333 / 400 correct (83.25)\n",
            "acc = 0.832500\n",
            "Starting epoch 28 / 80\n",
            "t = 1, avg_loss = 0.4689\n",
            "t = 2, avg_loss = 0.4456\n",
            "t = 3, avg_loss = 0.2431\n",
            "t = 4, avg_loss = 0.3086\n",
            "t = 5, avg_loss = 0.2759\n",
            "t = 6, avg_loss = 0.3501\n",
            "t = 7, avg_loss = 0.4359\n",
            "t = 8, avg_loss = 0.4211\n",
            "t = 9, avg_loss = 0.3934\n",
            "t = 10, avg_loss = 0.2309\n",
            "t = 11, avg_loss = 0.4966\n",
            "t = 12, avg_loss = 0.2568\n",
            "t = 13, avg_loss = 0.4446\n",
            "t = 14, avg_loss = 0.6113\n",
            "t = 15, avg_loss = 0.3483\n",
            "t = 16, avg_loss = 0.3611\n",
            "t = 17, avg_loss = 0.3786\n",
            "t = 18, avg_loss = 0.3106\n",
            "t = 19, avg_loss = 0.2848\n",
            "t = 20, avg_loss = 0.4441\n",
            "t = 21, avg_loss = 0.3674\n",
            "t = 22, avg_loss = 0.3464\n",
            "t = 23, avg_loss = 0.3988\n",
            "t = 24, avg_loss = 0.2525\n",
            "t = 25, avg_loss = 0.4088\n",
            "Checking accuracy on test set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 29 / 80\n",
            "t = 1, avg_loss = 0.3484\n",
            "t = 2, avg_loss = 0.3103\n",
            "t = 3, avg_loss = 0.2587\n",
            "t = 4, avg_loss = 0.2387\n",
            "t = 5, avg_loss = 0.4472\n",
            "t = 6, avg_loss = 0.4022\n",
            "t = 7, avg_loss = 0.3007\n",
            "t = 8, avg_loss = 0.3784\n",
            "t = 9, avg_loss = 0.2871\n",
            "t = 10, avg_loss = 0.2811\n",
            "t = 11, avg_loss = 0.3259\n",
            "t = 12, avg_loss = 0.2532\n",
            "t = 13, avg_loss = 0.3643\n",
            "t = 14, avg_loss = 0.4030\n",
            "t = 15, avg_loss = 0.3222\n",
            "t = 16, avg_loss = 0.4594\n",
            "t = 17, avg_loss = 0.3475\n",
            "t = 18, avg_loss = 0.2960\n",
            "t = 19, avg_loss = 0.3076\n",
            "t = 20, avg_loss = 0.5228\n",
            "t = 21, avg_loss = 0.4076\n",
            "t = 22, avg_loss = 0.4363\n",
            "t = 23, avg_loss = 0.4074\n",
            "t = 24, avg_loss = 0.5456\n",
            "t = 25, avg_loss = 0.3921\n",
            "Checking accuracy on test set\n",
            "Got 343 / 400 correct (85.75)\n",
            "acc = 0.857500\n",
            "Starting epoch 30 / 80\n",
            "t = 1, avg_loss = 0.3387\n",
            "t = 2, avg_loss = 0.3774\n",
            "t = 3, avg_loss = 0.4051\n",
            "t = 4, avg_loss = 0.2865\n",
            "t = 5, avg_loss = 0.3083\n",
            "t = 6, avg_loss = 0.4510\n",
            "t = 7, avg_loss = 0.4262\n",
            "t = 8, avg_loss = 0.2461\n",
            "t = 9, avg_loss = 0.3645\n",
            "t = 10, avg_loss = 0.3563\n",
            "t = 11, avg_loss = 0.3108\n",
            "t = 12, avg_loss = 0.3901\n",
            "t = 13, avg_loss = 0.2893\n",
            "t = 14, avg_loss = 0.3202\n",
            "t = 15, avg_loss = 0.3478\n",
            "t = 16, avg_loss = 0.3272\n",
            "t = 17, avg_loss = 0.4414\n",
            "t = 18, avg_loss = 0.4062\n",
            "t = 19, avg_loss = 0.3950\n",
            "t = 20, avg_loss = 0.3542\n",
            "t = 21, avg_loss = 0.3101\n",
            "t = 22, avg_loss = 0.3708\n",
            "t = 23, avg_loss = 0.3734\n",
            "t = 24, avg_loss = 0.3733\n",
            "t = 25, avg_loss = 0.4771\n",
            "Checking accuracy on test set\n",
            "Got 335 / 400 correct (83.75)\n",
            "acc = 0.837500\n",
            "Starting epoch 31 / 80\n",
            "t = 1, avg_loss = 0.2085\n",
            "t = 2, avg_loss = 0.3281\n",
            "t = 3, avg_loss = 0.3974\n",
            "t = 4, avg_loss = 0.2795\n",
            "t = 5, avg_loss = 0.3039\n",
            "t = 6, avg_loss = 0.3260\n",
            "t = 7, avg_loss = 0.3104\n",
            "t = 8, avg_loss = 0.3366\n",
            "t = 9, avg_loss = 0.3822\n",
            "t = 10, avg_loss = 0.3274\n",
            "t = 11, avg_loss = 0.4176\n",
            "t = 12, avg_loss = 0.4364\n",
            "t = 13, avg_loss = 0.2822\n",
            "t = 14, avg_loss = 0.3090\n",
            "t = 15, avg_loss = 0.3919\n",
            "t = 16, avg_loss = 0.3718\n",
            "t = 17, avg_loss = 0.5428\n",
            "t = 18, avg_loss = 0.3034\n",
            "t = 19, avg_loss = 0.4939\n",
            "t = 20, avg_loss = 0.3609\n",
            "t = 21, avg_loss = 0.3893\n",
            "t = 22, avg_loss = 0.3293\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0leS1FhWH_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot([print_every*batch_size*(i+1) for i in range((len(avg_loss_list)))],avg_loss_list)\n",
        "print(\"Loss:\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpTejWWGWIVi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot([i+1 for i in range((len(acc_list)))],acc_list)\n",
        "print(\"Accurancy:\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}