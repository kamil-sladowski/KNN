{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN_Avg_No_Relu2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6dbf998464524659a108ca4919037ad9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4fd55f76811945e482c3027a2b3797ba",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2f843db67bd3442293834f5c2b63e720",
              "IPY_MODEL_63ea1f6487ef4af78129406e95af6d80"
            ]
          }
        },
        "4fd55f76811945e482c3027a2b3797ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2f843db67bd3442293834f5c2b63e720": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_64ca0ee9ac704dfd973c7c716d196eea",
            "_dom_classes": [],
            "description": " 88%",
            "_model_name": "IntProgressModel",
            "bar_style": "danger",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 88,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aacd73c7a5f44695a77539b7bf1ba806"
          }
        },
        "63ea1f6487ef4af78129406e95af6d80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bc5c7bda96fd48d993cd2c0d3d9a3338",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 88/100 [20:11&lt;01:07,  5.62s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_24429900554b4c1bbe4b8c9a11f0a6a1"
          }
        },
        "64ca0ee9ac704dfd973c7c716d196eea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aacd73c7a5f44695a77539b7bf1ba806": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bc5c7bda96fd48d993cd2c0d3d9a3338": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "24429900554b4c1bbe4b8c9a11f0a6a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0ae929c62dd7400b9f51e7b62fba4b6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bd4d9a2b8e6b4cfe9727c08206deaff8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_32c8b3556f5548fabdc225150ea64192",
              "IPY_MODEL_8abaad212772426aa9e8ce636401a257"
            ]
          }
        },
        "bd4d9a2b8e6b4cfe9727c08206deaff8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "32c8b3556f5548fabdc225150ea64192": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a6bddaa5e953464f84b5ea25a7b9a7ad",
            "_dom_classes": [],
            "description": " 90%",
            "_model_name": "IntProgressModel",
            "bar_style": "danger",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 90,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2fbf0d377805445e8e8b483b16fac1cb"
          }
        },
        "8abaad212772426aa9e8ce636401a257": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_62cbe3414f994028b65c2471f64f0239",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 90/100 [08:52&lt;00:55,  5.56s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5eac49806b0947b3996122670e688288"
          }
        },
        "a6bddaa5e953464f84b5ea25a7b9a7ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2fbf0d377805445e8e8b483b16fac1cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "62cbe3414f994028b65c2471f64f0239": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5eac49806b0947b3996122670e688288": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "64c48c844e394895b3984ef09173f749": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_44aacaf385da4cf88ca0a1170b5c179a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_16daeaba47fe477b8fd065be33bdb690",
              "IPY_MODEL_2b2253786b0b41e98f90ed8e721ced8f"
            ]
          }
        },
        "44aacaf385da4cf88ca0a1170b5c179a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "16daeaba47fe477b8fd065be33bdb690": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_af4beb9b100047edbc5bde8ecfbb19a7",
            "_dom_classes": [],
            "description": " 88%",
            "_model_name": "IntProgressModel",
            "bar_style": "danger",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 88,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_18c2db9831e1439095feaac21a45cad7"
          }
        },
        "2b2253786b0b41e98f90ed8e721ced8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1aa574a1431c4c8399432b04c5c21268",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 88/100 [08:44&lt;01:18,  6.53s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f47107dcf5b248ecb39ac53d8a29ce36"
          }
        },
        "af4beb9b100047edbc5bde8ecfbb19a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "18c2db9831e1439095feaac21a45cad7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1aa574a1431c4c8399432b04c5c21268": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f47107dcf5b248ecb39ac53d8a29ce36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7e11c00cad734871856b4010e51be936": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0b83346625e641f59f70a2366a33b189",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7c69966d1a2e48fea5c18b6b44774932",
              "IPY_MODEL_822de21f3af84e9b88f082515628d357"
            ]
          }
        },
        "0b83346625e641f59f70a2366a33b189": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7c69966d1a2e48fea5c18b6b44774932": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6d6386a9a70d4f1184219a045a8d0233",
            "_dom_classes": [],
            "description": " 87%",
            "_model_name": "IntProgressModel",
            "bar_style": "danger",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 87,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_88e29fb2aef843bab94b38a531318e37"
          }
        },
        "822de21f3af84e9b88f082515628d357": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_96e1394dd7084e698cd88fadda81407b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 87/100 [08:36&lt;01:11,  5.52s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fba389d6c1254abd9ee9b383bab21f4f"
          }
        },
        "6d6386a9a70d4f1184219a045a8d0233": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "88e29fb2aef843bab94b38a531318e37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "96e1394dd7084e698cd88fadda81407b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fba389d6c1254abd9ee9b383bab21f4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamilo116/KNN/blob/master/KNN_Avg_No_Relu2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7ReM7FU-xs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import sys\n",
        "from random import shuffle\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms as transforms\n",
        "import timeit\n",
        "\n",
        "np.random.seed(4) \n",
        "torch.manual_seed(4) \n",
        "torch.cuda.manual_seed(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYIMZ8QyYewD",
        "colab_type": "code",
        "outputId": "de5081e9-11ef-46d8-b1a0-0349ecc6aa75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "! git clone https://github.com/wang-chen/kervolution.git \n",
        "\n",
        "sys.path.append(\"kervolution/\")\n",
        "from kervolution import Kerv2d\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'kervolution'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects:  16% (1/6)\u001b[K\rremote: Counting objects:  33% (2/6)\u001b[K\rremote: Counting objects:  50% (3/6)\u001b[K\rremote: Counting objects:  66% (4/6)\u001b[K\rremote: Counting objects:  83% (5/6)\u001b[K\rremote: Counting objects: 100% (6/6)\u001b[K\rremote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 53 (delta 2), reused 0 (delta 0), pack-reused 47\u001b[K\n",
            "Unpacking objects: 100% (53/53), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvbKg4VJXKY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LIMIT_IMAGES_NUM = 1000\n",
        "train_test_split_size = 0.2\n",
        "image_resize = (100, 100)\n",
        "batch_size = 64\n",
        "num_workers = 0\n",
        "\n",
        "in_channels = 3\n",
        "out_channels_1 = 16\n",
        "out_channels_2 = 24\n",
        "out_channels_3 = 32\n",
        "out_channels_4 = 48\n",
        "out_channels_5 = 64\n",
        "out_channels_6 = 100\n",
        "\n",
        "kernel_size = 3\n",
        "padding_1 = 1\n",
        "num_epochs = 50\n",
        "\n",
        "learning_rate = 0.0001\n",
        "weight_decay = 0\n",
        "\n",
        "MALIGNANT_DATASET = '/content/drive/My Drive/Colab_data/malignant/malignant/'\n",
        "BENIGN_DATASET = '/content/drive/My Drive/Colab_data/benign/benign/'\n",
        "DATA_FOLDER = '/content/drive/My Drive/Colab_data/'\n",
        "model_backup_path = os.path.join(DATA_FOLDER, 'backup_model_2') \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMOHez_kHZD6",
        "colab_type": "code",
        "outputId": "8b39e370-d006-45db-e605-fa6312cb6424",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b8P1NdXfVdX",
        "colab_type": "code",
        "outputId": "b66f9ab5-909b-4f08-c357-c31b63ac71c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "benign_file_list = sorted(os.listdir(BENIGN_DATASET))\n",
        "malignant_file_list = sorted(os.listdir(MALIGNANT_DATASET))\n",
        "shuffle(benign_file_list)\n",
        "shuffle(malignant_file_list)\n",
        "benign_file_list = benign_file_list[:LIMIT_IMAGES_NUM]\n",
        "malignant_file_list = malignant_file_list[:LIMIT_IMAGES_NUM]\n",
        "\n",
        "print(f\"Number of benign {len(benign_file_list)} images\")\n",
        "print(f\"Number of malignant {len(malignant_file_list)} images\")\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize(image_resize),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of benign 1000 images\n",
            "Number of malignant 1000 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGDQfal74BLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "benign_dict = {filename: 0 for filename in benign_file_list}\n",
        "malignant_dict = {filename: 1 for filename in malignant_file_list}\n",
        "img_class_dict = {**benign_dict , **malignant_dict}\n",
        "labeled_data = pd.Series(img_class_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvAAOqmVfVll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IsicDataset(Dataset):\n",
        "    def __init__(self, data_folder, labeled_data, \n",
        "                 transform=transforms.Compose([transforms.ToTensor()])):\n",
        "        self.labeled_data = labeled_data\n",
        "        self.transform = transform\n",
        "        self.data_folder = data_folder\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labeled_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        label = self.labeled_data[index]\n",
        "        if label == 0:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"benign\", \"benign\", index ))\n",
        "        else:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"malignant\", \"malignant\", index ))\n",
        "        image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "    @property\n",
        "    def labels(self):\n",
        "      return self.labeled_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSuYqjLAYrWA",
        "colab_type": "code",
        "outputId": "68a8fd4d-3eb1-4c88-8c26-e419d435f388",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        }
      },
      "source": [
        " \n",
        "dataset = IsicDataset(DATA_FOLDER, labeled_data, transform=data_transforms)\n",
        "print(dataset.labels)\n",
        "\n",
        "X_train, X_test = train_test_split(dataset.labels, test_size=train_test_split_size)\n",
        "print(\"number of training data: \",len(X_train))\n",
        "print(\"number of testing  data: \",len(X_test))\n",
        "\n",
        "train_sampler = SubsetRandomSampler(list(X_train.index))\n",
        "valid_sampler = SubsetRandomSampler(list(X_test.index))\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ISIC_0002557.jpeg    0\n",
            "ISIC_0000726.jpeg    0\n",
            "ISIC_0001024.jpeg    0\n",
            "ISIC_0000225.jpeg    0\n",
            "ISIC_0002706.jpeg    0\n",
            "                    ..\n",
            "ISIC_0011268.jpeg    1\n",
            "ISIC_0013472.jpeg    1\n",
            "ISIC_0014181.jpeg    1\n",
            "ISIC_0014092.jpeg    1\n",
            "ISIC_0010410.jpeg    1\n",
            "Length: 2000, dtype: int64\n",
            "number of training data:  1600\n",
            "number of testing  data:  400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e8nFBR6Yug5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "def train(model, train_loader ,loss_fn, optimizer, num_epochs=1, starting_from_epoch=1):\n",
        "    total_loss =0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
        "        model.train()\n",
        "\n",
        "        for t, (x, y) in enumerate(train_loader):\n",
        "            x_var = Variable(x.type(gpu_dtype))\n",
        "            y_var = Variable(y.type(gpu_dtype).long())\n",
        "            scores = model(x_var)\n",
        "            loss = loss_fn(scores, y_var)\n",
        "            total_loss += loss.data\n",
        "            \n",
        "            if (t + 1) % print_every == 0:\n",
        "                avg_loss = total_loss/print_every\n",
        "                print('t = %d, avg_loss = %.4f' % (t + 1, avg_loss) )\n",
        "                avg_loss_list.append(avg_loss)\n",
        "                total_loss = 0\n",
        "                \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        acc = check_accuracy(model_gpu, valid_loader)\n",
        "        print('acc = %f' %(acc))\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model_gpu.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            'acc_list': acc_list,\n",
        "            }, model_backup_path)\n",
        "            \n",
        "def check_accuracy(model, loader):\n",
        "    print('Checking accuracy on test set')   \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval() \n",
        "    for x, y in loader:\n",
        "        x_var = Variable(x.type(gpu_dtype))\n",
        "\n",
        "        scores = model(x_var)\n",
        "        _, preds = scores.data.cpu().max(1)\n",
        "        num_correct += (preds == y).sum()\n",
        "        num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    acc_list.append(acc)\n",
        "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "    return acc\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggvpMu36Yw2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.size()\n",
        "        return x.view(N, -1)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgmexhBRZAK6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "outputId": "c6c27629-0bb7-4b47-cfb3-d4faa6382ea9"
      },
      "source": [
        "gpu_dtype = torch.cuda.FloatTensor\n",
        "\n",
        "print_every = 2\n",
        "\n",
        "\n",
        "'''\n",
        "Kerv2d\n",
        "kervolution with following options:\n",
        "kernel_type: [linear, polynomial, gaussian, etc.]\n",
        "default is convolution:\n",
        "          kernel_type --> linear,\n",
        "balance, power, gamma is valid only when the kernel_type is specified\n",
        "if learnable_kernel = True,  they just be the initial value of learable parameters\n",
        "if learnable_kernel = False, they are the value of kernel_type's parameter\n",
        "the parameter [power] cannot be learned due to integer limitation\n",
        "dilation (int or tuple, optional): Spacing between kernel\n",
        "elements. Default: 1\n",
        "groups (int, optional): Number of blocked connections from input\n",
        "channels to output channels. Default: 1\n",
        "bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n",
        "kernel_type (str), Default: 'linear'\n",
        "learnable_kernel (bool): Learnable kernel parameters.  Default: False \n",
        "balance: 0, 1\n",
        "power: 3, 4, 5\n",
        "gamma:\n",
        "'''\n",
        "\n",
        "\n",
        "model_base = nn.Sequential( \n",
        "                nn.Kerv2d(in_channels , out_channels_1, padding=padding_1, dilation=1, groups=1, bias=True, \n",
        "                          kernel_type='gaussian', kernel_size=kernel_size, learnable_kernel=True,\n",
        "                          kernel_regularizer=True, stride=1, balance=0.5, power=20, gamma=1\n",
        "                          ),\n",
        "                nn.BatchNorm2d(out_channels_1),\n",
        "                nn.AvgPool2d(2, stride=2), \n",
        "                nn.Conv2d(out_channels_1 , out_channels_2, padding= padding_1, kernel_size=kernel_size, stride=1), \n",
        "                nn.BatchNorm2d(out_channels_2),\n",
        "                nn.AvgPool2d(2, stride=2), \n",
        "                nn.Conv2d(out_channels_2 , out_channels_3, padding= padding_1, kernel_size=kernel_size, stride=1), \n",
        "                nn.Dropout(0.1), \n",
        "                nn.BatchNorm2d(out_channels_3),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_3 , out_channels_4, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                \n",
        "                \n",
        "                nn.BatchNorm2d(out_channels_4),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_4 , out_channels_5, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.BatchNorm2d(out_channels_5),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_5 , out_channels_6, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.BatchNorm2d(out_channels_6),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "               \n",
        "                nn.Dropout(0.5),\n",
        "                Flatten(),\n",
        "                nn.Linear(100,64),\n",
        "                nn.Linear(64,2)\n",
        "            )\n",
        "model_gpu = model_base.type(gpu_dtype)\n",
        "print(model_gpu)\n",
        "loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) \n",
        "\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Kerv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (3): Conv2d(16, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (6): Conv2d(24, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (7): Dropout(p=0.1, inplace=False)\n",
            "  (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (10): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (11): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (12): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (13): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (14): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (15): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (16): Conv2d(64, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (17): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (18): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (19): Dropout(p=0.5, inplace=False)\n",
            "  (20): Flatten()\n",
            "  (21): Linear(in_features=100, out_features=64, bias=True)\n",
            "  (22): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nr2sQUvYlXYm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs)\n",
        "#check_accuracy(model_gpu, valid_loader)\n",
        "#check_accuracy(model_gpu, valid_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkR_h7GRTJv4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6dbf998464524659a108ca4919037ad9",
            "4fd55f76811945e482c3027a2b3797ba",
            "2f843db67bd3442293834f5c2b63e720",
            "63ea1f6487ef4af78129406e95af6d80",
            "64ca0ee9ac704dfd973c7c716d196eea",
            "aacd73c7a5f44695a77539b7bf1ba806",
            "bc5c7bda96fd48d993cd2c0d3d9a3338",
            "24429900554b4c1bbe4b8c9a11f0a6a1"
          ]
        },
        "outputId": "3d6b60d8-88a2-473b-9ab8-3d38339d0b3e"
      },
      "source": [
        "! pip install torch-lr-finder -v --global-option=\"amp\"\n",
        "from torch_lr_finder import LRFinder\n",
        "\n",
        "lr_finder = LRFinder(model_gpu, optimizer, loss_fn, device=\"cuda\")\n",
        "\n",
        "lr_finder.range_test(train_loader, end_lr=1, num_iter=100, start_lr=0.00001)\n",
        "lr_finder.plot()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pip/_internal/commands/install.py:283: UserWarning: Disabling all use of wheels due to the use of --build-options / --global-options / --install-options.\n",
            "  cmdoptions.check_install_build_global(options)\n",
            "Created temporary directory: /tmp/pip-ephem-wheel-cache-ha2nu6y4\n",
            "Created temporary directory: /tmp/pip-req-tracker-rohvjith\n",
            "Created requirements tracker '/tmp/pip-req-tracker-rohvjith'\n",
            "Created temporary directory: /tmp/pip-install-qcnkun2f\n",
            "1 location(s) to search for versions of torch-lr-finder:\n",
            "* https://pypi.org/simple/torch-lr-finder/\n",
            "Getting page https://pypi.org/simple/torch-lr-finder/\n",
            "Found index url https://pypi.org/simple\n",
            "Looking up \"https://pypi.org/simple/torch-lr-finder/\" in the cache\n",
            "Request header has \"max_age\" as 0, cache bypassed\n",
            "Starting new HTTPS connection (1): pypi.org:443\n",
            "https://pypi.org:443 \"GET /simple/torch-lr-finder/ HTTP/1.1\" 200 1168\n",
            "Updating cache with response from \"https://pypi.org/simple/torch-lr-finder/\"\n",
            "Caching due to etag\n",
            "Analyzing links from page https://pypi.org/simple/torch-lr-finder/\n",
            "  Found link https://files.pythonhosted.org/packages/5d/cd/91f910b0b05cb72ad66db3b8a82b86f8e1ab4241398eef8dc4dfd033a7eb/torch-lr-finder-0.0.1.tar.gz#sha256=3d1f91f0232f069325b456348b97d7936921f77393cef10e8253b3cb7cc2932d (from https://pypi.org/simple/torch-lr-finder/) (requires-python:>=2.7), version: 0.0.1\n",
            "  Skipping link: No binaries permitted for torch-lr-finder: https://files.pythonhosted.org/packages/62/7c/397078ef7ca83880a35037285fd9d1f0e70ab5414db3a6f81e868c7230e4/torch_lr_finder-0.0.1-py3-none-any.whl#sha256=7f690a2e093b10c0e1935e013572c4be7225820c5be40af56139a6c28626db9e (from https://pypi.org/simple/torch-lr-finder/) (requires-python:>=2.7)\n",
            "  Found link https://files.pythonhosted.org/packages/0b/7b/a8ccefca947877cb0112dc3b1ceea38caa24b9f75d6601769075ab6d624b/torch-lr-finder-0.1.tar.gz#sha256=cfee0b94701cd51eb69856a2def48423f5c26cbe74514880a1f5eb09d90aa841 (from https://pypi.org/simple/torch-lr-finder/) (requires-python:>=2.7), version: 0.1\n",
            "  Skipping link: No binaries permitted for torch-lr-finder: https://files.pythonhosted.org/packages/c5/a8/1a003a5b3ff76d3ee55e814028f2fd4d79c555956c36eaebd663a9cf0935/torch_lr_finder-0.1-py3-none-any.whl#sha256=1f218b9704e6cbac26d754c72e088124411c7a495665517f91f05c050d55443e (from https://pypi.org/simple/torch-lr-finder/) (requires-python:>=2.7)\n",
            "  Found link https://files.pythonhosted.org/packages/6f/05/8384b9c02748b40d17a08c18cea7d090872423990934b1a95d0db0ea3481/torch-lr-finder-0.1.2.tar.gz#sha256=79b97995cab86b392230497313857891041861d6d63d1b608fb285e01f8bfafa (from https://pypi.org/simple/torch-lr-finder/) (requires-python:>=2.7), version: 0.1.2\n",
            "  Skipping link: No binaries permitted for torch-lr-finder: https://files.pythonhosted.org/packages/8d/5a/28e71a45ff80efb2ed0759ceef0d34a713f4376119746246c12671c0c807/torch_lr_finder-0.1.2-py3-none-any.whl#sha256=c2af8c2cd539d29738c8903b5f604c11367de8415a90fafdd3cdc179c5d13bcc (from https://pypi.org/simple/torch-lr-finder/) (requires-python:>=2.7)\n",
            "  Found link https://files.pythonhosted.org/packages/92/d5/893fc09e1a9fc72bcef256806edb911db8e3762dc3cb90fd0f817d45f8c6/torch-lr-finder-0.1.3.tar.gz#sha256=7ad4f78300c5a6754890765db51bcc2f0335b05208010c5e97a0f174ef0036d9 (from https://pypi.org/simple/torch-lr-finder/) (requires-python:>=2.7), version: 0.1.3\n",
            "  Skipping link: No binaries permitted for torch-lr-finder: https://files.pythonhosted.org/packages/cd/ff/38ec8729a7a0a4d8045f100705a5dc1ae259d169e6f5f67c6e21c3f9d5cf/torch_lr_finder-0.1.3-py3-none-any.whl#sha256=d9ed12a5ad5a37c8df1d6e88818ef06a9a9585187b3ea2abf58ace7670474df8 (from https://pypi.org/simple/torch-lr-finder/) (requires-python:>=2.7)\n",
            "  Found link https://files.pythonhosted.org/packages/c3/27/976e1a3bbf9721619a06304b8db7ab9c40207ab29e7e0ba84bbe3ff28ad0/torch-lr-finder-0.1.4.tar.gz#sha256=8329faef69f5638fc641813f13a2fdec3156d754e1fa484bb4ddf6cd28f2feef (from https://pypi.org/simple/torch-lr-finder/) (requires-python:>=2.7), version: 0.1.4\n",
            "  Skipping link: No binaries permitted for torch-lr-finder: https://files.pythonhosted.org/packages/68/06/7301400132b63f96c3b4f5fbb5033130b9d07b85c9e0e247d4ac03451d80/torch_lr_finder-0.1.4-py3-none-any.whl#sha256=fb9ec3599b913202540ff3b960c691c1a07abeab0c2b7e60b314704bc886193e (from https://pypi.org/simple/torch-lr-finder/) (requires-python:>=2.7)\n",
            "Given no hashes to check 5 links for project 'torch-lr-finder': discarding no candidates\n",
            "Using version 0.1.4 (newest of versions: 0.0.1, 0.1, 0.1.2, 0.1.3, 0.1.4)\n",
            "Collecting torch-lr-finder\n",
            "  Created temporary directory: /tmp/pip-unpack-xeebqh4b\n",
            "  Looking up \"https://files.pythonhosted.org/packages/c3/27/976e1a3bbf9721619a06304b8db7ab9c40207ab29e7e0ba84bbe3ff28ad0/torch-lr-finder-0.1.4.tar.gz\" in the cache\n",
            "  No cache entry available\n",
            "  Starting new HTTPS connection (1): files.pythonhosted.org:443\n",
            "  https://files.pythonhosted.org:443 \"GET /packages/c3/27/976e1a3bbf9721619a06304b8db7ab9c40207ab29e7e0ba84bbe3ff28ad0/torch-lr-finder-0.1.4.tar.gz HTTP/1.1\" 200 9783\n",
            "  Downloading https://files.pythonhosted.org/packages/c3/27/976e1a3bbf9721619a06304b8db7ab9c40207ab29e7e0ba84bbe3ff28ad0/torch-lr-finder-0.1.4.tar.gz\n",
            "  Ignoring unknown cache-control directive: immutable\n",
            "  Updating cache with response from \"https://files.pythonhosted.org/packages/c3/27/976e1a3bbf9721619a06304b8db7ab9c40207ab29e7e0ba84bbe3ff28ad0/torch-lr-finder-0.1.4.tar.gz\"\n",
            "  Caching due to etag\n",
            "  Added torch-lr-finder from https://files.pythonhosted.org/packages/c3/27/976e1a3bbf9721619a06304b8db7ab9c40207ab29e7e0ba84bbe3ff28ad0/torch-lr-finder-0.1.4.tar.gz#sha256=8329faef69f5638fc641813f13a2fdec3156d754e1fa484bb4ddf6cd28f2feef to build tracker '/tmp/pip-req-tracker-rohvjith'\n",
            "    Running setup.py (path:/tmp/pip-install-qcnkun2f/torch-lr-finder/setup.py) egg_info for package torch-lr-finder\n",
            "    Running command python setup.py egg_info\n",
            "    running egg_info\n",
            "    creating /tmp/pip-install-qcnkun2f/torch-lr-finder/pip-egg-info/torch_lr_finder.egg-info\n",
            "    writing /tmp/pip-install-qcnkun2f/torch-lr-finder/pip-egg-info/torch_lr_finder.egg-info/PKG-INFO\n",
            "    writing dependency_links to /tmp/pip-install-qcnkun2f/torch-lr-finder/pip-egg-info/torch_lr_finder.egg-info/dependency_links.txt\n",
            "    writing requirements to /tmp/pip-install-qcnkun2f/torch-lr-finder/pip-egg-info/torch_lr_finder.egg-info/requires.txt\n",
            "    writing top-level names to /tmp/pip-install-qcnkun2f/torch-lr-finder/pip-egg-info/torch_lr_finder.egg-info/top_level.txt\n",
            "    writing manifest file '/tmp/pip-install-qcnkun2f/torch-lr-finder/pip-egg-info/torch_lr_finder.egg-info/SOURCES.txt'\n",
            "    reading manifest file '/tmp/pip-install-qcnkun2f/torch-lr-finder/pip-egg-info/torch_lr_finder.egg-info/SOURCES.txt'\n",
            "    writing manifest file '/tmp/pip-install-qcnkun2f/torch-lr-finder/pip-egg-info/torch_lr_finder.egg-info/SOURCES.txt'\n",
            "  Source in /tmp/pip-install-qcnkun2f/torch-lr-finder has version 0.1.4, which satisfies requirement torch-lr-finder from https://files.pythonhosted.org/packages/c3/27/976e1a3bbf9721619a06304b8db7ab9c40207ab29e7e0ba84bbe3ff28ad0/torch-lr-finder-0.1.4.tar.gz#sha256=8329faef69f5638fc641813f13a2fdec3156d754e1fa484bb4ddf6cd28f2feef\n",
            "  Removed torch-lr-finder from https://files.pythonhosted.org/packages/c3/27/976e1a3bbf9721619a06304b8db7ab9c40207ab29e7e0ba84bbe3ff28ad0/torch-lr-finder-0.1.4.tar.gz#sha256=8329faef69f5638fc641813f13a2fdec3156d754e1fa484bb4ddf6cd28f2feef from build tracker '/tmp/pip-req-tracker-rohvjith'\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from torch-lr-finder) (3.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch-lr-finder) (1.18.2)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from torch-lr-finder) (1.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torch-lr-finder) (4.38.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->torch-lr-finder) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->torch-lr-finder) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->torch-lr-finder) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->torch-lr-finder) (2.4.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->torch-lr-finder) (1.12.0)\n",
            "Skipping wheel build for torch-lr-finder, due to binaries being disabled for it.\n",
            "Installing collected packages: torch-lr-finder\n",
            "  Created temporary directory: /tmp/pip-record-f6xpmqz0\n",
            "    Running command /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-qcnkun2f/torch-lr-finder/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-qcnkun2f/torch-lr-finder/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' amp install --record /tmp/pip-record-f6xpmqz0/install-record.txt --single-version-externally-managed --compile\n",
            "    /usr/local/lib/python3.6/dist-packages/pip/_internal/commands/install.py:283: UserWarning: Disabling all use of wheels due to the use of --build-options / --global-options / --install-options.\n",
            "      cmdoptions.check_install_build_global(options)\n",
            "    Created temporary directory: /tmp/pip-ephem-wheel-cache-tm0l4yaj\n",
            "    Re-using requirements tracker '/tmp/pip-req-tracker-rohvjith'\n",
            "    Created temporary directory: /tmp/pip-install-jpk9b56t\n",
            "    Collecting git+https://github.com/NVIDIA/apex\n",
            "      Created temporary directory: /tmp/pip-req-build-9b1v7jzq\n",
            "      Cloning https://github.com/NVIDIA/apex to /tmp/pip-req-build-9b1v7jzq\n",
            "      Running command git clone -q https://github.com/NVIDIA/apex /tmp/pip-req-build-9b1v7jzq\n",
            "      Running command git submodule update --init --recursive -q\n",
            "      Added git+https://github.com/NVIDIA/apex to build tracker '/tmp/pip-req-tracker-rohvjith'\n",
            "        Running setup.py (path:/tmp/pip-req-build-9b1v7jzq/setup.py) egg_info for package from git+https://github.com/NVIDIA/apex\n",
            "        Running command python setup.py egg_info\n",
            "        torch.__version__  =  1.4.0\n",
            "        running egg_info\n",
            "        creating /tmp/pip-req-build-9b1v7jzq/pip-egg-info/apex.egg-info\n",
            "        writing /tmp/pip-req-build-9b1v7jzq/pip-egg-info/apex.egg-info/PKG-INFO\n",
            "        writing dependency_links to /tmp/pip-req-build-9b1v7jzq/pip-egg-info/apex.egg-info/dependency_links.txt\n",
            "        writing top-level names to /tmp/pip-req-build-9b1v7jzq/pip-egg-info/apex.egg-info/top_level.txt\n",
            "        writing manifest file '/tmp/pip-req-build-9b1v7jzq/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
            "        writing manifest file '/tmp/pip-req-build-9b1v7jzq/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
            "        /tmp/pip-req-build-9b1v7jzq/setup.py:46: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "          warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "      Source in /tmp/pip-req-build-9b1v7jzq has version 0.1, which satisfies requirement apex==0.1 from git+https://github.com/NVIDIA/apex\n",
            "      Removed apex==0.1 from git+https://github.com/NVIDIA/apex from build tracker '/tmp/pip-req-tracker-rohvjith'\n",
            "    Skipping wheel build for apex, due to binaries being disabled for it.\n",
            "    Installing collected packages: apex\n",
            "      Created temporary directory: /tmp/pip-record-ep04zco9\n",
            "        Running setup.py install for apex: started\n",
            "        Running command /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-9b1v7jzq/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-9b1v7jzq/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' --cpp_ext --cuda_ext install --record /tmp/pip-record-ep04zco9/install-record.txt --single-version-externally-managed --compile\n",
            "        torch.__version__  =  1.4.0\n",
            "        /tmp/pip-req-build-9b1v7jzq/setup.py:46: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "          warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "\n",
            "        Compiling cuda extensions with\n",
            "        nvcc: NVIDIA (R) Cuda compiler driver\n",
            "        Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "        Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "        Cuda compilation tools, release 10.1, V10.1.243\n",
            "        from /usr/local/cuda/bin\n",
            "\n",
            "        running install\n",
            "        running build\n",
            "        running build_py\n",
            "        creating build\n",
            "        creating build/lib.linux-x86_64-3.6\n",
            "        creating build/lib.linux-x86_64-3.6/apex\n",
            "        copying apex/__init__.py -> build/lib.linux-x86_64-3.6/apex\n",
            "        creating build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "        copying apex/optimizers/__init__.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "        copying apex/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "        copying apex/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "        copying apex/optimizers/fused_novograd.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "        copying apex/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "        creating build/lib.linux-x86_64-3.6/apex/pyprof\n",
            "        copying apex/pyprof/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof\n",
            "        creating build/lib.linux-x86_64-3.6/apex/normalization\n",
            "        copying apex/normalization/__init__.py -> build/lib.linux-x86_64-3.6/apex/normalization\n",
            "        copying apex/normalization/fused_layer_norm.py -> build/lib.linux-x86_64-3.6/apex/normalization\n",
            "        creating build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
            "        copying apex/multi_tensor_apply/__init__.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
            "        copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
            "        creating build/lib.linux-x86_64-3.6/apex/parallel\n",
            "        copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "        copying apex/parallel/optimized_sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "        copying apex/parallel/__init__.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "        copying apex/parallel/LARC.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "        copying apex/parallel/sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "        copying apex/parallel/distributed.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "        copying apex/parallel/sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "        copying apex/parallel/multiproc.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "        creating build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "        copying apex/fp16_utils/__init__.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "        copying apex/fp16_utils/fp16util.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "        copying apex/fp16_utils/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "        copying apex/fp16_utils/loss_scaler.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "        creating build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "        copying apex/reparameterization/__init__.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "        copying apex/reparameterization/reparameterization.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "        copying apex/reparameterization/weight_norm.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "        creating build/lib.linux-x86_64-3.6/apex/contrib\n",
            "        copying apex/contrib/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib\n",
            "        creating build/lib.linux-x86_64-3.6/apex/mlp\n",
            "        copying apex/mlp/__init__.py -> build/lib.linux-x86_64-3.6/apex/mlp\n",
            "        copying apex/mlp/mlp.py -> build/lib.linux-x86_64-3.6/apex/mlp\n",
            "        creating build/lib.linux-x86_64-3.6/apex/RNN\n",
            "        copying apex/RNN/cells.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "        copying apex/RNN/__init__.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "        copying apex/RNN/RNNBackend.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "        copying apex/RNN/models.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "        creating build/lib.linux-x86_64-3.6/apex/amp\n",
            "        copying apex/amp/opt.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "        copying apex/amp/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "        copying apex/amp/scaler.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "        copying apex/amp/__version__.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "        copying apex/amp/_amp_state.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "        copying apex/amp/rnn_compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "        copying apex/amp/utils.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "        copying apex/amp/wrap.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "        copying apex/amp/_initialize.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "        copying apex/amp/frontend.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "        copying apex/amp/_process_optimizer.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "        copying apex/amp/compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "        copying apex/amp/amp.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "        copying apex/amp/handle.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "        creating build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
            "        copying apex/pyprof/nvtx/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
            "        copying apex/pyprof/nvtx/nvmarker.py -> build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
            "        creating build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "        copying apex/pyprof/parse/__main__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "        copying apex/pyprof/parse/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "        copying apex/pyprof/parse/kernel.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "        copying apex/pyprof/parse/db.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "        copying apex/pyprof/parse/nvvp.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "        copying apex/pyprof/parse/parse.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "        creating build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/utility.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/prof.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/__main__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/misc.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/conv.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/embedding.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/output.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/usage.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/index_slice_join_mutate.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/convert.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/pooling.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/linear.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/pointwise.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/activation.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/base.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/dropout.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/optim.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/data.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/reduction.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/blas.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/loss.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/softmax.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/randomSample.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/normalization.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        copying apex/pyprof/prof/recurrentCell.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "        creating build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "        copying apex/contrib/optimizers/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "        copying apex/contrib/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "        copying apex/contrib/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "        copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "        copying apex/contrib/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "        creating build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n",
            "        copying apex/contrib/groupbn/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n",
            "        copying apex/contrib/groupbn/batch_norm.py -> build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n",
            "        creating build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n",
            "        copying apex/contrib/xentropy/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n",
            "        copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n",
            "        creating build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "        copying apex/contrib/multihead_attn/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "        copying apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "        copying apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "        copying apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "        copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "        copying apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "        copying apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "        copying apex/contrib/multihead_attn/self_multihead_attn.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "        copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "        creating build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "        copying apex/amp/lists/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "        copying apex/amp/lists/functional_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "        copying apex/amp/lists/tensor_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "        copying apex/amp/lists/torch_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "        running build_ext\n",
            "        building 'apex_C' extension\n",
            "        creating build/temp.linux-x86_64-3.6\n",
            "        creating build/temp.linux-x86_64-3.6/csrc\n",
            "        x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c csrc/flatten_unflatten.cpp -o build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=apex_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "        x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -o build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so\n",
            "        building 'amp_C' extension\n",
            "        x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/amp_C_frontend.cpp -o build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "        /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_sgd_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_sgd_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++11\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_scale_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++11\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_axpby_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++11\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_l2norm_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++11\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb_stage_1.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_1.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++11\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb_stage_2.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_2.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++11\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_adam.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adam.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++11\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_novograd.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_novograd.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++11\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++11\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_sgd_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_1.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_2.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adam.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_novograd.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so\n",
            "        building 'syncbn' extension\n",
            "        x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/syncbn.cpp -o build/temp.linux-x86_64-3.6/csrc/syncbn.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "        /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/welford.cu -o build/temp.linux-x86_64-3.6/csrc/welford.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++11\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/syncbn.o build/temp.linux-x86_64-3.6/csrc/welford.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so\n",
            "        building 'fused_layer_norm_cuda' extension\n",
            "        x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/layer_norm_cuda.cpp -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "        /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/layer_norm_cuda_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -maxrregcount=50 -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++11\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "        building 'mlp_cuda' extension\n",
            "        x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/mlp.cpp -o build/temp.linux-x86_64-3.6/csrc/mlp.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "        csrc/mlp.cpp: In function â€˜std::vector<at::Tensor> mlp_forward(std::vector<at::Tensor>)â€™:\n",
            "        csrc/mlp.cpp:47:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "           for (int i = 0; i < num_layers; i++) {\n",
            "                           ~~^~~~~~~~~~~~\n",
            "        csrc/mlp.cpp:56:68: warning: narrowing conversion of â€˜reserved_sizeâ€™ from â€˜long unsigned intâ€™ to â€˜long intâ€™ inside { } [-Wnarrowing]\n",
            "           auto reserved_space = at::empty({reserved_size}, inputs[0].type());\n",
            "                                                                            ^\n",
            "        csrc/mlp.cpp:56:68: warning: narrowing conversion of â€˜reserved_sizeâ€™ from â€˜long unsigned intâ€™ to â€˜long intâ€™ inside { } [-Wnarrowing]\n",
            "        In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
            "                         from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                         from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                         from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                         from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                         from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                         from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                         from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                         from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                         from csrc/mlp.cpp:1:\n",
            "        csrc/mlp.cpp: In lambda function:\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:116:56: warning: â€˜c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)â€™ is deprecated [-Wdeprecated-declarations]\n",
            "             at::ScalarType _st = ::detail::scalar_type(the_type);                    \\\n",
            "                                                                ^\n",
            "        csrc/mlp.cpp:58:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "           AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "           ^\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:31:23: note: declared here\n",
            "         inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
            "                               ^~~~~~~~~~~\n",
            "        csrc/mlp.cpp: In lambda function:\n",
            "        csrc/mlp.cpp:61:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "             for (int i = 0; i < num_layers; i++) {\n",
            "                             ~~^~~\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "             return __VA_ARGS__();                          \\\n",
            "                    ^~~~~~~~~~~\n",
            "        csrc/mlp.cpp:58:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "           AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "           ^\n",
            "        csrc/mlp.cpp:65:10: warning: unused variable â€˜resultâ€™ [-Wunused-variable]\n",
            "             auto result = mlp_fp<scalar_t>(\n",
            "                  ^\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "             return __VA_ARGS__();                          \\\n",
            "                    ^~~~~~~~~~~\n",
            "        csrc/mlp.cpp:58:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "           AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "           ^\n",
            "        csrc/mlp.cpp: In lambda function:\n",
            "        csrc/mlp.cpp:61:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "             for (int i = 0; i < num_layers; i++) {\n",
            "                             ~~^~~\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "             return __VA_ARGS__();                          \\\n",
            "                    ^~~~~~~~~~~\n",
            "        csrc/mlp.cpp:58:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "           AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "           ^\n",
            "        csrc/mlp.cpp:65:10: warning: unused variable â€˜resultâ€™ [-Wunused-variable]\n",
            "             auto result = mlp_fp<scalar_t>(\n",
            "                  ^\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "             return __VA_ARGS__();                          \\\n",
            "                    ^~~~~~~~~~~\n",
            "        csrc/mlp.cpp:58:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "           AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "           ^\n",
            "        csrc/mlp.cpp: In lambda function:\n",
            "        csrc/mlp.cpp:61:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "             for (int i = 0; i < num_layers; i++) {\n",
            "                             ~~^~~\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "             return __VA_ARGS__();                          \\\n",
            "                    ^~~~~~~~~~~\n",
            "        csrc/mlp.cpp:58:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "           AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "           ^\n",
            "        csrc/mlp.cpp:65:10: warning: unused variable â€˜resultâ€™ [-Wunused-variable]\n",
            "             auto result = mlp_fp<scalar_t>(\n",
            "                  ^\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "             return __VA_ARGS__();                          \\\n",
            "                    ^~~~~~~~~~~\n",
            "        csrc/mlp.cpp:58:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "           AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "           ^\n",
            "        csrc/mlp.cpp: In function â€˜std::vector<at::Tensor> mlp_backward(at::Tensor, std::vector<at::Tensor>, std::vector<at::Tensor>)â€™:\n",
            "        csrc/mlp.cpp:90:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "           for (int i = 0; i < num_layers; i++) {\n",
            "                           ~~^~~~~~~~~~~~\n",
            "        csrc/mlp.cpp:95:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "           for (int i = 0; i < inputs.size(); i++) {\n",
            "                           ~~^~~~~~~~~~~~~~~\n",
            "        In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
            "                         from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                         from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                         from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                         from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                         from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                         from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                         from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                         from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                         from csrc/mlp.cpp:1:\n",
            "        csrc/mlp.cpp: In lambda function:\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:116:56: warning: â€˜c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)â€™ is deprecated [-Wdeprecated-declarations]\n",
            "             at::ScalarType _st = ::detail::scalar_type(the_type);                    \\\n",
            "                                                                ^\n",
            "        csrc/mlp.cpp:99:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "           AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "           ^\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:31:23: note: declared here\n",
            "         inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
            "                               ^~~~~~~~~~~\n",
            "        csrc/mlp.cpp: In lambda function:\n",
            "        csrc/mlp.cpp:102:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "             for (int i = 0; i < num_layers; i++) {\n",
            "                             ~~^~~\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "             return __VA_ARGS__();                          \\\n",
            "                    ^~~~~~~~~~~\n",
            "        csrc/mlp.cpp:99:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "           AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "           ^\n",
            "        csrc/mlp.cpp:107:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "             for (int i = 0; i < inputs.size(); i++) {\n",
            "                             ~~^~~~~~~~~~~~~~~\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "             return __VA_ARGS__();                          \\\n",
            "                    ^~~~~~~~~~~\n",
            "        csrc/mlp.cpp:99:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "           AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "           ^\n",
            "        csrc/mlp.cpp:115:44: warning: narrowing conversion of â€˜(work_size / sizeof (scalar_t))â€™ from â€˜long unsigned intâ€™ to â€˜long intâ€™ inside { } [-Wnarrowing]\n",
            "             auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                          ~~~~~~~~~~^~~~~~~~~\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "             return __VA_ARGS__();                          \\\n",
            "                    ^~~~~~~~~~~\n",
            "        csrc/mlp.cpp:99:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "           AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "           ^\n",
            "        csrc/mlp.cpp:115:44: warning: narrowing conversion of â€˜(work_size / sizeof (scalar_t))â€™ from â€˜long unsigned intâ€™ to â€˜long intâ€™ inside { } [-Wnarrowing]\n",
            "             auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                          ~~~~~~~~~~^~~~~~~~~\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "             return __VA_ARGS__();                          \\\n",
            "                    ^~~~~~~~~~~\n",
            "        csrc/mlp.cpp:99:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "           AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "           ^\n",
            "        csrc/mlp.cpp:117:10: warning: unused variable â€˜resultâ€™ [-Wunused-variable]\n",
            "             auto result = mlp_bp<scalar_t>(\n",
            "                  ^\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "             return __VA_ARGS__();                          \\\n",
            "                    ^~~~~~~~~~~\n",
            "        csrc/mlp.cpp:99:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "           AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "           ^\n",
            "        csrc/mlp.cpp: In lambda function:\n",
            "        csrc/mlp.cpp:102:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "             for (int i = 0; i < num_layers; i++) {\n",
            "                             ~~^~~\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "             return __VA_ARGS__();                          \\\n",
            "                    ^~~~~~~~~~~\n",
            "        csrc/mlp.cpp:99:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "           AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "           ^\n",
            "        csrc/mlp.cpp:107:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "             for (int i = 0; i < inputs.size(); i++) {\n",
            "                             ~~^~~~~~~~~~~~~~~\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "             return __VA_ARGS__();                          \\\n",
            "                    ^~~~~~~~~~~\n",
            "        csrc/mlp.cpp:99:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "           AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "           ^\n",
            "        csrc/mlp.cpp:115:44: warning: narrowing conversion of â€˜(work_size / sizeof (scalar_t))â€™ from â€˜long unsigned intâ€™ to â€˜long intâ€™ inside { } [-Wnarrowing]\n",
            "             auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                          ~~~~~~~~~~^~~~~~~~~\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "             return __VA_ARGS__();                          \\\n",
            "                    ^~~~~~~~~~~\n",
            "        csrc/mlp.cpp:99:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "           AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "           ^\n",
            "        csrc/mlp.cpp:115:44: warning: narrowing conversion of â€˜(work_size / sizeof (scalar_t))â€™ from â€˜long unsigned intâ€™ to â€˜long intâ€™ inside { } [-Wnarrowing]\n",
            "             auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                          ~~~~~~~~~~^~~~~~~~~\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "             return __VA_ARGS__();                          \\\n",
            "                    ^~~~~~~~~~~\n",
            "        csrc/mlp.cpp:99:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "           AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "           ^\n",
            "        csrc/mlp.cpp:117:10: warning: unused variable â€˜resultâ€™ [-Wunused-variable]\n",
            "             auto result = mlp_bp<scalar_t>(\n",
            "                  ^\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "             return __VA_ARGS__();                          \\\n",
            "                    ^~~~~~~~~~~\n",
            "        csrc/mlp.cpp:99:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "           AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "           ^\n",
            "        csrc/mlp.cpp: In lambda function:\n",
            "        csrc/mlp.cpp:102:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "             for (int i = 0; i < num_layers; i++) {\n",
            "                             ~~^~~\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "             return __VA_ARGS__();                          \\\n",
            "                    ^~~~~~~~~~~\n",
            "        csrc/mlp.cpp:99:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "           AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "           ^\n",
            "        csrc/mlp.cpp:107:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "             for (int i = 0; i < inputs.size(); i++) {\n",
            "                             ~~^~~~~~~~~~~~~~~\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "             return __VA_ARGS__();                          \\\n",
            "                    ^~~~~~~~~~~\n",
            "        csrc/mlp.cpp:99:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "           AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "           ^\n",
            "        csrc/mlp.cpp:115:44: warning: narrowing conversion of â€˜(work_size / sizeof (scalar_t))â€™ from â€˜long unsigned intâ€™ to â€˜long intâ€™ inside { } [-Wnarrowing]\n",
            "             auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                          ~~~~~~~~~~^~~~~~~~~\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "             return __VA_ARGS__();                          \\\n",
            "                    ^~~~~~~~~~~\n",
            "        csrc/mlp.cpp:99:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "           AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "           ^\n",
            "        csrc/mlp.cpp:115:44: warning: narrowing conversion of â€˜(work_size / sizeof (scalar_t))â€™ from â€˜long unsigned intâ€™ to â€˜long intâ€™ inside { } [-Wnarrowing]\n",
            "             auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                          ~~~~~~~~~~^~~~~~~~~\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "             return __VA_ARGS__();                          \\\n",
            "                    ^~~~~~~~~~~\n",
            "        csrc/mlp.cpp:99:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "           AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "           ^\n",
            "        csrc/mlp.cpp:117:10: warning: unused variable â€˜resultâ€™ [-Wunused-variable]\n",
            "             auto result = mlp_bp<scalar_t>(\n",
            "                  ^\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro â€˜AT_PRIVATE_CASE_TYPEâ€™\n",
            "             return __VA_ARGS__();                          \\\n",
            "                    ^~~~~~~~~~~\n",
            "        csrc/mlp.cpp:99:3: note: in expansion of macro â€˜AT_DISPATCH_FLOATING_TYPES_AND_HALFâ€™\n",
            "           AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "           ^\n",
            "        /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/mlp_cuda.cu -o build/temp.linux-x86_64-3.6/csrc/mlp_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++11\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(14): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(18): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(23): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(97): warning: attribute \"__visibility__\" does not apply here\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(112): warning: attribute \"__visibility__\" does not apply here\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(14): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(18): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(23): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(97): warning: attribute \"__visibility__\" does not apply here\n",
            "\n",
            "        /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(112): warning: attribute \"__visibility__\" does not apply here\n",
            "\n",
            "        x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/mlp.o build/temp.linux-x86_64-3.6/csrc/mlp_cuda.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/mlp_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "        running install_lib\n",
            "        copying build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
            "        copying build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
            "        copying build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
            "        copying build/lib.linux-x86_64-3.6/mlp_cuda.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
            "        creating /usr/local/lib/python3.6/dist-packages/apex\n",
            "        creating /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "        copying build/lib.linux-x86_64-3.6/apex/optimizers/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "        copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_lamb.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "        copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_sgd.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "        copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_novograd.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "        copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "        copying build/lib.linux-x86_64-3.6/apex/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex\n",
            "        creating /usr/local/lib/python3.6/dist-packages/apex/pyprof\n",
            "        creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/nvtx/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/nvtx/nvmarker.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof\n",
            "        creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/__main__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/db.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/nvvp.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/parse.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "        creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/utility.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/prof.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/__main__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/misc.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/conv.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/embedding.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/output.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/usage.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/index_slice_join_mutate.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/convert.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/pooling.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/linear.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/pointwise.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/activation.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/base.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/dropout.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/optim.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/data.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/reduction.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/blas.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/loss.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/softmax.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/randomSample.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/normalization.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/recurrentCell.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "        creating /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
            "        copying build/lib.linux-x86_64-3.6/apex/normalization/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
            "        copying build/lib.linux-x86_64-3.6/apex/normalization/fused_layer_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
            "        creating /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
            "        copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
            "        copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/multi_tensor_apply.py -> /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
            "        creating /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "        copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm_kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "        copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "        copying build/lib.linux-x86_64-3.6/apex/parallel/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "        copying build/lib.linux-x86_64-3.6/apex/parallel/LARC.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "        copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm_kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "        copying build/lib.linux-x86_64-3.6/apex/parallel/distributed.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "        copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "        copying build/lib.linux-x86_64-3.6/apex/parallel/multiproc.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "        creating /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
            "        copying build/lib.linux-x86_64-3.6/apex/fp16_utils/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
            "        copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16util.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
            "        copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
            "        copying build/lib.linux-x86_64-3.6/apex/fp16_utils/loss_scaler.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
            "        creating /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
            "        copying build/lib.linux-x86_64-3.6/apex/reparameterization/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
            "        copying build/lib.linux-x86_64-3.6/apex/reparameterization/reparameterization.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
            "        copying build/lib.linux-x86_64-3.6/apex/reparameterization/weight_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
            "        creating /usr/local/lib/python3.6/dist-packages/apex/contrib\n",
            "        creating /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "        copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "        copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_lamb.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "        copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_sgd.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "        copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fp16_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "        copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "        copying build/lib.linux-x86_64-3.6/apex/contrib/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib\n",
            "        creating /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n",
            "        copying build/lib.linux-x86_64-3.6/apex/contrib/groupbn/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n",
            "        copying build/lib.linux-x86_64-3.6/apex/contrib/groupbn/batch_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n",
            "        creating /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n",
            "        copying build/lib.linux-x86_64-3.6/apex/contrib/xentropy/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n",
            "        copying build/lib.linux-x86_64-3.6/apex/contrib/xentropy/softmax_xentropy.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n",
            "        creating /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "        copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "        copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "        copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/encdec_multihead_attn.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "        copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "        copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "        copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/self_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "        copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "        copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/self_multihead_attn.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "        copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "        creating /usr/local/lib/python3.6/dist-packages/apex/mlp\n",
            "        copying build/lib.linux-x86_64-3.6/apex/mlp/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/mlp\n",
            "        copying build/lib.linux-x86_64-3.6/apex/mlp/mlp.py -> /usr/local/lib/python3.6/dist-packages/apex/mlp\n",
            "        creating /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
            "        copying build/lib.linux-x86_64-3.6/apex/RNN/cells.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
            "        copying build/lib.linux-x86_64-3.6/apex/RNN/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
            "        copying build/lib.linux-x86_64-3.6/apex/RNN/RNNBackend.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
            "        copying build/lib.linux-x86_64-3.6/apex/RNN/models.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
            "        creating /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "        copying build/lib.linux-x86_64-3.6/apex/amp/opt.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "        copying build/lib.linux-x86_64-3.6/apex/amp/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "        copying build/lib.linux-x86_64-3.6/apex/amp/scaler.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "        copying build/lib.linux-x86_64-3.6/apex/amp/__version__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "        copying build/lib.linux-x86_64-3.6/apex/amp/_amp_state.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "        copying build/lib.linux-x86_64-3.6/apex/amp/rnn_compat.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "        copying build/lib.linux-x86_64-3.6/apex/amp/utils.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "        copying build/lib.linux-x86_64-3.6/apex/amp/wrap.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "        copying build/lib.linux-x86_64-3.6/apex/amp/_initialize.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "        copying build/lib.linux-x86_64-3.6/apex/amp/frontend.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "        copying build/lib.linux-x86_64-3.6/apex/amp/_process_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "        copying build/lib.linux-x86_64-3.6/apex/amp/compat.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "        creating /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
            "        copying build/lib.linux-x86_64-3.6/apex/amp/lists/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
            "        copying build/lib.linux-x86_64-3.6/apex/amp/lists/functional_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
            "        copying build/lib.linux-x86_64-3.6/apex/amp/lists/tensor_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
            "        copying build/lib.linux-x86_64-3.6/apex/amp/lists/torch_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
            "        copying build/lib.linux-x86_64-3.6/apex/amp/amp.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "        copying build/lib.linux-x86_64-3.6/apex/amp/handle.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "        copying build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/__init__.py to __init__.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_lamb.py to fused_lamb.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_sgd.py to fused_sgd.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_novograd.py to fused_novograd.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/__init__.py to __init__.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx/__init__.py to __init__.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx/nvmarker.py to nvmarker.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/__init__.py to __init__.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/__main__.py to __main__.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/__init__.py to __init__.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/kernel.py to kernel.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/db.py to db.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/nvvp.py to nvvp.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/parse.py to parse.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/utility.py to utility.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/prof.py to prof.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/__main__.py to __main__.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/__init__.py to __init__.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/misc.py to misc.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/conv.py to conv.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/embedding.py to embedding.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/output.py to output.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/usage.py to usage.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/index_slice_join_mutate.py to index_slice_join_mutate.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/convert.py to convert.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/pooling.py to pooling.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/linear.py to linear.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/pointwise.py to pointwise.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/activation.py to activation.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/base.py to base.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/dropout.py to dropout.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/optim.py to optim.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/data.py to data.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/reduction.py to reduction.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/blas.py to blas.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/loss.py to loss.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/softmax.py to softmax.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/randomSample.py to randomSample.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/normalization.py to normalization.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/recurrentCell.py to recurrentCell.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/normalization/__init__.py to __init__.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/normalization/fused_layer_norm.py to fused_layer_norm.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply/__init__.py to __init__.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply/multi_tensor_apply.py to multi_tensor_apply.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/optimized_sync_batchnorm_kernel.py to optimized_sync_batchnorm_kernel.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/optimized_sync_batchnorm.py to optimized_sync_batchnorm.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/__init__.py to __init__.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/LARC.py to LARC.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/sync_batchnorm_kernel.py to sync_batchnorm_kernel.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/distributed.py to distributed.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/sync_batchnorm.py to sync_batchnorm.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/multiproc.py to multiproc.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/__init__.py to __init__.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/fp16util.py to fp16util.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/loss_scaler.py to loss_scaler.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/__init__.py to __init__.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/reparameterization.py to reparameterization.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/weight_norm.py to weight_norm.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/__init__.py to __init__.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fused_lamb.py to fused_lamb.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fused_sgd.py to fused_sgd.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/__init__.py to __init__.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn/__init__.py to __init__.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn/batch_norm.py to batch_norm.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy/__init__.py to __init__.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy/softmax_xentropy.py to softmax_xentropy.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/__init__.py to __init__.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/encdec_multihead_attn_func.py to encdec_multihead_attn_func.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/encdec_multihead_attn.py to encdec_multihead_attn.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py to fast_self_multihead_attn_func.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py to fast_encdec_multihead_attn_func.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/self_multihead_attn_func.py to self_multihead_attn_func.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py to fast_self_multihead_attn_norm_add_func.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/self_multihead_attn.py to self_multihead_attn.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py to fast_encdec_multihead_attn_norm_add_func.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/mlp/__init__.py to __init__.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/mlp/mlp.py to mlp.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/cells.py to cells.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/__init__.py to __init__.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/RNNBackend.py to RNNBackend.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/models.py to models.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/opt.py to opt.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/__init__.py to __init__.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/scaler.py to scaler.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/__version__.py to __version__.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_amp_state.py to _amp_state.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/rnn_compat.py to rnn_compat.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/utils.py to utils.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/wrap.py to wrap.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_initialize.py to _initialize.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/frontend.py to frontend.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_process_optimizer.py to _process_optimizer.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/compat.py to compat.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/__init__.py to __init__.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/functional_overrides.py to functional_overrides.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/tensor_overrides.py to tensor_overrides.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/torch_overrides.py to torch_overrides.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/amp.py to amp.cpython-36.pyc\n",
            "        byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/handle.py to handle.cpython-36.pyc\n",
            "        running install_egg_info\n",
            "        running egg_info\n",
            "        creating apex.egg-info\n",
            "        writing apex.egg-info/PKG-INFO\n",
            "        writing dependency_links to apex.egg-info/dependency_links.txt\n",
            "        writing top-level names to apex.egg-info/top_level.txt\n",
            "        writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "        writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "        Copying apex.egg-info to /usr/local/lib/python3.6/dist-packages/apex-0.1-py3.6.egg-info\n",
            "        running install_scripts\n",
            "        writing list of installed files to '/tmp/pip-record-ep04zco9/install-record.txt'\n",
            "        Running setup.py install for apex: finished with status 'done'\n",
            "      Removing source in /tmp/pip-req-build-9b1v7jzq\n",
            "    Successfully installed apex-0.1\n",
            "    Cleaning up...\n",
            "    Cleaned build tracker '/tmp/pip-req-tracker-rohvjith'\n",
            "    running install\n",
            "    running build\n",
            "    running build_py\n",
            "    Generating grammar tables from /usr/lib/python3.6/lib2to3/Grammar.txt\n",
            "    Generating grammar tables from /usr/lib/python3.6/lib2to3/PatternGrammar.txt\n",
            "    creating build\n",
            "    creating build/lib\n",
            "    creating build/lib/torch_lr_finder\n",
            "    copying torch_lr_finder/__init__.py -> build/lib/torch_lr_finder\n",
            "    copying torch_lr_finder/lr_finder.py -> build/lib/torch_lr_finder\n",
            "    running install_lib\n",
            "    creating /usr/local/lib/python3.6/dist-packages/torch_lr_finder\n",
            "    copying build/lib/torch_lr_finder/__init__.py -> /usr/local/lib/python3.6/dist-packages/torch_lr_finder\n",
            "    copying build/lib/torch_lr_finder/lr_finder.py -> /usr/local/lib/python3.6/dist-packages/torch_lr_finder\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/torch_lr_finder/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/torch_lr_finder/lr_finder.py to lr_finder.cpython-36.pyc\n",
            "    running install_egg_info\n",
            "    running egg_info\n",
            "    writing torch_lr_finder.egg-info/PKG-INFO\n",
            "    writing dependency_links to torch_lr_finder.egg-info/dependency_links.txt\n",
            "    writing requirements to torch_lr_finder.egg-info/requires.txt\n",
            "    writing top-level names to torch_lr_finder.egg-info/top_level.txt\n",
            "    reading manifest file 'torch_lr_finder.egg-info/SOURCES.txt'\n",
            "    writing manifest file 'torch_lr_finder.egg-info/SOURCES.txt'\n",
            "    Copying torch_lr_finder.egg-info to /usr/local/lib/python3.6/dist-packages/torch_lr_finder-0.1.4-py3.6.egg-info\n",
            "    running install_scripts\n",
            "    writing list of installed files to '/tmp/pip-record-f6xpmqz0/install-record.txt'\n",
            "    Running setup.py install for torch-lr-finder ... \u001b[?25l\u001b[?25hdone\n",
            "  Removing source in /tmp/pip-install-qcnkun2f/torch-lr-finder\n",
            "Successfully installed torch-lr-finder-0.1.4\n",
            "Cleaning up...\n",
            "Removed build tracker '/tmp/pip-req-tracker-rohvjith'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6dbf998464524659a108ca4919037ad9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Stopping early, the loss has diverged\n",
            "Learning rate search finished. See the graph with {finder_name}.plot()\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3de3yU9Zn38c+VcziFUwQkGA5CPaGgEbVUtAcVdVesbRXbWm3dsj3Yvtrt4dFn96mWPq3ts127665t1Za62qq1tNtiS2utolbrgaCAHAQiiDkICSSEhGQmc7ieP+YODHGAIJlMZvJ9v17zYuZ33/fMlds4V67f73ffP3N3REREesrLdAAiIjIwKUGIiEhKShAiIpKSEoSIiKSkBCEiIikpQYiISEoFmQ6gr4wdO9YnT56c6TBERLLKqlWrdrl7eaptOZMgJk+eTHV1dabDEBHJKma2/VDb1MUkIiIpKUGIiEhKShAiIpKSEoSIiKSkBCEiIikpQYiISEpKECIiWaz6jWZWbW9Oy3srQYiIZLEf/GUz3/r9xrS8txKEiEgWq23uZNLoIWl5byUIEZEsFYs7DXs6mTSqNC3vrwQhIpKl3mrtJBp3VRAiInKw2uZOACaNUoIQEZEktS0dAFSoi0lERJLVtXRiBsePVIIQEZEkdc0dTBhRQlFBer7KlSBERLJUbUsHFWkaoAYlCBGRrFXb3Jm2AWpQghARyUrhaIydbSEmjU7P+AMoQYiIZKX6lk7c0zfFFZQgRESyUl1L4hqIdE1xhTQmCDNbYmaNZrbuENvNzO40sxozW2tmZyZtu97MtgSP69MVo4hItuq+BiJdV1FDeiuI+4D5h9l+KTA9eCwCfgRgZqOBW4FzgDnArWY2Ko1xiohkndrmTgrzjXEjStL2GWlLEO7+DHC4m5QvAO73hBeAkWY2AbgEeNzdm929BXicwycaEZFBp7alg4kjS8nPs7R9RibHICYCtUmv64K2Q7W/jZktMrNqM6tuampKW6AiIgNNXXNHWruXIMsHqd39Hnevcveq8vLyTIcjItJvals6qUjjDCbIbIKoByYlva4I2g7VLiIiwL5wlOZ9XWmdwQSZTRDLgE8Es5nOBVrd/S3gMeBiMxsVDE5fHLSJiAgHprimu4upIF1vbGYPARcCY82sjsTMpEIAd/8xsBy4DKgBOoBPBtuazexbwMrgrRa7e3pW5BYRyUK1zcEU1zRXEGlLEO5+7RG2O/D5Q2xbAixJR1wiItmuP66BgCwfpBYRGYxqmzspLcxnzNCitH6OEoSISJapbelg0uhSzNJ3DQQoQYiIZJ3a5o603qSvmxKEiEgWcXfqWzrTPsUVlCBERLJKa2eEtnA07QPUoAQhIpJVapu7b/OtBCEiIkkOTHFVF5OIiCTZf5GcuphERCRZbUsHZaWFjCgpTPtnKUGIiGSR2ubOfuleAiUIEZGsUtfSQcXI9HcvgRKEiEhWae2MMHpYem+x0U0JQkQki4QjcUoK8vvls5QgRESySCgao6Swf766lSBERLJELO5EYk6xKggREUkWjsYAVEGIiMjBQpE4AMUFShAiIpLkQAWRA11MZjbfzDaZWY2Z3Zxie6WZPWFma83sKTOrSNoWM7PVwWNZOuMUEckG3RVEfyWItK1JbWb5wF3ARUAdsNLMlrn7hqTdvg/c7+7/bWbvA24Hrgu2dbr7rHTFJyKSbUKRRAWRC11Mc4Aad9/q7l3Aw8CCHvucAjwZPF+RYruIiATC0f6tINKZICYCtUmv64K2ZGuAq4LnHwSGm9mY4HWJmVWb2QtmdmWqDzCzRcE+1U1NTX0Zu4jIgJNLFURvfBW4wMxeAS4A6oFYsK3S3auAjwL/bmbTeh7s7ve4e5W7V5WXl/db0CIimdBdQRRn+xgEiS/7SUmvK4K2/dy9gaCCMLNhwIfcfU+wrT74d6uZPQXMBl5PY7wiIgNadwWRC9dBrASmm9kUMysCFgIHzUYys7Fm1h3DLcCSoH2UmRV37wPMBZIHt0VEBp0DXUxZPgbh7lHgJuAxYCPwiLuvN7PFZnZFsNuFwCYz2wyMA74dtJ8MVJvZGhKD19/tMftJRGTQOTBI3T8VRDq7mHD35cDyHm3fSHq+FFia4ri/ATPTGZuISLYJ50oFISIifau/KwglCBGRLHFgkFoVhIiIJAlF4uQZFORZv3yeEoSISJYIR2OUFOZjpgQhIiJJQpF4v11FDUoQIiJZo7uC6C9KECIiWSIUiStBiIjI24UiMXUxiYjI24Wj8X67UR8oQYiIZA1VECIiklI4qjEIERFJIRSJUaIKQkREetIYhIiIpBRWBSEiIqmEonGK++lOrqAEISKSNRIVhLqYRESkh5BmMYmISE+RWJxY3HPnOggzm29mm8ysxsxuTrG90syeMLO1ZvaUmVUkbbvezLYEj+vTGaeIyEB3YDW5HKggzCwfuAu4FDgFuNbMTumx2/eB+939dGAxcHtw7GjgVuAcYA5wq5mNSlesIiIDXfdqcrkySD0HqHH3re7eBTwMLOixzynAk8HzFUnbLwEed/dmd28BHgfmpzFWEZEBbX8FkSOD1BOB2qTXdUFbsjXAVcHzDwLDzWxML4/FzBaZWbWZVTc1NfVZ4CIiA02uVRC98VXgAjN7BbgAqAdivT3Y3e9x9yp3ryovL09XjCIiGbc/QfRjBVGQxveuByYlva4I2vZz9waCCsLMhgEfcvc9ZlYPXNjj2KfSGKuIyIB2YJA6NyqIlcB0M5tiZkXAQmBZ8g5mNtbMumO4BVgSPH8MuNjMRgWD0xcHbSIig1J3BZETs5jcPQrcROKLfSPwiLuvN7PFZnZFsNuFwCYz2wyMA74dHNsMfItEklkJLA7aREQGpe4Koj+vg0hnFxPuvhxY3qPtG0nPlwJLD3HsEg5UFCIig1o4lyoIERHpO6FI/1cQShAiIlkgHFUFISIiKXRXEEoQIiJykO4KQl1MIiJyEI1BiIhISqFIjII8oyBfCUJERJKE+3mxIFCCEBHJCqFIrF9vswFKECIiWSEUiffrjfpACUJEJCuEo7F+vdU3KEGIiGQFVRAiIpJSOKoxCBERSSEciffrcqOgBCEikhVCGoMQEZFUBmwFYWZDu1d+M7MZZnaFmRWmNzQREek2kCuIZ4ASM5sI/Bm4DrgvXUGJiMjBBmwFAZi7dwBXAT90948Ap6YvLBERSRYawLOYzMzOAz4G/CFoO2IqM7P5ZrbJzGrM7OYU208wsxVm9oqZrTWzy4L2yWbWaWarg8ePe/sDiYjkolAkRnE/34upt2tSfwm4Bfgfd19vZlOBFYc7wMzygbuAi4A6YKWZLXP3DUm7/QvwiLv/yMxOIbF+9eRg2+vuPqv3P4qISG5y98TN+vrxVt/QywTh7k8DTwMEg9W73P2LRzhsDlDj7luD4x4GFgDJCcKBEcHzMqCh96GLiAwOXbE47vR7BdHbWUwPmtkIMxsKrAM2mNnXjnDYRKA26XVd0JbsNuDjZlZHonr4QtK2KUHX09Nmdv4h4lpkZtVmVt3U1NSbH0VEJOuEo/2/WBD0fgziFHffC1wJ/BGYQmIm07G6FrjP3SuAy4AHggrlLeAEd58N/BPwoJmN6Hmwu9/j7lXuXlVeXt4H4YiIDDyhSGK50YG6HkRhcN3DlcAyd4+Q6B46nHpgUtLriqAt2Y3AIwDu/jxQAox197C77w7aVwGvAzN6GauISE4JZ2C5Ueh9grgbeAMYCjxjZpXA3iMcsxKYbmZTzKwIWAgs67HPm8D7AczsZBIJosnMyoNBboIB8enA1l7GKiKSU8LRzFQQvR2kvhO4M6lpu5m99wjHRM3sJuAxElNilwQzoBYD1e6+DPgKcK+ZfZlERXKDu7uZzQMWm1kEiAOfcffmo/7pRERyQChDFUSvEoSZlQG3AvOCpqeBxUDr4Y5z9+UkBp+T276R9HwDMDfFcb8Gft2b2EREcl2mKojepqMlQBtwdfDYC/wsXUGJiMgB3RXEgOxiAqa5+4eSXn/TzFanIyARETlY9yymgTpI3Wlm7+l+YWZzgc70hCQiIsm6r4MYqBXEZ4D7g7EIgBbg+vSEJCIiyTJVQfR2FtMa4Izui9Xcfa+ZfQlYm87gREQkcxXEUaUjd98bXFENiSucRUQkzQ5cST0wxyBSsT6LQkREDunAdRADuILo4Ui32hARkT7QfR3EgBqDMLM2UicCA0rTEpGIiBwkFIlTlJ9HXl7/dtwcNkG4+/D+CkRERFILR2MU9/P4AxxbF5OIiPSDUCTe7zOYQAlCRGTAC0di/T7+AEoQIiIDXjiqCkJERFIIqYIQEZFUVEGIiEhKoUis36+iBiUIEZEBLxSN9ftV1KAEISIy4IUj8dyrIMxsvpltMrMaM7s5xfYTzGyFmb1iZmvN7LKkbbcEx20ys0vSGaeIyECWqQqit+tBHDUzywfuAi4C6oCVZrYsWIe6278Aj7j7j8zsFBLrV08Oni8ETgWOB/5iZjPcPZaueEVEBqpcrCDmADXuvtXdu4CHgQU99nFgRPC8DGgIni8AHnb3sLtvA2qC9xMRGXQS01xzawxiIlCb9LouaEt2G/BxM6sjUT184SiOxcwWmVm1mVU3NTX1VdwiIgNKKBoflPdiuha4z90rgMuAB8ys1zG5+z3uXuXuVeXl5WkLUkQkU9ydrmicklwagwDqgUlJryuCtmQ3AvMB3P15MysBxvbyWBGRnNe93GiuVRArgelmNsXMikgMOi/rsc+bwPsBzOxkoARoCvZbaGbFZjYFmA68lMZYRUQGpHCwmlxOVRDuHjWzm4DHgHxgibuvN7PFQLW7LwO+AtxrZl8mMWB9g7s7sN7MHgE2AFHg85rBJCKDUSjavR51DiUIAHdfTmLwObntG0nPNwBzD3Hst4FvpzM+EZGBLhTJzHKjkPlBahEROYzuMQjdrE9ERA6iCkJERFJSBSEiIil1VxC5dqsNERE5RqFgmmuu3WpDRESOUTiqCkJERFJQBSEiIimpghARkZT2VxCaxSQiIsl0HYSIiKS0/26uShAiIpIsHIlRXJCHmfX7ZytBiIgMYOFoPCNXUYMShIjIgBaKxDIygwmUIEREBrRQJJaRayBACUJEZEBLdDGpghARkR5ytoIws/lmtsnMaszs5hTbf2Bmq4PHZjPbk7QtlrSt51rWIiKDQiYriLQtOWpm+cBdwEVAHbDSzJYFy4wC4O5fTtr/C8DspLfodPdZ6YpPRCQbhCIxhhandXXoQ0pnWpoD1Lj7VnfvAh4GFhxm/2uBh9IYj4hI1glF4hm5SA7SmyAmArVJr+uCtrcxs0pgCvBkUnOJmVWb2QtmdmX6whQRyZzuW2kcSjgay8h9mGDgDFIvBJa6e/KZqnT3KuCjwL+b2bSeB5nZoiCJVDc1NfVXrCIifeI3L9dxxjf/zNObD/39lasVRD0wKel1RdCWykJ6dC+5e33w71bgKQ4en+je5x53r3L3qvLy8r6IWUSk3/z02W2Eo3E++/NVrKtvTblPrl5JvRKYbmZTzKyIRBJ422wkMzsJGAU8n9Q2ysyKg+djgbnAhp7Hiohkq3X1raxv2MtN7z2RUUOKuOFnK6lt7njbfuFIjJJcm+bq7lHgJuAxYCPwiLuvN7PFZnZF0q4LgYfd3ZPaTgaqzWwNsAL4bvLsJxGRbPfQS29SXJDHp+dN5b8/NYdoPM71S16ieV/XQfuFojGKc22aK4C7LweW92j7Ro/Xt6U47m/AzHTGJiKSKR1dUX63uoHLZ06grLSQstJCfvKJKj72kxf51H0r+eL7T+Rd40cwfkQJkZhnrILIzORaEZFB7A9r36I9HGXhnBP2t1VNHs1/LJzNFx96hU/dVw3AsOD6h5ysIERE5O0eXlnL1PKhnD151EHt808bT/X/+QCbdrSxaUcbm3e2sX13B3Onjc1InEoQIiL9aPPONlZtb+F/X3ZSykWARpQUcvbk0Zw9eXQGojvYQLkOQkRkUPjlyloK840PnVmR6VCOSAlCRKSfhKMxfvNyHRefMp4xw4ozHc4RqYtJRKSPhCIx9oWjFBbkUZSfR2F+Hu2hKLUtHdQ2d/DC1t20dES45uxJR36zAUAJQkSkD8Tjzvx/f4Y3dr/9Yrdkc6aM5j0nZmbQ+WgpQYiI9IGVbzTzxu4Orju3ksoxQ+iKxemKxhlaVMCk0aVUjBrCpNFDKCstzHSovaYEISLSBx5d20BpYT63XHYSQ4py46tVg9QiIscoEouz/NUdvP/k43ImOYAShIjIMfvb67tp3tfFFWccn+lQ+pQShIjIMXp0TQPDSwq44F25teyAEoSIyDEIRWI8tm4Hl5w6nuIM3VQvXZQgRESOwdObm2gLR3OuewmUIEREjsmjaxoYPbSId08bk+lQ+pwShIjIO9TRFeWJjY1cNnM8Bfm593Waez+RiEg/eXzDTjojMa44Y2KmQ0kLJQgRkXfo0TVvMX5ECVWVo468cxZKa4Iws/lmtsnMaszs5hTbf2Bmq4PHZjPbk7TtejPbEjyuT2ecIiJHa31DK09vbuTvTp9AXt7b13XIBWm75M/M8oG7gIuAOmClmS1z9w3d+7j7l5P2/wIwO3g+GrgVqAIcWBUc25KueEVEeuvN3R1cv2Ql5cOK+fS8qZkOJ23SWUHMAWrcfau7dwEPAwsOs/+1wEPB80uAx929OUgKjwPz0xiriEivNLWFuW7Ji0Tjce6/cQ7jRpRkOqS0SWeCmAjUJr2uC9rexswqgSnAk0d7rIhIf2kLRbjhZy/RuDfMkhvO5sTjhmc6pLQaKIPUC4Gl7h47moPMbJGZVZtZdVNTU5pCE5HBLhZ3Xq1rZdH9q9i0o40ffvxMzjwhNwemk6XztoP1QPKySRVBWyoLgc/3OPbCHsc+1fMgd78HuAegqqrK33moxyYed7picUoKc+sye5HBrLMrxm9eqePZLbt4futu9nREyM8z/vXDp/Pedx2X6fD6RToTxEpguplNIfGFvxD4aM+dzOwkYBTwfFLzY8B3zKw7RV8M3JLGWHulZV8Xa+r2sLaulS2N7exo7aRhT4ide0PE3Tlnyhjmnzaei08dx4Sy0kyHKyLvUCzufO4Xq1ixqYnjy0r4wMnjmHviGOZOG8txOTzm0FPaEoS7R83sJhJf9vnAEndfb2aLgWp3XxbsuhB42N096dhmM/sWiSQDsNjdm9MR575wlAdffJNQJEY4GiccTfwbisTojMTp7IoRisTY3ryP2uZOAMygYlQpx5eVMmfKaMaXlRB354mNjdy6bD23LlvPrEkjWXj2JK6YdXxO3R9eZDD43p9eY8WmJhYvOJXrzq3ELDensR6JJX0vZ7Wqqiqvrq4+6uOa93Vx5rceBxJf/CUF+RQX5lFamE9J8CgtzGN8WQmnV4zk9IoyZk4sY3hJ6mUDaxrbeGz9TpatbmDTzjaGlxTw4bMq+Pi5lUwrH3ZMP6OIpN+vqmv52tK1fOK8ShYvOC3T4aSdma1y96qU2wZ7gojHnY5IjOKCPAryrM/+UnB3qre38MDz2/njureIxJzZJ4zk8pkTuGzmBI4fqS4okYFm5RvNfPTeFzhnyhju++TZOXl/pZ6UIDKsqS3M0lV1PLqmgQ1v7QWgqnIUk0YPYV84SkdXjH1dUSpGDeFj55zAOVNGZ6ykdfdBW07L4Fbb3MGCu55jZGkh//O5uZQNSd1LkGuUIAaQrU3t/GHtW/xx3Q7awhGGFhUwpCif0qJ81tXvpbUzwvTjhvHxcyv54JkTGXGIrqye3J3Xm9qZUFbK0OLejXm8tK2Z362u563WEG+1htjRmhhjueOaWVkzSyMai7O9uYOuaJyTxg9XcpN35PENO/n60jXE4s5vPz+XqYOoO1gJIkuEIjEeXdPAz1/Yzpq6VoYVF3D9uyu58T1TGT206JDHvbB1N3c8vpmXtjVTVlrI9edVcv27JzNmWHHK/dvDUb73x9d44IXtDC8uYNLoIRw/soTxZSVUv9FCTWM73/vQ6XzorIrDxuvuPFuzi7qWToYWFzCsOJ+hRQVUjhnK+LK+m+nR2BZi0442mvd17X/UNneweWc7NU3tdEXjAMwYN4xrzj6BD86eeNjzJdItFInx7T9s5IEXtnPKhBHcee1sTjxu8CQHUILISmvr9nD3M1tZ/upblBbmc915lXzy3VMoLconHMy42r67g7tW1PD81t0cN7yYT86dwitvtvDnDTspKczjmqpJXHLaeCpGDmF8WQlFBXk8s7mJW37zKg2tnXxq7hS+cvGMg2ZZtYUi/OMDq/jb67u5+dKT+Md5U1P+Vb5t1z5uXbaeZzanvkDx1ONHcNEp4/jAyeM49fgR7+gv+3jc+fmL27l9+Wt0Rg5cQ5lnMG5ECTPGDedd44cz/bhhdMXi/Kq6jtW1eyjKz+OiU8ex8OxJzJ02NmdvpCbHZn1DK196eDVbGtv59PlT+Ool78q5JUN7Qwkii23Z2cZ/rajh0TUNxFP8pxo7rJjPXjiNj51zwv4L9Woa27j76a38dnU9kVjiIDMoH1ZMY1uYaeVD+X8fPoOzDnGL4nA0xld/tZZH1zRww7sn85GqCsYMLWbU0EJiceeuFTXc+8w2igvy+PJFM5h/2nj2haO0B4/1DXt5fMNOXn6zBXeYOnYo3/vw6Zw9eXSvf+63Wjv5+tK1/HXLLi6YUc5nL5zG2GHFjB5aRFlpIfmH+NJ/bcdefrmylt+8XE9rZ4SKUaVcUzWJD1dV6NqUPhCPO5/9xSrq93RyddUkFsyaSFnpwOur74rG+e0r9UwcVcq5U8cc9PvSsKeTOx7fzK9frmPM0GLuuPoM5s0oz2C0maUEkQNeb2rniY07yc/Lo7gg8RheUsAFM46jtCj1Xz272sNs3tFGXUsndXs6qW/ppHLMEBbNm3rEq77jcef//mEjS57bdlB7Yb4RiTlXzZ7IzZedxHHDD92VtKs9zJMbG/nPFVuoa+lk0flT+fJFMw772a0dEZave4vvLN9ILO788+Un89E5Jxx1BRKKxPjzhp38cuWbPFezG4CJI0uZWj6UKWOHMnXsUN530jhOGDPkqN53sPvps9v41u83UDlmCNt3d1BckMflMydwzdmTmJPByRXJGttCfO7nL1O9PXHz5/LhxVw+cwKXnjaeFZua+Nlz23CHT5xXyU3vO5GRQwZ3d6QShLwj7s66+r3U7+lg974umtu72BuKcNEp45kzpffVQHs4yneWb+TBF99kxrhh3H7VTI4bXkIoEiMUibOns4sXtzbz15pdvFq3h7gnZnn929VnUDlm6DH/HG/u7uDRtQ1s2dnGtl372Nq0j7ZwFDP4wMnj+OTcyZw3dcyA+HLrb2/s2scTrzVSOXoIp00sY9yI4kOehy0727j8P59l3vSx3PuJKtY37OWhl97kd6sbaA9HOWH0ED50ZgVXnTmRSaMPnXjdnY6uWK8nUxyNV95s4TM/X8Xezii3XzWTooI8lq1u4MlNjXRF45jBlbMm8k8XzThsjIOJEoQMCE9tauR//XotO/eG37YtP884o6KM90wv5/zpYznrhFFpGztwd+paOvnlyloefOlNmvd1cdL44Zw/fSzDigsZWpzPsOICigryiMUdd4i5M7K0kPeedFzKCqimsZ3fra6nKD+PscOLKR9WzHEjijl5wggKB+Bc+lXbW7j3ma08tmEHyV8BY4cVMXNiGYvmTeO8aWP2t3dF43zwh8+xozXEn740j/LhByZAdHRF+dO6HSxdVcfzW3fjDjMnljFqaBFDCvMZUpRPQb6xc2+Y+j2dNOzppKMrxknjh/PhsypYMGviQe/3TsTizq+qa/nG79YzrqyYe66r4uQJI/Zv3xuK8NfNu5gydiinHD/iMO80+ChByIDR2hHhsfU7EletB1eqDy3K57SKsl5P6e1LoUiMZasbuP+FN6hpbCcUiR92/5FDCvnIWRV89JxKJo8ZwvNbd/OTv27jydcayTPeNk40tXwot/39qQOij9vdWbGpkbtWvM6q7S2UlRby8XNP4JqqE2hqD7Gufi/r6lt5rmYXDa0hPnbOCdx86UkMLynk+49t4r9W1HD3dWdxyanjD/kZ9Xs6+Z+XE4miPRyjsyvKvnCMSCzOuBElHD+yhIkjhzBySCFPvNbImto95OcZF8woZ9G8qZw7dcwh3ztZPO689EYzK7c1s3J7Cy9vb6E9HOX86WO5c+FsRmkWW68pQYj0UjQWZ19XjH3hKF3ROPl5Rl6ekWewtWkfv3hxO39ev5No3Jk4spT6PZ2MGVrEdedVct25lQwrKWB3exdNbWG27mrnP/6yhTd2d3DJqeP4l8tPOaZujR2tIRb/fj0nHjecS08bf9B1H+7Opp1tPLtlF3lmzJkympMnjCA/z3B3/rKxkTuf2MKr9a1UjCrlH94zhY9UTUrZzdPZFeOOxzfx02e3MX5ECZ+cO4Xb/7iRq86s4PsfOeMdx59KTWMbv365nl+vqqOxLcyCWcfzz5edfNgb4oUiMW568BX+snEnAO8aN5yqyaM4d+oYLj1t/KC4+rkvKUGI9KHGvSEeqa7lxW3NXD5zAlfOnnjIgfdwNMZP/rqN/3qyhrg7X/rADP5x3tSj7j5r2NPJtfe+wFutISKxOO4wecwQLj51PLvbu/jrliYa2w7uuhteXEDV5FE0toVZ37CXyjFD+Px7T+SDsyf2qtvr5Tdb+PrStdQ0tjNxZCl/+tL5h7wH2bEKRWL8cEUNP3566/7ZcZ84r/JtX/atHRH+4f6VVG9v4ZZLT+LqqkmDfpD5WClBiGRYw55Ovvnoeh5bv5Pzp4/ljqtn9brfvX5PJ9fe8wIt+7r47xvnMGnUEP68YQd/WreDv72+m+ElBbznxLHMm17O+TPG4p64Sv7Fbc28uG03BXnGonnTuHLW8Uf913UoEuPBF9/kvGljDurTT5fk62smjS7l6rMOTFHe0Rri+iUvsXVXOz+4ZhZ/d/rxaY9nMFCCEBkA3J1frqzltkfXM6y4kB9ccwbnTy+nKxpnfUMr1W+0sHNviNMnjeTsyaOYUFZKbXMH1977Aq2dER648RxmTRp50Ht2dEUpLsg/5HUh2cjdeXzDTp1q5gwAAAgCSURBVH723Bs8v3U3eQbzZpSzZWc7rZ0R7r7uLOaeODbTYeYMJQiRAWTzzjY+/4uXqWlq54yKkby2Y+/+wfGi/Dy6YonnE0eWEo7GicTi/PzGc5hZUZbJsDNi++59/Kq6jqWr6ojGnfs+eTanTRx85yGdlCBEBpjOrhjf/eNG1ta3MnvSKM6ePIqzJo9i9JAiNr7VRvX2ZqrfaKGxLcStf3/qoP9SjMWdiJb1TQslCBERSelwCULzwUREJKW0Jggzm29mm8ysxsxuPsQ+V5vZBjNbb2YPJrXHzGx18FiW6lgREUmfvr8ZSsDM8oG7gIuAOmClmS1z9w1J+0wHbgHmunuLmSWvUtPp7rPSFZ+IiBxeOiuIOUCNu2919y7gYWBBj30+Ddzl7i0A7t6YxnhEROQopDNBTARqk17XBW3JZgAzzOw5M3vBzOYnbSsxs+qg/cpUH2Bmi4J9qpuaUi9cIyIi70zaupiO4vOnAxcCFcAzZjbT3fcAle5eb2ZTgSfN7FV3fz35YHe/B7gHErOY+jd0EZHcls4Koh6YlPS6ImhLVgcsc/eIu28DNpNIGLh7ffDvVuApYHYaYxURkR7SmSBWAtPNbIqZFQELgZ6zkX5LonrAzMaS6HLaamajzKw4qX0usAEREek3aeticveomd0EPAbkA0vcfb2ZLQaq3X1ZsO1iM9sAxICvuftuM3s3cLeZxUkkse8mz35KZdWqVbvMbHuP5jKgtZchH2nfw21Pta03bT1fjwV2HTHSY3M05+SdHpuJc9mzrT/O5aHi6Ovj3un5PJp2/W4eeXuu/n9eecgt7p6zD+Cevtr3cNtTbetNW4rX1QPpnLzTYzNxLnu29ce5PJbz2R+/m0fTrt/NI28fLP+fJz9y/UrqR/tw38NtT7WtN21HE19fOZbP7O2xmTiXvfncdHinn9kfv5tH067fzSNvHyz/n++XM/diygVmVu2HuCeKHB2dy76l89l3sulc5noFkW3uyXQAOUTnsm/pfPadrDmXqiBERCQlVRAiIpKSEoSIiKSkBCEiIikpQWQRMxsa3Jzw7zIdSzYzs5PN7MdmttTMPpvpeLKdmV1pZvea2S/N7OJMx5PNzGyqmf3UzJZmOhZQgugXZrbEzBrNbF2P9iMuqNTD/wIeSU+U2aEvzqW7b3T3zwBXk7iNy6DVR+fzt+7+aeAzwDXpjHcg66NzudXdb0xvpL2nWUz9wMzmAe3A/e5+WtCWT+LmhPsXVAKuJXFbktt7vMWngDOAMUAJsMvdf98/0Q8sfXEu3b3RzK4APgs84O4PMkj11fkMjvs34Bfu/nI/hT+g9PG5XOruH+6v2A8l07f7HhTc/Rkzm9yjef+CSgBm9jCwwN1vB97WhWRmFwJDgVOATjNb7u7xdMY9EPXFuQzeZxmwzMz+AAzaBNFHv5sGfBf442BNDtB3v5sDiRJE5qRaUOmcQ+3s7v8MYGY3kKggBl1yOIyjOpdBsr0KKAaWpzWy7HRU5xP4AvABoMzMTnT3H6czuCxztL+bY4BvA7PN7JYgkWSMEkSWcff7Mh1DtnP3p0isMSJ9wN3vBO7MdBy5wN13kxjLGRA0SJ05vVlQSXpH57Jv6Xz2naw+l0oQmdObBZWkd3Qu+5bOZ9/J6nOpBNEPzOwh4HngXWZWZ2Y3unsU6F5QaSPwiLuvz2Sc2UDnsm/pfPadXDyXmuYqIiIpqYIQEZGUlCBERCQlJQgREUlJCUJERFJSghARkZSUIEREJCUlCMl5Ztbez5/3t37+vJFm9rn+/EwZHJQgRI6SmR32Hmbu/u5+/syRgBKE9DklCBmUzGyamf3JzFaZ2V/N7KSg/e/N7EUze8XM/mJm44L228zsATN7DnggeL3EzJ4ys61m9sWk924P/r0w2L7UzF4zs18Et8bGzC4L2laZ2Z1m9rb1PczsBjNbZmZPAk+Y2TAze8LMXjazV81sQbDrd4FpZrbazP41OPZrZrbSzNaa2TfTeS4ld+lurjJY3QN8xt23mNk5wA+B9wHPAue6u5vZPwBfB74SHHMK8B537zSz24CTgPcCw4FNZvYjd4/0+JzZwKlAA/AcMNfMqoG7gXnuvi24RcOhnAmc7u7NQRXxQXffa2ZjgRfMbBlwM3Cau88CsMSyn9NJrEVgJNa9mOfuz7zjsyWDkhKEDDpmNgx4N/Cr4A96SKwNAYm7bf7SzCYARcC2pEOXuXtn0us/uHsYCJtZIzCOxP3+k73k7nXB564GJpNYdWyru3e/90PAokOE+7i7N3eHDnwnWLksTmKtgXEpjrk4eLwSvB5GImEoQchRUYKQwSgP2NP9F3cP/wnc4e7LgoWFbkvatq/HvuGk5zFS///Um30OJ/kzPwaUA2e5e8TM3iCxBG1PBtzu7ncf5WeJHERjEDLouPteYJuZfQQSS2aa2RnB5jIO3K//+jSFsAmYmrQ85TW9PK4MaAySw3uByqC9jUQ3V7fHgE8FlRJmNtHMjjvmqGXQUQUhg8EQM0vu+rmDxF/jPzKzfwEKgYeBNSQqhl+ZWQvwJDClr4MJxjA+B/zJzPaRWDOgN34BPGpmrwLVwGvB++02s+fMbB2JdaG/ZmYnA88HXWjtwMeBxr7+WSS36XbfIhlgZsPcvT2Y1XQXsMXdf5DpuESSqYtJJDM+HQxaryfRdaTxAhlwVEGIiEhKqiBERCQlJQgREUlJCUJERFJSghARkZSUIEREJCUlCBERSen/A51rjupLdcucAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f9bf43eee10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3H3jt2OkqVE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "outputId": "3a6c1e92-1e91-4435-f8b6-0eff01ddb591"
      },
      "source": [
        "\n",
        "model_base = nn.Sequential( \n",
        "                nn.Kerv2d(in_channels , out_channels_1, padding=padding_1, dilation=1, groups=1, bias=True, \n",
        "                          kernel_type='gaussian', kernel_size=kernel_size, learnable_kernel=True,\n",
        "                          kernel_regularizer=True, stride=1, balance=0.5, power=50, gamma=1\n",
        "                          ),\n",
        "                nn.BatchNorm2d(out_channels_1),\n",
        "                nn.AvgPool2d(2, stride=2), \n",
        "                nn.Conv2d(out_channels_1 , out_channels_2, padding= padding_1, kernel_size=kernel_size, stride=1), \n",
        "                nn.BatchNorm2d(out_channels_2),\n",
        "                nn.AvgPool2d(2, stride=2), \n",
        "                nn.Conv2d(out_channels_2 , out_channels_3, padding= padding_1, kernel_size=kernel_size, stride=1), \n",
        "                nn.Dropout(0.1), \n",
        "                nn.BatchNorm2d(out_channels_3),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_3 , out_channels_4, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                \n",
        "                \n",
        "                nn.BatchNorm2d(out_channels_4),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_4 , out_channels_5, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.BatchNorm2d(out_channels_5),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_5 , out_channels_6, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.BatchNorm2d(out_channels_6),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "               \n",
        "                nn.Dropout(0.5),\n",
        "                Flatten(),\n",
        "                nn.Linear(100,64),\n",
        "                nn.Linear(64,2)\n",
        "            )\n",
        "model_gpu = model_base.type(gpu_dtype)\n",
        "print(model_gpu)\n",
        "loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) \n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Kerv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (3): Conv2d(16, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (6): Conv2d(24, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (7): Dropout(p=0.1, inplace=False)\n",
            "  (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (10): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (11): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (12): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (13): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (14): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (15): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (16): Conv2d(64, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (17): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (18): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (19): Dropout(p=0.5, inplace=False)\n",
            "  (20): Flatten()\n",
            "  (21): Linear(in_features=100, out_features=64, bias=True)\n",
            "  (22): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dc9XTFgskqcW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369,
          "referenced_widgets": [
            "0ae929c62dd7400b9f51e7b62fba4b6f",
            "bd4d9a2b8e6b4cfe9727c08206deaff8",
            "32c8b3556f5548fabdc225150ea64192",
            "8abaad212772426aa9e8ce636401a257",
            "a6bddaa5e953464f84b5ea25a7b9a7ad",
            "2fbf0d377805445e8e8b483b16fac1cb",
            "62cbe3414f994028b65c2471f64f0239",
            "5eac49806b0947b3996122670e688288"
          ]
        },
        "outputId": "5136c081-7453-40e3-ceda-193d9ac54c24"
      },
      "source": [
        "lr_finder.reset()\n",
        "lr_finder = LRFinder(model_gpu, optimizer, loss_fn, device=\"cuda\")\n",
        "\n",
        "lr_finder.range_test(train_loader, end_lr=1, num_iter=100, start_lr=0.00001)\n",
        "lr_finder.plot()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ae929c62dd7400b9f51e7b62fba4b6f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Stopping early, the loss has diverged\n",
            "Learning rate search finished. See the graph with {finder_name}.plot()\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f9bf04c3128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ej54f-wDkqhK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "outputId": "8972047d-6ec8-4fd7-f0b2-5eb0f1526395"
      },
      "source": [
        "model_base = nn.Sequential( \n",
        "                nn.Kerv2d(in_channels , out_channels_1, padding=padding_1, dilation=1, groups=1, bias=True, \n",
        "                          kernel_type='gaussian', kernel_size=kernel_size, learnable_kernel=True,\n",
        "                          kernel_regularizer=True, stride=1, balance=0.1, power=6, gamma=0.1\n",
        "                          ),\n",
        "                nn.BatchNorm2d(out_channels_1),\n",
        "                nn.AvgPool2d(2, stride=2), \n",
        "                nn.Conv2d(out_channels_1 , out_channels_2, padding= padding_1, kernel_size=kernel_size, stride=1), \n",
        "                nn.BatchNorm2d(out_channels_2),\n",
        "                nn.AvgPool2d(2, stride=2), \n",
        "                nn.Conv2d(out_channels_2 , out_channels_3, padding= padding_1, kernel_size=kernel_size, stride=1), \n",
        "                nn.Dropout(0.1), \n",
        "                nn.BatchNorm2d(out_channels_3),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_3 , out_channels_4, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                \n",
        "                \n",
        "                nn.BatchNorm2d(out_channels_4),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_4 , out_channels_5, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.BatchNorm2d(out_channels_5),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_5 , out_channels_6, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.BatchNorm2d(out_channels_6),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "               \n",
        "                nn.Dropout(0.5),\n",
        "                Flatten(),\n",
        "                nn.Linear(100,64),\n",
        "                nn.Linear(64,2)\n",
        "            )\n",
        "model_gpu = model_base.type(gpu_dtype)\n",
        "print(model_gpu)\n",
        "loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) "
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Kerv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (3): Conv2d(16, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (6): Conv2d(24, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (7): Dropout(p=0.1, inplace=False)\n",
            "  (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (10): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (11): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (12): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (13): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (14): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (15): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (16): Conv2d(64, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (17): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (18): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (19): Dropout(p=0.5, inplace=False)\n",
            "  (20): Flatten()\n",
            "  (21): Linear(in_features=100, out_features=64, bias=True)\n",
            "  (22): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lz8CSO88kqlC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369,
          "referenced_widgets": [
            "64c48c844e394895b3984ef09173f749",
            "44aacaf385da4cf88ca0a1170b5c179a",
            "16daeaba47fe477b8fd065be33bdb690",
            "2b2253786b0b41e98f90ed8e721ced8f",
            "af4beb9b100047edbc5bde8ecfbb19a7",
            "18c2db9831e1439095feaac21a45cad7",
            "1aa574a1431c4c8399432b04c5c21268",
            "f47107dcf5b248ecb39ac53d8a29ce36"
          ]
        },
        "outputId": "df4a80df-5a04-407d-bcbc-cd5b31f043fe"
      },
      "source": [
        "lr_finder.reset()\n",
        "lr_finder = LRFinder(model_gpu, optimizer, loss_fn, device=\"cuda\")\n",
        "\n",
        "lr_finder.range_test(train_loader, end_lr=1, num_iter=100, start_lr=0.00001)\n",
        "lr_finder.plot()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "64c48c844e394895b3984ef09173f749",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Stopping early, the loss has diverged\n",
            "Learning rate search finished. See the graph with {finder_name}.plot()\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f9bf054a908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORlihx82pVHV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "outputId": "de77b5b7-7010-40e5-bf33-40b2cbab68da"
      },
      "source": [
        "model_base = nn.Sequential( \n",
        "                nn.Kerv2d(in_channels , out_channels_1, padding=padding_1, dilation=1, groups=1, bias=True, \n",
        "                          kernel_type='gaussian', kernel_size=kernel_size, learnable_kernel=True,\n",
        "                          kernel_regularizer=True, stride=1, balance=0.1, power=3, gamma=0.1\n",
        "                          ),\n",
        "                nn.BatchNorm2d(out_channels_1),\n",
        "                nn.AvgPool2d(2, stride=2), \n",
        "                nn.Conv2d(out_channels_1 , out_channels_2, padding= padding_1, kernel_size=kernel_size, stride=1), \n",
        "                nn.BatchNorm2d(out_channels_2),\n",
        "                nn.AvgPool2d(2, stride=2), \n",
        "                nn.Conv2d(out_channels_2 , out_channels_3, padding= padding_1, kernel_size=kernel_size, stride=1), \n",
        "                nn.Dropout(0.1), \n",
        "                nn.BatchNorm2d(out_channels_3),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_3 , out_channels_4, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                \n",
        "                \n",
        "                nn.BatchNorm2d(out_channels_4),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_4 , out_channels_5, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.BatchNorm2d(out_channels_5),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_5 , out_channels_6, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.BatchNorm2d(out_channels_6),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "               \n",
        "                nn.Dropout(0.5),\n",
        "                Flatten(),\n",
        "                nn.Linear(100,64),\n",
        "                nn.Linear(64,2)\n",
        "            )\n",
        "model_gpu = model_base.type(gpu_dtype)\n",
        "print(model_gpu)\n",
        "loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Kerv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (3): Conv2d(16, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (6): Conv2d(24, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (7): Dropout(p=0.1, inplace=False)\n",
            "  (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (10): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (11): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (12): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (13): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (14): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (15): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (16): Conv2d(64, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (17): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (18): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (19): Dropout(p=0.5, inplace=False)\n",
            "  (20): Flatten()\n",
            "  (21): Linear(in_features=100, out_features=64, bias=True)\n",
            "  (22): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjliE_aopVLM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369,
          "referenced_widgets": [
            "7e11c00cad734871856b4010e51be936",
            "0b83346625e641f59f70a2366a33b189",
            "7c69966d1a2e48fea5c18b6b44774932",
            "822de21f3af84e9b88f082515628d357",
            "6d6386a9a70d4f1184219a045a8d0233",
            "88e29fb2aef843bab94b38a531318e37",
            "96e1394dd7084e698cd88fadda81407b",
            "fba389d6c1254abd9ee9b383bab21f4f"
          ]
        },
        "outputId": "7856f31b-e1d4-48a5-c7a3-0d3951c5df46"
      },
      "source": [
        "lr_finder.reset()\n",
        "lr_finder = LRFinder(model_gpu, optimizer, loss_fn, device=\"cuda\")\n",
        "\n",
        "lr_finder.range_test(train_loader, end_lr=1, num_iter=100, start_lr=0.00001)\n",
        "lr_finder.plot()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7e11c00cad734871856b4010e51be936",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Stopping early, the loss has diverged\n",
            "Learning rate search finished. See the graph with {finder_name}.plot()\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f9bf03190f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZhw_L7QkqpU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6beWHHokqfR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzuX5gLEeJfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def retry_from_backup():\n",
        "  model_gpu = model_base.type(gpu_dtype)\n",
        "  print(model_gpu)\n",
        "  loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) \n",
        "\n",
        "\n",
        "\n",
        "  checkpoint = torch.load(model_backup_path)\n",
        "  model_gpu.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  epoch = checkpoint['epoch']\n",
        "  loss = checkpoint['loss']\n",
        "  print(\"starting from epoch: \" + str(epoch))\n",
        "  print(\"starting from loss: \" + str(loss))\n",
        "\n",
        "  train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=50, starting_from_epoch=epoch)\n",
        "  check_accuracy(model_gpu, valid_loader)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDn-2g-TLY3k",
        "colab_type": "code",
        "outputId": "a5452d18-bbce-4263-9455-5652cb060e9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot([print_every*batch_size*(i+1) for i in range((len(avg_loss_list)))],avg_loss_list)\n",
        "print(\"Loss:\")\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGer6hJv7-zR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "6ee2e78b-8f10-4c00-87d7-710488ea78b3"
      },
      "source": [
        "plt.plot([i+1 for i in range((len(acc_list)))],acc_list)\n",
        "print(\"Accurancy:\")\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accurancy:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}