{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN_Avg_No_Relu2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamilo116/KNN/blob/master/KNN_Avg_No_Relu2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7ReM7FU-xs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import sys\n",
        "from random import shuffle\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms as transforms\n",
        "import timeit\n",
        "\n",
        "np.random.seed(4) \n",
        "torch.manual_seed(4) \n",
        "torch.cuda.manual_seed(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYIMZ8QyYewD",
        "colab_type": "code",
        "outputId": "152ad6bf-a695-48cd-b0d5-f6b74a2a084b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "! git clone https://github.com/wang-chen/kervolution.git \n",
        "\n",
        "sys.path.append(\"kervolution/\")\n",
        "from kervolution import Kerv2d\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'kervolution'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects:  16% (1/6)\u001b[K\rremote: Counting objects:  33% (2/6)\u001b[K\rremote: Counting objects:  50% (3/6)\u001b[K\rremote: Counting objects:  66% (4/6)\u001b[K\rremote: Counting objects:  83% (5/6)\u001b[K\rremote: Counting objects: 100% (6/6)\u001b[K\rremote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects:  16% (1/6)\u001b[K\rremote: Compressing objects:  33% (2/6)\u001b[K\rremote: Compressing objects:  50% (3/6)\u001b[K\rremote: Compressing objects:  66% (4/6)\u001b[K\rremote: Compressing objects:  83% (5/6)\u001b[K\rremote: Compressing objects: 100% (6/6)\u001b[K\rremote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "Unpacking objects:   1% (1/53)   \rUnpacking objects:   3% (2/53)   \rUnpacking objects:   5% (3/53)   \rUnpacking objects:   7% (4/53)   \rUnpacking objects:   9% (5/53)   \rUnpacking objects:  11% (6/53)   \rUnpacking objects:  13% (7/53)   \rUnpacking objects:  15% (8/53)   \rUnpacking objects:  16% (9/53)   \rUnpacking objects:  18% (10/53)   \rUnpacking objects:  20% (11/53)   \rUnpacking objects:  22% (12/53)   \rUnpacking objects:  24% (13/53)   \rUnpacking objects:  26% (14/53)   \rUnpacking objects:  28% (15/53)   \rUnpacking objects:  30% (16/53)   \rUnpacking objects:  32% (17/53)   \rUnpacking objects:  33% (18/53)   \rUnpacking objects:  35% (19/53)   \rUnpacking objects:  37% (20/53)   \rUnpacking objects:  39% (21/53)   \rUnpacking objects:  41% (22/53)   \rUnpacking objects:  43% (23/53)   \rUnpacking objects:  45% (24/53)   \rUnpacking objects:  47% (25/53)   \rUnpacking objects:  49% (26/53)   \rUnpacking objects:  50% (27/53)   \rUnpacking objects:  52% (28/53)   \rUnpacking objects:  54% (29/53)   \rUnpacking objects:  56% (30/53)   \rUnpacking objects:  58% (31/53)   \rUnpacking objects:  60% (32/53)   \rUnpacking objects:  62% (33/53)   \rUnpacking objects:  64% (34/53)   \rremote: Total 53 (delta 2), reused 0 (delta 0), pack-reused 47\u001b[K\n",
            "Unpacking objects:  66% (35/53)   \rUnpacking objects:  67% (36/53)   \rUnpacking objects:  69% (37/53)   \rUnpacking objects:  71% (38/53)   \rUnpacking objects:  73% (39/53)   \rUnpacking objects:  75% (40/53)   \rUnpacking objects:  77% (41/53)   \rUnpacking objects:  79% (42/53)   \rUnpacking objects:  81% (43/53)   \rUnpacking objects:  83% (44/53)   \rUnpacking objects:  84% (45/53)   \rUnpacking objects:  86% (46/53)   \rUnpacking objects:  88% (47/53)   \rUnpacking objects:  90% (48/53)   \rUnpacking objects:  92% (49/53)   \rUnpacking objects:  94% (50/53)   \rUnpacking objects:  96% (51/53)   \rUnpacking objects:  98% (52/53)   \rUnpacking objects: 100% (53/53)   \rUnpacking objects: 100% (53/53), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvbKg4VJXKY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LIMIT_IMAGES_NUM = 500\n",
        "train_test_split_size = 0.2\n",
        "image_resize = (100, 100)\n",
        "batch_size = 64\n",
        "num_workers = 0\n",
        "\n",
        "in_channels = 3\n",
        "out_channels_1 = 16\n",
        "out_channels_2 = 32\n",
        "out_channels_3 = 64\n",
        "out_channels_4 = 128\n",
        "\n",
        "kernel_size = 3\n",
        "padding_1 = 1\n",
        "num_epochs = 80\n",
        "\n",
        "learning_rate = 0.0003\n",
        "weight_decay = 0\n",
        "\n",
        "MALIGNANT_DATASET = '/content/drive/My Drive/Colab_data/malignant/malignant/'\n",
        "BENIGN_DATASET = '/content/drive/My Drive/Colab_data/benign/benign/'\n",
        "DATA_FOLDER = '/content/drive/My Drive/Colab_data/'\n",
        "model_backup_path = os.path.join(DATA_FOLDER, 'backup_model') \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMOHez_kHZD6",
        "colab_type": "code",
        "outputId": "d7e02d88-79a3-4600-f84c-9b3c62a0b363",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b8P1NdXfVdX",
        "colab_type": "code",
        "outputId": "5acf6a06-82f4-4745-d028-fcc2b25b57a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "benign_file_list = sorted(os.listdir(BENIGN_DATASET))\n",
        "malignant_file_list = sorted(os.listdir(MALIGNANT_DATASET))\n",
        "shuffle(benign_file_list)\n",
        "shuffle(malignant_file_list)\n",
        "benign_file_list = benign_file_list[:LIMIT_IMAGES_NUM]\n",
        "malignant_file_list = malignant_file_list[:LIMIT_IMAGES_NUM]\n",
        "\n",
        "print(f\"Number of benign {len(benign_file_list)} images\")\n",
        "print(f\"Number of malignant {len(malignant_file_list)} images\")\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize(image_resize),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of benign 500 images\n",
            "Number of malignant 500 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGDQfal74BLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "benign_dict = {filename: 0 for filename in benign_file_list}\n",
        "malignant_dict = {filename: 1 for filename in malignant_file_list}\n",
        "img_class_dict = {**benign_dict , **malignant_dict}\n",
        "labeled_data = pd.Series(img_class_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvAAOqmVfVll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IsicDataset(Dataset):\n",
        "    def __init__(self, data_folder, labeled_data, \n",
        "                 transform=transforms.Compose([transforms.ToTensor()])):\n",
        "        self.labeled_data = labeled_data\n",
        "        self.transform = transform\n",
        "        self.data_folder = data_folder\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labeled_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        label = self.labeled_data[index]\n",
        "        if label == 0:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"benign\", \"benign\", index ))\n",
        "        else:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"malignant\", \"malignant\", index ))\n",
        "        image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "    @property\n",
        "    def labels(self):\n",
        "      return self.labeled_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSuYqjLAYrWA",
        "colab_type": "code",
        "outputId": "b8820a8a-e8f3-4f60-aeff-c5f5130cbcc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        }
      },
      "source": [
        " \n",
        "dataset = IsicDataset(DATA_FOLDER, labeled_data, transform=data_transforms)\n",
        "print(dataset.labels)\n",
        "\n",
        "X_train, X_test = train_test_split(dataset.labels, test_size=train_test_split_size)\n",
        "print(\"number of training data: \",len(X_train))\n",
        "print(\"number of testing  data: \",len(X_test))\n",
        "\n",
        "train_sampler = SubsetRandomSampler(list(X_train.index))\n",
        "valid_sampler = SubsetRandomSampler(list(X_test.index))\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ISIC_0000861.jpeg    0\n",
            "ISIC_0002657.jpeg    0\n",
            "ISIC_0000588.jpeg    0\n",
            "ISIC_0000317.jpeg    0\n",
            "ISIC_0000874.jpeg    0\n",
            "                    ..\n",
            "ISIC_0000031.jpeg    1\n",
            "ISIC_0014788.jpeg    1\n",
            "ISIC_0012887.jpeg    1\n",
            "ISIC_0014542.jpeg    1\n",
            "ISIC_0015193.jpeg    1\n",
            "Length: 1000, dtype: int64\n",
            "number of training data:  800\n",
            "number of testing  data:  200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e8nFBR6Yug5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "def train(model, train_loader ,loss_fn, optimizer, num_epochs=1, starting_from_epoch=1):\n",
        "    total_loss =0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
        "        model.train()\n",
        "\n",
        "        for t, (x, y) in enumerate(train_loader):\n",
        "            x_var = Variable(x.type(gpu_dtype))\n",
        "            y_var = Variable(y.type(gpu_dtype).long())\n",
        "            scores = model(x_var)\n",
        "            loss = loss_fn(scores, y_var)\n",
        "            total_loss += loss.data\n",
        "            \n",
        "            if (t + 1) % print_every == 0:\n",
        "                avg_loss = total_loss/print_every\n",
        "                print('t = %d, avg_loss = %.4f' % (t + 1, avg_loss) )\n",
        "                avg_loss_list.append(avg_loss)\n",
        "                total_loss = 0\n",
        "                \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        acc = check_accuracy(model_gpu, valid_loader)\n",
        "        print('acc = %f' %(acc))\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model_gpu.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            }, model_backup_path)\n",
        "            \n",
        "def check_accuracy(model, loader):\n",
        "    print('Checking accuracy on test set')   \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval() \n",
        "    for x, y in loader:\n",
        "        x_var = Variable(x.type(gpu_dtype))\n",
        "\n",
        "        scores = model(x_var)\n",
        "        _, preds = scores.data.cpu().max(1)\n",
        "        num_correct += (preds == y).sum()\n",
        "        num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    acc_list.append(acc)\n",
        "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "    return acc\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggvpMu36Yw2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.size()\n",
        "        return x.view(N, -1)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgmexhBRZAK6",
        "colab_type": "code",
        "outputId": "ead5904d-566e-4192-8b4f-dfc8186c427b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "gpu_dtype = torch.cuda.FloatTensor\n",
        "\n",
        "print_every = 1\n",
        "\n",
        "\n",
        "'''\n",
        "Kerv2d\n",
        "kervolution with following options:\n",
        "kernel_type: [linear, polynomial, gaussian, etc.]\n",
        "default is convolution:\n",
        "          kernel_type --> linear,\n",
        "balance, power, gamma is valid only when the kernel_type is specified\n",
        "if learnable_kernel = True,  they just be the initial value of learable parameters\n",
        "if learnable_kernel = False, they are the value of kernel_type's parameter\n",
        "the parameter [power] cannot be learned due to integer limitation\n",
        "dilation (int or tuple, optional): Spacing between kernel\n",
        "elements. Default: 1\n",
        "groups (int, optional): Number of blocked connections from input\n",
        "channels to output channels. Default: 1\n",
        "bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n",
        "kernel_type (str), Default: 'linear'\n",
        "learnable_kernel (bool): Learnable kernel parameters.  Default: False \n",
        "balance: 0, 1\n",
        "power: 3, 4, 5\n",
        "gamma:\n",
        "'''\n",
        "\n",
        "\n",
        "model_base = nn.Sequential( \n",
        "                nn.Kerv2d(in_channels , out_channels_1, padding=padding_1, dilation=1, groups=1, bias=True, \n",
        "                          kernel_type='polynomial', kernel_size=kernel_size, learnable_kernel=True,\n",
        "                          kernel_regularizer=True, stride=1, balance=1, power=3, gamma=1\n",
        "                          ),\n",
        "                nn.BatchNorm2d(out_channels_1),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_1 , out_channels_2, padding= padding_1, kernel_size=kernel_size, stride=1), \n",
        "                nn.BatchNorm2d(out_channels_2),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_2 , out_channels_3, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.BatchNorm2d(out_channels_3),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_3 , out_channels_4, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.BatchNorm2d(out_channels_4),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Dropout(0.5),\n",
        "                Flatten(),\n",
        "                nn.Linear(4608,64),\n",
        "                nn.Linear(64,2)\n",
        "            )\n",
        "model_gpu = model_base.type(gpu_dtype)\n",
        "print(model_gpu)\n",
        "loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) \n",
        "\n",
        "train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs)\n",
        "check_accuracy(model_gpu, valid_loader)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Kerv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (8): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (9): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (11): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (12): Dropout(p=0.5, inplace=False)\n",
            "  (13): Flatten()\n",
            "  (14): Linear(in_features=4608, out_features=64, bias=True)\n",
            "  (15): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n",
            "Starting epoch 1 / 80\n",
            "t = 1, avg_loss = 0.7413\n",
            "t = 2, avg_loss = 1.0334\n",
            "t = 3, avg_loss = 0.9262\n",
            "t = 4, avg_loss = 0.7164\n",
            "t = 5, avg_loss = 0.8623\n",
            "t = 6, avg_loss = 1.0934\n",
            "t = 7, avg_loss = 0.8214\n",
            "t = 8, avg_loss = 0.8719\n",
            "t = 9, avg_loss = 0.9387\n",
            "t = 10, avg_loss = 0.7729\n",
            "t = 11, avg_loss = 0.7769\n",
            "t = 12, avg_loss = 0.6162\n",
            "t = 13, avg_loss = 0.7102\n",
            "Checking accuracy on test set\n",
            "Got 98 / 200 correct (49.00)\n",
            "acc = 0.490000\n",
            "Starting epoch 2 / 80\n",
            "t = 1, avg_loss = 0.7649\n",
            "t = 2, avg_loss = 0.7542\n",
            "t = 3, avg_loss = 0.6877\n",
            "t = 4, avg_loss = 0.7364\n",
            "t = 5, avg_loss = 0.7034\n",
            "t = 6, avg_loss = 0.7522\n",
            "t = 7, avg_loss = 0.9370\n",
            "t = 8, avg_loss = 0.6928\n",
            "t = 9, avg_loss = 0.6362\n",
            "t = 10, avg_loss = 0.5320\n",
            "t = 11, avg_loss = 0.7469\n",
            "t = 12, avg_loss = 0.6852\n",
            "t = 13, avg_loss = 0.9495\n",
            "Checking accuracy on test set\n",
            "Got 127 / 200 correct (63.50)\n",
            "acc = 0.635000\n",
            "Starting epoch 3 / 80\n",
            "t = 1, avg_loss = 0.8226\n",
            "t = 2, avg_loss = 0.9749\n",
            "t = 3, avg_loss = 0.8271\n",
            "t = 4, avg_loss = 0.6929\n",
            "t = 5, avg_loss = 0.5162\n",
            "t = 6, avg_loss = 0.6814\n",
            "t = 7, avg_loss = 0.7302\n",
            "t = 8, avg_loss = 0.6579\n",
            "t = 9, avg_loss = 0.6951\n",
            "t = 10, avg_loss = 0.6555\n",
            "t = 11, avg_loss = 0.6256\n",
            "t = 12, avg_loss = 0.6644\n",
            "t = 13, avg_loss = 0.5434\n",
            "Checking accuracy on test set\n",
            "Got 143 / 200 correct (71.50)\n",
            "acc = 0.715000\n",
            "Starting epoch 4 / 80\n",
            "t = 1, avg_loss = 0.5958\n",
            "t = 2, avg_loss = 0.5953\n",
            "t = 3, avg_loss = 0.7717\n",
            "t = 4, avg_loss = 0.5557\n",
            "t = 5, avg_loss = 0.8179\n",
            "t = 6, avg_loss = 0.7006\n",
            "t = 7, avg_loss = 0.7859\n",
            "t = 8, avg_loss = 0.6341\n",
            "t = 9, avg_loss = 0.7511\n",
            "t = 10, avg_loss = 0.6278\n",
            "t = 11, avg_loss = 0.6567\n",
            "t = 12, avg_loss = 0.6041\n",
            "t = 13, avg_loss = 0.4481\n",
            "Checking accuracy on test set\n",
            "Got 135 / 200 correct (67.50)\n",
            "acc = 0.675000\n",
            "Starting epoch 5 / 80\n",
            "t = 1, avg_loss = 0.6724\n",
            "t = 2, avg_loss = 0.5921\n",
            "t = 3, avg_loss = 0.5157\n",
            "t = 4, avg_loss = 0.6735\n",
            "t = 5, avg_loss = 0.6865\n",
            "t = 6, avg_loss = 0.6532\n",
            "t = 7, avg_loss = 0.7773\n",
            "t = 8, avg_loss = 0.7528\n",
            "t = 9, avg_loss = 0.7059\n",
            "t = 10, avg_loss = 0.7051\n",
            "t = 11, avg_loss = 0.6730\n",
            "t = 12, avg_loss = 0.6298\n",
            "t = 13, avg_loss = 0.6083\n",
            "Checking accuracy on test set\n",
            "Got 131 / 200 correct (65.50)\n",
            "acc = 0.655000\n",
            "Starting epoch 6 / 80\n",
            "t = 1, avg_loss = 0.8339\n",
            "t = 2, avg_loss = 0.5762\n",
            "t = 3, avg_loss = 0.6681\n",
            "t = 4, avg_loss = 0.7483\n",
            "t = 5, avg_loss = 0.7064\n",
            "t = 6, avg_loss = 0.5428\n",
            "t = 7, avg_loss = 0.6489\n",
            "t = 8, avg_loss = 0.5857\n",
            "t = 9, avg_loss = 0.7596\n",
            "t = 10, avg_loss = 0.6756\n",
            "t = 11, avg_loss = 0.6385\n",
            "t = 12, avg_loss = 0.7198\n",
            "t = 13, avg_loss = 0.5525\n",
            "Checking accuracy on test set\n",
            "Got 137 / 200 correct (68.50)\n",
            "acc = 0.685000\n",
            "Starting epoch 7 / 80\n",
            "t = 1, avg_loss = 0.7253\n",
            "t = 2, avg_loss = 0.6461\n",
            "t = 3, avg_loss = 0.6033\n",
            "t = 4, avg_loss = 0.5911\n",
            "t = 5, avg_loss = 0.8183\n",
            "t = 6, avg_loss = 0.6352\n",
            "t = 7, avg_loss = 0.5559\n",
            "t = 8, avg_loss = 0.8460\n",
            "t = 9, avg_loss = 0.7620\n",
            "t = 10, avg_loss = 0.7446\n",
            "t = 11, avg_loss = 0.5346\n",
            "t = 12, avg_loss = 0.6545\n",
            "t = 13, avg_loss = 0.7915\n",
            "Checking accuracy on test set\n",
            "Got 141 / 200 correct (70.50)\n",
            "acc = 0.705000\n",
            "Starting epoch 8 / 80\n",
            "t = 1, avg_loss = 0.7503\n",
            "t = 2, avg_loss = 0.4612\n",
            "t = 3, avg_loss = 0.7443\n",
            "t = 4, avg_loss = 0.6974\n",
            "t = 5, avg_loss = 0.8026\n",
            "t = 6, avg_loss = 0.5736\n",
            "t = 7, avg_loss = 0.5420\n",
            "t = 8, avg_loss = 0.4827\n",
            "t = 9, avg_loss = 0.5586\n",
            "t = 10, avg_loss = 0.7013\n",
            "t = 11, avg_loss = 0.6712\n",
            "t = 12, avg_loss = 0.5299\n",
            "t = 13, avg_loss = 0.6867\n",
            "Checking accuracy on test set\n",
            "Got 146 / 200 correct (73.00)\n",
            "acc = 0.730000\n",
            "Starting epoch 9 / 80\n",
            "t = 1, avg_loss = 0.5632\n",
            "t = 2, avg_loss = 0.4487\n",
            "t = 3, avg_loss = 0.7368\n",
            "t = 4, avg_loss = 0.5908\n",
            "t = 5, avg_loss = 0.6516\n",
            "t = 6, avg_loss = 0.6435\n",
            "t = 7, avg_loss = 0.5838\n",
            "t = 8, avg_loss = 0.5137\n",
            "t = 9, avg_loss = 0.6013\n",
            "t = 10, avg_loss = 0.5902\n",
            "t = 11, avg_loss = 0.6113\n",
            "t = 12, avg_loss = 0.6185\n",
            "t = 13, avg_loss = 0.6476\n",
            "Checking accuracy on test set\n",
            "Got 139 / 200 correct (69.50)\n",
            "acc = 0.695000\n",
            "Starting epoch 10 / 80\n",
            "t = 1, avg_loss = 0.6573\n",
            "t = 2, avg_loss = 0.6640\n",
            "t = 3, avg_loss = 0.5654\n",
            "t = 4, avg_loss = 0.7082\n",
            "t = 5, avg_loss = 0.7822\n",
            "t = 6, avg_loss = 0.5693\n",
            "t = 7, avg_loss = 0.6970\n",
            "t = 8, avg_loss = 0.5537\n",
            "t = 9, avg_loss = 0.5603\n",
            "t = 10, avg_loss = 0.4871\n",
            "t = 11, avg_loss = 0.5477\n",
            "t = 12, avg_loss = 0.6023\n",
            "t = 13, avg_loss = 0.6834\n",
            "Checking accuracy on test set\n",
            "Got 150 / 200 correct (75.00)\n",
            "acc = 0.750000\n",
            "Starting epoch 11 / 80\n",
            "t = 1, avg_loss = 0.5192\n",
            "t = 2, avg_loss = 0.6433\n",
            "t = 3, avg_loss = 0.5198\n",
            "t = 4, avg_loss = 0.6691\n",
            "t = 5, avg_loss = 0.5693\n",
            "t = 6, avg_loss = 0.6387\n",
            "t = 7, avg_loss = 0.6793\n",
            "t = 8, avg_loss = 0.4457\n",
            "t = 9, avg_loss = 0.6672\n",
            "t = 10, avg_loss = 0.6922\n",
            "t = 11, avg_loss = 0.6055\n",
            "t = 12, avg_loss = 0.5391\n",
            "t = 13, avg_loss = 0.6396\n",
            "Checking accuracy on test set\n",
            "Got 145 / 200 correct (72.50)\n",
            "acc = 0.725000\n",
            "Starting epoch 12 / 80\n",
            "t = 1, avg_loss = 0.7195\n",
            "t = 2, avg_loss = 0.4894\n",
            "t = 3, avg_loss = 0.5267\n",
            "t = 4, avg_loss = 0.6419\n",
            "t = 5, avg_loss = 0.5418\n",
            "t = 6, avg_loss = 0.5769\n",
            "t = 7, avg_loss = 0.6842\n",
            "t = 8, avg_loss = 0.7622\n",
            "t = 9, avg_loss = 0.5309\n",
            "t = 10, avg_loss = 0.6745\n",
            "t = 11, avg_loss = 0.5284\n",
            "t = 12, avg_loss = 0.5153\n",
            "t = 13, avg_loss = 0.5383\n",
            "Checking accuracy on test set\n",
            "Got 150 / 200 correct (75.00)\n",
            "acc = 0.750000\n",
            "Starting epoch 13 / 80\n",
            "t = 1, avg_loss = 0.6262\n",
            "t = 2, avg_loss = 0.4681\n",
            "t = 3, avg_loss = 0.6758\n",
            "t = 4, avg_loss = 0.5415\n",
            "t = 5, avg_loss = 0.5938\n",
            "t = 6, avg_loss = 0.5400\n",
            "t = 7, avg_loss = 0.5350\n",
            "t = 8, avg_loss = 0.5572\n",
            "t = 9, avg_loss = 0.6025\n",
            "t = 10, avg_loss = 0.6269\n",
            "t = 11, avg_loss = 0.6481\n",
            "t = 12, avg_loss = 0.6320\n",
            "t = 13, avg_loss = 0.7025\n",
            "Checking accuracy on test set\n",
            "Got 138 / 200 correct (69.00)\n",
            "acc = 0.690000\n",
            "Starting epoch 14 / 80\n",
            "t = 1, avg_loss = 0.4496\n",
            "t = 2, avg_loss = 0.5971\n",
            "t = 3, avg_loss = 0.4684\n",
            "t = 4, avg_loss = 0.5208\n",
            "t = 5, avg_loss = 0.5407\n",
            "t = 6, avg_loss = 0.7937\n",
            "t = 7, avg_loss = 0.6110\n",
            "t = 8, avg_loss = 0.5116\n",
            "t = 9, avg_loss = 0.6628\n",
            "t = 10, avg_loss = 0.6602\n",
            "t = 11, avg_loss = 0.6657\n",
            "t = 12, avg_loss = 0.7191\n",
            "t = 13, avg_loss = 0.6675\n",
            "Checking accuracy on test set\n",
            "Got 145 / 200 correct (72.50)\n",
            "acc = 0.725000\n",
            "Starting epoch 15 / 80\n",
            "t = 1, avg_loss = 0.6474\n",
            "t = 2, avg_loss = 0.5120\n",
            "t = 3, avg_loss = 0.6481\n",
            "t = 4, avg_loss = 0.5863\n",
            "t = 5, avg_loss = 0.6283\n",
            "t = 6, avg_loss = 0.6730\n",
            "t = 7, avg_loss = 0.5884\n",
            "t = 8, avg_loss = 0.6107\n",
            "t = 9, avg_loss = 0.5401\n",
            "t = 10, avg_loss = 0.6187\n",
            "t = 11, avg_loss = 0.6945\n",
            "t = 12, avg_loss = 0.5267\n",
            "t = 13, avg_loss = 0.6310\n",
            "Checking accuracy on test set\n",
            "Got 128 / 200 correct (64.00)\n",
            "acc = 0.640000\n",
            "Starting epoch 16 / 80\n",
            "t = 1, avg_loss = 0.6793\n",
            "t = 2, avg_loss = 0.5439\n",
            "t = 3, avg_loss = 0.5164\n",
            "t = 4, avg_loss = 0.5659\n",
            "t = 5, avg_loss = 0.5282\n",
            "t = 6, avg_loss = 0.5010\n",
            "t = 7, avg_loss = 0.5977\n",
            "t = 8, avg_loss = 0.5256\n",
            "t = 9, avg_loss = 0.6142\n",
            "t = 10, avg_loss = 0.6923\n",
            "t = 11, avg_loss = 0.6279\n",
            "t = 12, avg_loss = 0.6706\n",
            "t = 13, avg_loss = 0.8611\n",
            "Checking accuracy on test set\n",
            "Got 126 / 200 correct (63.00)\n",
            "acc = 0.630000\n",
            "Starting epoch 17 / 80\n",
            "t = 1, avg_loss = 0.5738\n",
            "t = 2, avg_loss = 0.5274\n",
            "t = 3, avg_loss = 0.7858\n",
            "t = 4, avg_loss = 0.6442\n",
            "t = 5, avg_loss = 0.5423\n",
            "t = 6, avg_loss = 0.5948\n",
            "t = 7, avg_loss = 0.7364\n",
            "t = 8, avg_loss = 0.5044\n",
            "t = 9, avg_loss = 0.6500\n",
            "t = 10, avg_loss = 0.5722\n",
            "t = 11, avg_loss = 0.4251\n",
            "t = 12, avg_loss = 0.5631\n",
            "t = 13, avg_loss = 0.4314\n",
            "Checking accuracy on test set\n",
            "Got 144 / 200 correct (72.00)\n",
            "acc = 0.720000\n",
            "Starting epoch 18 / 80\n",
            "t = 1, avg_loss = 0.6562\n",
            "t = 2, avg_loss = 0.7601\n",
            "t = 3, avg_loss = 0.4417\n",
            "t = 4, avg_loss = 0.4625\n",
            "t = 5, avg_loss = 0.6414\n",
            "t = 6, avg_loss = 0.4901\n",
            "t = 7, avg_loss = 0.6251\n",
            "t = 8, avg_loss = 0.5160\n",
            "t = 9, avg_loss = 0.5687\n",
            "t = 10, avg_loss = 0.6437\n",
            "t = 11, avg_loss = 0.5333\n",
            "t = 12, avg_loss = 0.6174\n",
            "t = 13, avg_loss = 0.5911\n",
            "Checking accuracy on test set\n",
            "Got 153 / 200 correct (76.50)\n",
            "acc = 0.765000\n",
            "Starting epoch 19 / 80\n",
            "t = 1, avg_loss = 0.5251\n",
            "t = 2, avg_loss = 0.5022\n",
            "t = 3, avg_loss = 0.5432\n",
            "t = 4, avg_loss = 0.5775\n",
            "t = 5, avg_loss = 0.5302\n",
            "t = 6, avg_loss = 0.5507\n",
            "t = 7, avg_loss = 0.5108\n",
            "t = 8, avg_loss = 0.7042\n",
            "t = 9, avg_loss = 0.5897\n",
            "t = 10, avg_loss = 0.4857\n",
            "t = 11, avg_loss = 0.5220\n",
            "t = 12, avg_loss = 0.5791\n",
            "t = 13, avg_loss = 0.8485\n",
            "Checking accuracy on test set\n",
            "Got 149 / 200 correct (74.50)\n",
            "acc = 0.745000\n",
            "Starting epoch 20 / 80\n",
            "t = 1, avg_loss = 0.4866\n",
            "t = 2, avg_loss = 0.5689\n",
            "t = 3, avg_loss = 0.5972\n",
            "t = 4, avg_loss = 0.8162\n",
            "t = 5, avg_loss = 0.6885\n",
            "t = 6, avg_loss = 0.4793\n",
            "t = 7, avg_loss = 0.5635\n",
            "t = 8, avg_loss = 0.6317\n",
            "t = 9, avg_loss = 0.6216\n",
            "t = 10, avg_loss = 0.5558\n",
            "t = 11, avg_loss = 0.5627\n",
            "t = 12, avg_loss = 0.6554\n",
            "t = 13, avg_loss = 0.4659\n",
            "Checking accuracy on test set\n",
            "Got 140 / 200 correct (70.00)\n",
            "acc = 0.700000\n",
            "Starting epoch 21 / 80\n",
            "t = 1, avg_loss = 0.6135\n",
            "t = 2, avg_loss = 0.6148\n",
            "t = 3, avg_loss = 0.6082\n",
            "t = 4, avg_loss = 0.5666\n",
            "t = 5, avg_loss = 0.5655\n",
            "t = 6, avg_loss = 0.5222\n",
            "t = 7, avg_loss = 0.5308\n",
            "t = 8, avg_loss = 0.6513\n",
            "t = 9, avg_loss = 0.7051\n",
            "t = 10, avg_loss = 0.5035\n",
            "t = 11, avg_loss = 0.6105\n",
            "t = 12, avg_loss = 0.4953\n",
            "t = 13, avg_loss = 0.4377\n",
            "Checking accuracy on test set\n",
            "Got 146 / 200 correct (73.00)\n",
            "acc = 0.730000\n",
            "Starting epoch 22 / 80\n",
            "t = 1, avg_loss = 0.4460\n",
            "t = 2, avg_loss = 0.5833\n",
            "t = 3, avg_loss = 0.5264\n",
            "t = 4, avg_loss = 0.6950\n",
            "t = 5, avg_loss = 0.5407\n",
            "t = 6, avg_loss = 0.6352\n",
            "t = 7, avg_loss = 0.4444\n",
            "t = 8, avg_loss = 0.5959\n",
            "t = 9, avg_loss = 0.5873\n",
            "t = 10, avg_loss = 0.5064\n",
            "t = 11, avg_loss = 0.5390\n",
            "t = 12, avg_loss = 0.5798\n",
            "t = 13, avg_loss = 0.5584\n",
            "Checking accuracy on test set\n",
            "Got 153 / 200 correct (76.50)\n",
            "acc = 0.765000\n",
            "Starting epoch 23 / 80\n",
            "t = 1, avg_loss = 0.6005\n",
            "t = 2, avg_loss = 0.5204\n",
            "t = 3, avg_loss = 0.6044\n",
            "t = 4, avg_loss = 0.3951\n",
            "t = 5, avg_loss = 0.4896\n",
            "t = 6, avg_loss = 0.4957\n",
            "t = 7, avg_loss = 0.5767\n",
            "t = 8, avg_loss = 0.7052\n",
            "t = 9, avg_loss = 0.5696\n",
            "t = 10, avg_loss = 0.5552\n",
            "t = 11, avg_loss = 0.5723\n",
            "t = 12, avg_loss = 0.5005\n",
            "t = 13, avg_loss = 0.6350\n",
            "Checking accuracy on test set\n",
            "Got 151 / 200 correct (75.50)\n",
            "acc = 0.755000\n",
            "Starting epoch 24 / 80\n",
            "t = 1, avg_loss = 0.4347\n",
            "t = 2, avg_loss = 0.6005\n",
            "t = 3, avg_loss = 0.4610\n",
            "t = 4, avg_loss = 0.6718\n",
            "t = 5, avg_loss = 0.5671\n",
            "t = 6, avg_loss = 0.4766\n",
            "t = 7, avg_loss = 0.6209\n",
            "t = 8, avg_loss = 0.5910\n",
            "t = 9, avg_loss = 0.5127\n",
            "t = 10, avg_loss = 0.6148\n",
            "t = 11, avg_loss = 0.5924\n",
            "t = 12, avg_loss = 0.4667\n",
            "t = 13, avg_loss = 0.4803\n",
            "Checking accuracy on test set\n",
            "Got 149 / 200 correct (74.50)\n",
            "acc = 0.745000\n",
            "Starting epoch 25 / 80\n",
            "t = 1, avg_loss = 0.4574\n",
            "t = 2, avg_loss = 0.4390\n",
            "t = 3, avg_loss = 0.5751\n",
            "t = 4, avg_loss = 0.5705\n",
            "t = 5, avg_loss = 0.5987\n",
            "t = 6, avg_loss = 0.4923\n",
            "t = 7, avg_loss = 0.4612\n",
            "t = 8, avg_loss = 0.6325\n",
            "t = 9, avg_loss = 0.5161\n",
            "t = 10, avg_loss = 0.5920\n",
            "t = 11, avg_loss = 0.6010\n",
            "t = 12, avg_loss = 0.4693\n",
            "t = 13, avg_loss = 0.4567\n",
            "Checking accuracy on test set\n",
            "Got 155 / 200 correct (77.50)\n",
            "acc = 0.775000\n",
            "Starting epoch 26 / 80\n",
            "t = 1, avg_loss = 0.5431\n",
            "t = 2, avg_loss = 0.4651\n",
            "t = 3, avg_loss = 0.4153\n",
            "t = 4, avg_loss = 0.6347\n",
            "t = 5, avg_loss = 0.4657\n",
            "t = 6, avg_loss = 0.4770\n",
            "t = 7, avg_loss = 0.5249\n",
            "t = 8, avg_loss = 0.5790\n",
            "t = 9, avg_loss = 0.5177\n",
            "t = 10, avg_loss = 0.4665\n",
            "t = 11, avg_loss = 0.4927\n",
            "t = 12, avg_loss = 0.5121\n",
            "t = 13, avg_loss = 0.4741\n",
            "Checking accuracy on test set\n",
            "Got 149 / 200 correct (74.50)\n",
            "acc = 0.745000\n",
            "Starting epoch 27 / 80\n",
            "t = 1, avg_loss = 0.4677\n",
            "t = 2, avg_loss = 0.5187\n",
            "t = 3, avg_loss = 0.4533\n",
            "t = 4, avg_loss = 0.5456\n",
            "t = 5, avg_loss = 0.5061\n",
            "t = 6, avg_loss = 0.6360\n",
            "t = 7, avg_loss = 0.4462\n",
            "t = 8, avg_loss = 0.3761\n",
            "t = 9, avg_loss = 0.4638\n",
            "t = 10, avg_loss = 0.4546\n",
            "t = 11, avg_loss = 0.5599\n",
            "t = 12, avg_loss = 0.5032\n",
            "t = 13, avg_loss = 0.4958\n",
            "Checking accuracy on test set\n",
            "Got 156 / 200 correct (78.00)\n",
            "acc = 0.780000\n",
            "Starting epoch 28 / 80\n",
            "t = 1, avg_loss = 0.5019\n",
            "t = 2, avg_loss = 0.5336\n",
            "t = 3, avg_loss = 0.4957\n",
            "t = 4, avg_loss = 0.5055\n",
            "t = 5, avg_loss = 0.5726\n",
            "t = 6, avg_loss = 0.4482\n",
            "t = 7, avg_loss = 0.5259\n",
            "t = 8, avg_loss = 0.6522\n",
            "t = 9, avg_loss = 0.4273\n",
            "t = 10, avg_loss = 0.4385\n",
            "t = 11, avg_loss = 0.5765\n",
            "t = 12, avg_loss = 0.3926\n",
            "t = 13, avg_loss = 0.7183\n",
            "Checking accuracy on test set\n",
            "Got 143 / 200 correct (71.50)\n",
            "acc = 0.715000\n",
            "Starting epoch 29 / 80\n",
            "t = 1, avg_loss = 0.5476\n",
            "t = 2, avg_loss = 0.4775\n",
            "t = 3, avg_loss = 0.5736\n",
            "t = 4, avg_loss = 0.5230\n",
            "t = 5, avg_loss = 0.4638\n",
            "t = 6, avg_loss = 0.4276\n",
            "t = 7, avg_loss = 0.5875\n",
            "t = 8, avg_loss = 0.5089\n",
            "t = 9, avg_loss = 0.5763\n",
            "t = 10, avg_loss = 0.4589\n",
            "t = 11, avg_loss = 0.5719\n",
            "t = 12, avg_loss = 0.4571\n",
            "t = 13, avg_loss = 0.4505\n",
            "Checking accuracy on test set\n",
            "Got 152 / 200 correct (76.00)\n",
            "acc = 0.760000\n",
            "Starting epoch 30 / 80\n",
            "t = 1, avg_loss = 0.4595\n",
            "t = 2, avg_loss = 0.5264\n",
            "t = 3, avg_loss = 0.5824\n",
            "t = 4, avg_loss = 0.4236\n",
            "t = 5, avg_loss = 0.5748\n",
            "t = 6, avg_loss = 0.5496\n",
            "t = 7, avg_loss = 0.4362\n",
            "t = 8, avg_loss = 0.5014\n",
            "t = 9, avg_loss = 0.4413\n",
            "t = 10, avg_loss = 0.6338\n",
            "t = 11, avg_loss = 0.5814\n",
            "t = 12, avg_loss = 0.5309\n",
            "t = 13, avg_loss = 0.5078\n",
            "Checking accuracy on test set\n",
            "Got 144 / 200 correct (72.00)\n",
            "acc = 0.720000\n",
            "Starting epoch 31 / 80\n",
            "t = 1, avg_loss = 0.6013\n",
            "t = 2, avg_loss = 0.5281\n",
            "t = 3, avg_loss = 0.5664\n",
            "t = 4, avg_loss = 0.6856\n",
            "t = 5, avg_loss = 0.5219\n",
            "t = 6, avg_loss = 0.5927\n",
            "t = 7, avg_loss = 0.6577\n",
            "t = 8, avg_loss = 0.5304\n",
            "t = 9, avg_loss = 0.4598\n",
            "t = 10, avg_loss = 0.6141\n",
            "t = 11, avg_loss = 0.5517\n",
            "t = 12, avg_loss = 0.5485\n",
            "t = 13, avg_loss = 0.5516\n",
            "Checking accuracy on test set\n",
            "Got 155 / 200 correct (77.50)\n",
            "acc = 0.775000\n",
            "Starting epoch 32 / 80\n",
            "t = 1, avg_loss = 0.5369\n",
            "t = 2, avg_loss = 0.5068\n",
            "t = 3, avg_loss = 0.4201\n",
            "t = 4, avg_loss = 0.4651\n",
            "t = 5, avg_loss = 0.6201\n",
            "t = 6, avg_loss = 0.6535\n",
            "t = 7, avg_loss = 0.4679\n",
            "t = 8, avg_loss = 0.5494\n",
            "t = 9, avg_loss = 0.4955\n",
            "t = 10, avg_loss = 0.5599\n",
            "t = 11, avg_loss = 0.4662\n",
            "t = 12, avg_loss = 0.5840\n",
            "t = 13, avg_loss = 0.4557\n",
            "Checking accuracy on test set\n",
            "Got 149 / 200 correct (74.50)\n",
            "acc = 0.745000\n",
            "Starting epoch 33 / 80\n",
            "t = 1, avg_loss = 0.5633\n",
            "t = 2, avg_loss = 0.5028\n",
            "t = 3, avg_loss = 0.4389\n",
            "t = 4, avg_loss = 0.5237\n",
            "t = 5, avg_loss = 0.4781\n",
            "t = 6, avg_loss = 0.4948\n",
            "t = 7, avg_loss = 0.4125\n",
            "t = 8, avg_loss = 0.5367\n",
            "t = 9, avg_loss = 0.4897\n",
            "t = 10, avg_loss = 0.5697\n",
            "t = 11, avg_loss = 0.5332\n",
            "t = 12, avg_loss = 0.5673\n",
            "t = 13, avg_loss = 0.4424\n",
            "Checking accuracy on test set\n",
            "Got 153 / 200 correct (76.50)\n",
            "acc = 0.765000\n",
            "Starting epoch 34 / 80\n",
            "t = 1, avg_loss = 0.4411\n",
            "t = 2, avg_loss = 0.4545\n",
            "t = 3, avg_loss = 0.4705\n",
            "t = 4, avg_loss = 0.5654\n",
            "t = 5, avg_loss = 0.3869\n",
            "t = 6, avg_loss = 0.4137\n",
            "t = 7, avg_loss = 0.4365\n",
            "t = 8, avg_loss = 0.4956\n",
            "t = 9, avg_loss = 0.4744\n",
            "t = 10, avg_loss = 0.5904\n",
            "t = 11, avg_loss = 0.4698\n",
            "t = 12, avg_loss = 0.5591\n",
            "t = 13, avg_loss = 0.4740\n",
            "Checking accuracy on test set\n",
            "Got 155 / 200 correct (77.50)\n",
            "acc = 0.775000\n",
            "Starting epoch 35 / 80\n",
            "t = 1, avg_loss = 0.4004\n",
            "t = 2, avg_loss = 0.4930\n",
            "t = 3, avg_loss = 0.5511\n",
            "t = 4, avg_loss = 0.5238\n",
            "t = 5, avg_loss = 0.4910\n",
            "t = 6, avg_loss = 0.5602\n",
            "t = 7, avg_loss = 0.5511\n",
            "t = 8, avg_loss = 0.5658\n",
            "t = 9, avg_loss = 0.4371\n",
            "t = 10, avg_loss = 0.5080\n",
            "t = 11, avg_loss = 0.3981\n",
            "t = 12, avg_loss = 0.4340\n",
            "t = 13, avg_loss = 0.4372\n",
            "Checking accuracy on test set\n",
            "Got 155 / 200 correct (77.50)\n",
            "acc = 0.775000\n",
            "Starting epoch 36 / 80\n",
            "t = 1, avg_loss = 0.4815\n",
            "t = 2, avg_loss = 0.3711\n",
            "t = 3, avg_loss = 0.4890\n",
            "t = 4, avg_loss = 0.5427\n",
            "t = 5, avg_loss = 0.4908\n",
            "t = 6, avg_loss = 0.5391\n",
            "t = 7, avg_loss = 0.4345\n",
            "t = 8, avg_loss = 0.4202\n",
            "t = 9, avg_loss = 0.5044\n",
            "t = 10, avg_loss = 0.4743\n",
            "t = 11, avg_loss = 0.5664\n",
            "t = 12, avg_loss = 0.4390\n",
            "t = 13, avg_loss = 0.5830\n",
            "Checking accuracy on test set\n",
            "Got 145 / 200 correct (72.50)\n",
            "acc = 0.725000\n",
            "Starting epoch 37 / 80\n",
            "t = 1, avg_loss = 0.4780\n",
            "t = 2, avg_loss = 0.3679\n",
            "t = 3, avg_loss = 0.4256\n",
            "t = 4, avg_loss = 0.6179\n",
            "t = 5, avg_loss = 0.5421\n",
            "t = 6, avg_loss = 0.3851\n",
            "t = 7, avg_loss = 0.4936\n",
            "t = 8, avg_loss = 0.3963\n",
            "t = 9, avg_loss = 0.4923\n",
            "t = 10, avg_loss = 0.7792\n",
            "t = 11, avg_loss = 0.4098\n",
            "t = 12, avg_loss = 0.4687\n",
            "t = 13, avg_loss = 0.3816\n",
            "Checking accuracy on test set\n",
            "Got 156 / 200 correct (78.00)\n",
            "acc = 0.780000\n",
            "Starting epoch 38 / 80\n",
            "t = 1, avg_loss = 0.5313\n",
            "t = 2, avg_loss = 0.4689\n",
            "t = 3, avg_loss = 0.5107\n",
            "t = 4, avg_loss = 0.4544\n",
            "t = 5, avg_loss = 0.5747\n",
            "t = 6, avg_loss = 0.4882\n",
            "t = 7, avg_loss = 0.4416\n",
            "t = 8, avg_loss = 0.4346\n",
            "t = 9, avg_loss = 0.4818\n",
            "t = 10, avg_loss = 0.4990\n",
            "t = 11, avg_loss = 0.5753\n",
            "t = 12, avg_loss = 0.4841\n",
            "t = 13, avg_loss = 0.6114\n",
            "Checking accuracy on test set\n",
            "Got 149 / 200 correct (74.50)\n",
            "acc = 0.745000\n",
            "Starting epoch 39 / 80\n",
            "t = 1, avg_loss = 0.4005\n",
            "t = 2, avg_loss = 0.4322\n",
            "t = 3, avg_loss = 0.5288\n",
            "t = 4, avg_loss = 0.4882\n",
            "t = 5, avg_loss = 0.5466\n",
            "t = 6, avg_loss = 0.3896\n",
            "t = 7, avg_loss = 0.5980\n",
            "t = 8, avg_loss = 0.6660\n",
            "t = 9, avg_loss = 0.4918\n",
            "t = 10, avg_loss = 0.5876\n",
            "t = 11, avg_loss = 0.6128\n",
            "t = 12, avg_loss = 0.5574\n",
            "t = 13, avg_loss = 0.3592\n",
            "Checking accuracy on test set\n",
            "Got 145 / 200 correct (72.50)\n",
            "acc = 0.725000\n",
            "Starting epoch 40 / 80\n",
            "t = 1, avg_loss = 0.4918\n",
            "t = 2, avg_loss = 0.4538\n",
            "t = 3, avg_loss = 0.4395\n",
            "t = 4, avg_loss = 0.5478\n",
            "t = 5, avg_loss = 0.5054\n",
            "t = 6, avg_loss = 0.5202\n",
            "t = 7, avg_loss = 0.4464\n",
            "t = 8, avg_loss = 0.5567\n",
            "t = 9, avg_loss = 0.5090\n",
            "t = 10, avg_loss = 0.4524\n",
            "t = 11, avg_loss = 0.4209\n",
            "t = 12, avg_loss = 0.5620\n",
            "t = 13, avg_loss = 0.4557\n",
            "Checking accuracy on test set\n",
            "Got 159 / 200 correct (79.50)\n",
            "acc = 0.795000\n",
            "Starting epoch 41 / 80\n",
            "t = 1, avg_loss = 0.6592\n",
            "t = 2, avg_loss = 0.5646\n",
            "t = 3, avg_loss = 0.3648\n",
            "t = 4, avg_loss = 0.3739\n",
            "t = 5, avg_loss = 0.4921\n",
            "t = 6, avg_loss = 0.5651\n",
            "t = 7, avg_loss = 0.4946\n",
            "t = 8, avg_loss = 0.4243\n",
            "t = 9, avg_loss = 0.5117\n",
            "t = 10, avg_loss = 0.5077\n",
            "t = 11, avg_loss = 0.5261\n",
            "t = 12, avg_loss = 0.3509\n",
            "t = 13, avg_loss = 0.3822\n",
            "Checking accuracy on test set\n",
            "Got 153 / 200 correct (76.50)\n",
            "acc = 0.765000\n",
            "Starting epoch 42 / 80\n",
            "t = 1, avg_loss = 0.3499\n",
            "t = 2, avg_loss = 0.4546\n",
            "t = 3, avg_loss = 0.4829\n",
            "t = 4, avg_loss = 0.4256\n",
            "t = 5, avg_loss = 0.5846\n",
            "t = 6, avg_loss = 0.4792\n",
            "t = 7, avg_loss = 0.4286\n",
            "t = 8, avg_loss = 0.4761\n",
            "t = 9, avg_loss = 0.5277\n",
            "t = 10, avg_loss = 0.5422\n",
            "t = 11, avg_loss = 0.5766\n",
            "t = 12, avg_loss = 0.5051\n",
            "t = 13, avg_loss = 0.5047\n",
            "Checking accuracy on test set\n",
            "Got 139 / 200 correct (69.50)\n",
            "acc = 0.695000\n",
            "Starting epoch 43 / 80\n",
            "t = 1, avg_loss = 0.3933\n",
            "t = 2, avg_loss = 0.5403\n",
            "t = 3, avg_loss = 0.5416\n",
            "t = 4, avg_loss = 0.5119\n",
            "t = 5, avg_loss = 0.4174\n",
            "t = 6, avg_loss = 0.6169\n",
            "t = 7, avg_loss = 0.4693\n",
            "t = 8, avg_loss = 0.4839\n",
            "t = 9, avg_loss = 0.4477\n",
            "t = 10, avg_loss = 0.4913\n",
            "t = 11, avg_loss = 0.5663\n",
            "t = 12, avg_loss = 0.4767\n",
            "t = 13, avg_loss = 0.6305\n",
            "Checking accuracy on test set\n",
            "Got 157 / 200 correct (78.50)\n",
            "acc = 0.785000\n",
            "Starting epoch 44 / 80\n",
            "t = 1, avg_loss = 0.5137\n",
            "t = 2, avg_loss = 0.4039\n",
            "t = 3, avg_loss = 0.4288\n",
            "t = 4, avg_loss = 0.5814\n",
            "t = 5, avg_loss = 0.5336\n",
            "t = 6, avg_loss = 0.4187\n",
            "t = 7, avg_loss = 0.5183\n",
            "t = 8, avg_loss = 0.3742\n",
            "t = 9, avg_loss = 0.4837\n",
            "t = 10, avg_loss = 0.5540\n",
            "t = 11, avg_loss = 0.5556\n",
            "t = 12, avg_loss = 0.6007\n",
            "t = 13, avg_loss = 0.5444\n",
            "Checking accuracy on test set\n",
            "Got 137 / 200 correct (68.50)\n",
            "acc = 0.685000\n",
            "Starting epoch 45 / 80\n",
            "t = 1, avg_loss = 0.5148\n",
            "t = 2, avg_loss = 0.4843\n",
            "t = 3, avg_loss = 0.4578\n",
            "t = 4, avg_loss = 0.4357\n",
            "t = 5, avg_loss = 0.5314\n",
            "t = 6, avg_loss = 0.6152\n",
            "t = 7, avg_loss = 0.4610\n",
            "t = 8, avg_loss = 0.5310\n",
            "t = 9, avg_loss = 0.4804\n",
            "t = 10, avg_loss = 0.5301\n",
            "t = 11, avg_loss = 0.4394\n",
            "t = 12, avg_loss = 0.4847\n",
            "t = 13, avg_loss = 0.4698\n",
            "Checking accuracy on test set\n",
            "Got 136 / 200 correct (68.00)\n",
            "acc = 0.680000\n",
            "Starting epoch 46 / 80\n",
            "t = 1, avg_loss = 0.4462\n",
            "t = 2, avg_loss = 0.4502\n",
            "t = 3, avg_loss = 0.4290\n",
            "t = 4, avg_loss = 0.4254\n",
            "t = 5, avg_loss = 0.4567\n",
            "t = 6, avg_loss = 0.4114\n",
            "t = 7, avg_loss = 0.5377\n",
            "t = 8, avg_loss = 0.5739\n",
            "t = 9, avg_loss = 0.5194\n",
            "t = 10, avg_loss = 0.3870\n",
            "t = 11, avg_loss = 0.5432\n",
            "t = 12, avg_loss = 0.4637\n",
            "t = 13, avg_loss = 0.3416\n",
            "Checking accuracy on test set\n",
            "Got 151 / 200 correct (75.50)\n",
            "acc = 0.755000\n",
            "Starting epoch 47 / 80\n",
            "t = 1, avg_loss = 0.4176\n",
            "t = 2, avg_loss = 0.4623\n",
            "t = 3, avg_loss = 0.4268\n",
            "t = 4, avg_loss = 0.5213\n",
            "t = 5, avg_loss = 0.4499\n",
            "t = 6, avg_loss = 0.5218\n",
            "t = 7, avg_loss = 0.4729\n",
            "t = 8, avg_loss = 0.4896\n",
            "t = 9, avg_loss = 0.4668\n",
            "t = 10, avg_loss = 0.4901\n",
            "t = 11, avg_loss = 0.3593\n",
            "t = 12, avg_loss = 0.4975\n",
            "t = 13, avg_loss = 0.5152\n",
            "Checking accuracy on test set\n",
            "Got 159 / 200 correct (79.50)\n",
            "acc = 0.795000\n",
            "Starting epoch 48 / 80\n",
            "t = 1, avg_loss = 0.4762\n",
            "t = 2, avg_loss = 0.4970\n",
            "t = 3, avg_loss = 0.4870\n",
            "t = 4, avg_loss = 0.4450\n",
            "t = 5, avg_loss = 0.5659\n",
            "t = 6, avg_loss = 0.4433\n",
            "t = 7, avg_loss = 0.4497\n",
            "t = 8, avg_loss = 0.4582\n",
            "t = 9, avg_loss = 0.4802\n",
            "t = 10, avg_loss = 0.5686\n",
            "t = 11, avg_loss = 0.4108\n",
            "t = 12, avg_loss = 0.3930\n",
            "t = 13, avg_loss = 0.5031\n",
            "Checking accuracy on test set\n",
            "Got 151 / 200 correct (75.50)\n",
            "acc = 0.755000\n",
            "Starting epoch 49 / 80\n",
            "t = 1, avg_loss = 0.5171\n",
            "t = 2, avg_loss = 0.4337\n",
            "t = 3, avg_loss = 0.4872\n",
            "t = 4, avg_loss = 0.5273\n",
            "t = 5, avg_loss = 0.4539\n",
            "t = 6, avg_loss = 0.5023\n",
            "t = 7, avg_loss = 0.5257\n",
            "t = 8, avg_loss = 0.5159\n",
            "t = 9, avg_loss = 0.5171\n",
            "t = 10, avg_loss = 0.3521\n",
            "t = 11, avg_loss = 0.5256\n",
            "t = 12, avg_loss = 0.3091\n",
            "t = 13, avg_loss = 0.4120\n",
            "Checking accuracy on test set\n",
            "Got 146 / 200 correct (73.00)\n",
            "acc = 0.730000\n",
            "Starting epoch 50 / 80\n",
            "t = 1, avg_loss = 0.4461\n",
            "t = 2, avg_loss = 0.5089\n",
            "t = 3, avg_loss = 0.3697\n",
            "t = 4, avg_loss = 0.4443\n",
            "t = 5, avg_loss = 0.5423\n",
            "t = 6, avg_loss = 0.4953\n",
            "t = 7, avg_loss = 0.4876\n",
            "t = 8, avg_loss = 0.5157\n",
            "t = 9, avg_loss = 0.3636\n",
            "t = 10, avg_loss = 0.4901\n",
            "t = 11, avg_loss = 0.5664\n",
            "t = 12, avg_loss = 0.4709\n",
            "t = 13, avg_loss = 0.3686\n",
            "Checking accuracy on test set\n",
            "Got 138 / 200 correct (69.00)\n",
            "acc = 0.690000\n",
            "Starting epoch 51 / 80\n",
            "t = 1, avg_loss = 0.4453\n",
            "t = 2, avg_loss = 0.5263\n",
            "t = 3, avg_loss = 0.4900\n",
            "t = 4, avg_loss = 0.4713\n",
            "t = 5, avg_loss = 0.4457\n",
            "t = 6, avg_loss = 0.3877\n",
            "t = 7, avg_loss = 0.5133\n",
            "t = 8, avg_loss = 0.4396\n",
            "t = 9, avg_loss = 0.4703\n",
            "t = 10, avg_loss = 0.4929\n",
            "t = 11, avg_loss = 0.4451\n",
            "t = 12, avg_loss = 0.5346\n",
            "t = 13, avg_loss = 0.4749\n",
            "Checking accuracy on test set\n",
            "Got 149 / 200 correct (74.50)\n",
            "acc = 0.745000\n",
            "Starting epoch 52 / 80\n",
            "t = 1, avg_loss = 0.4849\n",
            "t = 2, avg_loss = 0.5370\n",
            "t = 3, avg_loss = 0.4951\n",
            "t = 4, avg_loss = 0.4553\n",
            "t = 5, avg_loss = 0.5544\n",
            "t = 6, avg_loss = 0.4759\n",
            "t = 7, avg_loss = 0.3707\n",
            "t = 8, avg_loss = 0.5332\n",
            "t = 9, avg_loss = 0.3521\n",
            "t = 10, avg_loss = 0.4576\n",
            "t = 11, avg_loss = 0.4338\n",
            "t = 12, avg_loss = 0.4155\n",
            "t = 13, avg_loss = 0.4761\n",
            "Checking accuracy on test set\n",
            "Got 146 / 200 correct (73.00)\n",
            "acc = 0.730000\n",
            "Starting epoch 53 / 80\n",
            "t = 1, avg_loss = 0.4423\n",
            "t = 2, avg_loss = 0.5005\n",
            "t = 3, avg_loss = 0.3703\n",
            "t = 4, avg_loss = 0.4557\n",
            "t = 5, avg_loss = 0.4385\n",
            "t = 6, avg_loss = 0.4106\n",
            "t = 7, avg_loss = 0.4176\n",
            "t = 8, avg_loss = 0.4584\n",
            "t = 9, avg_loss = 0.4555\n",
            "t = 10, avg_loss = 0.4550\n",
            "t = 11, avg_loss = 0.5054\n",
            "t = 12, avg_loss = 0.5026\n",
            "t = 13, avg_loss = 0.3662\n",
            "Checking accuracy on test set\n",
            "Got 150 / 200 correct (75.00)\n",
            "acc = 0.750000\n",
            "Starting epoch 54 / 80\n",
            "t = 1, avg_loss = 0.5291\n",
            "t = 2, avg_loss = 0.3816\n",
            "t = 3, avg_loss = 0.5052\n",
            "t = 4, avg_loss = 0.4579\n",
            "t = 5, avg_loss = 0.4970\n",
            "t = 6, avg_loss = 0.4584\n",
            "t = 7, avg_loss = 0.4141\n",
            "t = 8, avg_loss = 0.3768\n",
            "t = 9, avg_loss = 0.5202\n",
            "t = 10, avg_loss = 0.4255\n",
            "t = 11, avg_loss = 0.5293\n",
            "t = 12, avg_loss = 0.4066\n",
            "t = 13, avg_loss = 0.5539\n",
            "Checking accuracy on test set\n",
            "Got 154 / 200 correct (77.00)\n",
            "acc = 0.770000\n",
            "Starting epoch 55 / 80\n",
            "t = 1, avg_loss = 0.4397\n",
            "t = 2, avg_loss = 0.4601\n",
            "t = 3, avg_loss = 0.4754\n",
            "t = 4, avg_loss = 0.5373\n",
            "t = 5, avg_loss = 0.3916\n",
            "t = 6, avg_loss = 0.4858\n",
            "t = 7, avg_loss = 0.4741\n",
            "t = 8, avg_loss = 0.5934\n",
            "t = 9, avg_loss = 0.4640\n",
            "t = 10, avg_loss = 0.5958\n",
            "t = 11, avg_loss = 0.3985\n",
            "t = 12, avg_loss = 0.3406\n",
            "t = 13, avg_loss = 0.2782\n",
            "Checking accuracy on test set\n",
            "Got 135 / 200 correct (67.50)\n",
            "acc = 0.675000\n",
            "Starting epoch 56 / 80\n",
            "t = 1, avg_loss = 0.4007\n",
            "t = 2, avg_loss = 0.5276\n",
            "t = 3, avg_loss = 0.3693\n",
            "t = 4, avg_loss = 0.3908\n",
            "t = 5, avg_loss = 0.5048\n",
            "t = 6, avg_loss = 0.5708\n",
            "t = 7, avg_loss = 0.4824\n",
            "t = 8, avg_loss = 0.4028\n",
            "t = 9, avg_loss = 0.4625\n",
            "t = 10, avg_loss = 0.4263\n",
            "t = 11, avg_loss = 0.4194\n",
            "t = 12, avg_loss = 0.3893\n",
            "t = 13, avg_loss = 0.4493\n",
            "Checking accuracy on test set\n",
            "Got 143 / 200 correct (71.50)\n",
            "acc = 0.715000\n",
            "Starting epoch 57 / 80\n",
            "t = 1, avg_loss = 0.4795\n",
            "t = 2, avg_loss = 0.4743\n",
            "t = 3, avg_loss = 0.5116\n",
            "t = 4, avg_loss = 0.4282\n",
            "t = 5, avg_loss = 0.5243\n",
            "t = 6, avg_loss = 0.3451\n",
            "t = 7, avg_loss = 0.3648\n",
            "t = 8, avg_loss = 0.4654\n",
            "t = 9, avg_loss = 0.3931\n",
            "t = 10, avg_loss = 0.4090\n",
            "t = 11, avg_loss = 0.5184\n",
            "t = 12, avg_loss = 0.5854\n",
            "t = 13, avg_loss = 0.6080\n",
            "Checking accuracy on test set\n",
            "Got 152 / 200 correct (76.00)\n",
            "acc = 0.760000\n",
            "Starting epoch 58 / 80\n",
            "t = 1, avg_loss = 0.4536\n",
            "t = 2, avg_loss = 0.4100\n",
            "t = 3, avg_loss = 0.5898\n",
            "t = 4, avg_loss = 0.4963\n",
            "t = 5, avg_loss = 0.5809\n",
            "t = 6, avg_loss = 0.4848\n",
            "t = 7, avg_loss = 0.3777\n",
            "t = 8, avg_loss = 0.3976\n",
            "t = 9, avg_loss = 0.5248\n",
            "t = 10, avg_loss = 0.5188\n",
            "t = 11, avg_loss = 0.4981\n",
            "t = 12, avg_loss = 0.4666\n",
            "t = 13, avg_loss = 0.4561\n",
            "Checking accuracy on test set\n",
            "Got 158 / 200 correct (79.00)\n",
            "acc = 0.790000\n",
            "Starting epoch 59 / 80\n",
            "t = 1, avg_loss = 0.5247\n",
            "t = 2, avg_loss = 0.4265\n",
            "t = 3, avg_loss = 0.4290\n",
            "t = 4, avg_loss = 0.3920\n",
            "t = 5, avg_loss = 0.4225\n",
            "t = 6, avg_loss = 0.4224\n",
            "t = 7, avg_loss = 0.4691\n",
            "t = 8, avg_loss = 0.4289\n",
            "t = 9, avg_loss = 0.4998\n",
            "t = 10, avg_loss = 0.4405\n",
            "t = 11, avg_loss = 0.4856\n",
            "t = 12, avg_loss = 0.4222\n",
            "t = 13, avg_loss = 0.4984\n",
            "Checking accuracy on test set\n",
            "Got 158 / 200 correct (79.00)\n",
            "acc = 0.790000\n",
            "Starting epoch 60 / 80\n",
            "t = 1, avg_loss = 0.3719\n",
            "t = 2, avg_loss = 0.6051\n",
            "t = 3, avg_loss = 0.3552\n",
            "t = 4, avg_loss = 0.4630\n",
            "t = 5, avg_loss = 0.4569\n",
            "t = 6, avg_loss = 0.5183\n",
            "t = 7, avg_loss = 0.5785\n",
            "t = 8, avg_loss = 0.4863\n",
            "t = 9, avg_loss = 0.4238\n",
            "t = 10, avg_loss = 0.4831\n",
            "t = 11, avg_loss = 0.4104\n",
            "t = 12, avg_loss = 0.4692\n",
            "t = 13, avg_loss = 0.5611\n",
            "Checking accuracy on test set\n",
            "Got 151 / 200 correct (75.50)\n",
            "acc = 0.755000\n",
            "Starting epoch 61 / 80\n",
            "t = 1, avg_loss = 0.5374\n",
            "t = 2, avg_loss = 0.4565\n",
            "t = 3, avg_loss = 0.3862\n",
            "t = 4, avg_loss = 0.5040\n",
            "t = 5, avg_loss = 0.4021\n",
            "t = 6, avg_loss = 0.5606\n",
            "t = 7, avg_loss = 0.3654\n",
            "t = 8, avg_loss = 0.4746\n",
            "t = 9, avg_loss = 0.4586\n",
            "t = 10, avg_loss = 0.4041\n",
            "t = 11, avg_loss = 0.4359\n",
            "t = 12, avg_loss = 0.4889\n",
            "t = 13, avg_loss = 0.4681\n",
            "Checking accuracy on test set\n",
            "Got 149 / 200 correct (74.50)\n",
            "acc = 0.745000\n",
            "Starting epoch 62 / 80\n",
            "t = 1, avg_loss = 0.5432\n",
            "t = 2, avg_loss = 0.4260\n",
            "t = 3, avg_loss = 0.3985\n",
            "t = 4, avg_loss = 0.4367\n",
            "t = 5, avg_loss = 0.4516\n",
            "t = 6, avg_loss = 0.4186\n",
            "t = 7, avg_loss = 0.4656\n",
            "t = 8, avg_loss = 0.3318\n",
            "t = 9, avg_loss = 0.5613\n",
            "t = 10, avg_loss = 0.4475\n",
            "t = 11, avg_loss = 0.5939\n",
            "t = 12, avg_loss = 0.4417\n",
            "t = 13, avg_loss = 0.4951\n",
            "Checking accuracy on test set\n",
            "Got 143 / 200 correct (71.50)\n",
            "acc = 0.715000\n",
            "Starting epoch 63 / 80\n",
            "t = 1, avg_loss = 0.4591\n",
            "t = 2, avg_loss = 0.4336\n",
            "t = 3, avg_loss = 0.4670\n",
            "t = 4, avg_loss = 0.4032\n",
            "t = 5, avg_loss = 0.5129\n",
            "t = 6, avg_loss = 0.3966\n",
            "t = 7, avg_loss = 0.4924\n",
            "t = 8, avg_loss = 0.5412\n",
            "t = 9, avg_loss = 0.4994\n",
            "t = 10, avg_loss = 0.4715\n",
            "t = 11, avg_loss = 0.4362\n",
            "t = 12, avg_loss = 0.4109\n",
            "t = 13, avg_loss = 0.3836\n",
            "Checking accuracy on test set\n",
            "Got 148 / 200 correct (74.00)\n",
            "acc = 0.740000\n",
            "Starting epoch 64 / 80\n",
            "t = 1, avg_loss = 0.3766\n",
            "t = 2, avg_loss = 0.4605\n",
            "t = 3, avg_loss = 0.4109\n",
            "t = 4, avg_loss = 0.3994\n",
            "t = 5, avg_loss = 0.4151\n",
            "t = 6, avg_loss = 0.3440\n",
            "t = 7, avg_loss = 0.5058\n",
            "t = 8, avg_loss = 0.5664\n",
            "t = 9, avg_loss = 0.5520\n",
            "t = 10, avg_loss = 0.4514\n",
            "t = 11, avg_loss = 0.4339\n",
            "t = 12, avg_loss = 0.4818\n",
            "t = 13, avg_loss = 0.4298\n",
            "Checking accuracy on test set\n",
            "Got 141 / 200 correct (70.50)\n",
            "acc = 0.705000\n",
            "Starting epoch 65 / 80\n",
            "t = 1, avg_loss = 0.3435\n",
            "t = 2, avg_loss = 0.4353\n",
            "t = 3, avg_loss = 0.3717\n",
            "t = 4, avg_loss = 0.5369\n",
            "t = 5, avg_loss = 0.3183\n",
            "t = 6, avg_loss = 0.4223\n",
            "t = 7, avg_loss = 0.3282\n",
            "t = 8, avg_loss = 0.5859\n",
            "t = 9, avg_loss = 0.6186\n",
            "t = 10, avg_loss = 0.4969\n",
            "t = 11, avg_loss = 0.5744\n",
            "t = 12, avg_loss = 0.4948\n",
            "t = 13, avg_loss = 0.4784\n",
            "Checking accuracy on test set\n",
            "Got 158 / 200 correct (79.00)\n",
            "acc = 0.790000\n",
            "Starting epoch 66 / 80\n",
            "t = 1, avg_loss = 0.3561\n",
            "t = 2, avg_loss = 0.3725\n",
            "t = 3, avg_loss = 0.4204\n",
            "t = 4, avg_loss = 0.3627\n",
            "t = 5, avg_loss = 0.5062\n",
            "t = 6, avg_loss = 0.6551\n",
            "t = 7, avg_loss = 0.4265\n",
            "t = 8, avg_loss = 0.5229\n",
            "t = 9, avg_loss = 0.5508\n",
            "t = 10, avg_loss = 0.5529\n",
            "t = 11, avg_loss = 0.3926\n",
            "t = 12, avg_loss = 0.4889\n",
            "t = 13, avg_loss = 0.4175\n",
            "Checking accuracy on test set\n",
            "Got 145 / 200 correct (72.50)\n",
            "acc = 0.725000\n",
            "Starting epoch 67 / 80\n",
            "t = 1, avg_loss = 0.3454\n",
            "t = 2, avg_loss = 0.4169\n",
            "t = 3, avg_loss = 0.5343\n",
            "t = 4, avg_loss = 0.4237\n",
            "t = 5, avg_loss = 0.4465\n",
            "t = 6, avg_loss = 0.5751\n",
            "t = 7, avg_loss = 0.4962\n",
            "t = 8, avg_loss = 0.4567\n",
            "t = 9, avg_loss = 0.4432\n",
            "t = 10, avg_loss = 0.3630\n",
            "t = 11, avg_loss = 0.3408\n",
            "t = 12, avg_loss = 0.4176\n",
            "t = 13, avg_loss = 0.3968\n",
            "Checking accuracy on test set\n",
            "Got 147 / 200 correct (73.50)\n",
            "acc = 0.735000\n",
            "Starting epoch 68 / 80\n",
            "t = 1, avg_loss = 0.6244\n",
            "t = 2, avg_loss = 0.4623\n",
            "t = 3, avg_loss = 0.3851\n",
            "t = 4, avg_loss = 0.4236\n",
            "t = 5, avg_loss = 0.4190\n",
            "t = 6, avg_loss = 0.4652\n",
            "t = 7, avg_loss = 0.5100\n",
            "t = 8, avg_loss = 0.4474\n",
            "t = 9, avg_loss = 0.3783\n",
            "t = 10, avg_loss = 0.3768\n",
            "t = 11, avg_loss = 0.4802\n",
            "t = 12, avg_loss = 0.5495\n",
            "t = 13, avg_loss = 0.3814\n",
            "Checking accuracy on test set\n",
            "Got 151 / 200 correct (75.50)\n",
            "acc = 0.755000\n",
            "Starting epoch 69 / 80\n",
            "t = 1, avg_loss = 0.5929\n",
            "t = 2, avg_loss = 0.3768\n",
            "t = 3, avg_loss = 0.4381\n",
            "t = 4, avg_loss = 0.4854\n",
            "t = 5, avg_loss = 0.4356\n",
            "t = 6, avg_loss = 0.3362\n",
            "t = 7, avg_loss = 0.4125\n",
            "t = 8, avg_loss = 0.4760\n",
            "t = 9, avg_loss = 0.3888\n",
            "t = 10, avg_loss = 0.4008\n",
            "t = 11, avg_loss = 0.5687\n",
            "t = 12, avg_loss = 0.3967\n",
            "t = 13, avg_loss = 0.3488\n",
            "Checking accuracy on test set\n",
            "Got 150 / 200 correct (75.00)\n",
            "acc = 0.750000\n",
            "Starting epoch 70 / 80\n",
            "t = 1, avg_loss = 0.5567\n",
            "t = 2, avg_loss = 0.5089\n",
            "t = 3, avg_loss = 0.4751\n",
            "t = 4, avg_loss = 0.3141\n",
            "t = 5, avg_loss = 0.5707\n",
            "t = 6, avg_loss = 0.3855\n",
            "t = 7, avg_loss = 0.5377\n",
            "t = 8, avg_loss = 0.3973\n",
            "t = 9, avg_loss = 0.3260\n",
            "t = 10, avg_loss = 0.4003\n",
            "t = 11, avg_loss = 0.5176\n",
            "t = 12, avg_loss = 0.4762\n",
            "t = 13, avg_loss = 0.3137\n",
            "Checking accuracy on test set\n",
            "Got 138 / 200 correct (69.00)\n",
            "acc = 0.690000\n",
            "Starting epoch 71 / 80\n",
            "t = 1, avg_loss = 0.4731\n",
            "t = 2, avg_loss = 0.3712\n",
            "t = 3, avg_loss = 0.3941\n",
            "t = 4, avg_loss = 0.4527\n",
            "t = 5, avg_loss = 0.4086\n",
            "t = 6, avg_loss = 0.3805\n",
            "t = 7, avg_loss = 0.4300\n",
            "t = 8, avg_loss = 0.4423\n",
            "t = 9, avg_loss = 0.4687\n",
            "t = 10, avg_loss = 0.3561\n",
            "t = 11, avg_loss = 0.4374\n",
            "t = 12, avg_loss = 0.3710\n",
            "t = 13, avg_loss = 0.5121\n",
            "Checking accuracy on test set\n",
            "Got 150 / 200 correct (75.00)\n",
            "acc = 0.750000\n",
            "Starting epoch 72 / 80\n",
            "t = 1, avg_loss = 0.5452\n",
            "t = 2, avg_loss = 0.4320\n",
            "t = 3, avg_loss = 0.4180\n",
            "t = 4, avg_loss = 0.3150\n",
            "t = 5, avg_loss = 0.4286\n",
            "t = 6, avg_loss = 0.4365\n",
            "t = 7, avg_loss = 0.4988\n",
            "t = 8, avg_loss = 0.4431\n",
            "t = 9, avg_loss = 0.2891\n",
            "t = 10, avg_loss = 0.6132\n",
            "t = 11, avg_loss = 0.3438\n",
            "t = 12, avg_loss = 0.5124\n",
            "t = 13, avg_loss = 0.4924\n",
            "Checking accuracy on test set\n",
            "Got 151 / 200 correct (75.50)\n",
            "acc = 0.755000\n",
            "Starting epoch 73 / 80\n",
            "t = 1, avg_loss = 0.3967\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-7b8c17403705>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_gpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0mcheck_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-7b7c48cb9b8f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, loss_fn, optimizer, num_epochs, starting_from_epoch)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mx_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0my_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-50a9cd504daf>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m           \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"malignant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"malignant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \"\"\"\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   1856\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1858\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreducing_gap\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresample\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mNEAREST\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nr2sQUvYlXYm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "19bf081e-ff2d-44ab-b0e1-b150a64d9dd2"
      },
      "source": [
        "check_accuracy(model_gpu, valid_loader)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking accuracy on test set\n",
            "Got 151 / 200 correct (75.50)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.755"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzuX5gLEeJfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def retry_from_backup()\n",
        "  model_gpu = model_base.type(gpu_dtype)\n",
        "  print(model_gpu)\n",
        "  loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) \n",
        "\n",
        "\n",
        "\n",
        "  checkpoint = torch.load(model_backup_path)\n",
        "  model_gpu.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  epoch = checkpoint['epoch']\n",
        "  loss = checkpoint['loss']\n",
        "  print(\"starting from epoch: \" + str(epoch))\n",
        "  print(\"starting from loss: \" + str(loss))\n",
        "  print(checkpoint['model_state_dict'])\n",
        "  print(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "  train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs, starting_from_epoch=epoch)\n",
        "  check_accuracy(model_gpu, valid_loader)\n",
        "#retry_from_backup()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDn-2g-TLY3k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "c68613ea-5f88-4ad4-e862-7a8be6b33676"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot([print_every*batch_size*(i+1) for i in range((len(avg_loss_list)))],avg_loss_list)\n",
        "print(\"Loss:\")\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGer6hJv7-zR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "f1a68d7f-69f4-4ac5-e9c9-80a681829dd4"
      },
      "source": [
        "plt.plot([i+1 for i in range((len(acc_list)))],acc_list)\n",
        "print(\"Accurancy:\")\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accurancy:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBTReWHxz4Ml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}