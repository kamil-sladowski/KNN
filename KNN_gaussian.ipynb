{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN_ascending_layers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamilo116/KNN/blob/master/KNN_gaussian.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7ReM7FU-xs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import sys\n",
        "from random import shuffle\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms as transforms\n",
        "import timeit\n",
        "\n",
        "np.random.seed(4) \n",
        "torch.manual_seed(4) \n",
        "torch.cuda.manual_seed(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYIMZ8QyYewD",
        "colab_type": "code",
        "outputId": "934f7dba-893b-4b7e-8047-41c975a450c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "! git clone https://github.com/wang-chen/kervolution.git \n",
        "\n",
        "sys.path.append(\"kervolution/\")\n",
        "from kervolution import Kerv2d\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'kervolution'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 53 (delta 2), reused 0 (delta 0), pack-reused 47\u001b[K\n",
            "Unpacking objects: 100% (53/53), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvbKg4VJXKY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LIMIT_IMAGES_NUM = 1000\n",
        "train_test_split_size = 0.2\n",
        "image_resize = (100, 100)\n",
        "batch_size = 64\n",
        "num_workers = 0\n",
        "\n",
        "out_1 = 16\n",
        "out_2 = 32\n",
        "out_3 = 64\n",
        "\n",
        "\n",
        "\n",
        "k_size_1 = 3\n",
        "padding_1 = 1\n",
        "in_channels = 3\n",
        "\n",
        "kernel_size = 3\n",
        "num_epochs = 80\n",
        "\n",
        "learning_rate = 0.0001\n",
        "weight_decay = 0.2\n",
        "\n",
        "MALIGNANT_DATASET = '/content/drive/My Drive/Colab_data/malignant/malignant/'\n",
        "BENIGN_DATASET = '/content/drive/My Drive/Colab_data/benign/benign/'\n",
        "DATA_FOLDER = '/content/drive/My Drive/Colab_data/'\n",
        "model_backup_path = os.path.join(DATA_FOLDER, 'backup_model2') \n",
        "TRAIN_DATA_PER_CATEGORY = 101"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbMvvuct1lUT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMOHez_kHZD6",
        "colab_type": "code",
        "outputId": "8e8bb3d4-9668-4ff7-cef4-c1fca06a5c6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b8P1NdXfVdX",
        "colab_type": "code",
        "outputId": "b19d1e42-4eba-4f27-bc7b-afd8164e4fe7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "benign_train_list = sorted(os.listdir(BENIGN_DATASET))[:LIMIT_IMAGES_NUM]\n",
        "malignant_train_list = sorted(os.listdir(MALIGNANT_DATASET))[:LIMIT_IMAGES_NUM]\n",
        "\n",
        "shuffle(benign_train_list)\n",
        "shuffle(malignant_train_list)\n",
        "\n",
        "test_benign_file_list = os.listdir(BENIGN_DATASET + 'test_set')[:TRAIN_DATA_PER_CATEGORY]\n",
        "test_malignant_file_list = os.listdir(MALIGNANT_DATASET + 'test_set')[:TRAIN_DATA_PER_CATEGORY]\n",
        "shuffle(test_benign_file_list)\n",
        "shuffle(test_malignant_file_list)\n",
        "print(f\"Number of training benign {len(benign_train_list)} images\")\n",
        "print(f\"Number of training malignant {len(malignant_train_list)} images\")\n",
        "print(f\"Number of test benign {len(test_benign_file_list)} images\")\n",
        "print(f\"Number of test malignant {len(test_malignant_file_list)} images\")\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize(image_resize),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    #transforms.RandomRotation(45),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "data_transforms_test = transforms.Compose([\n",
        "    transforms.Resize(image_resize),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training benign 1000 images\n",
            "Number of training malignant 1000 images\n",
            "Number of test benign 101 images\n",
            "Number of test malignant 101 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvAAOqmVfVll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IsicDataset(Dataset):\n",
        "    def __init__(self, data_folder, labeled_data, \n",
        "                 transform=transforms.Compose([transforms.ToTensor()]), datatype='train'):\n",
        "        self.labeled_data = labeled_data\n",
        "        self.transform = transform\n",
        "        self.data_folder = data_folder\n",
        "        self.datatype = datatype\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labeled_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        label = self.labeled_data[index]\n",
        "        test_set = ''\n",
        "        if self.datatype == 'test':\n",
        "          test_set = 'test_set' \n",
        "        if label == 0:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"benign\", \"benign\", test_set, index ))\n",
        "        else:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"malignant\", \"malignant\", test_set, index ))\n",
        "        image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "    @property\n",
        "    def labels(self):\n",
        "      return self.labeled_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e8nFBR6Yug5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "def prepare_dataset(benign_file_list, malignant_file_list, transform, datatype='train'):\n",
        "  benign_dict = {filename: 0 for filename in benign_file_list}\n",
        "  malignant_dict = {filename: 1 for filename in malignant_file_list}\n",
        "  img_class_dict = {**benign_dict , **malignant_dict}\n",
        "  labeled_data = pd.Series(img_class_dict)\n",
        "\n",
        "  dataset = IsicDataset(DATA_FOLDER, labeled_data, transform=transform, datatype=datatype)\n",
        "  print(dataset.labels)\n",
        "  return dataset\n",
        "\n",
        "def train(model, train_loader ,loss_fn, optimizer, num_epochs=1, starting_from_epoch=1):\n",
        "    total_loss =0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
        "        model.train()\n",
        "\n",
        "        for t, (x, y) in enumerate(train_loader):\n",
        "            x_var = Variable(x.type(gpu_dtype))\n",
        "            y_var = Variable(y.type(gpu_dtype).long())\n",
        "            scores = model(x_var)\n",
        "            loss = loss_fn(scores, y_var)\n",
        "            total_loss += loss.data\n",
        "            \n",
        "            if (t + 1) % print_every == 0:\n",
        "                avg_loss = total_loss/print_every\n",
        "                print('t = %d, avg_loss = %.4f' % (t + 1, avg_loss) )\n",
        "                avg_loss_list.append(avg_loss)\n",
        "                total_loss = 0\n",
        "                \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        acc = check_accuracy(model_gpu, valid_loader)\n",
        "        print('acc = %f' %(acc))\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model_gpu.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            'acc_list': acc_list,\n",
        "            }, model_backup_path)\n",
        "            \n",
        "def check_accuracy(model, loader, datatype='train'):\n",
        "    print(f'Checking accuracy on {datatype} set')   \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval() \n",
        "    for x, y in loader:\n",
        "        x_var = Variable(x.type(gpu_dtype))\n",
        "\n",
        "        scores = model(x_var)\n",
        "        _, preds = scores.data.cpu().max(1)\n",
        "        num_correct += (preds == y).sum()\n",
        "        num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    if datatype is 'train':\n",
        "      acc_list.append(acc)\n",
        "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "    return acc\n",
        "    \n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.size()\n",
        "        return x.view(N, -1)  \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSuYqjLAYrWA",
        "colab_type": "code",
        "outputId": "f5261fde-fbc6-4371-8441-711f921a7b10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "train_dataset = prepare_dataset(benign_train_list, malignant_train_list, data_transforms)\n",
        "\n",
        "X_train, X_valid = train_test_split(train_dataset.labels, test_size=train_test_split_size)\n",
        "\n",
        "print(\"number of training data: \",len(X_train))\n",
        "print(\"number of valid  data: \",len(X_valid))\n",
        "\n",
        "train_sampler = SubsetRandomSampler(list(X_train.index))\n",
        "valid_sampler = SubsetRandomSampler(list(X_valid.index))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ISIC_0000496.jpeg    0\n",
            "ISIC_0001026.jpeg    0\n",
            "ISIC_0002904.jpeg    0\n",
            "ISIC_0001833.jpeg    0\n",
            "ISIC_0001397.jpeg    0\n",
            "                    ..\n",
            "ISIC_0010792.jpeg    1\n",
            "ISIC_0010174.jpeg    1\n",
            "ISIC_0013316.jpeg    1\n",
            "ISIC_0015166.jpeg    1\n",
            "ISIC_0013652.jpeg    1\n",
            "Length: 2000, dtype: int64\n",
            "number of training data:  1600\n",
            "number of valid  data:  400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vjEOfNZUB7W",
        "colab_type": "code",
        "outputId": "acc97828-7b27-461a-df1e-b5d460ef47aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "test_dataset = prepare_dataset(test_benign_file_list, test_malignant_file_list, data_transforms_test, datatype='test')\n",
        "test_part, _ = train_test_split(test_dataset.labels, test_size=1)\n",
        "test_sampler = SubsetRandomSampler(list(test_part.index))\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=50, sampler=test_sampler, num_workers=num_workers)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ISIC_0002800.jpeg    0\n",
            "ISIC_0000763.jpeg    0\n",
            "ISIC_0001338.jpeg    0\n",
            "ISIC_0001480.jpeg    0\n",
            "ISIC_0000747.jpeg    0\n",
            "                    ..\n",
            "ISIC_0000156.jpeg    1\n",
            "ISIC_0015124.jpeg    1\n",
            "ISIC_0011780.jpeg    1\n",
            "ISIC_0014735.jpeg    1\n",
            "ISIC_0001142.jpeg    1\n",
            "Length: 202, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-gYHw0Jlbwt",
        "colab_type": "code",
        "outputId": "423c0f9e-6109-44c9-e37c-e0e469507c88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "source": [
        "print_every = 5\n",
        "gpu_dtype = torch.cuda.FloatTensor\n",
        "\n",
        "\n",
        "'''\n",
        "Kerv2d\n",
        "kervolution with following options:\n",
        "kernel_type: [linear, polynomial, gaussian, etc.]\n",
        "default is convolution:\n",
        "          kernel_type --> linear,\n",
        "balance, power, gamma is valid only when the kernel_type is specified\n",
        "if learnable_kernel = True,  they just be the initial value of learable parameters\n",
        "if learnable_kernel = False, they are the value of kernel_type's parameter\n",
        "the parameter [power] cannot be learned due to integer limitation\n",
        "dilation (int or tuple, optional): Spacing between kernel\n",
        "elements. Default: 1\n",
        "groups (int, optional): Number of blocked connections from input\n",
        "channels to output channels. Default: 1\n",
        "bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n",
        "kernel_type (str), Default: 'linear'\n",
        "learnable_kernel (bool): Learnable kernel parameters.  Default: False \n",
        "balance: 0, 1\n",
        "power: 3, 4, 5\n",
        "gamma:\n",
        "'''\n",
        "\n",
        "model_base = nn.Sequential( \n",
        "                #nn.Conv2d(in_channels , out_1, padding= padding_1, kernel_size=k_size_1, stride=1),\n",
        "                nn.Kerv2d(in_channels , out_1, padding=padding_1, bias=True, \n",
        "                          kernel_type='gaussian', kernel_size=3, learnable_kernel=True,\n",
        "                          kernel_regularizer=True, stride=1, gamma=0.75\n",
        "                          ), \n",
        "                #nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_1),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_1 , out_2, padding= padding_1, kernel_size=3, stride=1), \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_2),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_2 , out_3, padding= padding_1, kernel_size=3, stride=1),  \n",
        "                \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_3),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "               \n",
        "                nn.Dropout(0.5),\n",
        "                Flatten(),\n",
        "                nn.Linear(9216,64),\n",
        "\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Linear(64,2)\n",
        "            )\n",
        "model_gpu = model_base.type(gpu_dtype)\n",
        "print(model_gpu)\n",
        "loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Kerv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (4): ReLU(inplace=True)\n",
            "  (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (7): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (8): ReLU(inplace=True)\n",
            "  (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (11): Dropout(p=0.5, inplace=False)\n",
            "  (12): Flatten()\n",
            "  (13): Linear(in_features=9216, out_features=64, bias=True)\n",
            "  (14): ReLU(inplace=True)\n",
            "  (15): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgmexhBRZAK6",
        "colab_type": "code",
        "outputId": "aac4663f-f20e-471b-8fb0-5eef2c033ee2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 1 / 80\n",
            "t = 5, avg_loss = 0.6352\n",
            "t = 10, avg_loss = 0.6077\n",
            "t = 15, avg_loss = 0.6293\n",
            "t = 20, avg_loss = 0.5191\n",
            "t = 25, avg_loss = 0.5535\n",
            "Checking accuracy on train set\n",
            "Got 217 / 400 correct (54.25)\n",
            "acc = 0.542500\n",
            "Starting epoch 2 / 80\n",
            "t = 5, avg_loss = 0.5032\n",
            "t = 10, avg_loss = 0.5018\n",
            "t = 15, avg_loss = 0.4877\n",
            "t = 20, avg_loss = 0.5174\n",
            "t = 25, avg_loss = 0.5104\n",
            "Checking accuracy on train set\n",
            "Got 310 / 400 correct (77.50)\n",
            "acc = 0.775000\n",
            "Starting epoch 3 / 80\n",
            "t = 5, avg_loss = 0.4712\n",
            "t = 10, avg_loss = 0.4187\n",
            "t = 15, avg_loss = 0.4741\n",
            "t = 20, avg_loss = 0.5230\n",
            "t = 25, avg_loss = 0.5231\n",
            "Checking accuracy on train set\n",
            "Got 314 / 400 correct (78.50)\n",
            "acc = 0.785000\n",
            "Starting epoch 4 / 80\n",
            "t = 5, avg_loss = 0.4636\n",
            "t = 10, avg_loss = 0.4616\n",
            "t = 15, avg_loss = 0.4468\n",
            "t = 20, avg_loss = 0.4348\n",
            "t = 25, avg_loss = 0.4921\n",
            "Checking accuracy on train set\n",
            "Got 325 / 400 correct (81.25)\n",
            "acc = 0.812500\n",
            "Starting epoch 5 / 80\n",
            "t = 5, avg_loss = 0.4457\n",
            "t = 10, avg_loss = 0.4402\n",
            "t = 15, avg_loss = 0.4759\n",
            "t = 20, avg_loss = 0.4586\n",
            "t = 25, avg_loss = 0.4457\n",
            "Checking accuracy on train set\n",
            "Got 324 / 400 correct (81.00)\n",
            "acc = 0.810000\n",
            "Starting epoch 6 / 80\n",
            "t = 5, avg_loss = 0.4239\n",
            "t = 10, avg_loss = 0.4686\n",
            "t = 15, avg_loss = 0.4281\n",
            "t = 20, avg_loss = 0.4302\n",
            "t = 25, avg_loss = 0.3825\n",
            "Checking accuracy on train set\n",
            "Got 326 / 400 correct (81.50)\n",
            "acc = 0.815000\n",
            "Starting epoch 7 / 80\n",
            "t = 5, avg_loss = 0.3972\n",
            "t = 10, avg_loss = 0.4191\n",
            "t = 15, avg_loss = 0.3948\n",
            "t = 20, avg_loss = 0.4205\n",
            "t = 25, avg_loss = 0.3841\n",
            "Checking accuracy on train set\n",
            "Got 313 / 400 correct (78.25)\n",
            "acc = 0.782500\n",
            "Starting epoch 8 / 80\n",
            "t = 5, avg_loss = 0.3946\n",
            "t = 10, avg_loss = 0.3912\n",
            "t = 15, avg_loss = 0.3638\n",
            "t = 20, avg_loss = 0.4339\n",
            "t = 25, avg_loss = 0.4049\n",
            "Checking accuracy on train set\n",
            "Got 324 / 400 correct (81.00)\n",
            "acc = 0.810000\n",
            "Starting epoch 9 / 80\n",
            "t = 5, avg_loss = 0.3694\n",
            "t = 10, avg_loss = 0.3909\n",
            "t = 15, avg_loss = 0.4134\n",
            "t = 20, avg_loss = 0.4374\n",
            "t = 25, avg_loss = 0.3845\n",
            "Checking accuracy on train set\n",
            "Got 331 / 400 correct (82.75)\n",
            "acc = 0.827500\n",
            "Starting epoch 10 / 80\n",
            "t = 5, avg_loss = 0.3755\n",
            "t = 10, avg_loss = 0.3580\n",
            "t = 15, avg_loss = 0.4537\n",
            "t = 20, avg_loss = 0.4175\n",
            "t = 25, avg_loss = 0.3678\n",
            "Checking accuracy on train set\n",
            "Got 327 / 400 correct (81.75)\n",
            "acc = 0.817500\n",
            "Starting epoch 11 / 80\n",
            "t = 5, avg_loss = 0.3774\n",
            "t = 10, avg_loss = 0.3549\n",
            "t = 15, avg_loss = 0.3653\n",
            "t = 20, avg_loss = 0.3627\n",
            "t = 25, avg_loss = 0.4074\n",
            "Checking accuracy on train set\n",
            "Got 336 / 400 correct (84.00)\n",
            "acc = 0.840000\n",
            "Starting epoch 12 / 80\n",
            "t = 5, avg_loss = 0.3971\n",
            "t = 10, avg_loss = 0.3506\n",
            "t = 15, avg_loss = 0.3699\n",
            "t = 20, avg_loss = 0.3698\n",
            "t = 25, avg_loss = 0.3421\n",
            "Checking accuracy on train set\n",
            "Got 337 / 400 correct (84.25)\n",
            "acc = 0.842500\n",
            "Starting epoch 13 / 80\n",
            "t = 5, avg_loss = 0.3483\n",
            "t = 10, avg_loss = 0.3367\n",
            "t = 15, avg_loss = 0.4007\n",
            "t = 20, avg_loss = 0.3802\n",
            "t = 25, avg_loss = 0.3674\n",
            "Checking accuracy on train set\n",
            "Got 320 / 400 correct (80.00)\n",
            "acc = 0.800000\n",
            "Starting epoch 14 / 80\n",
            "t = 5, avg_loss = 0.3868\n",
            "t = 10, avg_loss = 0.3447\n",
            "t = 15, avg_loss = 0.3613\n",
            "t = 20, avg_loss = 0.3948\n",
            "t = 25, avg_loss = 0.3827\n",
            "Checking accuracy on train set\n",
            "Got 341 / 400 correct (85.25)\n",
            "acc = 0.852500\n",
            "Starting epoch 15 / 80\n",
            "t = 5, avg_loss = 0.3660\n",
            "t = 10, avg_loss = 0.3390\n",
            "t = 15, avg_loss = 0.3607\n",
            "t = 20, avg_loss = 0.3876\n",
            "t = 25, avg_loss = 0.3531\n",
            "Checking accuracy on train set\n",
            "Got 328 / 400 correct (82.00)\n",
            "acc = 0.820000\n",
            "Starting epoch 16 / 80\n",
            "t = 5, avg_loss = 0.3548\n",
            "t = 10, avg_loss = 0.3676\n",
            "t = 15, avg_loss = 0.3170\n",
            "t = 20, avg_loss = 0.3637\n",
            "t = 25, avg_loss = 0.3633\n",
            "Checking accuracy on train set\n",
            "Got 338 / 400 correct (84.50)\n",
            "acc = 0.845000\n",
            "Starting epoch 17 / 80\n",
            "t = 5, avg_loss = 0.3334\n",
            "t = 10, avg_loss = 0.3197\n",
            "t = 15, avg_loss = 0.3718\n",
            "t = 20, avg_loss = 0.3534\n",
            "t = 25, avg_loss = 0.3352\n",
            "Checking accuracy on train set\n",
            "Got 323 / 400 correct (80.75)\n",
            "acc = 0.807500\n",
            "Starting epoch 18 / 80\n",
            "t = 5, avg_loss = 0.3452\n",
            "t = 10, avg_loss = 0.3263\n",
            "t = 15, avg_loss = 0.3172\n",
            "t = 20, avg_loss = 0.4140\n",
            "t = 25, avg_loss = 0.3889\n",
            "Checking accuracy on train set\n",
            "Got 333 / 400 correct (83.25)\n",
            "acc = 0.832500\n",
            "Starting epoch 19 / 80\n",
            "t = 5, avg_loss = 0.3001\n",
            "t = 10, avg_loss = 0.3700\n",
            "t = 15, avg_loss = 0.3862\n",
            "t = 20, avg_loss = 0.3469\n",
            "t = 25, avg_loss = 0.3063\n",
            "Checking accuracy on train set\n",
            "Got 341 / 400 correct (85.25)\n",
            "acc = 0.852500\n",
            "Starting epoch 20 / 80\n",
            "t = 5, avg_loss = 0.3366\n",
            "t = 10, avg_loss = 0.3681\n",
            "t = 15, avg_loss = 0.3385\n",
            "t = 20, avg_loss = 0.3182\n",
            "t = 25, avg_loss = 0.3255\n",
            "Checking accuracy on train set\n",
            "Got 339 / 400 correct (84.75)\n",
            "acc = 0.847500\n",
            "Starting epoch 21 / 80\n",
            "t = 5, avg_loss = 0.2950\n",
            "t = 10, avg_loss = 0.3363\n",
            "t = 15, avg_loss = 0.2736\n",
            "t = 20, avg_loss = 0.3336\n",
            "t = 25, avg_loss = 0.3118\n",
            "Checking accuracy on train set\n",
            "Got 332 / 400 correct (83.00)\n",
            "acc = 0.830000\n",
            "Starting epoch 22 / 80\n",
            "t = 5, avg_loss = 0.3266\n",
            "t = 10, avg_loss = 0.3274\n",
            "t = 15, avg_loss = 0.2995\n",
            "t = 20, avg_loss = 0.3293\n",
            "t = 25, avg_loss = 0.3702\n",
            "Checking accuracy on train set\n",
            "Got 325 / 400 correct (81.25)\n",
            "acc = 0.812500\n",
            "Starting epoch 23 / 80\n",
            "t = 5, avg_loss = 0.3127\n",
            "t = 10, avg_loss = 0.3066\n",
            "t = 15, avg_loss = 0.3228\n",
            "t = 20, avg_loss = 0.3040\n",
            "t = 25, avg_loss = 0.3399\n",
            "Checking accuracy on train set\n",
            "Got 311 / 400 correct (77.75)\n",
            "acc = 0.777500\n",
            "Starting epoch 24 / 80\n",
            "t = 5, avg_loss = 0.2862\n",
            "t = 10, avg_loss = 0.3278\n",
            "t = 15, avg_loss = 0.3305\n",
            "t = 20, avg_loss = 0.3068\n",
            "t = 25, avg_loss = 0.3596\n",
            "Checking accuracy on train set\n",
            "Got 337 / 400 correct (84.25)\n",
            "acc = 0.842500\n",
            "Starting epoch 25 / 80\n",
            "t = 5, avg_loss = 0.3322\n",
            "t = 10, avg_loss = 0.3287\n",
            "t = 15, avg_loss = 0.3486\n",
            "t = 20, avg_loss = 0.3273\n",
            "t = 25, avg_loss = 0.2964\n",
            "Checking accuracy on train set\n",
            "Got 333 / 400 correct (83.25)\n",
            "acc = 0.832500\n",
            "Starting epoch 26 / 80\n",
            "t = 5, avg_loss = 0.3183\n",
            "t = 10, avg_loss = 0.3142\n",
            "t = 15, avg_loss = 0.2865\n",
            "t = 20, avg_loss = 0.3547\n",
            "t = 25, avg_loss = 0.3367\n",
            "Checking accuracy on train set\n",
            "Got 344 / 400 correct (86.00)\n",
            "acc = 0.860000\n",
            "Starting epoch 27 / 80\n",
            "t = 5, avg_loss = 0.3386\n",
            "t = 10, avg_loss = 0.2656\n",
            "t = 15, avg_loss = 0.2895\n",
            "t = 20, avg_loss = 0.3340\n",
            "t = 25, avg_loss = 0.2703\n",
            "Checking accuracy on train set\n",
            "Got 316 / 400 correct (79.00)\n",
            "acc = 0.790000\n",
            "Starting epoch 28 / 80\n",
            "t = 5, avg_loss = 0.3165\n",
            "t = 10, avg_loss = 0.3120\n",
            "t = 15, avg_loss = 0.2789\n",
            "t = 20, avg_loss = 0.3267\n",
            "t = 25, avg_loss = 0.3300\n",
            "Checking accuracy on train set\n",
            "Got 343 / 400 correct (85.75)\n",
            "acc = 0.857500\n",
            "Starting epoch 29 / 80\n",
            "t = 5, avg_loss = 0.3191\n",
            "t = 10, avg_loss = 0.3115\n",
            "t = 15, avg_loss = 0.3364\n",
            "t = 20, avg_loss = 0.2815\n",
            "t = 25, avg_loss = 0.3175\n",
            "Checking accuracy on train set\n",
            "Got 333 / 400 correct (83.25)\n",
            "acc = 0.832500\n",
            "Starting epoch 30 / 80\n",
            "t = 5, avg_loss = 0.3046\n",
            "t = 10, avg_loss = 0.3041\n",
            "t = 15, avg_loss = 0.3144\n",
            "t = 20, avg_loss = 0.2889\n",
            "t = 25, avg_loss = 0.3217\n",
            "Checking accuracy on train set\n",
            "Got 329 / 400 correct (82.25)\n",
            "acc = 0.822500\n",
            "Starting epoch 31 / 80\n",
            "t = 5, avg_loss = 0.2511\n",
            "t = 10, avg_loss = 0.2899\n",
            "t = 15, avg_loss = 0.3355\n",
            "t = 20, avg_loss = 0.3466\n",
            "t = 25, avg_loss = 0.3465\n",
            "Checking accuracy on train set\n",
            "Got 302 / 400 correct (75.50)\n",
            "acc = 0.755000\n",
            "Starting epoch 32 / 80\n",
            "t = 5, avg_loss = 0.3142\n",
            "t = 10, avg_loss = 0.2876\n",
            "t = 15, avg_loss = 0.2844\n",
            "t = 20, avg_loss = 0.2776\n",
            "t = 25, avg_loss = 0.3839\n",
            "Checking accuracy on train set\n",
            "Got 315 / 400 correct (78.75)\n",
            "acc = 0.787500\n",
            "Starting epoch 33 / 80\n",
            "t = 5, avg_loss = 0.3198\n",
            "t = 10, avg_loss = 0.3294\n",
            "t = 15, avg_loss = 0.3200\n",
            "t = 20, avg_loss = 0.3236\n",
            "t = 25, avg_loss = 0.3098\n",
            "Checking accuracy on train set\n",
            "Got 336 / 400 correct (84.00)\n",
            "acc = 0.840000\n",
            "Starting epoch 34 / 80\n",
            "t = 5, avg_loss = 0.2761\n",
            "t = 10, avg_loss = 0.3243\n",
            "t = 15, avg_loss = 0.3024\n",
            "t = 20, avg_loss = 0.2948\n",
            "t = 25, avg_loss = 0.3391\n",
            "Checking accuracy on train set\n",
            "Got 329 / 400 correct (82.25)\n",
            "acc = 0.822500\n",
            "Starting epoch 35 / 80\n",
            "t = 5, avg_loss = 0.2885\n",
            "t = 10, avg_loss = 0.3629\n",
            "t = 15, avg_loss = 0.2792\n",
            "t = 20, avg_loss = 0.2865\n",
            "t = 25, avg_loss = 0.2532\n",
            "Checking accuracy on train set\n",
            "Got 339 / 400 correct (84.75)\n",
            "acc = 0.847500\n",
            "Starting epoch 36 / 80\n",
            "t = 5, avg_loss = 0.2745\n",
            "t = 10, avg_loss = 0.3123\n",
            "t = 15, avg_loss = 0.2985\n",
            "t = 20, avg_loss = 0.3296\n",
            "t = 25, avg_loss = 0.2950\n",
            "Checking accuracy on train set\n",
            "Got 342 / 400 correct (85.50)\n",
            "acc = 0.855000\n",
            "Starting epoch 37 / 80\n",
            "t = 5, avg_loss = 0.2851\n",
            "t = 10, avg_loss = 0.3115\n",
            "t = 15, avg_loss = 0.3307\n",
            "t = 20, avg_loss = 0.3198\n",
            "t = 25, avg_loss = 0.3362\n",
            "Checking accuracy on train set\n",
            "Got 320 / 400 correct (80.00)\n",
            "acc = 0.800000\n",
            "Starting epoch 38 / 80\n",
            "t = 5, avg_loss = 0.3113\n",
            "t = 10, avg_loss = 0.3061\n",
            "t = 15, avg_loss = 0.3337\n",
            "t = 20, avg_loss = 0.2791\n",
            "t = 25, avg_loss = 0.2815\n",
            "Checking accuracy on train set\n",
            "Got 325 / 400 correct (81.25)\n",
            "acc = 0.812500\n",
            "Starting epoch 39 / 80\n",
            "t = 5, avg_loss = 0.3079\n",
            "t = 10, avg_loss = 0.2693\n",
            "t = 15, avg_loss = 0.3270\n",
            "t = 20, avg_loss = 0.2670\n",
            "t = 25, avg_loss = 0.3194\n",
            "Checking accuracy on train set\n",
            "Got 334 / 400 correct (83.50)\n",
            "acc = 0.835000\n",
            "Starting epoch 40 / 80\n",
            "t = 5, avg_loss = 0.2771\n",
            "t = 10, avg_loss = 0.2756\n",
            "t = 15, avg_loss = 0.2772\n",
            "t = 20, avg_loss = 0.2970\n",
            "t = 25, avg_loss = 0.2888\n",
            "Checking accuracy on train set\n",
            "Got 325 / 400 correct (81.25)\n",
            "acc = 0.812500\n",
            "Starting epoch 41 / 80\n",
            "t = 5, avg_loss = 0.2792\n",
            "t = 10, avg_loss = 0.2638\n",
            "t = 15, avg_loss = 0.2813\n",
            "t = 20, avg_loss = 0.2649\n",
            "t = 25, avg_loss = 0.3211\n",
            "Checking accuracy on train set\n",
            "Got 332 / 400 correct (83.00)\n",
            "acc = 0.830000\n",
            "Starting epoch 42 / 80\n",
            "t = 5, avg_loss = 0.2865\n",
            "t = 10, avg_loss = 0.2861\n",
            "t = 15, avg_loss = 0.2851\n",
            "t = 20, avg_loss = 0.2660\n",
            "t = 25, avg_loss = 0.3016\n",
            "Checking accuracy on train set\n",
            "Got 307 / 400 correct (76.75)\n",
            "acc = 0.767500\n",
            "Starting epoch 43 / 80\n",
            "t = 5, avg_loss = 0.3150\n",
            "t = 10, avg_loss = 0.2811\n",
            "t = 15, avg_loss = 0.2648\n",
            "t = 20, avg_loss = 0.2498\n",
            "t = 25, avg_loss = 0.3088\n",
            "Checking accuracy on train set\n",
            "Got 326 / 400 correct (81.50)\n",
            "acc = 0.815000\n",
            "Starting epoch 44 / 80\n",
            "t = 5, avg_loss = 0.2895\n",
            "t = 10, avg_loss = 0.2747\n",
            "t = 15, avg_loss = 0.2802\n",
            "t = 20, avg_loss = 0.2567\n",
            "t = 25, avg_loss = 0.3608\n",
            "Checking accuracy on train set\n",
            "Got 298 / 400 correct (74.50)\n",
            "acc = 0.745000\n",
            "Starting epoch 45 / 80\n",
            "t = 5, avg_loss = 0.2824\n",
            "t = 10, avg_loss = 0.3088\n",
            "t = 15, avg_loss = 0.2872\n",
            "t = 20, avg_loss = 0.3039\n",
            "t = 25, avg_loss = 0.2579\n",
            "Checking accuracy on train set\n",
            "Got 336 / 400 correct (84.00)\n",
            "acc = 0.840000\n",
            "Starting epoch 46 / 80\n",
            "t = 5, avg_loss = 0.2611\n",
            "t = 10, avg_loss = 0.2820\n",
            "t = 15, avg_loss = 0.3323\n",
            "t = 20, avg_loss = 0.2709\n",
            "t = 25, avg_loss = 0.2750\n",
            "Checking accuracy on train set\n",
            "Got 321 / 400 correct (80.25)\n",
            "acc = 0.802500\n",
            "Starting epoch 47 / 80\n",
            "t = 5, avg_loss = 0.2673\n",
            "t = 10, avg_loss = 0.3122\n",
            "t = 15, avg_loss = 0.2596\n",
            "t = 20, avg_loss = 0.2729\n",
            "t = 25, avg_loss = 0.2722\n",
            "Checking accuracy on train set\n",
            "Got 340 / 400 correct (85.00)\n",
            "acc = 0.850000\n",
            "Starting epoch 48 / 80\n",
            "t = 5, avg_loss = 0.2669\n",
            "t = 10, avg_loss = 0.3065\n",
            "t = 15, avg_loss = 0.2827\n",
            "t = 20, avg_loss = 0.2766\n",
            "t = 25, avg_loss = 0.2824\n",
            "Checking accuracy on train set\n",
            "Got 316 / 400 correct (79.00)\n",
            "acc = 0.790000\n",
            "Starting epoch 49 / 80\n",
            "t = 5, avg_loss = 0.2994\n",
            "t = 10, avg_loss = 0.2519\n",
            "t = 15, avg_loss = 0.2945\n",
            "t = 20, avg_loss = 0.2683\n",
            "t = 25, avg_loss = 0.2778\n",
            "Checking accuracy on train set\n",
            "Got 337 / 400 correct (84.25)\n",
            "acc = 0.842500\n",
            "Starting epoch 50 / 80\n",
            "t = 5, avg_loss = 0.2768\n",
            "t = 10, avg_loss = 0.2621\n",
            "t = 15, avg_loss = 0.3468\n",
            "t = 20, avg_loss = 0.2923\n",
            "t = 25, avg_loss = 0.2679\n",
            "Checking accuracy on train set\n",
            "Got 318 / 400 correct (79.50)\n",
            "acc = 0.795000\n",
            "Starting epoch 51 / 80\n",
            "t = 5, avg_loss = 0.2794\n",
            "t = 10, avg_loss = 0.2675\n",
            "t = 15, avg_loss = 0.2523\n",
            "t = 20, avg_loss = 0.2734\n",
            "t = 25, avg_loss = 0.3089\n",
            "Checking accuracy on train set\n",
            "Got 314 / 400 correct (78.50)\n",
            "acc = 0.785000\n",
            "Starting epoch 52 / 80\n",
            "t = 5, avg_loss = 0.2566\n",
            "t = 10, avg_loss = 0.2375\n",
            "t = 15, avg_loss = 0.2405\n",
            "t = 20, avg_loss = 0.2954\n",
            "t = 25, avg_loss = 0.2929\n",
            "Checking accuracy on train set\n",
            "Got 321 / 400 correct (80.25)\n",
            "acc = 0.802500\n",
            "Starting epoch 53 / 80\n",
            "t = 5, avg_loss = 0.2669\n",
            "t = 10, avg_loss = 0.2748\n",
            "t = 15, avg_loss = 0.2609\n",
            "t = 20, avg_loss = 0.2904\n",
            "t = 25, avg_loss = 0.3093\n",
            "Checking accuracy on train set\n",
            "Got 330 / 400 correct (82.50)\n",
            "acc = 0.825000\n",
            "Starting epoch 54 / 80\n",
            "t = 5, avg_loss = 0.2704\n",
            "t = 10, avg_loss = 0.2631\n",
            "t = 15, avg_loss = 0.2617\n",
            "t = 20, avg_loss = 0.2845\n",
            "t = 25, avg_loss = 0.2872\n",
            "Checking accuracy on train set\n",
            "Got 346 / 400 correct (86.50)\n",
            "acc = 0.865000\n",
            "Starting epoch 55 / 80\n",
            "t = 5, avg_loss = 0.2330\n",
            "t = 10, avg_loss = 0.2481\n",
            "t = 15, avg_loss = 0.2904\n",
            "t = 20, avg_loss = 0.2793\n",
            "t = 25, avg_loss = 0.2519\n",
            "Checking accuracy on train set\n",
            "Got 324 / 400 correct (81.00)\n",
            "acc = 0.810000\n",
            "Starting epoch 56 / 80\n",
            "t = 5, avg_loss = 0.2893\n",
            "t = 10, avg_loss = 0.2570\n",
            "t = 15, avg_loss = 0.2682\n",
            "t = 20, avg_loss = 0.3205\n",
            "t = 25, avg_loss = 0.3168\n",
            "Checking accuracy on train set\n",
            "Got 342 / 400 correct (85.50)\n",
            "acc = 0.855000\n",
            "Starting epoch 57 / 80\n",
            "t = 5, avg_loss = 0.2531\n",
            "t = 10, avg_loss = 0.2832\n",
            "t = 15, avg_loss = 0.2582\n",
            "t = 20, avg_loss = 0.2580\n",
            "t = 25, avg_loss = 0.2891\n",
            "Checking accuracy on train set\n",
            "Got 325 / 400 correct (81.25)\n",
            "acc = 0.812500\n",
            "Starting epoch 58 / 80\n",
            "t = 5, avg_loss = 0.3130\n",
            "t = 10, avg_loss = 0.2483\n",
            "t = 15, avg_loss = 0.2378\n",
            "t = 20, avg_loss = 0.2778\n",
            "t = 25, avg_loss = 0.2875\n",
            "Checking accuracy on train set\n",
            "Got 323 / 400 correct (80.75)\n",
            "acc = 0.807500\n",
            "Starting epoch 59 / 80\n",
            "t = 5, avg_loss = 0.2525\n",
            "t = 10, avg_loss = 0.2511\n",
            "t = 15, avg_loss = 0.2754\n",
            "t = 20, avg_loss = 0.3270\n",
            "t = 25, avg_loss = 0.3009\n",
            "Checking accuracy on train set\n",
            "Got 321 / 400 correct (80.25)\n",
            "acc = 0.802500\n",
            "Starting epoch 60 / 80\n",
            "t = 5, avg_loss = 0.2922\n",
            "t = 10, avg_loss = 0.2464\n",
            "t = 15, avg_loss = 0.2696\n",
            "t = 20, avg_loss = 0.2718\n",
            "t = 25, avg_loss = 0.2772\n",
            "Checking accuracy on train set\n",
            "Got 322 / 400 correct (80.50)\n",
            "acc = 0.805000\n",
            "Starting epoch 61 / 80\n",
            "t = 5, avg_loss = 0.2618\n",
            "t = 10, avg_loss = 0.2855\n",
            "t = 15, avg_loss = 0.3246\n",
            "t = 20, avg_loss = 0.2880\n",
            "t = 25, avg_loss = 0.2510\n",
            "Checking accuracy on train set\n",
            "Got 313 / 400 correct (78.25)\n",
            "acc = 0.782500\n",
            "Starting epoch 62 / 80\n",
            "t = 5, avg_loss = 0.2798\n",
            "t = 10, avg_loss = 0.2896\n",
            "t = 15, avg_loss = 0.2642\n",
            "t = 20, avg_loss = 0.2854\n",
            "t = 25, avg_loss = 0.2837\n",
            "Checking accuracy on train set\n",
            "Got 344 / 400 correct (86.00)\n",
            "acc = 0.860000\n",
            "Starting epoch 63 / 80\n",
            "t = 5, avg_loss = 0.2753\n",
            "t = 10, avg_loss = 0.2608\n",
            "t = 15, avg_loss = 0.2557\n",
            "t = 20, avg_loss = 0.2466\n",
            "t = 25, avg_loss = 0.2640\n",
            "Checking accuracy on train set\n",
            "Got 338 / 400 correct (84.50)\n",
            "acc = 0.845000\n",
            "Starting epoch 64 / 80\n",
            "t = 5, avg_loss = 0.2655\n",
            "t = 10, avg_loss = 0.2607\n",
            "t = 15, avg_loss = 0.2948\n",
            "t = 20, avg_loss = 0.2603\n",
            "t = 25, avg_loss = 0.2198\n",
            "Checking accuracy on train set\n",
            "Got 326 / 400 correct (81.50)\n",
            "acc = 0.815000\n",
            "Starting epoch 65 / 80\n",
            "t = 5, avg_loss = 0.2977\n",
            "t = 10, avg_loss = 0.2672\n",
            "t = 15, avg_loss = 0.2601\n",
            "t = 20, avg_loss = 0.2229\n",
            "t = 25, avg_loss = 0.2793\n",
            "Checking accuracy on train set\n",
            "Got 334 / 400 correct (83.50)\n",
            "acc = 0.835000\n",
            "Starting epoch 66 / 80\n",
            "t = 5, avg_loss = 0.2856\n",
            "t = 10, avg_loss = 0.2442\n",
            "t = 15, avg_loss = 0.2392\n",
            "t = 20, avg_loss = 0.2727\n",
            "t = 25, avg_loss = 0.2902\n",
            "Checking accuracy on train set\n",
            "Got 339 / 400 correct (84.75)\n",
            "acc = 0.847500\n",
            "Starting epoch 67 / 80\n",
            "t = 5, avg_loss = 0.2430\n",
            "t = 10, avg_loss = 0.2728\n",
            "t = 15, avg_loss = 0.2296\n",
            "t = 20, avg_loss = 0.2439\n",
            "t = 25, avg_loss = 0.2606\n",
            "Checking accuracy on train set\n",
            "Got 327 / 400 correct (81.75)\n",
            "acc = 0.817500\n",
            "Starting epoch 68 / 80\n",
            "t = 5, avg_loss = 0.2489\n",
            "t = 10, avg_loss = 0.2765\n",
            "t = 15, avg_loss = 0.3356\n",
            "t = 20, avg_loss = 0.2912\n",
            "t = 25, avg_loss = 0.2583\n",
            "Checking accuracy on train set\n",
            "Got 340 / 400 correct (85.00)\n",
            "acc = 0.850000\n",
            "Starting epoch 69 / 80\n",
            "t = 5, avg_loss = 0.2735\n",
            "t = 10, avg_loss = 0.2794\n",
            "t = 15, avg_loss = 0.2430\n",
            "t = 20, avg_loss = 0.2693\n",
            "t = 25, avg_loss = 0.2473\n",
            "Checking accuracy on train set\n",
            "Got 336 / 400 correct (84.00)\n",
            "acc = 0.840000\n",
            "Starting epoch 70 / 80\n",
            "t = 5, avg_loss = 0.2772\n",
            "t = 10, avg_loss = 0.2414\n",
            "t = 15, avg_loss = 0.3040\n",
            "t = 20, avg_loss = 0.2868\n",
            "t = 25, avg_loss = 0.2777\n",
            "Checking accuracy on train set\n",
            "Got 334 / 400 correct (83.50)\n",
            "acc = 0.835000\n",
            "Starting epoch 71 / 80\n",
            "t = 5, avg_loss = 0.2751\n",
            "t = 10, avg_loss = 0.2639\n",
            "t = 15, avg_loss = 0.2885\n",
            "t = 20, avg_loss = 0.2578\n",
            "t = 25, avg_loss = 0.2877\n",
            "Checking accuracy on train set\n",
            "Got 343 / 400 correct (85.75)\n",
            "acc = 0.857500\n",
            "Starting epoch 72 / 80\n",
            "t = 5, avg_loss = 0.2608\n",
            "t = 10, avg_loss = 0.2100\n",
            "t = 15, avg_loss = 0.2460\n",
            "t = 20, avg_loss = 0.3052\n",
            "t = 25, avg_loss = 0.3174\n",
            "Checking accuracy on train set\n",
            "Got 297 / 400 correct (74.25)\n",
            "acc = 0.742500\n",
            "Starting epoch 73 / 80\n",
            "t = 5, avg_loss = 0.2951\n",
            "t = 10, avg_loss = 0.2851\n",
            "t = 15, avg_loss = 0.2827\n",
            "t = 20, avg_loss = 0.3145\n",
            "t = 25, avg_loss = 0.2894\n",
            "Checking accuracy on train set\n",
            "Got 326 / 400 correct (81.50)\n",
            "acc = 0.815000\n",
            "Starting epoch 74 / 80\n",
            "t = 5, avg_loss = 0.2673\n",
            "t = 10, avg_loss = 0.2579\n",
            "t = 15, avg_loss = 0.3137\n",
            "t = 20, avg_loss = 0.2967\n",
            "t = 25, avg_loss = 0.2463\n",
            "Checking accuracy on train set\n",
            "Got 336 / 400 correct (84.00)\n",
            "acc = 0.840000\n",
            "Starting epoch 75 / 80\n",
            "t = 5, avg_loss = 0.2739\n",
            "t = 10, avg_loss = 0.3201\n",
            "t = 15, avg_loss = 0.2724\n",
            "t = 20, avg_loss = 0.2662\n",
            "t = 25, avg_loss = 0.2528\n",
            "Checking accuracy on train set\n",
            "Got 340 / 400 correct (85.00)\n",
            "acc = 0.850000\n",
            "Starting epoch 76 / 80\n",
            "t = 5, avg_loss = 0.2644\n",
            "t = 10, avg_loss = 0.2686\n",
            "t = 15, avg_loss = 0.2718\n",
            "t = 20, avg_loss = 0.2994\n",
            "t = 25, avg_loss = 0.2961\n",
            "Checking accuracy on train set\n",
            "Got 344 / 400 correct (86.00)\n",
            "acc = 0.860000\n",
            "Starting epoch 77 / 80\n",
            "t = 5, avg_loss = 0.2725\n",
            "t = 10, avg_loss = 0.2562\n",
            "t = 15, avg_loss = 0.2672\n",
            "t = 20, avg_loss = 0.3389\n",
            "t = 25, avg_loss = 0.2645\n",
            "Checking accuracy on train set\n",
            "Got 325 / 400 correct (81.25)\n",
            "acc = 0.812500\n",
            "Starting epoch 78 / 80\n",
            "t = 5, avg_loss = 0.2565\n",
            "t = 10, avg_loss = 0.2264\n",
            "t = 15, avg_loss = 0.2842\n",
            "t = 20, avg_loss = 0.2800\n",
            "t = 25, avg_loss = 0.2594\n",
            "Checking accuracy on train set\n",
            "Got 346 / 400 correct (86.50)\n",
            "acc = 0.865000\n",
            "Starting epoch 79 / 80\n",
            "t = 5, avg_loss = 0.2441\n",
            "t = 10, avg_loss = 0.2538\n",
            "t = 15, avg_loss = 0.2567\n",
            "t = 20, avg_loss = 0.2470\n",
            "t = 25, avg_loss = 0.2907\n",
            "Checking accuracy on train set\n",
            "Got 343 / 400 correct (85.75)\n",
            "acc = 0.857500\n",
            "Starting epoch 80 / 80\n",
            "t = 5, avg_loss = 0.2705\n",
            "t = 10, avg_loss = 0.2753\n",
            "t = 15, avg_loss = 0.2421\n",
            "t = 20, avg_loss = 0.2536\n",
            "t = 25, avg_loss = 0.2475\n",
            "Checking accuracy on train set\n",
            "Got 330 / 400 correct (82.50)\n",
            "acc = 0.825000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_woO1Gw9mv7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlYyIU8foUmu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "check_accuracy(model_gpu, test_loader, datatype='test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7upGSbMrUwMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AQsDt9jUwH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvoCj5uscUsz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_accurancy(acc_list):\n",
        "  plt.plot([i+1 for i in range((len(acc_list)))],acc_list)\n",
        "  print(\"Accurancy:\")\n",
        "  plt.show()\n",
        "\n",
        "def plot_loss_function(avg_loss_list):\n",
        "  plt.plot([print_every*batch_size*(i+1) for i in range((len(avg_loss_list)))],avg_loss_list)\n",
        "  print(\"Loss:\")\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzsruO_f87BL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-Co5KBw-Yy4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plot_accurancy(acc_list)\n",
        "#plot_loss_function(avg_loss_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzuX5gLEeJfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def retry_from_backup():\n",
        "  model_gpu = model_base.type(gpu_dtype)\n",
        "  print(model_gpu)\n",
        "  loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) \n",
        "\n",
        "  checkpoint = torch.load(model_backup_path)\n",
        "  model_gpu.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  epoch = checkpoint['epoch']\n",
        "  loss = checkpoint['loss']\n",
        "  acc_list = checkpoint['acc_list']\n",
        "  #avg_loss_list = checkpoint['avg_loss_list']\n",
        "  print(\"starting from epoch: \" + str(epoch))\n",
        "  print(\"starting from loss: \" + str(loss))\n",
        "  print(acc_list)\n",
        "  \n",
        "  \n",
        "  train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=20, starting_from_epoch=epoch)\n",
        "  check_accuracy(model_gpu, valid_loader)\n",
        "\n",
        "  plot_accurancy(acc_list)\n",
        "  plot_loss_function(avg_loss_list)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--rQZKqOalaJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b90b19ce-d0f4-477e-e9eb-5ba013e874ef"
      },
      "source": [
        "retry_from_backup()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Kerv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (4): ReLU(inplace=True)\n",
            "  (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (7): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (8): ReLU(inplace=True)\n",
            "  (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (11): Dropout(p=0.5, inplace=False)\n",
            "  (12): Flatten()\n",
            "  (13): Linear(in_features=9216, out_features=64, bias=True)\n",
            "  (14): ReLU(inplace=True)\n",
            "  (15): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n",
            "starting from epoch: 79\n",
            "starting from loss: tensor(0.2157, device='cuda:0', requires_grad=True)\n",
            "[0.5425, 0.775, 0.785, 0.8125, 0.81, 0.815, 0.7825, 0.81, 0.8275, 0.8175, 0.84, 0.8425, 0.8, 0.8525, 0.82, 0.845, 0.8075, 0.8325, 0.8525, 0.8475, 0.83, 0.8125, 0.7775, 0.8425, 0.8325, 0.86, 0.79, 0.8575, 0.8325, 0.8225, 0.755, 0.7875, 0.84, 0.8225, 0.8475, 0.855, 0.8, 0.8125, 0.835, 0.8125, 0.83, 0.7675, 0.815, 0.745, 0.84, 0.8025, 0.85, 0.79, 0.8425, 0.795, 0.785, 0.8025, 0.825, 0.865, 0.81, 0.855, 0.8125, 0.8075, 0.8025, 0.805, 0.7825, 0.86, 0.845, 0.815, 0.835, 0.8475, 0.8175, 0.85, 0.84, 0.835, 0.8575, 0.7425, 0.815, 0.84, 0.85, 0.86, 0.8125, 0.865, 0.8575, 0.825]\n",
            "Starting epoch 1 / 20\n",
            "t = 5, avg_loss = 0.2540\n",
            "t = 10, avg_loss = 0.2334\n",
            "t = 15, avg_loss = 0.2655\n",
            "t = 20, avg_loss = 0.3116\n",
            "t = 25, avg_loss = 0.2804\n",
            "Checking accuracy on train set\n",
            "Got 333 / 400 correct (83.25)\n",
            "acc = 0.832500\n",
            "Starting epoch 2 / 20\n",
            "t = 5, avg_loss = 0.2882\n",
            "t = 10, avg_loss = 0.2484\n",
            "t = 15, avg_loss = 0.2403\n",
            "t = 20, avg_loss = 0.2971\n",
            "t = 25, avg_loss = 0.2397\n",
            "Checking accuracy on train set\n",
            "Got 340 / 400 correct (85.00)\n",
            "acc = 0.850000\n",
            "Starting epoch 3 / 20\n",
            "t = 5, avg_loss = 0.2634\n",
            "t = 10, avg_loss = 0.2558\n",
            "t = 15, avg_loss = 0.2291\n",
            "t = 20, avg_loss = 0.3027\n",
            "t = 25, avg_loss = 0.2667\n",
            "Checking accuracy on train set\n",
            "Got 315 / 400 correct (78.75)\n",
            "acc = 0.787500\n",
            "Starting epoch 4 / 20\n",
            "t = 5, avg_loss = 0.2470\n",
            "t = 10, avg_loss = 0.2593\n",
            "t = 15, avg_loss = 0.2531\n",
            "t = 20, avg_loss = 0.2872\n",
            "t = 25, avg_loss = 0.2565\n",
            "Checking accuracy on train set\n",
            "Got 339 / 400 correct (84.75)\n",
            "acc = 0.847500\n",
            "Starting epoch 5 / 20\n",
            "t = 5, avg_loss = 0.2574\n",
            "t = 10, avg_loss = 0.2373\n",
            "t = 15, avg_loss = 0.2448\n",
            "t = 20, avg_loss = 0.2584\n",
            "t = 25, avg_loss = 0.2490\n",
            "Checking accuracy on train set\n",
            "Got 324 / 400 correct (81.00)\n",
            "acc = 0.810000\n",
            "Starting epoch 6 / 20\n",
            "t = 5, avg_loss = 0.2306\n",
            "t = 10, avg_loss = 0.2193\n",
            "t = 15, avg_loss = 0.2474\n",
            "t = 20, avg_loss = 0.2853\n",
            "t = 25, avg_loss = 0.2936\n",
            "Checking accuracy on train set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 7 / 20\n",
            "t = 5, avg_loss = 0.2144\n",
            "t = 10, avg_loss = 0.2511\n",
            "t = 15, avg_loss = 0.2382\n",
            "t = 20, avg_loss = 0.2684\n",
            "t = 25, avg_loss = 0.2919\n",
            "Checking accuracy on train set\n",
            "Got 305 / 400 correct (76.25)\n",
            "acc = 0.762500\n",
            "Starting epoch 8 / 20\n",
            "t = 5, avg_loss = 0.2782\n",
            "t = 10, avg_loss = 0.2800\n",
            "t = 15, avg_loss = 0.2541\n",
            "t = 20, avg_loss = 0.2806\n",
            "t = 25, avg_loss = 0.2818\n",
            "Checking accuracy on train set\n",
            "Got 336 / 400 correct (84.00)\n",
            "acc = 0.840000\n",
            "Starting epoch 9 / 20\n",
            "t = 5, avg_loss = 0.2503\n",
            "t = 10, avg_loss = 0.2207\n",
            "t = 15, avg_loss = 0.2445\n",
            "t = 20, avg_loss = 0.2642\n",
            "t = 25, avg_loss = 0.3047\n",
            "Checking accuracy on train set\n",
            "Got 336 / 400 correct (84.00)\n",
            "acc = 0.840000\n",
            "Starting epoch 10 / 20\n",
            "t = 5, avg_loss = 0.2504\n",
            "t = 10, avg_loss = 0.2717\n",
            "t = 15, avg_loss = 0.2505\n",
            "t = 20, avg_loss = 0.3098\n",
            "t = 25, avg_loss = 0.2597\n",
            "Checking accuracy on train set\n",
            "Got 340 / 400 correct (85.00)\n",
            "acc = 0.850000\n",
            "Starting epoch 11 / 20\n",
            "t = 5, avg_loss = 0.2832\n",
            "t = 10, avg_loss = 0.2426\n",
            "t = 15, avg_loss = 0.2872\n",
            "t = 20, avg_loss = 0.2919\n",
            "t = 25, avg_loss = 0.2716\n",
            "Checking accuracy on train set\n",
            "Got 312 / 400 correct (78.00)\n",
            "acc = 0.780000\n",
            "Starting epoch 12 / 20\n",
            "t = 5, avg_loss = 0.2641\n",
            "t = 10, avg_loss = 0.2401\n",
            "t = 15, avg_loss = 0.2603\n",
            "t = 20, avg_loss = 0.2943\n",
            "t = 25, avg_loss = 0.2464\n",
            "Checking accuracy on train set\n",
            "Got 343 / 400 correct (85.75)\n",
            "acc = 0.857500\n",
            "Starting epoch 13 / 20\n",
            "t = 5, avg_loss = 0.2455\n",
            "t = 10, avg_loss = 0.2279\n",
            "t = 15, avg_loss = 0.2717\n",
            "t = 20, avg_loss = 0.2769\n",
            "t = 25, avg_loss = 0.2739\n",
            "Checking accuracy on train set\n",
            "Got 343 / 400 correct (85.75)\n",
            "acc = 0.857500\n",
            "Starting epoch 14 / 20\n",
            "t = 5, avg_loss = 0.2901\n",
            "t = 10, avg_loss = 0.2446\n",
            "t = 15, avg_loss = 0.2334\n",
            "t = 20, avg_loss = 0.2592\n",
            "t = 25, avg_loss = 0.2607\n",
            "Checking accuracy on train set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 15 / 20\n",
            "t = 5, avg_loss = 0.2699\n",
            "t = 10, avg_loss = 0.2530\n",
            "t = 15, avg_loss = 0.2740\n",
            "t = 20, avg_loss = 0.2325\n",
            "t = 25, avg_loss = 0.2372\n",
            "Checking accuracy on train set\n",
            "Got 337 / 400 correct (84.25)\n",
            "acc = 0.842500\n",
            "Starting epoch 16 / 20\n",
            "t = 5, avg_loss = 0.2303\n",
            "t = 10, avg_loss = 0.2125\n",
            "t = 15, avg_loss = 0.2625\n",
            "t = 20, avg_loss = 0.2439\n",
            "t = 25, avg_loss = 0.2831\n",
            "Checking accuracy on train set\n",
            "Got 316 / 400 correct (79.00)\n",
            "acc = 0.790000\n",
            "Starting epoch 17 / 20\n",
            "t = 5, avg_loss = 0.2477\n",
            "t = 10, avg_loss = 0.2453\n",
            "t = 15, avg_loss = 0.2553\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-bc0ed074296d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mretry_from_backup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-3c10dff3369b>\u001b[0m in \u001b[0;36mretry_from_backup\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarting_from_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m   \u001b[0mcheck_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-49ca391291dc>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, loss_fn, optimizer, num_epochs, starting_from_epoch)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mx_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0my_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-c34cad82a6d6>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m           \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"malignant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"malignant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   1856\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1858\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreducing_gap\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresample\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mNEAREST\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwIc1sH-fQPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWxmwOKfgOR0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjJMcsW6PVLP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqAon2NL_qG2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "outputId": "bb35b557-6f79-4f83-d48a-7852656b6fe1"
      },
      "source": [
        "plot_accurancy(acc_list)\n",
        "plot_loss_function(avg_loss_list)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accurancy:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhLioSYJy-zW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "9eb08204-2269-40e3-b777-0f82da120af6"
      },
      "source": [
        "check_accuracy(model_gpu, test_loader, datatype='test')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking accuracy on test set\n",
            "Got 169 / 201 correct (84.08)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8407960199004975"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEiSqj1sGQue",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "3c8810dc-2d3a-45c5-a657-67b281fc86f7"
      },
      "source": [
        "print(acc_list)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.5425, 0.775, 0.785, 0.8125, 0.81, 0.815, 0.7825, 0.81, 0.8275, 0.8175, 0.84, 0.8425, 0.8, 0.8525, 0.82, 0.845, 0.8075, 0.8325, 0.8525, 0.8475, 0.83, 0.8125, 0.7775, 0.8425, 0.8325, 0.86, 0.79, 0.8575, 0.8325, 0.8225, 0.755, 0.7875, 0.84, 0.8225, 0.8475, 0.855, 0.8, 0.8125, 0.835, 0.8125, 0.83, 0.7675, 0.815, 0.745, 0.84, 0.8025, 0.85, 0.79, 0.8425, 0.795, 0.785, 0.8025, 0.825, 0.865, 0.81, 0.855, 0.8125, 0.8075, 0.8025, 0.805, 0.7825, 0.86, 0.845, 0.815, 0.835, 0.8475, 0.8175, 0.85, 0.84, 0.835, 0.8575, 0.7425, 0.815, 0.84, 0.85, 0.86, 0.8125, 0.865, 0.8575, 0.825, 0.8325, 0.85, 0.7875, 0.8475, 0.81, 0.88, 0.7625, 0.84, 0.84, 0.85, 0.78, 0.8575, 0.8575, 0.8675, 0.8425, 0.79]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJZaCVLMbm6R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AA9ySb8Rc91N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHu8X93dd6nW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}