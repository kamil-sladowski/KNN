{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN_ascending_layers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamilo116/KNN/blob/master/KNN_gaussian.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7ReM7FU-xs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import sys\n",
        "from random import shuffle\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms as transforms\n",
        "import timeit\n",
        "\n",
        "np.random.seed(4) \n",
        "torch.manual_seed(4) \n",
        "torch.cuda.manual_seed(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYIMZ8QyYewD",
        "colab_type": "code",
        "outputId": "ae3c5672-e557-48f5-e12d-97ae09d41f6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "! git clone https://github.com/wang-chen/kervolution.git \n",
        "\n",
        "sys.path.append(\"kervolution/\")\n",
        "from kervolution import Kerv2d\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'kervolution'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 53 (delta 2), reused 0 (delta 0), pack-reused 47\u001b[K\n",
            "Unpacking objects: 100% (53/53), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvbKg4VJXKY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LIMIT_IMAGES_NUM = 1000\n",
        "train_test_split_size = 0.2\n",
        "image_resize = (100, 100)\n",
        "batch_size = 64\n",
        "num_workers = 0\n",
        "\n",
        "out_1 = 16\n",
        "out_2 = 32\n",
        "out_3 = 64\n",
        "out_4 = 128\n",
        "\n",
        "\n",
        "k_size_1 = 3\n",
        "padding_1 = 1\n",
        "in_channels = 3\n",
        "\n",
        "kernel_size = 3\n",
        "num_epochs = 100\n",
        "\n",
        "learning_rate = 0.0001\n",
        "weight_decay = 0.1\n",
        "\n",
        "MALIGNANT_DATASET = '/content/drive/My Drive/Colab_data/malignant/malignant/'\n",
        "BENIGN_DATASET = '/content/drive/My Drive/Colab_data/benign/benign/'\n",
        "DATA_FOLDER = '/content/drive/My Drive/Colab_data/'\n",
        "model_backup_path = os.path.join(DATA_FOLDER, 'backup_model3') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMOHez_kHZD6",
        "colab_type": "code",
        "outputId": "ac5c1c5e-eba4-485a-a029-59ed6c17ce47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b8P1NdXfVdX",
        "colab_type": "code",
        "outputId": "45664a2e-e06e-41b1-a9df-b6ef9061b16d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "benign_file_list = sorted(os.listdir(BENIGN_DATASET))\n",
        "malignant_file_list = sorted(os.listdir(MALIGNANT_DATASET))\n",
        "shuffle(benign_file_list)\n",
        "shuffle(malignant_file_list)\n",
        "benign_file_list = benign_file_list[:LIMIT_IMAGES_NUM]\n",
        "malignant_file_list = malignant_file_list[:LIMIT_IMAGES_NUM]\n",
        "\n",
        "print(f\"Number of benign {len(benign_file_list)} images\")\n",
        "print(f\"Number of malignant {len(malignant_file_list)} images\")\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize(image_resize),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of benign 1000 images\n",
            "Number of malignant 1000 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGDQfal74BLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "benign_dict = {filename: 0 for filename in benign_file_list}\n",
        "malignant_dict = {filename: 1 for filename in malignant_file_list}\n",
        "img_class_dict = {**benign_dict , **malignant_dict}\n",
        "labeled_data = pd.Series(img_class_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvAAOqmVfVll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IsicDataset(Dataset):\n",
        "    def __init__(self, data_folder, labeled_data, \n",
        "                 transform=transforms.Compose([transforms.ToTensor()])):\n",
        "        self.labeled_data = labeled_data\n",
        "        self.transform = transform\n",
        "        self.data_folder = data_folder\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labeled_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        label = self.labeled_data[index]\n",
        "        if label == 0:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"benign\", \"benign\", index ))\n",
        "        else:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"malignant\", \"malignant\", index ))\n",
        "        image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "    @property\n",
        "    def labels(self):\n",
        "      return self.labeled_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSuYqjLAYrWA",
        "colab_type": "code",
        "outputId": "4f0b29ff-b6e5-4c04-e5e2-6dc0ed051afe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "dataset = IsicDataset(DATA_FOLDER, labeled_data, transform=data_transforms)\n",
        "print(dataset.labels)\n",
        "\n",
        "X_train, X_test = train_test_split(dataset.labels, test_size=train_test_split_size)\n",
        "print(\"number of training data: \",len(X_train))\n",
        "print(\"number of testing  data: \",len(X_test))\n",
        "\n",
        "train_sampler = SubsetRandomSampler(list(X_train.index))\n",
        "valid_sampler = SubsetRandomSampler(list(X_test.index))\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ISIC_0000060.jpeg    0\n",
            "ISIC_0001235.jpeg    0\n",
            "ISIC_0000336.jpeg    0\n",
            "ISIC_0001379.jpeg    0\n",
            "ISIC_0000789.jpeg    0\n",
            "                    ..\n",
            "ISIC_0012512.jpeg    1\n",
            "ISIC_0011943.jpeg    1\n",
            "ISIC_0011368.jpeg    1\n",
            "ISIC_0014249.jpeg    1\n",
            "ISIC_0012067.jpeg    1\n",
            "Length: 2000, dtype: int64\n",
            "number of training data:  1600\n",
            "number of testing  data:  400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e8nFBR6Yug5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "def train(model, train_loader ,loss_fn, optimizer, num_epochs=1, starting_from_epoch=1):\n",
        "    total_loss =0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
        "        model.train()\n",
        "\n",
        "        for t, (x, y) in enumerate(train_loader):\n",
        "            x_var = Variable(x.type(gpu_dtype))\n",
        "            y_var = Variable(y.type(gpu_dtype).long())\n",
        "            scores = model(x_var)\n",
        "            loss = loss_fn(scores, y_var)\n",
        "            total_loss += loss.data\n",
        "            \n",
        "            if (t + 1) % print_every == 0:\n",
        "                avg_loss = total_loss/print_every\n",
        "                print('t = %d, avg_loss = %.4f' % (t + 1, avg_loss) )\n",
        "                avg_loss_list.append(avg_loss)\n",
        "                total_loss = 0\n",
        "                \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        acc = check_accuracy(model_gpu, valid_loader)\n",
        "        print('acc = %f' %(acc))\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model_gpu.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            'acc_list': acc_list,\n",
        "            }, model_backup_path)\n",
        "            \n",
        "def check_accuracy(model, loader):\n",
        "    print('Checking accuracy on test set')   \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval() \n",
        "    for x, y in loader:\n",
        "        x_var = Variable(x.type(gpu_dtype))\n",
        "\n",
        "        scores = model(x_var)\n",
        "        _, preds = scores.data.cpu().max(1)\n",
        "        num_correct += (preds == y).sum()\n",
        "        num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    acc_list.append(acc)\n",
        "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "    return acc\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggvpMu36Yw2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.size()\n",
        "        return x.view(N, -1)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-gYHw0Jlbwt",
        "colab_type": "code",
        "outputId": "e8007ce4-8f79-449d-ca9b-76f44f5e0680",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "print_every = 2\n",
        "gpu_dtype = torch.cuda.FloatTensor\n",
        "\n",
        "\n",
        "'''\n",
        "Kerv2d\n",
        "kervolution with following options:\n",
        "kernel_type: [linear, polynomial, gaussian, etc.]\n",
        "default is convolution:\n",
        "          kernel_type --> linear,\n",
        "balance, power, gamma is valid only when the kernel_type is specified\n",
        "if learnable_kernel = True,  they just be the initial value of learable parameters\n",
        "if learnable_kernel = False, they are the value of kernel_type's parameter\n",
        "the parameter [power] cannot be learned due to integer limitation\n",
        "dilation (int or tuple, optional): Spacing between kernel\n",
        "elements. Default: 1\n",
        "groups (int, optional): Number of blocked connections from input\n",
        "channels to output channels. Default: 1\n",
        "bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n",
        "kernel_type (str), Default: 'linear'\n",
        "learnable_kernel (bool): Learnable kernel parameters.  Default: False \n",
        "balance: 0, 1\n",
        "power: 3, 4, 5\n",
        "gamma:\n",
        "'''\n",
        "\n",
        "\n",
        "model_base = nn.Sequential( \n",
        "                #nn.Conv2d(in_channels , out_1, padding= padding_1, kernel_size=k_size_1, stride=1),\n",
        "                nn.Kerv2d(in_channels , out_1, padding=padding_1, dilation=1, groups=1, bias=True, \n",
        "                          kernel_type='gaussian', kernel_size=k_size_1, learnable_kernel=True,\n",
        "                          kernel_regularizer=True, stride=1, balance=1, power=3, gamma=0.75\n",
        "                          ), \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_1),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_1 , out_2, padding= padding_1, kernel_size=k_size_1, stride=1), \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_2),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_2 , out_3, padding= padding_1, kernel_size=k_size_1, stride=1),  \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_3),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_3 , out_4, padding= padding_1, kernel_size=k_size_1, stride=1),  \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_4),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Dropout(0.5),\n",
        "                Flatten(),\n",
        "                nn.Linear(4608,64),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Linear(64,2)\n",
        "            )\n",
        "model_gpu = model_base.type(gpu_dtype)\n",
        "print(model_gpu)\n",
        "loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Kerv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (4): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (5): ReLU(inplace=True)\n",
            "  (6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (8): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (9): ReLU(inplace=True)\n",
            "  (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (12): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (13): ReLU(inplace=True)\n",
            "  (14): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (16): Dropout(p=0.5, inplace=False)\n",
            "  (17): Flatten()\n",
            "  (18): Linear(in_features=4608, out_features=64, bias=True)\n",
            "  (19): ReLU(inplace=True)\n",
            "  (20): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgmexhBRZAK6",
        "colab_type": "code",
        "outputId": "1bcd928c-610a-49e4-8e9d-0e2766a23b58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs)\n",
        "check_accuracy(model_gpu, valid_loader)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 1 / 100\n",
            "t = 2, avg_loss = 0.6772\n",
            "t = 4, avg_loss = 0.6745\n",
            "t = 6, avg_loss = 0.6605\n",
            "t = 8, avg_loss = 0.6816\n",
            "t = 10, avg_loss = 0.6429\n",
            "t = 12, avg_loss = 0.5810\n",
            "t = 14, avg_loss = 0.5988\n",
            "t = 16, avg_loss = 0.5688\n",
            "t = 18, avg_loss = 0.5441\n",
            "t = 20, avg_loss = 0.5752\n",
            "t = 22, avg_loss = 0.4925\n",
            "t = 24, avg_loss = 0.6299\n",
            "Checking accuracy on test set\n",
            "Got 206 / 400 correct (51.50)\n",
            "acc = 0.515000\n",
            "Starting epoch 2 / 100\n",
            "t = 2, avg_loss = 0.8335\n",
            "t = 4, avg_loss = 0.5886\n",
            "t = 6, avg_loss = 0.6011\n",
            "t = 8, avg_loss = 0.5707\n",
            "t = 10, avg_loss = 0.5029\n",
            "t = 12, avg_loss = 0.4743\n",
            "t = 14, avg_loss = 0.4807\n",
            "t = 16, avg_loss = 0.4755\n",
            "t = 18, avg_loss = 0.5198\n",
            "t = 20, avg_loss = 0.4593\n",
            "t = 22, avg_loss = 0.4724\n",
            "t = 24, avg_loss = 0.4876\n",
            "Checking accuracy on test set\n",
            "Got 271 / 400 correct (67.75)\n",
            "acc = 0.677500\n",
            "Starting epoch 3 / 100\n",
            "t = 2, avg_loss = 0.6274\n",
            "t = 4, avg_loss = 0.5177\n",
            "t = 6, avg_loss = 0.4898\n",
            "t = 8, avg_loss = 0.4210\n",
            "t = 10, avg_loss = 0.4689\n",
            "t = 12, avg_loss = 0.4859\n",
            "t = 14, avg_loss = 0.5435\n",
            "t = 16, avg_loss = 0.5027\n",
            "t = 18, avg_loss = 0.4271\n",
            "t = 20, avg_loss = 0.5213\n",
            "t = 22, avg_loss = 0.4776\n",
            "t = 24, avg_loss = 0.4325\n",
            "Checking accuracy on test set\n",
            "Got 310 / 400 correct (77.50)\n",
            "acc = 0.775000\n",
            "Starting epoch 4 / 100\n",
            "t = 2, avg_loss = 0.6600\n",
            "t = 4, avg_loss = 0.5021\n",
            "t = 6, avg_loss = 0.5036\n",
            "t = 8, avg_loss = 0.4701\n",
            "t = 10, avg_loss = 0.5748\n",
            "t = 12, avg_loss = 0.3749\n",
            "t = 14, avg_loss = 0.5198\n",
            "t = 16, avg_loss = 0.4544\n",
            "t = 18, avg_loss = 0.4225\n",
            "t = 20, avg_loss = 0.4853\n",
            "t = 22, avg_loss = 0.4412\n",
            "t = 24, avg_loss = 0.4721\n",
            "Checking accuracy on test set\n",
            "Got 317 / 400 correct (79.25)\n",
            "acc = 0.792500\n",
            "Starting epoch 5 / 100\n",
            "t = 2, avg_loss = 0.6527\n",
            "t = 4, avg_loss = 0.4430\n",
            "t = 6, avg_loss = 0.4093\n",
            "t = 8, avg_loss = 0.4125\n",
            "t = 10, avg_loss = 0.4926\n",
            "t = 12, avg_loss = 0.4449\n",
            "t = 14, avg_loss = 0.4470\n",
            "t = 16, avg_loss = 0.4857\n",
            "t = 18, avg_loss = 0.3685\n",
            "t = 20, avg_loss = 0.4749\n",
            "t = 22, avg_loss = 0.3347\n",
            "t = 24, avg_loss = 0.4104\n",
            "Checking accuracy on test set\n",
            "Got 317 / 400 correct (79.25)\n",
            "acc = 0.792500\n",
            "Starting epoch 6 / 100\n",
            "t = 2, avg_loss = 0.6886\n",
            "t = 4, avg_loss = 0.4684\n",
            "t = 6, avg_loss = 0.4662\n",
            "t = 8, avg_loss = 0.4350\n",
            "t = 10, avg_loss = 0.4627\n",
            "t = 12, avg_loss = 0.3700\n",
            "t = 14, avg_loss = 0.3744\n",
            "t = 16, avg_loss = 0.4049\n",
            "t = 18, avg_loss = 0.4355\n",
            "t = 20, avg_loss = 0.4081\n",
            "t = 22, avg_loss = 0.3596\n",
            "t = 24, avg_loss = 0.3979\n",
            "Checking accuracy on test set\n",
            "Got 322 / 400 correct (80.50)\n",
            "acc = 0.805000\n",
            "Starting epoch 7 / 100\n",
            "t = 2, avg_loss = 0.6780\n",
            "t = 4, avg_loss = 0.4219\n",
            "t = 6, avg_loss = 0.4986\n",
            "t = 8, avg_loss = 0.4919\n",
            "t = 10, avg_loss = 0.4578\n",
            "t = 12, avg_loss = 0.4009\n",
            "t = 14, avg_loss = 0.4131\n",
            "t = 16, avg_loss = 0.4065\n",
            "t = 18, avg_loss = 0.4598\n",
            "t = 20, avg_loss = 0.4853\n",
            "t = 22, avg_loss = 0.3118\n",
            "t = 24, avg_loss = 0.3556\n",
            "Checking accuracy on test set\n",
            "Got 315 / 400 correct (78.75)\n",
            "acc = 0.787500\n",
            "Starting epoch 8 / 100\n",
            "t = 2, avg_loss = 0.6050\n",
            "t = 4, avg_loss = 0.4667\n",
            "t = 6, avg_loss = 0.4387\n",
            "t = 8, avg_loss = 0.4528\n",
            "t = 10, avg_loss = 0.3768\n",
            "t = 12, avg_loss = 0.4248\n",
            "t = 14, avg_loss = 0.3535\n",
            "t = 16, avg_loss = 0.3842\n",
            "t = 18, avg_loss = 0.4898\n",
            "t = 20, avg_loss = 0.4504\n",
            "t = 22, avg_loss = 0.3669\n",
            "t = 24, avg_loss = 0.4015\n",
            "Checking accuracy on test set\n",
            "Got 326 / 400 correct (81.50)\n",
            "acc = 0.815000\n",
            "Starting epoch 9 / 100\n",
            "t = 2, avg_loss = 0.5966\n",
            "t = 4, avg_loss = 0.3033\n",
            "t = 6, avg_loss = 0.4112\n",
            "t = 8, avg_loss = 0.4155\n",
            "t = 10, avg_loss = 0.3690\n",
            "t = 12, avg_loss = 0.4551\n",
            "t = 14, avg_loss = 0.3836\n",
            "t = 16, avg_loss = 0.3451\n",
            "t = 18, avg_loss = 0.4337\n",
            "t = 20, avg_loss = 0.3623\n",
            "t = 22, avg_loss = 0.3696\n",
            "t = 24, avg_loss = 0.4056\n",
            "Checking accuracy on test set\n",
            "Got 308 / 400 correct (77.00)\n",
            "acc = 0.770000\n",
            "Starting epoch 10 / 100\n",
            "t = 2, avg_loss = 0.5421\n",
            "t = 4, avg_loss = 0.4023\n",
            "t = 6, avg_loss = 0.4338\n",
            "t = 8, avg_loss = 0.3520\n",
            "t = 10, avg_loss = 0.4112\n",
            "t = 12, avg_loss = 0.3387\n",
            "t = 14, avg_loss = 0.3508\n",
            "t = 16, avg_loss = 0.4719\n",
            "t = 18, avg_loss = 0.3599\n",
            "t = 20, avg_loss = 0.3967\n",
            "t = 22, avg_loss = 0.3360\n",
            "t = 24, avg_loss = 0.3112\n",
            "Checking accuracy on test set\n",
            "Got 319 / 400 correct (79.75)\n",
            "acc = 0.797500\n",
            "Starting epoch 11 / 100\n",
            "t = 2, avg_loss = 0.6288\n",
            "t = 4, avg_loss = 0.4166\n",
            "t = 6, avg_loss = 0.3220\n",
            "t = 8, avg_loss = 0.4568\n",
            "t = 10, avg_loss = 0.3323\n",
            "t = 12, avg_loss = 0.3690\n",
            "t = 14, avg_loss = 0.3816\n",
            "t = 16, avg_loss = 0.3687\n",
            "t = 18, avg_loss = 0.2912\n",
            "t = 20, avg_loss = 0.3742\n",
            "t = 22, avg_loss = 0.3765\n",
            "t = 24, avg_loss = 0.4339\n",
            "Checking accuracy on test set\n",
            "Got 310 / 400 correct (77.50)\n",
            "acc = 0.775000\n",
            "Starting epoch 12 / 100\n",
            "t = 2, avg_loss = 0.5408\n",
            "t = 4, avg_loss = 0.3972\n",
            "t = 6, avg_loss = 0.3046\n",
            "t = 8, avg_loss = 0.3924\n",
            "t = 10, avg_loss = 0.4020\n",
            "t = 12, avg_loss = 0.4209\n",
            "t = 14, avg_loss = 0.3042\n",
            "t = 16, avg_loss = 0.2963\n",
            "t = 18, avg_loss = 0.4831\n",
            "t = 20, avg_loss = 0.4171\n",
            "t = 22, avg_loss = 0.3655\n",
            "t = 24, avg_loss = 0.4066\n",
            "Checking accuracy on test set\n",
            "Got 320 / 400 correct (80.00)\n",
            "acc = 0.800000\n",
            "Starting epoch 13 / 100\n",
            "t = 2, avg_loss = 0.6698\n",
            "t = 4, avg_loss = 0.3436\n",
            "t = 6, avg_loss = 0.2822\n",
            "t = 8, avg_loss = 0.3427\n",
            "t = 10, avg_loss = 0.3317\n",
            "t = 12, avg_loss = 0.3713\n",
            "t = 14, avg_loss = 0.3669\n",
            "t = 16, avg_loss = 0.4269\n",
            "t = 18, avg_loss = 0.3386\n",
            "t = 20, avg_loss = 0.4328\n",
            "t = 22, avg_loss = 0.3348\n",
            "t = 24, avg_loss = 0.3663\n",
            "Checking accuracy on test set\n",
            "Got 301 / 400 correct (75.25)\n",
            "acc = 0.752500\n",
            "Starting epoch 14 / 100\n",
            "t = 2, avg_loss = 0.5710\n",
            "t = 4, avg_loss = 0.3887\n",
            "t = 6, avg_loss = 0.3276\n",
            "t = 8, avg_loss = 0.3134\n",
            "t = 10, avg_loss = 0.3840\n",
            "t = 12, avg_loss = 0.3780\n",
            "t = 14, avg_loss = 0.4099\n",
            "t = 16, avg_loss = 0.3429\n",
            "t = 18, avg_loss = 0.3570\n",
            "t = 20, avg_loss = 0.3529\n",
            "t = 22, avg_loss = 0.3219\n",
            "t = 24, avg_loss = 0.3348\n",
            "Checking accuracy on test set\n",
            "Got 335 / 400 correct (83.75)\n",
            "acc = 0.837500\n",
            "Starting epoch 15 / 100\n",
            "t = 2, avg_loss = 0.4924\n",
            "t = 4, avg_loss = 0.2474\n",
            "t = 6, avg_loss = 0.3377\n",
            "t = 8, avg_loss = 0.4091\n",
            "t = 10, avg_loss = 0.4100\n",
            "t = 12, avg_loss = 0.2951\n",
            "t = 14, avg_loss = 0.3600\n",
            "t = 16, avg_loss = 0.3757\n",
            "t = 18, avg_loss = 0.3910\n",
            "t = 20, avg_loss = 0.3323\n",
            "t = 22, avg_loss = 0.3542\n",
            "t = 24, avg_loss = 0.3451\n",
            "Checking accuracy on test set\n",
            "Got 335 / 400 correct (83.75)\n",
            "acc = 0.837500\n",
            "Starting epoch 16 / 100\n",
            "t = 2, avg_loss = 0.5193\n",
            "t = 4, avg_loss = 0.2692\n",
            "t = 6, avg_loss = 0.2802\n",
            "t = 8, avg_loss = 0.3839\n",
            "t = 10, avg_loss = 0.3613\n",
            "t = 12, avg_loss = 0.2895\n",
            "t = 14, avg_loss = 0.3338\n",
            "t = 16, avg_loss = 0.3308\n",
            "t = 18, avg_loss = 0.2494\n",
            "t = 20, avg_loss = 0.4058\n",
            "t = 22, avg_loss = 0.3941\n",
            "t = 24, avg_loss = 0.3104\n",
            "Checking accuracy on test set\n",
            "Got 310 / 400 correct (77.50)\n",
            "acc = 0.775000\n",
            "Starting epoch 17 / 100\n",
            "t = 2, avg_loss = 0.4886\n",
            "t = 4, avg_loss = 0.3460\n",
            "t = 6, avg_loss = 0.2898\n",
            "t = 8, avg_loss = 0.3558\n",
            "t = 10, avg_loss = 0.2806\n",
            "t = 12, avg_loss = 0.3226\n",
            "t = 14, avg_loss = 0.4104\n",
            "t = 16, avg_loss = 0.3023\n",
            "t = 18, avg_loss = 0.3505\n",
            "t = 20, avg_loss = 0.3236\n",
            "t = 22, avg_loss = 0.3074\n",
            "t = 24, avg_loss = 0.4164\n",
            "Checking accuracy on test set\n",
            "Got 331 / 400 correct (82.75)\n",
            "acc = 0.827500\n",
            "Starting epoch 18 / 100\n",
            "t = 2, avg_loss = 0.5146\n",
            "t = 4, avg_loss = 0.4029\n",
            "t = 6, avg_loss = 0.3649\n",
            "t = 8, avg_loss = 0.3156\n",
            "t = 10, avg_loss = 0.4662\n",
            "t = 12, avg_loss = 0.3258\n",
            "t = 14, avg_loss = 0.2751\n",
            "t = 16, avg_loss = 0.3016\n",
            "t = 18, avg_loss = 0.2208\n",
            "t = 20, avg_loss = 0.3288\n",
            "t = 22, avg_loss = 0.2828\n",
            "t = 24, avg_loss = 0.3582\n",
            "Checking accuracy on test set\n",
            "Got 318 / 400 correct (79.50)\n",
            "acc = 0.795000\n",
            "Starting epoch 19 / 100\n",
            "t = 2, avg_loss = 0.4225\n",
            "t = 4, avg_loss = 0.3636\n",
            "t = 6, avg_loss = 0.2793\n",
            "t = 8, avg_loss = 0.3730\n",
            "t = 10, avg_loss = 0.2714\n",
            "t = 12, avg_loss = 0.3145\n",
            "t = 14, avg_loss = 0.2884\n",
            "t = 16, avg_loss = 0.2994\n",
            "t = 18, avg_loss = 0.3270\n",
            "t = 20, avg_loss = 0.3396\n",
            "t = 22, avg_loss = 0.3636\n",
            "t = 24, avg_loss = 0.3724\n",
            "Checking accuracy on test set\n",
            "Got 311 / 400 correct (77.75)\n",
            "acc = 0.777500\n",
            "Starting epoch 20 / 100\n",
            "t = 2, avg_loss = 0.5035\n",
            "t = 4, avg_loss = 0.3164\n",
            "t = 6, avg_loss = 0.3839\n",
            "t = 8, avg_loss = 0.3694\n",
            "t = 10, avg_loss = 0.3682\n",
            "t = 12, avg_loss = 0.2558\n",
            "t = 14, avg_loss = 0.2903\n",
            "t = 16, avg_loss = 0.2885\n",
            "t = 18, avg_loss = 0.2848\n",
            "t = 20, avg_loss = 0.3230\n",
            "t = 22, avg_loss = 0.3065\n",
            "t = 24, avg_loss = 0.3953\n",
            "Checking accuracy on test set\n",
            "Got 324 / 400 correct (81.00)\n",
            "acc = 0.810000\n",
            "Starting epoch 21 / 100\n",
            "t = 2, avg_loss = 0.4651\n",
            "t = 4, avg_loss = 0.2973\n",
            "t = 6, avg_loss = 0.2805\n",
            "t = 8, avg_loss = 0.2895\n",
            "t = 10, avg_loss = 0.3518\n",
            "t = 12, avg_loss = 0.2869\n",
            "t = 14, avg_loss = 0.2979\n",
            "t = 16, avg_loss = 0.2543\n",
            "t = 18, avg_loss = 0.3210\n",
            "t = 20, avg_loss = 0.3149\n",
            "t = 22, avg_loss = 0.3078\n",
            "t = 24, avg_loss = 0.3055\n",
            "Checking accuracy on test set\n",
            "Got 329 / 400 correct (82.25)\n",
            "acc = 0.822500\n",
            "Starting epoch 22 / 100\n",
            "t = 2, avg_loss = 0.4265\n",
            "t = 4, avg_loss = 0.2247\n",
            "t = 6, avg_loss = 0.3549\n",
            "t = 8, avg_loss = 0.4012\n",
            "t = 10, avg_loss = 0.3277\n",
            "t = 12, avg_loss = 0.3415\n",
            "t = 14, avg_loss = 0.3153\n",
            "t = 16, avg_loss = 0.3278\n",
            "t = 18, avg_loss = 0.3602\n",
            "t = 20, avg_loss = 0.4123\n",
            "t = 22, avg_loss = 0.3138\n",
            "t = 24, avg_loss = 0.3027\n",
            "Checking accuracy on test set\n",
            "Got 334 / 400 correct (83.50)\n",
            "acc = 0.835000\n",
            "Starting epoch 23 / 100\n",
            "t = 2, avg_loss = 0.4985\n",
            "t = 4, avg_loss = 0.3140\n",
            "t = 6, avg_loss = 0.3119\n",
            "t = 8, avg_loss = 0.2838\n",
            "t = 10, avg_loss = 0.3531\n",
            "t = 12, avg_loss = 0.3305\n",
            "t = 14, avg_loss = 0.2777\n",
            "t = 16, avg_loss = 0.3156\n",
            "t = 18, avg_loss = 0.3520\n",
            "t = 20, avg_loss = 0.3317\n",
            "t = 22, avg_loss = 0.2756\n",
            "t = 24, avg_loss = 0.3302\n",
            "Checking accuracy on test set\n",
            "Got 329 / 400 correct (82.25)\n",
            "acc = 0.822500\n",
            "Starting epoch 24 / 100\n",
            "t = 2, avg_loss = 0.4371\n",
            "t = 4, avg_loss = 0.3594\n",
            "t = 6, avg_loss = 0.2932\n",
            "t = 8, avg_loss = 0.3524\n",
            "t = 10, avg_loss = 0.2716\n",
            "t = 12, avg_loss = 0.2868\n",
            "t = 14, avg_loss = 0.3315\n",
            "t = 16, avg_loss = 0.2984\n",
            "t = 18, avg_loss = 0.3435\n",
            "t = 20, avg_loss = 0.2828\n",
            "t = 22, avg_loss = 0.3403\n",
            "t = 24, avg_loss = 0.2562\n",
            "Checking accuracy on test set\n",
            "Got 329 / 400 correct (82.25)\n",
            "acc = 0.822500\n",
            "Starting epoch 25 / 100\n",
            "t = 2, avg_loss = 0.3711\n",
            "t = 4, avg_loss = 0.3677\n",
            "t = 6, avg_loss = 0.3883\n",
            "t = 8, avg_loss = 0.3143\n",
            "t = 10, avg_loss = 0.3554\n",
            "t = 12, avg_loss = 0.2796\n",
            "t = 14, avg_loss = 0.2848\n",
            "t = 16, avg_loss = 0.2146\n",
            "t = 18, avg_loss = 0.2146\n",
            "t = 20, avg_loss = 0.3289\n",
            "t = 22, avg_loss = 0.2634\n",
            "t = 24, avg_loss = 0.2933\n",
            "Checking accuracy on test set\n",
            "Got 313 / 400 correct (78.25)\n",
            "acc = 0.782500\n",
            "Starting epoch 26 / 100\n",
            "t = 2, avg_loss = 0.3877\n",
            "t = 4, avg_loss = 0.2336\n",
            "t = 6, avg_loss = 0.3437\n",
            "t = 8, avg_loss = 0.3313\n",
            "t = 10, avg_loss = 0.3145\n",
            "t = 12, avg_loss = 0.3244\n",
            "t = 14, avg_loss = 0.3511\n",
            "t = 16, avg_loss = 0.2862\n",
            "t = 18, avg_loss = 0.2926\n",
            "t = 20, avg_loss = 0.2433\n",
            "t = 22, avg_loss = 0.3014\n",
            "t = 24, avg_loss = 0.3645\n",
            "Checking accuracy on test set\n",
            "Got 334 / 400 correct (83.50)\n",
            "acc = 0.835000\n",
            "Starting epoch 27 / 100\n",
            "t = 2, avg_loss = 0.3644\n",
            "t = 4, avg_loss = 0.3655\n",
            "t = 6, avg_loss = 0.2100\n",
            "t = 8, avg_loss = 0.4502\n",
            "t = 10, avg_loss = 0.3020\n",
            "t = 12, avg_loss = 0.3966\n",
            "t = 14, avg_loss = 0.3931\n",
            "t = 16, avg_loss = 0.3207\n",
            "t = 18, avg_loss = 0.3138\n",
            "t = 20, avg_loss = 0.2678\n",
            "t = 22, avg_loss = 0.3733\n",
            "t = 24, avg_loss = 0.2891\n",
            "Checking accuracy on test set\n",
            "Got 301 / 400 correct (75.25)\n",
            "acc = 0.752500\n",
            "Starting epoch 28 / 100\n",
            "t = 2, avg_loss = 0.3524\n",
            "t = 4, avg_loss = 0.1897\n",
            "t = 6, avg_loss = 0.2993\n",
            "t = 8, avg_loss = 0.2851\n",
            "t = 10, avg_loss = 0.2589\n",
            "t = 12, avg_loss = 0.3354\n",
            "t = 14, avg_loss = 0.3557\n",
            "t = 16, avg_loss = 0.2730\n",
            "t = 18, avg_loss = 0.4121\n",
            "t = 20, avg_loss = 0.3296\n",
            "t = 22, avg_loss = 0.2950\n",
            "t = 24, avg_loss = 0.2997\n",
            "Checking accuracy on test set\n",
            "Got 332 / 400 correct (83.00)\n",
            "acc = 0.830000\n",
            "Starting epoch 29 / 100\n",
            "t = 2, avg_loss = 0.4985\n",
            "t = 4, avg_loss = 0.3751\n",
            "t = 6, avg_loss = 0.3185\n",
            "t = 8, avg_loss = 0.3040\n",
            "t = 10, avg_loss = 0.2289\n",
            "t = 12, avg_loss = 0.3141\n",
            "t = 14, avg_loss = 0.3276\n",
            "t = 16, avg_loss = 0.2262\n",
            "t = 18, avg_loss = 0.3948\n",
            "t = 20, avg_loss = 0.2625\n",
            "t = 22, avg_loss = 0.3496\n",
            "t = 24, avg_loss = 0.3441\n",
            "Checking accuracy on test set\n",
            "Got 311 / 400 correct (77.75)\n",
            "acc = 0.777500\n",
            "Starting epoch 30 / 100\n",
            "t = 2, avg_loss = 0.4057\n",
            "t = 4, avg_loss = 0.2577\n",
            "t = 6, avg_loss = 0.2404\n",
            "t = 8, avg_loss = 0.2446\n",
            "t = 10, avg_loss = 0.2764\n",
            "t = 12, avg_loss = 0.2557\n",
            "t = 14, avg_loss = 0.2482\n",
            "t = 16, avg_loss = 0.2870\n",
            "t = 18, avg_loss = 0.3541\n",
            "t = 20, avg_loss = 0.2447\n",
            "t = 22, avg_loss = 0.3029\n",
            "t = 24, avg_loss = 0.3229\n",
            "Checking accuracy on test set\n",
            "Got 322 / 400 correct (80.50)\n",
            "acc = 0.805000\n",
            "Starting epoch 31 / 100\n",
            "t = 2, avg_loss = 0.3821\n",
            "t = 4, avg_loss = 0.2748\n",
            "t = 6, avg_loss = 0.3021\n",
            "t = 8, avg_loss = 0.2674\n",
            "t = 10, avg_loss = 0.2582\n",
            "t = 12, avg_loss = 0.3082\n",
            "t = 14, avg_loss = 0.2564\n",
            "t = 16, avg_loss = 0.3226\n",
            "t = 18, avg_loss = 0.2361\n",
            "t = 20, avg_loss = 0.2897\n",
            "t = 22, avg_loss = 0.2922\n",
            "t = 24, avg_loss = 0.2691\n",
            "Checking accuracy on test set\n",
            "Got 331 / 400 correct (82.75)\n",
            "acc = 0.827500\n",
            "Starting epoch 32 / 100\n",
            "t = 2, avg_loss = 0.2975\n",
            "t = 4, avg_loss = 0.2076\n",
            "t = 6, avg_loss = 0.2833\n",
            "t = 8, avg_loss = 0.2142\n",
            "t = 10, avg_loss = 0.2363\n",
            "t = 12, avg_loss = 0.3246\n",
            "t = 14, avg_loss = 0.2568\n",
            "t = 16, avg_loss = 0.2598\n",
            "t = 18, avg_loss = 0.2380\n",
            "t = 20, avg_loss = 0.2294\n",
            "t = 22, avg_loss = 0.4159\n",
            "t = 24, avg_loss = 0.3060\n",
            "Checking accuracy on test set\n",
            "Got 305 / 400 correct (76.25)\n",
            "acc = 0.762500\n",
            "Starting epoch 33 / 100\n",
            "t = 2, avg_loss = 0.4516\n",
            "t = 4, avg_loss = 0.2630\n",
            "t = 6, avg_loss = 0.3032\n",
            "t = 8, avg_loss = 0.1983\n",
            "t = 10, avg_loss = 0.2285\n",
            "t = 12, avg_loss = 0.2569\n",
            "t = 14, avg_loss = 0.2998\n",
            "t = 16, avg_loss = 0.2102\n",
            "t = 18, avg_loss = 0.2707\n",
            "t = 20, avg_loss = 0.3095\n",
            "t = 22, avg_loss = 0.2366\n",
            "t = 24, avg_loss = 0.3585\n",
            "Checking accuracy on test set\n",
            "Got 339 / 400 correct (84.75)\n",
            "acc = 0.847500\n",
            "Starting epoch 34 / 100\n",
            "t = 2, avg_loss = 0.4052\n",
            "t = 4, avg_loss = 0.2056\n",
            "t = 6, avg_loss = 0.3711\n",
            "t = 8, avg_loss = 0.2975\n",
            "t = 10, avg_loss = 0.3538\n",
            "t = 12, avg_loss = 0.1966\n",
            "t = 14, avg_loss = 0.2305\n",
            "t = 16, avg_loss = 0.2325\n",
            "t = 18, avg_loss = 0.2052\n",
            "t = 20, avg_loss = 0.2724\n",
            "t = 22, avg_loss = 0.2637\n",
            "t = 24, avg_loss = 0.2909\n",
            "Checking accuracy on test set\n",
            "Got 337 / 400 correct (84.25)\n",
            "acc = 0.842500\n",
            "Starting epoch 35 / 100\n",
            "t = 2, avg_loss = 0.3821\n",
            "t = 4, avg_loss = 0.3572\n",
            "t = 6, avg_loss = 0.2659\n",
            "t = 8, avg_loss = 0.3338\n",
            "t = 10, avg_loss = 0.3225\n",
            "t = 12, avg_loss = 0.2738\n",
            "t = 14, avg_loss = 0.2511\n",
            "t = 16, avg_loss = 0.2355\n",
            "t = 18, avg_loss = 0.2789\n",
            "t = 20, avg_loss = 0.2096\n",
            "t = 22, avg_loss = 0.2535\n",
            "t = 24, avg_loss = 0.3171\n",
            "Checking accuracy on test set\n",
            "Got 328 / 400 correct (82.00)\n",
            "acc = 0.820000\n",
            "Starting epoch 36 / 100\n",
            "t = 2, avg_loss = 0.3938\n",
            "t = 4, avg_loss = 0.2403\n",
            "t = 6, avg_loss = 0.2076\n",
            "t = 8, avg_loss = 0.2491\n",
            "t = 10, avg_loss = 0.2898\n",
            "t = 12, avg_loss = 0.2672\n",
            "t = 14, avg_loss = 0.2392\n",
            "t = 16, avg_loss = 0.2380\n",
            "t = 18, avg_loss = 0.2616\n",
            "t = 20, avg_loss = 0.2431\n",
            "t = 22, avg_loss = 0.2692\n",
            "t = 24, avg_loss = 0.2692\n",
            "Checking accuracy on test set\n",
            "Got 324 / 400 correct (81.00)\n",
            "acc = 0.810000\n",
            "Starting epoch 37 / 100\n",
            "t = 2, avg_loss = 0.3437\n",
            "t = 4, avg_loss = 0.2411\n",
            "t = 6, avg_loss = 0.2552\n",
            "t = 8, avg_loss = 0.2598\n",
            "t = 10, avg_loss = 0.2615\n",
            "t = 12, avg_loss = 0.2582\n",
            "t = 14, avg_loss = 0.2541\n",
            "t = 16, avg_loss = 0.2252\n",
            "t = 18, avg_loss = 0.2136\n",
            "t = 20, avg_loss = 0.3364\n",
            "t = 22, avg_loss = 0.2755\n",
            "t = 24, avg_loss = 0.2788\n",
            "Checking accuracy on test set\n",
            "Got 327 / 400 correct (81.75)\n",
            "acc = 0.817500\n",
            "Starting epoch 38 / 100\n",
            "t = 2, avg_loss = 0.3520\n",
            "t = 4, avg_loss = 0.2910\n",
            "t = 6, avg_loss = 0.2139\n",
            "t = 8, avg_loss = 0.2173\n",
            "t = 10, avg_loss = 0.2168\n",
            "t = 12, avg_loss = 0.2266\n",
            "t = 14, avg_loss = 0.2556\n",
            "t = 16, avg_loss = 0.2270\n",
            "t = 18, avg_loss = 0.2492\n",
            "t = 20, avg_loss = 0.2740\n",
            "t = 22, avg_loss = 0.2191\n",
            "t = 24, avg_loss = 0.2847\n",
            "Checking accuracy on test set\n",
            "Got 312 / 400 correct (78.00)\n",
            "acc = 0.780000\n",
            "Starting epoch 39 / 100\n",
            "t = 2, avg_loss = 0.4169\n",
            "t = 4, avg_loss = 0.2846\n",
            "t = 6, avg_loss = 0.2399\n",
            "t = 8, avg_loss = 0.2805\n",
            "t = 10, avg_loss = 0.2833\n",
            "t = 12, avg_loss = 0.2658\n",
            "t = 14, avg_loss = 0.1963\n",
            "t = 16, avg_loss = 0.2419\n",
            "t = 18, avg_loss = 0.2554\n",
            "t = 20, avg_loss = 0.3447\n",
            "t = 22, avg_loss = 0.2544\n",
            "t = 24, avg_loss = 0.2788\n",
            "Checking accuracy on test set\n",
            "Got 338 / 400 correct (84.50)\n",
            "acc = 0.845000\n",
            "Starting epoch 40 / 100\n",
            "t = 2, avg_loss = 0.2635\n",
            "t = 4, avg_loss = 0.2697\n",
            "t = 6, avg_loss = 0.2580\n",
            "t = 8, avg_loss = 0.2507\n",
            "t = 10, avg_loss = 0.2554\n",
            "t = 12, avg_loss = 0.1808\n",
            "t = 14, avg_loss = 0.2456\n",
            "t = 16, avg_loss = 0.2268\n",
            "t = 18, avg_loss = 0.2166\n",
            "t = 20, avg_loss = 0.2037\n",
            "t = 22, avg_loss = 0.2488\n",
            "t = 24, avg_loss = 0.2305\n",
            "Checking accuracy on test set\n",
            "Got 332 / 400 correct (83.00)\n",
            "acc = 0.830000\n",
            "Starting epoch 41 / 100\n",
            "t = 2, avg_loss = 0.3823\n",
            "t = 4, avg_loss = 0.1936\n",
            "t = 6, avg_loss = 0.2043\n",
            "t = 8, avg_loss = 0.2554\n",
            "t = 10, avg_loss = 0.1898\n",
            "t = 12, avg_loss = 0.2319\n",
            "t = 14, avg_loss = 0.1604\n",
            "t = 16, avg_loss = 0.2245\n",
            "t = 18, avg_loss = 0.1789\n",
            "t = 20, avg_loss = 0.2225\n",
            "t = 22, avg_loss = 0.2719\n",
            "t = 24, avg_loss = 0.1991\n",
            "Checking accuracy on test set\n",
            "Got 333 / 400 correct (83.25)\n",
            "acc = 0.832500\n",
            "Starting epoch 42 / 100\n",
            "t = 2, avg_loss = 0.3369\n",
            "t = 4, avg_loss = 0.2688\n",
            "t = 6, avg_loss = 0.2252\n",
            "t = 8, avg_loss = 0.2122\n",
            "t = 10, avg_loss = 0.1733\n",
            "t = 12, avg_loss = 0.2772\n",
            "t = 14, avg_loss = 0.2434\n",
            "t = 16, avg_loss = 0.2322\n",
            "t = 18, avg_loss = 0.2277\n",
            "t = 20, avg_loss = 0.1940\n",
            "t = 22, avg_loss = 0.2364\n",
            "t = 24, avg_loss = 0.2318\n",
            "Checking accuracy on test set\n",
            "Got 322 / 400 correct (80.50)\n",
            "acc = 0.805000\n",
            "Starting epoch 43 / 100\n",
            "t = 2, avg_loss = 0.3212\n",
            "t = 4, avg_loss = 0.2001\n",
            "t = 6, avg_loss = 0.2215\n",
            "t = 8, avg_loss = 0.2820\n",
            "t = 10, avg_loss = 0.2244\n",
            "t = 12, avg_loss = 0.1873\n",
            "t = 14, avg_loss = 0.2297\n",
            "t = 16, avg_loss = 0.2678\n",
            "t = 18, avg_loss = 0.2500\n",
            "t = 20, avg_loss = 0.2267\n",
            "t = 22, avg_loss = 0.1878\n",
            "t = 24, avg_loss = 0.1826\n",
            "Checking accuracy on test set\n",
            "Got 332 / 400 correct (83.00)\n",
            "acc = 0.830000\n",
            "Starting epoch 44 / 100\n",
            "t = 2, avg_loss = 0.2600\n",
            "t = 4, avg_loss = 0.2030\n",
            "t = 6, avg_loss = 0.2093\n",
            "t = 8, avg_loss = 0.2138\n",
            "t = 10, avg_loss = 0.2038\n",
            "t = 12, avg_loss = 0.2197\n",
            "t = 14, avg_loss = 0.1452\n",
            "t = 16, avg_loss = 0.2929\n",
            "t = 18, avg_loss = 0.2219\n",
            "t = 20, avg_loss = 0.1603\n",
            "t = 22, avg_loss = 0.2725\n",
            "t = 24, avg_loss = 0.2782\n",
            "Checking accuracy on test set\n",
            "Got 330 / 400 correct (82.50)\n",
            "acc = 0.825000\n",
            "Starting epoch 45 / 100\n",
            "t = 2, avg_loss = 0.4037\n",
            "t = 4, avg_loss = 0.2580\n",
            "t = 6, avg_loss = 0.2014\n",
            "t = 8, avg_loss = 0.2096\n",
            "t = 10, avg_loss = 0.2257\n",
            "t = 12, avg_loss = 0.1755\n",
            "t = 14, avg_loss = 0.2070\n",
            "t = 16, avg_loss = 0.1957\n",
            "t = 18, avg_loss = 0.2657\n",
            "t = 20, avg_loss = 0.2056\n",
            "t = 22, avg_loss = 0.1866\n",
            "t = 24, avg_loss = 0.1989\n",
            "Checking accuracy on test set\n",
            "Got 340 / 400 correct (85.00)\n",
            "acc = 0.850000\n",
            "Starting epoch 46 / 100\n",
            "t = 2, avg_loss = 0.3364\n",
            "t = 4, avg_loss = 0.1714\n",
            "t = 6, avg_loss = 0.2303\n",
            "t = 8, avg_loss = 0.1821\n",
            "t = 10, avg_loss = 0.2123\n",
            "t = 12, avg_loss = 0.2387\n",
            "t = 14, avg_loss = 0.2290\n",
            "t = 16, avg_loss = 0.2470\n",
            "t = 18, avg_loss = 0.1700\n",
            "t = 20, avg_loss = 0.2922\n",
            "t = 22, avg_loss = 0.2155\n",
            "t = 24, avg_loss = 0.2496\n",
            "Checking accuracy on test set\n",
            "Got 303 / 400 correct (75.75)\n",
            "acc = 0.757500\n",
            "Starting epoch 47 / 100\n",
            "t = 2, avg_loss = 0.2920\n",
            "t = 4, avg_loss = 0.2531\n",
            "t = 6, avg_loss = 0.1958\n",
            "t = 8, avg_loss = 0.1889\n",
            "t = 10, avg_loss = 0.1566\n",
            "t = 12, avg_loss = 0.1964\n",
            "t = 14, avg_loss = 0.2076\n",
            "t = 16, avg_loss = 0.2563\n",
            "t = 18, avg_loss = 0.1413\n",
            "t = 20, avg_loss = 0.1936\n",
            "t = 22, avg_loss = 0.2129\n",
            "t = 24, avg_loss = 0.1905\n",
            "Checking accuracy on test set\n",
            "Got 336 / 400 correct (84.00)\n",
            "acc = 0.840000\n",
            "Starting epoch 48 / 100\n",
            "t = 2, avg_loss = 0.2728\n",
            "t = 4, avg_loss = 0.1324\n",
            "t = 6, avg_loss = 0.2052\n",
            "t = 8, avg_loss = 0.1814\n",
            "t = 10, avg_loss = 0.1624\n",
            "t = 12, avg_loss = 0.2669\n",
            "t = 14, avg_loss = 0.2310\n",
            "t = 16, avg_loss = 0.2060\n",
            "t = 18, avg_loss = 0.2096\n",
            "t = 20, avg_loss = 0.3157\n",
            "t = 22, avg_loss = 0.1958\n",
            "t = 24, avg_loss = 0.1873\n",
            "Checking accuracy on test set\n",
            "Got 315 / 400 correct (78.75)\n",
            "acc = 0.787500\n",
            "Starting epoch 49 / 100\n",
            "t = 2, avg_loss = 0.3253\n",
            "t = 4, avg_loss = 0.1911\n",
            "t = 6, avg_loss = 0.2210\n",
            "t = 8, avg_loss = 0.1920\n",
            "t = 10, avg_loss = 0.2038\n",
            "t = 12, avg_loss = 0.2248\n",
            "t = 14, avg_loss = 0.1759\n",
            "t = 16, avg_loss = 0.2100\n",
            "t = 18, avg_loss = 0.2222\n",
            "t = 20, avg_loss = 0.2068\n",
            "t = 22, avg_loss = 0.2313\n",
            "t = 24, avg_loss = 0.2903\n",
            "Checking accuracy on test set\n",
            "Got 335 / 400 correct (83.75)\n",
            "acc = 0.837500\n",
            "Starting epoch 50 / 100\n",
            "t = 2, avg_loss = 0.2537\n",
            "t = 4, avg_loss = 0.2036\n",
            "t = 6, avg_loss = 0.2273\n",
            "t = 8, avg_loss = 0.2027\n",
            "t = 10, avg_loss = 0.2301\n",
            "t = 12, avg_loss = 0.1252\n",
            "t = 14, avg_loss = 0.2864\n",
            "t = 16, avg_loss = 0.2020\n",
            "t = 18, avg_loss = 0.2306\n",
            "t = 20, avg_loss = 0.3386\n",
            "t = 22, avg_loss = 0.2386\n",
            "t = 24, avg_loss = 0.2445\n",
            "Checking accuracy on test set\n",
            "Got 326 / 400 correct (81.50)\n",
            "acc = 0.815000\n",
            "Starting epoch 51 / 100\n",
            "t = 2, avg_loss = 0.3352\n",
            "t = 4, avg_loss = 0.2119\n",
            "t = 6, avg_loss = 0.1848\n",
            "t = 8, avg_loss = 0.2762\n",
            "t = 10, avg_loss = 0.1832\n",
            "t = 12, avg_loss = 0.1747\n",
            "t = 14, avg_loss = 0.1583\n",
            "t = 16, avg_loss = 0.2881\n",
            "t = 18, avg_loss = 0.2337\n",
            "t = 20, avg_loss = 0.1856\n",
            "t = 22, avg_loss = 0.2993\n",
            "t = 24, avg_loss = 0.2401\n",
            "Checking accuracy on test set\n",
            "Got 333 / 400 correct (83.25)\n",
            "acc = 0.832500\n",
            "Starting epoch 52 / 100\n",
            "t = 2, avg_loss = 0.3027\n",
            "t = 4, avg_loss = 0.1745\n",
            "t = 6, avg_loss = 0.1838\n",
            "t = 8, avg_loss = 0.2571\n",
            "t = 10, avg_loss = 0.1953\n",
            "t = 12, avg_loss = 0.2156\n",
            "t = 14, avg_loss = 0.1861\n",
            "t = 16, avg_loss = 0.2195\n",
            "t = 18, avg_loss = 0.1995\n",
            "t = 20, avg_loss = 0.2291\n",
            "t = 22, avg_loss = 0.2126\n",
            "t = 24, avg_loss = 0.1509\n",
            "Checking accuracy on test set\n",
            "Got 318 / 400 correct (79.50)\n",
            "acc = 0.795000\n",
            "Starting epoch 53 / 100\n",
            "t = 2, avg_loss = 0.3675\n",
            "t = 4, avg_loss = 0.2061\n",
            "t = 6, avg_loss = 0.2172\n",
            "t = 8, avg_loss = 0.1834\n",
            "t = 10, avg_loss = 0.2034\n",
            "t = 12, avg_loss = 0.1622\n",
            "t = 14, avg_loss = 0.2737\n",
            "t = 16, avg_loss = 0.1489\n",
            "t = 18, avg_loss = 0.2359\n",
            "t = 20, avg_loss = 0.1708\n",
            "t = 22, avg_loss = 0.1978\n",
            "t = 24, avg_loss = 0.2233\n",
            "Checking accuracy on test set\n",
            "Got 332 / 400 correct (83.00)\n",
            "acc = 0.830000\n",
            "Starting epoch 54 / 100\n",
            "t = 2, avg_loss = 0.2747\n",
            "t = 4, avg_loss = 0.1582\n",
            "t = 6, avg_loss = 0.1791\n",
            "t = 8, avg_loss = 0.2008\n",
            "t = 10, avg_loss = 0.2132\n",
            "t = 12, avg_loss = 0.2374\n",
            "t = 14, avg_loss = 0.1675\n",
            "t = 16, avg_loss = 0.1874\n",
            "t = 18, avg_loss = 0.2217\n",
            "t = 20, avg_loss = 0.2284\n",
            "t = 22, avg_loss = 0.1838\n",
            "t = 24, avg_loss = 0.1670\n",
            "Checking accuracy on test set\n",
            "Got 328 / 400 correct (82.00)\n",
            "acc = 0.820000\n",
            "Starting epoch 55 / 100\n",
            "t = 2, avg_loss = 0.2600\n",
            "t = 4, avg_loss = 0.1439\n",
            "t = 6, avg_loss = 0.2260\n",
            "t = 8, avg_loss = 0.2436\n",
            "t = 10, avg_loss = 0.1779\n",
            "t = 12, avg_loss = 0.1632\n",
            "t = 14, avg_loss = 0.1948\n",
            "t = 16, avg_loss = 0.1773\n",
            "t = 18, avg_loss = 0.2325\n",
            "t = 20, avg_loss = 0.1402\n",
            "t = 22, avg_loss = 0.2057\n",
            "t = 24, avg_loss = 0.2150\n",
            "Checking accuracy on test set\n",
            "Got 328 / 400 correct (82.00)\n",
            "acc = 0.820000\n",
            "Starting epoch 56 / 100\n",
            "t = 2, avg_loss = 0.3037\n",
            "t = 4, avg_loss = 0.1750\n",
            "t = 6, avg_loss = 0.1335\n",
            "t = 8, avg_loss = 0.2126\n",
            "t = 10, avg_loss = 0.2063\n",
            "t = 12, avg_loss = 0.2343\n",
            "t = 14, avg_loss = 0.1984\n",
            "t = 16, avg_loss = 0.2030\n",
            "t = 18, avg_loss = 0.2367\n",
            "t = 20, avg_loss = 0.1904\n",
            "t = 22, avg_loss = 0.2430\n",
            "t = 24, avg_loss = 0.2525\n",
            "Checking accuracy on test set\n",
            "Got 320 / 400 correct (80.00)\n",
            "acc = 0.800000\n",
            "Starting epoch 57 / 100\n",
            "t = 2, avg_loss = 0.2213\n",
            "t = 4, avg_loss = 0.1857\n",
            "t = 6, avg_loss = 0.2128\n",
            "t = 8, avg_loss = 0.2286\n",
            "t = 10, avg_loss = 0.1812\n",
            "t = 12, avg_loss = 0.1473\n",
            "t = 14, avg_loss = 0.2111\n",
            "t = 16, avg_loss = 0.1610\n",
            "t = 18, avg_loss = 0.1757\n",
            "t = 20, avg_loss = 0.2318\n",
            "t = 22, avg_loss = 0.1517\n",
            "t = 24, avg_loss = 0.1640\n",
            "Checking accuracy on test set\n",
            "Got 331 / 400 correct (82.75)\n",
            "acc = 0.827500\n",
            "Starting epoch 58 / 100\n",
            "t = 2, avg_loss = 0.3138\n",
            "t = 4, avg_loss = 0.1902\n",
            "t = 6, avg_loss = 0.1262\n",
            "t = 8, avg_loss = 0.1957\n",
            "t = 10, avg_loss = 0.1992\n",
            "t = 12, avg_loss = 0.1809\n",
            "t = 14, avg_loss = 0.1676\n",
            "t = 16, avg_loss = 0.2022\n",
            "t = 18, avg_loss = 0.1478\n",
            "t = 20, avg_loss = 0.1846\n",
            "t = 22, avg_loss = 0.1691\n",
            "t = 24, avg_loss = 0.1371\n",
            "Checking accuracy on test set\n",
            "Got 326 / 400 correct (81.50)\n",
            "acc = 0.815000\n",
            "Starting epoch 59 / 100\n",
            "t = 2, avg_loss = 0.3600\n",
            "t = 4, avg_loss = 0.1548\n",
            "t = 6, avg_loss = 0.1478\n",
            "t = 8, avg_loss = 0.2056\n",
            "t = 10, avg_loss = 0.2111\n",
            "t = 12, avg_loss = 0.2321\n",
            "t = 14, avg_loss = 0.1679\n",
            "t = 16, avg_loss = 0.2136\n",
            "t = 18, avg_loss = 0.2037\n",
            "t = 20, avg_loss = 0.1624\n",
            "t = 22, avg_loss = 0.1911\n",
            "t = 24, avg_loss = 0.2241\n",
            "Checking accuracy on test set\n",
            "Got 339 / 400 correct (84.75)\n",
            "acc = 0.847500\n",
            "Starting epoch 60 / 100\n",
            "t = 2, avg_loss = 0.2887\n",
            "t = 4, avg_loss = 0.2083\n",
            "t = 6, avg_loss = 0.2000\n",
            "t = 8, avg_loss = 0.1837\n",
            "t = 10, avg_loss = 0.2322\n",
            "t = 12, avg_loss = 0.1747\n",
            "t = 14, avg_loss = 0.2014\n",
            "t = 16, avg_loss = 0.1920\n",
            "t = 18, avg_loss = 0.2091\n",
            "t = 20, avg_loss = 0.1545\n",
            "t = 22, avg_loss = 0.2297\n",
            "t = 24, avg_loss = 0.1652\n",
            "Checking accuracy on test set\n",
            "Got 328 / 400 correct (82.00)\n",
            "acc = 0.820000\n",
            "Starting epoch 61 / 100\n",
            "t = 2, avg_loss = 0.3429\n",
            "t = 4, avg_loss = 0.1654\n",
            "t = 6, avg_loss = 0.1530\n",
            "t = 8, avg_loss = 0.1808\n",
            "t = 10, avg_loss = 0.2197\n",
            "t = 12, avg_loss = 0.2216\n",
            "t = 14, avg_loss = 0.2145\n",
            "t = 16, avg_loss = 0.1606\n",
            "t = 18, avg_loss = 0.2200\n",
            "t = 20, avg_loss = 0.2168\n",
            "t = 22, avg_loss = 0.1714\n",
            "t = 24, avg_loss = 0.1836\n",
            "Checking accuracy on test set\n",
            "Got 322 / 400 correct (80.50)\n",
            "acc = 0.805000\n",
            "Starting epoch 62 / 100\n",
            "t = 2, avg_loss = 0.2510\n",
            "t = 4, avg_loss = 0.1923\n",
            "t = 6, avg_loss = 0.1674\n",
            "t = 8, avg_loss = 0.2017\n",
            "t = 10, avg_loss = 0.1460\n",
            "t = 12, avg_loss = 0.1494\n",
            "t = 14, avg_loss = 0.1341\n",
            "t = 16, avg_loss = 0.2054\n",
            "t = 18, avg_loss = 0.1962\n",
            "t = 20, avg_loss = 0.1741\n",
            "t = 22, avg_loss = 0.2471\n",
            "t = 24, avg_loss = 0.1640\n",
            "Checking accuracy on test set\n",
            "Got 331 / 400 correct (82.75)\n",
            "acc = 0.827500\n",
            "Starting epoch 63 / 100\n",
            "t = 2, avg_loss = 0.2638\n",
            "t = 4, avg_loss = 0.1522\n",
            "t = 6, avg_loss = 0.1342\n",
            "t = 8, avg_loss = 0.1488\n",
            "t = 10, avg_loss = 0.1528\n",
            "t = 12, avg_loss = 0.1759\n",
            "t = 14, avg_loss = 0.1547\n",
            "t = 16, avg_loss = 0.1752\n",
            "t = 18, avg_loss = 0.1699\n",
            "t = 20, avg_loss = 0.1557\n",
            "t = 22, avg_loss = 0.3612\n",
            "t = 24, avg_loss = 0.2058\n",
            "Checking accuracy on test set\n",
            "Got 337 / 400 correct (84.25)\n",
            "acc = 0.842500\n",
            "Starting epoch 64 / 100\n",
            "t = 2, avg_loss = 0.2316\n",
            "t = 4, avg_loss = 0.1477\n",
            "t = 6, avg_loss = 0.1672\n",
            "t = 8, avg_loss = 0.1541\n",
            "t = 10, avg_loss = 0.1667\n",
            "t = 12, avg_loss = 0.2105\n",
            "t = 14, avg_loss = 0.1536\n",
            "t = 16, avg_loss = 0.1423\n",
            "t = 18, avg_loss = 0.1491\n",
            "t = 20, avg_loss = 0.1565\n",
            "t = 22, avg_loss = 0.1613\n",
            "t = 24, avg_loss = 0.1807\n",
            "Checking accuracy on test set\n",
            "Got 332 / 400 correct (83.00)\n",
            "acc = 0.830000\n",
            "Starting epoch 65 / 100\n",
            "t = 2, avg_loss = 0.2341\n",
            "t = 4, avg_loss = 0.1561\n",
            "t = 6, avg_loss = 0.1954\n",
            "t = 8, avg_loss = 0.1532\n",
            "t = 10, avg_loss = 0.1460\n",
            "t = 12, avg_loss = 0.1291\n",
            "t = 14, avg_loss = 0.1281\n",
            "t = 16, avg_loss = 0.1579\n",
            "t = 18, avg_loss = 0.1858\n",
            "t = 20, avg_loss = 0.1267\n",
            "t = 22, avg_loss = 0.1248\n",
            "t = 24, avg_loss = 0.1062\n",
            "Checking accuracy on test set\n",
            "Got 340 / 400 correct (85.00)\n",
            "acc = 0.850000\n",
            "Starting epoch 66 / 100\n",
            "t = 2, avg_loss = 0.3151\n",
            "t = 4, avg_loss = 0.1924\n",
            "t = 6, avg_loss = 0.1704\n",
            "t = 8, avg_loss = 0.1977\n",
            "t = 10, avg_loss = 0.1852\n",
            "t = 12, avg_loss = 0.1464\n",
            "t = 14, avg_loss = 0.1721\n",
            "t = 16, avg_loss = 0.1446\n",
            "t = 18, avg_loss = 0.1683\n",
            "t = 20, avg_loss = 0.1321\n",
            "t = 22, avg_loss = 0.1916\n",
            "t = 24, avg_loss = 0.1674\n",
            "Checking accuracy on test set\n",
            "Got 337 / 400 correct (84.25)\n",
            "acc = 0.842500\n",
            "Starting epoch 67 / 100\n",
            "t = 2, avg_loss = 0.1661\n",
            "t = 4, avg_loss = 0.1592\n",
            "t = 6, avg_loss = 0.1343\n",
            "t = 8, avg_loss = 0.1285\n",
            "t = 10, avg_loss = 0.1618\n",
            "t = 12, avg_loss = 0.1648\n",
            "t = 14, avg_loss = 0.1774\n",
            "t = 16, avg_loss = 0.1500\n",
            "t = 18, avg_loss = 0.2608\n",
            "t = 20, avg_loss = 0.2021\n",
            "t = 22, avg_loss = 0.2773\n",
            "t = 24, avg_loss = 0.2068\n",
            "Checking accuracy on test set\n",
            "Got 315 / 400 correct (78.75)\n",
            "acc = 0.787500\n",
            "Starting epoch 68 / 100\n",
            "t = 2, avg_loss = 0.3006\n",
            "t = 4, avg_loss = 0.1986\n",
            "t = 6, avg_loss = 0.1580\n",
            "t = 8, avg_loss = 0.1415\n",
            "t = 10, avg_loss = 0.2478\n",
            "t = 12, avg_loss = 0.1973\n",
            "t = 14, avg_loss = 0.1381\n",
            "t = 16, avg_loss = 0.1808\n",
            "t = 18, avg_loss = 0.1338\n",
            "t = 20, avg_loss = 0.1484\n",
            "t = 22, avg_loss = 0.1286\n",
            "t = 24, avg_loss = 0.1803\n",
            "Checking accuracy on test set\n",
            "Got 335 / 400 correct (83.75)\n",
            "acc = 0.837500\n",
            "Starting epoch 69 / 100\n",
            "t = 2, avg_loss = 0.2773\n",
            "t = 4, avg_loss = 0.1767\n",
            "t = 6, avg_loss = 0.1762\n",
            "t = 8, avg_loss = 0.1548\n",
            "t = 10, avg_loss = 0.1827\n",
            "t = 12, avg_loss = 0.1952\n",
            "t = 14, avg_loss = 0.1158\n",
            "t = 16, avg_loss = 0.1444\n",
            "t = 18, avg_loss = 0.1294\n",
            "t = 20, avg_loss = 0.2466\n",
            "t = 22, avg_loss = 0.1516\n",
            "t = 24, avg_loss = 0.1586\n",
            "Checking accuracy on test set\n",
            "Got 333 / 400 correct (83.25)\n",
            "acc = 0.832500\n",
            "Starting epoch 70 / 100\n",
            "t = 2, avg_loss = 0.2327\n",
            "t = 4, avg_loss = 0.1666\n",
            "t = 6, avg_loss = 0.1470\n",
            "t = 8, avg_loss = 0.1465\n",
            "t = 10, avg_loss = 0.2006\n",
            "t = 12, avg_loss = 0.1669\n",
            "t = 14, avg_loss = 0.2080\n",
            "t = 16, avg_loss = 0.1609\n",
            "t = 18, avg_loss = 0.1749\n",
            "t = 20, avg_loss = 0.1637\n",
            "t = 22, avg_loss = 0.1275\n",
            "t = 24, avg_loss = 0.1767\n",
            "Checking accuracy on test set\n",
            "Got 326 / 400 correct (81.50)\n",
            "acc = 0.815000\n",
            "Starting epoch 71 / 100\n",
            "t = 2, avg_loss = 0.2012\n",
            "t = 4, avg_loss = 0.1537\n",
            "t = 6, avg_loss = 0.1379\n",
            "t = 8, avg_loss = 0.2083\n",
            "t = 10, avg_loss = 0.1294\n",
            "t = 12, avg_loss = 0.1895\n",
            "t = 14, avg_loss = 0.1543\n",
            "t = 16, avg_loss = 0.2160\n",
            "t = 18, avg_loss = 0.1750\n",
            "t = 20, avg_loss = 0.1563\n",
            "t = 22, avg_loss = 0.1323\n",
            "t = 24, avg_loss = 0.2099\n",
            "Checking accuracy on test set\n",
            "Got 334 / 400 correct (83.50)\n",
            "acc = 0.835000\n",
            "Starting epoch 72 / 100\n",
            "t = 2, avg_loss = 0.2296\n",
            "t = 4, avg_loss = 0.2029\n",
            "t = 6, avg_loss = 0.1206\n",
            "t = 8, avg_loss = 0.1583\n",
            "t = 10, avg_loss = 0.1874\n",
            "t = 12, avg_loss = 0.1168\n",
            "t = 14, avg_loss = 0.1564\n",
            "t = 16, avg_loss = 0.1877\n",
            "t = 18, avg_loss = 0.1813\n",
            "t = 20, avg_loss = 0.1358\n",
            "t = 22, avg_loss = 0.2316\n",
            "t = 24, avg_loss = 0.1418\n",
            "Checking accuracy on test set\n",
            "Got 328 / 400 correct (82.00)\n",
            "acc = 0.820000\n",
            "Starting epoch 73 / 100\n",
            "t = 2, avg_loss = 0.2225\n",
            "t = 4, avg_loss = 0.1418\n",
            "t = 6, avg_loss = 0.1236\n",
            "t = 8, avg_loss = 0.1278\n",
            "t = 10, avg_loss = 0.1269\n",
            "t = 12, avg_loss = 0.1754\n",
            "t = 14, avg_loss = 0.1924\n",
            "t = 16, avg_loss = 0.1599\n",
            "t = 18, avg_loss = 0.2041\n",
            "t = 20, avg_loss = 0.1630\n",
            "t = 22, avg_loss = 0.1335\n",
            "t = 24, avg_loss = 0.1587\n",
            "Checking accuracy on test set\n",
            "Got 337 / 400 correct (84.25)\n",
            "acc = 0.842500\n",
            "Starting epoch 74 / 100\n",
            "t = 2, avg_loss = 0.2896\n",
            "t = 4, avg_loss = 0.1589\n",
            "t = 6, avg_loss = 0.1131\n",
            "t = 8, avg_loss = 0.1379\n",
            "t = 10, avg_loss = 0.1700\n",
            "t = 12, avg_loss = 0.1542\n",
            "t = 14, avg_loss = 0.1260\n",
            "t = 16, avg_loss = 0.1601\n",
            "t = 18, avg_loss = 0.1567\n",
            "t = 20, avg_loss = 0.1587\n",
            "t = 22, avg_loss = 0.1042\n",
            "t = 24, avg_loss = 0.1427\n",
            "Checking accuracy on test set\n",
            "Got 335 / 400 correct (83.75)\n",
            "acc = 0.837500\n",
            "Starting epoch 75 / 100\n",
            "t = 2, avg_loss = 0.1663\n",
            "t = 4, avg_loss = 0.1671\n",
            "t = 6, avg_loss = 0.2019\n",
            "t = 8, avg_loss = 0.1884\n",
            "t = 10, avg_loss = 0.1352\n",
            "t = 12, avg_loss = 0.1507\n",
            "t = 14, avg_loss = 0.1585\n",
            "t = 16, avg_loss = 0.1198\n",
            "t = 18, avg_loss = 0.2333\n",
            "t = 20, avg_loss = 0.1670\n",
            "t = 22, avg_loss = 0.1457\n",
            "t = 24, avg_loss = 0.1400\n",
            "Checking accuracy on test set\n",
            "Got 338 / 400 correct (84.50)\n",
            "acc = 0.845000\n",
            "Starting epoch 76 / 100\n",
            "t = 2, avg_loss = 0.2685\n",
            "t = 4, avg_loss = 0.1343\n",
            "t = 6, avg_loss = 0.1297\n",
            "t = 8, avg_loss = 0.2279\n",
            "t = 10, avg_loss = 0.1278\n",
            "t = 12, avg_loss = 0.2182\n",
            "t = 14, avg_loss = 0.1478\n",
            "t = 16, avg_loss = 0.1306\n",
            "t = 18, avg_loss = 0.1317\n",
            "t = 20, avg_loss = 0.1409\n",
            "t = 22, avg_loss = 0.1570\n",
            "t = 24, avg_loss = 0.1578\n",
            "Checking accuracy on test set\n",
            "Got 339 / 400 correct (84.75)\n",
            "acc = 0.847500\n",
            "Starting epoch 77 / 100\n",
            "t = 2, avg_loss = 0.2676\n",
            "t = 4, avg_loss = 0.1201\n",
            "t = 6, avg_loss = 0.1970\n",
            "t = 8, avg_loss = 0.1403\n",
            "t = 10, avg_loss = 0.1607\n",
            "t = 12, avg_loss = 0.1475\n",
            "t = 14, avg_loss = 0.0869\n",
            "t = 16, avg_loss = 0.1694\n",
            "t = 18, avg_loss = 0.1335\n",
            "t = 20, avg_loss = 0.1629\n",
            "t = 22, avg_loss = 0.1353\n",
            "t = 24, avg_loss = 0.1440\n",
            "Checking accuracy on test set\n",
            "Got 339 / 400 correct (84.75)\n",
            "acc = 0.847500\n",
            "Starting epoch 78 / 100\n",
            "t = 2, avg_loss = 0.1887\n",
            "t = 4, avg_loss = 0.1080\n",
            "t = 6, avg_loss = 0.1407\n",
            "t = 8, avg_loss = 0.1262\n",
            "t = 10, avg_loss = 0.1526\n",
            "t = 12, avg_loss = 0.1701\n",
            "t = 14, avg_loss = 0.1914\n",
            "t = 16, avg_loss = 0.1933\n",
            "t = 18, avg_loss = 0.1568\n",
            "t = 20, avg_loss = 0.2394\n",
            "t = 22, avg_loss = 0.1587\n",
            "t = 24, avg_loss = 0.1221\n",
            "Checking accuracy on test set\n",
            "Got 342 / 400 correct (85.50)\n",
            "acc = 0.855000\n",
            "Starting epoch 79 / 100\n",
            "t = 2, avg_loss = 0.2655\n",
            "t = 4, avg_loss = 0.1826\n",
            "t = 6, avg_loss = 0.1481\n",
            "t = 8, avg_loss = 0.2134\n",
            "t = 10, avg_loss = 0.1525\n",
            "t = 12, avg_loss = 0.1895\n",
            "t = 14, avg_loss = 0.1842\n",
            "t = 16, avg_loss = 0.1278\n",
            "t = 18, avg_loss = 0.1041\n",
            "t = 20, avg_loss = 0.2064\n",
            "t = 22, avg_loss = 0.1662\n",
            "t = 24, avg_loss = 0.1877\n",
            "Checking accuracy on test set\n",
            "Got 337 / 400 correct (84.25)\n",
            "acc = 0.842500\n",
            "Starting epoch 80 / 100\n",
            "t = 2, avg_loss = 0.2143\n",
            "t = 4, avg_loss = 0.1389\n",
            "t = 6, avg_loss = 0.1478\n",
            "t = 8, avg_loss = 0.1328\n",
            "t = 10, avg_loss = 0.2350\n",
            "t = 12, avg_loss = 0.2204\n",
            "t = 14, avg_loss = 0.1058\n",
            "t = 16, avg_loss = 0.1244\n",
            "t = 18, avg_loss = 0.1117\n",
            "t = 20, avg_loss = 0.1676\n",
            "t = 22, avg_loss = 0.1390\n",
            "t = 24, avg_loss = 0.1342\n",
            "Checking accuracy on test set\n",
            "Got 319 / 400 correct (79.75)\n",
            "acc = 0.797500\n",
            "Starting epoch 81 / 100\n",
            "t = 2, avg_loss = 0.3123\n",
            "t = 4, avg_loss = 0.1957\n",
            "t = 6, avg_loss = 0.1254\n",
            "t = 8, avg_loss = 0.1996\n",
            "t = 10, avg_loss = 0.1686\n",
            "t = 12, avg_loss = 0.1836\n",
            "t = 14, avg_loss = 0.1338\n",
            "t = 16, avg_loss = 0.1149\n",
            "t = 18, avg_loss = 0.2038\n",
            "t = 20, avg_loss = 0.1858\n",
            "t = 22, avg_loss = 0.1818\n",
            "t = 24, avg_loss = 0.1249\n",
            "Checking accuracy on test set\n",
            "Got 327 / 400 correct (81.75)\n",
            "acc = 0.817500\n",
            "Starting epoch 82 / 100\n",
            "t = 2, avg_loss = 0.2831\n",
            "t = 4, avg_loss = 0.0842\n",
            "t = 6, avg_loss = 0.1679\n",
            "t = 8, avg_loss = 0.1997\n",
            "t = 10, avg_loss = 0.1662\n",
            "t = 12, avg_loss = 0.1987\n",
            "t = 14, avg_loss = 0.1375\n",
            "t = 16, avg_loss = 0.1666\n",
            "t = 18, avg_loss = 0.1643\n",
            "t = 20, avg_loss = 0.2049\n",
            "t = 22, avg_loss = 0.1336\n",
            "t = 24, avg_loss = 0.1284\n",
            "Checking accuracy on test set\n",
            "Got 325 / 400 correct (81.25)\n",
            "acc = 0.812500\n",
            "Starting epoch 83 / 100\n",
            "t = 2, avg_loss = 0.2146\n",
            "t = 4, avg_loss = 0.1231\n",
            "t = 6, avg_loss = 0.0910\n",
            "t = 8, avg_loss = 0.1538\n",
            "t = 10, avg_loss = 0.1489\n",
            "t = 12, avg_loss = 0.1993\n",
            "t = 14, avg_loss = 0.1373\n",
            "t = 16, avg_loss = 0.0822\n",
            "t = 18, avg_loss = 0.2002\n",
            "t = 20, avg_loss = 0.2089\n",
            "t = 22, avg_loss = 0.1367\n",
            "t = 24, avg_loss = 0.1544\n",
            "Checking accuracy on test set\n",
            "Got 331 / 400 correct (82.75)\n",
            "acc = 0.827500\n",
            "Starting epoch 84 / 100\n",
            "t = 2, avg_loss = 0.2305\n",
            "t = 4, avg_loss = 0.1091\n",
            "t = 6, avg_loss = 0.1220\n",
            "t = 8, avg_loss = 0.1344\n",
            "t = 10, avg_loss = 0.1508\n",
            "t = 12, avg_loss = 0.1206\n",
            "t = 14, avg_loss = 0.1564\n",
            "t = 16, avg_loss = 0.1704\n",
            "t = 18, avg_loss = 0.1238\n",
            "t = 20, avg_loss = 0.1472\n",
            "t = 22, avg_loss = 0.1577\n",
            "t = 24, avg_loss = 0.0992\n",
            "Checking accuracy on test set\n",
            "Got 313 / 400 correct (78.25)\n",
            "acc = 0.782500\n",
            "Starting epoch 85 / 100\n",
            "t = 2, avg_loss = 0.1404\n",
            "t = 4, avg_loss = 0.1308\n",
            "t = 6, avg_loss = 0.0739\n",
            "t = 8, avg_loss = 0.1278\n",
            "t = 10, avg_loss = 0.1442\n",
            "t = 12, avg_loss = 0.1874\n",
            "t = 14, avg_loss = 0.2048\n",
            "t = 16, avg_loss = 0.0709\n",
            "t = 18, avg_loss = 0.1480\n",
            "t = 20, avg_loss = 0.1450\n",
            "t = 22, avg_loss = 0.1323\n",
            "t = 24, avg_loss = 0.1317\n",
            "Checking accuracy on test set\n",
            "Got 338 / 400 correct (84.50)\n",
            "acc = 0.845000\n",
            "Starting epoch 86 / 100\n",
            "t = 2, avg_loss = 0.2273\n",
            "t = 4, avg_loss = 0.1692\n",
            "t = 6, avg_loss = 0.1088\n",
            "t = 8, avg_loss = 0.1460\n",
            "t = 10, avg_loss = 0.1207\n",
            "t = 12, avg_loss = 0.1098\n",
            "t = 14, avg_loss = 0.1744\n",
            "t = 16, avg_loss = 0.1312\n",
            "t = 18, avg_loss = 0.0942\n",
            "t = 20, avg_loss = 0.1251\n",
            "t = 22, avg_loss = 0.1961\n",
            "t = 24, avg_loss = 0.1739\n",
            "Checking accuracy on test set\n",
            "Got 319 / 400 correct (79.75)\n",
            "acc = 0.797500\n",
            "Starting epoch 87 / 100\n",
            "t = 2, avg_loss = 0.2715\n",
            "t = 4, avg_loss = 0.1312\n",
            "t = 6, avg_loss = 0.0958\n",
            "t = 8, avg_loss = 0.1780\n",
            "t = 10, avg_loss = 0.2022\n",
            "t = 12, avg_loss = 0.1229\n",
            "t = 14, avg_loss = 0.1242\n",
            "t = 16, avg_loss = 0.1199\n",
            "t = 18, avg_loss = 0.1870\n",
            "t = 20, avg_loss = 0.1794\n",
            "t = 22, avg_loss = 0.1669\n",
            "t = 24, avg_loss = 0.1571\n",
            "Checking accuracy on test set\n",
            "Got 330 / 400 correct (82.50)\n",
            "acc = 0.825000\n",
            "Starting epoch 88 / 100\n",
            "t = 2, avg_loss = 0.3246\n",
            "t = 4, avg_loss = 0.1343\n",
            "t = 6, avg_loss = 0.1643\n",
            "t = 8, avg_loss = 0.0794\n",
            "t = 10, avg_loss = 0.1758\n",
            "t = 12, avg_loss = 0.1086\n",
            "t = 14, avg_loss = 0.1265\n",
            "t = 16, avg_loss = 0.1521\n",
            "t = 18, avg_loss = 0.1348\n",
            "t = 20, avg_loss = 0.1037\n",
            "t = 22, avg_loss = 0.1563\n",
            "t = 24, avg_loss = 0.1732\n",
            "Checking accuracy on test set\n",
            "Got 332 / 400 correct (83.00)\n",
            "acc = 0.830000\n",
            "Starting epoch 89 / 100\n",
            "t = 2, avg_loss = 0.2458\n",
            "t = 4, avg_loss = 0.1455\n",
            "t = 6, avg_loss = 0.1124\n",
            "t = 8, avg_loss = 0.1861\n",
            "t = 10, avg_loss = 0.1499\n",
            "t = 12, avg_loss = 0.1306\n",
            "t = 14, avg_loss = 0.1076\n",
            "t = 16, avg_loss = 0.1492\n",
            "t = 18, avg_loss = 0.1454\n",
            "t = 20, avg_loss = 0.1203\n",
            "t = 22, avg_loss = 0.2160\n",
            "t = 24, avg_loss = 0.1389\n",
            "Checking accuracy on test set\n",
            "Got 337 / 400 correct (84.25)\n",
            "acc = 0.842500\n",
            "Starting epoch 90 / 100\n",
            "t = 2, avg_loss = 0.1765\n",
            "t = 4, avg_loss = 0.1995\n",
            "t = 6, avg_loss = 0.1823\n",
            "t = 8, avg_loss = 0.0942\n",
            "t = 10, avg_loss = 0.1097\n",
            "t = 12, avg_loss = 0.1450\n",
            "t = 14, avg_loss = 0.1155\n",
            "t = 16, avg_loss = 0.1176\n",
            "t = 18, avg_loss = 0.1750\n",
            "t = 20, avg_loss = 0.1858\n",
            "t = 22, avg_loss = 0.1294\n",
            "t = 24, avg_loss = 0.1292\n",
            "Checking accuracy on test set\n",
            "Got 304 / 400 correct (76.00)\n",
            "acc = 0.760000\n",
            "Starting epoch 91 / 100\n",
            "t = 2, avg_loss = 0.2092\n",
            "t = 4, avg_loss = 0.0945\n",
            "t = 6, avg_loss = 0.1349\n",
            "t = 8, avg_loss = 0.1446\n",
            "t = 10, avg_loss = 0.1646\n",
            "t = 12, avg_loss = 0.0732\n",
            "t = 14, avg_loss = 0.1108\n",
            "t = 16, avg_loss = 0.1227\n",
            "t = 18, avg_loss = 0.1642\n",
            "t = 20, avg_loss = 0.1384\n",
            "t = 22, avg_loss = 0.1130\n",
            "t = 24, avg_loss = 0.1413\n",
            "Checking accuracy on test set\n",
            "Got 337 / 400 correct (84.25)\n",
            "acc = 0.842500\n",
            "Starting epoch 92 / 100\n",
            "t = 2, avg_loss = 0.2104\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-85c345babb3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcheck_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-87b2c8b33d30>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, loss_fn, optimizer, num_epochs, starting_from_epoch)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mx_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0my_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-50a9cd504daf>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m           \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"malignant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"malignant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   1856\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1858\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreducing_gap\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresample\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mNEAREST\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvoCj5uscUsz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_accurancy(acc_list):\n",
        "  plt.plot([i+1 for i in range((len(acc_list)))],acc_list)\n",
        "  print(\"Accurancy:\")\n",
        "  plt.show()\n",
        "\n",
        "def plot_loss_function(avg_loss_list):\n",
        "  plt.plot([print_every*batch_size*(i+1) for i in range((len(avg_loss_list)))],avg_loss_list)\n",
        "  print(\"Loss:\")\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WwgxQDJ-SWu",
        "colab_type": "code",
        "outputId": "bc737fa4-f5e3-406e-d586-e56cbae353a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        }
      },
      "source": [
        "plot_accurancy(acc_list)\n",
        "plot_loss_function(avg_loss_list)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accurancy:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inOiv4VC1ABr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "cf03289c-72ee-4516-a223-66300927bf10"
      },
      "source": [
        "check_accuracy(model_gpu, valid_loader)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking accuracy on test set\n",
            "Got 333 / 400 correct (83.25)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8325"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzuX5gLEeJfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def retry_from_backup():\n",
        "  model_gpu = model_base.type(gpu_dtype)\n",
        "  print(model_gpu)\n",
        "  loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) \n",
        "\n",
        "\n",
        "\n",
        "  checkpoint = torch.load(model_backup_path)\n",
        "  model_gpu.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  epoch = checkpoint['epoch']\n",
        "  loss = checkpoint['loss']\n",
        "  acc_list = checkpoint['acc_list']\n",
        "  #avg_loss_list = checkpoint['avg_loss_list']\n",
        "  print(\"starting from epoch: \" + str(epoch))\n",
        "  print(\"starting from loss: \" + str(loss))\n",
        "  print(acc_list)\n",
        "  \n",
        "  \n",
        "  train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=88, starting_from_epoch=epoch)\n",
        "  check_accuracy(model_gpu, valid_loader)\n",
        "\n",
        "  plot_accurancy(acc_list)\n",
        "  plot_loss_function(avg_loss_list)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--rQZKqOalaJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#retry_from_backup()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}