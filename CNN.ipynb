{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMYOQzqXWyjYRMKk/Hg+Ox6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamilo116/KNN/blob/master/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7ReM7FU-xs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import sys\n",
        "from PIL import Image\n",
        "from random import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "import timeit\n",
        "\n",
        "np.random.seed(4) \n",
        "torch.manual_seed(4) \n",
        "torch.cuda.manual_seed(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMOHez_kHZD6",
        "colab_type": "code",
        "outputId": "a595ab20-4bf5-414f-c8ee-9f1c9712f5ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYIMZ8QyYewD",
        "colab_type": "code",
        "outputId": "1ea9adf7-1209-4167-fa44-45a4090e4f07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "! git clone https://github.com/wang-chen/kervolution.git \n",
        "\n",
        "sys.path.append(\"kervolution/\")\n",
        "from kervolution import Kerv2d\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'kervolution' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b8P1NdXfVdX",
        "colab_type": "code",
        "outputId": "56c95a8c-922f-42d5-8a00-20f05148f8f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "MALIGNANT_DATASET = '/content/drive/My Drive/Colab_data/malignant/malignant/'\n",
        "BENIGN_DATASET = '/content/drive/My Drive/Colab_data/benign/benign/'\n",
        "DATA_FOLDER = '/content/drive/My Drive/Colab_data/'\n",
        "LIMIT_IMAGES_NUM = 700\n",
        "\n",
        "benign_file_list = sorted(os.listdir(BENIGN_DATASET))[:LIMIT_IMAGES_NUM]\n",
        "malignant_file_list = sorted(os.listdir(MALIGNANT_DATASET))[:LIMIT_IMAGES_NUM]\n",
        "\n",
        "shuffle(benign_file_list)\n",
        "shuffle(malignant_file_list)\n",
        "\n",
        "print(f\"Number of benign {len(benign_file_list)} images\")\n",
        "print(f\"Number of malignant {len(malignant_file_list)} images\")\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of benign 700 images\n",
            "Number of malignant 700 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGDQfal74BLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "benign_dict = {filename: 0 for filename in benign_file_list}\n",
        "malignant_dict = {filename: 1 for filename in malignant_file_list}\n",
        "img_class_dict = {**benign_dict , **malignant_dict}\n",
        "labeled_data = pd.Series(img_class_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvAAOqmVfVll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IsicDataset(Dataset):\n",
        "    def __init__(self, data_folder, labeled_data, \n",
        "                 transform=transforms.Compose([transforms.ToTensor()])):\n",
        "        self.labeled_data = labeled_data\n",
        "        self.transform = transform\n",
        "        self.data_folder = data_folder\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labeled_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        label = self.labeled_data[index]\n",
        "        if label == 0:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"benign\", \"benign\", index ))\n",
        "        else:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"malignant\", \"malignant\", index ))\n",
        "        image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "    @property\n",
        "    def labels(self):\n",
        "      return self.labeled_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSuYqjLAYrWA",
        "colab_type": "code",
        "outputId": "f7c437d2-11ed-4bd7-f1cd-1c06080c66c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        }
      },
      "source": [
        " \n",
        "dataset = IsicDataset(DATA_FOLDER, labeled_data, transform=data_transforms)\n",
        "print(dataset.labels)\n",
        "\n",
        "X_train, X_test = train_test_split(dataset.labels, test_size=0.2)\n",
        "print(\"number of training data: \",len(X_train))\n",
        "print(\"number of testing  data: \",len(X_test))\n",
        "\n",
        "train_sampler = SubsetRandomSampler(list(X_train.index))\n",
        "valid_sampler = SubsetRandomSampler(list(X_test.index))\n",
        "batch_size = 64\n",
        "num_workers = 0\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ISIC_0000581.jpeg    0\n",
            "ISIC_0000133.jpeg    0\n",
            "ISIC_0000322.jpeg    0\n",
            "ISIC_0000721.jpeg    0\n",
            "ISIC_0000062.jpeg    0\n",
            "                    ..\n",
            "ISIC_0010416.jpeg    1\n",
            "ISIC_0010917.jpeg    1\n",
            "ISIC_0011743.jpeg    1\n",
            "ISIC_0011528.jpeg    1\n",
            "ISIC_0000459.jpeg    1\n",
            "Length: 1400, dtype: int64\n",
            "number of training data:  1120\n",
            "number of testing  data:  280\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e8nFBR6Yug5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "def train(model, train_loader ,loss_fn, optimizer, num_epochs = 1):\n",
        "    total_loss =0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
        "        model.train()\n",
        "\n",
        "        for t, (x, y) in enumerate(train_loader):\n",
        "            x_var = Variable(x.type(gpu_dtype))\n",
        "            y_var = Variable(y.type(gpu_dtype).long())\n",
        "            scores = model(x_var)\n",
        "            loss = loss_fn(scores, y_var)\n",
        "            total_loss += loss.data\n",
        "            \n",
        "            if (t + 1) % print_every == 0:\n",
        "                avg_loss = total_loss/print_every\n",
        "                print('t = %d, avg_loss = %.4f' % (t + 1, avg_loss) )\n",
        "                avg_loss_list.append(avg_loss)\n",
        "                total_loss = 0\n",
        "                \n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        acc = check_accuracy(fixed_model_gpu, valid_loader)\n",
        "        print('acc = %f' %(acc))\n",
        "            \n",
        "def check_accuracy(model, loader):\n",
        "    print('Checking accuracy on test set')   \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval() \n",
        "    for x, y in loader:\n",
        "        x_var = Variable(x.type(gpu_dtype))\n",
        "\n",
        "        scores = model(x_var)\n",
        "        _, preds = scores.data.cpu().max(1)\n",
        "        num_correct += (preds == y).sum()\n",
        "        num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    acc_list.append(acc)\n",
        "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "    return acc\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggvpMu36Yw2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.size()\n",
        "        return x.view(N, -1)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgmexhBRZAK6",
        "colab_type": "code",
        "outputId": "a3e47cdc-62fb-40c3-e989-4989c7fbaf54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print_every = 1\n",
        "gpu_dtype = torch.cuda.FloatTensor\n",
        "\n",
        "out_1 = 64\n",
        "out_2 = 48\n",
        "out_3 = 32\n",
        "out_4 = 24\n",
        "out_5 = 16\n",
        "\n",
        "k_size_1 = 3\n",
        "padding_1 = 1\n",
        "in_channels = 3\n",
        "\n",
        "num_epochs = 50\n",
        "\n",
        "\n",
        "fixed_model_base = nn.Sequential( \n",
        "                nn.Conv2d(in_channels , out_1, padding= padding_1, kernel_size=k_size_1, stride=1), \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_1),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_1 , out_2, padding= padding_1, kernel_size=k_size_1, stride=1), \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_2),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_2 , out_3, padding= padding_1, kernel_size=k_size_1, stride=1),  \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_3),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_3 , out_4, padding= padding_1, kernel_size=k_size_1, stride=1), \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_4),\n",
        "                nn.Conv2d(out_4 , out_5, padding= padding_1, kernel_size=k_size_1, stride=1), \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_5),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Dropout(0.5),\n",
        "                Flatten(),\n",
        "                nn.Linear(256,64),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Linear(64,10),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Linear(10,2)\n",
        "            )\n",
        "fixed_model_gpu = fixed_model_base.type(gpu_dtype)\n",
        "print(fixed_model_gpu)\n",
        "loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(fixed_model_gpu.parameters(), lr = 0.0011, weight_decay=0) \n",
        "\n",
        "train(fixed_model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs)\n",
        "check_accuracy(fixed_model_gpu, valid_loader)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (4): Conv2d(64, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (5): ReLU(inplace=True)\n",
            "  (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (8): Conv2d(48, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (9): ReLU(inplace=True)\n",
            "  (10): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (12): Conv2d(32, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (13): ReLU(inplace=True)\n",
            "  (14): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (15): Conv2d(24, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (16): ReLU(inplace=True)\n",
            "  (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (19): Dropout(p=0.5, inplace=False)\n",
            "  (20): Flatten()\n",
            "  (21): Linear(in_features=256, out_features=64, bias=True)\n",
            "  (22): ReLU(inplace=True)\n",
            "  (23): Linear(in_features=64, out_features=10, bias=True)\n",
            "  (24): ReLU(inplace=True)\n",
            "  (25): Linear(in_features=10, out_features=2, bias=True)\n",
            ")\n",
            "Starting epoch 1 / 50\n",
            "t = 1, avg_loss = 0.7219\n",
            "t = 2, avg_loss = 0.7236\n",
            "t = 3, avg_loss = 0.6782\n",
            "t = 4, avg_loss = 0.6804\n",
            "t = 5, avg_loss = 0.6988\n",
            "t = 6, avg_loss = 0.7038\n",
            "t = 7, avg_loss = 0.6624\n",
            "t = 8, avg_loss = 0.6771\n",
            "t = 9, avg_loss = 0.6158\n",
            "t = 10, avg_loss = 0.6600\n",
            "t = 11, avg_loss = 0.6253\n",
            "t = 12, avg_loss = 0.5874\n",
            "t = 13, avg_loss = 0.6304\n",
            "t = 14, avg_loss = 0.5518\n",
            "t = 15, avg_loss = 0.5433\n",
            "t = 16, avg_loss = 0.5474\n",
            "t = 17, avg_loss = 0.5135\n",
            "t = 18, avg_loss = 0.5397\n",
            "Checking accuracy on test set\n",
            "Got 137 / 280 correct (48.93)\n",
            "acc = 0.489286\n",
            "Starting epoch 2 / 50\n",
            "t = 1, avg_loss = 0.4845\n",
            "t = 2, avg_loss = 0.5336\n",
            "t = 3, avg_loss = 0.4663\n",
            "t = 4, avg_loss = 0.4925\n",
            "t = 5, avg_loss = 0.4621\n",
            "t = 6, avg_loss = 0.4366\n",
            "t = 7, avg_loss = 0.4465\n",
            "t = 8, avg_loss = 0.4937\n",
            "t = 9, avg_loss = 0.4194\n",
            "t = 10, avg_loss = 0.4880\n",
            "t = 11, avg_loss = 0.3979\n",
            "t = 12, avg_loss = 0.4028\n",
            "t = 13, avg_loss = 0.3634\n",
            "t = 14, avg_loss = 0.4298\n",
            "t = 15, avg_loss = 0.3686\n",
            "t = 16, avg_loss = 0.3929\n",
            "t = 17, avg_loss = 0.6267\n",
            "t = 18, avg_loss = 0.2471\n",
            "Checking accuracy on test set\n",
            "Got 158 / 280 correct (56.43)\n",
            "acc = 0.564286\n",
            "Starting epoch 3 / 50\n",
            "t = 1, avg_loss = 0.4205\n",
            "t = 2, avg_loss = 0.4281\n",
            "t = 3, avg_loss = 0.3928\n",
            "t = 4, avg_loss = 0.3562\n",
            "t = 5, avg_loss = 0.4281\n",
            "t = 6, avg_loss = 0.3791\n",
            "t = 7, avg_loss = 0.3961\n",
            "t = 8, avg_loss = 0.3475\n",
            "t = 9, avg_loss = 0.4608\n",
            "t = 10, avg_loss = 0.3822\n",
            "t = 11, avg_loss = 0.3217\n",
            "t = 12, avg_loss = 0.4335\n",
            "t = 13, avg_loss = 0.3816\n",
            "t = 14, avg_loss = 0.4228\n",
            "t = 15, avg_loss = 0.3794\n",
            "t = 16, avg_loss = 0.6010\n",
            "t = 17, avg_loss = 0.4015\n",
            "t = 18, avg_loss = 0.4033\n",
            "Checking accuracy on test set\n",
            "Got 212 / 280 correct (75.71)\n",
            "acc = 0.757143\n",
            "Starting epoch 4 / 50\n",
            "t = 1, avg_loss = 0.3816\n",
            "t = 2, avg_loss = 0.4286\n",
            "t = 3, avg_loss = 0.3721\n",
            "t = 4, avg_loss = 0.3404\n",
            "t = 5, avg_loss = 0.3278\n",
            "t = 6, avg_loss = 0.3759\n",
            "t = 7, avg_loss = 0.3814\n",
            "t = 8, avg_loss = 0.4137\n",
            "t = 9, avg_loss = 0.3175\n",
            "t = 10, avg_loss = 0.3454\n",
            "t = 11, avg_loss = 0.4470\n",
            "t = 12, avg_loss = 0.4047\n",
            "t = 13, avg_loss = 0.4497\n",
            "t = 14, avg_loss = 0.4168\n",
            "t = 15, avg_loss = 0.4772\n",
            "t = 16, avg_loss = 0.5010\n",
            "t = 17, avg_loss = 0.3546\n",
            "t = 18, avg_loss = 0.3978\n",
            "Checking accuracy on test set\n",
            "Got 233 / 280 correct (83.21)\n",
            "acc = 0.832143\n",
            "Starting epoch 5 / 50\n",
            "t = 1, avg_loss = 0.2833\n",
            "t = 2, avg_loss = 0.3106\n",
            "t = 3, avg_loss = 0.3793\n",
            "t = 4, avg_loss = 0.4409\n",
            "t = 5, avg_loss = 0.4229\n",
            "t = 6, avg_loss = 0.3558\n",
            "t = 7, avg_loss = 0.4953\n",
            "t = 8, avg_loss = 0.3827\n",
            "t = 9, avg_loss = 0.4615\n",
            "t = 10, avg_loss = 0.4547\n",
            "t = 11, avg_loss = 0.4238\n",
            "t = 12, avg_loss = 0.3522\n",
            "t = 13, avg_loss = 0.3824\n",
            "t = 14, avg_loss = 0.3218\n",
            "t = 15, avg_loss = 0.3204\n",
            "t = 16, avg_loss = 0.3311\n",
            "t = 17, avg_loss = 0.2875\n",
            "t = 18, avg_loss = 0.2352\n",
            "Checking accuracy on test set\n",
            "Got 221 / 280 correct (78.93)\n",
            "acc = 0.789286\n",
            "Starting epoch 6 / 50\n",
            "t = 1, avg_loss = 0.3647\n",
            "t = 2, avg_loss = 0.3995\n",
            "t = 3, avg_loss = 0.2984\n",
            "t = 4, avg_loss = 0.3552\n",
            "t = 5, avg_loss = 0.3802\n",
            "t = 6, avg_loss = 0.2991\n",
            "t = 7, avg_loss = 0.3471\n",
            "t = 8, avg_loss = 0.2652\n",
            "t = 9, avg_loss = 0.3672\n",
            "t = 10, avg_loss = 0.4635\n",
            "t = 11, avg_loss = 0.4065\n",
            "t = 12, avg_loss = 0.3179\n",
            "t = 13, avg_loss = 0.3613\n",
            "t = 14, avg_loss = 0.3955\n",
            "t = 15, avg_loss = 0.3656\n",
            "t = 16, avg_loss = 0.4684\n",
            "t = 17, avg_loss = 0.4042\n",
            "t = 18, avg_loss = 0.2564\n",
            "Checking accuracy on test set\n",
            "Got 226 / 280 correct (80.71)\n",
            "acc = 0.807143\n",
            "Starting epoch 7 / 50\n",
            "t = 1, avg_loss = 0.3540\n",
            "t = 2, avg_loss = 0.3940\n",
            "t = 3, avg_loss = 0.2826\n",
            "t = 4, avg_loss = 0.3180\n",
            "t = 5, avg_loss = 0.3730\n",
            "t = 6, avg_loss = 0.3463\n",
            "t = 7, avg_loss = 0.3458\n",
            "t = 8, avg_loss = 0.2783\n",
            "t = 9, avg_loss = 0.4155\n",
            "t = 10, avg_loss = 0.3385\n",
            "t = 11, avg_loss = 0.3407\n",
            "t = 12, avg_loss = 0.3569\n",
            "t = 13, avg_loss = 0.3658\n",
            "t = 14, avg_loss = 0.2730\n",
            "t = 15, avg_loss = 0.2652\n",
            "t = 16, avg_loss = 0.3021\n",
            "t = 17, avg_loss = 0.4532\n",
            "t = 18, avg_loss = 0.3659\n",
            "Checking accuracy on test set\n",
            "Got 236 / 280 correct (84.29)\n",
            "acc = 0.842857\n",
            "Starting epoch 8 / 50\n",
            "t = 1, avg_loss = 0.2525\n",
            "t = 2, avg_loss = 0.3276\n",
            "t = 3, avg_loss = 0.3650\n",
            "t = 4, avg_loss = 0.5045\n",
            "t = 5, avg_loss = 0.3664\n",
            "t = 6, avg_loss = 0.3787\n",
            "t = 7, avg_loss = 0.2985\n",
            "t = 8, avg_loss = 0.3330\n",
            "t = 9, avg_loss = 0.3234\n",
            "t = 10, avg_loss = 0.3175\n",
            "t = 11, avg_loss = 0.4021\n",
            "t = 12, avg_loss = 0.3364\n",
            "t = 13, avg_loss = 0.4022\n",
            "t = 14, avg_loss = 0.3405\n",
            "t = 15, avg_loss = 0.3626\n",
            "t = 16, avg_loss = 0.3951\n",
            "t = 17, avg_loss = 0.2190\n",
            "t = 18, avg_loss = 0.2375\n",
            "Checking accuracy on test set\n",
            "Got 225 / 280 correct (80.36)\n",
            "acc = 0.803571\n",
            "Starting epoch 9 / 50\n",
            "t = 1, avg_loss = 0.3077\n",
            "t = 2, avg_loss = 0.4138\n",
            "t = 3, avg_loss = 0.2404\n",
            "t = 4, avg_loss = 0.3208\n",
            "t = 5, avg_loss = 0.4306\n",
            "t = 6, avg_loss = 0.2733\n",
            "t = 7, avg_loss = 0.3561\n",
            "t = 8, avg_loss = 0.2362\n",
            "t = 9, avg_loss = 0.3540\n",
            "t = 10, avg_loss = 0.2883\n",
            "t = 11, avg_loss = 0.2958\n",
            "t = 12, avg_loss = 0.3660\n",
            "t = 13, avg_loss = 0.2524\n",
            "t = 14, avg_loss = 0.2815\n",
            "t = 15, avg_loss = 0.3119\n",
            "t = 16, avg_loss = 0.4002\n",
            "t = 17, avg_loss = 0.5270\n",
            "t = 18, avg_loss = 0.2692\n",
            "Checking accuracy on test set\n",
            "Got 227 / 280 correct (81.07)\n",
            "acc = 0.810714\n",
            "Starting epoch 10 / 50\n",
            "t = 1, avg_loss = 0.2100\n",
            "t = 2, avg_loss = 0.3300\n",
            "t = 3, avg_loss = 0.2796\n",
            "t = 4, avg_loss = 0.2911\n",
            "t = 5, avg_loss = 0.3361\n",
            "t = 6, avg_loss = 0.4848\n",
            "t = 7, avg_loss = 0.3197\n",
            "t = 8, avg_loss = 0.3148\n",
            "t = 9, avg_loss = 0.3763\n",
            "t = 10, avg_loss = 0.2075\n",
            "t = 11, avg_loss = 0.2617\n",
            "t = 12, avg_loss = 0.3931\n",
            "t = 13, avg_loss = 0.2841\n",
            "t = 14, avg_loss = 0.3287\n",
            "t = 15, avg_loss = 0.2810\n",
            "t = 16, avg_loss = 0.2746\n",
            "t = 17, avg_loss = 0.5241\n",
            "t = 18, avg_loss = 0.3141\n",
            "Checking accuracy on test set\n",
            "Got 233 / 280 correct (83.21)\n",
            "acc = 0.832143\n",
            "Starting epoch 11 / 50\n",
            "t = 1, avg_loss = 0.3679\n",
            "t = 2, avg_loss = 0.2381\n",
            "t = 3, avg_loss = 0.3573\n",
            "t = 4, avg_loss = 0.2496\n",
            "t = 5, avg_loss = 0.2839\n",
            "t = 6, avg_loss = 0.3567\n",
            "t = 7, avg_loss = 0.2658\n",
            "t = 8, avg_loss = 0.4013\n",
            "t = 9, avg_loss = 0.2967\n",
            "t = 10, avg_loss = 0.4234\n",
            "t = 11, avg_loss = 0.2468\n",
            "t = 12, avg_loss = 0.1770\n",
            "t = 13, avg_loss = 0.2710\n",
            "t = 14, avg_loss = 0.4185\n",
            "t = 15, avg_loss = 0.3369\n",
            "t = 16, avg_loss = 0.4296\n",
            "t = 17, avg_loss = 0.2795\n",
            "t = 18, avg_loss = 0.3895\n",
            "Checking accuracy on test set\n",
            "Got 239 / 280 correct (85.36)\n",
            "acc = 0.853571\n",
            "Starting epoch 12 / 50\n",
            "t = 1, avg_loss = 0.3878\n",
            "t = 2, avg_loss = 0.2169\n",
            "t = 3, avg_loss = 0.2603\n",
            "t = 4, avg_loss = 0.3759\n",
            "t = 5, avg_loss = 0.2388\n",
            "t = 6, avg_loss = 0.2818\n",
            "t = 7, avg_loss = 0.4008\n",
            "t = 8, avg_loss = 0.3552\n",
            "t = 9, avg_loss = 0.3910\n",
            "t = 10, avg_loss = 0.2168\n",
            "t = 11, avg_loss = 0.2948\n",
            "t = 12, avg_loss = 0.2802\n",
            "t = 13, avg_loss = 0.3277\n",
            "t = 14, avg_loss = 0.3190\n",
            "t = 15, avg_loss = 0.2697\n",
            "t = 16, avg_loss = 0.2418\n",
            "t = 17, avg_loss = 0.4089\n",
            "t = 18, avg_loss = 0.3356\n",
            "Checking accuracy on test set\n",
            "Got 230 / 280 correct (82.14)\n",
            "acc = 0.821429\n",
            "Starting epoch 13 / 50\n",
            "t = 1, avg_loss = 0.2297\n",
            "t = 2, avg_loss = 0.3492\n",
            "t = 3, avg_loss = 0.3521\n",
            "t = 4, avg_loss = 0.3337\n",
            "t = 5, avg_loss = 0.3114\n",
            "t = 6, avg_loss = 0.3912\n",
            "t = 7, avg_loss = 0.3715\n",
            "t = 8, avg_loss = 0.3637\n",
            "t = 9, avg_loss = 0.3220\n",
            "t = 10, avg_loss = 0.2418\n",
            "t = 11, avg_loss = 0.3720\n",
            "t = 12, avg_loss = 0.3700\n",
            "t = 13, avg_loss = 0.4714\n",
            "t = 14, avg_loss = 0.2712\n",
            "t = 15, avg_loss = 0.2401\n",
            "t = 16, avg_loss = 0.2981\n",
            "t = 17, avg_loss = 0.2934\n",
            "t = 18, avg_loss = 0.1816\n",
            "Checking accuracy on test set\n",
            "Got 236 / 280 correct (84.29)\n",
            "acc = 0.842857\n",
            "Starting epoch 14 / 50\n",
            "t = 1, avg_loss = 0.3772\n",
            "t = 2, avg_loss = 0.2174\n",
            "t = 3, avg_loss = 0.2777\n",
            "t = 4, avg_loss = 0.2948\n",
            "t = 5, avg_loss = 0.3467\n",
            "t = 6, avg_loss = 0.3834\n",
            "t = 7, avg_loss = 0.4249\n",
            "t = 8, avg_loss = 0.4758\n",
            "t = 9, avg_loss = 0.3008\n",
            "t = 10, avg_loss = 0.3054\n",
            "t = 11, avg_loss = 0.2570\n",
            "t = 12, avg_loss = 0.4299\n",
            "t = 13, avg_loss = 0.3215\n",
            "t = 14, avg_loss = 0.3306\n",
            "t = 15, avg_loss = 0.2841\n",
            "t = 16, avg_loss = 0.2894\n",
            "t = 17, avg_loss = 0.2597\n",
            "t = 18, avg_loss = 0.3243\n",
            "Checking accuracy on test set\n",
            "Got 241 / 280 correct (86.07)\n",
            "acc = 0.860714\n",
            "Starting epoch 15 / 50\n",
            "t = 1, avg_loss = 0.2437\n",
            "t = 2, avg_loss = 0.2872\n",
            "t = 3, avg_loss = 0.4193\n",
            "t = 4, avg_loss = 0.2078\n",
            "t = 5, avg_loss = 0.2531\n",
            "t = 6, avg_loss = 0.1986\n",
            "t = 7, avg_loss = 0.4112\n",
            "t = 8, avg_loss = 0.2786\n",
            "t = 9, avg_loss = 0.3075\n",
            "t = 10, avg_loss = 0.1798\n",
            "t = 11, avg_loss = 0.1835\n",
            "t = 12, avg_loss = 0.3493\n",
            "t = 13, avg_loss = 0.2134\n",
            "t = 14, avg_loss = 0.3057\n",
            "t = 15, avg_loss = 0.3965\n",
            "t = 16, avg_loss = 0.2379\n",
            "t = 17, avg_loss = 0.3330\n",
            "t = 18, avg_loss = 0.2095\n",
            "Checking accuracy on test set\n",
            "Got 236 / 280 correct (84.29)\n",
            "acc = 0.842857\n",
            "Starting epoch 16 / 50\n",
            "t = 1, avg_loss = 0.2111\n",
            "t = 2, avg_loss = 0.3041\n",
            "t = 3, avg_loss = 0.3580\n",
            "t = 4, avg_loss = 0.3155\n",
            "t = 5, avg_loss = 0.1573\n",
            "t = 6, avg_loss = 0.2446\n",
            "t = 7, avg_loss = 0.2588\n",
            "t = 8, avg_loss = 0.2081\n",
            "t = 9, avg_loss = 0.2056\n",
            "t = 10, avg_loss = 0.2557\n",
            "t = 11, avg_loss = 0.3573\n",
            "t = 12, avg_loss = 0.3515\n",
            "t = 13, avg_loss = 0.3385\n",
            "t = 14, avg_loss = 0.2247\n",
            "t = 15, avg_loss = 0.3445\n",
            "t = 16, avg_loss = 0.1869\n",
            "t = 17, avg_loss = 0.4326\n",
            "t = 18, avg_loss = 0.4130\n",
            "Checking accuracy on test set\n",
            "Got 244 / 280 correct (87.14)\n",
            "acc = 0.871429\n",
            "Starting epoch 17 / 50\n",
            "t = 1, avg_loss = 0.2974\n",
            "t = 2, avg_loss = 0.2345\n",
            "t = 3, avg_loss = 0.3280\n",
            "t = 4, avg_loss = 0.3230\n",
            "t = 5, avg_loss = 0.2392\n",
            "t = 6, avg_loss = 0.2185\n",
            "t = 7, avg_loss = 0.2457\n",
            "t = 8, avg_loss = 0.2250\n",
            "t = 9, avg_loss = 0.3414\n",
            "t = 10, avg_loss = 0.2993\n",
            "t = 11, avg_loss = 0.2790\n",
            "t = 12, avg_loss = 0.2938\n",
            "t = 13, avg_loss = 0.4235\n",
            "t = 14, avg_loss = 0.3441\n",
            "t = 15, avg_loss = 0.1773\n",
            "t = 16, avg_loss = 0.3598\n",
            "t = 17, avg_loss = 0.2172\n",
            "t = 18, avg_loss = 0.4321\n",
            "Checking accuracy on test set\n",
            "Got 231 / 280 correct (82.50)\n",
            "acc = 0.825000\n",
            "Starting epoch 18 / 50\n",
            "t = 1, avg_loss = 0.3752\n",
            "t = 2, avg_loss = 0.2606\n",
            "t = 3, avg_loss = 0.2729\n",
            "t = 4, avg_loss = 0.2443\n",
            "t = 5, avg_loss = 0.3208\n",
            "t = 6, avg_loss = 0.2226\n",
            "t = 7, avg_loss = 0.2265\n",
            "t = 8, avg_loss = 0.2360\n",
            "t = 9, avg_loss = 0.2433\n",
            "t = 10, avg_loss = 0.2728\n",
            "t = 11, avg_loss = 0.3637\n",
            "t = 12, avg_loss = 0.3929\n",
            "t = 13, avg_loss = 0.2451\n",
            "t = 14, avg_loss = 0.3927\n",
            "t = 15, avg_loss = 0.2963\n",
            "t = 16, avg_loss = 0.3236\n",
            "t = 17, avg_loss = 0.4127\n",
            "t = 18, avg_loss = 0.2872\n",
            "Checking accuracy on test set\n",
            "Got 244 / 280 correct (87.14)\n",
            "acc = 0.871429\n",
            "Starting epoch 19 / 50\n",
            "t = 1, avg_loss = 0.2312\n",
            "t = 2, avg_loss = 0.2366\n",
            "t = 3, avg_loss = 0.2105\n",
            "t = 4, avg_loss = 0.3091\n",
            "t = 5, avg_loss = 0.2106\n",
            "t = 6, avg_loss = 0.2694\n",
            "t = 7, avg_loss = 0.2291\n",
            "t = 8, avg_loss = 0.3257\n",
            "t = 9, avg_loss = 0.2862\n",
            "t = 10, avg_loss = 0.3381\n",
            "t = 11, avg_loss = 0.2623\n",
            "t = 12, avg_loss = 0.2180\n",
            "t = 13, avg_loss = 0.4115\n",
            "t = 14, avg_loss = 0.2550\n",
            "t = 15, avg_loss = 0.2233\n",
            "t = 16, avg_loss = 0.1976\n",
            "t = 17, avg_loss = 0.2324\n",
            "t = 18, avg_loss = 0.2556\n",
            "Checking accuracy on test set\n",
            "Got 235 / 280 correct (83.93)\n",
            "acc = 0.839286\n",
            "Starting epoch 20 / 50\n",
            "t = 1, avg_loss = 0.2930\n",
            "t = 2, avg_loss = 0.3056\n",
            "t = 3, avg_loss = 0.1584\n",
            "t = 4, avg_loss = 0.2904\n",
            "t = 5, avg_loss = 0.2494\n",
            "t = 6, avg_loss = 0.5746\n",
            "t = 7, avg_loss = 0.2720\n",
            "t = 8, avg_loss = 0.2145\n",
            "t = 9, avg_loss = 0.2413\n",
            "t = 10, avg_loss = 0.2982\n",
            "t = 11, avg_loss = 0.2506\n",
            "t = 12, avg_loss = 0.2266\n",
            "t = 13, avg_loss = 0.3237\n",
            "t = 14, avg_loss = 0.2610\n",
            "t = 15, avg_loss = 0.3311\n",
            "t = 16, avg_loss = 0.2856\n",
            "t = 17, avg_loss = 0.2711\n",
            "t = 18, avg_loss = 0.3083\n",
            "Checking accuracy on test set\n",
            "Got 235 / 280 correct (83.93)\n",
            "acc = 0.839286\n",
            "Starting epoch 21 / 50\n",
            "t = 1, avg_loss = 0.2399\n",
            "t = 2, avg_loss = 0.3479\n",
            "t = 3, avg_loss = 0.2797\n",
            "t = 4, avg_loss = 0.2074\n",
            "t = 5, avg_loss = 0.2733\n",
            "t = 6, avg_loss = 0.3047\n",
            "t = 7, avg_loss = 0.2612\n",
            "t = 8, avg_loss = 0.2461\n",
            "t = 9, avg_loss = 0.3816\n",
            "t = 10, avg_loss = 0.3054\n",
            "t = 11, avg_loss = 0.3374\n",
            "t = 12, avg_loss = 0.1973\n",
            "t = 13, avg_loss = 0.2732\n",
            "t = 14, avg_loss = 0.2469\n",
            "t = 15, avg_loss = 0.2063\n",
            "t = 16, avg_loss = 0.3300\n",
            "t = 17, avg_loss = 0.4190\n",
            "t = 18, avg_loss = 0.2558\n",
            "Checking accuracy on test set\n",
            "Got 243 / 280 correct (86.79)\n",
            "acc = 0.867857\n",
            "Starting epoch 22 / 50\n",
            "t = 1, avg_loss = 0.2646\n",
            "t = 2, avg_loss = 0.2673\n",
            "t = 3, avg_loss = 0.1990\n",
            "t = 4, avg_loss = 0.1944\n",
            "t = 5, avg_loss = 0.3436\n",
            "t = 6, avg_loss = 0.2930\n",
            "t = 7, avg_loss = 0.3172\n",
            "t = 8, avg_loss = 0.3699\n",
            "t = 9, avg_loss = 0.1502\n",
            "t = 10, avg_loss = 0.3194\n",
            "t = 11, avg_loss = 0.1545\n",
            "t = 12, avg_loss = 0.1419\n",
            "t = 13, avg_loss = 0.2627\n",
            "t = 14, avg_loss = 0.1261\n",
            "t = 15, avg_loss = 0.3930\n",
            "t = 16, avg_loss = 0.3191\n",
            "t = 17, avg_loss = 0.2845\n",
            "t = 18, avg_loss = 0.3017\n",
            "Checking accuracy on test set\n",
            "Got 238 / 280 correct (85.00)\n",
            "acc = 0.850000\n",
            "Starting epoch 23 / 50\n",
            "t = 1, avg_loss = 0.2681\n",
            "t = 2, avg_loss = 0.2505\n",
            "t = 3, avg_loss = 0.3460\n",
            "t = 4, avg_loss = 0.2071\n",
            "t = 5, avg_loss = 0.1555\n",
            "t = 6, avg_loss = 0.2082\n",
            "t = 7, avg_loss = 0.2408\n",
            "t = 8, avg_loss = 0.2833\n",
            "t = 9, avg_loss = 0.1475\n",
            "t = 10, avg_loss = 0.2965\n",
            "t = 11, avg_loss = 0.1962\n",
            "t = 12, avg_loss = 0.2753\n",
            "t = 13, avg_loss = 0.4433\n",
            "t = 14, avg_loss = 0.2309\n",
            "t = 15, avg_loss = 0.2742\n",
            "t = 16, avg_loss = 0.2417\n",
            "t = 17, avg_loss = 0.3263\n",
            "t = 18, avg_loss = 0.6041\n",
            "Checking accuracy on test set\n",
            "Got 239 / 280 correct (85.36)\n",
            "acc = 0.853571\n",
            "Starting epoch 24 / 50\n",
            "t = 1, avg_loss = 0.3265\n",
            "t = 2, avg_loss = 0.1899\n",
            "t = 3, avg_loss = 0.2833\n",
            "t = 4, avg_loss = 0.2419\n",
            "t = 5, avg_loss = 0.3265\n",
            "t = 6, avg_loss = 0.2198\n",
            "t = 7, avg_loss = 0.2427\n",
            "t = 8, avg_loss = 0.4203\n",
            "t = 9, avg_loss = 0.3008\n",
            "t = 10, avg_loss = 0.3183\n",
            "t = 11, avg_loss = 0.3584\n",
            "t = 12, avg_loss = 0.2859\n",
            "t = 13, avg_loss = 0.2427\n",
            "t = 14, avg_loss = 0.2488\n",
            "t = 15, avg_loss = 0.3332\n",
            "t = 16, avg_loss = 0.3043\n",
            "t = 17, avg_loss = 0.2049\n",
            "t = 18, avg_loss = 0.2945\n",
            "Checking accuracy on test set\n",
            "Got 235 / 280 correct (83.93)\n",
            "acc = 0.839286\n",
            "Starting epoch 25 / 50\n",
            "t = 1, avg_loss = 0.2943\n",
            "t = 2, avg_loss = 0.2790\n",
            "t = 3, avg_loss = 0.2320\n",
            "t = 4, avg_loss = 0.3120\n",
            "t = 5, avg_loss = 0.2890\n",
            "t = 6, avg_loss = 0.1628\n",
            "t = 7, avg_loss = 0.1984\n",
            "t = 8, avg_loss = 0.1892\n",
            "t = 9, avg_loss = 0.2801\n",
            "t = 10, avg_loss = 0.2407\n",
            "t = 11, avg_loss = 0.2023\n",
            "t = 12, avg_loss = 0.2843\n",
            "t = 13, avg_loss = 0.2550\n",
            "t = 14, avg_loss = 0.3124\n",
            "t = 15, avg_loss = 0.3758\n",
            "t = 16, avg_loss = 0.2370\n",
            "t = 17, avg_loss = 0.3667\n",
            "t = 18, avg_loss = 0.2675\n",
            "Checking accuracy on test set\n",
            "Got 233 / 280 correct (83.21)\n",
            "acc = 0.832143\n",
            "Starting epoch 26 / 50\n",
            "t = 1, avg_loss = 0.1892\n",
            "t = 2, avg_loss = 0.1418\n",
            "t = 3, avg_loss = 0.2271\n",
            "t = 4, avg_loss = 0.3786\n",
            "t = 5, avg_loss = 0.2083\n",
            "t = 6, avg_loss = 0.1280\n",
            "t = 7, avg_loss = 0.2003\n",
            "t = 8, avg_loss = 0.3493\n",
            "t = 9, avg_loss = 0.1791\n",
            "t = 10, avg_loss = 0.4194\n",
            "t = 11, avg_loss = 0.3324\n",
            "t = 12, avg_loss = 0.1963\n",
            "t = 13, avg_loss = 0.2869\n",
            "t = 14, avg_loss = 0.2098\n",
            "t = 15, avg_loss = 0.2098\n",
            "t = 16, avg_loss = 0.2149\n",
            "t = 17, avg_loss = 0.1815\n",
            "t = 18, avg_loss = 0.5211\n",
            "Checking accuracy on test set\n",
            "Got 239 / 280 correct (85.36)\n",
            "acc = 0.853571\n",
            "Starting epoch 27 / 50\n",
            "t = 1, avg_loss = 0.1575\n",
            "t = 2, avg_loss = 0.2128\n",
            "t = 3, avg_loss = 0.2603\n",
            "t = 4, avg_loss = 0.2147\n",
            "t = 5, avg_loss = 0.1887\n",
            "t = 6, avg_loss = 0.2011\n",
            "t = 7, avg_loss = 0.3243\n",
            "t = 8, avg_loss = 0.1021\n",
            "t = 9, avg_loss = 0.1791\n",
            "t = 10, avg_loss = 0.2909\n",
            "t = 11, avg_loss = 0.1779\n",
            "t = 12, avg_loss = 0.2071\n",
            "t = 13, avg_loss = 0.3566\n",
            "t = 14, avg_loss = 0.2606\n",
            "t = 15, avg_loss = 0.2266\n",
            "t = 16, avg_loss = 0.3444\n",
            "t = 17, avg_loss = 0.2239\n",
            "t = 18, avg_loss = 0.2682\n",
            "Checking accuracy on test set\n",
            "Got 246 / 280 correct (87.86)\n",
            "acc = 0.878571\n",
            "Starting epoch 28 / 50\n",
            "t = 1, avg_loss = 0.1498\n",
            "t = 2, avg_loss = 0.2813\n",
            "t = 3, avg_loss = 0.1743\n",
            "t = 4, avg_loss = 0.2334\n",
            "t = 5, avg_loss = 0.1484\n",
            "t = 6, avg_loss = 0.2636\n",
            "t = 7, avg_loss = 0.1903\n",
            "t = 8, avg_loss = 0.2301\n",
            "t = 9, avg_loss = 0.2294\n",
            "t = 10, avg_loss = 0.4055\n",
            "t = 11, avg_loss = 0.2357\n",
            "t = 12, avg_loss = 0.2463\n",
            "t = 13, avg_loss = 0.2069\n",
            "t = 14, avg_loss = 0.2270\n",
            "t = 15, avg_loss = 0.2404\n",
            "t = 16, avg_loss = 0.1635\n",
            "t = 17, avg_loss = 0.1972\n",
            "t = 18, avg_loss = 0.1538\n",
            "Checking accuracy on test set\n",
            "Got 245 / 280 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 29 / 50\n",
            "t = 1, avg_loss = 0.1938\n",
            "t = 2, avg_loss = 0.2225\n",
            "t = 3, avg_loss = 0.2946\n",
            "t = 4, avg_loss = 0.3809\n",
            "t = 5, avg_loss = 0.1932\n",
            "t = 6, avg_loss = 0.2026\n",
            "t = 7, avg_loss = 0.1961\n",
            "t = 8, avg_loss = 0.2054\n",
            "t = 9, avg_loss = 0.1521\n",
            "t = 10, avg_loss = 0.2550\n",
            "t = 11, avg_loss = 0.2931\n",
            "t = 12, avg_loss = 0.2935\n",
            "t = 13, avg_loss = 0.2216\n",
            "t = 14, avg_loss = 0.2632\n",
            "t = 15, avg_loss = 0.3682\n",
            "t = 16, avg_loss = 0.2101\n",
            "t = 17, avg_loss = 0.2419\n",
            "t = 18, avg_loss = 0.1074\n",
            "Checking accuracy on test set\n",
            "Got 235 / 280 correct (83.93)\n",
            "acc = 0.839286\n",
            "Starting epoch 30 / 50\n",
            "t = 1, avg_loss = 0.1808\n",
            "t = 2, avg_loss = 0.3271\n",
            "t = 3, avg_loss = 0.2869\n",
            "t = 4, avg_loss = 0.2095\n",
            "t = 5, avg_loss = 0.1771\n",
            "t = 6, avg_loss = 0.3404\n",
            "t = 7, avg_loss = 0.1589\n",
            "t = 8, avg_loss = 0.3123\n",
            "t = 9, avg_loss = 0.2163\n",
            "t = 10, avg_loss = 0.2411\n",
            "t = 11, avg_loss = 0.2821\n",
            "t = 12, avg_loss = 0.1494\n",
            "t = 13, avg_loss = 0.2750\n",
            "t = 14, avg_loss = 0.3312\n",
            "t = 15, avg_loss = 0.2728\n",
            "t = 16, avg_loss = 0.2146\n",
            "t = 17, avg_loss = 0.2228\n",
            "t = 18, avg_loss = 0.4899\n",
            "Checking accuracy on test set\n",
            "Got 248 / 280 correct (88.57)\n",
            "acc = 0.885714\n",
            "Starting epoch 31 / 50\n",
            "t = 1, avg_loss = 0.1550\n",
            "t = 2, avg_loss = 0.1909\n",
            "t = 3, avg_loss = 0.2522\n",
            "t = 4, avg_loss = 0.1837\n",
            "t = 5, avg_loss = 0.2634\n",
            "t = 6, avg_loss = 0.2110\n",
            "t = 7, avg_loss = 0.2248\n",
            "t = 8, avg_loss = 0.2738\n",
            "t = 9, avg_loss = 0.1803\n",
            "t = 10, avg_loss = 0.2798\n",
            "t = 11, avg_loss = 0.2624\n",
            "t = 12, avg_loss = 0.2627\n",
            "t = 13, avg_loss = 0.1751\n",
            "t = 14, avg_loss = 0.1582\n",
            "t = 15, avg_loss = 0.2284\n",
            "t = 16, avg_loss = 0.2586\n",
            "t = 17, avg_loss = 0.2693\n",
            "t = 18, avg_loss = 0.3439\n",
            "Checking accuracy on test set\n",
            "Got 240 / 280 correct (85.71)\n",
            "acc = 0.857143\n",
            "Starting epoch 32 / 50\n",
            "t = 1, avg_loss = 0.2521\n",
            "t = 2, avg_loss = 0.2757\n",
            "t = 3, avg_loss = 0.2936\n",
            "t = 4, avg_loss = 0.2546\n",
            "t = 5, avg_loss = 0.1223\n",
            "t = 6, avg_loss = 0.2276\n",
            "t = 7, avg_loss = 0.1711\n",
            "t = 8, avg_loss = 0.1976\n",
            "t = 9, avg_loss = 0.2885\n",
            "t = 10, avg_loss = 0.1764\n",
            "t = 11, avg_loss = 0.2999\n",
            "t = 12, avg_loss = 0.2231\n",
            "t = 13, avg_loss = 0.1856\n",
            "t = 14, avg_loss = 0.3346\n",
            "t = 15, avg_loss = 0.2934\n",
            "t = 16, avg_loss = 0.2544\n",
            "t = 17, avg_loss = 0.1969\n",
            "t = 18, avg_loss = 0.3767\n",
            "Checking accuracy on test set\n",
            "Got 249 / 280 correct (88.93)\n",
            "acc = 0.889286\n",
            "Starting epoch 33 / 50\n",
            "t = 1, avg_loss = 0.2043\n",
            "t = 2, avg_loss = 0.2451\n",
            "t = 3, avg_loss = 0.2789\n",
            "t = 4, avg_loss = 0.1146\n",
            "t = 5, avg_loss = 0.2760\n",
            "t = 6, avg_loss = 0.2082\n",
            "t = 7, avg_loss = 0.2521\n",
            "t = 8, avg_loss = 0.2268\n",
            "t = 9, avg_loss = 0.2215\n",
            "t = 10, avg_loss = 0.1908\n",
            "t = 11, avg_loss = 0.2537\n",
            "t = 12, avg_loss = 0.1892\n",
            "t = 13, avg_loss = 0.2557\n",
            "t = 14, avg_loss = 0.2066\n",
            "t = 15, avg_loss = 0.2064\n",
            "t = 16, avg_loss = 0.2193\n",
            "t = 17, avg_loss = 0.1616\n",
            "t = 18, avg_loss = 0.1884\n",
            "Checking accuracy on test set\n",
            "Got 243 / 280 correct (86.79)\n",
            "acc = 0.867857\n",
            "Starting epoch 34 / 50\n",
            "t = 1, avg_loss = 0.2201\n",
            "t = 2, avg_loss = 0.3535\n",
            "t = 3, avg_loss = 0.2369\n",
            "t = 4, avg_loss = 0.1889\n",
            "t = 5, avg_loss = 0.2314\n",
            "t = 6, avg_loss = 0.2215\n",
            "t = 7, avg_loss = 0.2330\n",
            "t = 8, avg_loss = 0.1300\n",
            "t = 9, avg_loss = 0.2963\n",
            "t = 10, avg_loss = 0.2793\n",
            "t = 11, avg_loss = 0.2337\n",
            "t = 12, avg_loss = 0.2498\n",
            "t = 13, avg_loss = 0.2383\n",
            "t = 14, avg_loss = 0.1952\n",
            "t = 15, avg_loss = 0.1548\n",
            "t = 16, avg_loss = 0.1475\n",
            "t = 17, avg_loss = 0.2527\n",
            "t = 18, avg_loss = 0.1161\n",
            "Checking accuracy on test set\n",
            "Got 245 / 280 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 35 / 50\n",
            "t = 1, avg_loss = 0.2416\n",
            "t = 2, avg_loss = 0.1545\n",
            "t = 3, avg_loss = 0.2155\n",
            "t = 4, avg_loss = 0.1045\n",
            "t = 5, avg_loss = 0.2434\n",
            "t = 6, avg_loss = 0.2917\n",
            "t = 7, avg_loss = 0.1676\n",
            "t = 8, avg_loss = 0.1699\n",
            "t = 9, avg_loss = 0.1736\n",
            "t = 10, avg_loss = 0.2547\n",
            "t = 11, avg_loss = 0.1420\n",
            "t = 12, avg_loss = 0.2218\n",
            "t = 13, avg_loss = 0.2447\n",
            "t = 14, avg_loss = 0.1242\n",
            "t = 15, avg_loss = 0.2320\n",
            "t = 16, avg_loss = 0.2281\n",
            "t = 17, avg_loss = 0.2797\n",
            "t = 18, avg_loss = 0.0970\n",
            "Checking accuracy on test set\n",
            "Got 237 / 280 correct (84.64)\n",
            "acc = 0.846429\n",
            "Starting epoch 36 / 50\n",
            "t = 1, avg_loss = 0.2678\n",
            "t = 2, avg_loss = 0.2408\n",
            "t = 3, avg_loss = 0.1330\n",
            "t = 4, avg_loss = 0.3460\n",
            "t = 5, avg_loss = 0.2291\n",
            "t = 6, avg_loss = 0.3518\n",
            "t = 7, avg_loss = 0.2231\n",
            "t = 8, avg_loss = 0.2843\n",
            "t = 9, avg_loss = 0.2376\n",
            "t = 10, avg_loss = 0.2586\n",
            "t = 11, avg_loss = 0.2049\n",
            "t = 12, avg_loss = 0.3778\n",
            "t = 13, avg_loss = 0.3437\n",
            "t = 14, avg_loss = 0.1818\n",
            "t = 15, avg_loss = 0.2124\n",
            "t = 16, avg_loss = 0.2766\n",
            "t = 17, avg_loss = 0.3317\n",
            "t = 18, avg_loss = 0.2814\n",
            "Checking accuracy on test set\n",
            "Got 241 / 280 correct (86.07)\n",
            "acc = 0.860714\n",
            "Starting epoch 37 / 50\n",
            "t = 1, avg_loss = 0.1896\n",
            "t = 2, avg_loss = 0.1966\n",
            "t = 3, avg_loss = 0.2509\n",
            "t = 4, avg_loss = 0.2584\n",
            "t = 5, avg_loss = 0.4031\n",
            "t = 6, avg_loss = 0.1658\n",
            "t = 7, avg_loss = 0.2443\n",
            "t = 8, avg_loss = 0.1658\n",
            "t = 9, avg_loss = 0.2017\n",
            "t = 10, avg_loss = 0.1946\n",
            "t = 11, avg_loss = 0.2547\n",
            "t = 12, avg_loss = 0.4215\n",
            "t = 13, avg_loss = 0.1988\n",
            "t = 14, avg_loss = 0.2635\n",
            "t = 15, avg_loss = 0.1970\n",
            "t = 16, avg_loss = 0.2613\n",
            "t = 17, avg_loss = 0.2461\n",
            "t = 18, avg_loss = 0.2485\n",
            "Checking accuracy on test set\n",
            "Got 243 / 280 correct (86.79)\n",
            "acc = 0.867857\n",
            "Starting epoch 38 / 50\n",
            "t = 1, avg_loss = 0.1553\n",
            "t = 2, avg_loss = 0.1581\n",
            "t = 3, avg_loss = 0.2599\n",
            "t = 4, avg_loss = 0.2040\n",
            "t = 5, avg_loss = 0.2608\n",
            "t = 6, avg_loss = 0.2527\n",
            "t = 7, avg_loss = 0.2203\n",
            "t = 8, avg_loss = 0.1501\n",
            "t = 9, avg_loss = 0.2398\n",
            "t = 10, avg_loss = 0.3129\n",
            "t = 11, avg_loss = 0.2219\n",
            "t = 12, avg_loss = 0.1173\n",
            "t = 13, avg_loss = 0.2542\n",
            "t = 14, avg_loss = 0.1515\n",
            "t = 15, avg_loss = 0.1472\n",
            "t = 16, avg_loss = 0.2602\n",
            "t = 17, avg_loss = 0.2250\n",
            "t = 18, avg_loss = 0.1400\n",
            "Checking accuracy on test set\n",
            "Got 245 / 280 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 39 / 50\n",
            "t = 1, avg_loss = 0.1614\n",
            "t = 2, avg_loss = 0.2904\n",
            "t = 3, avg_loss = 0.2886\n",
            "t = 4, avg_loss = 0.0970\n",
            "t = 5, avg_loss = 0.1121\n",
            "t = 6, avg_loss = 0.1218\n",
            "t = 7, avg_loss = 0.2104\n",
            "t = 8, avg_loss = 0.2459\n",
            "t = 9, avg_loss = 0.1395\n",
            "t = 10, avg_loss = 0.1400\n",
            "t = 11, avg_loss = 0.1220\n",
            "t = 12, avg_loss = 0.1792\n",
            "t = 13, avg_loss = 0.1408\n",
            "t = 14, avg_loss = 0.1840\n",
            "t = 15, avg_loss = 0.1820\n",
            "t = 16, avg_loss = 0.4383\n",
            "t = 17, avg_loss = 0.2407\n",
            "t = 18, avg_loss = 0.2532\n",
            "Checking accuracy on test set\n",
            "Got 236 / 280 correct (84.29)\n",
            "acc = 0.842857\n",
            "Starting epoch 40 / 50\n",
            "t = 1, avg_loss = 0.1207\n",
            "t = 2, avg_loss = 0.2962\n",
            "t = 3, avg_loss = 0.1745\n",
            "t = 4, avg_loss = 0.1546\n",
            "t = 5, avg_loss = 0.1540\n",
            "t = 6, avg_loss = 0.1995\n",
            "t = 7, avg_loss = 0.1721\n",
            "t = 8, avg_loss = 0.0976\n",
            "t = 9, avg_loss = 0.2529\n",
            "t = 10, avg_loss = 0.2459\n",
            "t = 11, avg_loss = 0.2192\n",
            "t = 12, avg_loss = 0.1542\n",
            "t = 13, avg_loss = 0.1976\n",
            "t = 14, avg_loss = 0.2115\n",
            "t = 15, avg_loss = 0.2203\n",
            "t = 16, avg_loss = 0.1749\n",
            "t = 17, avg_loss = 0.2955\n",
            "t = 18, avg_loss = 0.2066\n",
            "Checking accuracy on test set\n",
            "Got 239 / 280 correct (85.36)\n",
            "acc = 0.853571\n",
            "Starting epoch 41 / 50\n",
            "t = 1, avg_loss = 0.1363\n",
            "t = 2, avg_loss = 0.1644\n",
            "t = 3, avg_loss = 0.2062\n",
            "t = 4, avg_loss = 0.2936\n",
            "t = 5, avg_loss = 0.2708\n",
            "t = 6, avg_loss = 0.1961\n",
            "t = 7, avg_loss = 0.1693\n",
            "t = 8, avg_loss = 0.2989\n",
            "t = 9, avg_loss = 0.2461\n",
            "t = 10, avg_loss = 0.1490\n",
            "t = 11, avg_loss = 0.2682\n",
            "t = 12, avg_loss = 0.2291\n",
            "t = 13, avg_loss = 0.2035\n",
            "t = 14, avg_loss = 0.2913\n",
            "t = 15, avg_loss = 0.2039\n",
            "t = 16, avg_loss = 0.1767\n",
            "t = 17, avg_loss = 0.3551\n",
            "t = 18, avg_loss = 0.3517\n",
            "Checking accuracy on test set\n",
            "Got 239 / 280 correct (85.36)\n",
            "acc = 0.853571\n",
            "Starting epoch 42 / 50\n",
            "t = 1, avg_loss = 0.2100\n",
            "t = 2, avg_loss = 0.1908\n",
            "t = 3, avg_loss = 0.2260\n",
            "t = 4, avg_loss = 0.2771\n",
            "t = 5, avg_loss = 0.5043\n",
            "t = 6, avg_loss = 0.2291\n",
            "t = 7, avg_loss = 0.1755\n",
            "t = 8, avg_loss = 0.1824\n",
            "t = 9, avg_loss = 0.2093\n",
            "t = 10, avg_loss = 0.1427\n",
            "t = 11, avg_loss = 0.2812\n",
            "t = 12, avg_loss = 0.2491\n",
            "t = 13, avg_loss = 0.1781\n",
            "t = 14, avg_loss = 0.1724\n",
            "t = 15, avg_loss = 0.1531\n",
            "t = 16, avg_loss = 0.3042\n",
            "t = 17, avg_loss = 0.1581\n",
            "t = 18, avg_loss = 0.2541\n",
            "Checking accuracy on test set\n",
            "Got 241 / 280 correct (86.07)\n",
            "acc = 0.860714\n",
            "Starting epoch 43 / 50\n",
            "t = 1, avg_loss = 0.2673\n",
            "t = 2, avg_loss = 0.1033\n",
            "t = 3, avg_loss = 0.2421\n",
            "t = 4, avg_loss = 0.1818\n",
            "t = 5, avg_loss = 0.1360\n",
            "t = 6, avg_loss = 0.1846\n",
            "t = 7, avg_loss = 0.1620\n",
            "t = 8, avg_loss = 0.2720\n",
            "t = 9, avg_loss = 0.1948\n",
            "t = 10, avg_loss = 0.2929\n",
            "t = 11, avg_loss = 0.2800\n",
            "t = 12, avg_loss = 0.1712\n",
            "t = 13, avg_loss = 0.1817\n",
            "t = 14, avg_loss = 0.2303\n",
            "t = 15, avg_loss = 0.2737\n",
            "t = 16, avg_loss = 0.2825\n",
            "t = 17, avg_loss = 0.2786\n",
            "t = 18, avg_loss = 0.2670\n",
            "Checking accuracy on test set\n",
            "Got 245 / 280 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 44 / 50\n",
            "t = 1, avg_loss = 0.2609\n",
            "t = 2, avg_loss = 0.1208\n",
            "t = 3, avg_loss = 0.3429\n",
            "t = 4, avg_loss = 0.1693\n",
            "t = 5, avg_loss = 0.1955\n",
            "t = 6, avg_loss = 0.2425\n",
            "t = 7, avg_loss = 0.2026\n",
            "t = 8, avg_loss = 0.1784\n",
            "t = 9, avg_loss = 0.2451\n",
            "t = 10, avg_loss = 0.2193\n",
            "t = 11, avg_loss = 0.1685\n",
            "t = 12, avg_loss = 0.2220\n",
            "t = 13, avg_loss = 0.1981\n",
            "t = 14, avg_loss = 0.1713\n",
            "t = 15, avg_loss = 0.1710\n",
            "t = 16, avg_loss = 0.2256\n",
            "t = 17, avg_loss = 0.2335\n",
            "t = 18, avg_loss = 0.0835\n",
            "Checking accuracy on test set\n",
            "Got 246 / 280 correct (87.86)\n",
            "acc = 0.878571\n",
            "Starting epoch 45 / 50\n",
            "t = 1, avg_loss = 0.2417\n",
            "t = 2, avg_loss = 0.2260\n",
            "t = 3, avg_loss = 0.1787\n",
            "t = 4, avg_loss = 0.1936\n",
            "t = 5, avg_loss = 0.1231\n",
            "t = 6, avg_loss = 0.0710\n",
            "t = 7, avg_loss = 0.2968\n",
            "t = 8, avg_loss = 0.1195\n",
            "t = 9, avg_loss = 0.1252\n",
            "t = 10, avg_loss = 0.1627\n",
            "t = 11, avg_loss = 0.1839\n",
            "t = 12, avg_loss = 0.1685\n",
            "t = 13, avg_loss = 0.4876\n",
            "t = 14, avg_loss = 0.2707\n",
            "t = 15, avg_loss = 0.2046\n",
            "t = 16, avg_loss = 0.2488\n",
            "t = 17, avg_loss = 0.1538\n",
            "t = 18, avg_loss = 0.2083\n",
            "Checking accuracy on test set\n",
            "Got 241 / 280 correct (86.07)\n",
            "acc = 0.860714\n",
            "Starting epoch 46 / 50\n",
            "t = 1, avg_loss = 0.2024\n",
            "t = 2, avg_loss = 0.1227\n",
            "t = 3, avg_loss = 0.1437\n",
            "t = 4, avg_loss = 0.1342\n",
            "t = 5, avg_loss = 0.4177\n",
            "t = 6, avg_loss = 0.1847\n",
            "t = 7, avg_loss = 0.1822\n",
            "t = 8, avg_loss = 0.1124\n",
            "t = 9, avg_loss = 0.1342\n",
            "t = 10, avg_loss = 0.2338\n",
            "t = 11, avg_loss = 0.2028\n",
            "t = 12, avg_loss = 0.1992\n",
            "t = 13, avg_loss = 0.2444\n",
            "t = 14, avg_loss = 0.2472\n",
            "t = 15, avg_loss = 0.2408\n",
            "t = 16, avg_loss = 0.1509\n",
            "t = 17, avg_loss = 0.2557\n",
            "t = 18, avg_loss = 0.1284\n",
            "Checking accuracy on test set\n",
            "Got 243 / 280 correct (86.79)\n",
            "acc = 0.867857\n",
            "Starting epoch 47 / 50\n",
            "t = 1, avg_loss = 0.1894\n",
            "t = 2, avg_loss = 0.1797\n",
            "t = 3, avg_loss = 0.2407\n",
            "t = 4, avg_loss = 0.1651\n",
            "t = 5, avg_loss = 0.2014\n",
            "t = 6, avg_loss = 0.0842\n",
            "t = 7, avg_loss = 0.1583\n",
            "t = 8, avg_loss = 0.1422\n",
            "t = 9, avg_loss = 0.1686\n",
            "t = 10, avg_loss = 0.1712\n",
            "t = 11, avg_loss = 0.2264\n",
            "t = 12, avg_loss = 0.2182\n",
            "t = 13, avg_loss = 0.2336\n",
            "t = 14, avg_loss = 0.2487\n",
            "t = 15, avg_loss = 0.2751\n",
            "t = 16, avg_loss = 0.1843\n",
            "t = 17, avg_loss = 0.2103\n",
            "t = 18, avg_loss = 0.1210\n",
            "Checking accuracy on test set\n",
            "Got 249 / 280 correct (88.93)\n",
            "acc = 0.889286\n",
            "Starting epoch 48 / 50\n",
            "t = 1, avg_loss = 0.1197\n",
            "t = 2, avg_loss = 0.1545\n",
            "t = 3, avg_loss = 0.2385\n",
            "t = 4, avg_loss = 0.1196\n",
            "t = 5, avg_loss = 0.1800\n",
            "t = 6, avg_loss = 0.2017\n",
            "t = 7, avg_loss = 0.1740\n",
            "t = 8, avg_loss = 0.2938\n",
            "t = 9, avg_loss = 0.3267\n",
            "t = 10, avg_loss = 0.2249\n",
            "t = 11, avg_loss = 0.1853\n",
            "t = 12, avg_loss = 0.1799\n",
            "t = 13, avg_loss = 0.0736\n",
            "t = 14, avg_loss = 0.1668\n",
            "t = 15, avg_loss = 0.1406\n",
            "t = 16, avg_loss = 0.2089\n",
            "t = 17, avg_loss = 0.1968\n",
            "t = 18, avg_loss = 0.1383\n",
            "Checking accuracy on test set\n",
            "Got 244 / 280 correct (87.14)\n",
            "acc = 0.871429\n",
            "Starting epoch 49 / 50\n",
            "t = 1, avg_loss = 0.1794\n",
            "t = 2, avg_loss = 0.1909\n",
            "t = 3, avg_loss = 0.1680\n",
            "t = 4, avg_loss = 0.1173\n",
            "t = 5, avg_loss = 0.1145\n",
            "t = 6, avg_loss = 0.1584\n",
            "t = 7, avg_loss = 0.3229\n",
            "t = 8, avg_loss = 0.1402\n",
            "t = 9, avg_loss = 0.1740\n",
            "t = 10, avg_loss = 0.1011\n",
            "t = 11, avg_loss = 0.1829\n",
            "t = 12, avg_loss = 0.2026\n",
            "t = 13, avg_loss = 0.1913\n",
            "t = 14, avg_loss = 0.1581\n",
            "t = 15, avg_loss = 0.2202\n",
            "t = 16, avg_loss = 0.1240\n",
            "t = 17, avg_loss = 0.1939\n",
            "t = 18, avg_loss = 0.1535\n",
            "Checking accuracy on test set\n",
            "Got 250 / 280 correct (89.29)\n",
            "acc = 0.892857\n",
            "Starting epoch 50 / 50\n",
            "t = 1, avg_loss = 0.1933\n",
            "t = 2, avg_loss = 0.1196\n",
            "t = 3, avg_loss = 0.2759\n",
            "t = 4, avg_loss = 0.1266\n",
            "t = 5, avg_loss = 0.1166\n",
            "t = 6, avg_loss = 0.2810\n",
            "t = 7, avg_loss = 0.2844\n",
            "t = 8, avg_loss = 0.1921\n",
            "t = 9, avg_loss = 0.2477\n",
            "t = 10, avg_loss = 0.1188\n",
            "t = 11, avg_loss = 0.1015\n",
            "t = 12, avg_loss = 0.1417\n",
            "t = 13, avg_loss = 0.2046\n",
            "t = 14, avg_loss = 0.1577\n",
            "t = 15, avg_loss = 0.1224\n",
            "t = 16, avg_loss = 0.2057\n",
            "t = 17, avg_loss = 0.1403\n",
            "t = 18, avg_loss = 0.1400\n",
            "Checking accuracy on test set\n",
            "Got 250 / 280 correct (89.29)\n",
            "acc = 0.892857\n",
            "Checking accuracy on test set\n",
            "Got 246 / 280 correct (87.86)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8785714285714286"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDn-2g-TLY3k",
        "colab_type": "code",
        "outputId": "c1b3cda1-d6bb-4e8b-d742-aaef1e7638e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot([print_every*batch_size*(i+1) for i in range((len(avg_loss_list)))],avg_loss_list)\n",
        "print(\"Loss:\")\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD4CAYAAAAKA1qZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngmEjwDAM04L5f8E8bRA4G3gpAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChZnTRBtBFoL",
        "colab_type": "code",
        "outputId": "df401b82-791c-4c35-a2a2-3c4ec54e9569",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "plt.plot([i+1 for i in range((len(acc_list)))],acc_list)\n",
        "print(\"Accurancy:\")\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accurancy:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0Cul1DCngV4ppYa5/w8QJA2y0hGDEAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}