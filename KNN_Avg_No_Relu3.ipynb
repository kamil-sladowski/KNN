{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN_Avg_No_Relu3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "20815bfe7a7847a69b9179e66ba19961": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_091dbedc270a43098cd041f2ca00a7cd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4614d62b33bb46998b67a0d03d2369e9",
              "IPY_MODEL_e1af652f77ff4cffbc4167927c30683b"
            ]
          }
        },
        "091dbedc270a43098cd041f2ca00a7cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4614d62b33bb46998b67a0d03d2369e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_66d8bdd6204a45889215e06b5103003e",
            "_dom_classes": [],
            "description": " 84%",
            "_model_name": "IntProgressModel",
            "bar_style": "danger",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 84,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_74beb2150a284eb6bf5c8a1a3bc80bbe"
          }
        },
        "e1af652f77ff4cffbc4167927c30683b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8c996c1619ad4e50a00adeaa2fce6c69",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 84/100 [10:19&lt;01:30,  5.68s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aa458916fd8143f2be501cfab31f1916"
          }
        },
        "66d8bdd6204a45889215e06b5103003e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "74beb2150a284eb6bf5c8a1a3bc80bbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8c996c1619ad4e50a00adeaa2fce6c69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aa458916fd8143f2be501cfab31f1916": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamilo116/KNN/blob/master/KNN_Avg_No_Relu3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7ReM7FU-xs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import sys\n",
        "from random import shuffle\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms as transforms\n",
        "import timeit\n",
        "\n",
        "np.random.seed(4) \n",
        "torch.manual_seed(4) \n",
        "torch.cuda.manual_seed(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYIMZ8QyYewD",
        "colab_type": "code",
        "outputId": "c2dcb0a5-60b4-415b-baf9-f28db53af1a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! git clone https://github.com/wang-chen/kervolution.git \n",
        "\n",
        "sys.path.append(\"kervolution/\")\n",
        "from kervolution import Kerv2d\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'kervolution' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvbKg4VJXKY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LIMIT_IMAGES_NUM = 500\n",
        "train_test_split_size = 0.2\n",
        "image_resize = (100, 100)\n",
        "batch_size = 64\n",
        "num_workers = 0\n",
        "\n",
        "in_channels = 3\n",
        "out_channels_1 = 8\n",
        "out_channels_2 = 16\n",
        "out_channels_3 = 32\n",
        "out_channels_4 = 48\n",
        "out_channels_5 = 64\n",
        "out_channels_6 = 128\n",
        "\n",
        "kernel_size = 3\n",
        "padding_1 = 1\n",
        "num_epochs = 80\n",
        "\n",
        "learning_rate = 0.01\n",
        "weight_decay = 0\n",
        "\n",
        "MALIGNANT_DATASET = '/content/drive/My Drive/Colab_data/malignant/malignant/'\n",
        "BENIGN_DATASET = '/content/drive/My Drive/Colab_data/benign/benign/'\n",
        "DATA_FOLDER = '/content/drive/My Drive/Colab_data/'\n",
        "model_backup_path = os.path.join(DATA_FOLDER, 'backup_model') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMOHez_kHZD6",
        "colab_type": "code",
        "outputId": "344bd321-77c3-4815-874f-a3de201cef5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b8P1NdXfVdX",
        "colab_type": "code",
        "outputId": "38259cf9-f079-45bd-bcab-f85ab274ee92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "benign_file_list = sorted(os.listdir(BENIGN_DATASET))\n",
        "malignant_file_list = sorted(os.listdir(MALIGNANT_DATASET))\n",
        "shuffle(benign_file_list)\n",
        "shuffle(malignant_file_list)\n",
        "benign_file_list = benign_file_list[:LIMIT_IMAGES_NUM]\n",
        "malignant_file_list = malignant_file_list[:LIMIT_IMAGES_NUM]\n",
        "\n",
        "print(f\"Number of benign {len(benign_file_list)} images\")\n",
        "print(f\"Number of malignant {len(malignant_file_list)} images\")\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize(image_resize),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of benign 500 images\n",
            "Number of malignant 500 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGDQfal74BLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "benign_dict = {filename: 0 for filename in benign_file_list}\n",
        "malignant_dict = {filename: 1 for filename in malignant_file_list}\n",
        "img_class_dict = {**benign_dict , **malignant_dict}\n",
        "labeled_data = pd.Series(img_class_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvAAOqmVfVll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IsicDataset(Dataset):\n",
        "    def __init__(self, data_folder, labeled_data, \n",
        "                 transform=transforms.Compose([transforms.ToTensor()])):\n",
        "        self.labeled_data = labeled_data\n",
        "        self.transform = transform\n",
        "        self.data_folder = data_folder\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labeled_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        label = self.labeled_data[index]\n",
        "        if label == 0:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"benign\", \"benign\", index ))\n",
        "        else:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"malignant\", \"malignant\", index ))\n",
        "        image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "    @property\n",
        "    def labels(self):\n",
        "      return self.labeled_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSuYqjLAYrWA",
        "colab_type": "code",
        "outputId": "bb985eb4-4a41-415e-e376-24e68a7ff7a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        " \n",
        "dataset = IsicDataset(DATA_FOLDER, labeled_data, transform=data_transforms)\n",
        "print(dataset.labels)\n",
        "\n",
        "X_train, X_test = train_test_split(dataset.labels, test_size=train_test_split_size)\n",
        "print(\"number of training data: \",len(X_train))\n",
        "print(\"number of testing  data: \",len(X_test))\n",
        "\n",
        "train_sampler = SubsetRandomSampler(list(X_train.index))\n",
        "valid_sampler = SubsetRandomSampler(list(X_test.index))\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ISIC_0000875.jpeg    0\n",
            "ISIC_0000245.jpeg    0\n",
            "ISIC_0000672.jpeg    0\n",
            "ISIC_0002633.jpeg    0\n",
            "ISIC_0000005.jpeg    0\n",
            "                    ..\n",
            "ISIC_0013491.jpeg    1\n",
            "ISIC_0012678.jpeg    1\n",
            "ISIC_0000298.jpeg    1\n",
            "ISIC_0013530.jpeg    1\n",
            "ISIC_0000412.jpeg    1\n",
            "Length: 1000, dtype: int64\n",
            "number of training data:  800\n",
            "number of testing  data:  200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e8nFBR6Yug5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "def train(model, train_loader ,loss_fn, optimizer, num_epochs=1, starting_from_epoch=1):\n",
        "    total_loss =0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
        "        model.train()\n",
        "\n",
        "        for t, (x, y) in enumerate(train_loader):\n",
        "            x_var = Variable(x.type(gpu_dtype))\n",
        "            y_var = Variable(y.type(gpu_dtype).long())\n",
        "            scores = model(x_var)\n",
        "            loss = loss_fn(scores, y_var)\n",
        "            total_loss += loss.data\n",
        "            \n",
        "            if (t + 1) % print_every == 0:\n",
        "                avg_loss = total_loss/print_every\n",
        "                print('t = %d, avg_loss = %.4f' % (t + 1, avg_loss) )\n",
        "                avg_loss_list.append(avg_loss)\n",
        "                total_loss = 0\n",
        "                \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        acc = check_accuracy(model_gpu, valid_loader)\n",
        "        print('acc = %f' %(acc))\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model_gpu.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            }, model_backup_path)\n",
        "            \n",
        "def check_accuracy(model, loader):\n",
        "    print('Checking accuracy on test set')   \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval() \n",
        "    for x, y in loader:\n",
        "        x_var = Variable(x.type(gpu_dtype))\n",
        "\n",
        "        scores = model(x_var)\n",
        "        _, preds = scores.data.cpu().max(1)\n",
        "        num_correct += (preds == y).sum()\n",
        "        num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    acc_list.append(acc)\n",
        "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "    return acc\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggvpMu36Yw2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.size()\n",
        "        return x.view(N, -1)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgmexhBRZAK6",
        "colab_type": "code",
        "outputId": "27a37929-c2a8-4c0d-b4b9-a605bb7af894",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "20815bfe7a7847a69b9179e66ba19961",
            "091dbedc270a43098cd041f2ca00a7cd",
            "4614d62b33bb46998b67a0d03d2369e9",
            "e1af652f77ff4cffbc4167927c30683b",
            "66d8bdd6204a45889215e06b5103003e",
            "74beb2150a284eb6bf5c8a1a3bc80bbe",
            "8c996c1619ad4e50a00adeaa2fce6c69",
            "aa458916fd8143f2be501cfab31f1916"
          ]
        }
      },
      "source": [
        "gpu_dtype = torch.cuda.FloatTensor\n",
        "\n",
        "print_every = 1\n",
        "\n",
        "\n",
        "'''\n",
        "Kerv2d\n",
        "kervolution with following options:\n",
        "kernel_type: [linear, polynomial, gaussian, etc.]\n",
        "default is convolution:\n",
        "          kernel_type --> linear,\n",
        "balance, power, gamma is valid only when the kernel_type is specified\n",
        "if learnable_kernel = True,  they just be the initial value of learable parameters\n",
        "if learnable_kernel = False, they are the value of kernel_type's parameter\n",
        "the parameter [power] cannot be learned due to integer limitation\n",
        "dilation (int or tuple, optional): Spacing between kernel\n",
        "elements. Default: 1\n",
        "groups (int, optional): Number of blocked connections from input\n",
        "channels to output channels. Default: 1\n",
        "bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n",
        "kernel_type (str), Default: 'linear'\n",
        "learnable_kernel (bool): Learnable kernel parameters.  Default: False \n",
        "balance: 0, 1\n",
        "power: 3, 4, 5\n",
        "gamma:\n",
        "'''\n",
        "\n",
        "\n",
        "model_base = nn.Sequential( \n",
        "                nn.Kerv2d(in_channels , out_channels_1, padding=padding_1, dilation=1, groups=1, bias=True, \n",
        "                          kernel_type='polynomial', kernel_size=kernel_size, learnable_kernel=True,\n",
        "                          kernel_regularizer=True, stride=1, balance=1, power=5, gamma=1\n",
        "                          ),\n",
        "                nn.BatchNorm2d(out_channels_1),\n",
        "                nn.Conv2d(out_channels_1 , out_channels_2, padding= padding_1, kernel_size=kernel_size, stride=1), \n",
        "                nn.BatchNorm2d(out_channels_2),\n",
        "                nn.AvgPool2d(2, stride=2), \n",
        "                nn.Conv2d(out_channels_2 , out_channels_3, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.BatchNorm2d(out_channels_3),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_3 , out_channels_4, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.BatchNorm2d(out_channels_4),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_4 , out_channels_5, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.BatchNorm2d(out_channels_5),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_5 , out_channels_6, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.BatchNorm2d(out_channels_6),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Dropout(0.5),\n",
        "                Flatten(),\n",
        "                nn.Linear(1152,64),\n",
        "                nn.Linear(64,2)\n",
        "            )\n",
        "model_gpu = model_base.type(gpu_dtype)\n",
        "print(model_gpu)\n",
        "loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) \n",
        "\n",
        "! pip install torch-lr-finder -v --global-option=\"amp\"\n",
        "from torch_lr_finder import LRFinder\n",
        "\n",
        "lr_finder = LRFinder(model_gpu, optimizer, loss_fn, device=\"cuda\")\n",
        "\n",
        "lr_finder.range_test(train_loader, end_lr=1, num_iter=100, start_lr=1e-05)\n",
        "lr_finder.plot() \n",
        " \n",
        "\n",
        "#train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs)\n",
        "#check_accuracy(model_gpu, valid_loader)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Kerv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (4): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (5): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (7): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (8): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (9): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (10): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (11): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (14): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (15): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (16): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (17): Dropout(p=0.5, inplace=False)\n",
            "  (18): Flatten()\n",
            "  (19): Linear(in_features=1152, out_features=64, bias=True)\n",
            "  (20): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n",
            "/usr/local/lib/python3.6/dist-packages/pip/_internal/commands/install.py:283: UserWarning: Disabling all use of wheels due to the use of --build-options / --global-options / --install-options.\n",
            "  cmdoptions.check_install_build_global(options)\n",
            "Created temporary directory: /tmp/pip-ephem-wheel-cache-ck0wh9nw\n",
            "Created temporary directory: /tmp/pip-req-tracker-4xh1jj3x\n",
            "Created requirements tracker '/tmp/pip-req-tracker-4xh1jj3x'\n",
            "Created temporary directory: /tmp/pip-install-uhemdedn\n",
            "Requirement already satisfied: torch-lr-finder in /usr/local/lib/python3.6/dist-packages (0.1.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from torch-lr-finder) (3.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch-lr-finder) (1.18.2)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from torch-lr-finder) (1.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torch-lr-finder) (4.38.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->torch-lr-finder) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->torch-lr-finder) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->torch-lr-finder) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->torch-lr-finder) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->torch-lr-finder) (1.12.0)\n",
            "Cleaning up...\n",
            "Removed build tracker '/tmp/pip-req-tracker-4xh1jj3x'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "20815bfe7a7847a69b9179e66ba19961",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Stopping early, the loss has diverged\n",
            "Learning rate search finished. See the graph with {finder_name}.plot()\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f381c5db5c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hm3h_Kyyp_6h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "check_accuracy(model_gpu, valid_loader)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzuX5gLEeJfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def retry_from_backup():\n",
        "  model_gpu = model_base.type(gpu_dtype)\n",
        "  print(model_gpu)\n",
        "  loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) \n",
        "\n",
        "\n",
        "\n",
        "  checkpoint = torch.load(model_backup_path)\n",
        "  model_gpu.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  epoch = checkpoint['epoch']\n",
        "  loss = checkpoint['loss']\n",
        "  print(\"starting from epoch: \" + str(epoch))\n",
        "  print(\"starting from loss: \" + str(loss))\n",
        "  print(checkpoint['model_state_dict'])\n",
        "  print(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "  train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs, starting_from_epoch=epoch)\n",
        "  check_accuracy(model_gpu, valid_loader)\n",
        "#retry_from_backup()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDn-2g-TLY3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot([print_every*batch_size*(i+1) for i in range((len(avg_loss_list)))],avg_loss_list)\n",
        "print(\"Loss:\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGer6hJv7-zR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot([i+1 for i in range((len(acc_list)))],acc_list)\n",
        "print(\"Accurancy:\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBTReWHxz4Ml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}