{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN_Avg_No_Relu3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamilo116/KNN/blob/master/KNN_Avg_No_Relu3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7ReM7FU-xs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import sys\n",
        "from random import shuffle\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms as transforms\n",
        "import timeit\n",
        "\n",
        "np.random.seed(4) \n",
        "torch.manual_seed(4) \n",
        "torch.cuda.manual_seed(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYIMZ8QyYewD",
        "colab_type": "code",
        "outputId": "a820eb82-c64d-42ce-8d81-2c09bb044c15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! git clone https://github.com/wang-chen/kervolution.git \n",
        "\n",
        "sys.path.append(\"kervolution/\")\n",
        "from kervolution import Kerv2d\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'kervolution' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvbKg4VJXKY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LIMIT_IMAGES_NUM = 500\n",
        "train_test_split_size = 0.2\n",
        "image_resize = (100, 100)\n",
        "batch_size = 64\n",
        "num_workers = 0\n",
        "\n",
        "in_channels = 3\n",
        "out_channels_1 = 16\n",
        "out_channels_2 = 24\n",
        "out_channels_3 = 32\n",
        "out_channels_4 = 48\n",
        "out_channels_5 = 64\n",
        "\n",
        "kernel_size = 3\n",
        "padding_1 = 1\n",
        "num_epochs = 80\n",
        "\n",
        "learning_rate = 0.0001\n",
        "weight_decay = 0.1\n",
        "\n",
        "MALIGNANT_DATASET = '/content/drive/My Drive/Colab_data/malignant/malignant/'\n",
        "BENIGN_DATASET = '/content/drive/My Drive/Colab_data/benign/benign/'\n",
        "DATA_FOLDER = '/content/drive/My Drive/Colab_data/'\n",
        "model_backup_path = os.path.join(DATA_FOLDER, 'backup_model_3') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMOHez_kHZD6",
        "colab_type": "code",
        "outputId": "e9c39736-fa81-4dd4-ad5f-d6f8f089b0a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b8P1NdXfVdX",
        "colab_type": "code",
        "outputId": "7a653d11-42ac-4d44-a89f-59c10e5aa892",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "benign_file_list = sorted(os.listdir(BENIGN_DATASET))\n",
        "malignant_file_list = sorted(os.listdir(MALIGNANT_DATASET))\n",
        "shuffle(benign_file_list)\n",
        "shuffle(malignant_file_list)\n",
        "benign_file_list = benign_file_list[:LIMIT_IMAGES_NUM]\n",
        "malignant_file_list = malignant_file_list[:LIMIT_IMAGES_NUM]\n",
        "\n",
        "print(f\"Number of benign {len(benign_file_list)} images\")\n",
        "print(f\"Number of malignant {len(malignant_file_list)} images\")\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize(image_resize),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of benign 500 images\n",
            "Number of malignant 500 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGDQfal74BLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "benign_dict = {filename: 0 for filename in benign_file_list}\n",
        "malignant_dict = {filename: 1 for filename in malignant_file_list}\n",
        "img_class_dict = {**benign_dict , **malignant_dict}\n",
        "labeled_data = pd.Series(img_class_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvAAOqmVfVll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IsicDataset(Dataset):\n",
        "    def __init__(self, data_folder, labeled_data, \n",
        "                 transform=transforms.Compose([transforms.ToTensor()])):\n",
        "        self.labeled_data = labeled_data\n",
        "        self.transform = transform\n",
        "        self.data_folder = data_folder\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labeled_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        label = self.labeled_data[index]\n",
        "        if label == 0:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"benign\", \"benign\", index ))\n",
        "        else:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"malignant\", \"malignant\", index ))\n",
        "        image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "    @property\n",
        "    def labels(self):\n",
        "      return self.labeled_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSuYqjLAYrWA",
        "colab_type": "code",
        "outputId": "54c83e21-a7ac-4735-a016-6110454ec200",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        " \n",
        "dataset = IsicDataset(DATA_FOLDER, labeled_data, transform=data_transforms)\n",
        "print(dataset.labels)\n",
        "\n",
        "X_train, X_test = train_test_split(dataset.labels, test_size=train_test_split_size)\n",
        "print(\"number of training data: \",len(X_train))\n",
        "print(\"number of testing  data: \",len(X_test))\n",
        "\n",
        "train_sampler = SubsetRandomSampler(list(X_train.index))\n",
        "valid_sampler = SubsetRandomSampler(list(X_test.index))\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ISIC_0001026.jpeg    0\n",
            "ISIC_0002850.jpeg    0\n",
            "ISIC_0000871.jpeg    0\n",
            "ISIC_0000641.jpeg    0\n",
            "ISIC_0000770.jpeg    0\n",
            "                    ..\n",
            "ISIC_0024208.jpeg    1\n",
            "ISIC_0001105.jpeg    1\n",
            "ISIC_0025964.jpg     1\n",
            "ISIC_0014156.jpeg    1\n",
            "ISIC_0011617.jpeg    1\n",
            "Length: 1000, dtype: int64\n",
            "number of training data:  800\n",
            "number of testing  data:  200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e8nFBR6Yug5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "def train(model, train_loader ,loss_fn, optimizer, num_epochs=1, starting_from_epoch=1):\n",
        "    total_loss =0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
        "        model.train()\n",
        "\n",
        "        for t, (x, y) in enumerate(train_loader):\n",
        "            x_var = Variable(x.type(gpu_dtype))\n",
        "            y_var = Variable(y.type(gpu_dtype).long())\n",
        "            scores = model(x_var)\n",
        "            loss = loss_fn(scores, y_var)\n",
        "            total_loss += loss.data\n",
        "            \n",
        "            if (t + 1) % print_every == 0:\n",
        "                avg_loss = total_loss/print_every\n",
        "                print('t = %d, avg_loss = %.4f' % (t + 1, avg_loss) )\n",
        "                avg_loss_list.append(avg_loss)\n",
        "                total_loss = 0\n",
        "                \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        acc = check_accuracy(model_gpu, valid_loader)\n",
        "        print('acc = %f' %(acc))\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model_gpu.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            }, model_backup_path)\n",
        "            \n",
        "def check_accuracy(model, loader):\n",
        "    print('Checking accuracy on test set')   \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval() \n",
        "    for x, y in loader:\n",
        "        x_var = Variable(x.type(gpu_dtype))\n",
        "\n",
        "        scores = model(x_var)\n",
        "        _, preds = scores.data.cpu().max(1)\n",
        "        num_correct += (preds == y).sum()\n",
        "        num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    acc_list.append(acc)\n",
        "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "    return acc\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggvpMu36Yw2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.size()\n",
        "        return x.view(N, -1)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgmexhBRZAK6",
        "colab_type": "code",
        "outputId": "7d6a7bc6-3623-4331-d60b-8369b1199709",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "gpu_dtype = torch.cuda.FloatTensor\n",
        "\n",
        "print_every = 1\n",
        "\n",
        "\n",
        "'''\n",
        "Kerv2d\n",
        "kervolution with following options:\n",
        "kernel_type: [linear, polynomial, gaussian, etc.]\n",
        "default is convolution:\n",
        "          kernel_type --> linear,\n",
        "balance, power, gamma is valid only when the kernel_type is specified\n",
        "if learnable_kernel = True,  they just be the initial value of learable parameters\n",
        "if learnable_kernel = False, they are the value of kernel_type's parameter\n",
        "the parameter [power] cannot be learned due to integer limitation\n",
        "dilation (int or tuple, optional): Spacing between kernel\n",
        "elements. Default: 1\n",
        "groups (int, optional): Number of blocked connections from input\n",
        "channels to output channels. Default: 1\n",
        "bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n",
        "kernel_type (str), Default: 'linear'\n",
        "learnable_kernel (bool): Learnable kernel parameters.  Default: False \n",
        "balance: 0, 1\n",
        "power: 3, 4, 5\n",
        "gamma:\n",
        "'''\n",
        "\n",
        "\n",
        "model_base = nn.Sequential( \n",
        "                nn.Kerv2d(in_channels , out_channels_1, padding=padding_1, dilation=1, groups=1, bias=True, \n",
        "                          kernel_type='polynomial', kernel_size=kernel_size, learnable_kernel=True,\n",
        "                          kernel_regularizer=True, stride=1, balance=1, power=3, gamma=1\n",
        "                          ),\n",
        "                nn.BatchNorm2d(out_channels_1),\n",
        "                nn.Conv2d(out_channels_1 , out_channels_2, padding= padding_1, kernel_size=kernel_size, stride=1), \n",
        "                nn.BatchNorm2d(out_channels_2),\n",
        "                nn.AvgPool2d(2, stride=2), \n",
        "                nn.Conv2d(out_channels_2 , out_channels_3, padding= padding_1, kernel_size=kernel_size, stride=1), \n",
        "                nn.Dropout(0.1), \n",
        "                nn.BatchNorm2d(out_channels_3),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                #nn.Conv2d(out_channels_3 , out_channels_4, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.Kerv2d(out_channels_3 , out_channels_4, padding=padding_1, dilation=1, groups=1, bias=True, \n",
        "                          kernel_type='polynomial', kernel_size=kernel_size, learnable_kernel=True,\n",
        "                          kernel_regularizer=True, stride=1, balance=1, power=3, gamma=1\n",
        "                          ),\n",
        "                \n",
        "                nn.BatchNorm2d(out_channels_4),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_4 , out_channels_5, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.BatchNorm2d(out_channels_5),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "               \n",
        "                nn.Dropout(0.5),\n",
        "                Flatten(),\n",
        "                nn.Linear(2304,64),\n",
        "                nn.Linear(64,2)\n",
        "            )\n",
        "model_gpu = model_base.type(gpu_dtype)\n",
        "print(model_gpu)\n",
        "loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) \n",
        "\n",
        "train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs)\n",
        "check_accuracy(model_gpu, valid_loader)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Kerv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): Conv2d(16, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (4): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (5): Conv2d(24, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (6): Dropout(p=0.1, inplace=False)\n",
            "  (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (8): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (9): Kerv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (10): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (11): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (12): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (13): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (14): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (15): Dropout(p=0.5, inplace=False)\n",
            "  (16): Flatten()\n",
            "  (17): Linear(in_features=2304, out_features=64, bias=True)\n",
            "  (18): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n",
            "Starting epoch 1 / 80\n",
            "t = 1, avg_loss = 0.6788\n",
            "t = 2, avg_loss = 0.7090\n",
            "t = 3, avg_loss = 0.6793\n",
            "t = 4, avg_loss = 0.6630\n",
            "t = 5, avg_loss = 0.6284\n",
            "t = 6, avg_loss = 0.6220\n",
            "t = 7, avg_loss = 0.6251\n",
            "t = 8, avg_loss = 0.6692\n",
            "t = 9, avg_loss = 0.6709\n",
            "t = 10, avg_loss = 0.6151\n",
            "t = 11, avg_loss = 0.7641\n",
            "t = 12, avg_loss = 0.6658\n",
            "t = 13, avg_loss = 0.5641\n",
            "Checking accuracy on test set\n",
            "Got 116 / 200 correct (58.00)\n",
            "acc = 0.580000\n",
            "Starting epoch 2 / 80\n",
            "t = 1, avg_loss = 0.6965\n",
            "t = 2, avg_loss = 0.6261\n",
            "t = 3, avg_loss = 0.5532\n",
            "t = 4, avg_loss = 0.5464\n",
            "t = 5, avg_loss = 0.5719\n",
            "t = 6, avg_loss = 0.6784\n",
            "t = 7, avg_loss = 0.7438\n",
            "t = 8, avg_loss = 0.6723\n",
            "t = 9, avg_loss = 0.5868\n",
            "t = 10, avg_loss = 0.6152\n",
            "t = 11, avg_loss = 0.6624\n",
            "t = 12, avg_loss = 0.5680\n",
            "t = 13, avg_loss = 0.5738\n",
            "Checking accuracy on test set\n",
            "Got 107 / 200 correct (53.50)\n",
            "acc = 0.535000\n",
            "Starting epoch 3 / 80\n",
            "t = 1, avg_loss = 0.4948\n",
            "t = 2, avg_loss = 0.5729\n",
            "t = 3, avg_loss = 0.6197\n",
            "t = 4, avg_loss = 0.5807\n",
            "t = 5, avg_loss = 0.6616\n",
            "t = 6, avg_loss = 0.6017\n",
            "t = 7, avg_loss = 0.7023\n",
            "t = 8, avg_loss = 0.7669\n",
            "t = 9, avg_loss = 0.5232\n",
            "t = 10, avg_loss = 0.5305\n",
            "t = 11, avg_loss = 0.5596\n",
            "t = 12, avg_loss = 0.6110\n",
            "t = 13, avg_loss = 0.7068\n",
            "Checking accuracy on test set\n",
            "Got 119 / 200 correct (59.50)\n",
            "acc = 0.595000\n",
            "Starting epoch 4 / 80\n",
            "t = 1, avg_loss = 0.5511\n",
            "t = 2, avg_loss = 0.5482\n",
            "t = 3, avg_loss = 0.5970\n",
            "t = 4, avg_loss = 0.6148\n",
            "t = 5, avg_loss = 0.6273\n",
            "t = 6, avg_loss = 0.5953\n",
            "t = 7, avg_loss = 0.6055\n",
            "t = 8, avg_loss = 0.5544\n",
            "t = 9, avg_loss = 0.5533\n",
            "t = 10, avg_loss = 0.6668\n",
            "t = 11, avg_loss = 0.4659\n",
            "t = 12, avg_loss = 0.4876\n",
            "t = 13, avg_loss = 0.6016\n",
            "Checking accuracy on test set\n",
            "Got 151 / 200 correct (75.50)\n",
            "acc = 0.755000\n",
            "Starting epoch 5 / 80\n",
            "t = 1, avg_loss = 0.5160\n",
            "t = 2, avg_loss = 0.6165\n",
            "t = 3, avg_loss = 0.5879\n",
            "t = 4, avg_loss = 0.6669\n",
            "t = 5, avg_loss = 0.4952\n",
            "t = 6, avg_loss = 0.5405\n",
            "t = 7, avg_loss = 0.4747\n",
            "t = 8, avg_loss = 0.5838\n",
            "t = 9, avg_loss = 0.5149\n",
            "t = 10, avg_loss = 0.5652\n",
            "t = 11, avg_loss = 0.5230\n",
            "t = 12, avg_loss = 0.5204\n",
            "t = 13, avg_loss = 0.5947\n",
            "Checking accuracy on test set\n",
            "Got 148 / 200 correct (74.00)\n",
            "acc = 0.740000\n",
            "Starting epoch 6 / 80\n",
            "t = 1, avg_loss = 0.5265\n",
            "t = 2, avg_loss = 0.5282\n",
            "t = 3, avg_loss = 0.5449\n",
            "t = 4, avg_loss = 0.5038\n",
            "t = 5, avg_loss = 0.5640\n",
            "t = 6, avg_loss = 0.4794\n",
            "t = 7, avg_loss = 0.5322\n",
            "t = 8, avg_loss = 0.4925\n",
            "t = 9, avg_loss = 0.6505\n",
            "t = 10, avg_loss = 0.5863\n",
            "t = 11, avg_loss = 0.4816\n",
            "t = 12, avg_loss = 0.5800\n",
            "t = 13, avg_loss = 0.5767\n",
            "Checking accuracy on test set\n",
            "Got 156 / 200 correct (78.00)\n",
            "acc = 0.780000\n",
            "Starting epoch 7 / 80\n",
            "t = 1, avg_loss = 0.5198\n",
            "t = 2, avg_loss = 0.4334\n",
            "t = 3, avg_loss = 0.6137\n",
            "t = 4, avg_loss = 0.4900\n",
            "t = 5, avg_loss = 0.4462\n",
            "t = 6, avg_loss = 0.4925\n",
            "t = 7, avg_loss = 0.6013\n",
            "t = 8, avg_loss = 0.5088\n",
            "t = 9, avg_loss = 0.6374\n",
            "t = 10, avg_loss = 0.6282\n",
            "t = 11, avg_loss = 0.6340\n",
            "t = 12, avg_loss = 0.4430\n",
            "t = 13, avg_loss = 0.3872\n",
            "Checking accuracy on test set\n",
            "Got 159 / 200 correct (79.50)\n",
            "acc = 0.795000\n",
            "Starting epoch 8 / 80\n",
            "t = 1, avg_loss = 0.4541\n",
            "t = 2, avg_loss = 0.5011\n",
            "t = 3, avg_loss = 0.4590\n",
            "t = 4, avg_loss = 0.4286\n",
            "t = 5, avg_loss = 0.5945\n",
            "t = 6, avg_loss = 0.5786\n",
            "t = 7, avg_loss = 0.4966\n",
            "t = 8, avg_loss = 0.5915\n",
            "t = 9, avg_loss = 0.5457\n",
            "t = 10, avg_loss = 0.5577\n",
            "t = 11, avg_loss = 0.4541\n",
            "t = 12, avg_loss = 0.5749\n",
            "t = 13, avg_loss = 0.4704\n",
            "Checking accuracy on test set\n",
            "Got 155 / 200 correct (77.50)\n",
            "acc = 0.775000\n",
            "Starting epoch 9 / 80\n",
            "t = 1, avg_loss = 0.5050\n",
            "t = 2, avg_loss = 0.4599\n",
            "t = 3, avg_loss = 0.5087\n",
            "t = 4, avg_loss = 0.4993\n",
            "t = 5, avg_loss = 0.5050\n",
            "t = 6, avg_loss = 0.5081\n",
            "t = 7, avg_loss = 0.5474\n",
            "t = 8, avg_loss = 0.4864\n",
            "t = 9, avg_loss = 0.5792\n",
            "t = 10, avg_loss = 0.4862\n",
            "t = 11, avg_loss = 0.5687\n",
            "t = 12, avg_loss = 0.5313\n",
            "t = 13, avg_loss = 0.5013\n",
            "Checking accuracy on test set\n",
            "Got 153 / 200 correct (76.50)\n",
            "acc = 0.765000\n",
            "Starting epoch 10 / 80\n",
            "t = 1, avg_loss = 0.5298\n",
            "t = 2, avg_loss = 0.5761\n",
            "t = 3, avg_loss = 0.5757\n",
            "t = 4, avg_loss = 0.6239\n",
            "t = 5, avg_loss = 0.3638\n",
            "t = 6, avg_loss = 0.4819\n",
            "t = 7, avg_loss = 0.3879\n",
            "t = 8, avg_loss = 0.5258\n",
            "t = 9, avg_loss = 0.4826\n",
            "t = 10, avg_loss = 0.4728\n",
            "t = 11, avg_loss = 0.4815\n",
            "t = 12, avg_loss = 0.5710\n",
            "t = 13, avg_loss = 0.4455\n",
            "Checking accuracy on test set\n",
            "Got 163 / 200 correct (81.50)\n",
            "acc = 0.815000\n",
            "Starting epoch 11 / 80\n",
            "t = 1, avg_loss = 0.4368\n",
            "t = 2, avg_loss = 0.5174\n",
            "t = 3, avg_loss = 0.4175\n",
            "t = 4, avg_loss = 0.4596\n",
            "t = 5, avg_loss = 0.4726\n",
            "t = 6, avg_loss = 0.4673\n",
            "t = 7, avg_loss = 0.4443\n",
            "t = 8, avg_loss = 0.4397\n",
            "t = 9, avg_loss = 0.6576\n",
            "t = 10, avg_loss = 0.4227\n",
            "t = 11, avg_loss = 0.4906\n",
            "t = 12, avg_loss = 0.5853\n",
            "t = 13, avg_loss = 0.4561\n",
            "Checking accuracy on test set\n",
            "Got 159 / 200 correct (79.50)\n",
            "acc = 0.795000\n",
            "Starting epoch 12 / 80\n",
            "t = 1, avg_loss = 0.4287\n",
            "t = 2, avg_loss = 0.4454\n",
            "t = 3, avg_loss = 0.4105\n",
            "t = 4, avg_loss = 0.4372\n",
            "t = 5, avg_loss = 0.5198\n",
            "t = 6, avg_loss = 0.4589\n",
            "t = 7, avg_loss = 0.4583\n",
            "t = 8, avg_loss = 0.5180\n",
            "t = 9, avg_loss = 0.4738\n",
            "t = 10, avg_loss = 0.3808\n",
            "t = 11, avg_loss = 0.5469\n",
            "t = 12, avg_loss = 0.6716\n",
            "t = 13, avg_loss = 0.3361\n",
            "Checking accuracy on test set\n",
            "Got 164 / 200 correct (82.00)\n",
            "acc = 0.820000\n",
            "Starting epoch 13 / 80\n",
            "t = 1, avg_loss = 0.5044\n",
            "t = 2, avg_loss = 0.5461\n",
            "t = 3, avg_loss = 0.4160\n",
            "t = 4, avg_loss = 0.5534\n",
            "t = 5, avg_loss = 0.4588\n",
            "t = 6, avg_loss = 0.3784\n",
            "t = 7, avg_loss = 0.6206\n",
            "t = 8, avg_loss = 0.3466\n",
            "t = 9, avg_loss = 0.4051\n",
            "t = 10, avg_loss = 0.5534\n",
            "t = 11, avg_loss = 0.4873\n",
            "t = 12, avg_loss = 0.3949\n",
            "t = 13, avg_loss = 0.4253\n",
            "Checking accuracy on test set\n",
            "Got 158 / 200 correct (79.00)\n",
            "acc = 0.790000\n",
            "Starting epoch 14 / 80\n",
            "t = 1, avg_loss = 0.4489\n",
            "t = 2, avg_loss = 0.4635\n",
            "t = 3, avg_loss = 0.4661\n",
            "t = 4, avg_loss = 0.5169\n",
            "t = 5, avg_loss = 0.4516\n",
            "t = 6, avg_loss = 0.4351\n",
            "t = 7, avg_loss = 0.4414\n",
            "t = 8, avg_loss = 0.4761\n",
            "t = 9, avg_loss = 0.5296\n",
            "t = 10, avg_loss = 0.4211\n",
            "t = 11, avg_loss = 0.4040\n",
            "t = 12, avg_loss = 0.4854\n",
            "t = 13, avg_loss = 0.4391\n",
            "Checking accuracy on test set\n",
            "Got 163 / 200 correct (81.50)\n",
            "acc = 0.815000\n",
            "Starting epoch 15 / 80\n",
            "t = 1, avg_loss = 0.4687\n",
            "t = 2, avg_loss = 0.4057\n",
            "t = 3, avg_loss = 0.5176\n",
            "t = 4, avg_loss = 0.3879\n",
            "t = 5, avg_loss = 0.5199\n",
            "t = 6, avg_loss = 0.3403\n",
            "t = 7, avg_loss = 0.5753\n",
            "t = 8, avg_loss = 0.4190\n",
            "t = 9, avg_loss = 0.3964\n",
            "t = 10, avg_loss = 0.5026\n",
            "t = 11, avg_loss = 0.4617\n",
            "t = 12, avg_loss = 0.5029\n",
            "t = 13, avg_loss = 0.3106\n",
            "Checking accuracy on test set\n",
            "Got 166 / 200 correct (83.00)\n",
            "acc = 0.830000\n",
            "Starting epoch 16 / 80\n",
            "t = 1, avg_loss = 0.4198\n",
            "t = 2, avg_loss = 0.3887\n",
            "t = 3, avg_loss = 0.4263\n",
            "t = 4, avg_loss = 0.5868\n",
            "t = 5, avg_loss = 0.4576\n",
            "t = 6, avg_loss = 0.4878\n",
            "t = 7, avg_loss = 0.4330\n",
            "t = 8, avg_loss = 0.4102\n",
            "t = 9, avg_loss = 0.3747\n",
            "t = 10, avg_loss = 0.3741\n",
            "t = 11, avg_loss = 0.3990\n",
            "t = 12, avg_loss = 0.6023\n",
            "t = 13, avg_loss = 0.4201\n",
            "Checking accuracy on test set\n",
            "Got 169 / 200 correct (84.50)\n",
            "acc = 0.845000\n",
            "Starting epoch 17 / 80\n",
            "t = 1, avg_loss = 0.4396\n",
            "t = 2, avg_loss = 0.4053\n",
            "t = 3, avg_loss = 0.4112\n",
            "t = 4, avg_loss = 0.4932\n",
            "t = 5, avg_loss = 0.4222\n",
            "t = 6, avg_loss = 0.3843\n",
            "t = 7, avg_loss = 0.3426\n",
            "t = 8, avg_loss = 0.3429\n",
            "t = 9, avg_loss = 0.4521\n",
            "t = 10, avg_loss = 0.4473\n",
            "t = 11, avg_loss = 0.4721\n",
            "t = 12, avg_loss = 0.4754\n",
            "t = 13, avg_loss = 0.6048\n",
            "Checking accuracy on test set\n",
            "Got 166 / 200 correct (83.00)\n",
            "acc = 0.830000\n",
            "Starting epoch 18 / 80\n",
            "t = 1, avg_loss = 0.3794\n",
            "t = 2, avg_loss = 0.5475\n",
            "t = 3, avg_loss = 0.3704\n",
            "t = 4, avg_loss = 0.3866\n",
            "t = 5, avg_loss = 0.5006\n",
            "t = 6, avg_loss = 0.4485\n",
            "t = 7, avg_loss = 0.3560\n",
            "t = 8, avg_loss = 0.5254\n",
            "t = 9, avg_loss = 0.4074\n",
            "t = 10, avg_loss = 0.4246\n",
            "t = 11, avg_loss = 0.4132\n",
            "t = 12, avg_loss = 0.4183\n",
            "t = 13, avg_loss = 0.4657\n",
            "Checking accuracy on test set\n",
            "Got 160 / 200 correct (80.00)\n",
            "acc = 0.800000\n",
            "Starting epoch 19 / 80\n",
            "t = 1, avg_loss = 0.5367\n",
            "t = 2, avg_loss = 0.3741\n",
            "t = 3, avg_loss = 0.4024\n",
            "t = 4, avg_loss = 0.6368\n",
            "t = 5, avg_loss = 0.4358\n",
            "t = 6, avg_loss = 0.3767\n",
            "t = 7, avg_loss = 0.3903\n",
            "t = 8, avg_loss = 0.3610\n",
            "t = 9, avg_loss = 0.3743\n",
            "t = 10, avg_loss = 0.3429\n",
            "t = 11, avg_loss = 0.5234\n",
            "t = 12, avg_loss = 0.3936\n",
            "t = 13, avg_loss = 0.4014\n",
            "Checking accuracy on test set\n",
            "Got 163 / 200 correct (81.50)\n",
            "acc = 0.815000\n",
            "Starting epoch 20 / 80\n",
            "t = 1, avg_loss = 0.4356\n",
            "t = 2, avg_loss = 0.4012\n",
            "t = 3, avg_loss = 0.4409\n",
            "t = 4, avg_loss = 0.4405\n",
            "t = 5, avg_loss = 0.4803\n",
            "t = 6, avg_loss = 0.3724\n",
            "t = 7, avg_loss = 0.4558\n",
            "t = 8, avg_loss = 0.3770\n",
            "t = 9, avg_loss = 0.4936\n",
            "t = 10, avg_loss = 0.4312\n",
            "t = 11, avg_loss = 0.4401\n",
            "t = 12, avg_loss = 0.4038\n",
            "t = 13, avg_loss = 0.7527\n",
            "Checking accuracy on test set\n",
            "Got 165 / 200 correct (82.50)\n",
            "acc = 0.825000\n",
            "Starting epoch 21 / 80\n",
            "t = 1, avg_loss = 0.4433\n",
            "t = 2, avg_loss = 0.3971\n",
            "t = 3, avg_loss = 0.5661\n",
            "t = 4, avg_loss = 0.4283\n",
            "t = 5, avg_loss = 0.5092\n",
            "t = 6, avg_loss = 0.4553\n",
            "t = 7, avg_loss = 0.4273\n",
            "t = 8, avg_loss = 0.3486\n",
            "t = 9, avg_loss = 0.4581\n",
            "t = 10, avg_loss = 0.5114\n",
            "t = 11, avg_loss = 0.4398\n",
            "t = 12, avg_loss = 0.4279\n",
            "t = 13, avg_loss = 0.4681\n",
            "Checking accuracy on test set\n",
            "Got 165 / 200 correct (82.50)\n",
            "acc = 0.825000\n",
            "Starting epoch 22 / 80\n",
            "t = 1, avg_loss = 0.3306\n",
            "t = 2, avg_loss = 0.3153\n",
            "t = 3, avg_loss = 0.3759\n",
            "t = 4, avg_loss = 0.2793\n",
            "t = 5, avg_loss = 0.5236\n",
            "t = 6, avg_loss = 0.4452\n",
            "t = 7, avg_loss = 0.3262\n",
            "t = 8, avg_loss = 0.4053\n",
            "t = 9, avg_loss = 0.4779\n",
            "t = 10, avg_loss = 0.3600\n",
            "t = 11, avg_loss = 0.5847\n",
            "t = 12, avg_loss = 0.5084\n",
            "t = 13, avg_loss = 0.4814\n",
            "Checking accuracy on test set\n",
            "Got 169 / 200 correct (84.50)\n",
            "acc = 0.845000\n",
            "Starting epoch 23 / 80\n",
            "t = 1, avg_loss = 0.4529\n",
            "t = 2, avg_loss = 0.4332\n",
            "t = 3, avg_loss = 0.4156\n",
            "t = 4, avg_loss = 0.4264\n",
            "t = 5, avg_loss = 0.4320\n",
            "t = 6, avg_loss = 0.4368\n",
            "t = 7, avg_loss = 0.3920\n",
            "t = 8, avg_loss = 0.6037\n",
            "t = 9, avg_loss = 0.2663\n",
            "t = 10, avg_loss = 0.3050\n",
            "t = 11, avg_loss = 0.3484\n",
            "t = 12, avg_loss = 0.4036\n",
            "t = 13, avg_loss = 0.4988\n",
            "Checking accuracy on test set\n",
            "Got 159 / 200 correct (79.50)\n",
            "acc = 0.795000\n",
            "Starting epoch 24 / 80\n",
            "t = 1, avg_loss = 0.3911\n",
            "t = 2, avg_loss = 0.4503\n",
            "t = 3, avg_loss = 0.3038\n",
            "t = 4, avg_loss = 0.4148\n",
            "t = 5, avg_loss = 0.3817\n",
            "t = 6, avg_loss = 0.4745\n",
            "t = 7, avg_loss = 0.3862\n",
            "t = 8, avg_loss = 0.4475\n",
            "t = 9, avg_loss = 0.4090\n",
            "t = 10, avg_loss = 0.4886\n",
            "t = 11, avg_loss = 0.4092\n",
            "t = 12, avg_loss = 0.4275\n",
            "t = 13, avg_loss = 0.3786\n",
            "Checking accuracy on test set\n",
            "Got 174 / 200 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 25 / 80\n",
            "t = 1, avg_loss = 0.5414\n",
            "t = 2, avg_loss = 0.2766\n",
            "t = 3, avg_loss = 0.4693\n",
            "t = 4, avg_loss = 0.3405\n",
            "t = 5, avg_loss = 0.4848\n",
            "t = 6, avg_loss = 0.4970\n",
            "t = 7, avg_loss = 0.4001\n",
            "t = 8, avg_loss = 0.3875\n",
            "t = 9, avg_loss = 0.2772\n",
            "t = 10, avg_loss = 0.3794\n",
            "t = 11, avg_loss = 0.4999\n",
            "t = 12, avg_loss = 0.4705\n",
            "t = 13, avg_loss = 0.4240\n",
            "Checking accuracy on test set\n",
            "Got 168 / 200 correct (84.00)\n",
            "acc = 0.840000\n",
            "Starting epoch 26 / 80\n",
            "t = 1, avg_loss = 0.4014\n",
            "t = 2, avg_loss = 0.3911\n",
            "t = 3, avg_loss = 0.3466\n",
            "t = 4, avg_loss = 0.4597\n",
            "t = 5, avg_loss = 0.3416\n",
            "t = 6, avg_loss = 0.3596\n",
            "t = 7, avg_loss = 0.3700\n",
            "t = 8, avg_loss = 0.4199\n",
            "t = 9, avg_loss = 0.3193\n",
            "t = 10, avg_loss = 0.4229\n",
            "t = 11, avg_loss = 0.3617\n",
            "t = 12, avg_loss = 0.4883\n",
            "t = 13, avg_loss = 0.5630\n",
            "Checking accuracy on test set\n",
            "Got 174 / 200 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 27 / 80\n",
            "t = 1, avg_loss = 0.3889\n",
            "t = 2, avg_loss = 0.4420\n",
            "t = 3, avg_loss = 0.2965\n",
            "t = 4, avg_loss = 0.2696\n",
            "t = 5, avg_loss = 0.3766\n",
            "t = 6, avg_loss = 0.3342\n",
            "t = 7, avg_loss = 0.4541\n",
            "t = 8, avg_loss = 0.4981\n",
            "t = 9, avg_loss = 0.4590\n",
            "t = 10, avg_loss = 0.4799\n",
            "t = 11, avg_loss = 0.4204\n",
            "t = 12, avg_loss = 0.4452\n",
            "t = 13, avg_loss = 0.3934\n",
            "Checking accuracy on test set\n",
            "Got 168 / 200 correct (84.00)\n",
            "acc = 0.840000\n",
            "Starting epoch 28 / 80\n",
            "t = 1, avg_loss = 0.4167\n",
            "t = 2, avg_loss = 0.4223\n",
            "t = 3, avg_loss = 0.4448\n",
            "t = 4, avg_loss = 0.3644\n",
            "t = 5, avg_loss = 0.3257\n",
            "t = 6, avg_loss = 0.3302\n",
            "t = 7, avg_loss = 0.4700\n",
            "t = 8, avg_loss = 0.3901\n",
            "t = 9, avg_loss = 0.3360\n",
            "t = 10, avg_loss = 0.3554\n",
            "t = 11, avg_loss = 0.5152\n",
            "t = 12, avg_loss = 0.4364\n",
            "t = 13, avg_loss = 0.2949\n",
            "Checking accuracy on test set\n",
            "Got 162 / 200 correct (81.00)\n",
            "acc = 0.810000\n",
            "Starting epoch 29 / 80\n",
            "t = 1, avg_loss = 0.4914\n",
            "t = 2, avg_loss = 0.2521\n",
            "t = 3, avg_loss = 0.3473\n",
            "t = 4, avg_loss = 0.3857\n",
            "t = 5, avg_loss = 0.4337\n",
            "t = 6, avg_loss = 0.3336\n",
            "t = 7, avg_loss = 0.3389\n",
            "t = 8, avg_loss = 0.3738\n",
            "t = 9, avg_loss = 0.3566\n",
            "t = 10, avg_loss = 0.4991\n",
            "t = 11, avg_loss = 0.4271\n",
            "t = 12, avg_loss = 0.3749\n",
            "t = 13, avg_loss = 0.5017\n",
            "Checking accuracy on test set\n",
            "Got 169 / 200 correct (84.50)\n",
            "acc = 0.845000\n",
            "Starting epoch 30 / 80\n",
            "t = 1, avg_loss = 0.4127\n",
            "t = 2, avg_loss = 0.4176\n",
            "t = 3, avg_loss = 0.2998\n",
            "t = 4, avg_loss = 0.2741\n",
            "t = 5, avg_loss = 0.3341\n",
            "t = 6, avg_loss = 0.3461\n",
            "t = 7, avg_loss = 0.3034\n",
            "t = 8, avg_loss = 0.4365\n",
            "t = 9, avg_loss = 0.4524\n",
            "t = 10, avg_loss = 0.4499\n",
            "t = 11, avg_loss = 0.3771\n",
            "t = 12, avg_loss = 0.4458\n",
            "t = 13, avg_loss = 0.3409\n",
            "Checking accuracy on test set\n",
            "Got 169 / 200 correct (84.50)\n",
            "acc = 0.845000\n",
            "Starting epoch 31 / 80\n",
            "t = 1, avg_loss = 0.3912\n",
            "t = 2, avg_loss = 0.3245\n",
            "t = 3, avg_loss = 0.4567\n",
            "t = 4, avg_loss = 0.3468\n",
            "t = 5, avg_loss = 0.4379\n",
            "t = 6, avg_loss = 0.3677\n",
            "t = 7, avg_loss = 0.3644\n",
            "t = 8, avg_loss = 0.3107\n",
            "t = 9, avg_loss = 0.4102\n",
            "t = 10, avg_loss = 0.4063\n",
            "t = 11, avg_loss = 0.4946\n",
            "t = 12, avg_loss = 0.3694\n",
            "t = 13, avg_loss = 0.2575\n",
            "Checking accuracy on test set\n",
            "Got 176 / 200 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 32 / 80\n",
            "t = 1, avg_loss = 0.4145\n",
            "t = 2, avg_loss = 0.3282\n",
            "t = 3, avg_loss = 0.4224\n",
            "t = 4, avg_loss = 0.3662\n",
            "t = 5, avg_loss = 0.4483\n",
            "t = 6, avg_loss = 0.6385\n",
            "t = 7, avg_loss = 0.2875\n",
            "t = 8, avg_loss = 0.3269\n",
            "t = 9, avg_loss = 0.3974\n",
            "t = 10, avg_loss = 0.3468\n",
            "t = 11, avg_loss = 0.2777\n",
            "t = 12, avg_loss = 0.4018\n",
            "t = 13, avg_loss = 0.3470\n",
            "Checking accuracy on test set\n",
            "Got 168 / 200 correct (84.00)\n",
            "acc = 0.840000\n",
            "Starting epoch 33 / 80\n",
            "t = 1, avg_loss = 0.4652\n",
            "t = 2, avg_loss = 0.3172\n",
            "t = 3, avg_loss = 0.3534\n",
            "t = 4, avg_loss = 0.2872\n",
            "t = 5, avg_loss = 0.3639\n",
            "t = 6, avg_loss = 0.2981\n",
            "t = 7, avg_loss = 0.4388\n",
            "t = 8, avg_loss = 0.2943\n",
            "t = 9, avg_loss = 0.3911\n",
            "t = 10, avg_loss = 0.3630\n",
            "t = 11, avg_loss = 0.3872\n",
            "t = 12, avg_loss = 0.3236\n",
            "t = 13, avg_loss = 0.3639\n",
            "Checking accuracy on test set\n",
            "Got 175 / 200 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 34 / 80\n",
            "t = 1, avg_loss = 0.2654\n",
            "t = 2, avg_loss = 0.3735\n",
            "t = 3, avg_loss = 0.4906\n",
            "t = 4, avg_loss = 0.3756\n",
            "t = 5, avg_loss = 0.3578\n",
            "t = 6, avg_loss = 0.3825\n",
            "t = 7, avg_loss = 0.4189\n",
            "t = 8, avg_loss = 0.2818\n",
            "t = 9, avg_loss = 0.5049\n",
            "t = 10, avg_loss = 0.3614\n",
            "t = 11, avg_loss = 0.3225\n",
            "t = 12, avg_loss = 0.3322\n",
            "t = 13, avg_loss = 0.2954\n",
            "Checking accuracy on test set\n",
            "Got 172 / 200 correct (86.00)\n",
            "acc = 0.860000\n",
            "Starting epoch 35 / 80\n",
            "t = 1, avg_loss = 0.4534\n",
            "t = 2, avg_loss = 0.3378\n",
            "t = 3, avg_loss = 0.3778\n",
            "t = 4, avg_loss = 0.2514\n",
            "t = 5, avg_loss = 0.2991\n",
            "t = 6, avg_loss = 0.3682\n",
            "t = 7, avg_loss = 0.3843\n",
            "t = 8, avg_loss = 0.4123\n",
            "t = 9, avg_loss = 0.3230\n",
            "t = 10, avg_loss = 0.4136\n",
            "t = 11, avg_loss = 0.3467\n",
            "t = 12, avg_loss = 0.3569\n",
            "t = 13, avg_loss = 0.4237\n",
            "Checking accuracy on test set\n",
            "Got 174 / 200 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 36 / 80\n",
            "t = 1, avg_loss = 0.3629\n",
            "t = 2, avg_loss = 0.3970\n",
            "t = 3, avg_loss = 0.5457\n",
            "t = 4, avg_loss = 0.3237\n",
            "t = 5, avg_loss = 0.3258\n",
            "t = 6, avg_loss = 0.3643\n",
            "t = 7, avg_loss = 0.4792\n",
            "t = 8, avg_loss = 0.2682\n",
            "t = 9, avg_loss = 0.3565\n",
            "t = 10, avg_loss = 0.5021\n",
            "t = 11, avg_loss = 0.3057\n",
            "t = 12, avg_loss = 0.3044\n",
            "t = 13, avg_loss = 0.3907\n",
            "Checking accuracy on test set\n",
            "Got 173 / 200 correct (86.50)\n",
            "acc = 0.865000\n",
            "Starting epoch 37 / 80\n",
            "t = 1, avg_loss = 0.3264\n",
            "t = 2, avg_loss = 0.4665\n",
            "t = 3, avg_loss = 0.3149\n",
            "t = 4, avg_loss = 0.4114\n",
            "t = 5, avg_loss = 0.3893\n",
            "t = 6, avg_loss = 0.3375\n",
            "t = 7, avg_loss = 0.3826\n",
            "t = 8, avg_loss = 0.4264\n",
            "t = 9, avg_loss = 0.3869\n",
            "t = 10, avg_loss = 0.3184\n",
            "t = 11, avg_loss = 0.2871\n",
            "t = 12, avg_loss = 0.3592\n",
            "t = 13, avg_loss = 0.4027\n",
            "Checking accuracy on test set\n",
            "Got 172 / 200 correct (86.00)\n",
            "acc = 0.860000\n",
            "Starting epoch 38 / 80\n",
            "t = 1, avg_loss = 0.5433\n",
            "t = 2, avg_loss = 0.4470\n",
            "t = 3, avg_loss = 0.3156\n",
            "t = 4, avg_loss = 0.3803\n",
            "t = 5, avg_loss = 0.2997\n",
            "t = 6, avg_loss = 0.3524\n",
            "t = 7, avg_loss = 0.2783\n",
            "t = 8, avg_loss = 0.4876\n",
            "t = 9, avg_loss = 0.3773\n",
            "t = 10, avg_loss = 0.3751\n",
            "t = 11, avg_loss = 0.3072\n",
            "t = 12, avg_loss = 0.3103\n",
            "t = 13, avg_loss = 0.5537\n",
            "Checking accuracy on test set\n",
            "Got 175 / 200 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 39 / 80\n",
            "t = 1, avg_loss = 0.2884\n",
            "t = 2, avg_loss = 0.4051\n",
            "t = 3, avg_loss = 0.3338\n",
            "t = 4, avg_loss = 0.2937\n",
            "t = 5, avg_loss = 0.2852\n",
            "t = 6, avg_loss = 0.3735\n",
            "t = 7, avg_loss = 0.3347\n",
            "t = 8, avg_loss = 0.4865\n",
            "t = 9, avg_loss = 0.4504\n",
            "t = 10, avg_loss = 0.3928\n",
            "t = 11, avg_loss = 0.4110\n",
            "t = 12, avg_loss = 0.4135\n",
            "t = 13, avg_loss = 0.2772\n",
            "Checking accuracy on test set\n",
            "Got 177 / 200 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 40 / 80\n",
            "t = 1, avg_loss = 0.2723\n",
            "t = 2, avg_loss = 0.5050\n",
            "t = 3, avg_loss = 0.3845\n",
            "t = 4, avg_loss = 0.3436\n",
            "t = 5, avg_loss = 0.3787\n",
            "t = 6, avg_loss = 0.3574\n",
            "t = 7, avg_loss = 0.3873\n",
            "t = 8, avg_loss = 0.3630\n",
            "t = 9, avg_loss = 0.2344\n",
            "t = 10, avg_loss = 0.3985\n",
            "t = 11, avg_loss = 0.3397\n",
            "t = 12, avg_loss = 0.4336\n",
            "t = 13, avg_loss = 0.5122\n",
            "Checking accuracy on test set\n",
            "Got 174 / 200 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 41 / 80\n",
            "t = 1, avg_loss = 0.3492\n",
            "t = 2, avg_loss = 0.2807\n",
            "t = 3, avg_loss = 0.3663\n",
            "t = 4, avg_loss = 0.3327\n",
            "t = 5, avg_loss = 0.3432\n",
            "t = 6, avg_loss = 0.4082\n",
            "t = 7, avg_loss = 0.2930\n",
            "t = 8, avg_loss = 0.3180\n",
            "t = 9, avg_loss = 0.4845\n",
            "t = 10, avg_loss = 0.4842\n",
            "t = 11, avg_loss = 0.3013\n",
            "t = 12, avg_loss = 0.4044\n",
            "t = 13, avg_loss = 0.3383\n",
            "Checking accuracy on test set\n",
            "Got 172 / 200 correct (86.00)\n",
            "acc = 0.860000\n",
            "Starting epoch 42 / 80\n",
            "t = 1, avg_loss = 0.2743\n",
            "t = 2, avg_loss = 0.2705\n",
            "t = 3, avg_loss = 0.3273\n",
            "t = 4, avg_loss = 0.2650\n",
            "t = 5, avg_loss = 0.3186\n",
            "t = 6, avg_loss = 0.3784\n",
            "t = 7, avg_loss = 0.4373\n",
            "t = 8, avg_loss = 0.2954\n",
            "t = 9, avg_loss = 0.4673\n",
            "t = 10, avg_loss = 0.3844\n",
            "t = 11, avg_loss = 0.2866\n",
            "t = 12, avg_loss = 0.2734\n",
            "t = 13, avg_loss = 0.4534\n",
            "Checking accuracy on test set\n",
            "Got 175 / 200 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 43 / 80\n",
            "t = 1, avg_loss = 0.3686\n",
            "t = 2, avg_loss = 0.4379\n",
            "t = 3, avg_loss = 0.3622\n",
            "t = 4, avg_loss = 0.2402\n",
            "t = 5, avg_loss = 0.3405\n",
            "t = 6, avg_loss = 0.3819\n",
            "t = 7, avg_loss = 0.3992\n",
            "t = 8, avg_loss = 0.6002\n",
            "t = 9, avg_loss = 0.4389\n",
            "t = 10, avg_loss = 0.1982\n",
            "t = 11, avg_loss = 0.4081\n",
            "t = 12, avg_loss = 0.3601\n",
            "t = 13, avg_loss = 0.3202\n",
            "Checking accuracy on test set\n",
            "Got 168 / 200 correct (84.00)\n",
            "acc = 0.840000\n",
            "Starting epoch 44 / 80\n",
            "t = 1, avg_loss = 0.3678\n",
            "t = 2, avg_loss = 0.4830\n",
            "t = 3, avg_loss = 0.5006\n",
            "t = 4, avg_loss = 0.3427\n",
            "t = 5, avg_loss = 0.3174\n",
            "t = 6, avg_loss = 0.2807\n",
            "t = 7, avg_loss = 0.2626\n",
            "t = 8, avg_loss = 0.3200\n",
            "t = 9, avg_loss = 0.3866\n",
            "t = 10, avg_loss = 0.2656\n",
            "t = 11, avg_loss = 0.3588\n",
            "t = 12, avg_loss = 0.3965\n",
            "t = 13, avg_loss = 0.3007\n",
            "Checking accuracy on test set\n",
            "Got 174 / 200 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 45 / 80\n",
            "t = 1, avg_loss = 0.3422\n",
            "t = 2, avg_loss = 0.2900\n",
            "t = 3, avg_loss = 0.3369\n",
            "t = 4, avg_loss = 0.4285\n",
            "t = 5, avg_loss = 0.3228\n",
            "t = 6, avg_loss = 0.4086\n",
            "t = 7, avg_loss = 0.3408\n",
            "t = 8, avg_loss = 0.2506\n",
            "t = 9, avg_loss = 0.3804\n",
            "t = 10, avg_loss = 0.3418\n",
            "t = 11, avg_loss = 0.3249\n",
            "t = 12, avg_loss = 0.3259\n",
            "t = 13, avg_loss = 0.2621\n",
            "Checking accuracy on test set\n",
            "Got 174 / 200 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 46 / 80\n",
            "t = 1, avg_loss = 0.2918\n",
            "t = 2, avg_loss = 0.3402\n",
            "t = 3, avg_loss = 0.2953\n",
            "t = 4, avg_loss = 0.2912\n",
            "t = 5, avg_loss = 0.2392\n",
            "t = 6, avg_loss = 0.2746\n",
            "t = 7, avg_loss = 0.4343\n",
            "t = 8, avg_loss = 0.3350\n",
            "t = 9, avg_loss = 0.4789\n",
            "t = 10, avg_loss = 0.2893\n",
            "t = 11, avg_loss = 0.3173\n",
            "t = 12, avg_loss = 0.4403\n",
            "t = 13, avg_loss = 0.2598\n",
            "Checking accuracy on test set\n",
            "Got 173 / 200 correct (86.50)\n",
            "acc = 0.865000\n",
            "Starting epoch 47 / 80\n",
            "t = 1, avg_loss = 0.3183\n",
            "t = 2, avg_loss = 0.3761\n",
            "t = 3, avg_loss = 0.3290\n",
            "t = 4, avg_loss = 0.2573\n",
            "t = 5, avg_loss = 0.3327\n",
            "t = 6, avg_loss = 0.4172\n",
            "t = 7, avg_loss = 0.3881\n",
            "t = 8, avg_loss = 0.3225\n",
            "t = 9, avg_loss = 0.2641\n",
            "t = 10, avg_loss = 0.3375\n",
            "t = 11, avg_loss = 0.3027\n",
            "t = 12, avg_loss = 0.2990\n",
            "t = 13, avg_loss = 0.2499\n",
            "Checking accuracy on test set\n",
            "Got 167 / 200 correct (83.50)\n",
            "acc = 0.835000\n",
            "Starting epoch 48 / 80\n",
            "t = 1, avg_loss = 0.4000\n",
            "t = 2, avg_loss = 0.3166\n",
            "t = 3, avg_loss = 0.3475\n",
            "t = 4, avg_loss = 0.2681\n",
            "t = 5, avg_loss = 0.3177\n",
            "t = 6, avg_loss = 0.3172\n",
            "t = 7, avg_loss = 0.3462\n",
            "t = 8, avg_loss = 0.3962\n",
            "t = 9, avg_loss = 0.2730\n",
            "t = 10, avg_loss = 0.2465\n",
            "t = 11, avg_loss = 0.2934\n",
            "t = 12, avg_loss = 0.4093\n",
            "t = 13, avg_loss = 0.2976\n",
            "Checking accuracy on test set\n",
            "Got 177 / 200 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 49 / 80\n",
            "t = 1, avg_loss = 0.3109\n",
            "t = 2, avg_loss = 0.4134\n",
            "t = 3, avg_loss = 0.3073\n",
            "t = 4, avg_loss = 0.2095\n",
            "t = 5, avg_loss = 0.2181\n",
            "t = 6, avg_loss = 0.3078\n",
            "t = 7, avg_loss = 0.3717\n",
            "t = 8, avg_loss = 0.4519\n",
            "t = 9, avg_loss = 0.5416\n",
            "t = 10, avg_loss = 0.4081\n",
            "t = 11, avg_loss = 0.2714\n",
            "t = 12, avg_loss = 0.3865\n",
            "t = 13, avg_loss = 0.2493\n",
            "Checking accuracy on test set\n",
            "Got 171 / 200 correct (85.50)\n",
            "acc = 0.855000\n",
            "Starting epoch 50 / 80\n",
            "t = 1, avg_loss = 0.2999\n",
            "t = 2, avg_loss = 0.3052\n",
            "t = 3, avg_loss = 0.3622\n",
            "t = 4, avg_loss = 0.2809\n",
            "t = 5, avg_loss = 0.3589\n",
            "t = 6, avg_loss = 0.4266\n",
            "t = 7, avg_loss = 0.3378\n",
            "t = 8, avg_loss = 0.2354\n",
            "t = 9, avg_loss = 0.3381\n",
            "t = 10, avg_loss = 0.4743\n",
            "t = 11, avg_loss = 0.3190\n",
            "t = 12, avg_loss = 0.2593\n",
            "t = 13, avg_loss = 0.3144\n",
            "Checking accuracy on test set\n",
            "Got 176 / 200 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 51 / 80\n",
            "t = 1, avg_loss = 0.2856\n",
            "t = 2, avg_loss = 0.3164\n",
            "t = 3, avg_loss = 0.2764\n",
            "t = 4, avg_loss = 0.3901\n",
            "t = 5, avg_loss = 0.3352\n",
            "t = 6, avg_loss = 0.2709\n",
            "t = 7, avg_loss = 0.3333\n",
            "t = 8, avg_loss = 0.2836\n",
            "t = 9, avg_loss = 0.3408\n",
            "t = 10, avg_loss = 0.2432\n",
            "t = 11, avg_loss = 0.4149\n",
            "t = 12, avg_loss = 0.4035\n",
            "t = 13, avg_loss = 0.3383\n",
            "Checking accuracy on test set\n",
            "Got 172 / 200 correct (86.00)\n",
            "acc = 0.860000\n",
            "Starting epoch 52 / 80\n",
            "t = 1, avg_loss = 0.3456\n",
            "t = 2, avg_loss = 0.2943\n",
            "t = 3, avg_loss = 0.3293\n",
            "t = 4, avg_loss = 0.2554\n",
            "t = 5, avg_loss = 0.3706\n",
            "t = 6, avg_loss = 0.3267\n",
            "t = 7, avg_loss = 0.3219\n",
            "t = 8, avg_loss = 0.4263\n",
            "t = 9, avg_loss = 0.3408\n",
            "t = 10, avg_loss = 0.3339\n",
            "t = 11, avg_loss = 0.2364\n",
            "t = 12, avg_loss = 0.3034\n",
            "t = 13, avg_loss = 0.5024\n",
            "Checking accuracy on test set\n",
            "Got 173 / 200 correct (86.50)\n",
            "acc = 0.865000\n",
            "Starting epoch 53 / 80\n",
            "t = 1, avg_loss = 0.3127\n",
            "t = 2, avg_loss = 0.3505\n",
            "t = 3, avg_loss = 0.3786\n",
            "t = 4, avg_loss = 0.3137\n",
            "t = 5, avg_loss = 0.3064\n",
            "t = 6, avg_loss = 0.2547\n",
            "t = 7, avg_loss = 0.3184\n",
            "t = 8, avg_loss = 0.2836\n",
            "t = 9, avg_loss = 0.2820\n",
            "t = 10, avg_loss = 0.3267\n",
            "t = 11, avg_loss = 0.3931\n",
            "t = 12, avg_loss = 0.3311\n",
            "t = 13, avg_loss = 0.4564\n",
            "Checking accuracy on test set\n",
            "Got 171 / 200 correct (85.50)\n",
            "acc = 0.855000\n",
            "Starting epoch 54 / 80\n",
            "t = 1, avg_loss = 0.3219\n",
            "t = 2, avg_loss = 0.2642\n",
            "t = 3, avg_loss = 0.3833\n",
            "t = 4, avg_loss = 0.2650\n",
            "t = 5, avg_loss = 0.3814\n",
            "t = 6, avg_loss = 0.4039\n",
            "t = 7, avg_loss = 0.2810\n",
            "t = 8, avg_loss = 0.5119\n",
            "t = 9, avg_loss = 0.3104\n",
            "t = 10, avg_loss = 0.5686\n",
            "t = 11, avg_loss = 0.3283\n",
            "t = 12, avg_loss = 0.4400\n",
            "t = 13, avg_loss = 0.2072\n",
            "Checking accuracy on test set\n",
            "Got 177 / 200 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 55 / 80\n",
            "t = 1, avg_loss = 0.2681\n",
            "t = 2, avg_loss = 0.3773\n",
            "t = 3, avg_loss = 0.2737\n",
            "t = 4, avg_loss = 0.3590\n",
            "t = 5, avg_loss = 0.4236\n",
            "t = 6, avg_loss = 0.3649\n",
            "t = 7, avg_loss = 0.4185\n",
            "t = 8, avg_loss = 0.3449\n",
            "t = 9, avg_loss = 0.3452\n",
            "t = 10, avg_loss = 0.2795\n",
            "t = 11, avg_loss = 0.3889\n",
            "t = 12, avg_loss = 0.3487\n",
            "t = 13, avg_loss = 0.2602\n",
            "Checking accuracy on test set\n",
            "Got 170 / 200 correct (85.00)\n",
            "acc = 0.850000\n",
            "Starting epoch 56 / 80\n",
            "t = 1, avg_loss = 0.2518\n",
            "t = 2, avg_loss = 0.2777\n",
            "t = 3, avg_loss = 0.4720\n",
            "t = 4, avg_loss = 0.3259\n",
            "t = 5, avg_loss = 0.2888\n",
            "t = 6, avg_loss = 0.3228\n",
            "t = 7, avg_loss = 0.2637\n",
            "t = 8, avg_loss = 0.4686\n",
            "t = 9, avg_loss = 0.3073\n",
            "t = 10, avg_loss = 0.2579\n",
            "t = 11, avg_loss = 0.4183\n",
            "t = 12, avg_loss = 0.2762\n",
            "t = 13, avg_loss = 0.3208\n",
            "Checking accuracy on test set\n",
            "Got 177 / 200 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 57 / 80\n",
            "t = 1, avg_loss = 0.3317\n",
            "t = 2, avg_loss = 0.3095\n",
            "t = 3, avg_loss = 0.2845\n",
            "t = 4, avg_loss = 0.3317\n",
            "t = 5, avg_loss = 0.2911\n",
            "t = 6, avg_loss = 0.4274\n",
            "t = 7, avg_loss = 0.3625\n",
            "t = 8, avg_loss = 0.2760\n",
            "t = 9, avg_loss = 0.3835\n",
            "t = 10, avg_loss = 0.3623\n",
            "t = 11, avg_loss = 0.4079\n",
            "t = 12, avg_loss = 0.4897\n",
            "t = 13, avg_loss = 0.2633\n",
            "Checking accuracy on test set\n",
            "Got 174 / 200 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 58 / 80\n",
            "t = 1, avg_loss = 0.3526\n",
            "t = 2, avg_loss = 0.2612\n",
            "t = 3, avg_loss = 0.2935\n",
            "t = 4, avg_loss = 0.2297\n",
            "t = 5, avg_loss = 0.3343\n",
            "t = 6, avg_loss = 0.4660\n",
            "t = 7, avg_loss = 0.3259\n",
            "t = 8, avg_loss = 0.3137\n",
            "t = 9, avg_loss = 0.3525\n",
            "t = 10, avg_loss = 0.3462\n",
            "t = 11, avg_loss = 0.4236\n",
            "t = 12, avg_loss = 0.4016\n",
            "t = 13, avg_loss = 0.4170\n",
            "Checking accuracy on test set\n",
            "Got 173 / 200 correct (86.50)\n",
            "acc = 0.865000\n",
            "Starting epoch 59 / 80\n",
            "t = 1, avg_loss = 0.1931\n",
            "t = 2, avg_loss = 0.2976\n",
            "t = 3, avg_loss = 0.3258\n",
            "t = 4, avg_loss = 0.3318\n",
            "t = 5, avg_loss = 0.2547\n",
            "t = 6, avg_loss = 0.3193\n",
            "t = 7, avg_loss = 0.4453\n",
            "t = 8, avg_loss = 0.3949\n",
            "t = 9, avg_loss = 0.2781\n",
            "t = 10, avg_loss = 0.2797\n",
            "t = 11, avg_loss = 0.4874\n",
            "t = 12, avg_loss = 0.3894\n",
            "t = 13, avg_loss = 0.2403\n",
            "Checking accuracy on test set\n",
            "Got 174 / 200 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 60 / 80\n",
            "t = 1, avg_loss = 0.2755\n",
            "t = 2, avg_loss = 0.3415\n",
            "t = 3, avg_loss = 0.2962\n",
            "t = 4, avg_loss = 0.2782\n",
            "t = 5, avg_loss = 0.2949\n",
            "t = 6, avg_loss = 0.3890\n",
            "t = 7, avg_loss = 0.2611\n",
            "t = 8, avg_loss = 0.3798\n",
            "t = 9, avg_loss = 0.3589\n",
            "t = 10, avg_loss = 0.2423\n",
            "t = 11, avg_loss = 0.3263\n",
            "t = 12, avg_loss = 0.3764\n",
            "t = 13, avg_loss = 0.3195\n",
            "Checking accuracy on test set\n",
            "Got 174 / 200 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 61 / 80\n",
            "t = 1, avg_loss = 0.2482\n",
            "t = 2, avg_loss = 0.3269\n",
            "t = 3, avg_loss = 0.3492\n",
            "t = 4, avg_loss = 0.2964\n",
            "t = 5, avg_loss = 0.3221\n",
            "t = 6, avg_loss = 0.2559\n",
            "t = 7, avg_loss = 0.2660\n",
            "t = 8, avg_loss = 0.2485\n",
            "t = 9, avg_loss = 0.3745\n",
            "t = 10, avg_loss = 0.3530\n",
            "t = 11, avg_loss = 0.3389\n",
            "t = 12, avg_loss = 0.2728\n",
            "t = 13, avg_loss = 0.5319\n",
            "Checking accuracy on test set\n",
            "Got 172 / 200 correct (86.00)\n",
            "acc = 0.860000\n",
            "Starting epoch 62 / 80\n",
            "t = 1, avg_loss = 0.4012\n",
            "t = 2, avg_loss = 0.2812\n",
            "t = 3, avg_loss = 0.2526\n",
            "t = 4, avg_loss = 0.3374\n",
            "t = 5, avg_loss = 0.4936\n",
            "t = 6, avg_loss = 0.2753\n",
            "t = 7, avg_loss = 0.2336\n",
            "t = 8, avg_loss = 0.3235\n",
            "t = 9, avg_loss = 0.3130\n",
            "t = 10, avg_loss = 0.2912\n",
            "t = 11, avg_loss = 0.3319\n",
            "t = 12, avg_loss = 0.2617\n",
            "t = 13, avg_loss = 0.3892\n",
            "Checking accuracy on test set\n",
            "Got 172 / 200 correct (86.00)\n",
            "acc = 0.860000\n",
            "Starting epoch 63 / 80\n",
            "t = 1, avg_loss = 0.4514\n",
            "t = 2, avg_loss = 0.3266\n",
            "t = 3, avg_loss = 0.2572\n",
            "t = 4, avg_loss = 0.2419\n",
            "t = 5, avg_loss = 0.2856\n",
            "t = 6, avg_loss = 0.3192\n",
            "t = 7, avg_loss = 0.3648\n",
            "t = 8, avg_loss = 0.4397\n",
            "t = 9, avg_loss = 0.4492\n",
            "t = 10, avg_loss = 0.2591\n",
            "t = 11, avg_loss = 0.4514\n",
            "t = 12, avg_loss = 0.2917\n",
            "t = 13, avg_loss = 0.1911\n",
            "Checking accuracy on test set\n",
            "Got 175 / 200 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 64 / 80\n",
            "t = 1, avg_loss = 0.3109\n",
            "t = 2, avg_loss = 0.5471\n",
            "t = 3, avg_loss = 0.2950\n",
            "t = 4, avg_loss = 0.2794\n",
            "t = 5, avg_loss = 0.3377\n",
            "t = 6, avg_loss = 0.3426\n",
            "t = 7, avg_loss = 0.3549\n",
            "t = 8, avg_loss = 0.3112\n",
            "t = 9, avg_loss = 0.3111\n",
            "t = 10, avg_loss = 0.3428\n",
            "t = 11, avg_loss = 0.2621\n",
            "t = 12, avg_loss = 0.3929\n",
            "t = 13, avg_loss = 0.2971\n",
            "Checking accuracy on test set\n",
            "Got 170 / 200 correct (85.00)\n",
            "acc = 0.850000\n",
            "Starting epoch 65 / 80\n",
            "t = 1, avg_loss = 0.3974\n",
            "t = 2, avg_loss = 0.1989\n",
            "t = 3, avg_loss = 0.3714\n",
            "t = 4, avg_loss = 0.3249\n",
            "t = 5, avg_loss = 0.2506\n",
            "t = 6, avg_loss = 0.3084\n",
            "t = 7, avg_loss = 0.2415\n",
            "t = 8, avg_loss = 0.2214\n",
            "t = 9, avg_loss = 0.3428\n",
            "t = 10, avg_loss = 0.3541\n",
            "t = 11, avg_loss = 0.5177\n",
            "t = 12, avg_loss = 0.3290\n",
            "t = 13, avg_loss = 0.3132\n",
            "Checking accuracy on test set\n",
            "Got 175 / 200 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 66 / 80\n",
            "t = 1, avg_loss = 0.3342\n",
            "t = 2, avg_loss = 0.2679\n",
            "t = 3, avg_loss = 0.3460\n",
            "t = 4, avg_loss = 0.2530\n",
            "t = 5, avg_loss = 0.2869\n",
            "t = 6, avg_loss = 0.3774\n",
            "t = 7, avg_loss = 0.2125\n",
            "t = 8, avg_loss = 0.2352\n",
            "t = 9, avg_loss = 0.2518\n",
            "t = 10, avg_loss = 0.2663\n",
            "t = 11, avg_loss = 0.2817\n",
            "t = 12, avg_loss = 0.4107\n",
            "t = 13, avg_loss = 0.3621\n",
            "Checking accuracy on test set\n",
            "Got 174 / 200 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 67 / 80\n",
            "t = 1, avg_loss = 0.2002\n",
            "t = 2, avg_loss = 0.3387\n",
            "t = 3, avg_loss = 0.2251\n",
            "t = 4, avg_loss = 0.3344\n",
            "t = 5, avg_loss = 0.3110\n",
            "t = 6, avg_loss = 0.3262\n",
            "t = 7, avg_loss = 0.2688\n",
            "t = 8, avg_loss = 0.3432\n",
            "t = 9, avg_loss = 0.2687\n",
            "t = 10, avg_loss = 0.2742\n",
            "t = 11, avg_loss = 0.3152\n",
            "t = 12, avg_loss = 0.2450\n",
            "t = 13, avg_loss = 0.4110\n",
            "Checking accuracy on test set\n",
            "Got 175 / 200 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 68 / 80\n",
            "t = 1, avg_loss = 0.2287\n",
            "t = 2, avg_loss = 0.2225\n",
            "t = 3, avg_loss = 0.2256\n",
            "t = 4, avg_loss = 0.2947\n",
            "t = 5, avg_loss = 0.2772\n",
            "t = 6, avg_loss = 0.3148\n",
            "t = 7, avg_loss = 0.2980\n",
            "t = 8, avg_loss = 0.2873\n",
            "t = 9, avg_loss = 0.2364\n",
            "t = 10, avg_loss = 0.4122\n",
            "t = 11, avg_loss = 0.2688\n",
            "t = 12, avg_loss = 0.4242\n",
            "t = 13, avg_loss = 0.3375\n",
            "Checking accuracy on test set\n",
            "Got 176 / 200 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 69 / 80\n",
            "t = 1, avg_loss = 0.3394\n",
            "t = 2, avg_loss = 0.4223\n",
            "t = 3, avg_loss = 0.3336\n",
            "t = 4, avg_loss = 0.3989\n",
            "t = 5, avg_loss = 0.2503\n",
            "t = 6, avg_loss = 0.2942\n",
            "t = 7, avg_loss = 0.3685\n",
            "t = 8, avg_loss = 0.2949\n",
            "t = 9, avg_loss = 0.3729\n",
            "t = 10, avg_loss = 0.2700\n",
            "t = 11, avg_loss = 0.3304\n",
            "t = 12, avg_loss = 0.2409\n",
            "t = 13, avg_loss = 0.2682\n",
            "Checking accuracy on test set\n",
            "Got 173 / 200 correct (86.50)\n",
            "acc = 0.865000\n",
            "Starting epoch 70 / 80\n",
            "t = 1, avg_loss = 0.4307\n",
            "t = 2, avg_loss = 0.3672\n",
            "t = 3, avg_loss = 0.2790\n",
            "t = 4, avg_loss = 0.3329\n",
            "t = 5, avg_loss = 0.2819\n",
            "t = 6, avg_loss = 0.4111\n",
            "t = 7, avg_loss = 0.4614\n",
            "t = 8, avg_loss = 0.2402\n",
            "t = 9, avg_loss = 0.4158\n",
            "t = 10, avg_loss = 0.3013\n",
            "t = 11, avg_loss = 0.3168\n",
            "t = 12, avg_loss = 0.3717\n",
            "t = 13, avg_loss = 0.3296\n",
            "Checking accuracy on test set\n",
            "Got 173 / 200 correct (86.50)\n",
            "acc = 0.865000\n",
            "Starting epoch 71 / 80\n",
            "t = 1, avg_loss = 0.2966\n",
            "t = 2, avg_loss = 0.2886\n",
            "t = 3, avg_loss = 0.2967\n",
            "t = 4, avg_loss = 0.3370\n",
            "t = 5, avg_loss = 0.3057\n",
            "t = 6, avg_loss = 0.2992\n",
            "t = 7, avg_loss = 0.3235\n",
            "t = 8, avg_loss = 0.3481\n",
            "t = 9, avg_loss = 0.2718\n",
            "t = 10, avg_loss = 0.2693\n",
            "t = 11, avg_loss = 0.3185\n",
            "t = 12, avg_loss = 0.2640\n",
            "t = 13, avg_loss = 0.3645\n",
            "Checking accuracy on test set\n",
            "Got 176 / 200 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 72 / 80\n",
            "t = 1, avg_loss = 0.2875\n",
            "t = 2, avg_loss = 0.2559\n",
            "t = 3, avg_loss = 0.2571\n",
            "t = 4, avg_loss = 0.3209\n",
            "t = 5, avg_loss = 0.3042\n",
            "t = 6, avg_loss = 0.2559\n",
            "t = 7, avg_loss = 0.3767\n",
            "t = 8, avg_loss = 0.3380\n",
            "t = 9, avg_loss = 0.3795\n",
            "t = 10, avg_loss = 0.4469\n",
            "t = 11, avg_loss = 0.2911\n",
            "t = 12, avg_loss = 0.3486\n",
            "t = 13, avg_loss = 0.1847\n",
            "Checking accuracy on test set\n",
            "Got 177 / 200 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 73 / 80\n",
            "t = 1, avg_loss = 0.2424\n",
            "t = 2, avg_loss = 0.2638\n",
            "t = 3, avg_loss = 0.2711\n",
            "t = 4, avg_loss = 0.2709\n",
            "t = 5, avg_loss = 0.3749\n",
            "t = 6, avg_loss = 0.2750\n",
            "t = 7, avg_loss = 0.2912\n",
            "t = 8, avg_loss = 0.2614\n",
            "t = 9, avg_loss = 0.4024\n",
            "t = 10, avg_loss = 0.3232\n",
            "t = 11, avg_loss = 0.2760\n",
            "t = 12, avg_loss = 0.3821\n",
            "t = 13, avg_loss = 0.1744\n",
            "Checking accuracy on test set\n",
            "Got 178 / 200 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 74 / 80\n",
            "t = 1, avg_loss = 0.2325\n",
            "t = 2, avg_loss = 0.3279\n",
            "t = 3, avg_loss = 0.2035\n",
            "t = 4, avg_loss = 0.2604\n",
            "t = 5, avg_loss = 0.3386\n",
            "t = 6, avg_loss = 0.3041\n",
            "t = 7, avg_loss = 0.3608\n",
            "t = 8, avg_loss = 0.2649\n",
            "t = 9, avg_loss = 0.3356\n",
            "t = 10, avg_loss = 0.3403\n",
            "t = 11, avg_loss = 0.3268\n",
            "t = 12, avg_loss = 0.2325\n",
            "t = 13, avg_loss = 0.4702\n",
            "Checking accuracy on test set\n",
            "Got 175 / 200 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 75 / 80\n",
            "t = 1, avg_loss = 0.1947\n",
            "t = 2, avg_loss = 0.3048\n",
            "t = 3, avg_loss = 0.3076\n",
            "t = 4, avg_loss = 0.2255\n",
            "t = 5, avg_loss = 0.3016\n",
            "t = 6, avg_loss = 0.2374\n",
            "t = 7, avg_loss = 0.4370\n",
            "t = 8, avg_loss = 0.3781\n",
            "t = 9, avg_loss = 0.2335\n",
            "t = 10, avg_loss = 0.2921\n",
            "t = 11, avg_loss = 0.2900\n",
            "t = 12, avg_loss = 0.3275\n",
            "t = 13, avg_loss = 0.3325\n",
            "Checking accuracy on test set\n",
            "Got 176 / 200 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 76 / 80\n",
            "t = 1, avg_loss = 0.3384\n",
            "t = 2, avg_loss = 0.3860\n",
            "t = 3, avg_loss = 0.3403\n",
            "t = 4, avg_loss = 0.1770\n",
            "t = 5, avg_loss = 0.2619\n",
            "t = 6, avg_loss = 0.3990\n",
            "t = 7, avg_loss = 0.3190\n",
            "t = 8, avg_loss = 0.2246\n",
            "t = 9, avg_loss = 0.3343\n",
            "t = 10, avg_loss = 0.1955\n",
            "t = 11, avg_loss = 0.3653\n",
            "t = 12, avg_loss = 0.4825\n",
            "t = 13, avg_loss = 0.2540\n",
            "Checking accuracy on test set\n",
            "Got 174 / 200 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 77 / 80\n",
            "t = 1, avg_loss = 0.3495\n",
            "t = 2, avg_loss = 0.2068\n",
            "t = 3, avg_loss = 0.2404\n",
            "t = 4, avg_loss = 0.2643\n",
            "t = 5, avg_loss = 0.2507\n",
            "t = 6, avg_loss = 0.2893\n",
            "t = 7, avg_loss = 0.3680\n",
            "t = 8, avg_loss = 0.3791\n",
            "t = 9, avg_loss = 0.2422\n",
            "t = 10, avg_loss = 0.3144\n",
            "t = 11, avg_loss = 0.4165\n",
            "t = 12, avg_loss = 0.2963\n",
            "t = 13, avg_loss = 0.2357\n",
            "Checking accuracy on test set\n",
            "Got 176 / 200 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 78 / 80\n",
            "t = 1, avg_loss = 0.1979\n",
            "t = 2, avg_loss = 0.3645\n",
            "t = 3, avg_loss = 0.3414\n",
            "t = 4, avg_loss = 0.2942\n",
            "t = 5, avg_loss = 0.2253\n",
            "t = 6, avg_loss = 0.2312\n",
            "t = 7, avg_loss = 0.3326\n",
            "t = 8, avg_loss = 0.2342\n",
            "t = 9, avg_loss = 0.3637\n",
            "t = 10, avg_loss = 0.3099\n",
            "t = 11, avg_loss = 0.2892\n",
            "t = 12, avg_loss = 0.3283\n",
            "t = 13, avg_loss = 0.3880\n",
            "Checking accuracy on test set\n",
            "Got 177 / 200 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 79 / 80\n",
            "t = 1, avg_loss = 0.3507\n",
            "t = 2, avg_loss = 0.4075\n",
            "t = 3, avg_loss = 0.2315\n",
            "t = 4, avg_loss = 0.2345\n",
            "t = 5, avg_loss = 0.2905\n",
            "t = 6, avg_loss = 0.3165\n",
            "t = 7, avg_loss = 0.3581\n",
            "t = 8, avg_loss = 0.3446\n",
            "t = 9, avg_loss = 0.2792\n",
            "t = 10, avg_loss = 0.2265\n",
            "t = 11, avg_loss = 0.2449\n",
            "t = 12, avg_loss = 0.3338\n",
            "t = 13, avg_loss = 0.2892\n",
            "Checking accuracy on test set\n",
            "Got 174 / 200 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 80 / 80\n",
            "t = 1, avg_loss = 0.1780\n",
            "t = 2, avg_loss = 0.2730\n",
            "t = 3, avg_loss = 0.2723\n",
            "t = 4, avg_loss = 0.2415\n",
            "t = 5, avg_loss = 0.4871\n",
            "t = 6, avg_loss = 0.3082\n",
            "t = 7, avg_loss = 0.2570\n",
            "t = 8, avg_loss = 0.3148\n",
            "t = 9, avg_loss = 0.3061\n",
            "t = 10, avg_loss = 0.2937\n",
            "t = 11, avg_loss = 0.2845\n",
            "t = 12, avg_loss = 0.2898\n",
            "t = 13, avg_loss = 0.3753\n",
            "Checking accuracy on test set\n",
            "Got 173 / 200 correct (86.50)\n",
            "acc = 0.865000\n",
            "Checking accuracy on test set\n",
            "Got 174 / 200 correct (87.00)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.87"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hm3h_Kyyp_6h",
        "colab_type": "code",
        "outputId": "9dad81df-4dd4-4f6b-f976-2bb7d9570a30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "check_accuracy(model_gpu, valid_loader)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking accuracy on test set\n",
            "Got 175 / 200 correct (87.50)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.875"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzuX5gLEeJfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def retry_from_backup():\n",
        "  model_gpu = model_base.type(gpu_dtype)\n",
        "  print(model_gpu)\n",
        "  loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) \n",
        "\n",
        "\n",
        "\n",
        "  checkpoint = torch.load(model_backup_path)\n",
        "  model_gpu.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  epoch = checkpoint['epoch']\n",
        "  loss = checkpoint['loss']\n",
        "  print(\"starting from epoch: \" + str(epoch))\n",
        "  print(\"starting from loss: \" + str(loss))\n",
        "  print(checkpoint['model_state_dict'])\n",
        "  print(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "  train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs, starting_from_epoch=epoch)\n",
        "  check_accuracy(model_gpu, valid_loader)\n",
        "#retry_from_backup()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDn-2g-TLY3k",
        "colab_type": "code",
        "outputId": "da1f2329-12dd-4f2f-ad94-4d2557e953bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot([print_every*batch_size*(i+1) for i in range((len(avg_loss_list)))],avg_loss_list)\n",
        "print(\"Loss:\")\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGer6hJv7-zR",
        "colab_type": "code",
        "outputId": "8e270749-6214-47a2-b37d-000cb17a0617",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plt.plot([i+1 for i in range((len(acc_list)))],acc_list)\n",
        "print(\"Accurancy:\")\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accurancy:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBTReWHxz4Ml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}