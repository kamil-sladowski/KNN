{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN_Avg_No_Relu3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6a1452b4b80d438793c6cfd3ad0138c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4c353a0604f84bceb453f15893048411",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0109aeb532044697a71c7313a394686e",
              "IPY_MODEL_654483738bc44933b70cf9937f32ace2"
            ]
          }
        },
        "4c353a0604f84bceb453f15893048411": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0109aeb532044697a71c7313a394686e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_aecb9d0a3d744b65abfee1053b323387",
            "_dom_classes": [],
            "description": " 81%",
            "_model_name": "IntProgressModel",
            "bar_style": "danger",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 81,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a77020908f69411aa111fd829e8f553e"
          }
        },
        "654483738bc44933b70cf9937f32ace2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cb1ad53cf88b461b92a9aa42f18002c3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 81/100 [09:56&lt;02:11,  6.90s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6ec8a0470e684d639fb6645235e3a840"
          }
        },
        "aecb9d0a3d744b65abfee1053b323387": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a77020908f69411aa111fd829e8f553e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cb1ad53cf88b461b92a9aa42f18002c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6ec8a0470e684d639fb6645235e3a840": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamilo116/KNN/blob/master/KNN_Avg_No_Relu3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7ReM7FU-xs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import sys\n",
        "from random import shuffle\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms as transforms\n",
        "import timeit\n",
        "\n",
        "np.random.seed(4) \n",
        "torch.manual_seed(4) \n",
        "torch.cuda.manual_seed(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYIMZ8QyYewD",
        "colab_type": "code",
        "outputId": "c71f27ad-ef6a-42b9-ed5a-e22dda7145aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! git clone https://github.com/wang-chen/kervolution.git \n",
        "\n",
        "sys.path.append(\"kervolution/\")\n",
        "from kervolution import Kerv2d\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'kervolution' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvbKg4VJXKY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LIMIT_IMAGES_NUM = 500\n",
        "train_test_split_size = 0.2\n",
        "image_resize = (100, 100)\n",
        "batch_size = 64\n",
        "num_workers = 0\n",
        "\n",
        "in_channels = 3\n",
        "out_channels_1 = 16\n",
        "out_channels_x = 24\n",
        "out_channels_2 = 32\n",
        "out_channels_3 = 64\n",
        "out_channels_4 = 128\n",
        "\n",
        "kernel_size = 3\n",
        "padding_1 = 1\n",
        "num_epochs = 80\n",
        "\n",
        "learning_rate = 0.005\n",
        "weight_decay = 0\n",
        "\n",
        "MALIGNANT_DATASET = '/content/drive/My Drive/Colab_data/malignant/malignant/'\n",
        "BENIGN_DATASET = '/content/drive/My Drive/Colab_data/benign/benign/'\n",
        "DATA_FOLDER = '/content/drive/My Drive/Colab_data/'\n",
        "model_backup_path = os.path.join(DATA_FOLDER, 'backup_model') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMOHez_kHZD6",
        "colab_type": "code",
        "outputId": "d43a42f5-c46b-4bd6-bd00-9265e297b8bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b8P1NdXfVdX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "aa1b80de-fb85-4ae7-d5a2-a6616bbddaba"
      },
      "source": [
        "benign_file_list = sorted(os.listdir(BENIGN_DATASET))\n",
        "malignant_file_list = sorted(os.listdir(MALIGNANT_DATASET))\n",
        "shuffle(benign_file_list)\n",
        "shuffle(malignant_file_list)\n",
        "benign_file_list = benign_file_list[:LIMIT_IMAGES_NUM]\n",
        "malignant_file_list = malignant_file_list[:LIMIT_IMAGES_NUM]\n",
        "\n",
        "print(f\"Number of benign {len(benign_file_list)} images\")\n",
        "print(f\"Number of malignant {len(malignant_file_list)} images\")\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize(image_resize),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of benign 500 images\n",
            "Number of malignant 500 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGDQfal74BLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "benign_dict = {filename: 0 for filename in benign_file_list}\n",
        "malignant_dict = {filename: 1 for filename in malignant_file_list}\n",
        "img_class_dict = {**benign_dict , **malignant_dict}\n",
        "labeled_data = pd.Series(img_class_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvAAOqmVfVll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IsicDataset(Dataset):\n",
        "    def __init__(self, data_folder, labeled_data, \n",
        "                 transform=transforms.Compose([transforms.ToTensor()])):\n",
        "        self.labeled_data = labeled_data\n",
        "        self.transform = transform\n",
        "        self.data_folder = data_folder\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labeled_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        label = self.labeled_data[index]\n",
        "        if label == 0:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"benign\", \"benign\", index ))\n",
        "        else:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"malignant\", \"malignant\", index ))\n",
        "        image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "    @property\n",
        "    def labels(self):\n",
        "      return self.labeled_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSuYqjLAYrWA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "436e6c50-52d0-48cc-e82d-a7070469fbbe"
      },
      "source": [
        " \n",
        "dataset = IsicDataset(DATA_FOLDER, labeled_data, transform=data_transforms)\n",
        "print(dataset.labels)\n",
        "\n",
        "X_train, X_test = train_test_split(dataset.labels, test_size=train_test_split_size)\n",
        "print(\"number of training data: \",len(X_train))\n",
        "print(\"number of testing  data: \",len(X_test))\n",
        "\n",
        "train_sampler = SubsetRandomSampler(list(X_train.index))\n",
        "valid_sampler = SubsetRandomSampler(list(X_test.index))\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ISIC_0000264.jpeg    0\n",
            "ISIC_0001352.jpeg    0\n",
            "ISIC_0000755.jpeg    0\n",
            "ISIC_0001394.jpeg    0\n",
            "ISIC_0000021.jpeg    0\n",
            "                    ..\n",
            "ISIC_0024701.jpg     1\n",
            "ISIC_0000077.jpeg    1\n",
            "ISIC_0000517.jpeg    1\n",
            "ISIC_0025145.jpg     1\n",
            "ISIC_0011273.jpeg    1\n",
            "Length: 1000, dtype: int64\n",
            "number of training data:  800\n",
            "number of testing  data:  200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e8nFBR6Yug5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "def train(model, train_loader ,loss_fn, optimizer, num_epochs=1, starting_from_epoch=1):\n",
        "    total_loss =0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
        "        model.train()\n",
        "\n",
        "        for t, (x, y) in enumerate(train_loader):\n",
        "            x_var = Variable(x.type(gpu_dtype))\n",
        "            y_var = Variable(y.type(gpu_dtype).long())\n",
        "            scores = model(x_var)\n",
        "            loss = loss_fn(scores, y_var)\n",
        "            total_loss += loss.data\n",
        "            \n",
        "            if (t + 1) % print_every == 0:\n",
        "                avg_loss = total_loss/print_every\n",
        "                print('t = %d, avg_loss = %.4f' % (t + 1, avg_loss) )\n",
        "                avg_loss_list.append(avg_loss)\n",
        "                total_loss = 0\n",
        "                \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        acc = check_accuracy(model_gpu, valid_loader)\n",
        "        print('acc = %f' %(acc))\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model_gpu.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            }, model_backup_path)\n",
        "            \n",
        "def check_accuracy(model, loader):\n",
        "    print('Checking accuracy on test set')   \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval() \n",
        "    for x, y in loader:\n",
        "        x_var = Variable(x.type(gpu_dtype))\n",
        "\n",
        "        scores = model(x_var)\n",
        "        _, preds = scores.data.cpu().max(1)\n",
        "        num_correct += (preds == y).sum()\n",
        "        num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    acc_list.append(acc)\n",
        "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "    return acc\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggvpMu36Yw2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.size()\n",
        "        return x.view(N, -1)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgmexhBRZAK6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6a1452b4b80d438793c6cfd3ad0138c4",
            "4c353a0604f84bceb453f15893048411",
            "0109aeb532044697a71c7313a394686e",
            "654483738bc44933b70cf9937f32ace2",
            "aecb9d0a3d744b65abfee1053b323387",
            "a77020908f69411aa111fd829e8f553e",
            "cb1ad53cf88b461b92a9aa42f18002c3",
            "6ec8a0470e684d639fb6645235e3a840"
          ]
        },
        "outputId": "0543d9b8-0896-4b31-9746-e9125d8cbdca"
      },
      "source": [
        "gpu_dtype = torch.cuda.FloatTensor\n",
        "\n",
        "print_every = 1\n",
        "\n",
        "\n",
        "'''\n",
        "Kerv2d\n",
        "kervolution with following options:\n",
        "kernel_type: [linear, polynomial, gaussian, etc.]\n",
        "default is convolution:\n",
        "          kernel_type --> linear,\n",
        "balance, power, gamma is valid only when the kernel_type is specified\n",
        "if learnable_kernel = True,  they just be the initial value of learable parameters\n",
        "if learnable_kernel = False, they are the value of kernel_type's parameter\n",
        "the parameter [power] cannot be learned due to integer limitation\n",
        "dilation (int or tuple, optional): Spacing between kernel\n",
        "elements. Default: 1\n",
        "groups (int, optional): Number of blocked connections from input\n",
        "channels to output channels. Default: 1\n",
        "bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n",
        "kernel_type (str), Default: 'linear'\n",
        "learnable_kernel (bool): Learnable kernel parameters.  Default: False \n",
        "balance: 0, 1\n",
        "power: 3, 4, 5\n",
        "gamma:\n",
        "'''\n",
        "\n",
        "\n",
        "model_base = nn.Sequential( \n",
        "                nn.Kerv2d(in_channels , out_channels_1, padding=padding_1, dilation=1, groups=1, bias=True, \n",
        "                          kernel_type='polynomial', kernel_size=kernel_size, learnable_kernel=True,\n",
        "                          kernel_regularizer=True, stride=1, balance=1, power=5, gamma=1\n",
        "                          ),\n",
        "                nn.BatchNorm2d(out_channels_1),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_1 , out_channels_x, padding= padding_1, kernel_size=kernel_size, stride=1), \n",
        "                nn.BatchNorm2d(out_channels_x),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_x , out_channels_2, padding= padding_1, kernel_size=kernel_size, stride=1), \n",
        "                nn.BatchNorm2d(out_channels_2),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_2 , out_channels_3, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.BatchNorm2d(out_channels_3),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_3 , out_channels_4, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.BatchNorm2d(out_channels_4),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Dropout(0.5),\n",
        "                Flatten(),\n",
        "                nn.Linear(1152,64),\n",
        "                nn.Linear(64,2)\n",
        "            )\n",
        "model_gpu = model_base.type(gpu_dtype)\n",
        "print(model_gpu)\n",
        "loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) \n",
        "\n",
        "! pip install torch-lr-finder -v --global-option=\"amp\"\n",
        "from torch_lr_finder import LRFinder\n",
        "\n",
        "lr_finder = LRFinder(model_gpu, optimizer, loss_fn, device=\"cuda\")\n",
        "\n",
        "lr_finder.range_test(train_loader, end_lr=1, num_iter=100, start_lr=1e-05)\n",
        "lr_finder.plot() \n",
        " \n",
        "\n",
        "#train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs)\n",
        "#check_accuracy(model_gpu, valid_loader)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Kerv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (3): Conv2d(16, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (6): Conv2d(24, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (8): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (9): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (11): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (12): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (14): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (15): Dropout(p=0.5, inplace=False)\n",
            "  (16): Flatten()\n",
            "  (17): Linear(in_features=1152, out_features=64, bias=True)\n",
            "  (18): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n",
            "/usr/local/lib/python3.6/dist-packages/pip/_internal/commands/install.py:283: UserWarning: Disabling all use of wheels due to the use of --build-options / --global-options / --install-options.\n",
            "  cmdoptions.check_install_build_global(options)\n",
            "Created temporary directory: /tmp/pip-ephem-wheel-cache-c1pb_zky\n",
            "Created temporary directory: /tmp/pip-req-tracker-e3puquwb\n",
            "Created requirements tracker '/tmp/pip-req-tracker-e3puquwb'\n",
            "Created temporary directory: /tmp/pip-install-5b869b4e\n",
            "Requirement already satisfied: torch-lr-finder in /usr/local/lib/python3.6/dist-packages (0.1.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from torch-lr-finder) (3.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch-lr-finder) (1.18.2)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from torch-lr-finder) (1.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torch-lr-finder) (4.38.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->torch-lr-finder) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->torch-lr-finder) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->torch-lr-finder) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->torch-lr-finder) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->torch-lr-finder) (1.12.0)\n",
            "Cleaning up...\n",
            "Removed build tracker '/tmp/pip-req-tracker-e3puquwb'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a1452b4b80d438793c6cfd3ad0138c4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Stopping early, the loss has diverged\n",
            "Learning rate search finished. See the graph with {finder_name}.plot()\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f9cc50798d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzuX5gLEeJfE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "70362ac1-5c99-4e16-f443-3e04040a992e"
      },
      "source": [
        "def retry_from_backup()\n",
        "  model_gpu = model_base.type(gpu_dtype)\n",
        "  print(model_gpu)\n",
        "  loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) \n",
        "\n",
        "\n",
        "\n",
        "  checkpoint = torch.load(model_backup_path)\n",
        "  model_gpu.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  epoch = checkpoint['epoch']\n",
        "  loss = checkpoint['loss']\n",
        "  print(\"starting from epoch: \" + str(epoch))\n",
        "  print(\"starting from loss: \" + str(loss))\n",
        "  print(checkpoint['model_state_dict'])\n",
        "  print(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "  train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs, starting_from_epoch=epoch)\n",
        "  check_accuracy(model_gpu, valid_loader)\n",
        "#retry_from_backup()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-f6961f7a8651>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def retry_from_backup()\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDn-2g-TLY3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot([print_every*batch_size*(i+1) for i in range((len(avg_loss_list)))],avg_loss_list)\n",
        "print(\"Loss:\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGer6hJv7-zR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot([i+1 for i in range((len(acc_list)))],acc_list)\n",
        "print(\"Accurancy:\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBTReWHxz4Ml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}