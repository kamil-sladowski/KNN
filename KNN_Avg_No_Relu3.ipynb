{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN_Avg_No_Relu3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamilo116/KNN/blob/master/KNN_Avg_No_Relu3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7ReM7FU-xs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import sys\n",
        "from random import shuffle\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms as transforms\n",
        "import timeit\n",
        "\n",
        "np.random.seed(4) \n",
        "torch.manual_seed(4) \n",
        "torch.cuda.manual_seed(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYIMZ8QyYewD",
        "colab_type": "code",
        "outputId": "e4194393-c883-4da5-e23d-2869cd442995",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "! git clone https://github.com/wang-chen/kervolution.git \n",
        "\n",
        "sys.path.append(\"kervolution/\")\n",
        "from kervolution import Kerv2d\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'kervolution'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects:  16% (1/6)\u001b[K\rremote: Counting objects:  33% (2/6)\u001b[K\rremote: Counting objects:  50% (3/6)\u001b[K\rremote: Counting objects:  66% (4/6)\u001b[K\rremote: Counting objects:  83% (5/6)\u001b[K\rremote: Counting objects: 100% (6/6)\u001b[K\rremote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects:  16% (1/6)\u001b[K\rremote: Compressing objects:  33% (2/6)\u001b[K\rremote: Compressing objects:  50% (3/6)\u001b[K\rremote: Compressing objects:  66% (4/6)\u001b[K\rremote: Compressing objects:  83% (5/6)\u001b[K\rremote: Compressing objects: 100% (6/6)\u001b[K\rremote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 53 (delta 2), reused 0 (delta 0), pack-reused 47\u001b[K\n",
            "Unpacking objects:   1% (1/53)   \rUnpacking objects:   3% (2/53)   \rUnpacking objects:   5% (3/53)   \rUnpacking objects:   7% (4/53)   \rUnpacking objects:   9% (5/53)   \rUnpacking objects:  11% (6/53)   \rUnpacking objects:  13% (7/53)   \rUnpacking objects:  15% (8/53)   \rUnpacking objects:  16% (9/53)   \rUnpacking objects:  18% (10/53)   \rUnpacking objects:  20% (11/53)   \rUnpacking objects:  22% (12/53)   \rUnpacking objects:  24% (13/53)   \rUnpacking objects:  26% (14/53)   \rUnpacking objects:  28% (15/53)   \rUnpacking objects:  30% (16/53)   \rUnpacking objects:  32% (17/53)   \rUnpacking objects:  33% (18/53)   \rUnpacking objects:  35% (19/53)   \rUnpacking objects:  37% (20/53)   \rUnpacking objects:  39% (21/53)   \rUnpacking objects:  41% (22/53)   \rUnpacking objects:  43% (23/53)   \rUnpacking objects:  45% (24/53)   \rUnpacking objects:  47% (25/53)   \rUnpacking objects:  49% (26/53)   \rUnpacking objects:  50% (27/53)   \rUnpacking objects:  52% (28/53)   \rUnpacking objects:  54% (29/53)   \rUnpacking objects:  56% (30/53)   \rUnpacking objects:  58% (31/53)   \rUnpacking objects:  60% (32/53)   \rUnpacking objects:  62% (33/53)   \rUnpacking objects:  64% (34/53)   \rUnpacking objects:  66% (35/53)   \rUnpacking objects:  67% (36/53)   \rUnpacking objects:  69% (37/53)   \rUnpacking objects:  71% (38/53)   \rUnpacking objects:  73% (39/53)   \rUnpacking objects:  75% (40/53)   \rUnpacking objects:  77% (41/53)   \rUnpacking objects:  79% (42/53)   \rUnpacking objects:  81% (43/53)   \rUnpacking objects:  83% (44/53)   \rUnpacking objects:  84% (45/53)   \rUnpacking objects:  86% (46/53)   \rUnpacking objects:  88% (47/53)   \rUnpacking objects:  90% (48/53)   \rUnpacking objects:  92% (49/53)   \rUnpacking objects:  94% (50/53)   \rUnpacking objects:  96% (51/53)   \rUnpacking objects:  98% (52/53)   \rUnpacking objects: 100% (53/53)   \rUnpacking objects: 100% (53/53), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvbKg4VJXKY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LIMIT_IMAGES_NUM = 1000\n",
        "train_test_split_size = 0.2\n",
        "image_resize = (100, 100)\n",
        "batch_size = 64\n",
        "num_workers = 0\n",
        "\n",
        "in_channels = 3\n",
        "out_channels_1 = 16\n",
        "out_channels_2 = 24\n",
        "out_channels_3 = 32\n",
        "out_channels_4 = 48\n",
        "out_channels_5 = 64\n",
        "out_channels_6 = 128\n",
        "\n",
        "kernel_size = 3\n",
        "padding_1 = 1\n",
        "num_epochs = 80\n",
        "\n",
        "learning_rate = 0.0001\n",
        "weight_decay = 0.2\n",
        "\n",
        "MALIGNANT_DATASET = '/content/drive/My Drive/Colab_data/malignant/malignant/'\n",
        "BENIGN_DATASET = '/content/drive/My Drive/Colab_data/benign/benign/'\n",
        "DATA_FOLDER = '/content/drive/My Drive/Colab_data/'\n",
        "model_backup_path = os.path.join(DATA_FOLDER, 'backup_model_3.1') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMOHez_kHZD6",
        "colab_type": "code",
        "outputId": "1c89d2f2-dcc6-4412-fe0f-6a91422c5109",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b8P1NdXfVdX",
        "colab_type": "code",
        "outputId": "fb082971-5e87-4dc1-c405-f35e4adc8f01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "benign_file_list = sorted(os.listdir(BENIGN_DATASET))\n",
        "malignant_file_list = sorted(os.listdir(MALIGNANT_DATASET))\n",
        "shuffle(benign_file_list)\n",
        "shuffle(malignant_file_list)\n",
        "benign_file_list = benign_file_list[:LIMIT_IMAGES_NUM]\n",
        "malignant_file_list = malignant_file_list[:LIMIT_IMAGES_NUM]\n",
        "\n",
        "print(f\"Number of benign {len(benign_file_list)} images\")\n",
        "print(f\"Number of malignant {len(malignant_file_list)} images\")\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize(image_resize),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of benign 1000 images\n",
            "Number of malignant 1000 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGDQfal74BLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "benign_dict = {filename: 0 for filename in benign_file_list}\n",
        "malignant_dict = {filename: 1 for filename in malignant_file_list}\n",
        "img_class_dict = {**benign_dict , **malignant_dict}\n",
        "labeled_data = pd.Series(img_class_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvAAOqmVfVll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IsicDataset(Dataset):\n",
        "    def __init__(self, data_folder, labeled_data, \n",
        "                 transform=transforms.Compose([transforms.ToTensor()])):\n",
        "        self.labeled_data = labeled_data\n",
        "        self.transform = transform\n",
        "        self.data_folder = data_folder\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labeled_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        label = self.labeled_data[index]\n",
        "        if label == 0:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"benign\", \"benign\", index ))\n",
        "        else:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"malignant\", \"malignant\", index ))\n",
        "        image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "    @property\n",
        "    def labels(self):\n",
        "      return self.labeled_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSuYqjLAYrWA",
        "colab_type": "code",
        "outputId": "f6943447-ad30-4a2c-b098-c423b0275868",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        " \n",
        "dataset = IsicDataset(DATA_FOLDER, labeled_data, transform=data_transforms)\n",
        "print(dataset.labels)\n",
        "\n",
        "X_train, X_test = train_test_split(dataset.labels, test_size=train_test_split_size)\n",
        "print(\"number of training data: \",len(X_train))\n",
        "print(\"number of testing  data: \",len(X_test))\n",
        "\n",
        "train_sampler = SubsetRandomSampler(list(X_train.index))\n",
        "valid_sampler = SubsetRandomSampler(list(X_test.index))\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ISIC_0002499.jpeg    0\n",
            "ISIC_0000829.jpeg    0\n",
            "ISIC_0001298.jpeg    0\n",
            "ISIC_0001363.jpeg    0\n",
            "ISIC_0001459.jpeg    0\n",
            "                    ..\n",
            "ISIC_0011579.jpeg    1\n",
            "ISIC_0010355.jpeg    1\n",
            "ISIC_0011288.jpeg    1\n",
            "ISIC_0011490.jpeg    1\n",
            "ISIC_0012348.jpeg    1\n",
            "Length: 2000, dtype: int64\n",
            "number of training data:  1600\n",
            "number of testing  data:  400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e8nFBR6Yug5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "def train(model, train_loader ,loss_fn, optimizer, num_epochs=1, starting_from_epoch=1):\n",
        "    total_loss =0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
        "        model.train()\n",
        "\n",
        "        for t, (x, y) in enumerate(train_loader):\n",
        "            x_var = Variable(x.type(gpu_dtype))\n",
        "            y_var = Variable(y.type(gpu_dtype).long())\n",
        "            scores = model(x_var)\n",
        "            loss = loss_fn(scores, y_var)\n",
        "            total_loss += loss.data\n",
        "            \n",
        "            if (t + 1) % print_every == 0:\n",
        "                avg_loss = total_loss/print_every\n",
        "                print('t = %d, avg_loss = %.4f' % (t + 1, avg_loss) )\n",
        "                avg_loss_list.append(avg_loss)\n",
        "                total_loss = 0\n",
        "                \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        acc = check_accuracy(model_gpu, valid_loader)\n",
        "        print('acc = %f' %(acc))\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model_gpu.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            }, model_backup_path)\n",
        "            \n",
        "def check_accuracy(model, loader):\n",
        "    print('Checking accuracy on test set')   \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval() \n",
        "    for x, y in loader:\n",
        "        x_var = Variable(x.type(gpu_dtype))\n",
        "\n",
        "        scores = model(x_var)\n",
        "        _, preds = scores.data.cpu().max(1)\n",
        "        num_correct += (preds == y).sum()\n",
        "        num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    acc_list.append(acc)\n",
        "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "    return acc\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggvpMu36Yw2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.size()\n",
        "        return x.view(N, -1)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgmexhBRZAK6",
        "colab_type": "code",
        "outputId": "ed9ef4ef-708d-4a39-caa8-e0e81b4ce8f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "gpu_dtype = torch.cuda.FloatTensor\n",
        "\n",
        "print_every = 1\n",
        "\n",
        "\n",
        "'''\n",
        "Kerv2d\n",
        "kervolution with following options:\n",
        "kernel_type: [linear, polynomial, gaussian, etc.]\n",
        "default is convolution:\n",
        "          kernel_type --> linear,\n",
        "balance, power, gamma is valid only when the kernel_type is specified\n",
        "if learnable_kernel = True,  they just be the initial value of learable parameters\n",
        "if learnable_kernel = False, they are the value of kernel_type's parameter\n",
        "the parameter [power] cannot be learned due to integer limitation\n",
        "dilation (int or tuple, optional): Spacing between kernel\n",
        "elements. Default: 1\n",
        "groups (int, optional): Number of blocked connections from input\n",
        "channels to output channels. Default: 1\n",
        "bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n",
        "kernel_type (str), Default: 'linear'\n",
        "learnable_kernel (bool): Learnable kernel parameters.  Default: False \n",
        "balance: 0, 1\n",
        "power: 3, 4, 5\n",
        "gamma:\n",
        "'''\n",
        "\n",
        "\n",
        "model_base = nn.Sequential( \n",
        "                nn.Kerv2d(in_channels , out_channels_1, padding=padding_1, dilation=1, groups=1, bias=True, \n",
        "                          kernel_type='polynomial', kernel_size=kernel_size, learnable_kernel=True,\n",
        "                          kernel_regularizer=True, stride=1, balance=1, power=3, gamma=1\n",
        "                          ),\n",
        "                \n",
        "                nn.BatchNorm2d(out_channels_1),\n",
        "                nn.Conv2d(out_channels_1 , out_channels_2, padding= padding_1, kernel_size=kernel_size, stride=1), \n",
        "                nn.Dropout(0.1),\n",
        "                nn.BatchNorm2d(out_channels_2),\n",
        "                nn.AvgPool2d(2, stride=2), \n",
        "                \n",
        "                #nn.Conv2d(out_channels_2 , out_channels_3, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.Kerv2d(out_channels_2 , out_channels_3, padding=padding_1, dilation=1, groups=1, bias=True, \n",
        "                          kernel_type='polynomial', kernel_size=kernel_size, learnable_kernel=True,\n",
        "                          kernel_regularizer=True, stride=1, balance=1, power=3, gamma=1\n",
        "                          ),\n",
        "                \n",
        "                nn.BatchNorm2d(out_channels_3),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_3 , out_channels_4, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.BatchNorm2d(out_channels_4),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_4 , out_channels_5, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.BatchNorm2d(out_channels_5),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_5 , out_channels_6, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.BatchNorm2d(out_channels_6),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                Flatten(),\n",
        "                nn.Dropout(0.5),\n",
        "                nn.Linear(1152,64),\n",
        "                nn.Linear(64,2)\n",
        "            )\n",
        "model_gpu = model_base.type(gpu_dtype)\n",
        "print(model_gpu)\n",
        "loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) \n",
        "\n",
        "train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs)\n",
        "check_accuracy(model_gpu, valid_loader)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Kerv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): Conv2d(16, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (3): Dropout(p=0.1, inplace=False)\n",
            "  (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (6): Kerv2d(24, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (8): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (9): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (10): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (11): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (12): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (13): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (14): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (15): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (18): Flatten()\n",
            "  (19): Dropout(p=0.5, inplace=False)\n",
            "  (20): Linear(in_features=1152, out_features=64, bias=True)\n",
            "  (21): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n",
            "Starting epoch 1 / 80\n",
            "t = 1, avg_loss = 0.7245\n",
            "t = 2, avg_loss = 0.6723\n",
            "t = 3, avg_loss = 0.6425\n",
            "t = 4, avg_loss = 0.6636\n",
            "t = 5, avg_loss = 0.6642\n",
            "t = 6, avg_loss = 0.6554\n",
            "t = 7, avg_loss = 0.7152\n",
            "t = 8, avg_loss = 0.5620\n",
            "t = 9, avg_loss = 0.6936\n",
            "t = 10, avg_loss = 0.6152\n",
            "t = 11, avg_loss = 0.6489\n",
            "t = 12, avg_loss = 0.6395\n",
            "t = 13, avg_loss = 0.5915\n",
            "t = 14, avg_loss = 0.6481\n",
            "t = 15, avg_loss = 0.5551\n",
            "t = 16, avg_loss = 0.7065\n",
            "t = 17, avg_loss = 0.6864\n",
            "t = 18, avg_loss = 0.5807\n",
            "t = 19, avg_loss = 0.6071\n",
            "t = 20, avg_loss = 0.5983\n",
            "t = 21, avg_loss = 0.5716\n",
            "t = 22, avg_loss = 0.7544\n",
            "t = 23, avg_loss = 0.5496\n",
            "t = 24, avg_loss = 0.6187\n",
            "t = 25, avg_loss = 0.6281\n",
            "Checking accuracy on test set\n",
            "Got 244 / 400 correct (61.00)\n",
            "acc = 0.610000\n",
            "Starting epoch 2 / 80\n",
            "t = 1, avg_loss = 0.6149\n",
            "t = 2, avg_loss = 0.6355\n",
            "t = 3, avg_loss = 0.5932\n",
            "t = 4, avg_loss = 0.5348\n",
            "t = 5, avg_loss = 0.5285\n",
            "t = 6, avg_loss = 0.5677\n",
            "t = 7, avg_loss = 0.7047\n",
            "t = 8, avg_loss = 0.5925\n",
            "t = 9, avg_loss = 0.6591\n",
            "t = 10, avg_loss = 0.6203\n",
            "t = 11, avg_loss = 0.5800\n",
            "t = 12, avg_loss = 0.5769\n",
            "t = 13, avg_loss = 0.5062\n",
            "t = 14, avg_loss = 0.6611\n",
            "t = 15, avg_loss = 0.4972\n",
            "t = 16, avg_loss = 0.5283\n",
            "t = 17, avg_loss = 0.5517\n",
            "t = 18, avg_loss = 0.5937\n",
            "t = 19, avg_loss = 0.6454\n",
            "t = 20, avg_loss = 0.5683\n",
            "t = 21, avg_loss = 0.5492\n",
            "t = 22, avg_loss = 0.5227\n",
            "t = 23, avg_loss = 0.6930\n",
            "t = 24, avg_loss = 0.6248\n",
            "t = 25, avg_loss = 0.6153\n",
            "Checking accuracy on test set\n",
            "Got 283 / 400 correct (70.75)\n",
            "acc = 0.707500\n",
            "Starting epoch 3 / 80\n",
            "t = 1, avg_loss = 0.7336\n",
            "t = 2, avg_loss = 0.5988\n",
            "t = 3, avg_loss = 0.4882\n",
            "t = 4, avg_loss = 0.6169\n",
            "t = 5, avg_loss = 0.5517\n",
            "t = 6, avg_loss = 0.7116\n",
            "t = 7, avg_loss = 0.6639\n",
            "t = 8, avg_loss = 0.5925\n",
            "t = 9, avg_loss = 0.5240\n",
            "t = 10, avg_loss = 0.6951\n",
            "t = 11, avg_loss = 0.5460\n",
            "t = 12, avg_loss = 0.6127\n",
            "t = 13, avg_loss = 0.5482\n",
            "t = 14, avg_loss = 0.5463\n",
            "t = 15, avg_loss = 0.6634\n",
            "t = 16, avg_loss = 0.5616\n",
            "t = 17, avg_loss = 0.6181\n",
            "t = 18, avg_loss = 0.5275\n",
            "t = 19, avg_loss = 0.5090\n",
            "t = 20, avg_loss = 0.6050\n",
            "t = 21, avg_loss = 0.5127\n",
            "t = 22, avg_loss = 0.6347\n",
            "t = 23, avg_loss = 0.4521\n",
            "t = 24, avg_loss = 0.6049\n",
            "t = 25, avg_loss = 0.5740\n",
            "Checking accuracy on test set\n",
            "Got 295 / 400 correct (73.75)\n",
            "acc = 0.737500\n",
            "Starting epoch 4 / 80\n",
            "t = 1, avg_loss = 0.5295\n",
            "t = 2, avg_loss = 0.6134\n",
            "t = 3, avg_loss = 0.6527\n",
            "t = 4, avg_loss = 0.5433\n",
            "t = 5, avg_loss = 0.5409\n",
            "t = 6, avg_loss = 0.5355\n",
            "t = 7, avg_loss = 0.4620\n",
            "t = 8, avg_loss = 0.5012\n",
            "t = 9, avg_loss = 0.5849\n",
            "t = 10, avg_loss = 0.4495\n",
            "t = 11, avg_loss = 0.5051\n",
            "t = 12, avg_loss = 0.5738\n",
            "t = 13, avg_loss = 0.5809\n",
            "t = 14, avg_loss = 0.4762\n",
            "t = 15, avg_loss = 0.5642\n",
            "t = 16, avg_loss = 0.5423\n",
            "t = 17, avg_loss = 0.5691\n",
            "t = 18, avg_loss = 0.5685\n",
            "t = 19, avg_loss = 0.5898\n",
            "t = 20, avg_loss = 0.6540\n",
            "t = 21, avg_loss = 0.5442\n",
            "t = 22, avg_loss = 0.5191\n",
            "t = 23, avg_loss = 0.5529\n",
            "t = 24, avg_loss = 0.4275\n",
            "t = 25, avg_loss = 0.4922\n",
            "Checking accuracy on test set\n",
            "Got 309 / 400 correct (77.25)\n",
            "acc = 0.772500\n",
            "Starting epoch 5 / 80\n",
            "t = 1, avg_loss = 0.6182\n",
            "t = 2, avg_loss = 0.4767\n",
            "t = 3, avg_loss = 0.4581\n",
            "t = 4, avg_loss = 0.5204\n",
            "t = 5, avg_loss = 0.6262\n",
            "t = 6, avg_loss = 0.5709\n",
            "t = 7, avg_loss = 0.6471\n",
            "t = 8, avg_loss = 0.6993\n",
            "t = 9, avg_loss = 0.5861\n",
            "t = 10, avg_loss = 0.5577\n",
            "t = 11, avg_loss = 0.5466\n",
            "t = 12, avg_loss = 0.5122\n",
            "t = 13, avg_loss = 0.6259\n",
            "t = 14, avg_loss = 0.5162\n",
            "t = 15, avg_loss = 0.5899\n",
            "t = 16, avg_loss = 0.4736\n",
            "t = 17, avg_loss = 0.4829\n",
            "t = 18, avg_loss = 0.5510\n",
            "t = 19, avg_loss = 0.5316\n",
            "t = 20, avg_loss = 0.5402\n",
            "t = 21, avg_loss = 0.5418\n",
            "t = 22, avg_loss = 0.4720\n",
            "t = 23, avg_loss = 0.4084\n",
            "t = 24, avg_loss = 0.5797\n",
            "t = 25, avg_loss = 0.5151\n",
            "Checking accuracy on test set\n",
            "Got 305 / 400 correct (76.25)\n",
            "acc = 0.762500\n",
            "Starting epoch 6 / 80\n",
            "t = 1, avg_loss = 0.6058\n",
            "t = 2, avg_loss = 0.4874\n",
            "t = 3, avg_loss = 0.5165\n",
            "t = 4, avg_loss = 0.5152\n",
            "t = 5, avg_loss = 0.5285\n",
            "t = 6, avg_loss = 0.6068\n",
            "t = 7, avg_loss = 0.5247\n",
            "t = 8, avg_loss = 0.4807\n",
            "t = 9, avg_loss = 0.4892\n",
            "t = 10, avg_loss = 0.5221\n",
            "t = 11, avg_loss = 0.5626\n",
            "t = 12, avg_loss = 0.4521\n",
            "t = 13, avg_loss = 0.6003\n",
            "t = 14, avg_loss = 0.6333\n",
            "t = 15, avg_loss = 0.5082\n",
            "t = 16, avg_loss = 0.4501\n",
            "t = 17, avg_loss = 0.4154\n",
            "t = 18, avg_loss = 0.5397\n",
            "t = 19, avg_loss = 0.5122\n",
            "t = 20, avg_loss = 0.5335\n",
            "t = 21, avg_loss = 0.4444\n",
            "t = 22, avg_loss = 0.5106\n",
            "t = 23, avg_loss = 0.5661\n",
            "t = 24, avg_loss = 0.5367\n",
            "t = 25, avg_loss = 0.5771\n",
            "Checking accuracy on test set\n",
            "Got 316 / 400 correct (79.00)\n",
            "acc = 0.790000\n",
            "Starting epoch 7 / 80\n",
            "t = 1, avg_loss = 0.4696\n",
            "t = 2, avg_loss = 0.4396\n",
            "t = 3, avg_loss = 0.5922\n",
            "t = 4, avg_loss = 0.5483\n",
            "t = 5, avg_loss = 0.5647\n",
            "t = 6, avg_loss = 0.4966\n",
            "t = 7, avg_loss = 0.4567\n",
            "t = 8, avg_loss = 0.6489\n",
            "t = 9, avg_loss = 0.4865\n",
            "t = 10, avg_loss = 0.4084\n",
            "t = 11, avg_loss = 0.5356\n",
            "t = 12, avg_loss = 0.5177\n",
            "t = 13, avg_loss = 0.4820\n",
            "t = 14, avg_loss = 0.4331\n",
            "t = 15, avg_loss = 0.4833\n",
            "t = 16, avg_loss = 0.4484\n",
            "t = 17, avg_loss = 0.5446\n",
            "t = 18, avg_loss = 0.4929\n",
            "t = 19, avg_loss = 0.4605\n",
            "t = 20, avg_loss = 0.5087\n",
            "t = 21, avg_loss = 0.5817\n",
            "t = 22, avg_loss = 0.4884\n",
            "t = 23, avg_loss = 0.6294\n",
            "t = 24, avg_loss = 0.4745\n",
            "t = 25, avg_loss = 0.4974\n",
            "Checking accuracy on test set\n",
            "Got 303 / 400 correct (75.75)\n",
            "acc = 0.757500\n",
            "Starting epoch 8 / 80\n",
            "t = 1, avg_loss = 0.4912\n",
            "t = 2, avg_loss = 0.5122\n",
            "t = 3, avg_loss = 0.5382\n",
            "t = 4, avg_loss = 0.4201\n",
            "t = 5, avg_loss = 0.4558\n",
            "t = 6, avg_loss = 0.5156\n",
            "t = 7, avg_loss = 0.4909\n",
            "t = 8, avg_loss = 0.4849\n",
            "t = 9, avg_loss = 0.7140\n",
            "t = 10, avg_loss = 0.4477\n",
            "t = 11, avg_loss = 0.4861\n",
            "t = 12, avg_loss = 0.4118\n",
            "t = 13, avg_loss = 0.4121\n",
            "t = 14, avg_loss = 0.5830\n",
            "t = 15, avg_loss = 0.4884\n",
            "t = 16, avg_loss = 0.3956\n",
            "t = 17, avg_loss = 0.5799\n",
            "t = 18, avg_loss = 0.4364\n",
            "t = 19, avg_loss = 0.4992\n",
            "t = 20, avg_loss = 0.4625\n",
            "t = 21, avg_loss = 0.4778\n",
            "t = 22, avg_loss = 0.4583\n",
            "t = 23, avg_loss = 0.5379\n",
            "t = 24, avg_loss = 0.5659\n",
            "t = 25, avg_loss = 0.4136\n",
            "Checking accuracy on test set\n",
            "Got 315 / 400 correct (78.75)\n",
            "acc = 0.787500\n",
            "Starting epoch 9 / 80\n",
            "t = 1, avg_loss = 0.5769\n",
            "t = 2, avg_loss = 0.4613\n",
            "t = 3, avg_loss = 0.4600\n",
            "t = 4, avg_loss = 0.5890\n",
            "t = 5, avg_loss = 0.7305\n",
            "t = 6, avg_loss = 0.5290\n",
            "t = 7, avg_loss = 0.4362\n",
            "t = 8, avg_loss = 0.4285\n",
            "t = 9, avg_loss = 0.4225\n",
            "t = 10, avg_loss = 0.5046\n",
            "t = 11, avg_loss = 0.5430\n",
            "t = 12, avg_loss = 0.4474\n",
            "t = 13, avg_loss = 0.3436\n",
            "t = 14, avg_loss = 0.6097\n",
            "t = 15, avg_loss = 0.7527\n",
            "t = 16, avg_loss = 0.6592\n",
            "t = 17, avg_loss = 0.3950\n",
            "t = 18, avg_loss = 0.5396\n",
            "t = 19, avg_loss = 0.5603\n",
            "t = 20, avg_loss = 0.4473\n",
            "t = 21, avg_loss = 0.5121\n",
            "t = 22, avg_loss = 0.3941\n",
            "t = 23, avg_loss = 0.4076\n",
            "t = 24, avg_loss = 0.5833\n",
            "t = 25, avg_loss = 0.4868\n",
            "Checking accuracy on test set\n",
            "Got 319 / 400 correct (79.75)\n",
            "acc = 0.797500\n",
            "Starting epoch 10 / 80\n",
            "t = 1, avg_loss = 0.5473\n",
            "t = 2, avg_loss = 0.5113\n",
            "t = 3, avg_loss = 0.5017\n",
            "t = 4, avg_loss = 0.4561\n",
            "t = 5, avg_loss = 0.4783\n",
            "t = 6, avg_loss = 0.4950\n",
            "t = 7, avg_loss = 0.5012\n",
            "t = 8, avg_loss = 0.5860\n",
            "t = 9, avg_loss = 0.4477\n",
            "t = 10, avg_loss = 0.4948\n",
            "t = 11, avg_loss = 0.5651\n",
            "t = 12, avg_loss = 0.3324\n",
            "t = 13, avg_loss = 0.4410\n",
            "t = 14, avg_loss = 0.3937\n",
            "t = 15, avg_loss = 0.5986\n",
            "t = 16, avg_loss = 0.4375\n",
            "t = 17, avg_loss = 0.5184\n",
            "t = 18, avg_loss = 0.5174\n",
            "t = 19, avg_loss = 0.5093\n",
            "t = 20, avg_loss = 0.5701\n",
            "t = 21, avg_loss = 0.4121\n",
            "t = 22, avg_loss = 0.6024\n",
            "t = 23, avg_loss = 0.5720\n",
            "t = 24, avg_loss = 0.5848\n",
            "t = 25, avg_loss = 0.3697\n",
            "Checking accuracy on test set\n",
            "Got 324 / 400 correct (81.00)\n",
            "acc = 0.810000\n",
            "Starting epoch 11 / 80\n",
            "t = 1, avg_loss = 0.4620\n",
            "t = 2, avg_loss = 0.5080\n",
            "t = 3, avg_loss = 0.5640\n",
            "t = 4, avg_loss = 0.4888\n",
            "t = 5, avg_loss = 0.3869\n",
            "t = 6, avg_loss = 0.4178\n",
            "t = 7, avg_loss = 0.6401\n",
            "t = 8, avg_loss = 0.4596\n",
            "t = 9, avg_loss = 0.5527\n",
            "t = 10, avg_loss = 0.5408\n",
            "t = 11, avg_loss = 0.5226\n",
            "t = 12, avg_loss = 0.3744\n",
            "t = 13, avg_loss = 0.4807\n",
            "t = 14, avg_loss = 0.6428\n",
            "t = 15, avg_loss = 0.4770\n",
            "t = 16, avg_loss = 0.4819\n",
            "t = 17, avg_loss = 0.5020\n",
            "t = 18, avg_loss = 0.4902\n",
            "t = 19, avg_loss = 0.5025\n",
            "t = 20, avg_loss = 0.4030\n",
            "t = 21, avg_loss = 0.6916\n",
            "t = 22, avg_loss = 0.3554\n",
            "t = 23, avg_loss = 0.5665\n",
            "t = 24, avg_loss = 0.4665\n",
            "t = 25, avg_loss = 0.4321\n",
            "Checking accuracy on test set\n",
            "Got 322 / 400 correct (80.50)\n",
            "acc = 0.805000\n",
            "Starting epoch 12 / 80\n",
            "t = 1, avg_loss = 0.5531\n",
            "t = 2, avg_loss = 0.4622\n",
            "t = 3, avg_loss = 0.5267\n",
            "t = 4, avg_loss = 0.4770\n",
            "t = 5, avg_loss = 0.4718\n",
            "t = 6, avg_loss = 0.3802\n",
            "t = 7, avg_loss = 0.4487\n",
            "t = 8, avg_loss = 0.4967\n",
            "t = 9, avg_loss = 0.4755\n",
            "t = 10, avg_loss = 0.6209\n",
            "t = 11, avg_loss = 0.4886\n",
            "t = 12, avg_loss = 0.4781\n",
            "t = 13, avg_loss = 0.4256\n",
            "t = 14, avg_loss = 0.4423\n",
            "t = 15, avg_loss = 0.5102\n",
            "t = 16, avg_loss = 0.4246\n",
            "t = 17, avg_loss = 0.4302\n",
            "t = 18, avg_loss = 0.4382\n",
            "t = 19, avg_loss = 0.4821\n",
            "t = 20, avg_loss = 0.4428\n",
            "t = 21, avg_loss = 0.3347\n",
            "t = 22, avg_loss = 0.5623\n",
            "t = 23, avg_loss = 0.5147\n",
            "t = 24, avg_loss = 0.5287\n",
            "t = 25, avg_loss = 0.5333\n",
            "Checking accuracy on test set\n",
            "Got 320 / 400 correct (80.00)\n",
            "acc = 0.800000\n",
            "Starting epoch 13 / 80\n",
            "t = 1, avg_loss = 0.4956\n",
            "t = 2, avg_loss = 0.5205\n",
            "t = 3, avg_loss = 0.5774\n",
            "t = 4, avg_loss = 0.4139\n",
            "t = 5, avg_loss = 0.4234\n",
            "t = 6, avg_loss = 0.4334\n",
            "t = 7, avg_loss = 0.4040\n",
            "t = 8, avg_loss = 0.6053\n",
            "t = 9, avg_loss = 0.4615\n",
            "t = 10, avg_loss = 0.4854\n",
            "t = 11, avg_loss = 0.5159\n",
            "t = 12, avg_loss = 0.4104\n",
            "t = 13, avg_loss = 0.4173\n",
            "t = 14, avg_loss = 0.4380\n",
            "t = 15, avg_loss = 0.4324\n",
            "t = 16, avg_loss = 0.4236\n",
            "t = 17, avg_loss = 0.4222\n",
            "t = 18, avg_loss = 0.4801\n",
            "t = 19, avg_loss = 0.5694\n",
            "t = 20, avg_loss = 0.5390\n",
            "t = 21, avg_loss = 0.5370\n",
            "t = 22, avg_loss = 0.4249\n",
            "t = 23, avg_loss = 0.4442\n",
            "t = 24, avg_loss = 0.5351\n",
            "t = 25, avg_loss = 0.3943\n",
            "Checking accuracy on test set\n",
            "Got 318 / 400 correct (79.50)\n",
            "acc = 0.795000\n",
            "Starting epoch 14 / 80\n",
            "t = 1, avg_loss = 0.4737\n",
            "t = 2, avg_loss = 0.4711\n",
            "t = 3, avg_loss = 0.4437\n",
            "t = 4, avg_loss = 0.4726\n",
            "t = 5, avg_loss = 0.5072\n",
            "t = 6, avg_loss = 0.6515\n",
            "t = 7, avg_loss = 0.4594\n",
            "t = 8, avg_loss = 0.4642\n",
            "t = 9, avg_loss = 0.5107\n",
            "t = 10, avg_loss = 0.4470\n",
            "t = 11, avg_loss = 0.4462\n",
            "t = 12, avg_loss = 0.5494\n",
            "t = 13, avg_loss = 0.3958\n",
            "t = 14, avg_loss = 0.3272\n",
            "t = 15, avg_loss = 0.4266\n",
            "t = 16, avg_loss = 0.3935\n",
            "t = 17, avg_loss = 0.4069\n",
            "t = 18, avg_loss = 0.6306\n",
            "t = 19, avg_loss = 0.5141\n",
            "t = 20, avg_loss = 0.5321\n",
            "t = 21, avg_loss = 0.5555\n",
            "t = 22, avg_loss = 0.3747\n",
            "t = 23, avg_loss = 0.4145\n",
            "t = 24, avg_loss = 0.5610\n",
            "t = 25, avg_loss = 0.4696\n",
            "Checking accuracy on test set\n",
            "Got 330 / 400 correct (82.50)\n",
            "acc = 0.825000\n",
            "Starting epoch 15 / 80\n",
            "t = 1, avg_loss = 0.3982\n",
            "t = 2, avg_loss = 0.3812\n",
            "t = 3, avg_loss = 0.5411\n",
            "t = 4, avg_loss = 0.4174\n",
            "t = 5, avg_loss = 0.4817\n",
            "t = 6, avg_loss = 0.6025\n",
            "t = 7, avg_loss = 0.5625\n",
            "t = 8, avg_loss = 0.4456\n",
            "t = 9, avg_loss = 0.4174\n",
            "t = 10, avg_loss = 0.4797\n",
            "t = 11, avg_loss = 0.4303\n",
            "t = 12, avg_loss = 0.4574\n",
            "t = 13, avg_loss = 0.4269\n",
            "t = 14, avg_loss = 0.5047\n",
            "t = 15, avg_loss = 0.5831\n",
            "t = 16, avg_loss = 0.4744\n",
            "t = 17, avg_loss = 0.3134\n",
            "t = 18, avg_loss = 0.3671\n",
            "t = 19, avg_loss = 0.6139\n",
            "t = 20, avg_loss = 0.4515\n",
            "t = 21, avg_loss = 0.6117\n",
            "t = 22, avg_loss = 0.5626\n",
            "t = 23, avg_loss = 0.5018\n",
            "t = 24, avg_loss = 0.4808\n",
            "t = 25, avg_loss = 0.3445\n",
            "Checking accuracy on test set\n",
            "Got 320 / 400 correct (80.00)\n",
            "acc = 0.800000\n",
            "Starting epoch 16 / 80\n",
            "t = 1, avg_loss = 0.4567\n",
            "t = 2, avg_loss = 0.4169\n",
            "t = 3, avg_loss = 0.3691\n",
            "t = 4, avg_loss = 0.4921\n",
            "t = 5, avg_loss = 0.3598\n",
            "t = 6, avg_loss = 0.4076\n",
            "t = 7, avg_loss = 0.3960\n",
            "t = 8, avg_loss = 0.5714\n",
            "t = 9, avg_loss = 0.7485\n",
            "t = 10, avg_loss = 0.4196\n",
            "t = 11, avg_loss = 0.5006\n",
            "t = 12, avg_loss = 0.7364\n",
            "t = 13, avg_loss = 0.3946\n",
            "t = 14, avg_loss = 0.4566\n",
            "t = 15, avg_loss = 0.5716\n",
            "t = 16, avg_loss = 0.4697\n",
            "t = 17, avg_loss = 0.5223\n",
            "t = 18, avg_loss = 0.4579\n",
            "t = 19, avg_loss = 0.4039\n",
            "t = 20, avg_loss = 0.5907\n",
            "t = 21, avg_loss = 0.5397\n",
            "t = 22, avg_loss = 0.4540\n",
            "t = 23, avg_loss = 0.3681\n",
            "t = 24, avg_loss = 0.4408\n",
            "t = 25, avg_loss = 0.3679\n",
            "Checking accuracy on test set\n",
            "Got 321 / 400 correct (80.25)\n",
            "acc = 0.802500\n",
            "Starting epoch 17 / 80\n",
            "t = 1, avg_loss = 0.4172\n",
            "t = 2, avg_loss = 0.4195\n",
            "t = 3, avg_loss = 0.4404\n",
            "t = 4, avg_loss = 0.5581\n",
            "t = 5, avg_loss = 0.4826\n",
            "t = 6, avg_loss = 0.4869\n",
            "t = 7, avg_loss = 0.4600\n",
            "t = 8, avg_loss = 0.3949\n",
            "t = 9, avg_loss = 0.4415\n",
            "t = 10, avg_loss = 0.4601\n",
            "t = 11, avg_loss = 0.4926\n",
            "t = 12, avg_loss = 0.3786\n",
            "t = 13, avg_loss = 0.5023\n",
            "t = 14, avg_loss = 0.5900\n",
            "t = 15, avg_loss = 0.6829\n",
            "t = 16, avg_loss = 0.3999\n",
            "t = 17, avg_loss = 0.6155\n",
            "t = 18, avg_loss = 0.4509\n",
            "t = 19, avg_loss = 0.3212\n",
            "t = 20, avg_loss = 0.4580\n",
            "t = 21, avg_loss = 0.4802\n",
            "t = 22, avg_loss = 0.4393\n",
            "t = 23, avg_loss = 0.4624\n",
            "t = 24, avg_loss = 0.5572\n",
            "t = 25, avg_loss = 0.4143\n",
            "Checking accuracy on test set\n",
            "Got 327 / 400 correct (81.75)\n",
            "acc = 0.817500\n",
            "Starting epoch 18 / 80\n",
            "t = 1, avg_loss = 0.4622\n",
            "t = 2, avg_loss = 0.3879\n",
            "t = 3, avg_loss = 0.5290\n",
            "t = 4, avg_loss = 0.5368\n",
            "t = 5, avg_loss = 0.3735\n",
            "t = 6, avg_loss = 0.3887\n",
            "t = 7, avg_loss = 0.3699\n",
            "t = 8, avg_loss = 0.4143\n",
            "t = 9, avg_loss = 0.3938\n",
            "t = 10, avg_loss = 0.4387\n",
            "t = 11, avg_loss = 0.4468\n",
            "t = 12, avg_loss = 0.4968\n",
            "t = 13, avg_loss = 0.6085\n",
            "t = 14, avg_loss = 0.6827\n",
            "t = 15, avg_loss = 0.5818\n",
            "t = 16, avg_loss = 0.4635\n",
            "t = 17, avg_loss = 0.4083\n",
            "t = 18, avg_loss = 0.4812\n",
            "t = 19, avg_loss = 0.5636\n",
            "t = 20, avg_loss = 0.3678\n",
            "t = 21, avg_loss = 0.4856\n",
            "t = 22, avg_loss = 0.4822\n",
            "t = 23, avg_loss = 0.5177\n",
            "t = 24, avg_loss = 0.6091\n",
            "t = 25, avg_loss = 0.4327\n",
            "Checking accuracy on test set\n",
            "Got 323 / 400 correct (80.75)\n",
            "acc = 0.807500\n",
            "Starting epoch 19 / 80\n",
            "t = 1, avg_loss = 0.4351\n",
            "t = 2, avg_loss = 0.4581\n",
            "t = 3, avg_loss = 0.4515\n",
            "t = 4, avg_loss = 0.3926\n",
            "t = 5, avg_loss = 0.4701\n",
            "t = 6, avg_loss = 0.4524\n",
            "t = 7, avg_loss = 0.4084\n",
            "t = 8, avg_loss = 0.4861\n",
            "t = 9, avg_loss = 0.5144\n",
            "t = 10, avg_loss = 0.3831\n",
            "t = 11, avg_loss = 0.4324\n",
            "t = 12, avg_loss = 0.3894\n",
            "t = 13, avg_loss = 0.4651\n",
            "t = 14, avg_loss = 0.4258\n",
            "t = 15, avg_loss = 0.3794\n",
            "t = 16, avg_loss = 0.3857\n",
            "t = 17, avg_loss = 0.4869\n",
            "t = 18, avg_loss = 0.5925\n",
            "t = 19, avg_loss = 0.4448\n",
            "t = 20, avg_loss = 0.5992\n",
            "t = 21, avg_loss = 0.5398\n",
            "t = 22, avg_loss = 0.4976\n",
            "t = 23, avg_loss = 0.4101\n",
            "t = 24, avg_loss = 0.3397\n",
            "t = 25, avg_loss = 0.3701\n",
            "Checking accuracy on test set\n",
            "Got 320 / 400 correct (80.00)\n",
            "acc = 0.800000\n",
            "Starting epoch 20 / 80\n",
            "t = 1, avg_loss = 0.4345\n",
            "t = 2, avg_loss = 0.4644\n",
            "t = 3, avg_loss = 0.5434\n",
            "t = 4, avg_loss = 0.3790\n",
            "t = 5, avg_loss = 0.5799\n",
            "t = 6, avg_loss = 0.4176\n",
            "t = 7, avg_loss = 0.4663\n",
            "t = 8, avg_loss = 0.4119\n",
            "t = 9, avg_loss = 0.3788\n",
            "t = 10, avg_loss = 0.5097\n",
            "t = 11, avg_loss = 0.4496\n",
            "t = 12, avg_loss = 0.4648\n",
            "t = 13, avg_loss = 0.4468\n",
            "t = 14, avg_loss = 0.4450\n",
            "t = 15, avg_loss = 0.5042\n",
            "t = 16, avg_loss = 0.4563\n",
            "t = 17, avg_loss = 0.4722\n",
            "t = 18, avg_loss = 0.6016\n",
            "t = 19, avg_loss = 0.4170\n",
            "t = 20, avg_loss = 0.5979\n",
            "t = 21, avg_loss = 0.4059\n",
            "t = 22, avg_loss = 0.5023\n",
            "t = 23, avg_loss = 0.4843\n",
            "t = 24, avg_loss = 0.4581\n",
            "t = 25, avg_loss = 0.6197\n",
            "Checking accuracy on test set\n",
            "Got 328 / 400 correct (82.00)\n",
            "acc = 0.820000\n",
            "Starting epoch 21 / 80\n",
            "t = 1, avg_loss = 0.4419\n",
            "t = 2, avg_loss = 0.3767\n",
            "t = 3, avg_loss = 0.4170\n",
            "t = 4, avg_loss = 0.5335\n",
            "t = 5, avg_loss = 0.3998\n",
            "t = 6, avg_loss = 0.4480\n",
            "t = 7, avg_loss = 0.4147\n",
            "t = 8, avg_loss = 0.4691\n",
            "t = 9, avg_loss = 0.4250\n",
            "t = 10, avg_loss = 0.5164\n",
            "t = 11, avg_loss = 0.5323\n",
            "t = 12, avg_loss = 0.3770\n",
            "t = 13, avg_loss = 0.3841\n",
            "t = 14, avg_loss = 0.4163\n",
            "t = 15, avg_loss = 0.5485\n",
            "t = 16, avg_loss = 0.4048\n",
            "t = 17, avg_loss = 0.3613\n",
            "t = 18, avg_loss = 0.4266\n",
            "t = 19, avg_loss = 0.4822\n",
            "t = 20, avg_loss = 0.4983\n",
            "t = 21, avg_loss = 0.3413\n",
            "t = 22, avg_loss = 0.5596\n",
            "t = 23, avg_loss = 0.6101\n",
            "t = 24, avg_loss = 0.4818\n",
            "t = 25, avg_loss = 0.4000\n",
            "Checking accuracy on test set\n",
            "Got 325 / 400 correct (81.25)\n",
            "acc = 0.812500\n",
            "Starting epoch 22 / 80\n",
            "t = 1, avg_loss = 0.3349\n",
            "t = 2, avg_loss = 0.4218\n",
            "t = 3, avg_loss = 0.3295\n",
            "t = 4, avg_loss = 0.5075\n",
            "t = 5, avg_loss = 0.5057\n",
            "t = 6, avg_loss = 0.5759\n",
            "t = 7, avg_loss = 0.5142\n",
            "t = 8, avg_loss = 0.3873\n",
            "t = 9, avg_loss = 0.4111\n",
            "t = 10, avg_loss = 0.3368\n",
            "t = 11, avg_loss = 0.3813\n",
            "t = 12, avg_loss = 0.5065\n",
            "t = 13, avg_loss = 0.3733\n",
            "t = 14, avg_loss = 0.4190\n",
            "t = 15, avg_loss = 0.4017\n",
            "t = 16, avg_loss = 0.5187\n",
            "t = 17, avg_loss = 0.4514\n",
            "t = 18, avg_loss = 0.4118\n",
            "t = 19, avg_loss = 0.4303\n",
            "t = 20, avg_loss = 0.4295\n",
            "t = 21, avg_loss = 0.5540\n",
            "t = 22, avg_loss = 0.5739\n",
            "t = 23, avg_loss = 0.5431\n",
            "t = 24, avg_loss = 0.5761\n",
            "t = 25, avg_loss = 0.3872\n",
            "Checking accuracy on test set\n",
            "Got 324 / 400 correct (81.00)\n",
            "acc = 0.810000\n",
            "Starting epoch 23 / 80\n",
            "t = 1, avg_loss = 0.3498\n",
            "t = 2, avg_loss = 0.4036\n",
            "t = 3, avg_loss = 0.3783\n",
            "t = 4, avg_loss = 0.5199\n",
            "t = 5, avg_loss = 0.4431\n",
            "t = 6, avg_loss = 0.5332\n",
            "t = 7, avg_loss = 0.5334\n",
            "t = 8, avg_loss = 0.3986\n",
            "t = 9, avg_loss = 0.3967\n",
            "t = 10, avg_loss = 0.6120\n",
            "t = 11, avg_loss = 0.4115\n",
            "t = 12, avg_loss = 0.3990\n",
            "t = 13, avg_loss = 0.3763\n",
            "t = 14, avg_loss = 0.4658\n",
            "t = 15, avg_loss = 0.4115\n",
            "t = 16, avg_loss = 0.4434\n",
            "t = 17, avg_loss = 0.5544\n",
            "t = 18, avg_loss = 0.3890\n",
            "t = 19, avg_loss = 0.3924\n",
            "t = 20, avg_loss = 0.4521\n",
            "t = 21, avg_loss = 0.5469\n",
            "t = 22, avg_loss = 0.4793\n",
            "t = 23, avg_loss = 0.3791\n",
            "t = 24, avg_loss = 0.3513\n",
            "t = 25, avg_loss = 0.5070\n",
            "Checking accuracy on test set\n",
            "Got 333 / 400 correct (83.25)\n",
            "acc = 0.832500\n",
            "Starting epoch 24 / 80\n",
            "t = 1, avg_loss = 0.3406\n",
            "t = 2, avg_loss = 0.4701\n",
            "t = 3, avg_loss = 0.3745\n",
            "t = 4, avg_loss = 0.4341\n",
            "t = 5, avg_loss = 0.4394\n",
            "t = 6, avg_loss = 0.3499\n",
            "t = 7, avg_loss = 0.5250\n",
            "t = 8, avg_loss = 0.4278\n",
            "t = 9, avg_loss = 0.4448\n",
            "t = 10, avg_loss = 0.5196\n",
            "t = 11, avg_loss = 0.3740\n",
            "t = 12, avg_loss = 0.5310\n",
            "t = 13, avg_loss = 0.4104\n",
            "t = 14, avg_loss = 0.5281\n",
            "t = 15, avg_loss = 0.3831\n",
            "t = 16, avg_loss = 0.4550\n",
            "t = 17, avg_loss = 0.3947\n",
            "t = 18, avg_loss = 0.4234\n",
            "t = 19, avg_loss = 0.4664\n",
            "t = 20, avg_loss = 0.5286\n",
            "t = 21, avg_loss = 0.4347\n",
            "t = 22, avg_loss = 0.4079\n",
            "t = 23, avg_loss = 0.4974\n",
            "t = 24, avg_loss = 0.4611\n",
            "t = 25, avg_loss = 0.5855\n",
            "Checking accuracy on test set\n",
            "Got 327 / 400 correct (81.75)\n",
            "acc = 0.817500\n",
            "Starting epoch 25 / 80\n",
            "t = 1, avg_loss = 0.3865\n",
            "t = 2, avg_loss = 0.5465\n",
            "t = 3, avg_loss = 0.4211\n",
            "t = 4, avg_loss = 0.3813\n",
            "t = 5, avg_loss = 0.4198\n",
            "t = 6, avg_loss = 0.3883\n",
            "t = 7, avg_loss = 0.4699\n",
            "t = 8, avg_loss = 0.5049\n",
            "t = 9, avg_loss = 0.4542\n",
            "t = 10, avg_loss = 0.3787\n",
            "t = 11, avg_loss = 0.5313\n",
            "t = 12, avg_loss = 0.3731\n",
            "t = 13, avg_loss = 0.3012\n",
            "t = 14, avg_loss = 0.4399\n",
            "t = 15, avg_loss = 0.5633\n",
            "t = 16, avg_loss = 0.5125\n",
            "t = 17, avg_loss = 0.4554\n",
            "t = 18, avg_loss = 0.4005\n",
            "t = 19, avg_loss = 0.3649\n",
            "t = 20, avg_loss = 0.3540\n",
            "t = 21, avg_loss = 0.6338\n",
            "t = 22, avg_loss = 0.5485\n",
            "t = 23, avg_loss = 0.5598\n",
            "t = 24, avg_loss = 0.4085\n",
            "t = 25, avg_loss = 0.4721\n",
            "Checking accuracy on test set\n",
            "Got 323 / 400 correct (80.75)\n",
            "acc = 0.807500\n",
            "Starting epoch 26 / 80\n",
            "t = 1, avg_loss = 0.4636\n",
            "t = 2, avg_loss = 0.4101\n",
            "t = 3, avg_loss = 0.5468\n",
            "t = 4, avg_loss = 0.4802\n",
            "t = 5, avg_loss = 0.4238\n",
            "t = 6, avg_loss = 0.5605\n",
            "t = 7, avg_loss = 0.4113\n",
            "t = 8, avg_loss = 0.3900\n",
            "t = 9, avg_loss = 0.4508\n",
            "t = 10, avg_loss = 0.4143\n",
            "t = 11, avg_loss = 0.3598\n",
            "t = 12, avg_loss = 0.4120\n",
            "t = 13, avg_loss = 0.5649\n",
            "t = 14, avg_loss = 0.3583\n",
            "t = 15, avg_loss = 0.3710\n",
            "t = 16, avg_loss = 0.4008\n",
            "t = 17, avg_loss = 0.5481\n",
            "t = 18, avg_loss = 0.4655\n",
            "t = 19, avg_loss = 0.4419\n",
            "t = 20, avg_loss = 0.4345\n",
            "t = 21, avg_loss = 0.5692\n",
            "t = 22, avg_loss = 0.3138\n",
            "t = 23, avg_loss = 0.6098\n",
            "t = 24, avg_loss = 0.4540\n",
            "t = 25, avg_loss = 0.5513\n",
            "Checking accuracy on test set\n",
            "Got 331 / 400 correct (82.75)\n",
            "acc = 0.827500\n",
            "Starting epoch 27 / 80\n",
            "t = 1, avg_loss = 0.5005\n",
            "t = 2, avg_loss = 0.5194\n",
            "t = 3, avg_loss = 0.3771\n",
            "t = 4, avg_loss = 0.3475\n",
            "t = 5, avg_loss = 0.4664\n",
            "t = 6, avg_loss = 0.3748\n",
            "t = 7, avg_loss = 0.3946\n",
            "t = 8, avg_loss = 0.4598\n",
            "t = 9, avg_loss = 0.4361\n",
            "t = 10, avg_loss = 0.4296\n",
            "t = 11, avg_loss = 0.5153\n",
            "t = 12, avg_loss = 0.3287\n",
            "t = 13, avg_loss = 0.4963\n",
            "t = 14, avg_loss = 0.4377\n",
            "t = 15, avg_loss = 0.4012\n",
            "t = 16, avg_loss = 0.4361\n",
            "t = 17, avg_loss = 0.5590\n",
            "t = 18, avg_loss = 0.5463\n",
            "t = 19, avg_loss = 0.4103\n",
            "t = 20, avg_loss = 0.5557\n",
            "t = 21, avg_loss = 0.4178\n",
            "t = 22, avg_loss = 0.5386\n",
            "t = 23, avg_loss = 0.3020\n",
            "t = 24, avg_loss = 0.3018\n",
            "t = 25, avg_loss = 0.4532\n",
            "Checking accuracy on test set\n",
            "Got 329 / 400 correct (82.25)\n",
            "acc = 0.822500\n",
            "Starting epoch 28 / 80\n",
            "t = 1, avg_loss = 0.5353\n",
            "t = 2, avg_loss = 0.3729\n",
            "t = 3, avg_loss = 0.4665\n",
            "t = 4, avg_loss = 0.3603\n",
            "t = 5, avg_loss = 0.4425\n",
            "t = 6, avg_loss = 0.5118\n",
            "t = 7, avg_loss = 0.4398\n",
            "t = 8, avg_loss = 0.3688\n",
            "t = 9, avg_loss = 0.5152\n",
            "t = 10, avg_loss = 0.5822\n",
            "t = 11, avg_loss = 0.5117\n",
            "t = 12, avg_loss = 0.4968\n",
            "t = 13, avg_loss = 0.4488\n",
            "t = 14, avg_loss = 0.4535\n",
            "t = 15, avg_loss = 0.3990\n",
            "t = 16, avg_loss = 0.3716\n",
            "t = 17, avg_loss = 0.4428\n",
            "t = 18, avg_loss = 0.4902\n",
            "t = 19, avg_loss = 0.4376\n",
            "t = 20, avg_loss = 0.5317\n",
            "t = 21, avg_loss = 0.4038\n",
            "t = 22, avg_loss = 0.4446\n",
            "t = 23, avg_loss = 0.3401\n",
            "t = 24, avg_loss = 0.3956\n",
            "t = 25, avg_loss = 0.3202\n",
            "Checking accuracy on test set\n",
            "Got 330 / 400 correct (82.50)\n",
            "acc = 0.825000\n",
            "Starting epoch 29 / 80\n",
            "t = 1, avg_loss = 0.4587\n",
            "t = 2, avg_loss = 0.4042\n",
            "t = 3, avg_loss = 0.5373\n",
            "t = 4, avg_loss = 0.4787\n",
            "t = 5, avg_loss = 0.3527\n",
            "t = 6, avg_loss = 0.4075\n",
            "t = 7, avg_loss = 0.6169\n",
            "t = 8, avg_loss = 0.3780\n",
            "t = 9, avg_loss = 0.4146\n",
            "t = 10, avg_loss = 0.4396\n",
            "t = 11, avg_loss = 0.4401\n",
            "t = 12, avg_loss = 0.3719\n",
            "t = 13, avg_loss = 0.3629\n",
            "t = 14, avg_loss = 0.3532\n",
            "t = 15, avg_loss = 0.4727\n",
            "t = 16, avg_loss = 0.3584\n",
            "t = 17, avg_loss = 0.6845\n",
            "t = 18, avg_loss = 0.4714\n",
            "t = 19, avg_loss = 0.4420\n",
            "t = 20, avg_loss = 0.4325\n",
            "t = 21, avg_loss = 0.5643\n",
            "t = 22, avg_loss = 0.4498\n",
            "t = 23, avg_loss = 0.4482\n",
            "t = 24, avg_loss = 0.4819\n",
            "t = 25, avg_loss = 0.4212\n",
            "Checking accuracy on test set\n",
            "Got 330 / 400 correct (82.50)\n",
            "acc = 0.825000\n",
            "Starting epoch 30 / 80\n",
            "t = 1, avg_loss = 0.3276\n",
            "t = 2, avg_loss = 0.4898\n",
            "t = 3, avg_loss = 0.4745\n",
            "t = 4, avg_loss = 0.5387\n",
            "t = 5, avg_loss = 0.4197\n",
            "t = 6, avg_loss = 0.4107\n",
            "t = 7, avg_loss = 0.6175\n",
            "t = 8, avg_loss = 0.4893\n",
            "t = 9, avg_loss = 0.4696\n",
            "t = 10, avg_loss = 0.4055\n",
            "t = 11, avg_loss = 0.4178\n",
            "t = 12, avg_loss = 0.4304\n",
            "t = 13, avg_loss = 0.4065\n",
            "t = 14, avg_loss = 0.2989\n",
            "t = 15, avg_loss = 0.3141\n",
            "t = 16, avg_loss = 0.2772\n",
            "t = 17, avg_loss = 0.4180\n",
            "t = 18, avg_loss = 0.4782\n",
            "t = 19, avg_loss = 0.4850\n",
            "t = 20, avg_loss = 0.4763\n",
            "t = 21, avg_loss = 0.3507\n",
            "t = 22, avg_loss = 0.4815\n",
            "t = 23, avg_loss = 0.4257\n",
            "t = 24, avg_loss = 0.4835\n",
            "t = 25, avg_loss = 0.4340\n",
            "Checking accuracy on test set\n",
            "Got 332 / 400 correct (83.00)\n",
            "acc = 0.830000\n",
            "Starting epoch 31 / 80\n",
            "t = 1, avg_loss = 0.4052\n",
            "t = 2, avg_loss = 0.4936\n",
            "t = 3, avg_loss = 0.4374\n",
            "t = 4, avg_loss = 0.5623\n",
            "t = 5, avg_loss = 0.4426\n",
            "t = 6, avg_loss = 0.4749\n",
            "t = 7, avg_loss = 0.4645\n",
            "t = 8, avg_loss = 0.3863\n",
            "t = 9, avg_loss = 0.4172\n",
            "t = 10, avg_loss = 0.4608\n",
            "t = 11, avg_loss = 0.4681\n",
            "t = 12, avg_loss = 0.5106\n",
            "t = 13, avg_loss = 0.5385\n",
            "t = 14, avg_loss = 0.4632\n",
            "t = 15, avg_loss = 0.4984\n",
            "t = 16, avg_loss = 0.3373\n",
            "t = 17, avg_loss = 0.4307\n",
            "t = 18, avg_loss = 0.5205\n",
            "t = 19, avg_loss = 0.4301\n",
            "t = 20, avg_loss = 0.5309\n",
            "t = 21, avg_loss = 0.3371\n",
            "t = 22, avg_loss = 0.3176\n",
            "t = 23, avg_loss = 0.4854\n",
            "t = 24, avg_loss = 0.4279\n",
            "t = 25, avg_loss = 0.3169\n",
            "Checking accuracy on test set\n",
            "Got 333 / 400 correct (83.25)\n",
            "acc = 0.832500\n",
            "Starting epoch 32 / 80\n",
            "t = 1, avg_loss = 0.3658\n",
            "t = 2, avg_loss = 0.4626\n",
            "t = 3, avg_loss = 0.4685\n",
            "t = 4, avg_loss = 0.3780\n",
            "t = 5, avg_loss = 0.4525\n",
            "t = 6, avg_loss = 0.4248\n",
            "t = 7, avg_loss = 0.4520\n",
            "t = 8, avg_loss = 0.4472\n",
            "t = 9, avg_loss = 0.5857\n",
            "t = 10, avg_loss = 0.4178\n",
            "t = 11, avg_loss = 0.4811\n",
            "t = 12, avg_loss = 0.4398\n",
            "t = 13, avg_loss = 0.3786\n",
            "t = 14, avg_loss = 0.4411\n",
            "t = 15, avg_loss = 0.5825\n",
            "t = 16, avg_loss = 0.4564\n",
            "t = 17, avg_loss = 0.4158\n",
            "t = 18, avg_loss = 0.4103\n",
            "t = 19, avg_loss = 0.4488\n",
            "t = 20, avg_loss = 0.4597\n",
            "t = 21, avg_loss = 0.4464\n",
            "t = 22, avg_loss = 0.3906\n",
            "t = 23, avg_loss = 0.3595\n",
            "t = 24, avg_loss = 0.5100\n",
            "t = 25, avg_loss = 0.4558\n",
            "Checking accuracy on test set\n",
            "Got 328 / 400 correct (82.00)\n",
            "acc = 0.820000\n",
            "Starting epoch 33 / 80\n",
            "t = 1, avg_loss = 0.5119\n",
            "t = 2, avg_loss = 0.5935\n",
            "t = 3, avg_loss = 0.3595\n",
            "t = 4, avg_loss = 0.4051\n",
            "t = 5, avg_loss = 0.4835\n",
            "t = 6, avg_loss = 0.4441\n",
            "t = 7, avg_loss = 0.5441\n",
            "t = 8, avg_loss = 0.4914\n",
            "t = 9, avg_loss = 0.4830\n",
            "t = 10, avg_loss = 0.4290\n",
            "t = 11, avg_loss = 0.4120\n",
            "t = 12, avg_loss = 0.4274\n",
            "t = 13, avg_loss = 0.6083\n",
            "t = 14, avg_loss = 0.4230\n",
            "t = 15, avg_loss = 0.3339\n",
            "t = 16, avg_loss = 0.4407\n",
            "t = 17, avg_loss = 0.3426\n",
            "t = 18, avg_loss = 0.3934\n",
            "t = 19, avg_loss = 0.5075\n",
            "t = 20, avg_loss = 0.4102\n",
            "t = 21, avg_loss = 0.4826\n",
            "t = 22, avg_loss = 0.3784\n",
            "t = 23, avg_loss = 0.3856\n",
            "t = 24, avg_loss = 0.5030\n",
            "t = 25, avg_loss = 0.4822\n",
            "Checking accuracy on test set\n",
            "Got 327 / 400 correct (81.75)\n",
            "acc = 0.817500\n",
            "Starting epoch 34 / 80\n",
            "t = 1, avg_loss = 0.5655\n",
            "t = 2, avg_loss = 0.2956\n",
            "t = 3, avg_loss = 0.4132\n",
            "t = 4, avg_loss = 0.4975\n",
            "t = 5, avg_loss = 0.4689\n",
            "t = 6, avg_loss = 0.3810\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-cd19a9399f15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_gpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0mcheck_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-7b7c48cb9b8f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, loss_fn, optimizer, num_epochs, starting_from_epoch)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mx_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0my_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-50a9cd504daf>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m           \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"malignant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"malignant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \"\"\"\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   1856\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1858\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreducing_gap\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresample\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mNEAREST\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hm3h_Kyyp_6h",
        "colab_type": "code",
        "outputId": "cf539143-8e19-49f9-9865-de27b715acf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "check_accuracy(model_gpu, valid_loader)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking accuracy on test set\n",
            "Got 328 / 400 correct (82.00)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.82"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzuX5gLEeJfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def retry_from_backup():\n",
        "  model_gpu = model_base.type(gpu_dtype)\n",
        "  print(model_gpu)\n",
        "  loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) \n",
        "\n",
        "\n",
        "\n",
        "  checkpoint = torch.load(model_backup_path)\n",
        "  model_gpu.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  epoch = checkpoint['epoch']\n",
        "  loss = checkpoint['loss']\n",
        "  print(\"starting from epoch: \" + str(epoch))\n",
        "  print(\"starting from loss: \" + str(loss))\n",
        "\n",
        "\n",
        "  train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs, starting_from_epoch=epoch)\n",
        "  check_accuracy(model_gpu, valid_loader)\n",
        "#retry_from_backup()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDn-2g-TLY3k",
        "colab_type": "code",
        "outputId": "2c5531b0-ccf7-4eda-d7ec-b21992edf291",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot([print_every*batch_size*(i+1) for i in range((len(avg_loss_list)))],avg_loss_list)\n",
        "print(\"Loss:\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGer6hJv7-zR",
        "colab_type": "code",
        "outputId": "a2ac3700-ac47-4244-e6e1-abf536c2363c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "plt.plot([i+1 for i in range((len(acc_list)))],acc_list)\n",
        "print(\"Accurancy:\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accurancy:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBTReWHxz4Ml",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c27ef2c2-49db-4bbe-8843-4a520f411624"
      },
      "source": [
        "gpu_dtype = torch.cuda.FloatTensor\n",
        "\n",
        "print_every = 1\n",
        "\n",
        "model_base = nn.Sequential( \n",
        "                nn.Kerv2d(in_channels , out_channels_1, padding=padding_1, dilation=1, groups=1, bias=True, \n",
        "                          kernel_type='polynomial', kernel_size=kernel_size, learnable_kernel=True,\n",
        "                          kernel_regularizer=True, stride=1, balance=1, power=3, gamma=1\n",
        "                          ),\n",
        "                \n",
        "                nn.BatchNorm2d(out_channels_1),\n",
        "                nn.Conv2d(out_channels_1 , out_channels_2, padding= padding_1, kernel_size=kernel_size, stride=1), \n",
        "                nn.Dropout(0.1),\n",
        "                nn.BatchNorm2d(out_channels_2),\n",
        "                nn.AvgPool2d(2, stride=2), \n",
        "                \n",
        "                #nn.Conv2d(out_channels_2 , out_channels_3, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.Kerv2d(out_channels_2 , out_channels_3, padding=padding_1, dilation=1, groups=1, bias=True, \n",
        "                          kernel_type='polynomial', kernel_size=kernel_size, learnable_kernel=True,\n",
        "                          kernel_regularizer=True, stride=1, balance=1, power=3, gamma=1\n",
        "                          ),\n",
        "                \n",
        "                nn.BatchNorm2d(out_channels_3),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_3 , out_channels_4, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.BatchNorm2d(out_channels_4),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_4 , out_channels_5, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.BatchNorm2d(out_channels_5),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_5 , out_channels_6, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.BatchNorm2d(out_channels_6),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                Flatten(),\n",
        "                nn.Dropout(0.5),\n",
        "                nn.Linear(1152,64),\n",
        "                nn.Linear(64,2)\n",
        "            )\n",
        "model_gpu = model_base.type(gpu_dtype)\n",
        "print(model_gpu)\n",
        "loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) \n",
        "\n",
        "retry_from_backup()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Kerv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): Conv2d(16, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (3): Dropout(p=0.1, inplace=False)\n",
            "  (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (6): Kerv2d(24, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (8): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (9): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (10): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (11): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (12): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (13): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (14): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (15): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (18): Flatten()\n",
            "  (19): Dropout(p=0.5, inplace=False)\n",
            "  (20): Linear(in_features=1152, out_features=64, bias=True)\n",
            "  (21): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n",
            "Sequential(\n",
            "  (0): Kerv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): Conv2d(16, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (3): Dropout(p=0.1, inplace=False)\n",
            "  (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (6): Kerv2d(24, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (8): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (9): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (10): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (11): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (12): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (13): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (14): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (15): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (18): Flatten()\n",
            "  (19): Dropout(p=0.5, inplace=False)\n",
            "  (20): Linear(in_features=1152, out_features=64, bias=True)\n",
            "  (21): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n",
            "starting from epoch: 32\n",
            "starting from loss: tensor(0.4822, device='cuda:0', requires_grad=True)\n",
            "Starting epoch 1 / 80\n",
            "t = 1, avg_loss = 0.5710\n",
            "t = 2, avg_loss = 0.4103\n",
            "t = 3, avg_loss = 0.5666\n",
            "t = 4, avg_loss = 0.4563\n",
            "t = 5, avg_loss = 0.4212\n",
            "t = 6, avg_loss = 0.3405\n",
            "t = 7, avg_loss = 0.4301\n",
            "t = 8, avg_loss = 0.4949\n",
            "t = 9, avg_loss = 0.5781\n",
            "t = 10, avg_loss = 0.4728\n",
            "t = 11, avg_loss = 0.4269\n",
            "t = 12, avg_loss = 0.4447\n",
            "t = 13, avg_loss = 0.4637\n",
            "t = 14, avg_loss = 0.4186\n",
            "t = 15, avg_loss = 0.2984\n",
            "t = 16, avg_loss = 0.4264\n",
            "t = 17, avg_loss = 0.4135\n",
            "t = 18, avg_loss = 0.5827\n",
            "t = 19, avg_loss = 0.3544\n",
            "t = 20, avg_loss = 0.4376\n",
            "t = 21, avg_loss = 0.4274\n",
            "t = 22, avg_loss = 0.4021\n",
            "t = 23, avg_loss = 0.5629\n",
            "t = 24, avg_loss = 0.4277\n",
            "t = 25, avg_loss = 0.4415\n",
            "Checking accuracy on test set\n",
            "Got 334 / 400 correct (83.50)\n",
            "acc = 0.835000\n",
            "Starting epoch 2 / 80\n",
            "t = 1, avg_loss = 0.4529\n",
            "t = 2, avg_loss = 0.4421\n",
            "t = 3, avg_loss = 0.4941\n",
            "t = 4, avg_loss = 0.3595\n",
            "t = 5, avg_loss = 0.4636\n",
            "t = 6, avg_loss = 0.3723\n",
            "t = 7, avg_loss = 0.3706\n",
            "t = 8, avg_loss = 0.5842\n",
            "t = 9, avg_loss = 0.5156\n",
            "t = 10, avg_loss = 0.4999\n",
            "t = 11, avg_loss = 0.3742\n",
            "t = 12, avg_loss = 0.3833\n",
            "t = 13, avg_loss = 0.3907\n",
            "t = 14, avg_loss = 0.3886\n",
            "t = 15, avg_loss = 0.3982\n",
            "t = 16, avg_loss = 0.4630\n",
            "t = 17, avg_loss = 0.3715\n",
            "t = 18, avg_loss = 0.3203\n",
            "t = 19, avg_loss = 0.3847\n",
            "t = 20, avg_loss = 0.2967\n",
            "t = 21, avg_loss = 0.4148\n",
            "t = 22, avg_loss = 0.4060\n",
            "t = 23, avg_loss = 0.3148\n",
            "t = 24, avg_loss = 0.4087\n",
            "t = 25, avg_loss = 0.5022\n",
            "Checking accuracy on test set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 3 / 80\n",
            "t = 1, avg_loss = 0.3767\n",
            "t = 2, avg_loss = 0.5057\n",
            "t = 3, avg_loss = 0.3952\n",
            "t = 4, avg_loss = 0.3749\n",
            "t = 5, avg_loss = 0.3524\n",
            "t = 6, avg_loss = 0.6943\n",
            "t = 7, avg_loss = 0.6032\n",
            "t = 8, avg_loss = 0.5377\n",
            "t = 9, avg_loss = 0.4392\n",
            "t = 10, avg_loss = 0.3699\n",
            "t = 11, avg_loss = 0.2857\n",
            "t = 12, avg_loss = 0.5764\n",
            "t = 13, avg_loss = 0.3636\n",
            "t = 14, avg_loss = 0.4255\n",
            "t = 15, avg_loss = 0.3390\n",
            "t = 16, avg_loss = 0.4150\n",
            "t = 17, avg_loss = 0.4367\n",
            "t = 18, avg_loss = 0.4318\n",
            "t = 19, avg_loss = 0.3966\n",
            "t = 20, avg_loss = 0.4242\n",
            "t = 21, avg_loss = 0.4104\n",
            "t = 22, avg_loss = 0.4071\n",
            "t = 23, avg_loss = 0.3881\n",
            "t = 24, avg_loss = 0.5229\n",
            "t = 25, avg_loss = 0.3443\n",
            "Checking accuracy on test set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 4 / 80\n",
            "t = 1, avg_loss = 0.4800\n",
            "t = 2, avg_loss = 0.3652\n",
            "t = 3, avg_loss = 0.4734\n",
            "t = 4, avg_loss = 0.4282\n",
            "t = 5, avg_loss = 0.3562\n",
            "t = 6, avg_loss = 0.4610\n",
            "t = 7, avg_loss = 0.4416\n",
            "t = 8, avg_loss = 0.4374\n",
            "t = 9, avg_loss = 0.5235\n",
            "t = 10, avg_loss = 0.3645\n",
            "t = 11, avg_loss = 0.4569\n",
            "t = 12, avg_loss = 0.2560\n",
            "t = 13, avg_loss = 0.3781\n",
            "t = 14, avg_loss = 0.5579\n",
            "t = 15, avg_loss = 0.5652\n",
            "t = 16, avg_loss = 0.5063\n",
            "t = 17, avg_loss = 0.3605\n",
            "t = 18, avg_loss = 0.4871\n",
            "t = 19, avg_loss = 0.3680\n",
            "t = 20, avg_loss = 0.4942\n",
            "t = 21, avg_loss = 0.3860\n",
            "t = 22, avg_loss = 0.3983\n",
            "t = 23, avg_loss = 0.3899\n",
            "t = 24, avg_loss = 0.4660\n",
            "t = 25, avg_loss = 0.4716\n",
            "Checking accuracy on test set\n",
            "Got 344 / 400 correct (86.00)\n",
            "acc = 0.860000\n",
            "Starting epoch 5 / 80\n",
            "t = 1, avg_loss = 0.5354\n",
            "t = 2, avg_loss = 0.3264\n",
            "t = 3, avg_loss = 0.4543\n",
            "t = 4, avg_loss = 0.5848\n",
            "t = 5, avg_loss = 0.4866\n",
            "t = 6, avg_loss = 0.5012\n",
            "t = 7, avg_loss = 0.4139\n",
            "t = 8, avg_loss = 0.3565\n",
            "t = 9, avg_loss = 0.4456\n",
            "t = 10, avg_loss = 0.3695\n",
            "t = 11, avg_loss = 0.2830\n",
            "t = 12, avg_loss = 0.4108\n",
            "t = 13, avg_loss = 0.3379\n",
            "t = 14, avg_loss = 0.4441\n",
            "t = 15, avg_loss = 0.6007\n",
            "t = 16, avg_loss = 0.4301\n",
            "t = 17, avg_loss = 0.4552\n",
            "t = 18, avg_loss = 0.4034\n",
            "t = 19, avg_loss = 0.3999\n",
            "t = 20, avg_loss = 0.4233\n",
            "t = 21, avg_loss = 0.3731\n",
            "t = 22, avg_loss = 0.4068\n",
            "t = 23, avg_loss = 0.3925\n",
            "t = 24, avg_loss = 0.4320\n",
            "t = 25, avg_loss = 0.3845\n",
            "Checking accuracy on test set\n",
            "Got 329 / 400 correct (82.25)\n",
            "acc = 0.822500\n",
            "Starting epoch 6 / 80\n",
            "t = 1, avg_loss = 0.4915\n",
            "t = 2, avg_loss = 0.4048\n",
            "t = 3, avg_loss = 0.3085\n",
            "t = 4, avg_loss = 0.3177\n",
            "t = 5, avg_loss = 0.4741\n",
            "t = 6, avg_loss = 0.2750\n",
            "t = 7, avg_loss = 0.4231\n",
            "t = 8, avg_loss = 0.4612\n",
            "t = 9, avg_loss = 0.5346\n",
            "t = 10, avg_loss = 0.5456\n",
            "t = 11, avg_loss = 0.4978\n",
            "t = 12, avg_loss = 0.5593\n",
            "t = 13, avg_loss = 0.2821\n",
            "t = 14, avg_loss = 0.4331\n",
            "t = 15, avg_loss = 0.3849\n",
            "t = 16, avg_loss = 0.4435\n",
            "t = 17, avg_loss = 0.3287\n",
            "t = 18, avg_loss = 0.4455\n",
            "t = 19, avg_loss = 0.4869\n",
            "t = 20, avg_loss = 0.3603\n",
            "t = 21, avg_loss = 0.4576\n",
            "t = 22, avg_loss = 0.3555\n",
            "t = 23, avg_loss = 0.4843\n",
            "t = 24, avg_loss = 0.3758\n",
            "t = 25, avg_loss = 0.3664\n",
            "Checking accuracy on test set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 7 / 80\n",
            "t = 1, avg_loss = 0.3762\n",
            "t = 2, avg_loss = 0.4309\n",
            "t = 3, avg_loss = 0.4121\n",
            "t = 4, avg_loss = 0.3207\n",
            "t = 5, avg_loss = 0.4217\n",
            "t = 6, avg_loss = 0.4468\n",
            "t = 7, avg_loss = 0.5026\n",
            "t = 8, avg_loss = 0.3994\n",
            "t = 9, avg_loss = 0.4817\n",
            "t = 10, avg_loss = 0.4136\n",
            "t = 11, avg_loss = 0.4301\n",
            "t = 12, avg_loss = 0.4430\n",
            "t = 13, avg_loss = 0.3280\n",
            "t = 14, avg_loss = 0.3842\n",
            "t = 15, avg_loss = 0.3331\n",
            "t = 16, avg_loss = 0.3695\n",
            "t = 17, avg_loss = 0.3745\n",
            "t = 18, avg_loss = 0.3641\n",
            "t = 19, avg_loss = 0.4515\n",
            "t = 20, avg_loss = 0.4538\n",
            "t = 21, avg_loss = 0.3433\n",
            "t = 22, avg_loss = 0.3744\n",
            "t = 23, avg_loss = 0.4725\n",
            "t = 24, avg_loss = 0.4304\n",
            "t = 25, avg_loss = 0.4104\n",
            "Checking accuracy on test set\n",
            "Got 343 / 400 correct (85.75)\n",
            "acc = 0.857500\n",
            "Starting epoch 8 / 80\n",
            "t = 1, avg_loss = 0.3694\n",
            "t = 2, avg_loss = 0.4120\n",
            "t = 3, avg_loss = 0.5034\n",
            "t = 4, avg_loss = 0.3890\n",
            "t = 5, avg_loss = 0.3502\n",
            "t = 6, avg_loss = 0.4377\n",
            "t = 7, avg_loss = 0.4089\n",
            "t = 8, avg_loss = 0.4303\n",
            "t = 9, avg_loss = 0.3321\n",
            "t = 10, avg_loss = 0.4294\n",
            "t = 11, avg_loss = 0.4256\n",
            "t = 12, avg_loss = 0.3676\n",
            "t = 13, avg_loss = 0.5396\n",
            "t = 14, avg_loss = 0.4843\n",
            "t = 15, avg_loss = 0.3573\n",
            "t = 16, avg_loss = 0.4814\n",
            "t = 17, avg_loss = 0.4098\n",
            "t = 18, avg_loss = 0.3202\n",
            "t = 19, avg_loss = 0.3307\n",
            "t = 20, avg_loss = 0.4028\n",
            "t = 21, avg_loss = 0.5030\n",
            "t = 22, avg_loss = 0.3801\n",
            "t = 23, avg_loss = 0.6310\n",
            "t = 24, avg_loss = 0.2921\n",
            "t = 25, avg_loss = 0.4565\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 9 / 80\n",
            "t = 1, avg_loss = 0.4443\n",
            "t = 2, avg_loss = 0.3710\n",
            "t = 3, avg_loss = 0.3753\n",
            "t = 4, avg_loss = 0.4006\n",
            "t = 5, avg_loss = 0.4034\n",
            "t = 6, avg_loss = 0.4065\n",
            "t = 7, avg_loss = 0.3802\n",
            "t = 8, avg_loss = 0.2776\n",
            "t = 9, avg_loss = 0.4921\n",
            "t = 10, avg_loss = 0.5011\n",
            "t = 11, avg_loss = 0.3773\n",
            "t = 12, avg_loss = 0.3496\n",
            "t = 13, avg_loss = 0.4733\n",
            "t = 14, avg_loss = 0.4505\n",
            "t = 15, avg_loss = 0.4563\n",
            "t = 16, avg_loss = 0.3273\n",
            "t = 17, avg_loss = 0.5584\n",
            "t = 18, avg_loss = 0.3376\n",
            "t = 19, avg_loss = 0.4966\n",
            "t = 20, avg_loss = 0.4681\n",
            "t = 21, avg_loss = 0.3975\n",
            "t = 22, avg_loss = 0.4427\n",
            "t = 23, avg_loss = 0.4004\n",
            "t = 24, avg_loss = 0.3218\n",
            "t = 25, avg_loss = 0.4374\n",
            "Checking accuracy on test set\n",
            "Got 346 / 400 correct (86.50)\n",
            "acc = 0.865000\n",
            "Starting epoch 10 / 80\n",
            "t = 1, avg_loss = 0.3803\n",
            "t = 2, avg_loss = 0.4529\n",
            "t = 3, avg_loss = 0.3640\n",
            "t = 4, avg_loss = 0.4011\n",
            "t = 5, avg_loss = 0.3892\n",
            "t = 6, avg_loss = 0.4841\n",
            "t = 7, avg_loss = 0.3840\n",
            "t = 8, avg_loss = 0.3157\n",
            "t = 9, avg_loss = 0.3739\n",
            "t = 10, avg_loss = 0.3497\n",
            "t = 11, avg_loss = 0.4214\n",
            "t = 12, avg_loss = 0.3980\n",
            "t = 13, avg_loss = 0.4741\n",
            "t = 14, avg_loss = 0.3751\n",
            "t = 15, avg_loss = 0.5398\n",
            "t = 16, avg_loss = 0.4415\n",
            "t = 17, avg_loss = 0.4293\n",
            "t = 18, avg_loss = 0.3634\n",
            "t = 19, avg_loss = 0.7503\n",
            "t = 20, avg_loss = 0.3078\n",
            "t = 21, avg_loss = 0.4613\n",
            "t = 22, avg_loss = 0.3876\n",
            "t = 23, avg_loss = 0.6542\n",
            "t = 24, avg_loss = 0.4582\n",
            "t = 25, avg_loss = 0.3800\n",
            "Checking accuracy on test set\n",
            "Got 332 / 400 correct (83.00)\n",
            "acc = 0.830000\n",
            "Starting epoch 11 / 80\n",
            "t = 1, avg_loss = 0.4398\n",
            "t = 2, avg_loss = 0.3879\n",
            "t = 3, avg_loss = 0.4952\n",
            "t = 4, avg_loss = 0.5380\n",
            "t = 5, avg_loss = 0.3067\n",
            "t = 6, avg_loss = 0.3764\n",
            "t = 7, avg_loss = 0.4130\n",
            "t = 8, avg_loss = 0.4014\n",
            "t = 9, avg_loss = 0.3468\n",
            "t = 10, avg_loss = 0.4181\n",
            "t = 11, avg_loss = 0.5568\n",
            "t = 12, avg_loss = 0.5294\n",
            "t = 13, avg_loss = 0.4193\n",
            "t = 14, avg_loss = 0.4410\n",
            "t = 15, avg_loss = 0.5520\n",
            "t = 16, avg_loss = 0.2891\n",
            "t = 17, avg_loss = 0.3284\n",
            "t = 18, avg_loss = 0.4425\n",
            "t = 19, avg_loss = 0.3411\n",
            "t = 20, avg_loss = 0.4229\n",
            "t = 21, avg_loss = 0.4961\n",
            "t = 22, avg_loss = 0.4012\n",
            "t = 23, avg_loss = 0.3198\n",
            "t = 24, avg_loss = 0.4278\n",
            "t = 25, avg_loss = 0.4259\n",
            "Checking accuracy on test set\n",
            "Got 344 / 400 correct (86.00)\n",
            "acc = 0.860000\n",
            "Starting epoch 12 / 80\n",
            "t = 1, avg_loss = 0.4016\n",
            "t = 2, avg_loss = 0.5029\n",
            "t = 3, avg_loss = 0.3956\n",
            "t = 4, avg_loss = 0.4882\n",
            "t = 5, avg_loss = 0.4130\n",
            "t = 6, avg_loss = 0.4689\n",
            "t = 7, avg_loss = 0.4545\n",
            "t = 8, avg_loss = 0.3677\n",
            "t = 9, avg_loss = 0.3787\n",
            "t = 10, avg_loss = 0.3407\n",
            "t = 11, avg_loss = 0.3625\n",
            "t = 12, avg_loss = 0.3288\n",
            "t = 13, avg_loss = 0.4189\n",
            "t = 14, avg_loss = 0.4707\n",
            "t = 15, avg_loss = 0.4957\n",
            "t = 16, avg_loss = 0.3442\n",
            "t = 17, avg_loss = 0.4030\n",
            "t = 18, avg_loss = 0.4195\n",
            "t = 19, avg_loss = 0.6163\n",
            "t = 20, avg_loss = 0.4091\n",
            "t = 21, avg_loss = 0.3717\n",
            "t = 22, avg_loss = 0.5081\n",
            "t = 23, avg_loss = 0.5057\n",
            "t = 24, avg_loss = 0.3477\n",
            "t = 25, avg_loss = 0.3774\n",
            "Checking accuracy on test set\n",
            "Got 336 / 400 correct (84.00)\n",
            "acc = 0.840000\n",
            "Starting epoch 13 / 80\n",
            "t = 1, avg_loss = 0.3450\n",
            "t = 2, avg_loss = 0.5311\n",
            "t = 3, avg_loss = 0.4150\n",
            "t = 4, avg_loss = 0.3781\n",
            "t = 5, avg_loss = 0.4463\n",
            "t = 6, avg_loss = 0.5221\n",
            "t = 7, avg_loss = 0.3728\n",
            "t = 8, avg_loss = 0.3239\n",
            "t = 9, avg_loss = 0.3260\n",
            "t = 10, avg_loss = 0.4520\n",
            "t = 11, avg_loss = 0.4463\n",
            "t = 12, avg_loss = 0.4764\n",
            "t = 13, avg_loss = 0.5125\n",
            "t = 14, avg_loss = 0.3838\n",
            "t = 15, avg_loss = 0.4356\n",
            "t = 16, avg_loss = 0.3364\n",
            "t = 17, avg_loss = 0.3913\n",
            "t = 18, avg_loss = 0.2982\n",
            "t = 19, avg_loss = 0.4809\n",
            "t = 20, avg_loss = 0.4497\n",
            "t = 21, avg_loss = 0.4279\n",
            "t = 22, avg_loss = 0.5019\n",
            "t = 23, avg_loss = 0.3968\n",
            "t = 24, avg_loss = 0.4993\n",
            "t = 25, avg_loss = 0.4127\n",
            "Checking accuracy on test set\n",
            "Got 328 / 400 correct (82.00)\n",
            "acc = 0.820000\n",
            "Starting epoch 14 / 80\n",
            "t = 1, avg_loss = 0.4118\n",
            "t = 2, avg_loss = 0.3734\n",
            "t = 3, avg_loss = 0.5316\n",
            "t = 4, avg_loss = 0.4098\n",
            "t = 5, avg_loss = 0.3639\n",
            "t = 6, avg_loss = 0.3008\n",
            "t = 7, avg_loss = 0.3878\n",
            "t = 8, avg_loss = 0.3896\n",
            "t = 9, avg_loss = 0.3684\n",
            "t = 10, avg_loss = 0.4377\n",
            "t = 11, avg_loss = 0.3964\n",
            "t = 12, avg_loss = 0.3060\n",
            "t = 13, avg_loss = 0.5497\n",
            "t = 14, avg_loss = 0.4873\n",
            "t = 15, avg_loss = 0.3712\n",
            "t = 16, avg_loss = 0.4384\n",
            "t = 17, avg_loss = 0.2960\n",
            "t = 18, avg_loss = 0.4082\n",
            "t = 19, avg_loss = 0.5506\n",
            "t = 20, avg_loss = 0.3460\n",
            "t = 21, avg_loss = 0.3822\n",
            "t = 22, avg_loss = 0.3029\n",
            "t = 23, avg_loss = 0.3299\n",
            "t = 24, avg_loss = 0.3098\n",
            "t = 25, avg_loss = 0.3902\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 15 / 80\n",
            "t = 1, avg_loss = 0.3239\n",
            "t = 2, avg_loss = 0.4225\n",
            "t = 3, avg_loss = 0.3544\n",
            "t = 4, avg_loss = 0.4035\n",
            "t = 5, avg_loss = 0.5301\n",
            "t = 6, avg_loss = 0.3072\n",
            "t = 7, avg_loss = 0.3140\n",
            "t = 8, avg_loss = 0.3637\n",
            "t = 9, avg_loss = 0.3736\n",
            "t = 10, avg_loss = 0.3138\n",
            "t = 11, avg_loss = 0.2920\n",
            "t = 12, avg_loss = 0.4776\n",
            "t = 13, avg_loss = 0.4983\n",
            "t = 14, avg_loss = 0.6272\n",
            "t = 15, avg_loss = 0.4205\n",
            "t = 16, avg_loss = 0.4368\n",
            "t = 17, avg_loss = 0.4334\n",
            "t = 18, avg_loss = 0.3555\n",
            "t = 19, avg_loss = 0.4011\n",
            "t = 20, avg_loss = 0.5051\n",
            "t = 21, avg_loss = 0.3684\n",
            "t = 22, avg_loss = 0.5693\n",
            "t = 23, avg_loss = 0.4455\n",
            "t = 24, avg_loss = 0.4661\n",
            "t = 25, avg_loss = 0.3930\n",
            "Checking accuracy on test set\n",
            "Got 331 / 400 correct (82.75)\n",
            "acc = 0.827500\n",
            "Starting epoch 16 / 80\n",
            "t = 1, avg_loss = 0.5048\n",
            "t = 2, avg_loss = 0.4368\n",
            "t = 3, avg_loss = 0.5912\n",
            "t = 4, avg_loss = 0.3650\n",
            "t = 5, avg_loss = 0.4607\n",
            "t = 6, avg_loss = 0.4470\n",
            "t = 7, avg_loss = 0.3401\n",
            "t = 8, avg_loss = 0.5569\n",
            "t = 9, avg_loss = 0.4426\n",
            "t = 10, avg_loss = 0.5199\n",
            "t = 11, avg_loss = 0.3440\n",
            "t = 12, avg_loss = 0.4071\n",
            "t = 13, avg_loss = 0.3600\n",
            "t = 14, avg_loss = 0.3539\n",
            "t = 15, avg_loss = 0.4607\n",
            "t = 16, avg_loss = 0.4367\n",
            "t = 17, avg_loss = 0.3983\n",
            "t = 18, avg_loss = 0.3026\n",
            "t = 19, avg_loss = 0.5585\n",
            "t = 20, avg_loss = 0.3456\n",
            "t = 21, avg_loss = 0.4521\n",
            "t = 22, avg_loss = 0.4306\n",
            "t = 23, avg_loss = 0.4356\n",
            "t = 24, avg_loss = 0.3213\n",
            "t = 25, avg_loss = 0.4021\n",
            "Checking accuracy on test set\n",
            "Got 336 / 400 correct (84.00)\n",
            "acc = 0.840000\n",
            "Starting epoch 17 / 80\n",
            "t = 1, avg_loss = 0.3962\n",
            "t = 2, avg_loss = 0.3591\n",
            "t = 3, avg_loss = 0.4149\n",
            "t = 4, avg_loss = 0.3871\n",
            "t = 5, avg_loss = 0.5385\n",
            "t = 6, avg_loss = 0.5528\n",
            "t = 7, avg_loss = 0.4387\n",
            "t = 8, avg_loss = 0.3984\n",
            "t = 9, avg_loss = 0.5068\n",
            "t = 10, avg_loss = 0.4574\n",
            "t = 11, avg_loss = 0.4628\n",
            "t = 12, avg_loss = 0.4007\n",
            "t = 13, avg_loss = 0.4399\n",
            "t = 14, avg_loss = 0.3881\n",
            "t = 15, avg_loss = 0.5287\n",
            "t = 16, avg_loss = 0.4641\n",
            "t = 17, avg_loss = 0.4124\n",
            "t = 18, avg_loss = 0.4139\n",
            "t = 19, avg_loss = 0.3440\n",
            "t = 20, avg_loss = 0.4635\n",
            "t = 21, avg_loss = 0.3976\n",
            "t = 22, avg_loss = 0.3450\n",
            "t = 23, avg_loss = 0.4395\n",
            "t = 24, avg_loss = 0.4210\n",
            "t = 25, avg_loss = 0.4064\n",
            "Checking accuracy on test set\n",
            "Got 341 / 400 correct (85.25)\n",
            "acc = 0.852500\n",
            "Starting epoch 18 / 80\n",
            "t = 1, avg_loss = 0.4146\n",
            "t = 2, avg_loss = 0.2831\n",
            "t = 3, avg_loss = 0.5440\n",
            "t = 4, avg_loss = 0.5403\n",
            "t = 5, avg_loss = 0.3163\n",
            "t = 6, avg_loss = 0.4508\n",
            "t = 7, avg_loss = 0.3520\n",
            "t = 8, avg_loss = 0.4486\n",
            "t = 9, avg_loss = 0.3189\n",
            "t = 10, avg_loss = 0.4899\n",
            "t = 11, avg_loss = 0.4927\n",
            "t = 12, avg_loss = 0.4787\n",
            "t = 13, avg_loss = 0.4713\n",
            "t = 14, avg_loss = 0.3930\n",
            "t = 15, avg_loss = 0.4270\n",
            "t = 16, avg_loss = 0.2995\n",
            "t = 17, avg_loss = 0.3549\n",
            "t = 18, avg_loss = 0.4504\n",
            "t = 19, avg_loss = 0.3901\n",
            "t = 20, avg_loss = 0.3402\n",
            "t = 21, avg_loss = 0.3388\n",
            "t = 22, avg_loss = 0.4146\n",
            "t = 23, avg_loss = 0.4593\n",
            "t = 24, avg_loss = 0.3485\n",
            "t = 25, avg_loss = 0.4594\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 19 / 80\n",
            "t = 1, avg_loss = 0.4248\n",
            "t = 2, avg_loss = 0.4825\n",
            "t = 3, avg_loss = 0.4800\n",
            "t = 4, avg_loss = 0.2839\n",
            "t = 5, avg_loss = 0.4056\n",
            "t = 6, avg_loss = 0.2706\n",
            "t = 7, avg_loss = 0.3327\n",
            "t = 8, avg_loss = 0.3534\n",
            "t = 9, avg_loss = 0.4574\n",
            "t = 10, avg_loss = 0.3528\n",
            "t = 11, avg_loss = 0.3925\n",
            "t = 12, avg_loss = 0.3942\n",
            "t = 13, avg_loss = 0.3648\n",
            "t = 14, avg_loss = 0.4229\n",
            "t = 15, avg_loss = 0.4889\n",
            "t = 16, avg_loss = 0.4162\n",
            "t = 17, avg_loss = 0.3549\n",
            "t = 18, avg_loss = 0.4973\n",
            "t = 19, avg_loss = 0.4056\n",
            "t = 20, avg_loss = 0.4281\n",
            "t = 21, avg_loss = 0.3897\n",
            "t = 22, avg_loss = 0.4240\n",
            "t = 23, avg_loss = 0.3903\n",
            "t = 24, avg_loss = 0.5168\n",
            "t = 25, avg_loss = 0.3771\n",
            "Checking accuracy on test set\n",
            "Got 339 / 400 correct (84.75)\n",
            "acc = 0.847500\n",
            "Starting epoch 20 / 80\n",
            "t = 1, avg_loss = 0.4307\n",
            "t = 2, avg_loss = 0.2999\n",
            "t = 3, avg_loss = 0.3783\n",
            "t = 4, avg_loss = 0.4001\n",
            "t = 5, avg_loss = 0.4771\n",
            "t = 6, avg_loss = 0.4730\n",
            "t = 7, avg_loss = 0.4905\n",
            "t = 8, avg_loss = 0.3304\n",
            "t = 9, avg_loss = 0.3573\n",
            "t = 10, avg_loss = 0.3460\n",
            "t = 11, avg_loss = 0.4119\n",
            "t = 12, avg_loss = 0.3812\n",
            "t = 13, avg_loss = 0.3890\n",
            "t = 14, avg_loss = 0.3142\n",
            "t = 15, avg_loss = 0.3544\n",
            "t = 16, avg_loss = 0.3513\n",
            "t = 17, avg_loss = 0.4466\n",
            "t = 18, avg_loss = 0.3806\n",
            "t = 19, avg_loss = 0.4670\n",
            "t = 20, avg_loss = 0.3961\n",
            "t = 21, avg_loss = 0.4127\n",
            "t = 22, avg_loss = 0.4897\n",
            "t = 23, avg_loss = 0.4766\n",
            "t = 24, avg_loss = 0.3042\n",
            "t = 25, avg_loss = 0.5017\n",
            "Checking accuracy on test set\n",
            "Got 335 / 400 correct (83.75)\n",
            "acc = 0.837500\n",
            "Starting epoch 21 / 80\n",
            "t = 1, avg_loss = 0.4673\n",
            "t = 2, avg_loss = 0.3596\n",
            "t = 3, avg_loss = 0.5055\n",
            "t = 4, avg_loss = 0.6243\n",
            "t = 5, avg_loss = 0.4564\n",
            "t = 6, avg_loss = 0.4582\n",
            "t = 7, avg_loss = 0.3471\n",
            "t = 8, avg_loss = 0.4623\n",
            "t = 9, avg_loss = 0.3093\n",
            "t = 10, avg_loss = 0.4216\n",
            "t = 11, avg_loss = 0.4305\n",
            "t = 12, avg_loss = 0.3533\n",
            "t = 13, avg_loss = 0.2756\n",
            "t = 14, avg_loss = 0.3420\n",
            "t = 15, avg_loss = 0.4871\n",
            "t = 16, avg_loss = 0.3422\n",
            "t = 17, avg_loss = 0.3304\n",
            "t = 18, avg_loss = 0.4686\n",
            "t = 19, avg_loss = 0.4046\n",
            "t = 20, avg_loss = 0.3467\n",
            "t = 21, avg_loss = 0.3627\n",
            "t = 22, avg_loss = 0.3980\n",
            "t = 23, avg_loss = 0.3385\n",
            "t = 24, avg_loss = 0.3587\n",
            "t = 25, avg_loss = 0.4633\n",
            "Checking accuracy on test set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 22 / 80\n",
            "t = 1, avg_loss = 0.3729\n",
            "t = 2, avg_loss = 0.3632\n",
            "t = 3, avg_loss = 0.3201\n",
            "t = 4, avg_loss = 0.3224\n",
            "t = 5, avg_loss = 0.4319\n",
            "t = 6, avg_loss = 0.3784\n",
            "t = 7, avg_loss = 0.4281\n",
            "t = 8, avg_loss = 0.3386\n",
            "t = 9, avg_loss = 0.4449\n",
            "t = 10, avg_loss = 0.3169\n",
            "t = 11, avg_loss = 0.3612\n",
            "t = 12, avg_loss = 0.3438\n",
            "t = 13, avg_loss = 0.3120\n",
            "t = 14, avg_loss = 0.3858\n",
            "t = 15, avg_loss = 0.4749\n",
            "t = 16, avg_loss = 0.3946\n",
            "t = 17, avg_loss = 0.4782\n",
            "t = 18, avg_loss = 0.4097\n",
            "t = 19, avg_loss = 0.3020\n",
            "t = 20, avg_loss = 0.4162\n",
            "t = 21, avg_loss = 0.4351\n",
            "t = 22, avg_loss = 0.4454\n",
            "t = 23, avg_loss = 0.3462\n",
            "t = 24, avg_loss = 0.3592\n",
            "t = 25, avg_loss = 0.4286\n",
            "Checking accuracy on test set\n",
            "Got 343 / 400 correct (85.75)\n",
            "acc = 0.857500\n",
            "Starting epoch 23 / 80\n",
            "t = 1, avg_loss = 0.4024\n",
            "t = 2, avg_loss = 0.2612\n",
            "t = 3, avg_loss = 0.3615\n",
            "t = 4, avg_loss = 0.3435\n",
            "t = 5, avg_loss = 0.3676\n",
            "t = 6, avg_loss = 0.3414\n",
            "t = 7, avg_loss = 0.2851\n",
            "t = 8, avg_loss = 0.4665\n",
            "t = 9, avg_loss = 0.3628\n",
            "t = 10, avg_loss = 0.4466\n",
            "t = 11, avg_loss = 0.3604\n",
            "t = 12, avg_loss = 0.3207\n",
            "t = 13, avg_loss = 0.3603\n",
            "t = 14, avg_loss = 0.3788\n",
            "t = 15, avg_loss = 0.3820\n",
            "t = 16, avg_loss = 0.4621\n",
            "t = 17, avg_loss = 0.4221\n",
            "t = 18, avg_loss = 0.3866\n",
            "t = 19, avg_loss = 0.4037\n",
            "t = 20, avg_loss = 0.3203\n",
            "t = 21, avg_loss = 0.4539\n",
            "t = 22, avg_loss = 0.4402\n",
            "t = 23, avg_loss = 0.3653\n",
            "t = 24, avg_loss = 0.4242\n",
            "t = 25, avg_loss = 0.4319\n",
            "Checking accuracy on test set\n",
            "Got 344 / 400 correct (86.00)\n",
            "acc = 0.860000\n",
            "Starting epoch 24 / 80\n",
            "t = 1, avg_loss = 0.3776\n",
            "t = 2, avg_loss = 0.3719\n",
            "t = 3, avg_loss = 0.4970\n",
            "t = 4, avg_loss = 0.3622\n",
            "t = 5, avg_loss = 0.4048\n",
            "t = 6, avg_loss = 0.3495\n",
            "t = 7, avg_loss = 0.4213\n",
            "t = 8, avg_loss = 0.4721\n",
            "t = 9, avg_loss = 0.3599\n",
            "t = 10, avg_loss = 0.4760\n",
            "t = 11, avg_loss = 0.2818\n",
            "t = 12, avg_loss = 0.4087\n",
            "t = 13, avg_loss = 0.3288\n",
            "t = 14, avg_loss = 0.5036\n",
            "t = 15, avg_loss = 0.3545\n",
            "t = 16, avg_loss = 0.3757\n",
            "t = 17, avg_loss = 0.4973\n",
            "t = 18, avg_loss = 0.2837\n",
            "t = 19, avg_loss = 0.4438\n",
            "t = 20, avg_loss = 0.3405\n",
            "t = 21, avg_loss = 0.3890\n",
            "t = 22, avg_loss = 0.3761\n",
            "t = 23, avg_loss = 0.3353\n",
            "t = 24, avg_loss = 0.4957\n",
            "t = 25, avg_loss = 0.4386\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 25 / 80\n",
            "t = 1, avg_loss = 0.3898\n",
            "t = 2, avg_loss = 0.4580\n",
            "t = 3, avg_loss = 0.4745\n",
            "t = 4, avg_loss = 0.3679\n",
            "t = 5, avg_loss = 0.4998\n",
            "t = 6, avg_loss = 0.3081\n",
            "t = 7, avg_loss = 0.3320\n",
            "t = 8, avg_loss = 0.3899\n",
            "t = 9, avg_loss = 0.3496\n",
            "t = 10, avg_loss = 0.5009\n",
            "t = 11, avg_loss = 0.4703\n",
            "t = 12, avg_loss = 0.3073\n",
            "t = 13, avg_loss = 0.3579\n",
            "t = 14, avg_loss = 0.2902\n",
            "t = 15, avg_loss = 0.3724\n",
            "t = 16, avg_loss = 0.3951\n",
            "t = 17, avg_loss = 0.3319\n",
            "t = 18, avg_loss = 0.4492\n",
            "t = 19, avg_loss = 0.3440\n",
            "t = 20, avg_loss = 0.3165\n",
            "t = 21, avg_loss = 0.3240\n",
            "t = 22, avg_loss = 0.5335\n",
            "t = 23, avg_loss = 0.4247\n",
            "t = 24, avg_loss = 0.3649\n",
            "t = 25, avg_loss = 0.2738\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 26 / 80\n",
            "t = 1, avg_loss = 0.4060\n",
            "t = 2, avg_loss = 0.3531\n",
            "t = 3, avg_loss = 0.4160\n",
            "t = 4, avg_loss = 0.3724\n",
            "t = 5, avg_loss = 0.4156\n",
            "t = 6, avg_loss = 0.3575\n",
            "t = 7, avg_loss = 0.3131\n",
            "t = 8, avg_loss = 0.4148\n",
            "t = 9, avg_loss = 0.4186\n",
            "t = 10, avg_loss = 0.3643\n",
            "t = 11, avg_loss = 0.3705\n",
            "t = 12, avg_loss = 0.6454\n",
            "t = 13, avg_loss = 0.4044\n",
            "t = 14, avg_loss = 0.4020\n",
            "t = 15, avg_loss = 0.3269\n",
            "t = 16, avg_loss = 0.4055\n",
            "t = 17, avg_loss = 0.4517\n",
            "t = 18, avg_loss = 0.4528\n",
            "t = 19, avg_loss = 0.4093\n",
            "t = 20, avg_loss = 0.3875\n",
            "t = 21, avg_loss = 0.4125\n",
            "t = 22, avg_loss = 0.4072\n",
            "t = 23, avg_loss = 0.4124\n",
            "t = 24, avg_loss = 0.3755\n",
            "t = 25, avg_loss = 0.4061\n",
            "Checking accuracy on test set\n",
            "Got 351 / 400 correct (87.75)\n",
            "acc = 0.877500\n",
            "Starting epoch 27 / 80\n",
            "t = 1, avg_loss = 0.4022\n",
            "t = 2, avg_loss = 0.4685\n",
            "t = 3, avg_loss = 0.3002\n",
            "t = 4, avg_loss = 0.4977\n",
            "t = 5, avg_loss = 0.3391\n",
            "t = 6, avg_loss = 0.3323\n",
            "t = 7, avg_loss = 0.4637\n",
            "t = 8, avg_loss = 0.3602\n",
            "t = 9, avg_loss = 0.3373\n",
            "t = 10, avg_loss = 0.4087\n",
            "t = 11, avg_loss = 0.3446\n",
            "t = 12, avg_loss = 0.2925\n",
            "t = 13, avg_loss = 0.4949\n",
            "t = 14, avg_loss = 0.4464\n",
            "t = 15, avg_loss = 0.3969\n",
            "t = 16, avg_loss = 0.3798\n",
            "t = 17, avg_loss = 0.3715\n",
            "t = 18, avg_loss = 0.4959\n",
            "t = 19, avg_loss = 0.4514\n",
            "t = 20, avg_loss = 0.4078\n",
            "t = 21, avg_loss = 0.4845\n",
            "t = 22, avg_loss = 0.3558\n",
            "t = 23, avg_loss = 0.3326\n",
            "t = 24, avg_loss = 0.2791\n",
            "t = 25, avg_loss = 0.3192\n",
            "Checking accuracy on test set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 28 / 80\n",
            "t = 1, avg_loss = 0.5022\n",
            "t = 2, avg_loss = 0.3863\n",
            "t = 3, avg_loss = 0.3887\n",
            "t = 4, avg_loss = 0.3871\n",
            "t = 5, avg_loss = 0.3776\n",
            "t = 6, avg_loss = 0.3699\n",
            "t = 7, avg_loss = 0.4045\n",
            "t = 8, avg_loss = 0.3020\n",
            "t = 9, avg_loss = 0.3654\n",
            "t = 10, avg_loss = 0.3222\n",
            "t = 11, avg_loss = 0.4001\n",
            "t = 12, avg_loss = 0.4230\n",
            "t = 13, avg_loss = 0.4366\n",
            "t = 14, avg_loss = 0.4791\n",
            "t = 15, avg_loss = 0.3175\n",
            "t = 16, avg_loss = 0.3546\n",
            "t = 17, avg_loss = 0.2588\n",
            "t = 18, avg_loss = 0.5046\n",
            "t = 19, avg_loss = 0.4777\n",
            "t = 20, avg_loss = 0.3636\n",
            "t = 21, avg_loss = 0.5116\n",
            "t = 22, avg_loss = 0.3871\n",
            "t = 23, avg_loss = 0.3409\n",
            "t = 24, avg_loss = 0.4837\n",
            "t = 25, avg_loss = 0.4387\n",
            "Checking accuracy on test set\n",
            "Got 338 / 400 correct (84.50)\n",
            "acc = 0.845000\n",
            "Starting epoch 29 / 80\n",
            "t = 1, avg_loss = 0.4412\n",
            "t = 2, avg_loss = 0.3935\n",
            "t = 3, avg_loss = 0.3436\n",
            "t = 4, avg_loss = 0.5037\n",
            "t = 5, avg_loss = 0.4015\n",
            "t = 6, avg_loss = 0.3775\n",
            "t = 7, avg_loss = 0.3038\n",
            "t = 8, avg_loss = 0.4106\n",
            "t = 9, avg_loss = 0.4507\n",
            "t = 10, avg_loss = 0.3729\n",
            "t = 11, avg_loss = 0.3894\n",
            "t = 12, avg_loss = 0.3383\n",
            "t = 13, avg_loss = 0.4335\n",
            "t = 14, avg_loss = 0.3159\n",
            "t = 15, avg_loss = 0.3956\n",
            "t = 16, avg_loss = 0.2790\n",
            "t = 17, avg_loss = 0.3428\n",
            "t = 18, avg_loss = 0.3817\n",
            "t = 19, avg_loss = 0.3022\n",
            "t = 20, avg_loss = 0.6228\n",
            "t = 21, avg_loss = 0.2792\n",
            "t = 22, avg_loss = 0.4625\n",
            "t = 23, avg_loss = 0.3802\n",
            "t = 24, avg_loss = 0.3614\n",
            "t = 25, avg_loss = 0.4109\n",
            "Checking accuracy on test set\n",
            "Got 344 / 400 correct (86.00)\n",
            "acc = 0.860000\n",
            "Starting epoch 30 / 80\n",
            "t = 1, avg_loss = 0.4184\n",
            "t = 2, avg_loss = 0.3626\n",
            "t = 3, avg_loss = 0.4080\n",
            "t = 4, avg_loss = 0.3773\n",
            "t = 5, avg_loss = 0.4897\n",
            "t = 6, avg_loss = 0.3634\n",
            "t = 7, avg_loss = 0.3041\n",
            "t = 8, avg_loss = 0.5005\n",
            "t = 9, avg_loss = 0.4164\n",
            "t = 10, avg_loss = 0.3762\n",
            "t = 11, avg_loss = 0.4055\n",
            "t = 12, avg_loss = 0.3519\n",
            "t = 13, avg_loss = 0.3367\n",
            "t = 14, avg_loss = 0.4000\n",
            "t = 15, avg_loss = 0.2538\n",
            "t = 16, avg_loss = 0.3602\n",
            "t = 17, avg_loss = 0.3754\n",
            "t = 18, avg_loss = 0.3580\n",
            "t = 19, avg_loss = 0.4026\n",
            "t = 20, avg_loss = 0.4757\n",
            "t = 21, avg_loss = 0.4579\n",
            "t = 22, avg_loss = 0.2479\n",
            "t = 23, avg_loss = 0.3806\n",
            "t = 24, avg_loss = 0.3690\n",
            "t = 25, avg_loss = 0.3593\n",
            "Checking accuracy on test set\n",
            "Got 345 / 400 correct (86.25)\n",
            "acc = 0.862500\n",
            "Starting epoch 31 / 80\n",
            "t = 1, avg_loss = 0.3423\n",
            "t = 2, avg_loss = 0.3554\n",
            "t = 3, avg_loss = 0.3943\n",
            "t = 4, avg_loss = 0.3864\n",
            "t = 5, avg_loss = 0.3000\n",
            "t = 6, avg_loss = 0.4170\n",
            "t = 7, avg_loss = 0.4116\n",
            "t = 8, avg_loss = 0.2526\n",
            "t = 9, avg_loss = 0.2998\n",
            "t = 10, avg_loss = 0.3023\n",
            "t = 11, avg_loss = 0.4174\n",
            "t = 12, avg_loss = 0.3918\n",
            "t = 13, avg_loss = 0.2795\n",
            "t = 14, avg_loss = 0.4219\n",
            "t = 15, avg_loss = 0.4316\n",
            "t = 16, avg_loss = 0.4889\n",
            "t = 17, avg_loss = 0.3581\n",
            "t = 18, avg_loss = 0.3841\n",
            "t = 19, avg_loss = 0.3811\n",
            "t = 20, avg_loss = 0.4593\n",
            "t = 21, avg_loss = 0.4369\n",
            "t = 22, avg_loss = 0.3891\n",
            "t = 23, avg_loss = 0.4325\n",
            "t = 24, avg_loss = 0.3075\n",
            "t = 25, avg_loss = 0.3806\n",
            "Checking accuracy on test set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 32 / 80\n",
            "t = 1, avg_loss = 0.3244\n",
            "t = 2, avg_loss = 0.3041\n",
            "t = 3, avg_loss = 0.4000\n",
            "t = 4, avg_loss = 0.4691\n",
            "t = 5, avg_loss = 0.3893\n",
            "t = 6, avg_loss = 0.3178\n",
            "t = 7, avg_loss = 0.5003\n",
            "t = 8, avg_loss = 0.3166\n",
            "t = 9, avg_loss = 0.4571\n",
            "t = 10, avg_loss = 0.3855\n",
            "t = 11, avg_loss = 0.3692\n",
            "t = 12, avg_loss = 0.2876\n",
            "t = 13, avg_loss = 0.3134\n",
            "t = 14, avg_loss = 0.3815\n",
            "t = 15, avg_loss = 0.3357\n",
            "t = 16, avg_loss = 0.5101\n",
            "t = 17, avg_loss = 0.4661\n",
            "t = 18, avg_loss = 0.4717\n",
            "t = 19, avg_loss = 0.2862\n",
            "t = 20, avg_loss = 0.3533\n",
            "t = 21, avg_loss = 0.4392\n",
            "t = 22, avg_loss = 0.4906\n",
            "t = 23, avg_loss = 0.2826\n",
            "t = 24, avg_loss = 0.4361\n",
            "t = 25, avg_loss = 0.4409\n",
            "Checking accuracy on test set\n",
            "Got 341 / 400 correct (85.25)\n",
            "acc = 0.852500\n",
            "Starting epoch 33 / 80\n",
            "t = 1, avg_loss = 0.3229\n",
            "t = 2, avg_loss = 0.3613\n",
            "t = 3, avg_loss = 0.3335\n",
            "t = 4, avg_loss = 0.5415\n",
            "t = 5, avg_loss = 0.4044\n",
            "t = 6, avg_loss = 0.4526\n",
            "t = 7, avg_loss = 0.3194\n",
            "t = 8, avg_loss = 0.4659\n",
            "t = 9, avg_loss = 0.5334\n",
            "t = 10, avg_loss = 0.4829\n",
            "t = 11, avg_loss = 0.4247\n",
            "t = 12, avg_loss = 0.4203\n",
            "t = 13, avg_loss = 0.3376\n",
            "t = 14, avg_loss = 0.5183\n",
            "t = 15, avg_loss = 0.3741\n",
            "t = 16, avg_loss = 0.3926\n",
            "t = 17, avg_loss = 0.4797\n",
            "t = 18, avg_loss = 0.3643\n",
            "t = 19, avg_loss = 0.3473\n",
            "t = 20, avg_loss = 0.3985\n",
            "t = 21, avg_loss = 0.4571\n",
            "t = 22, avg_loss = 0.4272\n",
            "t = 23, avg_loss = 0.3329\n",
            "t = 24, avg_loss = 0.2681\n",
            "t = 25, avg_loss = 0.3687\n",
            "Checking accuracy on test set\n",
            "Got 346 / 400 correct (86.50)\n",
            "acc = 0.865000\n",
            "Starting epoch 34 / 80\n",
            "t = 1, avg_loss = 0.4072\n",
            "t = 2, avg_loss = 0.3944\n",
            "t = 3, avg_loss = 0.3243\n",
            "t = 4, avg_loss = 0.3550\n",
            "t = 5, avg_loss = 0.3521\n",
            "t = 6, avg_loss = 0.3024\n",
            "t = 7, avg_loss = 0.2976\n",
            "t = 8, avg_loss = 0.4474\n",
            "t = 9, avg_loss = 0.3659\n",
            "t = 10, avg_loss = 0.3778\n",
            "t = 11, avg_loss = 0.3638\n",
            "t = 12, avg_loss = 0.2757\n",
            "t = 13, avg_loss = 0.3010\n",
            "t = 14, avg_loss = 0.4241\n",
            "t = 15, avg_loss = 0.3836\n",
            "t = 16, avg_loss = 0.3862\n",
            "t = 17, avg_loss = 0.4368\n",
            "t = 18, avg_loss = 0.4317\n",
            "t = 19, avg_loss = 0.4438\n",
            "t = 20, avg_loss = 0.3994\n",
            "t = 21, avg_loss = 0.3951\n",
            "t = 22, avg_loss = 0.4038\n",
            "t = 23, avg_loss = 0.3666\n",
            "t = 24, avg_loss = 0.3265\n",
            "t = 25, avg_loss = 0.4391\n",
            "Checking accuracy on test set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 35 / 80\n",
            "t = 1, avg_loss = 0.3673\n",
            "t = 2, avg_loss = 0.3763\n",
            "t = 3, avg_loss = 0.3338\n",
            "t = 4, avg_loss = 0.3375\n",
            "t = 5, avg_loss = 0.4119\n",
            "t = 6, avg_loss = 0.3828\n",
            "t = 7, avg_loss = 0.3098\n",
            "t = 8, avg_loss = 0.4690\n",
            "t = 9, avg_loss = 0.3986\n",
            "t = 10, avg_loss = 0.3694\n",
            "t = 11, avg_loss = 0.2970\n",
            "t = 12, avg_loss = 0.3891\n",
            "t = 13, avg_loss = 0.3868\n",
            "t = 14, avg_loss = 0.3834\n",
            "t = 15, avg_loss = 0.4000\n",
            "t = 16, avg_loss = 0.4247\n",
            "t = 17, avg_loss = 0.4899\n",
            "t = 18, avg_loss = 0.3723\n",
            "t = 19, avg_loss = 0.3056\n",
            "t = 20, avg_loss = 0.3922\n",
            "t = 21, avg_loss = 0.3765\n",
            "t = 22, avg_loss = 0.4312\n",
            "t = 23, avg_loss = 0.3612\n",
            "t = 24, avg_loss = 0.3348\n",
            "t = 25, avg_loss = 0.3696\n",
            "Checking accuracy on test set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 36 / 80\n",
            "t = 1, avg_loss = 0.4854\n",
            "t = 2, avg_loss = 0.3141\n",
            "t = 3, avg_loss = 0.3538\n",
            "t = 4, avg_loss = 0.3097\n",
            "t = 5, avg_loss = 0.3622\n",
            "t = 6, avg_loss = 0.4042\n",
            "t = 7, avg_loss = 0.3047\n",
            "t = 8, avg_loss = 0.3866\n",
            "t = 9, avg_loss = 0.3199\n",
            "t = 10, avg_loss = 0.2999\n",
            "t = 11, avg_loss = 0.2824\n",
            "t = 12, avg_loss = 0.4276\n",
            "t = 13, avg_loss = 0.5030\n",
            "t = 14, avg_loss = 0.3679\n",
            "t = 15, avg_loss = 0.3333\n",
            "t = 16, avg_loss = 0.2849\n",
            "t = 17, avg_loss = 0.3871\n",
            "t = 18, avg_loss = 0.3381\n",
            "t = 19, avg_loss = 0.3695\n",
            "t = 20, avg_loss = 0.3047\n",
            "t = 21, avg_loss = 0.2783\n",
            "t = 22, avg_loss = 0.4809\n",
            "t = 23, avg_loss = 0.3402\n",
            "t = 24, avg_loss = 0.4714\n",
            "t = 25, avg_loss = 0.5034\n",
            "Checking accuracy on test set\n",
            "Got 344 / 400 correct (86.00)\n",
            "acc = 0.860000\n",
            "Starting epoch 37 / 80\n",
            "t = 1, avg_loss = 0.2509\n",
            "t = 2, avg_loss = 0.4147\n",
            "t = 3, avg_loss = 0.3503\n",
            "t = 4, avg_loss = 0.3011\n",
            "t = 5, avg_loss = 0.4103\n",
            "t = 6, avg_loss = 0.4258\n",
            "t = 7, avg_loss = 0.3961\n",
            "t = 8, avg_loss = 0.3187\n",
            "t = 9, avg_loss = 0.4355\n",
            "t = 10, avg_loss = 0.3886\n",
            "t = 11, avg_loss = 0.3760\n",
            "t = 12, avg_loss = 0.4245\n",
            "t = 13, avg_loss = 0.3300\n",
            "t = 14, avg_loss = 0.4360\n",
            "t = 15, avg_loss = 0.4569\n",
            "t = 16, avg_loss = 0.3415\n",
            "t = 17, avg_loss = 0.3904\n",
            "t = 18, avg_loss = 0.3561\n",
            "t = 19, avg_loss = 0.2802\n",
            "t = 20, avg_loss = 0.4632\n",
            "t = 21, avg_loss = 0.2769\n",
            "t = 22, avg_loss = 0.4699\n",
            "t = 23, avg_loss = 0.4437\n",
            "t = 24, avg_loss = 0.3023\n",
            "t = 25, avg_loss = 0.3392\n",
            "Checking accuracy on test set\n",
            "Got 325 / 400 correct (81.25)\n",
            "acc = 0.812500\n",
            "Starting epoch 38 / 80\n",
            "t = 1, avg_loss = 0.4028\n",
            "t = 2, avg_loss = 0.3526\n",
            "t = 3, avg_loss = 0.5073\n",
            "t = 4, avg_loss = 0.3030\n",
            "t = 5, avg_loss = 0.3584\n",
            "t = 6, avg_loss = 0.3614\n",
            "t = 7, avg_loss = 0.2750\n",
            "t = 8, avg_loss = 0.3103\n",
            "t = 9, avg_loss = 0.2816\n",
            "t = 10, avg_loss = 0.5160\n",
            "t = 11, avg_loss = 0.3846\n",
            "t = 12, avg_loss = 0.3017\n",
            "t = 13, avg_loss = 0.5075\n",
            "t = 14, avg_loss = 0.5489\n",
            "t = 15, avg_loss = 0.3648\n",
            "t = 16, avg_loss = 0.4338\n",
            "t = 17, avg_loss = 0.3722\n",
            "t = 18, avg_loss = 0.4448\n",
            "t = 19, avg_loss = 0.3165\n",
            "t = 20, avg_loss = 0.3904\n",
            "t = 21, avg_loss = 0.5128\n",
            "t = 22, avg_loss = 0.3671\n",
            "t = 23, avg_loss = 0.4451\n",
            "t = 24, avg_loss = 0.3817\n",
            "t = 25, avg_loss = 0.4403\n",
            "Checking accuracy on test set\n",
            "Got 342 / 400 correct (85.50)\n",
            "acc = 0.855000\n",
            "Starting epoch 39 / 80\n",
            "t = 1, avg_loss = 0.3348\n",
            "t = 2, avg_loss = 0.2655\n",
            "t = 3, avg_loss = 0.3291\n",
            "t = 4, avg_loss = 0.3188\n",
            "t = 5, avg_loss = 0.3340\n",
            "t = 6, avg_loss = 0.3469\n",
            "t = 7, avg_loss = 0.4028\n",
            "t = 8, avg_loss = 0.3663\n",
            "t = 9, avg_loss = 0.3982\n",
            "t = 10, avg_loss = 0.3938\n",
            "t = 11, avg_loss = 0.2317\n",
            "t = 12, avg_loss = 0.3137\n",
            "t = 13, avg_loss = 0.3999\n",
            "t = 14, avg_loss = 0.3909\n",
            "t = 15, avg_loss = 0.3688\n",
            "t = 16, avg_loss = 0.4183\n",
            "t = 17, avg_loss = 0.3046\n",
            "t = 18, avg_loss = 0.3105\n",
            "t = 19, avg_loss = 0.4235\n",
            "t = 20, avg_loss = 0.3595\n",
            "t = 21, avg_loss = 0.3748\n",
            "t = 22, avg_loss = 0.4120\n",
            "t = 23, avg_loss = 0.3453\n",
            "t = 24, avg_loss = 0.3967\n",
            "t = 25, avg_loss = 0.3641\n",
            "Checking accuracy on test set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 40 / 80\n",
            "t = 1, avg_loss = 0.3618\n",
            "t = 2, avg_loss = 0.3959\n",
            "t = 3, avg_loss = 0.3733\n",
            "t = 4, avg_loss = 0.4338\n",
            "t = 5, avg_loss = 0.2827\n",
            "t = 6, avg_loss = 0.2840\n",
            "t = 7, avg_loss = 0.3363\n",
            "t = 8, avg_loss = 0.4176\n",
            "t = 9, avg_loss = 0.3355\n",
            "t = 10, avg_loss = 0.3246\n",
            "t = 11, avg_loss = 0.3764\n",
            "t = 12, avg_loss = 0.2049\n",
            "t = 13, avg_loss = 0.2761\n",
            "t = 14, avg_loss = 0.3436\n",
            "t = 15, avg_loss = 0.5618\n",
            "t = 16, avg_loss = 0.3598\n",
            "t = 17, avg_loss = 0.2626\n",
            "t = 18, avg_loss = 0.3259\n",
            "t = 19, avg_loss = 0.2900\n",
            "t = 20, avg_loss = 0.2920\n",
            "t = 21, avg_loss = 0.3069\n",
            "t = 22, avg_loss = 0.2877\n",
            "t = 23, avg_loss = 0.4088\n",
            "t = 24, avg_loss = 0.3693\n",
            "t = 25, avg_loss = 0.3857\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 41 / 80\n",
            "t = 1, avg_loss = 0.3471\n",
            "t = 2, avg_loss = 0.3567\n",
            "t = 3, avg_loss = 0.2316\n",
            "t = 4, avg_loss = 0.3119\n",
            "t = 5, avg_loss = 0.4081\n",
            "t = 6, avg_loss = 0.3944\n",
            "t = 7, avg_loss = 0.4323\n",
            "t = 8, avg_loss = 0.4501\n",
            "t = 9, avg_loss = 0.3628\n",
            "t = 10, avg_loss = 0.3037\n",
            "t = 11, avg_loss = 0.3726\n",
            "t = 12, avg_loss = 0.3168\n",
            "t = 13, avg_loss = 0.4550\n",
            "t = 14, avg_loss = 0.3931\n",
            "t = 15, avg_loss = 0.2524\n",
            "t = 16, avg_loss = 0.3222\n",
            "t = 17, avg_loss = 0.4564\n",
            "t = 18, avg_loss = 0.2446\n",
            "t = 19, avg_loss = 0.3456\n",
            "t = 20, avg_loss = 0.3880\n",
            "t = 21, avg_loss = 0.3510\n",
            "t = 22, avg_loss = 0.4859\n",
            "t = 23, avg_loss = 0.4055\n",
            "t = 24, avg_loss = 0.3666\n",
            "t = 25, avg_loss = 0.3293\n",
            "Checking accuracy on test set\n",
            "Got 346 / 400 correct (86.50)\n",
            "acc = 0.865000\n",
            "Starting epoch 42 / 80\n",
            "t = 1, avg_loss = 0.3361\n",
            "t = 2, avg_loss = 0.4074\n",
            "t = 3, avg_loss = 0.3741\n",
            "t = 4, avg_loss = 0.2731\n",
            "t = 5, avg_loss = 0.4478\n",
            "t = 6, avg_loss = 0.3580\n",
            "t = 7, avg_loss = 0.4132\n",
            "t = 8, avg_loss = 0.4036\n",
            "t = 9, avg_loss = 0.3147\n",
            "t = 10, avg_loss = 0.3106\n",
            "t = 11, avg_loss = 0.3622\n",
            "t = 12, avg_loss = 0.2594\n",
            "t = 13, avg_loss = 0.5247\n",
            "t = 14, avg_loss = 0.2194\n",
            "t = 15, avg_loss = 0.3254\n",
            "t = 16, avg_loss = 0.3571\n",
            "t = 17, avg_loss = 0.3158\n",
            "t = 18, avg_loss = 0.3936\n",
            "t = 19, avg_loss = 0.3328\n",
            "t = 20, avg_loss = 0.3015\n",
            "t = 21, avg_loss = 0.5068\n",
            "t = 22, avg_loss = 0.3691\n",
            "t = 23, avg_loss = 0.5057\n",
            "t = 24, avg_loss = 0.5213\n",
            "t = 25, avg_loss = 0.4355\n",
            "Checking accuracy on test set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 43 / 80\n",
            "t = 1, avg_loss = 0.3441\n",
            "t = 2, avg_loss = 0.2950\n",
            "t = 3, avg_loss = 0.3676\n",
            "t = 4, avg_loss = 0.4721\n",
            "t = 5, avg_loss = 0.4086\n",
            "t = 6, avg_loss = 0.3379\n",
            "t = 7, avg_loss = 0.3404\n",
            "t = 8, avg_loss = 0.4044\n",
            "t = 9, avg_loss = 0.3941\n",
            "t = 10, avg_loss = 0.4157\n",
            "t = 11, avg_loss = 0.3368\n",
            "t = 12, avg_loss = 0.4637\n",
            "t = 13, avg_loss = 0.4099\n",
            "t = 14, avg_loss = 0.3325\n",
            "t = 15, avg_loss = 0.4886\n",
            "t = 16, avg_loss = 0.4382\n",
            "t = 17, avg_loss = 0.3058\n",
            "t = 18, avg_loss = 0.4283\n",
            "t = 19, avg_loss = 0.3226\n",
            "t = 20, avg_loss = 0.4839\n",
            "t = 21, avg_loss = 0.3248\n",
            "t = 22, avg_loss = 0.3914\n",
            "t = 23, avg_loss = 0.3565\n",
            "t = 24, avg_loss = 0.2870\n",
            "t = 25, avg_loss = 0.3194\n",
            "Checking accuracy on test set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 44 / 80\n",
            "t = 1, avg_loss = 0.3408\n",
            "t = 2, avg_loss = 0.3123\n",
            "t = 3, avg_loss = 0.3813\n",
            "t = 4, avg_loss = 0.2884\n",
            "t = 5, avg_loss = 0.3433\n",
            "t = 6, avg_loss = 0.3057\n",
            "t = 7, avg_loss = 0.3634\n",
            "t = 8, avg_loss = 0.2886\n",
            "t = 9, avg_loss = 0.3737\n",
            "t = 10, avg_loss = 0.3787\n",
            "t = 11, avg_loss = 0.2656\n",
            "t = 12, avg_loss = 0.4035\n",
            "t = 13, avg_loss = 0.3306\n",
            "t = 14, avg_loss = 0.2552\n",
            "t = 15, avg_loss = 0.3551\n",
            "t = 16, avg_loss = 0.4502\n",
            "t = 17, avg_loss = 0.3355\n",
            "t = 18, avg_loss = 0.3827\n",
            "t = 19, avg_loss = 0.4534\n",
            "t = 20, avg_loss = 0.5171\n",
            "t = 21, avg_loss = 0.3788\n",
            "t = 22, avg_loss = 0.3419\n",
            "t = 23, avg_loss = 0.3553\n",
            "t = 24, avg_loss = 0.2977\n",
            "t = 25, avg_loss = 0.3758\n",
            "Checking accuracy on test set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 45 / 80\n",
            "t = 1, avg_loss = 0.3049\n",
            "t = 2, avg_loss = 0.5045\n",
            "t = 3, avg_loss = 0.3868\n",
            "t = 4, avg_loss = 0.4386\n",
            "t = 5, avg_loss = 0.3856\n",
            "t = 6, avg_loss = 0.2978\n",
            "t = 7, avg_loss = 0.5401\n",
            "t = 8, avg_loss = 0.3720\n",
            "t = 9, avg_loss = 0.2899\n",
            "t = 10, avg_loss = 0.4549\n",
            "t = 11, avg_loss = 0.3672\n",
            "t = 12, avg_loss = 0.5165\n",
            "t = 13, avg_loss = 0.4002\n",
            "t = 14, avg_loss = 0.3942\n",
            "t = 15, avg_loss = 0.3488\n",
            "t = 16, avg_loss = 0.4077\n",
            "t = 17, avg_loss = 0.3465\n",
            "t = 18, avg_loss = 0.2564\n",
            "t = 19, avg_loss = 0.3581\n",
            "t = 20, avg_loss = 0.3491\n",
            "t = 21, avg_loss = 0.3497\n",
            "t = 22, avg_loss = 0.3891\n",
            "t = 23, avg_loss = 0.5098\n",
            "t = 24, avg_loss = 0.3727\n",
            "t = 25, avg_loss = 0.2846\n",
            "Checking accuracy on test set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 46 / 80\n",
            "t = 1, avg_loss = 0.3284\n",
            "t = 2, avg_loss = 0.4468\n",
            "t = 3, avg_loss = 0.2880\n",
            "t = 4, avg_loss = 0.3375\n",
            "t = 5, avg_loss = 0.3653\n",
            "t = 6, avg_loss = 0.3531\n",
            "t = 7, avg_loss = 0.2941\n",
            "t = 8, avg_loss = 0.2621\n",
            "t = 9, avg_loss = 0.3139\n",
            "t = 10, avg_loss = 0.3540\n",
            "t = 11, avg_loss = 0.2771\n",
            "t = 12, avg_loss = 0.4894\n",
            "t = 13, avg_loss = 0.3878\n",
            "t = 14, avg_loss = 0.4095\n",
            "t = 15, avg_loss = 0.3610\n",
            "t = 16, avg_loss = 0.4071\n",
            "t = 17, avg_loss = 0.4058\n",
            "t = 18, avg_loss = 0.3164\n",
            "t = 19, avg_loss = 0.5733\n",
            "t = 20, avg_loss = 0.3449\n",
            "t = 21, avg_loss = 0.3024\n",
            "t = 22, avg_loss = 0.3573\n",
            "t = 23, avg_loss = 0.4141\n",
            "t = 24, avg_loss = 0.3343\n",
            "t = 25, avg_loss = 0.4202\n",
            "Checking accuracy on test set\n",
            "Got 346 / 400 correct (86.50)\n",
            "acc = 0.865000\n",
            "Starting epoch 47 / 80\n",
            "t = 1, avg_loss = 0.5038\n",
            "t = 2, avg_loss = 0.2337\n",
            "t = 3, avg_loss = 0.4183\n",
            "t = 4, avg_loss = 0.4029\n",
            "t = 5, avg_loss = 0.3494\n",
            "t = 6, avg_loss = 0.2377\n",
            "t = 7, avg_loss = 0.3255\n",
            "t = 8, avg_loss = 0.3736\n",
            "t = 9, avg_loss = 0.4739\n",
            "t = 10, avg_loss = 0.3192\n",
            "t = 11, avg_loss = 0.4503\n",
            "t = 12, avg_loss = 0.4091\n",
            "t = 13, avg_loss = 0.2807\n",
            "t = 14, avg_loss = 0.2975\n",
            "t = 15, avg_loss = 0.2986\n",
            "t = 16, avg_loss = 0.4331\n",
            "t = 17, avg_loss = 0.4382\n",
            "t = 18, avg_loss = 0.2930\n",
            "t = 19, avg_loss = 0.2702\n",
            "t = 20, avg_loss = 0.4060\n",
            "t = 21, avg_loss = 0.2722\n",
            "t = 22, avg_loss = 0.4472\n",
            "t = 23, avg_loss = 0.4187\n",
            "t = 24, avg_loss = 0.3439\n",
            "t = 25, avg_loss = 0.4724\n",
            "Checking accuracy on test set\n",
            "Got 345 / 400 correct (86.25)\n",
            "acc = 0.862500\n",
            "Starting epoch 48 / 80\n",
            "t = 1, avg_loss = 0.3265\n",
            "t = 2, avg_loss = 0.4059\n",
            "t = 3, avg_loss = 0.2273\n",
            "t = 4, avg_loss = 0.4026\n",
            "t = 5, avg_loss = 0.3280\n",
            "t = 6, avg_loss = 0.2881\n",
            "t = 7, avg_loss = 0.3864\n",
            "t = 8, avg_loss = 0.3742\n",
            "t = 9, avg_loss = 0.3317\n",
            "t = 10, avg_loss = 0.3590\n",
            "t = 11, avg_loss = 0.4479\n",
            "t = 12, avg_loss = 0.6120\n",
            "t = 13, avg_loss = 0.4226\n",
            "t = 14, avg_loss = 0.4076\n",
            "t = 15, avg_loss = 0.4766\n",
            "t = 16, avg_loss = 0.4804\n",
            "t = 17, avg_loss = 0.3720\n",
            "t = 18, avg_loss = 0.3798\n",
            "t = 19, avg_loss = 0.3491\n",
            "t = 20, avg_loss = 0.3976\n",
            "t = 21, avg_loss = 0.4068\n",
            "t = 22, avg_loss = 0.3108\n",
            "t = 23, avg_loss = 0.2912\n",
            "t = 24, avg_loss = 0.4377\n",
            "t = 25, avg_loss = 0.2929\n",
            "Checking accuracy on test set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 49 / 80\n",
            "t = 1, avg_loss = 0.3562\n",
            "t = 2, avg_loss = 0.3701\n",
            "t = 3, avg_loss = 0.2887\n",
            "t = 4, avg_loss = 0.3337\n",
            "t = 5, avg_loss = 0.2924\n",
            "t = 6, avg_loss = 0.4234\n",
            "t = 7, avg_loss = 0.4070\n",
            "t = 8, avg_loss = 0.3519\n",
            "t = 9, avg_loss = 0.4060\n",
            "t = 10, avg_loss = 0.3415\n",
            "t = 11, avg_loss = 0.2651\n",
            "t = 12, avg_loss = 0.3251\n",
            "t = 13, avg_loss = 0.3727\n",
            "t = 14, avg_loss = 0.2568\n",
            "t = 15, avg_loss = 0.4778\n",
            "t = 16, avg_loss = 0.2424\n",
            "t = 17, avg_loss = 0.2820\n",
            "t = 18, avg_loss = 0.3528\n",
            "t = 19, avg_loss = 0.4456\n",
            "t = 20, avg_loss = 0.3475\n",
            "t = 21, avg_loss = 0.3816\n",
            "t = 22, avg_loss = 0.4128\n",
            "t = 23, avg_loss = 0.3204\n",
            "t = 24, avg_loss = 0.3995\n",
            "t = 25, avg_loss = 0.3809\n",
            "Checking accuracy on test set\n",
            "Got 359 / 400 correct (89.75)\n",
            "acc = 0.897500\n",
            "Starting epoch 50 / 80\n",
            "t = 1, avg_loss = 0.4039\n",
            "t = 2, avg_loss = 0.2653\n",
            "t = 3, avg_loss = 0.4386\n",
            "t = 4, avg_loss = 0.3080\n",
            "t = 5, avg_loss = 0.3636\n",
            "t = 6, avg_loss = 0.3871\n",
            "t = 7, avg_loss = 0.3694\n",
            "t = 8, avg_loss = 0.4475\n",
            "t = 9, avg_loss = 0.4130\n",
            "t = 10, avg_loss = 0.3027\n",
            "t = 11, avg_loss = 0.4300\n",
            "t = 12, avg_loss = 0.3456\n",
            "t = 13, avg_loss = 0.3987\n",
            "t = 14, avg_loss = 0.4120\n",
            "t = 15, avg_loss = 0.4085\n",
            "t = 16, avg_loss = 0.2724\n",
            "t = 17, avg_loss = 0.3339\n",
            "t = 18, avg_loss = 0.5179\n",
            "t = 19, avg_loss = 0.4541\n",
            "t = 20, avg_loss = 0.2788\n",
            "t = 21, avg_loss = 0.3336\n",
            "t = 22, avg_loss = 0.2140\n",
            "t = 23, avg_loss = 0.3099\n",
            "t = 24, avg_loss = 0.3465\n",
            "t = 25, avg_loss = 0.4410\n",
            "Checking accuracy on test set\n",
            "Got 345 / 400 correct (86.25)\n",
            "acc = 0.862500\n",
            "Starting epoch 51 / 80\n",
            "t = 1, avg_loss = 0.2516\n",
            "t = 2, avg_loss = 0.3189\n",
            "t = 3, avg_loss = 0.3062\n",
            "t = 4, avg_loss = 0.5193\n",
            "t = 5, avg_loss = 0.3511\n",
            "t = 6, avg_loss = 0.5195\n",
            "t = 7, avg_loss = 0.3468\n",
            "t = 8, avg_loss = 0.3465\n",
            "t = 9, avg_loss = 0.4499\n",
            "t = 10, avg_loss = 0.4111\n",
            "t = 11, avg_loss = 0.3817\n",
            "t = 12, avg_loss = 0.3937\n",
            "t = 13, avg_loss = 0.3471\n",
            "t = 14, avg_loss = 0.3458\n",
            "t = 15, avg_loss = 0.3537\n",
            "t = 16, avg_loss = 0.2807\n",
            "t = 17, avg_loss = 0.3352\n",
            "t = 18, avg_loss = 0.4083\n",
            "t = 19, avg_loss = 0.4718\n",
            "t = 20, avg_loss = 0.2922\n",
            "t = 21, avg_loss = 0.4921\n",
            "t = 22, avg_loss = 0.3466\n",
            "t = 23, avg_loss = 0.3894\n",
            "t = 24, avg_loss = 0.2708\n",
            "t = 25, avg_loss = 0.4339\n",
            "Checking accuracy on test set\n",
            "Got 345 / 400 correct (86.25)\n",
            "acc = 0.862500\n",
            "Starting epoch 52 / 80\n",
            "t = 1, avg_loss = 0.3489\n",
            "t = 2, avg_loss = 0.3253\n",
            "t = 3, avg_loss = 0.3473\n",
            "t = 4, avg_loss = 0.3425\n",
            "t = 5, avg_loss = 0.3706\n",
            "t = 6, avg_loss = 0.2965\n",
            "t = 7, avg_loss = 0.3937\n",
            "t = 8, avg_loss = 0.3068\n",
            "t = 9, avg_loss = 0.3222\n",
            "t = 10, avg_loss = 0.3619\n",
            "t = 11, avg_loss = 0.2816\n",
            "t = 12, avg_loss = 0.2731\n",
            "t = 13, avg_loss = 0.4054\n",
            "t = 14, avg_loss = 0.4130\n",
            "t = 15, avg_loss = 0.3176\n",
            "t = 16, avg_loss = 0.4265\n",
            "t = 17, avg_loss = 0.3337\n",
            "t = 18, avg_loss = 0.3563\n",
            "t = 19, avg_loss = 0.2894\n",
            "t = 20, avg_loss = 0.3077\n",
            "t = 21, avg_loss = 0.3377\n",
            "t = 22, avg_loss = 0.3205\n",
            "t = 23, avg_loss = 0.3429\n",
            "t = 24, avg_loss = 0.3297\n",
            "t = 25, avg_loss = 0.3843\n",
            "Checking accuracy on test set\n",
            "Got 360 / 400 correct (90.00)\n",
            "acc = 0.900000\n",
            "Starting epoch 53 / 80\n",
            "t = 1, avg_loss = 0.4344\n",
            "t = 2, avg_loss = 0.3851\n",
            "t = 3, avg_loss = 0.2616\n",
            "t = 4, avg_loss = 0.2834\n",
            "t = 5, avg_loss = 0.3311\n",
            "t = 6, avg_loss = 0.3050\n",
            "t = 7, avg_loss = 0.3084\n",
            "t = 8, avg_loss = 0.4061\n",
            "t = 9, avg_loss = 0.3928\n",
            "t = 10, avg_loss = 0.3210\n",
            "t = 11, avg_loss = 0.3138\n",
            "t = 12, avg_loss = 0.2793\n",
            "t = 13, avg_loss = 0.3692\n",
            "t = 14, avg_loss = 0.2911\n",
            "t = 15, avg_loss = 0.2904\n",
            "t = 16, avg_loss = 0.4193\n",
            "t = 17, avg_loss = 0.3941\n",
            "t = 18, avg_loss = 0.3091\n",
            "t = 19, avg_loss = 0.2703\n",
            "t = 20, avg_loss = 0.4353\n",
            "t = 21, avg_loss = 0.3624\n",
            "t = 22, avg_loss = 0.2714\n",
            "t = 23, avg_loss = 0.3623\n",
            "t = 24, avg_loss = 0.4709\n",
            "t = 25, avg_loss = 0.3717\n",
            "Checking accuracy on test set\n",
            "Got 362 / 400 correct (90.50)\n",
            "acc = 0.905000\n",
            "Starting epoch 54 / 80\n",
            "t = 1, avg_loss = 0.3489\n",
            "t = 2, avg_loss = 0.3706\n",
            "t = 3, avg_loss = 0.3840\n",
            "t = 4, avg_loss = 0.3026\n",
            "t = 5, avg_loss = 0.4141\n",
            "t = 6, avg_loss = 0.2902\n",
            "t = 7, avg_loss = 0.4027\n",
            "t = 8, avg_loss = 0.2748\n",
            "t = 9, avg_loss = 0.2933\n",
            "t = 10, avg_loss = 0.3801\n",
            "t = 11, avg_loss = 0.2902\n",
            "t = 12, avg_loss = 0.4639\n",
            "t = 13, avg_loss = 0.2298\n",
            "t = 14, avg_loss = 0.3087\n",
            "t = 15, avg_loss = 0.3962\n",
            "t = 16, avg_loss = 0.2964\n",
            "t = 17, avg_loss = 0.4180\n",
            "t = 18, avg_loss = 0.3138\n",
            "t = 19, avg_loss = 0.3810\n",
            "t = 20, avg_loss = 0.4150\n",
            "t = 21, avg_loss = 0.3375\n",
            "t = 22, avg_loss = 0.5394\n",
            "t = 23, avg_loss = 0.3208\n",
            "t = 24, avg_loss = 0.3831\n",
            "t = 25, avg_loss = 0.2719\n",
            "Checking accuracy on test set\n",
            "Got 341 / 400 correct (85.25)\n",
            "acc = 0.852500\n",
            "Starting epoch 55 / 80\n",
            "t = 1, avg_loss = 0.4323\n",
            "t = 2, avg_loss = 0.2758\n",
            "t = 3, avg_loss = 0.3922\n",
            "t = 4, avg_loss = 0.2919\n",
            "t = 5, avg_loss = 0.3513\n",
            "t = 6, avg_loss = 0.2678\n",
            "t = 7, avg_loss = 0.2909\n",
            "t = 8, avg_loss = 0.2897\n",
            "t = 9, avg_loss = 0.4296\n",
            "t = 10, avg_loss = 0.3782\n",
            "t = 11, avg_loss = 0.3618\n",
            "t = 12, avg_loss = 0.3686\n",
            "t = 13, avg_loss = 0.3227\n",
            "t = 14, avg_loss = 0.3853\n",
            "t = 15, avg_loss = 0.5166\n",
            "t = 16, avg_loss = 0.5834\n",
            "t = 17, avg_loss = 0.4492\n",
            "t = 18, avg_loss = 0.4017\n",
            "t = 19, avg_loss = 0.5263\n",
            "t = 20, avg_loss = 0.4044\n",
            "t = 21, avg_loss = 0.3096\n",
            "t = 22, avg_loss = 0.3600\n",
            "t = 23, avg_loss = 0.5191\n",
            "t = 24, avg_loss = 0.5179\n",
            "t = 25, avg_loss = 0.4480\n",
            "Checking accuracy on test set\n",
            "Got 337 / 400 correct (84.25)\n",
            "acc = 0.842500\n",
            "Starting epoch 56 / 80\n",
            "t = 1, avg_loss = 0.4610\n",
            "t = 2, avg_loss = 0.3652\n",
            "t = 3, avg_loss = 0.3415\n",
            "t = 4, avg_loss = 0.2933\n",
            "t = 5, avg_loss = 0.3298\n",
            "t = 6, avg_loss = 0.3219\n",
            "t = 7, avg_loss = 0.4054\n",
            "t = 8, avg_loss = 0.3562\n",
            "t = 9, avg_loss = 0.3652\n",
            "t = 10, avg_loss = 0.3756\n",
            "t = 11, avg_loss = 0.3360\n",
            "t = 12, avg_loss = 0.3567\n",
            "t = 13, avg_loss = 0.3609\n",
            "t = 14, avg_loss = 0.3493\n",
            "t = 15, avg_loss = 0.2818\n",
            "t = 16, avg_loss = 0.3941\n",
            "t = 17, avg_loss = 0.3284\n",
            "t = 18, avg_loss = 0.3291\n",
            "t = 19, avg_loss = 0.4320\n",
            "t = 20, avg_loss = 0.2989\n",
            "t = 21, avg_loss = 0.4882\n",
            "t = 22, avg_loss = 0.4123\n",
            "t = 23, avg_loss = 0.3692\n",
            "t = 24, avg_loss = 0.3566\n",
            "t = 25, avg_loss = 0.4902\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 57 / 80\n",
            "t = 1, avg_loss = 0.3001\n",
            "t = 2, avg_loss = 0.5496\n",
            "t = 3, avg_loss = 0.4328\n",
            "t = 4, avg_loss = 0.2513\n",
            "t = 5, avg_loss = 0.2761\n",
            "t = 6, avg_loss = 0.3818\n",
            "t = 7, avg_loss = 0.4571\n",
            "t = 8, avg_loss = 0.3752\n",
            "t = 9, avg_loss = 0.3034\n",
            "t = 10, avg_loss = 0.3924\n",
            "t = 11, avg_loss = 0.4363\n",
            "t = 12, avg_loss = 0.3537\n",
            "t = 13, avg_loss = 0.3358\n",
            "t = 14, avg_loss = 0.3244\n",
            "t = 15, avg_loss = 0.3360\n",
            "t = 16, avg_loss = 0.2973\n",
            "t = 17, avg_loss = 0.2737\n",
            "t = 18, avg_loss = 0.3366\n",
            "t = 19, avg_loss = 0.3442\n",
            "t = 20, avg_loss = 0.4599\n",
            "t = 21, avg_loss = 0.4051\n",
            "t = 22, avg_loss = 0.3817\n",
            "t = 23, avg_loss = 0.2879\n",
            "t = 24, avg_loss = 0.5248\n",
            "t = 25, avg_loss = 0.2821\n",
            "Checking accuracy on test set\n",
            "Got 341 / 400 correct (85.25)\n",
            "acc = 0.852500\n",
            "Starting epoch 58 / 80\n",
            "t = 1, avg_loss = 0.3729\n",
            "t = 2, avg_loss = 0.4117\n",
            "t = 3, avg_loss = 0.3611\n",
            "t = 4, avg_loss = 0.4361\n",
            "t = 5, avg_loss = 0.2165\n",
            "t = 6, avg_loss = 0.5111\n",
            "t = 7, avg_loss = 0.2513\n",
            "t = 8, avg_loss = 0.4486\n",
            "t = 9, avg_loss = 0.3374\n",
            "t = 10, avg_loss = 0.3644\n",
            "t = 11, avg_loss = 0.3021\n",
            "t = 12, avg_loss = 0.3150\n",
            "t = 13, avg_loss = 0.4470\n",
            "t = 14, avg_loss = 0.3580\n",
            "t = 15, avg_loss = 0.3884\n",
            "t = 16, avg_loss = 0.4252\n",
            "t = 17, avg_loss = 0.2846\n",
            "t = 18, avg_loss = 0.2555\n",
            "t = 19, avg_loss = 0.3201\n",
            "t = 20, avg_loss = 0.2430\n",
            "t = 21, avg_loss = 0.3027\n",
            "t = 22, avg_loss = 0.3184\n",
            "t = 23, avg_loss = 0.3914\n",
            "t = 24, avg_loss = 0.3695\n",
            "t = 25, avg_loss = 0.3857\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 59 / 80\n",
            "t = 1, avg_loss = 0.4832\n",
            "t = 2, avg_loss = 0.2866\n",
            "t = 3, avg_loss = 0.2591\n",
            "t = 4, avg_loss = 0.4963\n",
            "t = 5, avg_loss = 0.5522\n",
            "t = 6, avg_loss = 0.3471\n",
            "t = 7, avg_loss = 0.3532\n",
            "t = 8, avg_loss = 0.2815\n",
            "t = 9, avg_loss = 0.3032\n",
            "t = 10, avg_loss = 0.3394\n",
            "t = 11, avg_loss = 0.3576\n",
            "t = 12, avg_loss = 0.3258\n",
            "t = 13, avg_loss = 0.3644\n",
            "t = 14, avg_loss = 0.4846\n",
            "t = 15, avg_loss = 0.2914\n",
            "t = 16, avg_loss = 0.4197\n",
            "t = 17, avg_loss = 0.3071\n",
            "t = 18, avg_loss = 0.3644\n",
            "t = 19, avg_loss = 0.3363\n",
            "t = 20, avg_loss = 0.3929\n",
            "t = 21, avg_loss = 0.4462\n",
            "t = 22, avg_loss = 0.4120\n",
            "t = 23, avg_loss = 0.4006\n",
            "t = 24, avg_loss = 0.3677\n",
            "t = 25, avg_loss = 0.3957\n",
            "Checking accuracy on test set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 60 / 80\n",
            "t = 1, avg_loss = 0.3277\n",
            "t = 2, avg_loss = 0.3448\n",
            "t = 3, avg_loss = 0.5434\n",
            "t = 4, avg_loss = 0.3355\n",
            "t = 5, avg_loss = 0.4014\n",
            "t = 6, avg_loss = 0.3323\n",
            "t = 7, avg_loss = 0.3648\n",
            "t = 8, avg_loss = 0.3494\n",
            "t = 9, avg_loss = 0.3269\n",
            "t = 10, avg_loss = 0.3392\n",
            "t = 11, avg_loss = 0.3890\n",
            "t = 12, avg_loss = 0.3068\n",
            "t = 13, avg_loss = 0.3763\n",
            "t = 14, avg_loss = 0.3143\n",
            "t = 15, avg_loss = 0.3700\n",
            "t = 16, avg_loss = 0.4379\n",
            "t = 17, avg_loss = 0.5381\n",
            "t = 18, avg_loss = 0.3670\n",
            "t = 19, avg_loss = 0.3030\n",
            "t = 20, avg_loss = 0.3621\n",
            "t = 21, avg_loss = 0.5198\n",
            "t = 22, avg_loss = 0.4393\n",
            "t = 23, avg_loss = 0.3271\n",
            "t = 24, avg_loss = 0.2946\n",
            "t = 25, avg_loss = 0.4139\n",
            "Checking accuracy on test set\n",
            "Got 345 / 400 correct (86.25)\n",
            "acc = 0.862500\n",
            "Starting epoch 61 / 80\n",
            "t = 1, avg_loss = 0.5712\n",
            "t = 2, avg_loss = 0.3098\n",
            "t = 3, avg_loss = 0.3319\n",
            "t = 4, avg_loss = 0.4668\n",
            "t = 5, avg_loss = 0.2708\n",
            "t = 6, avg_loss = 0.4389\n",
            "t = 7, avg_loss = 0.3494\n",
            "t = 8, avg_loss = 0.3745\n",
            "t = 9, avg_loss = 0.3291\n",
            "t = 10, avg_loss = 0.4222\n",
            "t = 11, avg_loss = 0.5121\n",
            "t = 12, avg_loss = 0.2897\n",
            "t = 13, avg_loss = 0.3291\n",
            "t = 14, avg_loss = 0.3909\n",
            "t = 15, avg_loss = 0.4015\n",
            "t = 16, avg_loss = 0.3659\n",
            "t = 17, avg_loss = 0.4021\n",
            "t = 18, avg_loss = 0.3534\n",
            "t = 19, avg_loss = 0.2810\n",
            "t = 20, avg_loss = 0.3434\n",
            "t = 21, avg_loss = 0.3576\n",
            "t = 22, avg_loss = 0.4139\n",
            "t = 23, avg_loss = 0.2603\n",
            "t = 24, avg_loss = 0.3394\n",
            "t = 25, avg_loss = 0.4741\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 62 / 80\n",
            "t = 1, avg_loss = 0.3310\n",
            "t = 2, avg_loss = 0.4996\n",
            "t = 3, avg_loss = 0.2902\n",
            "t = 4, avg_loss = 0.2724\n",
            "t = 5, avg_loss = 0.3995\n",
            "t = 6, avg_loss = 0.3777\n",
            "t = 7, avg_loss = 0.3064\n",
            "t = 8, avg_loss = 0.2607\n",
            "t = 9, avg_loss = 0.3676\n",
            "t = 10, avg_loss = 0.3538\n",
            "t = 11, avg_loss = 0.4549\n",
            "t = 12, avg_loss = 0.3733\n",
            "t = 13, avg_loss = 0.4183\n",
            "t = 14, avg_loss = 0.3571\n",
            "t = 15, avg_loss = 0.2904\n",
            "t = 16, avg_loss = 0.3334\n",
            "t = 17, avg_loss = 0.3713\n",
            "t = 18, avg_loss = 0.3444\n",
            "t = 19, avg_loss = 0.2551\n",
            "t = 20, avg_loss = 0.3602\n",
            "t = 21, avg_loss = 0.4371\n",
            "t = 22, avg_loss = 0.3066\n",
            "t = 23, avg_loss = 0.3630\n",
            "t = 24, avg_loss = 0.2615\n",
            "t = 25, avg_loss = 0.3213\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 63 / 80\n",
            "t = 1, avg_loss = 0.3340\n",
            "t = 2, avg_loss = 0.2500\n",
            "t = 3, avg_loss = 0.3286\n",
            "t = 4, avg_loss = 0.3083\n",
            "t = 5, avg_loss = 0.2777\n",
            "t = 6, avg_loss = 0.4729\n",
            "t = 7, avg_loss = 0.3731\n",
            "t = 8, avg_loss = 0.4966\n",
            "t = 9, avg_loss = 0.2999\n",
            "t = 10, avg_loss = 0.3491\n",
            "t = 11, avg_loss = 0.3427\n",
            "t = 12, avg_loss = 0.3720\n",
            "t = 13, avg_loss = 0.4483\n",
            "t = 14, avg_loss = 0.4686\n",
            "t = 15, avg_loss = 0.3269\n",
            "t = 16, avg_loss = 0.3649\n",
            "t = 17, avg_loss = 0.4714\n",
            "t = 18, avg_loss = 0.3368\n",
            "t = 19, avg_loss = 0.2874\n",
            "t = 20, avg_loss = 0.4539\n",
            "t = 21, avg_loss = 0.3301\n",
            "t = 22, avg_loss = 0.4070\n",
            "t = 23, avg_loss = 0.4023\n",
            "t = 24, avg_loss = 0.3053\n",
            "t = 25, avg_loss = 0.2864\n",
            "Checking accuracy on test set\n",
            "Got 358 / 400 correct (89.50)\n",
            "acc = 0.895000\n",
            "Starting epoch 64 / 80\n",
            "t = 1, avg_loss = 0.3430\n",
            "t = 2, avg_loss = 0.3464\n",
            "t = 3, avg_loss = 0.3065\n",
            "t = 4, avg_loss = 0.3938\n",
            "t = 5, avg_loss = 0.3448\n",
            "t = 6, avg_loss = 0.2846\n",
            "t = 7, avg_loss = 0.4054\n",
            "t = 8, avg_loss = 0.4018\n",
            "t = 9, avg_loss = 0.3485\n",
            "t = 10, avg_loss = 0.3139\n",
            "t = 11, avg_loss = 0.3956\n",
            "t = 12, avg_loss = 0.3561\n",
            "t = 13, avg_loss = 0.2928\n",
            "t = 14, avg_loss = 0.3363\n",
            "t = 15, avg_loss = 0.4044\n",
            "t = 16, avg_loss = 0.2913\n",
            "t = 17, avg_loss = 0.3994\n",
            "t = 18, avg_loss = 0.2937\n",
            "t = 19, avg_loss = 0.2796\n",
            "t = 20, avg_loss = 0.3363\n",
            "t = 21, avg_loss = 0.3338\n",
            "t = 22, avg_loss = 0.3966\n",
            "t = 23, avg_loss = 0.3881\n",
            "t = 24, avg_loss = 0.2624\n",
            "t = 25, avg_loss = 0.3892\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 65 / 80\n",
            "t = 1, avg_loss = 0.2946\n",
            "t = 2, avg_loss = 0.4120\n",
            "t = 3, avg_loss = 0.3061\n",
            "t = 4, avg_loss = 0.3660\n",
            "t = 5, avg_loss = 0.3587\n",
            "t = 6, avg_loss = 0.2732\n",
            "t = 7, avg_loss = 0.4028\n",
            "t = 8, avg_loss = 0.3994\n",
            "t = 9, avg_loss = 0.2891\n",
            "t = 10, avg_loss = 0.2718\n",
            "t = 11, avg_loss = 0.3514\n",
            "t = 12, avg_loss = 0.5012\n",
            "t = 13, avg_loss = 0.4030\n",
            "t = 14, avg_loss = 0.2411\n",
            "t = 15, avg_loss = 0.4364\n",
            "t = 16, avg_loss = 0.2233\n",
            "t = 17, avg_loss = 0.3632\n",
            "t = 18, avg_loss = 0.4435\n",
            "t = 19, avg_loss = 0.3771\n",
            "t = 20, avg_loss = 0.4173\n",
            "t = 21, avg_loss = 0.2401\n",
            "t = 22, avg_loss = 0.3569\n",
            "t = 23, avg_loss = 0.2658\n",
            "t = 24, avg_loss = 0.4061\n",
            "t = 25, avg_loss = 0.3286\n",
            "Checking accuracy on test set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 66 / 80\n",
            "t = 1, avg_loss = 0.3760\n",
            "t = 2, avg_loss = 0.4002\n",
            "t = 3, avg_loss = 0.3815\n",
            "t = 4, avg_loss = 0.3120\n",
            "t = 5, avg_loss = 0.2539\n",
            "t = 6, avg_loss = 0.2952\n",
            "t = 7, avg_loss = 0.2442\n",
            "t = 8, avg_loss = 0.4103\n",
            "t = 9, avg_loss = 0.2987\n",
            "t = 10, avg_loss = 0.2954\n",
            "t = 12, avg_loss = 0.3871\n",
            "t = 13, avg_loss = 0.3393\n",
            "t = 14, avg_loss = 0.2913\n",
            "t = 15, avg_loss = 0.3620\n",
            "t = 16, avg_loss = 0.2591\n",
            "t = 17, avg_loss = 0.2798\n",
            "t = 18, avg_loss = 0.2682\n",
            "t = 19, avg_loss = 0.4140\n",
            "t = 20, avg_loss = 0.3223\n",
            "t = 21, avg_loss = 0.3873\n",
            "t = 22, avg_loss = 0.4195\n",
            "t = 23, avg_loss = 0.2911\n",
            "t = 24, avg_loss = 0.4274\n",
            "t = 25, avg_loss = 0.2882\n",
            "Checking accuracy on test set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 67 / 80\n",
            "t = 1, avg_loss = 0.2302\n",
            "t = 2, avg_loss = 0.2885\n",
            "t = 3, avg_loss = 0.4953\n",
            "t = 4, avg_loss = 0.3313\n",
            "t = 5, avg_loss = 0.4357\n",
            "t = 6, avg_loss = 0.3546\n",
            "t = 7, avg_loss = 0.3369\n",
            "t = 8, avg_loss = 0.3062\n",
            "t = 9, avg_loss = 0.3216\n",
            "t = 10, avg_loss = 0.2653\n",
            "t = 11, avg_loss = 0.4209\n",
            "t = 12, avg_loss = 0.2419\n",
            "t = 13, avg_loss = 0.3758\n",
            "t = 14, avg_loss = 0.3843\n",
            "t = 15, avg_loss = 0.3248\n",
            "t = 16, avg_loss = 0.2939\n",
            "t = 17, avg_loss = 0.3827\n",
            "t = 18, avg_loss = 0.2880\n",
            "t = 19, avg_loss = 0.2925\n",
            "t = 20, avg_loss = 0.2827\n",
            "t = 21, avg_loss = 0.3114\n",
            "t = 22, avg_loss = 0.3505\n",
            "t = 23, avg_loss = 0.4960\n",
            "t = 24, avg_loss = 0.4505\n",
            "t = 25, avg_loss = 0.3373\n",
            "Checking accuracy on test set\n",
            "Got 363 / 400 correct (90.75)\n",
            "acc = 0.907500\n",
            "Starting epoch 68 / 80\n",
            "t = 1, avg_loss = 0.3362\n",
            "t = 2, avg_loss = 0.3317\n",
            "t = 3, avg_loss = 0.4037\n",
            "t = 4, avg_loss = 0.2592\n",
            "t = 5, avg_loss = 0.3264\n",
            "t = 6, avg_loss = 0.2968\n",
            "t = 7, avg_loss = 0.6000\n",
            "t = 8, avg_loss = 0.4291\n",
            "t = 9, avg_loss = 0.2603\n",
            "t = 10, avg_loss = 0.4509\n",
            "t = 11, avg_loss = 0.3824\n",
            "t = 12, avg_loss = 0.3347\n",
            "t = 13, avg_loss = 0.3142\n",
            "t = 14, avg_loss = 0.4616\n",
            "t = 15, avg_loss = 0.4297\n",
            "t = 16, avg_loss = 0.3683\n",
            "t = 17, avg_loss = 0.3900\n",
            "t = 18, avg_loss = 0.3091\n",
            "t = 19, avg_loss = 0.3950\n",
            "t = 20, avg_loss = 0.4732\n",
            "t = 21, avg_loss = 0.4013\n",
            "t = 22, avg_loss = 0.4402\n",
            "t = 23, avg_loss = 0.3023\n",
            "t = 24, avg_loss = 0.4176\n",
            "t = 25, avg_loss = 0.3595\n",
            "Checking accuracy on test set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 69 / 80\n",
            "t = 1, avg_loss = 0.3890\n",
            "t = 2, avg_loss = 0.3125\n",
            "t = 3, avg_loss = 0.3723\n",
            "t = 4, avg_loss = 0.3130\n",
            "t = 5, avg_loss = 0.3416\n",
            "t = 6, avg_loss = 0.3315\n",
            "t = 7, avg_loss = 0.3531\n",
            "t = 8, avg_loss = 0.3929\n",
            "t = 9, avg_loss = 0.3809\n",
            "t = 10, avg_loss = 0.4304\n",
            "t = 11, avg_loss = 0.2607\n",
            "t = 12, avg_loss = 0.3435\n",
            "t = 13, avg_loss = 0.2424\n",
            "t = 14, avg_loss = 0.3903\n",
            "t = 15, avg_loss = 0.3738\n",
            "t = 16, avg_loss = 0.2325\n",
            "t = 17, avg_loss = 0.4327\n",
            "t = 18, avg_loss = 0.2714\n",
            "t = 19, avg_loss = 0.3547\n",
            "t = 20, avg_loss = 0.3172\n",
            "t = 21, avg_loss = 0.2838\n",
            "t = 22, avg_loss = 0.3494\n",
            "t = 23, avg_loss = 0.3258\n",
            "t = 24, avg_loss = 0.4578\n",
            "t = 25, avg_loss = 0.4850\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 70 / 80\n",
            "t = 1, avg_loss = 0.2720\n",
            "t = 2, avg_loss = 0.3311\n",
            "t = 3, avg_loss = 0.3158\n",
            "t = 4, avg_loss = 0.4218\n",
            "t = 5, avg_loss = 0.4615\n",
            "t = 6, avg_loss = 0.3739\n",
            "t = 7, avg_loss = 0.2688\n",
            "t = 8, avg_loss = 0.3209\n",
            "t = 9, avg_loss = 0.3277\n",
            "t = 10, avg_loss = 0.3378\n",
            "t = 11, avg_loss = 0.3260\n",
            "t = 12, avg_loss = 0.4230\n",
            "t = 13, avg_loss = 0.3111\n",
            "t = 14, avg_loss = 0.2713\n",
            "t = 15, avg_loss = 0.3908\n",
            "t = 16, avg_loss = 0.2451\n",
            "t = 17, avg_loss = 0.3013\n",
            "t = 18, avg_loss = 0.3989\n",
            "t = 19, avg_loss = 0.3978\n",
            "t = 20, avg_loss = 0.2322\n",
            "t = 21, avg_loss = 0.3560\n",
            "t = 22, avg_loss = 0.3681\n",
            "t = 23, avg_loss = 0.2678\n",
            "t = 24, avg_loss = 0.3221\n",
            "t = 25, avg_loss = 0.3730\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 71 / 80\n",
            "t = 1, avg_loss = 0.3302\n",
            "t = 2, avg_loss = 0.2400\n",
            "t = 3, avg_loss = 0.2824\n",
            "t = 4, avg_loss = 0.3319\n",
            "t = 5, avg_loss = 0.3809\n",
            "t = 6, avg_loss = 0.3592\n",
            "t = 7, avg_loss = 0.2479\n",
            "t = 8, avg_loss = 0.3418\n",
            "t = 9, avg_loss = 0.2822\n",
            "t = 10, avg_loss = 0.2876\n",
            "t = 11, avg_loss = 0.2461\n",
            "t = 12, avg_loss = 0.4105\n",
            "t = 13, avg_loss = 0.3178\n",
            "t = 14, avg_loss = 0.3408\n",
            "t = 15, avg_loss = 0.3980\n",
            "t = 16, avg_loss = 0.3252\n",
            "t = 17, avg_loss = 0.2637\n",
            "t = 18, avg_loss = 0.2980\n",
            "t = 19, avg_loss = 0.3309\n",
            "t = 20, avg_loss = 0.2987\n",
            "t = 21, avg_loss = 0.2982\n",
            "t = 22, avg_loss = 0.3825\n",
            "t = 23, avg_loss = 0.5133\n",
            "t = 24, avg_loss = 0.3726\n",
            "t = 25, avg_loss = 0.3729\n",
            "Checking accuracy on test set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 72 / 80\n",
            "t = 1, avg_loss = 0.4766\n",
            "t = 2, avg_loss = 0.3152\n",
            "t = 3, avg_loss = 0.3494\n",
            "t = 4, avg_loss = 0.2706\n",
            "t = 5, avg_loss = 0.2921\n",
            "t = 6, avg_loss = 0.3689\n",
            "t = 7, avg_loss = 0.3984\n",
            "t = 9, avg_loss = 0.3891\n",
            "t = 10, avg_loss = 0.3884\n",
            "t = 11, avg_loss = 0.2974\n",
            "t = 12, avg_loss = 0.4628\n",
            "t = 13, avg_loss = 0.2628\n",
            "t = 14, avg_loss = 0.3014\n",
            "t = 15, avg_loss = 0.3836\n",
            "t = 16, avg_loss = 0.3564\n",
            "t = 17, avg_loss = 0.4299\n",
            "t = 18, avg_loss = 0.2657\n",
            "t = 19, avg_loss = 0.3433\n",
            "t = 20, avg_loss = 0.3896\n",
            "t = 21, avg_loss = 0.4529\n",
            "t = 22, avg_loss = 0.3016\n",
            "t = 23, avg_loss = 0.3988\n",
            "t = 24, avg_loss = 0.4034\n",
            "t = 25, avg_loss = 0.2961\n",
            "Checking accuracy on test set\n",
            "Got 337 / 400 correct (84.25)\n",
            "acc = 0.842500\n",
            "Starting epoch 73 / 80\n",
            "t = 1, avg_loss = 0.3039\n",
            "t = 2, avg_loss = 0.3118\n",
            "t = 3, avg_loss = 0.4562\n",
            "t = 4, avg_loss = 0.3800\n",
            "t = 5, avg_loss = 0.4097\n",
            "t = 6, avg_loss = 0.4089\n",
            "t = 7, avg_loss = 0.3216\n",
            "t = 8, avg_loss = 0.2694\n",
            "t = 9, avg_loss = 0.2577\n",
            "t = 10, avg_loss = 0.3613\n",
            "t = 11, avg_loss = 0.4383\n",
            "t = 12, avg_loss = 0.3637\n",
            "t = 13, avg_loss = 0.3272\n",
            "t = 14, avg_loss = 0.2869\n",
            "t = 15, avg_loss = 0.2531\n",
            "t = 16, avg_loss = 0.5207\n",
            "t = 17, avg_loss = 0.3425\n",
            "t = 18, avg_loss = 0.3737\n",
            "t = 19, avg_loss = 0.3247\n",
            "t = 20, avg_loss = 0.4301\n",
            "t = 21, avg_loss = 0.3500\n",
            "t = 22, avg_loss = 0.2879\n",
            "t = 23, avg_loss = 0.3594\n",
            "t = 24, avg_loss = 0.4700\n",
            "t = 25, avg_loss = 0.2603\n",
            "Checking accuracy on test set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 74 / 80\n",
            "t = 1, avg_loss = 0.2786\n",
            "t = 2, avg_loss = 0.2460\n",
            "t = 3, avg_loss = 0.3025\n",
            "t = 4, avg_loss = 0.2630\n",
            "t = 5, avg_loss = 0.2902\n",
            "t = 6, avg_loss = 0.3821\n",
            "t = 7, avg_loss = 0.2784\n",
            "t = 8, avg_loss = 0.4435\n",
            "t = 9, avg_loss = 0.3116\n",
            "t = 10, avg_loss = 0.3875\n",
            "t = 11, avg_loss = 0.3303\n",
            "t = 12, avg_loss = 0.4615\n",
            "t = 13, avg_loss = 0.3190\n",
            "t = 14, avg_loss = 0.3561\n",
            "t = 15, avg_loss = 0.3426\n",
            "t = 16, avg_loss = 0.3050\n",
            "t = 17, avg_loss = 0.3566\n",
            "t = 18, avg_loss = 0.3218\n",
            "t = 19, avg_loss = 0.3791\n",
            "t = 20, avg_loss = 0.4662\n",
            "t = 21, avg_loss = 0.3293\n",
            "t = 22, avg_loss = 0.4164\n",
            "t = 23, avg_loss = 0.3922\n",
            "t = 24, avg_loss = 0.3216\n",
            "t = 25, avg_loss = 0.3675\n",
            "Checking accuracy on test set\n",
            "Got 351 / 400 correct (87.75)\n",
            "acc = 0.877500\n",
            "Starting epoch 75 / 80\n",
            "t = 1, avg_loss = 0.4156\n",
            "t = 2, avg_loss = 0.3770\n",
            "t = 3, avg_loss = 0.3615\n",
            "t = 4, avg_loss = 0.3662\n",
            "t = 5, avg_loss = 0.4209\n",
            "t = 6, avg_loss = 0.3003\n",
            "t = 7, avg_loss = 0.2082\n",
            "t = 8, avg_loss = 0.3104\n",
            "t = 9, avg_loss = 0.4774\n",
            "t = 10, avg_loss = 0.3210\n",
            "t = 11, avg_loss = 0.3077\n",
            "t = 12, avg_loss = 0.3077\n",
            "t = 13, avg_loss = 0.3463\n",
            "t = 14, avg_loss = 0.4346\n",
            "t = 15, avg_loss = 0.2966\n",
            "t = 16, avg_loss = 0.3892\n",
            "t = 17, avg_loss = 0.3728\n",
            "t = 18, avg_loss = 0.2794\n",
            "t = 19, avg_loss = 0.3278\n",
            "t = 20, avg_loss = 0.3118\n",
            "t = 21, avg_loss = 0.3213\n",
            "t = 22, avg_loss = 0.3426\n",
            "t = 23, avg_loss = 0.3566\n",
            "t = 24, avg_loss = 0.2079\n",
            "t = 25, avg_loss = 0.4437\n",
            "Checking accuracy on test set\n",
            "Got 362 / 400 correct (90.50)\n",
            "acc = 0.905000\n",
            "Starting epoch 76 / 80\n",
            "t = 1, avg_loss = 0.2425\n",
            "t = 2, avg_loss = 0.3271\n",
            "t = 3, avg_loss = 0.4111\n",
            "t = 4, avg_loss = 0.4012\n",
            "t = 5, avg_loss = 0.3261\n",
            "t = 6, avg_loss = 0.2869\n",
            "t = 7, avg_loss = 0.3544\n",
            "t = 8, avg_loss = 0.3792\n",
            "t = 9, avg_loss = 0.3012\n",
            "t = 10, avg_loss = 0.3620\n",
            "t = 11, avg_loss = 0.2844\n",
            "t = 12, avg_loss = 0.2395\n",
            "t = 13, avg_loss = 0.2575\n",
            "t = 14, avg_loss = 0.3282\n",
            "t = 15, avg_loss = 0.3252\n",
            "t = 16, avg_loss = 0.2669\n",
            "t = 17, avg_loss = 0.3168\n",
            "t = 18, avg_loss = 0.5533\n",
            "t = 19, avg_loss = 0.3846\n",
            "t = 20, avg_loss = 0.3006\n",
            "t = 21, avg_loss = 0.2809\n",
            "t = 22, avg_loss = 0.2866\n",
            "t = 23, avg_loss = 0.3390\n",
            "t = 24, avg_loss = 0.3708\n",
            "t = 25, avg_loss = 0.3028\n",
            "Checking accuracy on test set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 77 / 80\n",
            "t = 1, avg_loss = 0.3134\n",
            "t = 2, avg_loss = 0.3878\n",
            "t = 3, avg_loss = 0.3723\n",
            "t = 4, avg_loss = 0.3997\n",
            "t = 5, avg_loss = 0.2265\n",
            "t = 6, avg_loss = 0.2541\n",
            "t = 7, avg_loss = 0.3759\n",
            "t = 8, avg_loss = 0.4086\n",
            "t = 9, avg_loss = 0.4347\n",
            "t = 10, avg_loss = 0.3049\n",
            "t = 11, avg_loss = 0.2790\n",
            "t = 12, avg_loss = 0.3732\n",
            "t = 13, avg_loss = 0.3609\n",
            "t = 14, avg_loss = 0.3869\n",
            "t = 15, avg_loss = 0.2853\n",
            "t = 16, avg_loss = 0.4230\n",
            "t = 17, avg_loss = 0.3948\n",
            "t = 18, avg_loss = 0.3434\n",
            "t = 19, avg_loss = 0.3286\n",
            "t = 20, avg_loss = 0.2738\n",
            "t = 21, avg_loss = 0.3038\n",
            "t = 22, avg_loss = 0.2891\n",
            "t = 23, avg_loss = 0.4004\n",
            "t = 24, avg_loss = 0.3217\n",
            "t = 25, avg_loss = 0.4459\n",
            "Checking accuracy on test set\n",
            "Got 343 / 400 correct (85.75)\n",
            "acc = 0.857500\n",
            "Starting epoch 78 / 80\n",
            "t = 1, avg_loss = 0.4493\n",
            "t = 2, avg_loss = 0.3618\n",
            "t = 3, avg_loss = 0.3044\n",
            "t = 4, avg_loss = 0.2978\n",
            "t = 5, avg_loss = 0.2953\n",
            "t = 6, avg_loss = 0.2575\n",
            "t = 7, avg_loss = 0.2607\n",
            "t = 8, avg_loss = 0.3341\n",
            "t = 9, avg_loss = 0.3368\n",
            "t = 10, avg_loss = 0.2940\n",
            "t = 11, avg_loss = 0.3815\n",
            "t = 12, avg_loss = 0.2468\n",
            "t = 13, avg_loss = 0.2814\n",
            "t = 14, avg_loss = 0.3728\n",
            "t = 15, avg_loss = 0.3744\n",
            "t = 16, avg_loss = 0.3619\n",
            "t = 17, avg_loss = 0.3960\n",
            "t = 18, avg_loss = 0.2592\n",
            "t = 19, avg_loss = 0.3392\n",
            "t = 20, avg_loss = 0.3142\n",
            "t = 21, avg_loss = 0.4471\n",
            "t = 22, avg_loss = 0.4349\n",
            "t = 23, avg_loss = 0.2510\n",
            "t = 24, avg_loss = 0.3588\n",
            "t = 25, avg_loss = 0.2735\n",
            "Checking accuracy on test set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 79 / 80\n",
            "t = 1, avg_loss = 0.2952\n",
            "t = 2, avg_loss = 0.3412\n",
            "t = 3, avg_loss = 0.2979\n",
            "t = 4, avg_loss = 0.4062\n",
            "t = 5, avg_loss = 0.3098\n",
            "t = 6, avg_loss = 0.3546\n",
            "t = 7, avg_loss = 0.3370\n",
            "t = 8, avg_loss = 0.3653\n",
            "t = 9, avg_loss = 0.3715\n",
            "t = 10, avg_loss = 0.3070\n",
            "t = 11, avg_loss = 0.4666\n",
            "t = 12, avg_loss = 0.3764\n",
            "t = 13, avg_loss = 0.2957\n",
            "t = 14, avg_loss = 0.3330\n",
            "t = 15, avg_loss = 0.2408\n",
            "t = 16, avg_loss = 0.3294\n",
            "t = 17, avg_loss = 0.4055\n",
            "t = 18, avg_loss = 0.4129\n",
            "t = 19, avg_loss = 0.3475\n",
            "t = 20, avg_loss = 0.2902\n",
            "t = 21, avg_loss = 0.2675\n",
            "t = 22, avg_loss = 0.3021\n",
            "t = 23, avg_loss = 0.2957\n",
            "t = 24, avg_loss = 0.4016\n",
            "t = 25, avg_loss = 0.3626\n",
            "Checking accuracy on test set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 80 / 80\n",
            "t = 1, avg_loss = 0.4759\n",
            "t = 2, avg_loss = 0.2825\n",
            "t = 3, avg_loss = 0.3680\n",
            "t = 4, avg_loss = 0.3248\n",
            "t = 5, avg_loss = 0.3806\n",
            "t = 6, avg_loss = 0.3931\n",
            "t = 7, avg_loss = 0.3639\n",
            "t = 8, avg_loss = 0.3122\n",
            "t = 9, avg_loss = 0.3957\n",
            "t = 10, avg_loss = 0.2308\n",
            "t = 11, avg_loss = 0.5208\n",
            "t = 12, avg_loss = 0.3362\n",
            "t = 13, avg_loss = 0.3110\n",
            "t = 14, avg_loss = 0.2898\n",
            "t = 15, avg_loss = 0.3852\n",
            "t = 16, avg_loss = 0.3536\n",
            "t = 17, avg_loss = 0.3379\n",
            "t = 18, avg_loss = 0.4172\n",
            "t = 19, avg_loss = 0.4270\n",
            "t = 20, avg_loss = 0.2854\n",
            "t = 21, avg_loss = 0.3413\n",
            "t = 22, avg_loss = 0.3288\n",
            "t = 23, avg_loss = 0.4761\n",
            "t = 24, avg_loss = 0.2710\n",
            "t = 25, avg_loss = 0.2411\n",
            "Checking accuracy on test set\n",
            "Got 358 / 400 correct (89.50)\n",
            "acc = 0.895000\n",
            "Checking accuracy on test set\n",
            "Got 357 / 400 correct (89.25)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsT35q4knOUq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "07ab765e-c4ca-4ff4-c0ec-57dd7e66abb4"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot([print_every*batch_size*(i+1) for i in range((len(avg_loss_list)))],avg_loss_list)\n",
        "print(\"Loss:\")\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO2dd5gUZfLHv7WBnGElLVkQQUGUZEQkCOKZPeH0foYznVnv9EAxHOqJ4dTTw8AZz4RZUVAMh4DkBRHJLEsGZcmZTe/vj+me7enp8HZP93T3bH2eZ5+d6Xmn35q3u6ur662ql4QQYBiGYaJPVtACMAzDMN7ACp1hGCZDYIXOMAyTIbBCZxiGyRBYoTMMw2QIOUF13KRJE9G2bdugumcYhokkCxYs2C6EyDP6LDCF3rZtWxQUFATVPcMwTCQhovVmn7HLhWEYJkNghc4wDJMhsEJnGIbJEFihMwzDZAis0BmGYTIEVugMwzAZAit0hmGYDIEVuscsWL8Ty7fuDVoMhmGqIIElFmUqF784GwCwbuywgCVhGKaqwRY6wzBMhsAKnWEYJkNghc4wDJMhsEJnGIbJEFihMwzDZAis0BmGYTIEVugMwzAZAit0hmGYDIEVOsMwTIbACp1hGCZDYIXOMAyTIbBCZxiGyRBYoTMMw2QIrNAZhmEyBCmFTkRDiGglERUS0UiDz58hokXK3yoi2u29qAzDMIwVtvXQiSgbwDgAgwBsAjCfiCYKIZapbYQQd2ra3wqghw+yMgzDMBbIWOi9ARQKIYqEECUAJgA436L9CADveSEcwzAMI4+MQm8JYKPm/SZlWxJE1AZAOwD/M/n8eiIqIKKC4uJip7IyDMMwFng9KTocwEdCiHKjD4UQ44UQPYUQPfPy8jzu2phdB0oghEhLXwzDMEEio9A3A2ileZ+vbDNiOELkbincth89Hv4Wb8/dELQoDMMwviOj0OcD6EhE7YioGmJKe6K+ERF1BtAQwGxvRXRPUfF+AMC0ldsCloRhGMZ/bBW6EKIMwC0ApgBYDuADIcRSIhpDROdpmg4HMEGEyL+RRQQACI9EDMMw/mEbtggAQojJACbrtj2ge/+Qd2J5g6LPwfqcYZiqQJXIFA3RQwPDMIxvZLRCj7tcApaDYRgmHWS0Qoficqlgjc4wTBUgoxU6BS0AwzBMGsloha7CPnSGYaoCGa3QOWyRYZiqREYrdGKfC8MwVYiMVugqguNcGIapAmS0QmeXC8MwVYmMVuiqx4UVOsMwVYGMVugqQbhc9h8pS3ufDMNUbTJaoVOALpdnvl2V/k4ZhqnSZLhCj/0PwuNypMxwjQ+GYRjfyGiFHod96L6wZfchzCnaEbQYDMMoZLRCryzOlX6NXhUmYgc+PQ3Dx88JWgyGYRQyWqETF+fylYMl7FZimDCR2Qo9aAEYhmHSSEYrdJUginPxQwHDMOkmoxU6+bTAxZ6DpdhzsNTjvTIMw6SG1JqiUSUetuixRu8+5hsAwLqxw7zdMcMwTApktIWuEoT7I9WbyJgvluGej372RhiGYaoEGa3Qs/wy0dPAazPX4oOCTZ7u86MFm3Dfp794uk+nFG7bj8OlHB3DMH6Q0Qo9XpwrkN7DdxP564c/4525GwLrf8/BUgx8ehpGfrw4MBkYJpPJaIWuEkEDPSM5UBIrWDZ37c6AJWGYzCSjFXqQmaJGrP5tHzreNxkbdx4MWhSGYTKQjFboQbrQjfp8f/5GlJYLfL3k1/QLxISa3/Yexpri/UGLwUScjA5bVGGXCxN2+vzjewAcCsukRkZb6CpRDFtkGIZxipRCJ6IhRLSSiAqJaKRJm98T0TIiWkpE73orZmoEkfrPMAyTbmxdLkSUDWAcgEEANgGYT0QThRDLNG06AhgF4FQhxC4iOsovgf1gTfF+dMirE7QYDMMwKSFjofcGUCiEKBJClACYAOB8XZvrAIwTQuwCACHENm/FTObH1dtxSLJ8q5WBPmnxVgz45zR8u+w3jyRT+gxJZA3DZBIlZRVoO3ISXpq2JmhRQomMQm8JYKPm/SZlm5ZOADoR0UwimkNEQ4x2RETXE1EBERUUFxe7kxhAUfF+XPHqXNwrmfVopVyXbtkDAFj5617X8jBy8C2OSRXViHthamHAkoQTryZFcwB0BHAmgBEA/kNEDfSNhBDjhRA9hRA98/LyXHe273AsQcUuzEu1zGVc6GplRoZhwg8bB8bIKPTNAFpp3ucr27RsAjBRCFEqhFgLYBViCj4UyBz8sE6cfliwEaM+yYxUeb5lMinDJ5ElMgp9PoCORNSOiKoBGA5goq7NZ4hZ5yCiJoi5YIo8lNMQWR0cyAIXHnV590eL8d68jfYNI0A4b5kMkznYKnQhRBmAWwBMAbAcwAdCiKVENIaIzlOaTQGwg4iWAZgK4G4hhG/LwVt5R/YcLMXm3YdisisqxEyRTF2xDWu3H1D26e2tn5UXw/gIX2CGSGWKCiEmA5is2/aA5rUAcJfyFwgvT1uDTk3r4u6PFmP7/iOJGXcmB//qN+anRzgGAD8th4Ub31qAJVv24Me/nRW0KIzHZETqf0WFwGNfrTD9PCw387DIERRV/feHha+Xci2hTCXyqf8LN+xC+3snG36m+rHXbj+Aior0qpOQzrEyTKSJF9wLVozQEnmFPnuNnKv+nbnrfZaEsYNdLsDPG3ejrLwiaDGYDCXSCn3ngRJMWrxVqm3x/hKfpUmEM0WTqeojsmzLXpw/biae+mZV0KJ4yv4jZXjhh0KUp/kpmEkm0j70zbsPxSNaGCbsFO8/AqAyOzlTePyrFXhrznq0aVQbw7o197UvfsqzJpIWOkkeVjN7YcH6ndh7uNQ7gRgp+GLMTPYp19KRMl78O2giaaG7cmcos5SHS8tx8Yuz0btdI4+l0vfn7+6jSBSGRAiBfUfKUK9GbtCiRI50Vs8Ia2Z30ETSQk8F1c+3ZLPxY+/GnQex/0hZOkViQsQ7czeg20PfxBPOGCZKRFKhS7tcLO7iZh+d/sRUDB8/W1qWof+agccmL0/eP4C5RTs8syRmr9mBtiMnYd7anZ7sLwii4HL5fnmsjHIRr+8pDdvK4SGSCj0VKuNYheF2AFiyWb6U7vKte/Hy9OSyNZ8v2ozLxs/Bxwv1dczcMeI/cwAAnyzc5Mn+goAv/MxG1tDyAj6XjImkQv/0p9SVpN8uODWC67nvV8e32Z3uFRXCNgFq5prtOOnhb3GA3UJMGjlwpAwPfr4EB0uSz7t0urODVuS/bNqDtiMnYVbh9oAlMSaSCv21mWul2hkd/HiNdO/EsWTDzoNS7T4s2Ij2907GCWO+sWy3cech7DhQgsJt0XMJhMXlMvmXrdiuhBDqqap18fcdLsVdHyzCnkPG0V+vzFiLN2evx6szzK+9qjB0c4piiYzfr/B9UTZXRFKhu0Ho/oeNuz+K1Tzfe1jO8s7Njt6hC8PY7zlYipveWYhrAijMFmZ99/rMdfhk4Wb8x8B9CABlFbHs1jAcQ4BLa5gRPa2QIsLCRJfNOg0D1XIIFRUCoz/7Bat/2xe0OI4IUrGVKGn3WwJISIuyDqpQrhv12C3csCueIJXO38WK3JqMVuhGB7/SUtdNioKwbKt9Bp+V7zqdqc85WVnYvv8I3p6zIT5hGhWcjNLiTbtxyYuzcLjUm6SVuGKy8Q+kqjiK9x3B1j3RyWK2u8mq46EO20UvzMKw5370VaYwEg+qCOmNJaMVuhFW64weKbUumjSzcDu6PjjF9PMnp6y07ttWOnmIKt0u29Ncp8Ytbizz+z9fioL1u7B8qzeLeKsKPcvnx4Rej36Hkx/7n7+dOGDMF8vQduQk199Xz139jbBg3U58u4zL8YaFSGaKpoLqcikzsKZLbKrg2cWAqzHM6aBCRO8RPgzyqoc9qyrM4GmQDSQwo/LJJnH7JS/J52x4QhhOIoS3+F6VtdCNKLVR6HY6wK2O2LBDLhJGS5Cpz//32jz8/YulaZXFq0lMNSzUTKH7qeajcAsxVVQhuxEGpVDDHgWV4RZ68kG3Og0qbMpUe5U48ejk5cjOIlxzWjus/HUfzn52esLn//zG2nUDALsOlqBOjWAO3/RVxZi+qtjx99yMnvqdXQe9Kaam9wWbtvOkt+hgNx76SVHjfYRb2XkJ+9DTjJnVaFkOwOYy9tLv+vqs2CPwRoM49ef/V2j7/YtfnI37P1vinUApIHtyh+EaqPShm1joVUcnOXqyEhIWejqGLqyujrCQwQrd+P16k0QfInvFZOtycXBKy1qKVkxZmj6ffaagHmI3N+fyCoH7P1tieBOOIh8UbEzapp6XT05ZgWmap7AKD85XLwmrhRw0mavQkXjQ/zOjCG1HTsJFL8yy/I4VXj5Sbtp1CBUVIjQXSDoIw0+1s9BVjKzXnzbswltz1uP/XpsXqZwFM5Zvrcxf0J/b46auwZWvzYu/Vy3joN0qfijyX/ccxq4DcpFiqfz6JZv3+D7flLEKvUI3cEfK7NdxTNlCd3i090lmhYYd2VPUzamsHVMv4rqFSbSGE9ZuP4Cb311omiZvL4P7ft+asx5tR07yZKWuN2atk24bf6JMudfw0fex79Hr0e987WPG6mKc+/yPeHuOv2sbVxmFLoOdf86PanJ+Vajbf6QMA/75AxZv2u3L/oPAi7junzbExsOLaA2jXYybWogO906Ov5/mYvLYiFmF29H/qR/i8yYfGrhL3CC7ypDMjTDKT5tGYcxGuP2N65RIthW/+pvVnbkKvcKFRZiihe6UFb/u9c3kWbB+F9YUH7BNdvIC2cfIMFzvas2c1dv2mxTokpfSqOWTU1YmZAxr3RapsNqnYmz67GazIxlPLLLY16GScs8yes1w67A4cKQML/6wxrNsbreuE79d/xmr0O2ShPTIXMZeK6TLxs/B1t2HPd5ruLjz/UU4518zADg7mQ+XlmPKUn8zEH9vkRRjWKlToo0RC9anviiJX9avnX77YH7sSSAe5WIxm3z3R4tx+hNTvRLNEqeK8YmvV+Dxr1dg8i+pzX24PQzpMmYyV6FL+Mz12E+K2n3u/LDty4DFqq3G7dOfNmOZi7T9sV+twA1vLYi7SLxAv6xcUYrLzAnJU+ziF2en7HrxSyHYWZr3fBx7opGJQwdiNWzCyD6lBpPMXFqUkVLoRDSEiFYSUSERjTT4/CoiKiaiRcrftd6L6oyS8go88fUKR9+x87v7kSWX7XdRkZBQXiEcKaVNu7wvbNX/qR9S+r5eficx0drqjodKy50/svtkoustdDOxzGq5pJuwLA4dDimSsVXoRJQNYByAoQC6ABhBRF0Mmr4vhDhB+XvFYzkdU1JWgfnrdjn6jv5ceWnamnj9lvPHzcQjkxLXDt2jy140O9VHf/YLXplhXGf6h5XeTJrp0Z/4bi+E4x+cUukyEcYrKul3vWD9LkxduQ3LtlRa5h3unezIOkrlPvePycsx+rNfcMzor/DQxKX2X9Bgpa/0v9ytO3bB+l147nv75DEtvqlR2cxZD6KDrDhcWi4dOhgTyGEHHmngoG9odshY6L0BFAohioQQJQAmADjfX7FSZ9Ou1JM/xn61Ar9/OeZn/Xlj8qN/d5vVhVTenrMh6Wag8qPPS1mpJ+DkX9z5o/cdKcOyrXuxcedBtBs1Ge01ERxmXPziLFz9+vyk5crU9/uPlKHtyEn44uctht9/7Kvl+GaZ+6Sp8dOL8PacDThSVuEoNM8pTm+SWl0w8Wdnyyj650OX+w0ymaIqv+45jH99t9rR+Fw2fg56PPytdHu3eDWMbh8U/H7AkFHoLQFoY6Q2Kdv0XExEi4noIyJqZbQjIrqeiAqIqKC42B/LVMWuFK4RNXL9nVJwZIGkQHmFSCpmtW2fs8nXwm378LSmpsy5z5vXvq4QAh3unYw3Zq5NiI82m0BT4+9f+GGN4ecvTzN+mgkbqVybTt13foW3Jk/0Gv8qWR86ANz63kI8890qLNU8oRWs24lZa8yNFyODSU9JWQV+DjgMN+QGumeTol8AaCuE6AbgWwBvGjUSQowXQvQUQvTMy8vzqGtjnF5sRECbxrUBAIO7NHXVp93B/sSDxa3N0FaK3HmgJO4OUK0kp776Ef+Zi+c0NWWskmiEiN1EHvpiGU4dWxkrnmPTZ1j8oUbIiOYk10Hf1Kli8GuqpVJRyy34ISP3wZLyhO8AsTK7f/jPXMfyvTV7HdqOnIRdB0rwyKRluOaNAsf7qErIKPTNALQWd76yLY4QYocQQp3efgXASd6I5x6nymJO0U689mOsYFb9mrmu+gzy7q2Nd9bKUVR8AHsOlib4/mTGxq6UsAx6K9RP/V1SVuFJjLGjQ+iwu1R+v9G5ddrj/8OEeRvc7xSVMskmGKWb9+bFnAObdx/Cks2VK4o5LdIVtOlQefyCT/2fD6AjEbUjomoAhgOYqG1ARM01b88DYOwwTiNOh+1/K7Zhh+ISCUvNZyfMWrMj/rpgXWXc8+bdh3DBCzMTKjNWCG+tY7OLKyfbehy1Fm5peQVufe8nFBW7S6DpNPorz5J4ZKkQwPjpa6Tq2W/dcwj/p73pOnShGLXftOsQRn7yi6P96BFCQAiBZ79bndJ+tPh1+fiV3euGsFZ9tC2oLYQoI6JbAEwBkA3gNSHEUiIaA6BACDERwG1EdB6AMgA7AVzlo8xSpKKv3i/YiEMuMt788nM65ca3Fya818dfd7h3Mi49KR9PXtrdk/7Mxtre5VL5euH6Xfji5y34NYV6LT8WbsfUFdtcf9+MpVv2YFbhDpzQukHC9u37j+Afk1fg7TkbMP2e/pb7mL460X/sWLF4pYj00U/QrcRlc93sPVRmmw3q15OYnULffbAEW3YfRpcW9fwRAOHIdrZCaoUEIcRkAJN12x7QvB4FYJS3oqVGqhboRJMIDDMGPzMNq37zJz1bll0HSrBIYnIJAD5csMlSoTsZPrOmdi4XYfA61Zvi1R6tbKSVTl0M+cMbT05soTTZsPMgNuw4iNaNa5nuLVVF4JciqRAi7vO24sMFmwDEFmf53GGEjmfYDML542Zi/Y6DWDd2mO+ihHX6J2MzRdM93kErcwAY+cliDxWaPGY3z8M2kUba74lKjR4ZtPerH1Y5ezIwi2deY+Jy0rd3e+MzXCfA4a6WbPZmwW6naMU0OuXWW7i+PHMxKschpPo8egr96yVytRjCegf1k20u066ven0exk9PDCF04hIwG+pznpuha6dPdkr+zK7b3/ZGs/aN7HjeMWERgFjhtlGfLI4ncqWSpWpFhUjM4A3bZaMdNy986E5KHu89XIr/TC/y5Gag3oCFAMo8CDgwI3IKfeoKufj1sE5ahI2Ssgr8sLIY/5jsrEyCFukl6HTtirYfQNuRk2JWqWRYnN/V/Pya0NPvdsOOA9hhUO2xek7skrz2zQK8N29jPK7fu8k83XvhfRCAH2UbACDLA2319y+WSbd98POleHTycsxYnVry36UvzcK9n8YmryfM34ij7/vKt5o3kVPosgfVSwv92xSyFtOJm99slq3prOPUvv7DymLN0nDWyiVdE89GY6nf5mSeRe8yOVBSjtOfmIqfN+7GPR/9HN9uli+gHxY7dxYQK5RlV6ROCO9vYqoVrO5Xa5GmMmmtPfZlFQJtR07Cq0qosR/sVX6HdgzdDJVRCZItHixQYkTkFLpsLQUv7fPr/huNZAaz35xXt7rpd8pNF9OW79dsH0n7NPt+RUU8hNHpTam0vAJvzLS/qN/yYKUYfSLR+OmpZbQeLCnHla/PwwcFm+LbzE5v/Y3spWnGWbYqQgj0evQ73Pn+oqTtCe8hfA/TPah5qrr6jfkJ8eROMBLzrdnrpL4rc1pd9MJM6e+E1aUbPYUu2S7MWYi+YfKbZUsaFBXvx8s2isIIWcVmlllZWi7ios8u2mHYxoz/zl6PhyQeo7Vx+G5xswqWVzjVuaqok2zqf1cI/WSj979RL7rbpfv8vvEsVEo1b9t7GJ/+ZHyTdSLC+OlrXN+83CIVthgmZA9qgcNKi5mAWaLkxp3Gj3f6CebLxs9B8b4juLxvG0f9FkqupmOmK1LJ8NzrUjmYYenSSYM+N+vfaZU/rahPf7vKcDugKPA0Rxa5uWd46RpavGk3jm9Z33RM//jqPKz8bR96tW0Y79tAItt+rOalfEu+8me3/iFb08KLR+yo4XQi+Ma3FyYUDDuoLAJw3INTHFlR8parcbuyCnnJ9RdCOrN6U6ksYCZlqjVezNBa2s99b54FuvNASdJNxOuJZ69Kzhoda6NDoo/Y0nPev2ea6oe3Zq/Dyt9i634aGRphSR40I3IKPYh6xFGpBOAmPtiLmi2yCt1MIZZXVEg/6u8/kliSV+bYuKlTYiRNkC4Xp8W5zCTV/4QxXy5LGMOtew7j+rcWOOssTcgOgZFlrP/dK00Wa77/8+T6+VG5/oEMdrl43afsxF+UcXuzlLVczV0u8o/hQ/81IyETUEbioc/OsG+k7k+3Q+3kYyoKXXZoZSdF7ZAVVb+S1JeLU1tzU8sPK7chv2FN5Ga7txsT/dfeXvt3vr8IDWtVs+g7QppcIXIWehArtnm1UnimMl1yvUwzK5zIfd6AzDXnZu1QVdSxX61I2hYEjidFTcZTvz0nO8s3xfXUN6tw/X+Trf2b311o0NoeL8V8Z+4GfPrTZrxmESFl1V2q54JfrpvoKfQqsgZnEPg9sre+95Npv24vED+tKP3CznYWulUGoOwF7NWFLjue1bLJVyPJqJSB+yiX5G1+3mSNTi11m7bfigqBb5f9Zrg8Y7qJnEJnde4ffp+OZqUJsogcXZhjv1qBpVv8DwfTl+P905vW+QjzNGWL9SzcYBx1JaPcPl+0Ge/P32jbzg31a+baWr4/mcieblK52Xl1bhtJ8ObsdbjuvwX4YvEWlJRV4N//W+17RrMZkfOhR9GvFWae+qYypE0/4ZguYi4XeV6atgavzCjC61f38nxOJaXdWfyIMknrTd//JS/Nwm97naeJmz1N6DcPOa657TV14QuzHPef0KeDtpt3H0LLBjVT6s8rtGO1ZPMeNK9fo/Izza/6RYk1P1JWgffnb8BT36xCaXkw1nrkLHT2uGQeROR4wrGsQuCPr85Li6UeBOpwuFHm2u/bQfD3qVfAWbKSuoTh4dJyqbkrPyOP4gVAKbamrtm6uqqc1bKz4jduuycvv+zSyFnoUVxNiLEmlSOaalTG1j2H0Lx+OCxCIJYodbAk9Sel1DIDgqfz/V/jghNaxN+bTfL6VQjMiK17rCt9CghUz8kGYB8q69siIP7s1j/YQs88iIKLIDHLog2qWufPm/ag/1M/pLwfbcKYFUL4W8tl54ESHP/QN66++9miyuJn+w+ndpNzU9LA6DvaoSotr0BZeUXcIBECqKZUy5QpnuYHkVPokYryZ6SITXYFo0AroxYE7nx/EeYWmU9spgunbhZ1Au7NWevQduQklJZXYNAz0wzb6lcnCquFrrJaWTjmrx/+bHnpr9/hPDTVDtXjc80byZPhQgAd7/sKg5+dHp+DEKKy/LHdpCin/iuwhZ55ZFFqafWpoJ5OpeUCn/60Ob5QeJRQ5xGemrISAHCotNzUQhz0tE7RC+CfmlovYeOIUrp2i4W7Y9qqYvR78gfP+zY6JfWRNkXFBxK2GIU1ppMIKnTW6JkGkbv0fC+J8oIoFQI4WFImlc2sv2EJCOnEsLCiDy81wtXRtRhPo0/CcAZFcFI0aAkYryGiwHyOZhZVlCo9CAF0eWBKwntZQpALE300Oino8yZyFjrHoWcmhyRWnveLR75chs73fx1Y/0ZsdrCiTdLknQOlErQCcoKTS3/kx4tT7k82d+CThZsB6BY9D8hej5xCZ5dL5pFFhBIfF861hvCKj8uYpQO96nBSSC5KrqbvlssvXzfBg8zapVsMqpfaqJ+gfeiRc7mwPs88Zq3ZnvJCvG7x8nwKSjXqlcfniza7/m4YMIsQsVsf1RKPf6fhmrMm29NJBC30oCVgvCYoZZ4p6K3sfQ5itkOoz+Op9GEkHnNuNHIhGMzIKfSg74BMZpEJ9sHHCxItcke/KeAL6nBpOfr+4/uEbV6Xq1712z7sPezNUoVWc3jCgQOL49AVzuiUF7QITAZhdoGO9mBR6XQxR7ewthNlEbR9VFR8AL/uTYwxf/hL+0W/nTD4memePQXG3UE2AxfUuEopdCIaQkQriaiQiEZatLuYiAQR9fROxESObV7Pr10zVRCzlHA3NbuDMnb11qe2gqYdHxZssm/kA58v2ozdB0sMi2sZTkaGBKsMUO1P+XbZb2mQJhnbSVEiygYwDsAgAJsAzCeiiUKIZbp2dQHcDmCuH4IyjB94GeGiXa4unaQS8hmUv/r2CYsAAE3rVQ+kf7cEGV4rg4yF3htAoRCiSAhRAmACgPMN2j0M4HEA1iXJGCZETPJwDc0fC4OZ3A1y8epUcVseWAYvFkDXc1jJaNa7iZwS5BJ0LQFogzo3KdviENGJAFoJISZZ7YiIrieiAiIqKC6Odroxw4QFzvY05uxnp3u+TzXZaNaaHUmfOa397gcpT4oSURaApwH8xa6tEGK8EKKnEKJnXh5PbjIM4x9Fxd5XYLSa7RSi0pUUFDIKfTOAVpr3+co2lboAjgPwAxGtA9AXwEQ/J0YZJmxs3x+9Ko2Mc6zcW2HIupVR6PMBdCSidkRUDcBwABPVD4UQe4QQTYQQbYUQbQHMAXCeEMJ6RV2GySCe+3510CIwaSDs0xW2Cl0IUQbgFgBTACwH8IEQYikRjSGi8/wWkGEYJixYzVeEQdlL1XIRQkwGMFm37QGTtmemLhbDMEz48MqtwpmiTALq2oUMw5jzyowiT/dnZYWHwe3GWiGicJEyhrHnkUnLPd3fG7PWmX62bZ9/MfWysEKPKNlcR5hhGB2s0CMKL/TBMIweVugRhfU5w0QXvyJiIqnQp/71THx9x+me7vOOgR093Z/fZLETnWEYHZFU6O2a1EbnZuZldHu2aeh4n34Vy/EL9qEzTHTxK6s0kgq9KlGvhnGqgNXKKQzDVE0yUqHXrJYdtAiekd+wluF29rgwTHRhH7okdw3qhJvOPNq23dDjmiW8D6vBm2VwhJ4f0cAbZncAABvVSURBVAPZrNEZhtGRcQr9tgEdUT3X/mc1ql0tDdKkzuV92iRtO6FVAw5bZBgmiUgr9BvOaJ/w/ub+HaS/q9eHYVSPfx3cCRed2NLwMzt9/uQl3XyQiGGYMBNphT7qnGMT3ndpXl/6u/qoljAavFaV3ezkvbRnK+sGDMMEBvvQqyAVQhiGU6br5nNF39bp6YhhGE+osgo9jBa5HjMLnYgwoHNT3/tvWreG730wTFWE49A9YMXDQ3BU3eoAkn3mdnHdU+44wxMZnh/RA1/eeppUWyGE6Y1n9LBjfbegQ1Cvn2EYB0ReoU+67TQ0qROLWFGVn5F/qlWjmqiRWxmf7jQx55hmdV3LCAANauUCAHKzs6SfDiqEQG52FkYN7Yym9arHtxOAnOwsNKsXDQt6cBf/nyYYJkqwD92Eri3qo1fbRrbt3vlTXwDBWZ2tlAQhYeIXN0J1udzQrwOOPqqOX6L5zkkuSjEYEeUxkCEKbkAm3EReoWuxuutZrdYN+H8xqXlATm4oWpmjVmtGi1djq7rLMpWauZmT4cxY45dhmREK3YnCUHWkGyXz5jW9nX9JRemw3CoWUYf2HqSVV33tdz0Xbf/VU1jyLso3Iytys739Xc+P6OHp/pjwInzyuWSEQpdBP3zVc6ytofyGNeOvRw3tDADo1ykv7q93yoO/64JLT8rH4K5N5X3oDpS/U64+ta2j9lY3ovo1cy2/m6muBK+vyZaac45h3FB1FHr86ov9v6xXK9w2oLIGut6KVCccP7jhZNzQrzID9XBpRUK7C05oIdX/UXWr48lLu6N6TjZKyirsvwDrxKJUqVPduIqjFm1oVZmJMJf1bIUx53f1TC4n3KdLLIs6UXqS8Srqq6rCLhcLZCwlfZPcbMJdgzqZtlfrwehrYB0uLU943z7P+URdt/z6eOSC42zbJfjQNWZutezUD5tX7ppTOzZJiB7ysy/9cT62eT10TjH6KExEqd4a+/vDSUYodD1dWyQvfqFXBnolo9c5T//+BNzYrwNObJ0YofHyH09K2u+8+wbYytS4tibskAhX9E0uupUsc/Kd6vI+rdG4TuqTg1kE9GprHH1yzvHN8KfT2kntxy9foJ4hXZsZbs+kuvDp+ineGAQeCFKF4bBFBxhbjLERjE+K6j4tK090gzStVwMjh3ZOWuptwLHJMdVH1a2BbvnmdWRmjzrLVY12rZdDlWKgJqY71YvqwxtPMdz+wuUn4f5zu6S2cw2pXvujhx2LcZef6Hrf53ZrnqIE6SJNWpKVsS1tGhuvQxB2MkKhWym2lg1iE03JFnri+4Mlia4UWVQ/8+tX9cKrV/Y0bOO21G2iyyXeYRIdbeKzzVY9ApByXfWGtewniVO98VTLyTKVU2bfHQzcYtdKPoFY4bWRlS6r16tu6krMw0QV/x88OcrFFaplnDglmjwB5VahqzSuU93QegdSUeiVrym+LTk2vaFNbffFD52NUzo0Ttimfve1q3qZfs/upL6xXwec0SnPupHEfmTR178QEKhdzZ1SaeQyWslP0lXj3otuiOzPuyjjV60Vv5FS6EQ0hIhWElEhEY00+PxGIvqFiBYR0Y9E5N3zeorEDVsbC73fMfaKyQgZZeXWCtaGLVr6ilM49/pJKGQAaFE/uczAoC5Hue/YAVaj9/wfgovd9nr+ICdNs6JZRCm71HKyspDjcRx+mPDbQg/Mh05E2QDGARgKoAuAEQYK+10hxPFCiBMAPAHgac8ldUm8vkvchy4Stqv0P8Yb5TT33gH45s4zMKJ3ZT1yt9epUXar0YlglwULVEYlmE2EGqHda79j8vDxn4197n5f1la/rqlEPRuj73sVImjn7nJCrgeTlTIQID3pbUaz+jXw6pXmT3dRp3t+g6BFcIXMGdQbQKEQokgIUQJgAoDztQ2EEHs1b2sjRIX61AtX1XlmLhe36H9o03o10KlpXTx2Ubd4rLd+YtWOEb1bJ+375PYxl0mrRpWTNZU3K3sev6QbbhvQEX3aNU76TDbqQV9LRdbKyM3JSpqY1K/pqvLtnWfglv72a8Ia9b98zBCM+0Py5KnR6NfSTVK7iasmInx7Vz/H3zMjahZvuya18c9LuwfWv0wuhRuevewEPOXz7woyDr0lgI2a95uUbQkQ0c1EtAYxC/02ox0R0fVEVEBEBcXFxW7kdYzeEk8l9d8pquWcbdPZLf2PxkDF/14tJytezEpreV97ejv8+Lf+hlUf1YlJdQJYRZvB2aROddw1qJPh7552z5moJpHab/YzOjdLDhMFgONaVm7/t07RjjnfOA6/Y9O6+OvZxyT2KylPzWrZaNskOTphiMHNQ+/7d1NN043LxSr/INdoRfCQc/FJ+YH1Pf2e/pj61zM932+3/PquotLCgGdnkBBinBCiA4C/ARht0ma8EKKnEKJnXp47n7URo4d1wbDjm2PAseZukyQfuledW1zUqkI2m+x69MLjcM2p7fDXs4+JWzp5dapXFvJKqOVCyG+YqKzUvbbPq43Pbz4Vo4clZk7OGnkWfn5wsGHfWpGa16+JE1vbP2Lqf6r6tnXjWih8dGhS+/hjq8EYeXFD1d4o1ZdGbgujidOgbOEWDcxdRLk50bLQndLTo6qbKo1qV0O7JrU93We68MuHLvPMshmAdoHKfGWbGRMAvJiKUE5p0aBmUpzy//7SD9Vzs3HtmwUAjHzo/l88FUpou1lXl/epTC6qXysXo4cdi8FdmmHhhl0A5At5CSHQvVUDbNt3JGF77VQfSR2cdTkGitTKJeRm9PXiqK6shfcPik88G00sGo1/qtdTFsF0YnH63f1x3X8LsPK3fY72mZMmC93o3G9Rvwa27Dnsan992jXC3LU7bdvVs6n5ExZC4y92gcwZNB9ARyJqR0TVAAwHMFHbgIg6at4OA7DaOxHd0T6vToILwksLfXivyvub1cEvV10ukj70a09vj9aNa6F7q5hle87x1gkxbu5JZjpaSnfbtPld9xb4oyYD1u/aJOq4NqpdLe5eStfEYtFjw3D1qcYTi5YBSRZj6HX1RjP2HykDALx7XR88rLiAUlFi717XV6qdk0qj6eDPZ3awb5QC+lBhLYFVWxRClAG4BcAUAMsBfCCEWEpEY4joPKXZLUS0lIgWAbgLwJW+SOsCvS6NT4qmcO2MvbibZR0YFVW52fnQ9bRrUhvrxg4z9P16hYxEiaccoV7NHFx7WjvUVmP7defk8yN64MHfJVutRueuF09IRq6ssEwsPnLhcfFVqrRYXcdEhNsHdDRv4DGndGiCAZ2dR3fNv29gwntZg0UmGiudmIntlZhBlEeQMmeEEJOFEJ2EEB2EEI8q2x4QQkxUXt8uhOgqhDhBCNFfCLHUT6GdoNZ1qavLlvQsysXi4D/4uy5Y/ehQx1EubmXwu64KEWH0uV3QRRlTo/6yDPzaRu3sRsToxqDHSJEYuS0MXS4ejtXN/TskFQnr1bYRvrglee1Yu17vHNQJ718vZ/Hq+fzmU6XanXp0suXoZDjyXC400qJ+TcO+g8KpoeUUqzHlaosuGXP+cfj4zyejTWNl8qQybjGOm8UbZE4FIvLVBaCmtHdSlMnxFvVkVOwy4K482bho2OCumhoyFr8+YSEOW2nMufrUdrhJeSQ2y0g0uk/WyDVS6MkNvbyg7j67M77WhD1aXsgmH2p9/x2buqsgKWsBZ2tuevo8DT+pEALvXNsX8+4dgCFdm2GgRRBDOvDb0DKib3v75TJTIeMVeo3cbJzUJnkQ1RN5+t39MWvkWQmfOVmZKMgU4QHHNsWk207DpUroWPP67hdIUH/FkOMq/fZXn9oOZ3U+Cj/dP0g68UpWecoYR3cO6oTnRvTAMJO5BCOXS90auXj2shMSttWSLPX66U3GiVOpkjCXI9FeRs8Y+dulFbrmq03r1sCI3q0tS0BosauBY7UguDqndFS9GnjpjycFHqFiXmrBm2vaaPdqSDJXW/SJ1o1rJZWjlUmHV63iTi6tKa/o2qK+NxE7BvH5jWpXw2tX9XJcs+Pm/h3w6U2nJMn1zGXdUbtaNt65to/h93q3S7zx5mZn4bzuLUx/n5nv9oIeLXFz/8oJL738ZjXUe7T2JqzO6iavd/0ZIeMOXPzg2UnbysplLfTK/WdlER676Hh0bWH/dAcAo21KBphVxQSSx/euQceYtDRHnxCWCmbnTzOdYWS0iI3M3INWaR/b3DhXw2uqnEK3O+Vll5g7u2szTLnjDJx/QlKOVag5W6krfpbJ467MrUFd/MNM0d59dueEi1c9sS/skY+lY4bg1KObGFooF0iOpZpJq82aNZJBy/vX942v2dnvmLw0VNMz5pQOTTzZj1HiixpFomYVm5FqhU23XNGndcL7oJN3zCx0fQbqNQZPJeoYaiPerNCH0/r1ZJ+59S9tMDqUP90/SCpjUsVNdmHQdMtvgHVjh6W0j39e2h1vzFonnSgie+ra6Rl1P+d1b4HHLjpecq8x+ihK7qQ2DdG0Xg2s3X7A0ffd4PbByehiv7BHS3z6k3H6x8ihnfHVL1vjywRqFfaY87vigc8TYxTsFPqdAzvhpDYNccWrc52KbmkQePEk6eWN2Iv7Wr9OeWhYuxremLkOh0rNK7aqfcWfvtjl4g1W0Q0Na1dLPRknYK49rZ1jZeeUo+rVwD1Dkhf/0GMV5WLV3oz4RZHChdiiQU1FoTm7ok5s3QDXnS5X0Copo9bk9/+uu9x6tADw5CXdkrZNuL4vbjijPW7s1wGf33Ja3ELPziKcqVQPvUKTvKZOeGfbJDDdPrAjurWSc8GoPH7x8bj/3C6ulbZMpjKQmmV7YusGCauZyT6pGLnAVCmysgh/G9IZjQzcktrDHm+v7MqvkPwqp9BVMmnpMi2jz+0Sd0k4wY9HQKehoXbH5KlLu+OKvq09SiF3LpvTc8auff9j8rBsTLIv3Ej/G2Xi9m3fGKM0C2WrFnpuNuGNq3tj3dhhCTfduwYfg2Ob18PtA+SKnznhsl6t8afT2rmObOos6WO2sw3m3zcQ15/R3vCzbvkN8PrVlZO/9VPIXNWvfGaX5Kv6/tXjUe6Tz6/KKfRwpTaEDy9vdE5LuNv1nN+wFh654HhD5eaUDnm142GRMqTz9q9VNN3y62Pk0M4WrSspV2pNmFme9Wvm4qvbT8fRR9m7CtNt7sj0V79mru31m1e3umlQg95FetGJ7gqLxeLwE0uIWBkv71zbJx6+rMa+q8fKa6qcQlfJTPvcPepkXdN6qS9ArUfWGEnXij1A7EK8Z4i5otRbb0T254zZOpQCwLBuzQ1j/I0UgdaqPqvzUbixn9yNR42kCHKi3ukhfP2qXhjRu5XU93KzybVF1rBWLob3aoW8OtXxl0GdMO3uMw1vfK0tJtpV6lbPSbLQZZ9ws7NVhS7V3DFVTqGHLPs4NNw+oCN+/Fv/ygQsD1BDu/pIJlOEqXqsvvY7gTBc0pVlkLuGcX84EX/XlQyWUWJObnJtGsdKRtjVAJLB6ElNRhQiwjOXdccXt5yG9yRqvPTvfBQeu6ibtHvuPqWi6ARNNq1eCRtd48e1rB93m906oKPped7TYAEYq9+tflY9Ry5ihy10j/mjYiU5iWapCmRlJZfnTZVTjm6CdWOHoZvB6i/G5QDC89yUJB/BNhHmWKUuvOovVSfKbrOoz2KmLI5S0uuDCjE0Yu1jctFRF/bIx/H59XGyRXEqPUbjkByNRbjylLZYN3YY+mpCM5MUugMz/t3rdDkREl/NyqKkZq/8n/EC8UDijV09nmyhe8SooZ2x+tGhaavKxxhTv2ZuXGmpNDNYtzQo9BesjFr95++7Y8L1fePL4tXIzca6scNcTVJfeGLMbWKk6GRXmAoDE2+Rqy+Tym1L5snBLItWnxcgk22bk0VJax20lcx6VduXsYXuDX7XV2HkyMnOwjxN1b6Pbjw5werygjOPyTNd6k4W1e8tozRqV89x9BusnkhUvWLkcvlMsgiXUy46saXhEn6p0C2/gXSynlcYrrtroT9/fnBwPCxUxrbPzqKEEFE9xzSti1FDOxs+KeTEfeicWMRkKDec0R4923pftOiNq+Vr8pihVhb0yx1kdqOoUBWGQYMuLfxJI3/69yckbatVLRsHS8wTZmT4/i9n4mBJmWUbL6OrjFSl1fxM/Zq5cReszBxbjolCz6JYfPmUO2OF2qau3Bb7QPPTsogVOpPBpJq16jdqXQ8n/mAvUOOUMyFdon7N3JRivp3SqWnihPblfVrjlrOsY++HHNcMl56Uj7vPtq8vk5OdFVfI2ieo6ff0x5bdxqs+qTesSh86K3SGSRuqpdauSW3MuKd/0gLcXhALhTTW2EO6NsPrM9fhtI7e1H5xilaq28462vdSs+pC5wBwUY+WhvVTBplUchzeqzVmrN4ef6+vOjp6WBfbujHVc7LxpLKurx3ZGh+61kLPb1grIbBAXctWW6M/mxOLGCY4iGJFwPxSaGYWeJ/2jbFu7DB0bpaeKn1W3DX4GNwx0H6FrlTQLgd324COOK5lYumBefcOwJjzuxp+d1g38zDN/IY1Xa13oEU9Rg2VFagu7NFSUzfH/HtPXNINfxnUCb00oZB1qufg5v4d0MWn6otsoTOMAelIV1ArXzKJYcRGESNH1XMXAfXj386ybyRJs/o1Me++gcjNzsKEeRsAWOcJNK5THbfqQlZrVstOqgTqJWyhM4wFfjkaTj26MWpILrwRJJyIl4gaIae6TIyWPDQiXVMhbKEzVZoRvVtj/5HkCIybzuyAG95agPZ5dQy+lRq/PDRYOrOQkePJS7olLDbz8Z9PwYzVxZ72oU02UxODZLOb+7RvhGmripHvw1yMFlboTJXGrNTw2V2b+RaBU7dGZcSHarnlN/TvQn/2shMCX+7NLVPuOANHyuzDJi/tmbjQxEltGsaXe0sVo4nrCos4dCNuPKMDftetheWiLF7ACp1hAiQnOwsvXXGiZ8vfGXFBj2itqqUlrIvIPHVpdzzz3ar4Qu12ZGWR78ocYIXOMIGjXZi7KlM9Jwt/GexvNI1XHJ9fX3ph7XTCCp1hHKKvxJiJBJHQtPKRoenvVIIoJXexQmcYB3x562m++rvDghqOVxVuXpkEK3SGcYA+4SWd1K2eg30GETl+UCM3G2/9qTe6tgju9zLOYYXOMBHhh7vPxK6DJWnr7/SOxku5VVWiEJPPCp1hIkLjOtXRuI73SwQy1qilA5rUTW8ZYDdIKXQiGgLgXwCyAbwihBir+/wuANcCKANQDOAaIcR6j2VlGIZJG9PuPhO7D5aifV4dPHFJNww81rg4WJiwVehElA1gHIBBADYBmE9EE4UQyzTNfgLQUwhxkIj+DOAJAJf5ITDD+Mm//9AjIfGHqbq0aVwbbZSqyb/XJS6FFRkLvTeAQiFEEQAQ0QQA5wOIK3QhxFRN+zkArvBSSIZJF+d2axG0CAzjGplKBC0BbNS836RsM+NPAL4y+oCIrieiAiIqKC72ts4CwzBMVcfTaotEdAWAngCeNPpcCDFeCNFTCNEzL49n0BmGYbxExuWyGYDWgZSvbEuAiAYCuA9APyHEEW/EYxiGYWSRsdDnA+hIRO2IqBqA4QAmahsQUQ8ALwM4TwixzXsxGYZhGDtsFboQogzALQCmAFgO4AMhxFIiGkNE5ynNngRQB8CHRLSIiCaa7I5hGIbxCak4dCHEZACTddse0Lwe6LFcDMMwjEN4CTqGYZgMgRU6wzBMhkAioIozRFQMwG15gCYAtnsoTjph2YMhyrID0ZafZfeWNkIIw7jvwBR6KhBRgRCiZ9ByuIFlD4Yoyw5EW36WPX2wy4VhGCZDYIXOMAyTIURVoY8PWoAUYNmDIcqyA9GWn2VPE5H0oTMMwzDJRNVCZxiGYXSwQmcYhskQIqfQiWgIEa0kokIiGhmQDK2IaCoRLSOipUR0u7K9ERF9S0Srlf8Nle1ERM8pMi8mohM1+7pSab+aiK7UbD+JiH5RvvMcEZHHvyGbiH4ioi+V9+2IaK7S3/tKITYQUXXlfaHyeVvNPkYp21cS0dma7b4eIyJqQEQfEdEKIlpORCdHZeyJ6E7lnFlCRO8RUY2wjj0RvUZE24hoiWab7+Ns1ocHsj+pnDOLiehTImqg+czReLo5ZmlBCBGZP8TWNF0DoD2AagB+BtAlADmaAzhReV0XwCoAXRBbem+ksn0kgMeV1+cgtugHAegLYK6yvRGAIuV/Q+V1Q+WzeUpbUr471OPfcBeAdwF8qbz/AMBw5fVLAP6svL4JwEvK6+EA3lded1HGvzqAdspxyU7HMQLwJoBrldfVADSIwtgjtjDMWgA1NWN+VVjHHsAZAE4EsESzzfdxNuvDA9kHA8hRXj+ukd3xeDo9Zun6S1tHHl0QJwOYonk/CsCoEMj1OWJrrq4E0FzZ1hzASuX1ywBGaNqvVD4fAeBlzfaXlW3NAazQbE9o54G8+QC+B3AWgC+VC2q75mSPjzNiVTZPVl7nKO1IP/ZqO7+PEYD6iClF0m0P/dijcvWvRspYfgng7DCPPYC2SFSKvo+zWR+pyq777EIA7xiNk914urlevDr/7f6i5nJxuhye7yiPVD0AzAXQVAixVfnoVwDqMuFmcltt32Sw3SueBXAPgArlfWMAu0WsVLK+v7iMyud7lPZOf5NXtANQDOB1irmMXiGi2ojA2AshNgN4CsAGAFsRG8sFiM7YA+kZZ7M+vOQaVC6V6VR2N9dLWoiaQg8VRFQHwMcA7hBC7NV+JmK36NDFhBLRuQC2CSEWBC2LS3IQe5R+UQjRA8ABxB7L44R47BsitsB6OwAtANQGMCRQoVIgHePsRx9EdB+AMgDveLnfMBA1hS61HF46IKJcxJT5O0KIT5TNvxFRc+Xz5gDU1ZvM5Lbanm+w3QtOBXAeEa0DMAExt8u/ADQgIrU+vra/uIzK5/UB7HDxm7xiE4BNQoi5yvuPEFPwURj7gQDWCiGKhRClAD5B7HhEZeyB9IyzWR8pQ0RXATgXwOXKzcKN7Dvg/Jilh3T5drz4Q8w6K0LMwlEnKboGIAcB+C+AZ3Xbn0TiZM4TyuthSJwwmqdsb4SYP7ih8rcWQCPlM/2E0Tk+/I4zUTkp+iESJ3luUl7fjMRJng+U112ROJFUhNgkku/HCMAMAMcorx9Sxj30Yw+gD4ClAGop+34TwK1hHnsk+9B9H2ezPjyQfQiAZQDydO0cj6fTY5auv7R15JnAsdn0VYjNPt8XkAynIfYYuBjAIuXvHMR8Zd8DWA3gO82JSwDGKTL/AqCnZl/XAChU/q7WbO8JYInynX/Dh4kVJCr09soFVqicrNWV7TWU94XK5+01379PkW8lNJEgfh8jACcAKFDG/zNFUURi7AH8HcAKZf9vKUoklGMP4D3EfP2liD0Z/Skd42zWhweyFyLm31av2ZfcjqebY5aOP079ZxiGyRCi5kNnGIZhTGCFzjAMkyGwQmcYhskQWKEzDMNkCKzQGYZhMgRW6AzDMBkCK3SGYZgM4f8B6TPqGjKnqboAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y93JNYpPnRMB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "50e732d9-f228-4f94-ba79-18d5a97bbecc"
      },
      "source": [
        "plt.plot([i+1 for i in range((len(acc_list)))],acc_list)\n",
        "print(\"Accurancy:\")\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accurancy:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}