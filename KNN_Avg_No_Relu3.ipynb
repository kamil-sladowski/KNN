{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN_Avg_No_Relu3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ca80d06c45a14d6b99abb13fa8affc09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ae81782b371b474fb01b3947a9f669be",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cc031a2909f54ebab55c3f93d86c8950",
              "IPY_MODEL_3ea564fd404f4d8aaec6a29e283d8a82"
            ]
          }
        },
        "ae81782b371b474fb01b3947a9f669be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cc031a2909f54ebab55c3f93d86c8950": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1af51133ed654596a8d5d94a5866ea5f",
            "_dom_classes": [],
            "description": " 89%",
            "_model_name": "IntProgressModel",
            "bar_style": "danger",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 89,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4979ac6b77b04a00acb79aa361ccaf7d"
          }
        },
        "3ea564fd404f4d8aaec6a29e283d8a82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_360fd62faedd44b4b1052f615a28841a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 89/100 [13:11&lt;01:06,  6.01s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_70b9b79fc5354813ab418257454b4a4a"
          }
        },
        "1af51133ed654596a8d5d94a5866ea5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4979ac6b77b04a00acb79aa361ccaf7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "360fd62faedd44b4b1052f615a28841a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "70b9b79fc5354813ab418257454b4a4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamilo116/KNN/blob/master/KNN_Avg_No_Relu3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7ReM7FU-xs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import sys\n",
        "from random import shuffle\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms as transforms\n",
        "import timeit\n",
        "\n",
        "np.random.seed(4) \n",
        "torch.manual_seed(4) \n",
        "torch.cuda.manual_seed(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYIMZ8QyYewD",
        "colab_type": "code",
        "outputId": "06d1fef6-f49b-4160-ac3b-d87cb79240b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! git clone https://github.com/wang-chen/kervolution.git \n",
        "\n",
        "sys.path.append(\"kervolution/\")\n",
        "from kervolution import Kerv2d\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'kervolution' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvbKg4VJXKY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LIMIT_IMAGES_NUM = 500\n",
        "train_test_split_size = 0.2\n",
        "image_resize = (100, 100)\n",
        "batch_size = 64\n",
        "num_workers = 0\n",
        "\n",
        "in_channels = 3\n",
        "out_channels_1 = 8\n",
        "out_channels_2 = 16\n",
        "out_channels_3 = 32\n",
        "out_channels_4 = 48\n",
        "out_channels_5 = 64\n",
        "out_channels_6 = 128\n",
        "\n",
        "kernel_size = 3\n",
        "padding_1 = 1\n",
        "num_epochs = 80\n",
        "\n",
        "learning_rate = 0.0005\n",
        "weight_decay = 0\n",
        "\n",
        "MALIGNANT_DATASET = '/content/drive/My Drive/Colab_data/malignant/malignant/'\n",
        "BENIGN_DATASET = '/content/drive/My Drive/Colab_data/benign/benign/'\n",
        "DATA_FOLDER = '/content/drive/My Drive/Colab_data/'\n",
        "model_backup_path = os.path.join(DATA_FOLDER, 'backup_model') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMOHez_kHZD6",
        "colab_type": "code",
        "outputId": "0d1ad90f-b07e-431b-8031-4817953361a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b8P1NdXfVdX",
        "colab_type": "code",
        "outputId": "e8a07d14-35fd-4dcb-e7a0-166d1c8b0875",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "benign_file_list = sorted(os.listdir(BENIGN_DATASET))\n",
        "malignant_file_list = sorted(os.listdir(MALIGNANT_DATASET))\n",
        "shuffle(benign_file_list)\n",
        "shuffle(malignant_file_list)\n",
        "benign_file_list = benign_file_list[:LIMIT_IMAGES_NUM]\n",
        "malignant_file_list = malignant_file_list[:LIMIT_IMAGES_NUM]\n",
        "\n",
        "print(f\"Number of benign {len(benign_file_list)} images\")\n",
        "print(f\"Number of malignant {len(malignant_file_list)} images\")\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize(image_resize),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of benign 500 images\n",
            "Number of malignant 500 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGDQfal74BLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "benign_dict = {filename: 0 for filename in benign_file_list}\n",
        "malignant_dict = {filename: 1 for filename in malignant_file_list}\n",
        "img_class_dict = {**benign_dict , **malignant_dict}\n",
        "labeled_data = pd.Series(img_class_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvAAOqmVfVll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IsicDataset(Dataset):\n",
        "    def __init__(self, data_folder, labeled_data, \n",
        "                 transform=transforms.Compose([transforms.ToTensor()])):\n",
        "        self.labeled_data = labeled_data\n",
        "        self.transform = transform\n",
        "        self.data_folder = data_folder\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labeled_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        label = self.labeled_data[index]\n",
        "        if label == 0:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"benign\", \"benign\", index ))\n",
        "        else:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"malignant\", \"malignant\", index ))\n",
        "        image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "    @property\n",
        "    def labels(self):\n",
        "      return self.labeled_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSuYqjLAYrWA",
        "colab_type": "code",
        "outputId": "96720497-bba2-4469-c9df-c7e2dfae17d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        " \n",
        "dataset = IsicDataset(DATA_FOLDER, labeled_data, transform=data_transforms)\n",
        "print(dataset.labels)\n",
        "\n",
        "X_train, X_test = train_test_split(dataset.labels, test_size=train_test_split_size)\n",
        "print(\"number of training data: \",len(X_train))\n",
        "print(\"number of testing  data: \",len(X_test))\n",
        "\n",
        "train_sampler = SubsetRandomSampler(list(X_train.index))\n",
        "valid_sampler = SubsetRandomSampler(list(X_test.index))\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ISIC_0000822.jpeg    0\n",
            "ISIC_0000053.jpeg    0\n",
            "ISIC_0001104.jpeg    0\n",
            "ISIC_0000135.jpeg    0\n",
            "ISIC_0000092.jpeg    0\n",
            "                    ..\n",
            "ISIC_0014857.jpeg    1\n",
            "ISIC_0010023.jpeg    1\n",
            "ISIC_0011616.jpeg    1\n",
            "ISIC_0014061.jpeg    1\n",
            "ISIC_0026754.jpg     1\n",
            "Length: 1000, dtype: int64\n",
            "number of training data:  800\n",
            "number of testing  data:  200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e8nFBR6Yug5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "def train(model, train_loader ,loss_fn, optimizer, num_epochs=1, starting_from_epoch=1):\n",
        "    total_loss =0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
        "        model.train()\n",
        "\n",
        "        for t, (x, y) in enumerate(train_loader):\n",
        "            x_var = Variable(x.type(gpu_dtype))\n",
        "            y_var = Variable(y.type(gpu_dtype).long())\n",
        "            scores = model(x_var)\n",
        "            loss = loss_fn(scores, y_var)\n",
        "            total_loss += loss.data\n",
        "            \n",
        "            if (t + 1) % print_every == 0:\n",
        "                avg_loss = total_loss/print_every\n",
        "                print('t = %d, avg_loss = %.4f' % (t + 1, avg_loss) )\n",
        "                avg_loss_list.append(avg_loss)\n",
        "                total_loss = 0\n",
        "                \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        acc = check_accuracy(model_gpu, valid_loader)\n",
        "        print('acc = %f' %(acc))\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model_gpu.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            }, model_backup_path)\n",
        "            \n",
        "def check_accuracy(model, loader):\n",
        "    print('Checking accuracy on test set')   \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval() \n",
        "    for x, y in loader:\n",
        "        x_var = Variable(x.type(gpu_dtype))\n",
        "\n",
        "        scores = model(x_var)\n",
        "        _, preds = scores.data.cpu().max(1)\n",
        "        num_correct += (preds == y).sum()\n",
        "        num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    acc_list.append(acc)\n",
        "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "    return acc\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggvpMu36Yw2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.size()\n",
        "        return x.view(N, -1)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgmexhBRZAK6",
        "colab_type": "code",
        "outputId": "bfcfa99e-f0f9-4f24-fb8a-47a0877f879a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ca80d06c45a14d6b99abb13fa8affc09",
            "ae81782b371b474fb01b3947a9f669be",
            "cc031a2909f54ebab55c3f93d86c8950",
            "3ea564fd404f4d8aaec6a29e283d8a82",
            "1af51133ed654596a8d5d94a5866ea5f",
            "4979ac6b77b04a00acb79aa361ccaf7d",
            "360fd62faedd44b4b1052f615a28841a",
            "70b9b79fc5354813ab418257454b4a4a"
          ]
        }
      },
      "source": [
        "gpu_dtype = torch.cuda.FloatTensor\n",
        "\n",
        "print_every = 1\n",
        "\n",
        "\n",
        "'''\n",
        "Kerv2d\n",
        "kervolution with following options:\n",
        "kernel_type: [linear, polynomial, gaussian, etc.]\n",
        "default is convolution:\n",
        "          kernel_type --> linear,\n",
        "balance, power, gamma is valid only when the kernel_type is specified\n",
        "if learnable_kernel = True,  they just be the initial value of learable parameters\n",
        "if learnable_kernel = False, they are the value of kernel_type's parameter\n",
        "the parameter [power] cannot be learned due to integer limitation\n",
        "dilation (int or tuple, optional): Spacing between kernel\n",
        "elements. Default: 1\n",
        "groups (int, optional): Number of blocked connections from input\n",
        "channels to output channels. Default: 1\n",
        "bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n",
        "kernel_type (str), Default: 'linear'\n",
        "learnable_kernel (bool): Learnable kernel parameters.  Default: False \n",
        "balance: 0, 1\n",
        "power: 3, 4, 5\n",
        "gamma:\n",
        "'''\n",
        "\n",
        "\n",
        "model_base = nn.Sequential( \n",
        "                nn.Kerv2d(in_channels , out_channels_1, padding=padding_1, dilation=1, groups=1, bias=True, \n",
        "                          kernel_type='polynomial', kernel_size=kernel_size, learnable_kernel=True,\n",
        "                          kernel_regularizer=True, stride=1, balance=1, power=5, gamma=1\n",
        "                          ),\n",
        "                nn.BatchNorm2d(out_channels_1),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_1 , out_channels_2, padding= padding_1, kernel_size=kernel_size, stride=1), \n",
        "                nn.BatchNorm2d(out_channels_2),\n",
        "                nn.AvgPool2d(2, stride=2), \n",
        "                nn.Conv2d(out_channels_2 , out_channels_3, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.BatchNorm2d(out_channels_3),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_3 , out_channels_4, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.BatchNorm2d(out_channels_4),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_4 , out_channels_5, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.BatchNorm2d(out_channels_5),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_5 , out_channels_6, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.BatchNorm2d(out_channels_6),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Dropout(0.5),\n",
        "                Flatten(),\n",
        "                nn.Linear(128,64),\n",
        "                nn.Linear(64,2)\n",
        "            )\n",
        "model_gpu = model_base.type(gpu_dtype)\n",
        "print(model_gpu)\n",
        "loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) \n",
        "\n",
        "! pip install torch-lr-finder -v --global-option=\"amp\"\n",
        "from torch_lr_finder import LRFinder\n",
        "\n",
        "lr_finder = LRFinder(model_gpu, optimizer, loss_fn, device=\"cuda\")\n",
        "\n",
        "lr_finder.range_test(train_loader, end_lr=1, num_iter=100, start_lr=1e-05)\n",
        "lr_finder.plot() \n",
        " \n",
        "\n",
        "#train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs)\n",
        "#check_accuracy(model_gpu, valid_loader)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Kerv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (3): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (6): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (8): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (9): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (10): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (11): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (12): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (13): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (14): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (15): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (18): Dropout(p=0.5, inplace=False)\n",
            "  (19): Flatten()\n",
            "  (20): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (21): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n",
            "/usr/local/lib/python3.6/dist-packages/pip/_internal/commands/install.py:283: UserWarning: Disabling all use of wheels due to the use of --build-options / --global-options / --install-options.\n",
            "  cmdoptions.check_install_build_global(options)\n",
            "Created temporary directory: /tmp/pip-ephem-wheel-cache-xm2qn9rv\n",
            "Created temporary directory: /tmp/pip-req-tracker-bhkjr4ga\n",
            "Created requirements tracker '/tmp/pip-req-tracker-bhkjr4ga'\n",
            "Created temporary directory: /tmp/pip-install-ju1uypsy\n",
            "Requirement already satisfied: torch-lr-finder in /usr/local/lib/python3.6/dist-packages (0.1.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from torch-lr-finder) (3.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch-lr-finder) (1.18.2)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from torch-lr-finder) (1.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torch-lr-finder) (4.38.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->torch-lr-finder) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->torch-lr-finder) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->torch-lr-finder) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->torch-lr-finder) (2.4.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->torch-lr-finder) (1.12.0)\n",
            "Cleaning up...\n",
            "Removed build tracker '/tmp/pip-req-tracker-bhkjr4ga'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ca80d06c45a14d6b99abb13fa8affc09",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Stopping early, the loss has diverged\n",
            "Learning rate search finished. See the graph with {finder_name}.plot()\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f9b6e02be48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hm3h_Kyyp_6h",
        "colab_type": "code",
        "outputId": "8b97f747-5e06-4e37-8c3b-c6a91ca213e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "check_accuracy(model_gpu, valid_loader)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking accuracy on test set\n",
            "Got 107 / 200 correct (53.50)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.535"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzuX5gLEeJfE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "outputId": "befc3788-a767-40d9-bdf0-e27fc24b2041"
      },
      "source": [
        "def retry_from_backup():\n",
        "  model_gpu = model_base.type(gpu_dtype)\n",
        "  print(model_gpu)\n",
        "  loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) \n",
        "\n",
        "\n",
        "\n",
        "  checkpoint = torch.load(model_backup_path)\n",
        "  model_gpu.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  epoch = checkpoint['epoch']\n",
        "  loss = checkpoint['loss']\n",
        "  print(\"starting from epoch: \" + str(epoch))\n",
        "  print(\"starting from loss: \" + str(loss))\n",
        "  print(checkpoint['model_state_dict'])\n",
        "  print(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "  train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs, starting_from_epoch=epoch)\n",
        "  check_accuracy(model_gpu, valid_loader)\n",
        "#retry_from_backup()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-f6961f7a8651>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def retry_from_backup()\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDn-2g-TLY3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot([print_every*batch_size*(i+1) for i in range((len(avg_loss_list)))],avg_loss_list)\n",
        "print(\"Loss:\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGer6hJv7-zR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot([i+1 for i in range((len(acc_list)))],acc_list)\n",
        "print(\"Accurancy:\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBTReWHxz4Ml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}