{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN_Avg_No_Relu3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamilo116/KNN/blob/master/KNN_Avg_No_Relu3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7ReM7FU-xs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import sys\n",
        "from random import shuffle\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms as transforms\n",
        "import timeit\n",
        "\n",
        "np.random.seed(4) \n",
        "torch.manual_seed(4) \n",
        "torch.cuda.manual_seed(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYIMZ8QyYewD",
        "colab_type": "code",
        "outputId": "dee306ed-65b9-43c3-8d32-2a5b710fe398",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "! git clone https://github.com/wang-chen/kervolution.git \n",
        "\n",
        "sys.path.append(\"kervolution/\")\n",
        "from kervolution import Kerv2d\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'kervolution'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects:  16% (1/6)\u001b[K\rremote: Counting objects:  33% (2/6)\u001b[K\rremote: Counting objects:  50% (3/6)\u001b[K\rremote: Counting objects:  66% (4/6)\u001b[K\rremote: Counting objects:  83% (5/6)\u001b[K\rremote: Counting objects: 100% (6/6)\u001b[K\rremote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects:  16% (1/6)\u001b[K\rremote: Compressing objects:  33% (2/6)\u001b[K\rremote: Compressing objects:  50% (3/6)\u001b[K\rremote: Compressing objects:  66% (4/6)\u001b[K\rremote: Compressing objects:  83% (5/6)\u001b[K\rremote: Compressing objects: 100% (6/6)\u001b[K\rremote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 53 (delta 2), reused 0 (delta 0), pack-reused 47\u001b[K\n",
            "Unpacking objects:   1% (1/53)   \rUnpacking objects:   3% (2/53)   \rUnpacking objects:   5% (3/53)   \rUnpacking objects:   7% (4/53)   \rUnpacking objects:   9% (5/53)   \rUnpacking objects:  11% (6/53)   \rUnpacking objects:  13% (7/53)   \rUnpacking objects:  15% (8/53)   \rUnpacking objects:  16% (9/53)   \rUnpacking objects:  18% (10/53)   \rUnpacking objects:  20% (11/53)   \rUnpacking objects:  22% (12/53)   \rUnpacking objects:  24% (13/53)   \rUnpacking objects:  26% (14/53)   \rUnpacking objects:  28% (15/53)   \rUnpacking objects:  30% (16/53)   \rUnpacking objects:  32% (17/53)   \rUnpacking objects:  33% (18/53)   \rUnpacking objects:  35% (19/53)   \rUnpacking objects:  37% (20/53)   \rUnpacking objects:  39% (21/53)   \rUnpacking objects:  41% (22/53)   \rUnpacking objects:  43% (23/53)   \rUnpacking objects:  45% (24/53)   \rUnpacking objects:  47% (25/53)   \rUnpacking objects:  49% (26/53)   \rUnpacking objects:  50% (27/53)   \rUnpacking objects:  52% (28/53)   \rUnpacking objects:  54% (29/53)   \rUnpacking objects:  56% (30/53)   \rUnpacking objects:  58% (31/53)   \rUnpacking objects:  60% (32/53)   \rUnpacking objects:  62% (33/53)   \rUnpacking objects:  64% (34/53)   \rUnpacking objects:  66% (35/53)   \rUnpacking objects:  67% (36/53)   \rUnpacking objects:  69% (37/53)   \rUnpacking objects:  71% (38/53)   \rUnpacking objects:  73% (39/53)   \rUnpacking objects:  75% (40/53)   \rUnpacking objects:  77% (41/53)   \rUnpacking objects:  79% (42/53)   \rUnpacking objects:  81% (43/53)   \rUnpacking objects:  83% (44/53)   \rUnpacking objects:  84% (45/53)   \rUnpacking objects:  86% (46/53)   \rUnpacking objects:  88% (47/53)   \rUnpacking objects:  90% (48/53)   \rUnpacking objects:  92% (49/53)   \rUnpacking objects:  94% (50/53)   \rUnpacking objects:  96% (51/53)   \rUnpacking objects:  98% (52/53)   \rUnpacking objects: 100% (53/53)   \rUnpacking objects: 100% (53/53), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvbKg4VJXKY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LIMIT_IMAGES_NUM = 500\n",
        "train_test_split_size = 0.2\n",
        "image_resize = (100, 100)\n",
        "batch_size = 64\n",
        "num_workers = 0\n",
        "\n",
        "in_channels = 3\n",
        "out_channels_1 = 16\n",
        "out_channels_2 = 24\n",
        "out_channels_3 = 32\n",
        "out_channels_4 = 48\n",
        "out_channels_5 = 64\n",
        "out_channels_6 = 128\n",
        "\n",
        "kernel_size = 3\n",
        "padding_1 = 1\n",
        "num_epochs = 80\n",
        "\n",
        "learning_rate = 0.0001\n",
        "weight_decay = 0.1\n",
        "\n",
        "MALIGNANT_DATASET = '/content/drive/My Drive/Colab_data/malignant/malignant/'\n",
        "BENIGN_DATASET = '/content/drive/My Drive/Colab_data/benign/benign/'\n",
        "DATA_FOLDER = '/content/drive/My Drive/Colab_data/'\n",
        "model_backup_path = os.path.join(DATA_FOLDER, 'backup_model_3') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMOHez_kHZD6",
        "colab_type": "code",
        "outputId": "52f5793d-4bd5-45ac-e0ed-55d941815cb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b8P1NdXfVdX",
        "colab_type": "code",
        "outputId": "19c1edb1-13bc-4c4f-b918-901d61e916e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "benign_file_list = sorted(os.listdir(BENIGN_DATASET))\n",
        "malignant_file_list = sorted(os.listdir(MALIGNANT_DATASET))\n",
        "shuffle(benign_file_list)\n",
        "shuffle(malignant_file_list)\n",
        "benign_file_list = benign_file_list[:LIMIT_IMAGES_NUM]\n",
        "malignant_file_list = malignant_file_list[:LIMIT_IMAGES_NUM]\n",
        "\n",
        "print(f\"Number of benign {len(benign_file_list)} images\")\n",
        "print(f\"Number of malignant {len(malignant_file_list)} images\")\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize(image_resize),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of benign 500 images\n",
            "Number of malignant 500 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGDQfal74BLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "benign_dict = {filename: 0 for filename in benign_file_list}\n",
        "malignant_dict = {filename: 1 for filename in malignant_file_list}\n",
        "img_class_dict = {**benign_dict , **malignant_dict}\n",
        "labeled_data = pd.Series(img_class_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvAAOqmVfVll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IsicDataset(Dataset):\n",
        "    def __init__(self, data_folder, labeled_data, \n",
        "                 transform=transforms.Compose([transforms.ToTensor()])):\n",
        "        self.labeled_data = labeled_data\n",
        "        self.transform = transform\n",
        "        self.data_folder = data_folder\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labeled_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        label = self.labeled_data[index]\n",
        "        if label == 0:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"benign\", \"benign\", index ))\n",
        "        else:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"malignant\", \"malignant\", index ))\n",
        "        image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "    @property\n",
        "    def labels(self):\n",
        "      return self.labeled_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSuYqjLAYrWA",
        "colab_type": "code",
        "outputId": "ca2b42fa-d015-4b2b-d0d1-c1b22f081c82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        }
      },
      "source": [
        " \n",
        "dataset = IsicDataset(DATA_FOLDER, labeled_data, transform=data_transforms)\n",
        "print(dataset.labels)\n",
        "\n",
        "X_train, X_test = train_test_split(dataset.labels, test_size=train_test_split_size)\n",
        "print(\"number of training data: \",len(X_train))\n",
        "print(\"number of testing  data: \",len(X_test))\n",
        "\n",
        "train_sampler = SubsetRandomSampler(list(X_train.index))\n",
        "valid_sampler = SubsetRandomSampler(list(X_test.index))\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ISIC_0001291.jpeg    0\n",
            "ISIC_0002751.jpeg    0\n",
            "ISIC_0000506.jpeg    0\n",
            "ISIC_0000396.jpeg    0\n",
            "ISIC_0000115.jpeg    0\n",
            "                    ..\n",
            "ISIC_0025709.jpg     1\n",
            "ISIC_0014541.jpeg    1\n",
            "ISIC_0012758.jpeg    1\n",
            "ISIC_0026735.jpg     1\n",
            "ISIC_0024972.jpg     1\n",
            "Length: 1000, dtype: int64\n",
            "number of training data:  800\n",
            "number of testing  data:  200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e8nFBR6Yug5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "def train(model, train_loader ,loss_fn, optimizer, num_epochs=1, starting_from_epoch=1):\n",
        "    total_loss =0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
        "        model.train()\n",
        "\n",
        "        for t, (x, y) in enumerate(train_loader):\n",
        "            x_var = Variable(x.type(gpu_dtype))\n",
        "            y_var = Variable(y.type(gpu_dtype).long())\n",
        "            scores = model(x_var)\n",
        "            loss = loss_fn(scores, y_var)\n",
        "            total_loss += loss.data\n",
        "            \n",
        "            if (t + 1) % print_every == 0:\n",
        "                avg_loss = total_loss/print_every\n",
        "                print('t = %d, avg_loss = %.4f' % (t + 1, avg_loss) )\n",
        "                avg_loss_list.append(avg_loss)\n",
        "                total_loss = 0\n",
        "                \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        acc = check_accuracy(model_gpu, valid_loader)\n",
        "        print('acc = %f' %(acc))\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model_gpu.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            }, model_backup_path)\n",
        "            \n",
        "def check_accuracy(model, loader):\n",
        "    print('Checking accuracy on test set')   \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval() \n",
        "    for x, y in loader:\n",
        "        x_var = Variable(x.type(gpu_dtype))\n",
        "\n",
        "        scores = model(x_var)\n",
        "        _, preds = scores.data.cpu().max(1)\n",
        "        num_correct += (preds == y).sum()\n",
        "        num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    acc_list.append(acc)\n",
        "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "    return acc\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggvpMu36Yw2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.size()\n",
        "        return x.view(N, -1)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgmexhBRZAK6",
        "colab_type": "code",
        "outputId": "bd8f4a8b-e0d6-4c64-9bd1-d13d0e15bf1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "gpu_dtype = torch.cuda.FloatTensor\n",
        "\n",
        "print_every = 1\n",
        "\n",
        "\n",
        "'''\n",
        "Kerv2d\n",
        "kervolution with following options:\n",
        "kernel_type: [linear, polynomial, gaussian, etc.]\n",
        "default is convolution:\n",
        "          kernel_type --> linear,\n",
        "balance, power, gamma is valid only when the kernel_type is specified\n",
        "if learnable_kernel = True,  they just be the initial value of learable parameters\n",
        "if learnable_kernel = False, they are the value of kernel_type's parameter\n",
        "the parameter [power] cannot be learned due to integer limitation\n",
        "dilation (int or tuple, optional): Spacing between kernel\n",
        "elements. Default: 1\n",
        "groups (int, optional): Number of blocked connections from input\n",
        "channels to output channels. Default: 1\n",
        "bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n",
        "kernel_type (str), Default: 'linear'\n",
        "learnable_kernel (bool): Learnable kernel parameters.  Default: False \n",
        "balance: 0, 1\n",
        "power: 3, 4, 5\n",
        "gamma:\n",
        "'''\n",
        "\n",
        "\n",
        "model_base = nn.Sequential( \n",
        "                nn.Kerv2d(in_channels , out_channels_1, padding=padding_1, dilation=1, groups=1, bias=True, \n",
        "                          kernel_type='polynomial', kernel_size=kernel_size, learnable_kernel=True,\n",
        "                          kernel_regularizer=True, stride=1, balance=1, power=3, gamma=1\n",
        "                          ),\n",
        "                \n",
        "                nn.BatchNorm2d(out_channels_1),\n",
        "                nn.Conv2d(out_channels_1 , out_channels_2, padding= padding_1, kernel_size=kernel_size, stride=1), \n",
        "                nn.Dropout(0.1),\n",
        "                nn.BatchNorm2d(out_channels_2),\n",
        "                nn.AvgPool2d(2, stride=2), \n",
        "                \n",
        "                #nn.Conv2d(out_channels_2 , out_channels_3, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.Kerv2d(out_channels_2 , out_channels_3, padding=padding_1, dilation=1, groups=1, bias=True, \n",
        "                          kernel_type='polynomial', kernel_size=kernel_size, learnable_kernel=True,\n",
        "                          kernel_regularizer=True, stride=1, balance=1, power=3, gamma=1\n",
        "                          ),\n",
        "                \n",
        "                nn.BatchNorm2d(out_channels_3),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_3 , out_channels_4, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.BatchNorm2d(out_channels_4),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_4 , out_channels_5, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.BatchNorm2d(out_channels_5),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_5 , out_channels_6, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.BatchNorm2d(out_channels_6),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                Flatten(),\n",
        "                nn.Dropout(0.5),\n",
        "                nn.Linear(1152,64),\n",
        "                nn.Linear(64,2)\n",
        "            )\n",
        "model_gpu = model_base.type(gpu_dtype)\n",
        "print(model_gpu)\n",
        "loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) \n",
        "\n",
        "train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs)\n",
        "check_accuracy(model_gpu, valid_loader)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Kerv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): Conv2d(16, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (3): Dropout(p=0.1, inplace=False)\n",
            "  (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (6): Kerv2d(24, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (8): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (9): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (10): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (11): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (12): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (13): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (14): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (15): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (18): Flatten()\n",
            "  (19): Dropout(p=0.5, inplace=False)\n",
            "  (20): Linear(in_features=1152, out_features=64, bias=True)\n",
            "  (21): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n",
            "Starting epoch 1 / 80\n",
            "t = 1, avg_loss = 0.7113\n",
            "t = 2, avg_loss = 0.6935\n",
            "t = 3, avg_loss = 0.6552\n",
            "t = 4, avg_loss = 0.5942\n",
            "t = 5, avg_loss = 0.6489\n",
            "t = 6, avg_loss = 0.5636\n",
            "t = 7, avg_loss = 0.5649\n",
            "t = 8, avg_loss = 0.5473\n",
            "t = 9, avg_loss = 0.6325\n",
            "t = 10, avg_loss = 0.7391\n",
            "t = 11, avg_loss = 0.7498\n",
            "t = 12, avg_loss = 0.6227\n",
            "t = 13, avg_loss = 0.6563\n",
            "Checking accuracy on test set\n",
            "Got 100 / 200 correct (50.00)\n",
            "acc = 0.500000\n",
            "Starting epoch 2 / 80\n",
            "t = 1, avg_loss = 0.5841\n",
            "t = 2, avg_loss = 0.6675\n",
            "t = 3, avg_loss = 0.6486\n",
            "t = 4, avg_loss = 0.7159\n",
            "t = 5, avg_loss = 0.5202\n",
            "t = 6, avg_loss = 0.6248\n",
            "t = 7, avg_loss = 0.5834\n",
            "t = 8, avg_loss = 0.5768\n",
            "t = 9, avg_loss = 0.5992\n",
            "t = 10, avg_loss = 0.5592\n",
            "t = 11, avg_loss = 0.5228\n",
            "t = 12, avg_loss = 0.6128\n",
            "t = 13, avg_loss = 0.7143\n",
            "Checking accuracy on test set\n",
            "Got 115 / 200 correct (57.50)\n",
            "acc = 0.575000\n",
            "Starting epoch 3 / 80\n",
            "t = 1, avg_loss = 0.5219\n",
            "t = 2, avg_loss = 0.5367\n",
            "t = 3, avg_loss = 0.5322\n",
            "t = 4, avg_loss = 0.5934\n",
            "t = 5, avg_loss = 0.5456\n",
            "t = 6, avg_loss = 0.5398\n",
            "t = 7, avg_loss = 0.6418\n",
            "t = 8, avg_loss = 0.6404\n",
            "t = 9, avg_loss = 0.6455\n",
            "t = 10, avg_loss = 0.6155\n",
            "t = 11, avg_loss = 0.5637\n",
            "t = 12, avg_loss = 0.4856\n",
            "t = 13, avg_loss = 0.6621\n",
            "Checking accuracy on test set\n",
            "Got 123 / 200 correct (61.50)\n",
            "acc = 0.615000\n",
            "Starting epoch 4 / 80\n",
            "t = 1, avg_loss = 0.4497\n",
            "t = 2, avg_loss = 0.5519\n",
            "t = 3, avg_loss = 0.5161\n",
            "t = 4, avg_loss = 0.6760\n",
            "t = 5, avg_loss = 0.4901\n",
            "t = 6, avg_loss = 0.5587\n",
            "t = 7, avg_loss = 0.6095\n",
            "t = 8, avg_loss = 0.5058\n",
            "t = 9, avg_loss = 0.4874\n",
            "t = 10, avg_loss = 0.5228\n",
            "t = 11, avg_loss = 0.5172\n",
            "t = 12, avg_loss = 0.6237\n",
            "t = 13, avg_loss = 0.6603\n",
            "Checking accuracy on test set\n",
            "Got 137 / 200 correct (68.50)\n",
            "acc = 0.685000\n",
            "Starting epoch 5 / 80\n",
            "t = 1, avg_loss = 0.5552\n",
            "t = 2, avg_loss = 0.4606\n",
            "t = 3, avg_loss = 0.5253\n",
            "t = 4, avg_loss = 0.5196\n",
            "t = 5, avg_loss = 0.5375\n",
            "t = 6, avg_loss = 0.5165\n",
            "t = 7, avg_loss = 0.5596\n",
            "t = 8, avg_loss = 0.6426\n",
            "t = 9, avg_loss = 0.5094\n",
            "t = 10, avg_loss = 0.5219\n",
            "t = 11, avg_loss = 0.4457\n",
            "t = 12, avg_loss = 0.5704\n",
            "t = 13, avg_loss = 0.4780\n",
            "Checking accuracy on test set\n",
            "Got 140 / 200 correct (70.00)\n",
            "acc = 0.700000\n",
            "Starting epoch 6 / 80\n",
            "t = 1, avg_loss = 0.4842\n",
            "t = 2, avg_loss = 0.5055\n",
            "t = 3, avg_loss = 0.4679\n",
            "t = 4, avg_loss = 0.6598\n",
            "t = 5, avg_loss = 0.5794\n",
            "t = 6, avg_loss = 0.4328\n",
            "t = 7, avg_loss = 0.5019\n",
            "t = 8, avg_loss = 0.6557\n",
            "t = 9, avg_loss = 0.4515\n",
            "t = 10, avg_loss = 0.4732\n",
            "t = 11, avg_loss = 0.6183\n",
            "t = 12, avg_loss = 0.5318\n",
            "t = 13, avg_loss = 0.5464\n",
            "Checking accuracy on test set\n",
            "Got 144 / 200 correct (72.00)\n",
            "acc = 0.720000\n",
            "Starting epoch 7 / 80\n",
            "t = 1, avg_loss = 0.6102\n",
            "t = 2, avg_loss = 0.4122\n",
            "t = 3, avg_loss = 0.5720\n",
            "t = 4, avg_loss = 0.5094\n",
            "t = 5, avg_loss = 0.4206\n",
            "t = 6, avg_loss = 0.4744\n",
            "t = 7, avg_loss = 0.3370\n",
            "t = 8, avg_loss = 0.6066\n",
            "t = 9, avg_loss = 0.8123\n",
            "t = 10, avg_loss = 0.4976\n",
            "t = 11, avg_loss = 0.6474\n",
            "t = 12, avg_loss = 0.5881\n",
            "t = 13, avg_loss = 0.6362\n",
            "Checking accuracy on test set\n",
            "Got 144 / 200 correct (72.00)\n",
            "acc = 0.720000\n",
            "Starting epoch 8 / 80\n",
            "t = 1, avg_loss = 0.4869\n",
            "t = 2, avg_loss = 0.4005\n",
            "t = 3, avg_loss = 0.4665\n",
            "t = 4, avg_loss = 0.4551\n",
            "t = 5, avg_loss = 0.5643\n",
            "t = 6, avg_loss = 0.4839\n",
            "t = 7, avg_loss = 0.5767\n",
            "t = 8, avg_loss = 0.5862\n",
            "t = 9, avg_loss = 0.5090\n",
            "t = 10, avg_loss = 0.4889\n",
            "t = 11, avg_loss = 0.4468\n",
            "t = 12, avg_loss = 0.4025\n",
            "t = 13, avg_loss = 0.5432\n",
            "Checking accuracy on test set\n",
            "Got 145 / 200 correct (72.50)\n",
            "acc = 0.725000\n",
            "Starting epoch 9 / 80\n",
            "t = 1, avg_loss = 0.4851\n",
            "t = 2, avg_loss = 0.4646\n",
            "t = 3, avg_loss = 0.4859\n",
            "t = 4, avg_loss = 0.4928\n",
            "t = 5, avg_loss = 0.4956\n",
            "t = 6, avg_loss = 0.4126\n",
            "t = 7, avg_loss = 0.5241\n",
            "t = 8, avg_loss = 0.4506\n",
            "t = 9, avg_loss = 0.4852\n",
            "t = 10, avg_loss = 0.6477\n",
            "t = 11, avg_loss = 0.4873\n",
            "t = 12, avg_loss = 0.4844\n",
            "t = 13, avg_loss = 0.5938\n",
            "Checking accuracy on test set\n",
            "Got 151 / 200 correct (75.50)\n",
            "acc = 0.755000\n",
            "Starting epoch 10 / 80\n",
            "t = 1, avg_loss = 0.5285\n",
            "t = 2, avg_loss = 0.4947\n",
            "t = 3, avg_loss = 0.4839\n",
            "t = 4, avg_loss = 0.5823\n",
            "t = 5, avg_loss = 0.6083\n",
            "t = 6, avg_loss = 0.4501\n",
            "t = 7, avg_loss = 0.5494\n",
            "t = 8, avg_loss = 0.4791\n",
            "t = 9, avg_loss = 0.4464\n",
            "t = 10, avg_loss = 0.4945\n",
            "t = 11, avg_loss = 0.5407\n",
            "t = 12, avg_loss = 0.4880\n",
            "t = 13, avg_loss = 0.5059\n",
            "Checking accuracy on test set\n",
            "Got 141 / 200 correct (70.50)\n",
            "acc = 0.705000\n",
            "Starting epoch 11 / 80\n",
            "t = 1, avg_loss = 0.4173\n",
            "t = 2, avg_loss = 0.4021\n",
            "t = 3, avg_loss = 0.5346\n",
            "t = 4, avg_loss = 0.4682\n",
            "t = 5, avg_loss = 0.4026\n",
            "t = 6, avg_loss = 0.4827\n",
            "t = 7, avg_loss = 0.4829\n",
            "t = 8, avg_loss = 0.4909\n",
            "t = 9, avg_loss = 0.6070\n",
            "t = 10, avg_loss = 0.4273\n",
            "t = 11, avg_loss = 0.4852\n",
            "t = 12, avg_loss = 0.4547\n",
            "t = 13, avg_loss = 0.4250\n",
            "Checking accuracy on test set\n",
            "Got 155 / 200 correct (77.50)\n",
            "acc = 0.775000\n",
            "Starting epoch 12 / 80\n",
            "t = 1, avg_loss = 0.3487\n",
            "t = 2, avg_loss = 0.5242\n",
            "t = 3, avg_loss = 0.4295\n",
            "t = 4, avg_loss = 0.4642\n",
            "t = 5, avg_loss = 0.4942\n",
            "t = 6, avg_loss = 0.5249\n",
            "t = 7, avg_loss = 0.4038\n",
            "t = 8, avg_loss = 0.4491\n",
            "t = 9, avg_loss = 0.5747\n",
            "t = 10, avg_loss = 0.4993\n",
            "t = 11, avg_loss = 0.4967\n",
            "t = 12, avg_loss = 0.4805\n",
            "t = 13, avg_loss = 0.3870\n",
            "Checking accuracy on test set\n",
            "Got 150 / 200 correct (75.00)\n",
            "acc = 0.750000\n",
            "Starting epoch 13 / 80\n",
            "t = 1, avg_loss = 0.5148\n",
            "t = 2, avg_loss = 0.4619\n",
            "t = 3, avg_loss = 0.3628\n",
            "t = 4, avg_loss = 0.4826\n",
            "t = 5, avg_loss = 0.5293\n",
            "t = 6, avg_loss = 0.5204\n",
            "t = 7, avg_loss = 0.3841\n",
            "t = 8, avg_loss = 0.4201\n",
            "t = 9, avg_loss = 0.4474\n",
            "t = 10, avg_loss = 0.5011\n",
            "t = 11, avg_loss = 0.3920\n",
            "t = 12, avg_loss = 0.6162\n",
            "t = 13, avg_loss = 0.5375\n",
            "Checking accuracy on test set\n",
            "Got 151 / 200 correct (75.50)\n",
            "acc = 0.755000\n",
            "Starting epoch 14 / 80\n",
            "t = 1, avg_loss = 0.5096\n",
            "t = 2, avg_loss = 0.4139\n",
            "t = 3, avg_loss = 0.5175\n",
            "t = 4, avg_loss = 0.5371\n",
            "t = 5, avg_loss = 0.4189\n",
            "t = 6, avg_loss = 0.4500\n",
            "t = 7, avg_loss = 0.4267\n",
            "t = 8, avg_loss = 0.3510\n",
            "t = 9, avg_loss = 0.4788\n",
            "t = 10, avg_loss = 0.3946\n",
            "t = 11, avg_loss = 0.4895\n",
            "t = 12, avg_loss = 0.3723\n",
            "t = 13, avg_loss = 0.3204\n",
            "Checking accuracy on test set\n",
            "Got 158 / 200 correct (79.00)\n",
            "acc = 0.790000\n",
            "Starting epoch 15 / 80\n",
            "t = 1, avg_loss = 0.4543\n",
            "t = 2, avg_loss = 0.4834\n",
            "t = 3, avg_loss = 0.6257\n",
            "t = 4, avg_loss = 0.5040\n",
            "t = 5, avg_loss = 0.3722\n",
            "t = 6, avg_loss = 0.4997\n",
            "t = 7, avg_loss = 0.3995\n",
            "t = 8, avg_loss = 0.4363\n",
            "t = 9, avg_loss = 0.4967\n",
            "t = 10, avg_loss = 0.4184\n",
            "t = 11, avg_loss = 0.3344\n",
            "t = 12, avg_loss = 0.4242\n",
            "t = 13, avg_loss = 0.6238\n",
            "Checking accuracy on test set\n",
            "Got 150 / 200 correct (75.00)\n",
            "acc = 0.750000\n",
            "Starting epoch 16 / 80\n",
            "t = 1, avg_loss = 0.4263\n",
            "t = 2, avg_loss = 0.4318\n",
            "t = 3, avg_loss = 0.3936\n",
            "t = 4, avg_loss = 0.4085\n",
            "t = 5, avg_loss = 0.4813\n",
            "t = 6, avg_loss = 0.5940\n",
            "t = 7, avg_loss = 0.5165\n",
            "t = 8, avg_loss = 0.4804\n",
            "t = 9, avg_loss = 0.4087\n",
            "t = 10, avg_loss = 0.4145\n",
            "t = 11, avg_loss = 0.4502\n",
            "t = 12, avg_loss = 0.4732\n",
            "t = 13, avg_loss = 0.4020\n",
            "Checking accuracy on test set\n",
            "Got 161 / 200 correct (80.50)\n",
            "acc = 0.805000\n",
            "Starting epoch 17 / 80\n",
            "t = 1, avg_loss = 0.4480\n",
            "t = 2, avg_loss = 0.4803\n",
            "t = 3, avg_loss = 0.4652\n",
            "t = 4, avg_loss = 0.2972\n",
            "t = 5, avg_loss = 0.4187\n",
            "t = 6, avg_loss = 0.3845\n",
            "t = 7, avg_loss = 0.5012\n",
            "t = 8, avg_loss = 0.5374\n",
            "t = 9, avg_loss = 0.4617\n",
            "t = 10, avg_loss = 0.4864\n",
            "t = 11, avg_loss = 0.5438\n",
            "t = 12, avg_loss = 0.3954\n",
            "t = 13, avg_loss = 0.3229\n",
            "Checking accuracy on test set\n",
            "Got 153 / 200 correct (76.50)\n",
            "acc = 0.765000\n",
            "Starting epoch 18 / 80\n",
            "t = 1, avg_loss = 0.3854\n",
            "t = 2, avg_loss = 0.4480\n",
            "t = 3, avg_loss = 0.4566\n",
            "t = 4, avg_loss = 0.5150\n",
            "t = 5, avg_loss = 0.3941\n",
            "t = 6, avg_loss = 0.3476\n",
            "t = 7, avg_loss = 0.5137\n",
            "t = 8, avg_loss = 0.6677\n",
            "t = 9, avg_loss = 0.4811\n",
            "t = 10, avg_loss = 0.3917\n",
            "t = 11, avg_loss = 0.4983\n",
            "t = 12, avg_loss = 0.4086\n",
            "t = 13, avg_loss = 0.4160\n",
            "Checking accuracy on test set\n",
            "Got 163 / 200 correct (81.50)\n",
            "acc = 0.815000\n",
            "Starting epoch 19 / 80\n",
            "t = 1, avg_loss = 0.4072\n",
            "t = 2, avg_loss = 0.4980\n",
            "t = 3, avg_loss = 0.5440\n",
            "t = 4, avg_loss = 0.5092\n",
            "t = 5, avg_loss = 0.3746\n",
            "t = 6, avg_loss = 0.4705\n",
            "t = 7, avg_loss = 0.4002\n",
            "t = 8, avg_loss = 0.3353\n",
            "t = 9, avg_loss = 0.4227\n",
            "t = 10, avg_loss = 0.4173\n",
            "t = 11, avg_loss = 0.5329\n",
            "t = 12, avg_loss = 0.4491\n",
            "t = 13, avg_loss = 0.4792\n",
            "Checking accuracy on test set\n",
            "Got 157 / 200 correct (78.50)\n",
            "acc = 0.785000\n",
            "Starting epoch 20 / 80\n",
            "t = 1, avg_loss = 0.3038\n",
            "t = 2, avg_loss = 0.6049\n",
            "t = 3, avg_loss = 0.2939\n",
            "t = 4, avg_loss = 0.5011\n",
            "t = 5, avg_loss = 0.5533\n",
            "t = 6, avg_loss = 0.5215\n",
            "t = 7, avg_loss = 0.4201\n",
            "t = 8, avg_loss = 0.3359\n",
            "t = 9, avg_loss = 0.4381\n",
            "t = 10, avg_loss = 0.4822\n",
            "t = 11, avg_loss = 0.4989\n",
            "t = 12, avg_loss = 0.4540\n",
            "t = 13, avg_loss = 0.3607\n",
            "Checking accuracy on test set\n",
            "Got 159 / 200 correct (79.50)\n",
            "acc = 0.795000\n",
            "Starting epoch 21 / 80\n",
            "t = 1, avg_loss = 0.5072\n",
            "t = 2, avg_loss = 0.3791\n",
            "t = 3, avg_loss = 0.3705\n",
            "t = 4, avg_loss = 0.5084\n",
            "t = 5, avg_loss = 0.3567\n",
            "t = 6, avg_loss = 0.3564\n",
            "t = 7, avg_loss = 0.5516\n",
            "t = 8, avg_loss = 0.4243\n",
            "t = 9, avg_loss = 0.5364\n",
            "t = 10, avg_loss = 0.4455\n",
            "t = 11, avg_loss = 0.5054\n",
            "t = 12, avg_loss = 0.4203\n",
            "t = 13, avg_loss = 0.6085\n",
            "Checking accuracy on test set\n",
            "Got 155 / 200 correct (77.50)\n",
            "acc = 0.775000\n",
            "Starting epoch 22 / 80\n",
            "t = 1, avg_loss = 0.4495\n",
            "t = 2, avg_loss = 0.4237\n",
            "t = 3, avg_loss = 0.4364\n",
            "t = 4, avg_loss = 0.4937\n",
            "t = 5, avg_loss = 0.4904\n",
            "t = 6, avg_loss = 0.5242\n",
            "t = 7, avg_loss = 0.5283\n",
            "t = 8, avg_loss = 0.4678\n",
            "t = 9, avg_loss = 0.4560\n",
            "t = 10, avg_loss = 0.5051\n",
            "t = 11, avg_loss = 0.4249\n",
            "t = 12, avg_loss = 0.4571\n",
            "t = 13, avg_loss = 0.2494\n",
            "Checking accuracy on test set\n",
            "Got 149 / 200 correct (74.50)\n",
            "acc = 0.745000\n",
            "Starting epoch 23 / 80\n",
            "t = 1, avg_loss = 0.5133\n",
            "t = 2, avg_loss = 0.4304\n",
            "t = 3, avg_loss = 0.4902\n",
            "t = 4, avg_loss = 0.4591\n",
            "t = 5, avg_loss = 0.5917\n",
            "t = 6, avg_loss = 0.3850\n",
            "t = 7, avg_loss = 0.5527\n",
            "t = 8, avg_loss = 0.4719\n",
            "t = 9, avg_loss = 0.4644\n",
            "t = 10, avg_loss = 0.6033\n",
            "t = 11, avg_loss = 0.4483\n",
            "t = 12, avg_loss = 0.3968\n",
            "t = 13, avg_loss = 0.3801\n",
            "Checking accuracy on test set\n",
            "Got 155 / 200 correct (77.50)\n",
            "acc = 0.775000\n",
            "Starting epoch 24 / 80\n",
            "t = 1, avg_loss = 0.3661\n",
            "t = 2, avg_loss = 0.5725\n",
            "t = 3, avg_loss = 0.4691\n",
            "t = 4, avg_loss = 0.4364\n",
            "t = 5, avg_loss = 0.3877\n",
            "t = 6, avg_loss = 0.4730\n",
            "t = 7, avg_loss = 0.4517\n",
            "t = 8, avg_loss = 0.5075\n",
            "t = 9, avg_loss = 0.3581\n",
            "t = 10, avg_loss = 0.4014\n",
            "t = 11, avg_loss = 0.3391\n",
            "t = 12, avg_loss = 0.4509\n",
            "t = 13, avg_loss = 0.3949\n",
            "Checking accuracy on test set\n",
            "Got 160 / 200 correct (80.00)\n",
            "acc = 0.800000\n",
            "Starting epoch 25 / 80\n",
            "t = 1, avg_loss = 0.4510\n",
            "t = 2, avg_loss = 0.3686\n",
            "t = 3, avg_loss = 0.3656\n",
            "t = 4, avg_loss = 0.4332\n",
            "t = 5, avg_loss = 0.5119\n",
            "t = 6, avg_loss = 0.3746\n",
            "t = 7, avg_loss = 0.3822\n",
            "t = 8, avg_loss = 0.3038\n",
            "t = 9, avg_loss = 0.5289\n",
            "t = 10, avg_loss = 0.2964\n",
            "t = 11, avg_loss = 0.5433\n",
            "t = 12, avg_loss = 0.4117\n",
            "t = 13, avg_loss = 0.4771\n",
            "Checking accuracy on test set\n",
            "Got 156 / 200 correct (78.00)\n",
            "acc = 0.780000\n",
            "Starting epoch 26 / 80\n",
            "t = 1, avg_loss = 0.4003\n",
            "t = 2, avg_loss = 0.4091\n",
            "t = 3, avg_loss = 0.4073\n",
            "t = 4, avg_loss = 0.4396\n",
            "t = 5, avg_loss = 0.4897\n",
            "t = 6, avg_loss = 0.4826\n",
            "t = 7, avg_loss = 0.3723\n",
            "t = 8, avg_loss = 0.4809\n",
            "t = 9, avg_loss = 0.3822\n",
            "t = 10, avg_loss = 0.3348\n",
            "t = 11, avg_loss = 0.5391\n",
            "t = 12, avg_loss = 0.3759\n",
            "t = 13, avg_loss = 0.3071\n",
            "Checking accuracy on test set\n",
            "Got 157 / 200 correct (78.50)\n",
            "acc = 0.785000\n",
            "Starting epoch 27 / 80\n",
            "t = 1, avg_loss = 0.3330\n",
            "t = 2, avg_loss = 0.3649\n",
            "t = 3, avg_loss = 0.4881\n",
            "t = 4, avg_loss = 0.3850\n",
            "t = 5, avg_loss = 0.4295\n",
            "t = 6, avg_loss = 0.4143\n",
            "t = 7, avg_loss = 0.3661\n",
            "t = 8, avg_loss = 0.4800\n",
            "t = 9, avg_loss = 0.5103\n",
            "t = 10, avg_loss = 0.4280\n",
            "t = 11, avg_loss = 0.3726\n",
            "t = 12, avg_loss = 0.4082\n",
            "t = 13, avg_loss = 0.2777\n",
            "Checking accuracy on test set\n",
            "Got 160 / 200 correct (80.00)\n",
            "acc = 0.800000\n",
            "Starting epoch 28 / 80\n",
            "t = 1, avg_loss = 0.4878\n",
            "t = 2, avg_loss = 0.3698\n",
            "t = 3, avg_loss = 0.3934\n",
            "t = 4, avg_loss = 0.4115\n",
            "t = 5, avg_loss = 0.4390\n",
            "t = 6, avg_loss = 0.5287\n",
            "t = 7, avg_loss = 0.4094\n",
            "t = 8, avg_loss = 0.5139\n",
            "t = 9, avg_loss = 0.4060\n",
            "t = 10, avg_loss = 0.3374\n",
            "t = 11, avg_loss = 0.4220\n",
            "t = 12, avg_loss = 0.3102\n",
            "t = 13, avg_loss = 0.3729\n",
            "Checking accuracy on test set\n",
            "Got 158 / 200 correct (79.00)\n",
            "acc = 0.790000\n",
            "Starting epoch 29 / 80\n",
            "t = 1, avg_loss = 0.3890\n",
            "t = 2, avg_loss = 0.3698\n",
            "t = 3, avg_loss = 0.4084\n",
            "t = 4, avg_loss = 0.4575\n",
            "t = 5, avg_loss = 0.4324\n",
            "t = 6, avg_loss = 0.3081\n",
            "t = 7, avg_loss = 0.4256\n",
            "t = 8, avg_loss = 0.3879\n",
            "t = 9, avg_loss = 0.4672\n",
            "t = 10, avg_loss = 0.4080\n",
            "t = 11, avg_loss = 0.3768\n",
            "t = 12, avg_loss = 0.4767\n",
            "t = 13, avg_loss = 0.4031\n",
            "Checking accuracy on test set\n",
            "Got 162 / 200 correct (81.00)\n",
            "acc = 0.810000\n",
            "Starting epoch 30 / 80\n",
            "t = 1, avg_loss = 0.3439\n",
            "t = 2, avg_loss = 0.4671\n",
            "t = 3, avg_loss = 0.4320\n",
            "t = 4, avg_loss = 0.3636\n",
            "t = 5, avg_loss = 0.3209\n",
            "t = 6, avg_loss = 0.5039\n",
            "t = 7, avg_loss = 0.3919\n",
            "t = 8, avg_loss = 0.3874\n",
            "t = 9, avg_loss = 0.2588\n",
            "t = 10, avg_loss = 0.4166\n",
            "t = 11, avg_loss = 0.5087\n",
            "t = 12, avg_loss = 0.4350\n",
            "t = 13, avg_loss = 0.3247\n",
            "Checking accuracy on test set\n",
            "Got 163 / 200 correct (81.50)\n",
            "acc = 0.815000\n",
            "Starting epoch 31 / 80\n",
            "t = 1, avg_loss = 0.2698\n",
            "t = 2, avg_loss = 0.3501\n",
            "t = 3, avg_loss = 0.4312\n",
            "t = 4, avg_loss = 0.3966\n",
            "t = 5, avg_loss = 0.3846\n",
            "t = 6, avg_loss = 0.3763\n",
            "t = 7, avg_loss = 0.3111\n",
            "t = 8, avg_loss = 0.3412\n",
            "t = 9, avg_loss = 0.3883\n",
            "t = 10, avg_loss = 0.5830\n",
            "t = 11, avg_loss = 0.4703\n",
            "t = 12, avg_loss = 0.5064\n",
            "t = 13, avg_loss = 0.3847\n",
            "Checking accuracy on test set\n",
            "Got 166 / 200 correct (83.00)\n",
            "acc = 0.830000\n",
            "Starting epoch 32 / 80\n",
            "t = 1, avg_loss = 0.4696\n",
            "t = 2, avg_loss = 0.4628\n",
            "t = 3, avg_loss = 0.4520\n",
            "t = 4, avg_loss = 0.4336\n",
            "t = 5, avg_loss = 0.4891\n",
            "t = 6, avg_loss = 0.3097\n",
            "t = 7, avg_loss = 0.4266\n",
            "t = 8, avg_loss = 0.3361\n",
            "t = 9, avg_loss = 0.3749\n",
            "t = 10, avg_loss = 0.4149\n",
            "t = 11, avg_loss = 0.4245\n",
            "t = 12, avg_loss = 0.4531\n",
            "t = 13, avg_loss = 0.3253\n",
            "Checking accuracy on test set\n",
            "Got 163 / 200 correct (81.50)\n",
            "acc = 0.815000\n",
            "Starting epoch 33 / 80\n",
            "t = 1, avg_loss = 0.4444\n",
            "t = 2, avg_loss = 0.3491\n",
            "t = 3, avg_loss = 0.4992\n",
            "t = 4, avg_loss = 0.3753\n",
            "t = 5, avg_loss = 0.4719\n",
            "t = 6, avg_loss = 0.5576\n",
            "t = 7, avg_loss = 0.3766\n",
            "t = 8, avg_loss = 0.3418\n",
            "t = 9, avg_loss = 0.3607\n",
            "t = 10, avg_loss = 0.4570\n",
            "t = 11, avg_loss = 0.4439\n",
            "t = 12, avg_loss = 0.4601\n",
            "t = 13, avg_loss = 0.2211\n",
            "Checking accuracy on test set\n",
            "Got 158 / 200 correct (79.00)\n",
            "acc = 0.790000\n",
            "Starting epoch 34 / 80\n",
            "t = 1, avg_loss = 0.5104\n",
            "t = 2, avg_loss = 0.4075\n",
            "t = 3, avg_loss = 0.3437\n",
            "t = 4, avg_loss = 0.4153\n",
            "t = 5, avg_loss = 0.4058\n",
            "t = 6, avg_loss = 0.3624\n",
            "t = 7, avg_loss = 0.4334\n",
            "t = 8, avg_loss = 0.4876\n",
            "t = 9, avg_loss = 0.4730\n",
            "t = 10, avg_loss = 0.3726\n",
            "t = 11, avg_loss = 0.3262\n",
            "t = 12, avg_loss = 0.3100\n",
            "t = 13, avg_loss = 0.2855\n",
            "Checking accuracy on test set\n",
            "Got 165 / 200 correct (82.50)\n",
            "acc = 0.825000\n",
            "Starting epoch 35 / 80\n",
            "t = 1, avg_loss = 0.3550\n",
            "t = 2, avg_loss = 0.4309\n",
            "t = 3, avg_loss = 0.3231\n",
            "t = 4, avg_loss = 0.4770\n",
            "t = 5, avg_loss = 0.3785\n",
            "t = 6, avg_loss = 0.4474\n",
            "t = 7, avg_loss = 0.3962\n",
            "t = 8, avg_loss = 0.3758\n",
            "t = 9, avg_loss = 0.4058\n",
            "t = 10, avg_loss = 0.3656\n",
            "t = 11, avg_loss = 0.3871\n",
            "t = 12, avg_loss = 0.3883\n",
            "t = 13, avg_loss = 0.9433\n",
            "Checking accuracy on test set\n",
            "Got 159 / 200 correct (79.50)\n",
            "acc = 0.795000\n",
            "Starting epoch 36 / 80\n",
            "t = 1, avg_loss = 0.3388\n",
            "t = 2, avg_loss = 0.4070\n",
            "t = 3, avg_loss = 0.2908\n",
            "t = 4, avg_loss = 0.3887\n",
            "t = 5, avg_loss = 0.3827\n",
            "t = 6, avg_loss = 0.4422\n",
            "t = 7, avg_loss = 0.4819\n",
            "t = 8, avg_loss = 0.3856\n",
            "t = 9, avg_loss = 0.4521\n",
            "t = 10, avg_loss = 0.5309\n",
            "t = 11, avg_loss = 0.3442\n",
            "t = 12, avg_loss = 0.3617\n",
            "t = 13, avg_loss = 0.4459\n",
            "Checking accuracy on test set\n",
            "Got 160 / 200 correct (80.00)\n",
            "acc = 0.800000\n",
            "Starting epoch 37 / 80\n",
            "t = 1, avg_loss = 0.3505\n",
            "t = 2, avg_loss = 0.3178\n",
            "t = 3, avg_loss = 0.5009\n",
            "t = 4, avg_loss = 0.3164\n",
            "t = 5, avg_loss = 0.4459\n",
            "t = 6, avg_loss = 0.5683\n",
            "t = 7, avg_loss = 0.3997\n",
            "t = 8, avg_loss = 0.3631\n",
            "t = 9, avg_loss = 0.3557\n",
            "t = 10, avg_loss = 0.3862\n",
            "t = 11, avg_loss = 0.3801\n",
            "t = 12, avg_loss = 0.3714\n",
            "t = 13, avg_loss = 0.5337\n",
            "Checking accuracy on test set\n",
            "Got 163 / 200 correct (81.50)\n",
            "acc = 0.815000\n",
            "Starting epoch 38 / 80\n",
            "t = 1, avg_loss = 0.2866\n",
            "t = 2, avg_loss = 0.3473\n",
            "t = 3, avg_loss = 0.3420\n",
            "t = 4, avg_loss = 0.5541\n",
            "t = 5, avg_loss = 0.3621\n",
            "t = 6, avg_loss = 0.4375\n",
            "t = 7, avg_loss = 0.3798\n",
            "t = 8, avg_loss = 0.3487\n",
            "t = 9, avg_loss = 0.4869\n",
            "t = 10, avg_loss = 0.3174\n",
            "t = 11, avg_loss = 0.3875\n",
            "t = 12, avg_loss = 0.4170\n",
            "t = 13, avg_loss = 0.5500\n",
            "Checking accuracy on test set\n",
            "Got 158 / 200 correct (79.00)\n",
            "acc = 0.790000\n",
            "Starting epoch 39 / 80\n",
            "t = 1, avg_loss = 0.3909\n",
            "t = 2, avg_loss = 0.3155\n",
            "t = 3, avg_loss = 0.5263\n",
            "t = 4, avg_loss = 0.4451\n",
            "t = 5, avg_loss = 0.3392\n",
            "t = 6, avg_loss = 0.3208\n",
            "t = 7, avg_loss = 0.4748\n",
            "t = 8, avg_loss = 0.4214\n",
            "t = 9, avg_loss = 0.4075\n",
            "t = 10, avg_loss = 0.3676\n",
            "t = 11, avg_loss = 0.3763\n",
            "t = 12, avg_loss = 0.3368\n",
            "t = 13, avg_loss = 0.3753\n",
            "Checking accuracy on test set\n",
            "Got 160 / 200 correct (80.00)\n",
            "acc = 0.800000\n",
            "Starting epoch 40 / 80\n",
            "t = 1, avg_loss = 0.3501\n",
            "t = 2, avg_loss = 0.3574\n",
            "t = 3, avg_loss = 0.3973\n",
            "t = 4, avg_loss = 0.4718\n",
            "t = 5, avg_loss = 0.4416\n",
            "t = 6, avg_loss = 0.3860\n",
            "t = 7, avg_loss = 0.4710\n",
            "t = 8, avg_loss = 0.3494\n",
            "t = 9, avg_loss = 0.3991\n",
            "t = 10, avg_loss = 0.3350\n",
            "t = 11, avg_loss = 0.4277\n",
            "t = 12, avg_loss = 0.3519\n",
            "t = 13, avg_loss = 0.3635\n",
            "Checking accuracy on test set\n",
            "Got 163 / 200 correct (81.50)\n",
            "acc = 0.815000\n",
            "Starting epoch 41 / 80\n",
            "t = 1, avg_loss = 0.4234\n",
            "t = 2, avg_loss = 0.5211\n",
            "t = 3, avg_loss = 0.3194\n",
            "t = 4, avg_loss = 0.4172\n",
            "t = 5, avg_loss = 0.4980\n",
            "t = 6, avg_loss = 0.3861\n",
            "t = 7, avg_loss = 0.4492\n",
            "t = 8, avg_loss = 0.3670\n",
            "t = 9, avg_loss = 0.2895\n",
            "t = 10, avg_loss = 0.3322\n",
            "t = 11, avg_loss = 0.3024\n",
            "t = 12, avg_loss = 0.4065\n",
            "t = 13, avg_loss = 0.5230\n",
            "Checking accuracy on test set\n",
            "Got 161 / 200 correct (80.50)\n",
            "acc = 0.805000\n",
            "Starting epoch 42 / 80\n",
            "t = 1, avg_loss = 0.5055\n",
            "t = 2, avg_loss = 0.3483\n",
            "t = 3, avg_loss = 0.3953\n",
            "t = 4, avg_loss = 0.3565\n",
            "t = 5, avg_loss = 0.3107\n",
            "t = 6, avg_loss = 0.3179\n",
            "t = 7, avg_loss = 0.4320\n",
            "t = 8, avg_loss = 0.3648\n",
            "t = 9, avg_loss = 0.4696\n",
            "t = 10, avg_loss = 0.3748\n",
            "t = 11, avg_loss = 0.3407\n",
            "t = 12, avg_loss = 0.4537\n",
            "t = 13, avg_loss = 0.5081\n",
            "Checking accuracy on test set\n",
            "Got 163 / 200 correct (81.50)\n",
            "acc = 0.815000\n",
            "Starting epoch 43 / 80\n",
            "t = 1, avg_loss = 0.3381\n",
            "t = 2, avg_loss = 0.3466\n",
            "t = 3, avg_loss = 0.4169\n",
            "t = 4, avg_loss = 0.3321\n",
            "t = 5, avg_loss = 0.3269\n",
            "t = 6, avg_loss = 0.4828\n",
            "t = 7, avg_loss = 0.3683\n",
            "t = 8, avg_loss = 0.5449\n",
            "t = 9, avg_loss = 0.3664\n",
            "t = 10, avg_loss = 0.3055\n",
            "t = 11, avg_loss = 0.4492\n",
            "t = 12, avg_loss = 0.3591\n",
            "t = 13, avg_loss = 0.2627\n",
            "Checking accuracy on test set\n",
            "Got 163 / 200 correct (81.50)\n",
            "acc = 0.815000\n",
            "Starting epoch 44 / 80\n",
            "t = 1, avg_loss = 0.3075\n",
            "t = 2, avg_loss = 0.4134\n",
            "t = 3, avg_loss = 0.4127\n",
            "t = 4, avg_loss = 0.3921\n",
            "t = 5, avg_loss = 0.2705\n",
            "t = 6, avg_loss = 0.4688\n",
            "t = 7, avg_loss = 0.3753\n",
            "t = 8, avg_loss = 0.4095\n",
            "t = 9, avg_loss = 0.3599\n",
            "t = 10, avg_loss = 0.3878\n",
            "t = 11, avg_loss = 0.3656\n",
            "t = 12, avg_loss = 0.3737\n",
            "t = 13, avg_loss = 0.5465\n",
            "Checking accuracy on test set\n",
            "Got 161 / 200 correct (80.50)\n",
            "acc = 0.805000\n",
            "Starting epoch 45 / 80\n",
            "t = 1, avg_loss = 0.3740\n",
            "t = 2, avg_loss = 0.3791\n",
            "t = 3, avg_loss = 0.3908\n",
            "t = 4, avg_loss = 0.4524\n",
            "t = 5, avg_loss = 0.4407\n",
            "t = 6, avg_loss = 0.2939\n",
            "t = 7, avg_loss = 0.3625\n",
            "t = 8, avg_loss = 0.3574\n",
            "t = 9, avg_loss = 0.3371\n",
            "t = 10, avg_loss = 0.4243\n",
            "t = 11, avg_loss = 0.3946\n",
            "t = 12, avg_loss = 0.3402\n",
            "t = 13, avg_loss = 0.3731\n",
            "Checking accuracy on test set\n",
            "Got 164 / 200 correct (82.00)\n",
            "acc = 0.820000\n",
            "Starting epoch 46 / 80\n",
            "t = 1, avg_loss = 0.3313\n",
            "t = 2, avg_loss = 0.5623\n",
            "t = 3, avg_loss = 0.3325\n",
            "t = 4, avg_loss = 0.2922\n",
            "t = 5, avg_loss = 0.3995\n",
            "t = 6, avg_loss = 0.4150\n",
            "t = 7, avg_loss = 0.3898\n",
            "t = 8, avg_loss = 0.3330\n",
            "t = 9, avg_loss = 0.3561\n",
            "t = 10, avg_loss = 0.4213\n",
            "t = 11, avg_loss = 0.3190\n",
            "t = 12, avg_loss = 0.4685\n",
            "t = 13, avg_loss = 0.3104\n",
            "Checking accuracy on test set\n",
            "Got 160 / 200 correct (80.00)\n",
            "acc = 0.800000\n",
            "Starting epoch 47 / 80\n",
            "t = 1, avg_loss = 0.3280\n",
            "t = 2, avg_loss = 0.3715\n",
            "t = 3, avg_loss = 0.4469\n",
            "t = 4, avg_loss = 0.5232\n",
            "t = 5, avg_loss = 0.3747\n",
            "t = 6, avg_loss = 0.3953\n",
            "t = 7, avg_loss = 0.3170\n",
            "t = 8, avg_loss = 0.3185\n",
            "t = 9, avg_loss = 0.3117\n",
            "t = 10, avg_loss = 0.3878\n",
            "t = 11, avg_loss = 0.3753\n",
            "t = 12, avg_loss = 0.3340\n",
            "t = 13, avg_loss = 0.3289\n",
            "Checking accuracy on test set\n",
            "Got 166 / 200 correct (83.00)\n",
            "acc = 0.830000\n",
            "Starting epoch 48 / 80\n",
            "t = 1, avg_loss = 0.5076\n",
            "t = 2, avg_loss = 0.4025\n",
            "t = 3, avg_loss = 0.3545\n",
            "t = 4, avg_loss = 0.3448\n",
            "t = 5, avg_loss = 0.4310\n",
            "t = 6, avg_loss = 0.3196\n",
            "t = 7, avg_loss = 0.3263\n",
            "t = 8, avg_loss = 0.4156\n",
            "t = 9, avg_loss = 0.4413\n",
            "t = 10, avg_loss = 0.4218\n",
            "t = 11, avg_loss = 0.3904\n",
            "t = 12, avg_loss = 0.3744\n",
            "t = 13, avg_loss = 0.3876\n",
            "Checking accuracy on test set\n",
            "Got 163 / 200 correct (81.50)\n",
            "acc = 0.815000\n",
            "Starting epoch 49 / 80\n",
            "t = 1, avg_loss = 0.3605\n",
            "t = 2, avg_loss = 0.3498\n",
            "t = 3, avg_loss = 0.3113\n",
            "t = 4, avg_loss = 0.3292\n",
            "t = 5, avg_loss = 0.4256\n",
            "t = 6, avg_loss = 0.3983\n",
            "t = 7, avg_loss = 0.3325\n",
            "t = 8, avg_loss = 0.3306\n",
            "t = 9, avg_loss = 0.5307\n",
            "t = 10, avg_loss = 0.3173\n",
            "t = 11, avg_loss = 0.3249\n",
            "t = 12, avg_loss = 0.4364\n",
            "t = 13, avg_loss = 0.4879\n",
            "Checking accuracy on test set\n",
            "Got 159 / 200 correct (79.50)\n",
            "acc = 0.795000\n",
            "Starting epoch 50 / 80\n",
            "t = 1, avg_loss = 0.2449\n",
            "t = 2, avg_loss = 0.3859\n",
            "t = 3, avg_loss = 0.3415\n",
            "t = 4, avg_loss = 0.3028\n",
            "t = 5, avg_loss = 0.2893\n",
            "t = 6, avg_loss = 0.3574\n",
            "t = 7, avg_loss = 0.3372\n",
            "t = 8, avg_loss = 0.4320\n",
            "t = 9, avg_loss = 0.3667\n",
            "t = 10, avg_loss = 0.4542\n",
            "t = 11, avg_loss = 0.2888\n",
            "t = 12, avg_loss = 0.3753\n",
            "t = 13, avg_loss = 0.6000\n",
            "Checking accuracy on test set\n",
            "Got 161 / 200 correct (80.50)\n",
            "acc = 0.805000\n",
            "Starting epoch 51 / 80\n",
            "t = 1, avg_loss = 0.3553\n",
            "t = 2, avg_loss = 0.2996\n",
            "t = 3, avg_loss = 0.3051\n",
            "t = 4, avg_loss = 0.3433\n",
            "t = 5, avg_loss = 0.3457\n",
            "t = 6, avg_loss = 0.4172\n",
            "t = 7, avg_loss = 0.4328\n",
            "t = 8, avg_loss = 0.4485\n",
            "t = 9, avg_loss = 0.3367\n",
            "t = 10, avg_loss = 0.3792\n",
            "t = 11, avg_loss = 0.3149\n",
            "t = 12, avg_loss = 0.5300\n",
            "t = 13, avg_loss = 0.3306\n",
            "Checking accuracy on test set\n",
            "Got 164 / 200 correct (82.00)\n",
            "acc = 0.820000\n",
            "Starting epoch 52 / 80\n",
            "t = 1, avg_loss = 0.3729\n",
            "t = 2, avg_loss = 0.4429\n",
            "t = 3, avg_loss = 0.2957\n",
            "t = 4, avg_loss = 0.3484\n",
            "t = 5, avg_loss = 0.4058\n",
            "t = 6, avg_loss = 0.3607\n",
            "t = 7, avg_loss = 0.3998\n",
            "t = 8, avg_loss = 0.3318\n",
            "t = 9, avg_loss = 0.2748\n",
            "t = 10, avg_loss = 0.4330\n",
            "t = 11, avg_loss = 0.3880\n",
            "t = 12, avg_loss = 0.2750\n",
            "t = 13, avg_loss = 0.3265\n",
            "Checking accuracy on test set\n",
            "Got 158 / 200 correct (79.00)\n",
            "acc = 0.790000\n",
            "Starting epoch 53 / 80\n",
            "t = 1, avg_loss = 0.4264\n",
            "t = 2, avg_loss = 0.2236\n",
            "t = 3, avg_loss = 0.2954\n",
            "t = 4, avg_loss = 0.4829\n",
            "t = 5, avg_loss = 0.4703\n",
            "t = 6, avg_loss = 0.3819\n",
            "t = 7, avg_loss = 0.3072\n",
            "t = 8, avg_loss = 0.3760\n",
            "t = 9, avg_loss = 0.3673\n",
            "t = 10, avg_loss = 0.3930\n",
            "t = 11, avg_loss = 0.3478\n",
            "t = 12, avg_loss = 0.3821\n",
            "t = 13, avg_loss = 0.3492\n",
            "Checking accuracy on test set\n",
            "Got 167 / 200 correct (83.50)\n",
            "acc = 0.835000\n",
            "Starting epoch 54 / 80\n",
            "t = 1, avg_loss = 0.4581\n",
            "t = 2, avg_loss = 0.3780\n",
            "t = 3, avg_loss = 0.2431\n",
            "t = 4, avg_loss = 0.3556\n",
            "t = 5, avg_loss = 0.3357\n",
            "t = 6, avg_loss = 0.4385\n",
            "t = 7, avg_loss = 0.3651\n",
            "t = 8, avg_loss = 0.3583\n",
            "t = 9, avg_loss = 0.4202\n",
            "t = 10, avg_loss = 0.2904\n",
            "t = 11, avg_loss = 0.2250\n",
            "t = 12, avg_loss = 0.4652\n",
            "t = 13, avg_loss = 0.3635\n",
            "Checking accuracy on test set\n",
            "Got 162 / 200 correct (81.00)\n",
            "acc = 0.810000\n",
            "Starting epoch 55 / 80\n",
            "t = 1, avg_loss = 0.3156\n",
            "t = 2, avg_loss = 0.3801\n",
            "t = 3, avg_loss = 0.4836\n",
            "t = 4, avg_loss = 0.2902\n",
            "t = 5, avg_loss = 0.3879\n",
            "t = 6, avg_loss = 0.3169\n",
            "t = 7, avg_loss = 0.4191\n",
            "t = 8, avg_loss = 0.3598\n",
            "t = 9, avg_loss = 0.3642\n",
            "t = 10, avg_loss = 0.4050\n",
            "t = 11, avg_loss = 0.3277\n",
            "t = 12, avg_loss = 0.3140\n",
            "t = 13, avg_loss = 0.2878\n",
            "Checking accuracy on test set\n",
            "Got 168 / 200 correct (84.00)\n",
            "acc = 0.840000\n",
            "Starting epoch 56 / 80\n",
            "t = 1, avg_loss = 0.5439\n",
            "t = 2, avg_loss = 0.3609\n",
            "t = 3, avg_loss = 0.3025\n",
            "t = 4, avg_loss = 0.3646\n",
            "t = 5, avg_loss = 0.3730\n",
            "t = 6, avg_loss = 0.3261\n",
            "t = 7, avg_loss = 0.4311\n",
            "t = 8, avg_loss = 0.3004\n",
            "t = 9, avg_loss = 0.3876\n",
            "t = 10, avg_loss = 0.2688\n",
            "t = 11, avg_loss = 0.4174\n",
            "t = 12, avg_loss = 0.4316\n",
            "t = 13, avg_loss = 0.3729\n",
            "Checking accuracy on test set\n",
            "Got 163 / 200 correct (81.50)\n",
            "acc = 0.815000\n",
            "Starting epoch 57 / 80\n",
            "t = 1, avg_loss = 0.3107\n",
            "t = 2, avg_loss = 0.3082\n",
            "t = 3, avg_loss = 0.3193\n",
            "t = 4, avg_loss = 0.6108\n",
            "t = 5, avg_loss = 0.2837\n",
            "t = 6, avg_loss = 0.3123\n",
            "t = 7, avg_loss = 0.4111\n",
            "t = 8, avg_loss = 0.3040\n",
            "t = 9, avg_loss = 0.3869\n",
            "t = 10, avg_loss = 0.3739\n",
            "t = 11, avg_loss = 0.3235\n",
            "t = 12, avg_loss = 0.3638\n",
            "t = 13, avg_loss = 0.2384\n",
            "Checking accuracy on test set\n",
            "Got 161 / 200 correct (80.50)\n",
            "acc = 0.805000\n",
            "Starting epoch 58 / 80\n",
            "t = 1, avg_loss = 0.3348\n",
            "t = 2, avg_loss = 0.2529\n",
            "t = 3, avg_loss = 0.3960\n",
            "t = 4, avg_loss = 0.3175\n",
            "t = 5, avg_loss = 0.3074\n",
            "t = 6, avg_loss = 0.3302\n",
            "t = 7, avg_loss = 0.3229\n",
            "t = 8, avg_loss = 0.3757\n",
            "t = 9, avg_loss = 0.3873\n",
            "t = 10, avg_loss = 0.3594\n",
            "t = 11, avg_loss = 0.4077\n",
            "t = 12, avg_loss = 0.2942\n",
            "t = 13, avg_loss = 0.3772\n",
            "Checking accuracy on test set\n",
            "Got 170 / 200 correct (85.00)\n",
            "acc = 0.850000\n",
            "Starting epoch 59 / 80\n",
            "t = 1, avg_loss = 0.4599\n",
            "t = 2, avg_loss = 0.2987\n",
            "t = 3, avg_loss = 0.4183\n",
            "t = 4, avg_loss = 0.2627\n",
            "t = 5, avg_loss = 0.2425\n",
            "t = 6, avg_loss = 0.3930\n",
            "t = 7, avg_loss = 0.3540\n",
            "t = 8, avg_loss = 0.2900\n",
            "t = 9, avg_loss = 0.5134\n",
            "t = 10, avg_loss = 0.3488\n",
            "t = 11, avg_loss = 0.3082\n",
            "t = 12, avg_loss = 0.2336\n",
            "t = 13, avg_loss = 0.2809\n",
            "Checking accuracy on test set\n",
            "Got 163 / 200 correct (81.50)\n",
            "acc = 0.815000\n",
            "Starting epoch 60 / 80\n",
            "t = 1, avg_loss = 0.2610\n",
            "t = 2, avg_loss = 0.3350\n",
            "t = 3, avg_loss = 0.4343\n",
            "t = 4, avg_loss = 0.4680\n",
            "t = 5, avg_loss = 0.6435\n",
            "t = 6, avg_loss = 0.3510\n",
            "t = 7, avg_loss = 0.2215\n",
            "t = 8, avg_loss = 0.4378\n",
            "t = 9, avg_loss = 0.3267\n",
            "t = 10, avg_loss = 0.2238\n",
            "t = 11, avg_loss = 0.5136\n",
            "t = 12, avg_loss = 0.3465\n",
            "t = 13, avg_loss = 0.2597\n",
            "Checking accuracy on test set\n",
            "Got 164 / 200 correct (82.00)\n",
            "acc = 0.820000\n",
            "Starting epoch 61 / 80\n",
            "t = 1, avg_loss = 0.3708\n",
            "t = 2, avg_loss = 0.4152\n",
            "t = 3, avg_loss = 0.4081\n",
            "t = 4, avg_loss = 0.4876\n",
            "t = 5, avg_loss = 0.2953\n",
            "t = 6, avg_loss = 0.3429\n",
            "t = 7, avg_loss = 0.3118\n",
            "t = 8, avg_loss = 0.4260\n",
            "t = 9, avg_loss = 0.3508\n",
            "t = 10, avg_loss = 0.3553\n",
            "t = 11, avg_loss = 0.3049\n",
            "t = 12, avg_loss = 0.4047\n",
            "t = 13, avg_loss = 0.3696\n",
            "Checking accuracy on test set\n",
            "Got 163 / 200 correct (81.50)\n",
            "acc = 0.815000\n",
            "Starting epoch 62 / 80\n",
            "t = 1, avg_loss = 0.3815\n",
            "t = 2, avg_loss = 0.3420\n",
            "t = 3, avg_loss = 0.3764\n",
            "t = 4, avg_loss = 0.3613\n",
            "t = 5, avg_loss = 0.3491\n",
            "t = 6, avg_loss = 0.3332\n",
            "t = 7, avg_loss = 0.4572\n",
            "t = 8, avg_loss = 0.3082\n",
            "t = 9, avg_loss = 0.3809\n",
            "t = 10, avg_loss = 0.2504\n",
            "t = 11, avg_loss = 0.2930\n",
            "t = 12, avg_loss = 0.2933\n",
            "t = 13, avg_loss = 0.4677\n",
            "Checking accuracy on test set\n",
            "Got 165 / 200 correct (82.50)\n",
            "acc = 0.825000\n",
            "Starting epoch 63 / 80\n",
            "t = 1, avg_loss = 0.3295\n",
            "t = 2, avg_loss = 0.4230\n",
            "t = 3, avg_loss = 0.4856\n",
            "t = 4, avg_loss = 0.4464\n",
            "t = 5, avg_loss = 0.2333\n",
            "t = 6, avg_loss = 0.4243\n",
            "t = 7, avg_loss = 0.3389\n",
            "t = 8, avg_loss = 0.2923\n",
            "t = 9, avg_loss = 0.3866\n",
            "t = 10, avg_loss = 0.3586\n",
            "t = 11, avg_loss = 0.3823\n",
            "t = 12, avg_loss = 0.4418\n",
            "t = 13, avg_loss = 0.3580\n",
            "Checking accuracy on test set\n",
            "Got 167 / 200 correct (83.50)\n",
            "acc = 0.835000\n",
            "Starting epoch 64 / 80\n",
            "t = 1, avg_loss = 0.2924\n",
            "t = 2, avg_loss = 0.3151\n",
            "t = 3, avg_loss = 0.3379\n",
            "t = 4, avg_loss = 0.3699\n",
            "t = 5, avg_loss = 0.2846\n",
            "t = 6, avg_loss = 0.4050\n",
            "t = 7, avg_loss = 0.2764\n",
            "t = 8, avg_loss = 0.2351\n",
            "t = 9, avg_loss = 0.3843\n",
            "t = 10, avg_loss = 0.4204\n",
            "t = 11, avg_loss = 0.4222\n",
            "t = 12, avg_loss = 0.3096\n",
            "t = 13, avg_loss = 0.3262\n",
            "Checking accuracy on test set\n",
            "Got 167 / 200 correct (83.50)\n",
            "acc = 0.835000\n",
            "Starting epoch 65 / 80\n",
            "t = 1, avg_loss = 0.2676\n",
            "t = 2, avg_loss = 0.2693\n",
            "t = 3, avg_loss = 0.3880\n",
            "t = 4, avg_loss = 0.6139\n",
            "t = 5, avg_loss = 0.3794\n",
            "t = 6, avg_loss = 0.3292\n",
            "t = 7, avg_loss = 0.3766\n",
            "t = 8, avg_loss = 0.3770\n",
            "t = 9, avg_loss = 0.3544\n",
            "t = 10, avg_loss = 0.2838\n",
            "t = 11, avg_loss = 0.3639\n",
            "t = 12, avg_loss = 0.4261\n",
            "t = 13, avg_loss = 0.2133\n",
            "Checking accuracy on test set\n",
            "Got 167 / 200 correct (83.50)\n",
            "acc = 0.835000\n",
            "Starting epoch 66 / 80\n",
            "t = 1, avg_loss = 0.2718\n",
            "t = 2, avg_loss = 0.3458\n",
            "t = 3, avg_loss = 0.2845\n",
            "t = 4, avg_loss = 0.3223\n",
            "t = 5, avg_loss = 0.3225\n",
            "t = 6, avg_loss = 0.3596\n",
            "t = 7, avg_loss = 0.3604\n",
            "t = 8, avg_loss = 0.4453\n",
            "t = 9, avg_loss = 0.4046\n",
            "t = 10, avg_loss = 0.3786\n",
            "t = 11, avg_loss = 0.3982\n",
            "t = 12, avg_loss = 0.2936\n",
            "t = 13, avg_loss = 0.3229\n",
            "Checking accuracy on test set\n",
            "Got 170 / 200 correct (85.00)\n",
            "acc = 0.850000\n",
            "Starting epoch 67 / 80\n",
            "t = 1, avg_loss = 0.3374\n",
            "t = 2, avg_loss = 0.2330\n",
            "t = 3, avg_loss = 0.3313\n",
            "t = 4, avg_loss = 0.3158\n",
            "t = 5, avg_loss = 0.5472\n",
            "t = 6, avg_loss = 0.3697\n",
            "t = 7, avg_loss = 0.3471\n",
            "t = 8, avg_loss = 0.3160\n",
            "t = 9, avg_loss = 0.4084\n",
            "t = 10, avg_loss = 0.3937\n",
            "t = 11, avg_loss = 0.3077\n",
            "t = 12, avg_loss = 0.4163\n",
            "t = 13, avg_loss = 0.5025\n",
            "Checking accuracy on test set\n",
            "Got 170 / 200 correct (85.00)\n",
            "acc = 0.850000\n",
            "Starting epoch 68 / 80\n",
            "t = 1, avg_loss = 0.1974\n",
            "t = 2, avg_loss = 0.5144\n",
            "t = 3, avg_loss = 0.3413\n",
            "t = 4, avg_loss = 0.4890\n",
            "t = 5, avg_loss = 0.2923\n",
            "t = 6, avg_loss = 0.4833\n",
            "t = 7, avg_loss = 0.2764\n",
            "t = 8, avg_loss = 0.3869\n",
            "t = 9, avg_loss = 0.2719\n",
            "t = 10, avg_loss = 0.3001\n",
            "t = 11, avg_loss = 0.3766\n",
            "t = 12, avg_loss = 0.3428\n",
            "t = 13, avg_loss = 0.4507\n",
            "Checking accuracy on test set\n",
            "Got 165 / 200 correct (82.50)\n",
            "acc = 0.825000\n",
            "Starting epoch 69 / 80\n",
            "t = 1, avg_loss = 0.3380\n",
            "t = 2, avg_loss = 0.4902\n",
            "t = 3, avg_loss = 0.3414\n",
            "t = 4, avg_loss = 0.3439\n",
            "t = 5, avg_loss = 0.5104\n",
            "t = 6, avg_loss = 0.3018\n",
            "t = 7, avg_loss = 0.2944\n",
            "t = 8, avg_loss = 0.3201\n",
            "t = 9, avg_loss = 0.4369\n",
            "t = 10, avg_loss = 0.2328\n",
            "t = 11, avg_loss = 0.2978\n",
            "t = 12, avg_loss = 0.3870\n",
            "t = 13, avg_loss = 0.4903\n",
            "Checking accuracy on test set\n",
            "Got 163 / 200 correct (81.50)\n",
            "acc = 0.815000\n",
            "Starting epoch 70 / 80\n",
            "t = 1, avg_loss = 0.2518\n",
            "t = 2, avg_loss = 0.2748\n",
            "t = 3, avg_loss = 0.3327\n",
            "t = 4, avg_loss = 0.3023\n",
            "t = 5, avg_loss = 0.3039\n",
            "t = 6, avg_loss = 0.4113\n",
            "t = 7, avg_loss = 0.3669\n",
            "t = 8, avg_loss = 0.4053\n",
            "t = 9, avg_loss = 0.5006\n",
            "t = 10, avg_loss = 0.3920\n",
            "t = 11, avg_loss = 0.3305\n",
            "t = 12, avg_loss = 0.4172\n",
            "t = 13, avg_loss = 0.4137\n",
            "Checking accuracy on test set\n",
            "Got 164 / 200 correct (82.00)\n",
            "acc = 0.820000\n",
            "Starting epoch 71 / 80\n",
            "t = 1, avg_loss = 0.3499\n",
            "t = 2, avg_loss = 0.3263\n",
            "t = 3, avg_loss = 0.2907\n",
            "t = 4, avg_loss = 0.3718\n",
            "t = 5, avg_loss = 0.2501\n",
            "t = 6, avg_loss = 0.2943\n",
            "t = 7, avg_loss = 0.3918\n",
            "t = 8, avg_loss = 0.5353\n",
            "t = 9, avg_loss = 0.3180\n",
            "t = 10, avg_loss = 0.3008\n",
            "t = 11, avg_loss = 0.3054\n",
            "t = 12, avg_loss = 0.4361\n",
            "t = 13, avg_loss = 0.4255\n",
            "Checking accuracy on test set\n",
            "Got 163 / 200 correct (81.50)\n",
            "acc = 0.815000\n",
            "Starting epoch 72 / 80\n",
            "t = 1, avg_loss = 0.2855\n",
            "t = 2, avg_loss = 0.3112\n",
            "t = 3, avg_loss = 0.2876\n",
            "t = 4, avg_loss = 0.4182\n",
            "t = 5, avg_loss = 0.4630\n",
            "t = 6, avg_loss = 0.4580\n",
            "t = 7, avg_loss = 0.4710\n",
            "t = 8, avg_loss = 0.2497\n",
            "t = 9, avg_loss = 0.3724\n",
            "t = 10, avg_loss = 0.3399\n",
            "t = 11, avg_loss = 0.3432\n",
            "t = 12, avg_loss = 0.3360\n",
            "t = 13, avg_loss = 0.2477\n",
            "Checking accuracy on test set\n",
            "Got 171 / 200 correct (85.50)\n",
            "acc = 0.855000\n",
            "Starting epoch 73 / 80\n",
            "t = 1, avg_loss = 0.3281\n",
            "t = 2, avg_loss = 0.2683\n",
            "t = 3, avg_loss = 0.3482\n",
            "t = 4, avg_loss = 0.3652\n",
            "t = 5, avg_loss = 0.3072\n",
            "t = 6, avg_loss = 0.4190\n",
            "t = 7, avg_loss = 0.2418\n",
            "t = 8, avg_loss = 0.3586\n",
            "t = 9, avg_loss = 0.3706\n",
            "t = 10, avg_loss = 0.3502\n",
            "t = 11, avg_loss = 0.2490\n",
            "t = 12, avg_loss = 0.2460\n",
            "t = 13, avg_loss = 0.3890\n",
            "Checking accuracy on test set\n",
            "Got 170 / 200 correct (85.00)\n",
            "acc = 0.850000\n",
            "Starting epoch 74 / 80\n",
            "t = 1, avg_loss = 0.2876\n",
            "t = 2, avg_loss = 0.4683\n",
            "t = 3, avg_loss = 0.2127\n",
            "t = 4, avg_loss = 0.3732\n",
            "t = 5, avg_loss = 0.3652\n",
            "t = 6, avg_loss = 0.3755\n",
            "t = 7, avg_loss = 0.3187\n",
            "t = 8, avg_loss = 0.4055\n",
            "t = 9, avg_loss = 0.3897\n",
            "t = 10, avg_loss = 0.3829\n",
            "t = 11, avg_loss = 0.3166\n",
            "t = 12, avg_loss = 0.2539\n",
            "t = 13, avg_loss = 0.2168\n",
            "Checking accuracy on test set\n",
            "Got 165 / 200 correct (82.50)\n",
            "acc = 0.825000\n",
            "Starting epoch 75 / 80\n",
            "t = 1, avg_loss = 0.4145\n",
            "t = 2, avg_loss = 0.2872\n",
            "t = 3, avg_loss = 0.2453\n",
            "t = 4, avg_loss = 0.2631\n",
            "t = 5, avg_loss = 0.2565\n",
            "t = 6, avg_loss = 0.3054\n",
            "t = 7, avg_loss = 0.4074\n",
            "t = 8, avg_loss = 0.4806\n",
            "t = 9, avg_loss = 0.3464\n",
            "t = 10, avg_loss = 0.4523\n",
            "t = 11, avg_loss = 0.2576\n",
            "t = 12, avg_loss = 0.3181\n",
            "t = 13, avg_loss = 0.4477\n",
            "Checking accuracy on test set\n",
            "Got 161 / 200 correct (80.50)\n",
            "acc = 0.805000\n",
            "Starting epoch 76 / 80\n",
            "t = 1, avg_loss = 0.3137\n",
            "t = 2, avg_loss = 0.2398\n",
            "t = 3, avg_loss = 0.2350\n",
            "t = 4, avg_loss = 0.3328\n",
            "t = 5, avg_loss = 0.3196\n",
            "t = 6, avg_loss = 0.3480\n",
            "t = 7, avg_loss = 0.4315\n",
            "t = 8, avg_loss = 0.3679\n",
            "t = 9, avg_loss = 0.3080\n",
            "t = 10, avg_loss = 0.4040\n",
            "t = 11, avg_loss = 0.2461\n",
            "t = 12, avg_loss = 0.3211\n",
            "t = 13, avg_loss = 0.3217\n",
            "Checking accuracy on test set\n",
            "Got 167 / 200 correct (83.50)\n",
            "acc = 0.835000\n",
            "Starting epoch 77 / 80\n",
            "t = 1, avg_loss = 0.3352\n",
            "t = 2, avg_loss = 0.2637\n",
            "t = 3, avg_loss = 0.2709\n",
            "t = 4, avg_loss = 0.3716\n",
            "t = 5, avg_loss = 0.3100\n",
            "t = 6, avg_loss = 0.4775\n",
            "t = 7, avg_loss = 0.3795\n",
            "t = 8, avg_loss = 0.3393\n",
            "t = 9, avg_loss = 0.2681\n",
            "t = 10, avg_loss = 0.2931\n",
            "t = 11, avg_loss = 0.5014\n",
            "t = 12, avg_loss = 0.3853\n",
            "t = 13, avg_loss = 0.2023\n",
            "Checking accuracy on test set\n",
            "Got 164 / 200 correct (82.00)\n",
            "acc = 0.820000\n",
            "Starting epoch 78 / 80\n",
            "t = 1, avg_loss = 0.2268\n",
            "t = 2, avg_loss = 0.2814\n",
            "t = 3, avg_loss = 0.2972\n",
            "t = 4, avg_loss = 0.4327\n",
            "t = 5, avg_loss = 0.3569\n",
            "t = 6, avg_loss = 0.1942\n",
            "t = 7, avg_loss = 0.2780\n",
            "t = 8, avg_loss = 0.3367\n",
            "t = 9, avg_loss = 0.3512\n",
            "t = 10, avg_loss = 0.2512\n",
            "t = 11, avg_loss = 0.2674\n",
            "t = 12, avg_loss = 0.3981\n",
            "t = 13, avg_loss = 0.6892\n",
            "Checking accuracy on test set\n",
            "Got 169 / 200 correct (84.50)\n",
            "acc = 0.845000\n",
            "Starting epoch 79 / 80\n",
            "t = 1, avg_loss = 0.2649\n",
            "t = 2, avg_loss = 0.3606\n",
            "t = 3, avg_loss = 0.3092\n",
            "t = 4, avg_loss = 0.2949\n",
            "t = 5, avg_loss = 0.3374\n",
            "t = 6, avg_loss = 0.2900\n",
            "t = 7, avg_loss = 0.3540\n",
            "t = 8, avg_loss = 0.3409\n",
            "t = 9, avg_loss = 0.2283\n",
            "t = 10, avg_loss = 0.2322\n",
            "t = 11, avg_loss = 0.3971\n",
            "t = 12, avg_loss = 0.3589\n",
            "t = 13, avg_loss = 0.2557\n",
            "Checking accuracy on test set\n",
            "Got 167 / 200 correct (83.50)\n",
            "acc = 0.835000\n",
            "Starting epoch 80 / 80\n",
            "t = 1, avg_loss = 0.2989\n",
            "t = 2, avg_loss = 0.3376\n",
            "t = 3, avg_loss = 0.3536\n",
            "t = 4, avg_loss = 0.3240\n",
            "t = 5, avg_loss = 0.3705\n",
            "t = 6, avg_loss = 0.1846\n",
            "t = 7, avg_loss = 0.2691\n",
            "t = 8, avg_loss = 0.3388\n",
            "t = 9, avg_loss = 0.2503\n",
            "t = 10, avg_loss = 0.3246\n",
            "t = 11, avg_loss = 0.2579\n",
            "t = 12, avg_loss = 0.3210\n",
            "t = 13, avg_loss = 0.4362\n",
            "Checking accuracy on test set\n",
            "Got 164 / 200 correct (82.00)\n",
            "acc = 0.820000\n",
            "Checking accuracy on test set\n",
            "Got 166 / 200 correct (83.00)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.83"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hm3h_Kyyp_6h",
        "colab_type": "code",
        "outputId": "86351ac7-635a-45d2-b9fd-ae798fae6f2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "check_accuracy(model_gpu, valid_loader)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking accuracy on test set\n",
            "Got 165 / 200 correct (82.50)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.825"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzuX5gLEeJfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def retry_from_backup():\n",
        "  model_gpu = model_base.type(gpu_dtype)\n",
        "  print(model_gpu)\n",
        "  loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) \n",
        "\n",
        "\n",
        "\n",
        "  checkpoint = torch.load(model_backup_path)\n",
        "  model_gpu.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  epoch = checkpoint['epoch']\n",
        "  loss = checkpoint['loss']\n",
        "  print(\"starting from epoch: \" + str(epoch))\n",
        "  print(\"starting from loss: \" + str(loss))\n",
        "  print(checkpoint['model_state_dict'])\n",
        "  print(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "  train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs, starting_from_epoch=epoch)\n",
        "  check_accuracy(model_gpu, valid_loader)\n",
        "#retry_from_backup()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDn-2g-TLY3k",
        "colab_type": "code",
        "outputId": "6fbbed87-5410-4785-faf8-1ebf1eb3b82f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot([print_every*batch_size*(i+1) for i in range((len(avg_loss_list)))],avg_loss_list)\n",
        "print(\"Loss:\")\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGer6hJv7-zR",
        "colab_type": "code",
        "outputId": "ce87cca2-5307-48f1-f005-ae61ee47441b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "plt.plot([i+1 for i in range((len(acc_list)))],acc_list)\n",
        "print(\"Accurancy:\")\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accurancy:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXzb9X348ddb8n3fjp3ERxLnJAk5SKBJKGsLhJDC2tIS2m6Ucqy/jbYrazvYwVa67tGubN260gMovcvdI9C0wAqUHBxx7jgksePEju0klo/Y8m1Jn98f+kqRbTmWHR+y9H4+HnpE+ur7ld8+8tZH788lxhiUUkpFLttUB6CUUmpiaaJXSqkIp4leKaUinCZ6pZSKcJrolVIqwsVMdQCD5eTkmJKSkqkOQymlppU9e/Y0GWNygz0Xdom+pKSE8vLyqQ5DKaWmFRGpGe45Ld0opVSE00SvlFIRThO9UkpFOE30SikV4TTRK6VUhNNEr5RSEU4TvVJKRThN9EqpqNLn8vDUO7W09/RPdSiTJqRELyIbReSYiFSJyP1Bni8SkddEZJ+IHBSRTdbxEhHpFpH91u374/0NKKXUaPz+8Bnu/9UhNn97Bwfrzk91OJNixEQvInbgEeAGYDFwm4gsHnTaPwHPGGNWAFuA7wY8d8IYc7l1+8w4xa2UUmNy7KwTu01wuT185Hu7eGLHSSJ9A6ZQlkBYA1QZY6oBROQp4GbgSMA5Bkiz7qcDDeMZpFJq6nz/TydYXJDG1fODLqMyYR55rYq3qpv9j2Nswt/fsJCFM9IuctXIjp/roDQnmec+cxVffPYgD714hAN15/mfLSsuNeSwFUrpZiZwOuBxnXUs0L8CnxSROmAb8NmA50qtks6fRGRDsC8gIveISLmIlDscjtCjV0pNKLfH8F8vH+fHu05N6tc91dTJwy8f43RLFx29Ljp6Xeysauapd06PfPEIKhudzM9PISMpjsf+chWfXlfKb/c3UH++exwiD0/j1Rl7G/BjY8wsYBPwMxGxAWeAIqukcx/wSxEZ8nZsjHnUGLPaGLM6N3dyWw1KqeE1nO+mz+2hoqFtUr/uEztPEmuz8cxfXcWv/3odv/7rdVw1N5vtlZfWEOzuc1Pb0kVZXioAIsKWNbMB2HGJrx3OQkn09cDsgMezrGOB7gSeATDGvAkkADnGmF5jTLN1fA9wAph/qUErpSbHCUcHAOfae3E4eyfla57v6uPZ8jpuuryQvLQE//ENZTmccHRypm3sLe8Tjg6MgQUzUv3HyvJSyE+LZ3tl0yXFDfDQC0e475n9YVfzDyXR7wbKRKRUROLwdrZuHXROLfB+ABFZhDfRO0Qk1+rMRUTmAGVA9XgFr5SaWCebOv33J6tV/4u3a+nud3P3hjkDjq8vywG4pIR8/JwTgPn5Kf5jIsK6eTnsOtGMxzP2BN3v9vBM+Wl+tbee5/cObgtPrRETvTHGBdwLvAS8i3d0TYWIPCQiN1mn/R1wt4gcAJ4EPmW8b2lXAwdFZD/wHPAZY0zLRHwjSqnQhTqGvNrRSWKsHYCKhvaJDAmAXpebH+86xdXzcwe0ugEW5KeSm3ppLe/j5zqItQvF2ckDjm8oy6Gls48jZ8b+Pe4/fZ6OXheZSbF85YWKS/rkMd5CqtEbY7YZY+YbY+YaY75mHXvQGLPVun/EGLPOGLPcGkb5snX8eWPMEuvYSmPMCxP3rSilQnGyqZOVD73C68caQzp3/oxUirKSJqVF/9v9DTicvdy9oXTIcyLChnk57KxqGnPL+/g5J3NyUoi1D0x96+Zd+qeF7ZVN2AR++um1uNyGv3/+UNiUcHRmrFJR5s0Tzbg8hpcqzo147smmTubkJLOkMG3CW/TGGH64/SQLZ6Sy3kq8g62/xJb38XNOygLKNj55qQksnJF6SZ29OyodLJuVwdJZ6TywaSFvHHfw1O5LHyU0HsJuK0Gl1KVrON9Nd7+bublDk9qemlYAdlRdPKl197mpP9/NnJxkbDbh94fP0t7TT1pC7JhiMsaws6qZs+09QZ+vb+3m2DknD390OSIS9BzfG8COqiYum5k+qq/f2euirrWbW1fPDvr8+nk5/PTNGrr73CTG2YOe4/EYdp1oZt287AExtvf0c6Cujb++Zi4An1xbzB8On+XfXjzC+nk5zM5KGlWs400TvVIR6J9/c5jKxg7+9KVrhiTNfbWtxNiE0y3d1DR3DqlX+5xq9nbEluYmkxzvTRVHGtq5ck72mGLaeqCBzz+1/6LnzMxI5KblhcM+n5eWwIL8VHZUNvGZ984d1devavSOICrLTw36/PqyHB7fcZJ3TrXw3mEmh716tJG7flrOf31sOR9eOct//M0Tzbg9xv9GZLMJ/3HLMq771ht865Xj/Netl48q1vGmiV6pCHS80Wkl8i5Kci4k8pbOPqqbOvnY6lk8U17H9sqmYRN9tcNK9DnJ5KV6hzlWjDHRn2vv4cHfVrCyKIP/vnUFwzTYyUyOIy7m4hXl9WU5/OytGnr63STEBm95BxNsxE2gtaXZxNlt7Kh0DJvod5/yjiV5bPtJPrRipv9NdHulg6Q4OyuKMv3nzspM4tYrZvOzN2v40sYFFKQnhhzreNMavQobDmcvj7xWRb/bM9WhTIqefjffebUS5zivotjrclPX6h3xsb1qYOfivlpv2ebDK2cxMyORHRfpfDzZ5G0Bl+Ykk5saT15qPBX1o++QNcbwwK8O0dPv5uGPLqcoO4nZWcFvKfEjtz3Xl+XQ5/L4k26oKhs7iIuxDfvGlhhnZ3VJ5kU7ZPfWthJrF949086uExeWZ9hR2cSVc7KHvEl9el0pHmOCziw+4ejge6+foLvPParvYyw00auw8e0/VvLNl46xdX90LJX06tFGHn75OD/aeWpcX7emuQvfYI/Bsz331HjLNstnZbB+Xg47TzThGuaNtdrRSUF6Aklx3uQ71g7ZZ/fU8erRRr68cSFzgvQZjNba0izi7LZRj5A5fs7J3NwU7LZhPk7gfRM5etYZdHJYn8vDgbo2tlxRRE5KPI9t904JOt3SxanmrqAdyLOzkrjhsgJ++XYtHb0u//Gefjef+dkevvGHo9z8yA4qrU8bE0UTvQoLrZ19PLvHO0Lhse3VYTMsbSL5OkV/+uYpevrHr1XnK7ksKUxj14nmAYl8T00riwvTSIyzs74sB2ePi4PDtNKrmzopDSj7XDYznSpHx6hibTjfzVdfOMKa0izueE/J2L6hQZLiYlhZnDH6RH/WyYJhyjY+G+Z5SzY7q4a+9pEz7fS5PFw1N5vbryrm9WMOKs852WGdu6Es+EihuzaU4uxx8UzACJxv/d9xKhs7+Pz7y2ju6OOD39nBM7tPT9jfvSZ6FRZ+8XYNPf0e7t5QytGzF/7zDKfP5eGzT+7j8BhKCeFiT00rGUmxNHX08Zt94zeTstoqufzlVcU4e1wcqPP+jPrdHg7WtbHSqiOvm5eDCEHLN8YYqh0dzMm9kOiXFKbh9hiOng2t9WmM4e+fP4jbGB6+ZTm2i7SkR2tDWS7vnmkPeSEyZ08/DW09w3bE+iwpTCMzKZY3ggyz9L0xryzK5JNXFpMQa+Px7SfZUdlEflo88/KCv4msKMrkipJMnth5Epfbw56aVh57o5rb1szmC9fO5/ef38DKoky+/PxB7nvmwCXNzh2OJno15byzIWt47/xcvnj9AnJT43ls+8mLXnP0bDsvHGjgV2E21TxUPf1uKhrauPWK2SwuSOPxHSfH7T/4SUcnuanxXLd4xoBEfvSMk+5+NyuLvYk+KzmOJYVpQRN9S2cf7T0uSnMuJK8lhd7hjKFOnPrlO7Vsr2zigRsWUpQ9vsMLb1peSEKsjX/+zeGQWsGV1oib+SMkeptNuGZBHn98t3FIX9He2lZmZiQyIz2BzOQ4blk1i1/vq+eNSgfr5+UOOyQU4K4Nc6hr7eY3+xv44rMHKEhP5B9v9G7rkZeWwM/uXMt9184nNzV+XN8Q/d/XuL+iUqP0230NNHX0cveGOcTH2Ln9qmLeOO7g2EVajofrvbXiPVbn4nRzuL6NfrdhVVEmd19dSlVjB386Pj6rJ560Si6ZyXFcVpjuHy+/1/pZrSq+MDJk/bxc9ta2Dqgf+14DYE5A6WZWZiJpCTFD6vTBEu3pli6+9rt3WTcvm0+sLR6X7yvQ7Kwkvnz9Ql492shze+qGPD84psoRRtwEunFpAW3d/UM+Ve6tafW/SQLcuX4O/R4Pzh7XsGUbnw8syqckO4n7nz/IyaZOvnnLsgEdz3ab8Ln3l/EPmxaNGN9YaKJXU8oYw+M7qlk4I5V187zD9j6x1vexePj173ytyiMNbeNa3x5v9/5yL/c9PXTsuL8MUJzJ5mWFzEhL8HfuhaLynJPV//ZK0NJVdVMnc62Sy/qyHPbVetdg2VPTyoy0BArTB64I6fIY3g7Y4AMu1PkDSzciwpLCdP/Im16Xm6+8UMHKr77Cr/ZeSLYej+FLzx3AJsI3PrJsQlqoAJ96TwlrSrN46IUjNASUcI6ddXLD/2znY99/01/aOX6ug4RYG7MzR/5ksWF+DqkJMfzu4Bn/sYbz3Zxp62FlUYb/WGlOMh9YlA9cWEJhOHabcOf6Ulwew19eVcx7Rjh/vGmiV1PqT8cdHD/Xwd0b5vg/+mYmx/Gx1bP57f4GGp3BZ1FWNLQTZ7fR7zYcCtM6/dGz7bx48AxbDzTQ2tk34Lm9ta0UZyeRkxJPrN3Gp9aVsOtEc8hlke//qZqmjj5eOzpwvZrzXX20dPb5O1E3zPMm8rdONLO3tpWVxRkDSgyrijOJjxk6gqW6qZNYuzAzY+DY78tmpnH0rJOqxg4+8r1d/GjnKTKS4rjvmQN88dkDdPW5+NlbNbxV3cI/3biIWSEk1rGy2YSHb1mO2+oLMMbw5Du13PSdHTR1eJdJ2PQ/23m54qx36YO81JDedOJj7Fy3eAYvVZyl1+VtRAT7NATw0M1L+MFfrCI3NX7E192ypojvfHzFhLXaL0YTfQQ53dI11SGM2uPbT5KfFs8HB82G/PS6Uvo9Hn66q2bINS63h3fPtHPjsgLA+5F6JC2dfSGPV3d7DE0dw6+9Xn++m92nWvy348MMjXt8+0nv3qQew8tHzvqPG2PYU3OeVQGTa25bU0RynJ3HR+ibAO/ko60HvH0Tg0tX1f6Si7dEsaokk4RYG7/aV0dda7e/I9YnIdbOmtKsIWu8nGzqoDg7mZhBi38tKUyn1+Vh07e3c7qlm0f/YhWvfOFqPve+eTy/t44P/u8Ovv77o1yzIJdbrwi+1MB4KspO4oFNi9he2cRN39nJA786xJrSLH7/+Q28+Nn1FGUlcc/P9vBWdXPQNW6Gs3l5Ac4el7//Yk9NKwmxNhYVDNw3qSA9keuXzAjpNWPtNjYvKxzVJK/xook+Qhw/52TDf7w2bnXeidbT7+ZffnuYHVVN3LGudMhEk5KcZK5dlM+T79QO6aSsbuqk1+VhQ1kOpTnJ/jLIcNwew0e+t4v7njkQUmz/urWCDd94jWpr041Ah+vbuOabr/HR77/pv133rTd4pnzg4lWN7T38dn89n1hbRHF2Ei8GlAHqWrtp6uhlRUDrMD0xlo9dMZsXDjTQMqj1P9hPdp3C5TGsm5fN3prWAT+fk44LyxaAt3W6pjSb3x/2vtGsHNQiBXjv/FxOODoHlG+qHQOHVvpcPjsDm8BlhWls+/wGrlsygxi7jfuuW8DP71xLe4+LWLvw9Q8vu2jn5Hj65Noi1s/L4ciZdr68cQE/uWMNuanxlOQk89z/u8rbaHAbls/KGPnFLOvm5pCeGOv/ve2tPc+yWRlDVr2cLqZn1GoI35C3XScufZeciVbt6ODD393FT96s4c71pdy5fuiStAA3LJ1Bc5CVCn3ljctmprOiKIO9ta0XHXnxUsVZTjZ1sqOyyf9RfDgOZy9Pl5+mu9/NF589gDsgifa6vMcykuL48R1X8PM71/LzO9eypiSLrw6qE//kTW8y/vS6UjYvK2DXiWaarU8JvjemVYNa17esmmWtKnmW4XT1ufjF27VsXDKDP798Ju09Lv9wSvB2otptMqAWvWFeDsZAXIyNJYVDN9a+bU0RRVlJfOm5g3T2unB7DDXNXQM6Yn1KcpJ5/Yt/xtN/ddWQss66eTn8333v5aUvXM2MgH6AiSYiPPaXq3nt767hr6+ZN6A8Ex9j58EPLuZPX7qGT6wtCvk142JsXL8kn1eOnKOtq5+K+rYhZZvpRBN9hKi1FqDaV3N+iiO5uN8fOsMH/3cHDW3d/PD21fzz5sXDtpKGWyP8cH078TE25uQks6o4k6aOPk63DD+e+rHt1cTahe5+94it/5+9VUO/28Pn3l/G3trzAzqEv/3HSo6edfL1Dy/lmgV5rC/LYX1ZDg9/dGCduKvPxc/fquW6xfmU5CRz49JC3AHLAu+paSU5zj5kY43FBWmU5iTz4sHhZwY/W15HW3c/d22Y42+dB35P1U0dFGUlDfiE5NuZadnMdOJjhpYNkuNj+OYtyzjd2sU3/nCU+lbvPrGBHbGBirKThv2dpSfGTsmaLolx9osO4QxWhhrJ5mWFdPS6+M5rlbg8ZkjZazrRRB8haq36/IG68/S5wnOtmB6rlTwvL4Xff34D77dGLAxnuDXCKxraWFiQRozd5v/Pt6c2+Lone2pa2Fd7nr/9wHxibHLRtV26+9z8/K0a3r8wny98oIzrFufzn68cp/KckwOnz/O9109wy6pZQ+IOrBP/8p1antvjTca+rfAWFaQyJyCB761t5fKijCFT8UWEG5cW8OaJ5qB9BG6P4Yc7TrKyKINVxZnMyUkmIymWvQFv7sFKLgtnpLJwRiofWDz8z3vtnGzueE8pP32zhp+/7e0XCRxDH42umptNZlKsf52awBE3040m+ghR09yFCPS6PJe0HdpEev1YI519br50/cKQW33r5+VQfqrVv/CTMYaKhnYus0oQ8/NTSYmPGbal/ugb1aQnxnLHuhJWFGVcdMbt83vraOns4+4NpYgIX/vQUpLj7Nz3zAH+7tkD5Kcl8OAHFwe91lcn/trv3uX7r5/g8tkZ/o/6IsLmZQW8Vd1MbXMX755pH7Z1uHl5AR6Dv6Ye6OWKs9S2dPnfQESElUWZ/g5Zj8dwqrlzSMlFRPjD31494rK+X964gDk5yTz6hvdTTLAafTSJtdvYeFkB/W5DSXYS2Skjj6wJV5rop5FXjpzjhQPBP9afbuniPXO949BDGYUyFV48eIbs5DiunJMV8jXry3Loc3t4x1qp8HRLN84el3+Wpt0m3jp9kJLVqaZOXj5yjk+sLSIpLob183I5VN82ZKgjeJPkEztOsmxWOmtKvfHlpsbzb3++lEP1bVQ1dvCNjywbdtMNEeEbtyzDJkJDWw/3XD1nQGfkjcsK8Rj4xh+O4jHBO0XBuy/q3NxkfjeofGOM4dHt1RRlJXFdwCiPVcWZVDV2cL6rjzPtPfT0e/wdsaOVEGvn4Y8txyaQmhBDTkrcmF4nkmy2RnYN9/uaLkJK9CKyUUSOiUiViNwf5PkiEXlNRPaJyEER2RTw3APWdcdE5PrxDD7afPf1Kh5++diQ470uN2fae1hTks3MjMSwnC3a3efmj+82svGyGaOqlQauEQ4XOmIDOxVXFGVy9Gz7kNmdT+w8SYxN+JS1mNb6Mm+nZODysj5/PNpIdVMnd20YnKAL+Mx75/LF6+Zz9TBrlPvMzEjkPz+2nA+tmDlkyN38/BTm5aXwu0PeURwrZwdPHCLCjcsKeftky4A5BE++c5p9tef562vmDij5+D4Z7Dt9/sKIm0toia8syuQfNi3i42uKJm3UTDhbW5rFpqUzuCVgk5HpaMT/cSJiBx4BbgAWA7eJyODPr/8EPGOMWQFsAb5rXbvYerwE2Ah813o9NQb1rd3UtnQNWb/6dEs3xkBRdiIrizPDskX/6tFGuvvd/rHvoUqMs7Oq+MIa4Ycb2rDbZEBH5qriTDwGDpy+0Ko/39XHs+V13Hz5TPLSvCNAls9KJzUhJugWeo9tr2ZmRiKbLhs6Jvr+GxZy7/vKQor3+iUz+Natlw9bfweYl5dCetLw2/FtXlaAMfD7Q97yjXc5gSOsm5fNxwZtg7d8djp2m7C3ptU/+ibY9oGjcdeGOTwwBZN6wlGM3cZ3P7Fq0meyjrdQmlZrgCpjTLUxpg94Crh50DkG8DWx0gHf586bgaeMMb3GmJNAlfV6apR6+t00Onsx5sKWaD6+iVJFWcmsLMrgTFvPgKF+l+qJHSf5x18fCuncPTWtfPLxt2kctC/o7w41kJMSz9rS0e9OFLhGeEVDO2V5KQMmnVw+29tJ5nuD63W5+eqL79Ld7+auDReGbsbYbVw1J5s3jjcNGI5ZfqqFd062cMe6klGPzBgNfxlghE69+fmpzM9P4XcHz/iXExAR/iPICpBJcTEsKkhlb20r1Y5OkuPs5IUwS1NFl1D+qmcCgbNB6qxjgf4V+KSI1AHbgM+O4lpE5B4RKReRcodjekz4mWxn2i4kzsEzMWusoZVFWUn+DsC941i++cmbp/jF27WcbQu+HEGgb750lB1VTfzDrw/5k2lnr4tXjzayaemMi276MBzfglE7q5qoaGhn8aCx4OmJsczPT2FPbSunmjr5yPd28fzeOv7fNXNZOCNtyGvVn+/mVLP3zbGn382Xnz9IYXoCW9aEPs56LMryU/nnzYu5y+pMvZjNywrZXdPCN18+xlvVLfzz5kVDxq37rCzKZH/teaoaOyjNTdaSixpivJovtwE/NsbMAjYBPxORkF/bGPOoMWa1MWZ1bu7F66DRqr71Qgv9eOPARF/b0k1SnJ2clDgWFaSREGsb0jnpcnuG3UnoYk63dFFjJcVth85c9NzD9W28Vd3CksI0/u/dRp63lhB+9WgjPf0eNi8bftPni1lSmE5GUiy/2lePw9nLZVZHbKCVRZm8Xd3C5v/dwemWbn7wF6v4+40Lh5y3vsz79+Wr+X/zpWNUOzr5j1uWh7SN3aW6c33piEvlAmxa6i3ffO/1E1yzIHdIySbQquJMOvvcvH2yOeqHRKrgQknG9UDgX9ks61igO4FnAIwxbwIJQE6I16oQ1LV6k216YiyV5waWbmpbOinKSkJEiLXbWDYrY0CHrMdjuPMn5dz22Fuj/rq+2nhOSpy/I3E4j22vJiU+hl/edSVXlGTylRcqONPWzYsHG8hLjWf1GEcu2G3Cunk5vGEt7xBsducVJVl097tZMCOVbZ/fMOz6IyXZSczMSGR7ZRPvnGzhiZ0n+eSVRf5JReFiXl4KiwrSSEuIGXE5AV+HbL/bRP2QSBVcKIl+N1AmIqUiEoe3c3XroHNqgfcDiMgivIneYZ23RUTiRaQUKAPeGa/go0n9+W4r4WUPWae9tqWLoqwLswJXFWdSUX9h+d5fvF3Dn4472H3KW9oYjR1VDmakJfCp95Swp6Z12Np/w/luXjx4hluvmE16UiwPf3Q5LrfhvqcP8NoxB5uWFlzScrUbAjrDBpduAG6+vJAf3XEFT91z5bAlDvB2im4oy+HNE8186bkDzM5M4oEbwrPj8TsfX8HTf3XViMsJzMpM9K+eOHeMQytVZBsx0RtjXMC9wEvAu3hH11SIyEMicpN12t8Bd4vIAeBJ4FPGqwJvS/8I8Afgb4wx4bt4eBg4VNcWdN2WutZuZqQlsLggjfrz3XRaQwmNMUMS/cqiTFwe7/K9Nc2d/Pu2o6ywOgBHapUHcnsMO6ua2VCW4y+7DFe+8c0evGNdCeCdcv7ApoW8Wd1Mn8vDB5ePbrTNYL4Wd0l2EqlBxrLH2G382YK8kBadWl+Wg7PXRW1LF9+8ZRnJk1CyGYu5uSlDVksMRkT86+Zoi14FE1Id3RizzRgz3xgz1xjzNevYg8aYrdb9I8aYdcaY5caYy40xLwdc+zXrugXGmN9PzLcRGXafauGD39kRdJx3fWs3MzMT/Xte+rZGa3T20tPvoTg7MNFn+F/vS88eJMYufPcTK1lVnDlgFcWRHKpvo627n/VlOZTkJHPZzLSg1zt7+nny7VpuuGzGgPXHP7m2mPXzcijOTmLFMOPGQzUrM4lFBWlcURL6ZKvhrJubQ0KsjTvXlbJ2zuhHAYWj9WU5JMfZmXOJQytVZArPpkyU2mfV1Q/Xtw3ZsaautYsr52T7O/KOn3Ny+ewM/xo3RdkXWnLZKfGU5iTzvddO4Ox18fBHl1OQnsiNSwt46MUjnHB0hDTW2tdh6YvlxqWFfOMPRznd0sXsgE8QT+8+jbPXxT1XDxxNYrMJj9++mt5+z7jsMvTMX105LsvEZibHsf3L74uomZ8fX1PEpqUFk9KhrKYfXQIhjPj2QT0+qLO13+3hbHsPszITKcpKIj7G5t8D0zciJrB0A7CiKANnr4sPLMrjIyu9I1o3LS1AhAFbpF3M9somFhekkWOt8eGb8BNYvunodfGjnadYU5rFsiDrfSfE2i86OWg0UhNix23ThtzU+IgahmizCVnJkfPGpcaXJvow4pveXzlo+OTZth48BmZmJmK3CXNzUzhmvRnUtnRhE4Z0QG5cMoN5eSn8+4eX+hPajPQErijOCinRd/a62FvbOmDT46LsJJbPSvfX+Ssa2rjpf3dwpq2bz75v3ti/caXUhNJEHya6+lxUN3USYxMqz3UM2DWozhpD76t/L5iR6m/R1zZ3UpCeOGSHpuuWzOD/7nsveakDR2zcuKyAY+ec/uuH887JFvrdZsiwwxuXFXCwro3/fPkYH/ruLjr7XPzy7ivZUKbzH5QKV5row8S7Z9oxBq5ZkEd3v9uf3AH/Tva+VntZfgpn2npo7+mntqVrQEfsSG5YOgMRRuyU3V7ZRFyMbUjn5yarfPO/r1bxnrnZbPvcBq6MkA5NpSKVJvowUdHgrc9/aIW3nh64zIFvslRBhrd1Pj/PGnlzrmPI0MqR5KUmsLY0ixcPNlx0+70dVQ7WlGQNqYnPykzic+8v48HNi3ni9ium9RrdSkULTfRhoqK+nazkODbM95ZKApc5qG/tJj8t3r8NnG/kzb7aVpo6+i66hVowNy4r5ISjk2PDlIfNY6IAABqYSURBVG/Otfdw/FzHgPp8oPuunc+n15eOy0gapdTE00Q/wX538Awf+d6uAZtMB3O4oY0lhWmkJcRSkJ4wYJmDutbuAZ2tszITSYy188d3G4GhI25GcsNlM7AJbDsUfBPqndYuTOG2LIBSamw00U+wt6qb2VPTysG64Tft7nN5OH7O6d81qSw/dUDppv5894CJSDabUJafwm5r16XirNHNhsxJieeymem8c3LoxCyA3adaSU2IYdGMkWdlKqXCnyb6CebbJehim1IfP+ek3238i3UtyE+hqrEDt8fg9hgazntnxQYqy0vFZX1KGG2LHrzLJBw43RZ0Rcu9Na2sKMrU0oxSEUIT/QRzOHsB2H6RTamPWB2xvkRflp9Kr8tDbUsXjc4eXB4zZJz8/HzvzNb0xNgxTUhaVZxJd7+bo4MWSGvv6ed4o9O/dopSavrTRD/BGq1Ev6+21b8Q2WAVDW0kx9kpsZYxCFzmoN4/hn5woveeM5qhlYF8mx3vGbTt4P7a8xiDfwMTpdT0p4l+AhljaHT2sqQwjX634e1hauKHrV2TfKWSsjxva73ynDNgstSgRG/tmTp7DGUbgML0BGakJQxJ9HtrWxHx7kWqlIoMmugnUHuPiz6Xh01LC4iPsfk38Qjk9hjePdPu74gFSI6PYWZGIsfPdQRMlhqY0AvTE5iVmciK2Rfff3Q4IsLK4owhWw7uqWllQX5q0KWAlVLTky51N4EcVkfsrMxE1pRmBe2QPdXcSVefe8iuSfPzUzh+zklyvJ3s5DgS4wZOXBIRXv/iNWPag9VnZVEm2w6dpbG9h7y0BDwew/7a83zw8rFt+aeUCk/aop9Aje3e+nxuajzr5+VQ2dgxZIPtw/XehcyWDNoHdf6MVKodndQ0dw0ZceMTY7dd0gqMKwdtJF7Z2IGz16UdsUpFGE30E8jR4U30eakJ/slHOwaNvjnS0E6c3UZZ/sD14efnpdLn9rCnpnVIfX68LClMIy7G5q/T+xL+Su2IVSqiaKKfQL4WfV5aPItmpJGdHOffzMPncEMbC2akDtlQwzeqptfluegeqJciPsbO0pnp/kS/p6aVrOQ4SsY4kkcpFZ400V8ij8fw+af28Vb10BE1jc4e4mNspMbHYLMJ68ty2FHV7F9MrKa5k4N1bUPq8wDz8lLwVWUCZ8WOt1XFmRyub6fX5WZvbSsrizIjakMOpVSIiV5ENorIMRGpEpH7gzz/LRHZb92Oi8j5gOfcAc9tHc/gw0FlYwe/3d/ASxVD141xOHvJS7uwk9H6eTk0dfRy9KyTFw40cOO3dyDArVfMHnJtYpyd2VaCn6gWPXj3l+1ze9hR2US1o5OVxWMbxaOUCl8jjroRETvwCHAtUAfsFpGtxpgjvnOMMV8IOP+zwIqAl+g2xlw+fiGHF1/Zo9ba0i9Qo7N3wMYfvs05PvvkPqoaO1hZlMG3b1sxbIt9fn4KtS3Dd8aOh5VWx+sPd5wE0I5YpSJQKC36NUCVMabaGNMHPAXcfJHzbwOeHI/gpgNfB6Zvk+5Ajc5ecgPWa5+RnkBZnncdm8+8dy5P/9VVFy3LLJyRhggTmujz0rzj8XedaCbGJkH3fVVKTW+hjKOfCZwOeFwHrA12oogUA6XAqwGHE0SkHHABXzfG/CbIdfcA9wAUFRWFFnmY2FtzIdF7PGbAQmAOZy/vmTtw96Vv37aCrj53SEsMfHp9KatKMkmb4MlLq4ozqWvtZnFh2pDx+kqp6W+8O2O3AM8ZY9wBx4qNMauBjwP/LSJzB19kjHnUGLPaGLM6N3f67D3a0tlHdVMnMzMS6XV5/MMpAXr63bR195OXOnAHpkUFaSGvI5OVHMefLcgb15iD8cWzUss2SkWkUBJ9PRDYWzjLOhbMFgaVbYwx9da/1cDrDKzfT2v7rLLNn6/wziStCajT+1atzE0N/632rpyTjQhcNVf3flUqEoWS6HcDZSJSKiJxeJP5kNEzIrIQyATeDDiWKSLx1v0cYB1wZPC109WemlZibMKNS72JPrBOHzhZKtzNz0/lT1/8M65bnD/VoSilJsCINXpjjEtE7gVeAuzAE8aYChF5CCg3xviS/hbgKTNwx+lFwA9ExIP3TeXrgaN1pru9ta0sLkxjXl4KNoHa5k7/c4HLH0wHo913Vik1fYS0qJkxZhuwbdCxBwc9/tcg1+0Cll5CfGHL5fZw4HQbt14xm7gYGwXpidQEtuitBc0G1+iVUmqy6czYMTp61kl3v9u/LkxxdtLA0o2zF5tAdoomeqXU1NJEP0a+iVK+EStFWUkDJk01OnvJTom/pGWElVJqPGiiH6O9ta3kp8VTmO7tbC3KTqK5s48Oa7vAwZOllFJqqmiiH6M9Na2sKr6wAFiRtaWfr1XvW+dGKaWmmib6MWhs76GutXvABKPiLO/G3r46faOzRztilVJhQRP9GATboMPfom/pxO0xNHX0TZuhlUqpyKaJfgz21LQSF2MbsI58elIs6Ymx1LZ00drVh9tjpsVkKaVU5NNEP0q7T7Xw630NLJ+VTnzMwAXAirKSqGnuurCzlLbolVJhQBN9iDwewyOvVbHl0bdIjrfzlZsuG3JOkTWWvtGaLKWlG6VUOAhpZmy0cXsMrx5tpNflXYTTGHim/DTbK5v44PJC/v1Dl5EaZOng4qwkXjp8lrNtvlmxWrpRSk09TfRBbD1QzxeePjDgWHyMja9/eCm3XjF72D1Vi7KScHkMB+raAG3RK6XCgyb6IF44cIaZGYn8+I4r/MeyU+LJSo676HW+hcHKT7WQGh+jm3gopcKCJvpB2rr62V7p4I51pZTlp47qWt8Qy8rGDubkJk9EeEopNWraGTvIS0fO0u823Li0YNTXFqQnEmv3lnV0+QOlVLjQRD/I7w6eYXZWIstmpY/6WrtN/Jt956VpR6xSKjxoog/Q2tnHzqomblxaOGyH60h85RsdQ6+UChea6AO8VHEWl8ewednoyzY+vkSvI26UUuFCE32A3x06Q0l20oClDUarOFtb9Eqp8BJSoheRjSJyTESqROT+IM9/S0T2W7fjInI+4LnbRaTSut0+nsGPp+aOXnadaObGZQVjLtsAFGd7R9vka41eKRUmRhxeKSJ24BHgWqAO2C0iWwM3+TbGfCHg/M8CK6z7WcC/AKsBA+yxrm0d1+9iHPyh4ixuj+HGpYWX9DrXLMjl3z+0lLWlWeMUmVJKXZpQWvRrgCpjTLUxpg94Crj5IuffBjxp3b8eeMUY02Il91eAjZcS8ER58cAZ5uQms6hgdGPnB4u12/j42iJi7FoVU0qFh1Cy0UzgdMDjOuvYECJSDJQCr4722qlU19rF2yeb2bz00so2SikVjsa72bkFeM4Y4x7NRSJyj4iUi0i5w+EY55BG9qOdp7CJsGVN0aR/baWUmmihJPp6YHbA41nWsWC2cKFsE/K1xphHjTGrjTGrc3NzQwhp/LT39PP07tPcuKyAwozESf3aSik1GUJJ9LuBMhEpFZE4vMl86+CTRGQhkAm8GXD4JeA6EckUkUzgOutY2HjqnVo6el3cvWHOVIeilFITYsRRN8YYl4jcizdB24EnjDEVIvIQUG6M8SX9LcBTxhgTcG2LiHwV75sFwEPGmJbx/RbGrt/t4Uc7T3HlnCwumzn6JQ+UUmo6CGn1SmPMNmDboGMPDnr8r8Nc+wTwxBjjm1DbDp3hTFsPX/vQ0N2ilFIqUkTtGEBjDI9tr2ZubjLXzM+b6nCUUmrCRG2if7O6mcP17dy1YQ42mw6pVEpFrqhN9D/eeYrs5Dg+tCLshvUrpdS4itpEf+RMOxvKckiI1e3+lFKRLSoTvTGGRmevLjymlIoKUZno27td9Lk8uma8UioqRGWid3T0ALo5iFIqOkRlom9s7wUgL1VLN0qpyBedid5pJfo0bdErpSJflCZ6Ld0opaJHVCZ6h7OXhFgbqfEhrQChlFLTWlQm+kZnL3mpCbrJiFIqKkRnom/v1bKNUipqRGWid3T0kqeJXikVJaIy0Te292iiV0pFjahL9D39btp7XFq6UUpFjahL9A6nTpZSSkWXqEv0vslSuTpZSikVJaIu0Tt8k6VSNNErpaJDSIleRDaKyDERqRKR+4c552MickREKkTklwHH3SKy37ptDXbtZNLlD5RS0WbEqaEiYgceAa4F6oDdIrLVGHMk4Jwy4AFgnTGmVUQCN2HtNsZcPs5xj5nD2YtNIDtZE71SKjqE0qJfA1QZY6qNMX3AU8DNg865G3jEGNMKYIxpHN8wx09jey85KfHYdZ9YpVSUCCXRzwROBzyus44Fmg/MF5GdIvKWiGwMeC5BRMqt438e7AuIyD3WOeUOh2NU38BoNTp7dGilUiqqjNeqXjFAGXANMAt4Q0SWGmPOA8XGmHoRmQO8KiKHjDEnAi82xjwKPAqwevVqM04xBaWzYpVS0SaUFn09MDvg8SzrWKA6YKsxpt8YcxI4jjfxY4ypt/6tBl4HVlxizJeksb1Xx9ArpaJKKIl+N1AmIqUiEgdsAQaPnvkN3tY8IpKDt5RTLSKZIhIfcHwdcIQp4vYYmjp0QTOlVHQZsXRjjHGJyL3AS4AdeMIYUyEiDwHlxpit1nPXicgRwA18yRjTLCLvAX4gIh68bypfDxytM9laOvvwGB1aqZSKLiHV6I0x24Btg449GHDfAPdZt8BzdgFLLz3M8eHbWUpr9EqpaBJVM2P9yx9ooldKRZGoSvSOdl3QTCkVfaIr0Xdoi14pFX2iKtE3tveQmhBDQqx9qkNRSqlJE12J3qmTpZRS0SeqEr3DqZOllFLRJ6oSfaNTJ0sppaJP1CR6YwyNTt0UXCkVfaIm0Xf0uujp9+isWKVU1ImaRN+om4IrpaJU9CT6dh1Dr5SKTtGT6HWdG6VUlIqaRO/Q0o1SKkpFVaKPs9tISxyvTbWUUmp6iJpEX93UyeysRER0U3ClVHSJmkRfec7JghmpUx2GUkpNuqhI9D39bmpauijL00SvlIo+UZHoqxo7MAbm52uiV0pFn6hI9MfPOQGYn58yxZEopdTkCynRi8hGETkmIlUicv8w53xMRI6ISIWI/DLg+O0iUmndbh+vwEfj+LkOYu1CSU7yVHx5pZSaUiOONRQRO/AIcC1QB+wWka3GmCMB55QBDwDrjDGtIpJnHc8C/gVYDRhgj3Vt6/h/K8OrPOekNCeZWHtUfIBRSqkBQsl8a4AqY0y1MaYPeAq4edA5dwOP+BK4MabROn498IoxpsV67hVg4/iEHrrjjU6tzyulolYoiX4mcDrgcZ11LNB8YL6I7BSRt0Rk4yiuRUTuEZFyESl3OByhRx+Crj4Xp1u6NdErpaLWeNUyYoAy4BrgNuAxEckI9WJjzKPGmNXGmNW5ubnjFJJX5bkOQDtilVLRK5REXw/MDng8yzoWqA7YaozpN8acBI7jTfyhXDuhfCNuyrRFr5SKUqEk+t1AmYiUikgcsAXYOuic3+BtzSMiOXhLOdXAS8B1IpIpIpnAddaxSVPZ2EGc3UZxVtJkflmllAobI466Mca4RORevAnaDjxhjKkQkYeAcmPMVi4k9COAG/iSMaYZQES+ivfNAuAhY0zLRHwjwzl+zsmc3GRidMSNUipKhbSUozFmG7Bt0LEHA+4b4D7rNvjaJ4AnLi3Msas818Gq4syp+vJKKTXlIrqZ6+zpp/58ty5mppSKahGd6CsbvSNuyvJ0xI1SKnpFdqL3r3GjLXqlVPSK6ER//FwH8TE2ZuuIG6VUFIvwRO9kXl4KdpvuKqWUil4Rnegrz3Vo2UYpFfUiNtG3dfdztr1HE71SKupFbKKv1M1GlFIKiOBEX9vSBaCbjSilol7EJvqmjl4AclPjpzgSpZSaWhGc6PuIi7GRGh/SKg9KKRWxIjfRO3vJTYlHRIdWKqWiW8QmekdHLzkpcVMdhlJKTbmITfRNHX3kpGh9XimlIjjR92qiV0opIjTRezyGls4+clK1dKOUUhGZ6Fu7+nB7jLbolVKKCE30TR19AJrolVKKiE303slSmuiVUirERC8iG0XkmIhUicj9QZ7/lIg4RGS/dbsr4Dl3wPGt4xn8cC7MitUavVJKjThtVETswCPAtUAdsFtEthpjjgw69WljzL1BXqLbGHP5pYcaOodTW/RKKeUTSot+DVBljKk2xvQBTwE3T2xYl6apo49Yu5CeGDvVoSil1JQLJdHPBE4HPK6zjg32ERE5KCLPicjsgOMJIlIuIm+JyJ8H+wIico91TrnD4Qg9+mE0dfSSnazLHyilFIxfZ+wLQIkxZhnwCvCTgOeKjTGrgY8D/y0icwdfbIx51Biz2hizOjc395KDaero1TH0SillCSXR1wOBLfRZ1jE/Y0yzMabXevg4sCrguXrr32rgdWDFJcQbkqYO74JmSimlQkv0u4EyESkVkThgCzBg9IyIFAQ8vAl41zqeKSLx1v0cYB0wuBN33DU5dZ0bpZTyGXHUjTHGJSL3Ai8BduAJY0yFiDwElBtjtgKfE5GbABfQAnzKunwR8AMR8eB9U/l6kNE648oYQ3NnLzm64YhSSgEhJHoAY8w2YNugYw8G3H8AeCDIdbuApZcY46i0dffT79blD5RSyifiZsZemBWrnbFKKQURmOgdTu86N9oZq5RSXhGX6P0teq3RK6UUEMmJXlv0SikFRGiit9uEDF3+QCmlgAhM9A5nL9nJcdhsuvyBUkpBBCZ63RRcKaUGisBEr5OllFIqUOQlemevjqFXSqkAEZXojTE0dfTpGHqllAoQUYm+vcdFn9ujNXqllAoQUYn+wmQpLd0opZRPZCV63StWKaWGiKxE3+Fd50YTvVJKXRBhiV5b9EopNVjEJXqbQFay1uiVUson4hJ9VnIcdl3+QCml/CIq0Tt0r1illBoiohJ9U0cvubr8gVJKDRBSoheRjSJyTESqROT+IM9/SkQcIrLfut0V8NztIlJp3W4fz+AHa+ro1Ra9UkoNMuLm4CJiBx4BrgXqgN0istUYc2TQqU8bY+4ddG0W8C/AasAAe6xrW8cl+gDe5Q90nRullBoslBb9GqDKGFNtjOkDngJuDvH1rwdeMca0WMn9FWDj2EK9uM4+Nz39uvyBUkoNFkqinwmcDnhcZx0b7CMiclBEnhOR2aO5VkTuEZFyESl3OBwhhj5Qv8vD5mUFLCpIG9P1SikVqcarM/YFoMQYswxvq/0no7nYGPOoMWa1MWZ1bm7umALITI7jOx9fydXzx3a9UkpFqlASfT0wO+DxLOuYnzGm2RjTaz18HFgV6rVKKaUmViiJfjdQJiKlIhIHbAG2Bp4gIgUBD28C3rXuvwRcJyKZIpIJXGcdU0opNUlGHHVjjHGJyL14E7QdeMIYUyEiDwHlxpitwOdE5CbABbQAn7KubRGRr+J9swB4yBjTMgHfh1JKqWGIMWaqYxhg9erVpry8fKrDUEqpaUVE9hhjVgd7LqJmxiqllBpKE71SSkU4TfRKKRXhNNErpVSEC7vOWBFxADWjuCQHaJqgcMYqHGMCjWs0wjEmCM+4wjEmiL64io0xQWeMhl2iHy0RKR+up3mqhGNMoHGNRjjGBOEZVzjGBBpXIC3dKKVUhNNEr5RSES4SEv2jUx1AEOEYE2hcoxGOMUF4xhWOMYHG5Tfta/RKKaUuLhJa9EoppS5CE71SSkW4aZvoR9qwfBLjeEJEGkXkcMCxLBF5xdoQ/RVriebJjGm2iLwmIkdEpEJEPh8mcSWIyDsicsCK6yvW8VIRedv6XT5tLYc9qUTELiL7ROTFMIrplIgcEpH9IlJuHZvS36EVQ4a1k9xREXlXRK6ayrhEZIH1M/Ld2kXkb8PkZ/UF62/9sIg8af0fmPS/rWmZ6AM2LL8BWAzcJiKLpyicHzN0H9z7gT8aY8qAP1qPJ5ML+DtjzGLgSuBvrJ/PVMfVC7zPGLMcuBzYKCJXAt8AvmWMmQe0AndOclwAn+fCPgqESUwAf2aMuTxg3PVU/w4B/gf4gzFmIbAc789tyuIyxhyzfkaX4930qAv49VTGBCAiM4HPAauNMZfhXeZ9C1Pxt2WMmXY34CrgpYDHDwAPTGE8JcDhgMfHgALrfgFwbIp/Xr8Frg2nuIAkYC+wFu8swZhgv9tJimUW3kTwPuBFQKY6JuvrngJyBh2b0t8hkA6cxBrIES5xBcRxHbAzHGLiwp7ZWXj3/ngRuH4q/ramZYue0Dcsnyr5xpgz1v2zQP5UBSIiJcAK4G3CIC6rRLIfaMS7v/AJ4LwxxmWdMhW/y/8Gvgx4rMfZYRATgAFeFpE9InKPdWyqf4elgAP4kVXqelxEksMgLp8twJPW/SmNyRhTDzwM1AJngDZgD1PwtzVdE/20Ybxv21MyhlVEUoDngb81xrSHQ1zGGLfxfsSeBawBFk52DIFEZDPQaIzZM5VxDGO9MWYl3hLl34jI1YFPTtHvMAZYCXzPGLMC6GRQSWSq/rasWvdNwLODn5uKmKw+gZvxvjkWAskMLfNOiuma6MN90/Fzvn10rX8bJzsAEYnFm+R/YYz5VbjE5WOMOQ+8hveja4aI+La1nOzf5TrgJhE5BTyFt3zzP1McE+BvEWKMacRbc17D1P8O64A6Y8zb1uPn8Cb+qY4LvG+Ie40x56zHUx3TB4CTxhiHMaYf+BXev7dJ/9uarol+xA3Lp9hW4Hbr/u14a+STRkQE+CHwrjHmv8IorlwRybDuJ+LtN3gXb8K/ZSriMsY8YIyZZYwpwft39Kox5hNTGROAiCSLSKrvPt7a82Gm+HdojDkLnBaRBdah9wNHpjouy21cKNvA1MdUC1wpIknW/0nfz2ry/7amosNknDo6NgHH8dZ4/3EK43gSb/2tH29r5068Nd4/ApXA/wFZkxzTerwfUw8C+63bpjCIaxmwz4rrMPCgdXwO8A5Qhfdjd/wU/S6vAV4Mh5isr3/AulX4/san+ndoxXA5UG79Hn8DZE51XHjLIs1AesCxcPhZfQU4av29/wyIn4q/LV0CQSmlItx0Ld0opZQKkSZ6pZSKcJrolVIqwmmiV0qpCKeJXimlIpwmeqWUinCa6JVSKsL9f61egkPi+QUsAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBTReWHxz4Ml",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "097ef1c6-78ca-46f0-ff28-145d3d766ff0"
      },
      "source": [
        "check_accuracy(model_gpu, valid_loader)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking accuracy on test set\n",
            "Got 164 / 200 correct (82.00)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.82"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    }
  ]
}