{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN_Avg_No_Relu3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamilo116/KNN/blob/master/KNN_Avg_No_Relu3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7ReM7FU-xs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import sys\n",
        "from random import shuffle\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms as transforms\n",
        "import timeit\n",
        "\n",
        "np.random.seed(4) \n",
        "torch.manual_seed(4) \n",
        "torch.cuda.manual_seed(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYIMZ8QyYewD",
        "colab_type": "code",
        "outputId": "df7e49b1-5640-4de7-879a-45a0e932dcb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! git clone https://github.com/wang-chen/kervolution.git \n",
        "\n",
        "sys.path.append(\"kervolution/\")\n",
        "from kervolution import Kerv2d\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'kervolution' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvbKg4VJXKY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LIMIT_IMAGES_NUM = 1000\n",
        "train_test_split_size = 0.2\n",
        "image_resize = (100, 100)\n",
        "batch_size = 64\n",
        "num_workers = 0\n",
        "\n",
        "in_channels = 3\n",
        "out_channels_1 = 16\n",
        "out_channels_2 = 24\n",
        "out_channels_3 = 32\n",
        "out_channels_4 = 48\n",
        "out_channels_5 = 64\n",
        "out_channels_6 = 128\n",
        "\n",
        "kernel_size = 3\n",
        "padding_1 = 1\n",
        "num_epochs = 80\n",
        "\n",
        "learning_rate = 0.0001\n",
        "weight_decay = 0.1\n",
        "\n",
        "MALIGNANT_DATASET = '/content/drive/My Drive/Colab_data/malignant/malignant/'\n",
        "BENIGN_DATASET = '/content/drive/My Drive/Colab_data/benign/benign/'\n",
        "DATA_FOLDER = '/content/drive/My Drive/Colab_data/'\n",
        "model_backup_path = os.path.join(DATA_FOLDER, 'backup_model_3') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMOHez_kHZD6",
        "colab_type": "code",
        "outputId": "b18dff93-fd73-4fac-ee20-bc1ef60816aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b8P1NdXfVdX",
        "colab_type": "code",
        "outputId": "80bc9576-2f39-4dd1-c848-ebcb2d367d5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "benign_file_list = sorted(os.listdir(BENIGN_DATASET))\n",
        "malignant_file_list = sorted(os.listdir(MALIGNANT_DATASET))\n",
        "shuffle(benign_file_list)\n",
        "shuffle(malignant_file_list)\n",
        "benign_file_list = benign_file_list[:LIMIT_IMAGES_NUM]\n",
        "malignant_file_list = malignant_file_list[:LIMIT_IMAGES_NUM]\n",
        "\n",
        "print(f\"Number of benign {len(benign_file_list)} images\")\n",
        "print(f\"Number of malignant {len(malignant_file_list)} images\")\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize(image_resize),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of benign 1000 images\n",
            "Number of malignant 1000 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGDQfal74BLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "benign_dict = {filename: 0 for filename in benign_file_list}\n",
        "malignant_dict = {filename: 1 for filename in malignant_file_list}\n",
        "img_class_dict = {**benign_dict , **malignant_dict}\n",
        "labeled_data = pd.Series(img_class_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvAAOqmVfVll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IsicDataset(Dataset):\n",
        "    def __init__(self, data_folder, labeled_data, \n",
        "                 transform=transforms.Compose([transforms.ToTensor()])):\n",
        "        self.labeled_data = labeled_data\n",
        "        self.transform = transform\n",
        "        self.data_folder = data_folder\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labeled_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        label = self.labeled_data[index]\n",
        "        if label == 0:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"benign\", \"benign\", index ))\n",
        "        else:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"malignant\", \"malignant\", index ))\n",
        "        image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "    @property\n",
        "    def labels(self):\n",
        "      return self.labeled_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSuYqjLAYrWA",
        "colab_type": "code",
        "outputId": "539924f7-5680-429f-b7e3-a7773fad3679",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        " \n",
        "dataset = IsicDataset(DATA_FOLDER, labeled_data, transform=data_transforms)\n",
        "print(dataset.labels)\n",
        "\n",
        "X_train, X_test = train_test_split(dataset.labels, test_size=train_test_split_size)\n",
        "print(\"number of training data: \",len(X_train))\n",
        "print(\"number of testing  data: \",len(X_test))\n",
        "\n",
        "train_sampler = SubsetRandomSampler(list(X_train.index))\n",
        "valid_sampler = SubsetRandomSampler(list(X_test.index))\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ISIC_0000610.jpeg    0\n",
            "ISIC_0000935.jpeg    0\n",
            "ISIC_0002870.jpeg    0\n",
            "ISIC_0000923.jpeg    0\n",
            "ISIC_0001029.jpeg    0\n",
            "                    ..\n",
            "ISIC_0011752.jpeg    1\n",
            "ISIC_0000046.jpeg    1\n",
            "ISIC_0014288.jpeg    1\n",
            "ISIC_0014766.jpeg    1\n",
            "ISIC_0000290.jpeg    1\n",
            "Length: 2000, dtype: int64\n",
            "number of training data:  1600\n",
            "number of testing  data:  400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e8nFBR6Yug5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "def train(model, train_loader ,loss_fn, optimizer, num_epochs=1, starting_from_epoch=1):\n",
        "    total_loss =0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
        "        model.train()\n",
        "\n",
        "        for t, (x, y) in enumerate(train_loader):\n",
        "            x_var = Variable(x.type(gpu_dtype))\n",
        "            y_var = Variable(y.type(gpu_dtype).long())\n",
        "            scores = model(x_var)\n",
        "            loss = loss_fn(scores, y_var)\n",
        "            total_loss += loss.data\n",
        "            \n",
        "            if (t + 1) % print_every == 0:\n",
        "                avg_loss = total_loss/print_every\n",
        "                print('t = %d, avg_loss = %.4f' % (t + 1, avg_loss) )\n",
        "                avg_loss_list.append(avg_loss)\n",
        "                total_loss = 0\n",
        "                \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        acc = check_accuracy(model_gpu, valid_loader)\n",
        "        print('acc = %f' %(acc))\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model_gpu.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            }, model_backup_path)\n",
        "            \n",
        "def check_accuracy(model, loader):\n",
        "    print('Checking accuracy on test set')   \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval() \n",
        "    for x, y in loader:\n",
        "        x_var = Variable(x.type(gpu_dtype))\n",
        "\n",
        "        scores = model(x_var)\n",
        "        _, preds = scores.data.cpu().max(1)\n",
        "        num_correct += (preds == y).sum()\n",
        "        num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    acc_list.append(acc)\n",
        "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "    return acc\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggvpMu36Yw2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.size()\n",
        "        return x.view(N, -1)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgmexhBRZAK6",
        "colab_type": "code",
        "outputId": "49982ba4-ad10-4a26-e6e9-8a82565626ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "gpu_dtype = torch.cuda.FloatTensor\n",
        "\n",
        "print_every = 1\n",
        "\n",
        "\n",
        "'''\n",
        "Kerv2d\n",
        "kervolution with following options:\n",
        "kernel_type: [linear, polynomial, gaussian, etc.]\n",
        "default is convolution:\n",
        "          kernel_type --> linear,\n",
        "balance, power, gamma is valid only when the kernel_type is specified\n",
        "if learnable_kernel = True,  they just be the initial value of learable parameters\n",
        "if learnable_kernel = False, they are the value of kernel_type's parameter\n",
        "the parameter [power] cannot be learned due to integer limitation\n",
        "dilation (int or tuple, optional): Spacing between kernel\n",
        "elements. Default: 1\n",
        "groups (int, optional): Number of blocked connections from input\n",
        "channels to output channels. Default: 1\n",
        "bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n",
        "kernel_type (str), Default: 'linear'\n",
        "learnable_kernel (bool): Learnable kernel parameters.  Default: False \n",
        "balance: 0, 1\n",
        "power: 3, 4, 5\n",
        "gamma:\n",
        "'''\n",
        "\n",
        "\n",
        "model_base = nn.Sequential( \n",
        "                nn.Kerv2d(in_channels , out_channels_1, padding=padding_1, dilation=1, groups=1, bias=True, \n",
        "                          kernel_type='polynomial', kernel_size=kernel_size, learnable_kernel=True,\n",
        "                          kernel_regularizer=True, stride=1, balance=1, power=3, gamma=1\n",
        "                          ),\n",
        "                nn.Dropout(0.1),\n",
        "                nn.BatchNorm2d(out_channels_1),\n",
        "                nn.Conv2d(out_channels_1 , out_channels_2, padding= padding_1, kernel_size=kernel_size, stride=1), \n",
        "                \n",
        "                nn.BatchNorm2d(out_channels_2),\n",
        "                nn.AvgPool2d(2, stride=2), \n",
        "                nn.Conv2d(out_channels_2 , out_channels_3, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.BatchNorm2d(out_channels_3),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_3 , out_channels_4, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.BatchNorm2d(out_channels_4),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_4 , out_channels_5, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.BatchNorm2d(out_channels_5),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_5 , out_channels_6, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.BatchNorm2d(out_channels_6),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Dropout(0.5),\n",
        "                Flatten(),\n",
        "                nn.Linear(1152,64),\n",
        "                nn.Linear(64,2)\n",
        "            )\n",
        "model_gpu = model_base.type(gpu_dtype)\n",
        "print(model_gpu)\n",
        "loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) \n",
        "\n",
        "train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs)\n",
        "check_accuracy(model_gpu, valid_loader)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Kerv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): Dropout(p=0.1, inplace=False)\n",
            "  (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (3): Conv2d(16, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (6): Conv2d(24, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (8): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (9): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (10): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (11): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (12): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (13): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (14): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (15): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (18): Dropout(p=0.5, inplace=False)\n",
            "  (19): Flatten()\n",
            "  (20): Linear(in_features=1152, out_features=64, bias=True)\n",
            "  (21): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n",
            "Starting epoch 1 / 80\n",
            "t = 1, avg_loss = 0.7310\n",
            "t = 2, avg_loss = 0.7400\n",
            "t = 3, avg_loss = 0.6603\n",
            "t = 4, avg_loss = 0.7564\n",
            "t = 5, avg_loss = 0.6793\n",
            "t = 6, avg_loss = 0.6997\n",
            "t = 7, avg_loss = 0.6961\n",
            "t = 8, avg_loss = 0.6943\n",
            "t = 9, avg_loss = 0.6731\n",
            "t = 10, avg_loss = 0.7294\n",
            "t = 11, avg_loss = 0.6264\n",
            "t = 12, avg_loss = 0.6794\n",
            "t = 13, avg_loss = 0.6020\n",
            "t = 14, avg_loss = 0.6434\n",
            "t = 15, avg_loss = 0.5999\n",
            "t = 16, avg_loss = 0.5912\n",
            "t = 17, avg_loss = 0.6215\n",
            "t = 18, avg_loss = 0.6698\n",
            "t = 19, avg_loss = 0.6503\n",
            "t = 20, avg_loss = 0.7219\n",
            "t = 21, avg_loss = 0.5747\n",
            "t = 22, avg_loss = 0.5930\n",
            "t = 23, avg_loss = 0.5882\n",
            "t = 24, avg_loss = 0.6828\n",
            "t = 25, avg_loss = 0.6846\n",
            "Checking accuracy on test set\n",
            "Got 239 / 400 correct (59.75)\n",
            "acc = 0.597500\n",
            "Starting epoch 2 / 80\n",
            "t = 1, avg_loss = 0.6183\n",
            "t = 2, avg_loss = 0.5804\n",
            "t = 3, avg_loss = 0.6827\n",
            "t = 4, avg_loss = 0.6172\n",
            "t = 5, avg_loss = 0.6062\n",
            "t = 6, avg_loss = 0.6660\n",
            "t = 7, avg_loss = 0.7343\n",
            "t = 8, avg_loss = 0.7636\n",
            "t = 9, avg_loss = 0.6998\n",
            "t = 10, avg_loss = 0.6595\n",
            "t = 11, avg_loss = 0.6498\n",
            "t = 12, avg_loss = 0.6433\n",
            "t = 13, avg_loss = 0.7060\n",
            "t = 14, avg_loss = 0.6264\n",
            "t = 15, avg_loss = 0.6159\n",
            "t = 16, avg_loss = 0.6079\n",
            "t = 17, avg_loss = 0.6391\n",
            "t = 18, avg_loss = 0.5833\n",
            "t = 19, avg_loss = 0.6530\n",
            "t = 20, avg_loss = 0.5373\n",
            "t = 21, avg_loss = 0.6398\n",
            "t = 22, avg_loss = 0.5325\n",
            "t = 23, avg_loss = 0.6449\n",
            "t = 24, avg_loss = 0.6654\n",
            "t = 25, avg_loss = 0.5877\n",
            "Checking accuracy on test set\n",
            "Got 271 / 400 correct (67.75)\n",
            "acc = 0.677500\n",
            "Starting epoch 3 / 80\n",
            "t = 1, avg_loss = 0.6070\n",
            "t = 2, avg_loss = 0.7025\n",
            "t = 3, avg_loss = 0.6210\n",
            "t = 4, avg_loss = 0.6790\n",
            "t = 5, avg_loss = 0.7684\n",
            "t = 6, avg_loss = 0.6282\n",
            "t = 7, avg_loss = 0.6023\n",
            "t = 8, avg_loss = 0.6519\n",
            "t = 9, avg_loss = 0.6535\n",
            "t = 10, avg_loss = 0.6777\n",
            "t = 11, avg_loss = 0.6657\n",
            "t = 12, avg_loss = 0.5792\n",
            "t = 13, avg_loss = 0.6122\n",
            "t = 14, avg_loss = 0.6930\n",
            "t = 15, avg_loss = 0.6523\n",
            "t = 16, avg_loss = 0.6397\n",
            "t = 17, avg_loss = 0.6199\n",
            "t = 18, avg_loss = 0.6975\n",
            "t = 19, avg_loss = 0.5883\n",
            "t = 20, avg_loss = 0.6426\n",
            "t = 21, avg_loss = 0.6411\n",
            "t = 22, avg_loss = 0.6045\n",
            "t = 23, avg_loss = 0.6806\n",
            "t = 24, avg_loss = 0.6249\n",
            "t = 25, avg_loss = 0.6241\n",
            "Checking accuracy on test set\n",
            "Got 249 / 400 correct (62.25)\n",
            "acc = 0.622500\n",
            "Starting epoch 4 / 80\n",
            "t = 1, avg_loss = 0.7077\n",
            "t = 2, avg_loss = 0.6746\n",
            "t = 3, avg_loss = 0.6083\n",
            "t = 4, avg_loss = 0.6243\n",
            "t = 5, avg_loss = 0.6503\n",
            "t = 6, avg_loss = 0.7274\n",
            "t = 7, avg_loss = 0.7149\n",
            "t = 8, avg_loss = 0.6231\n",
            "t = 9, avg_loss = 0.6226\n",
            "t = 10, avg_loss = 0.5993\n",
            "t = 11, avg_loss = 0.6720\n",
            "t = 12, avg_loss = 0.6278\n",
            "t = 13, avg_loss = 0.6257\n",
            "t = 14, avg_loss = 0.6291\n",
            "t = 15, avg_loss = 0.6246\n",
            "t = 16, avg_loss = 0.6427\n",
            "t = 17, avg_loss = 0.5523\n",
            "t = 18, avg_loss = 0.7154\n",
            "t = 19, avg_loss = 0.6592\n",
            "t = 20, avg_loss = 0.6127\n",
            "t = 21, avg_loss = 0.6719\n",
            "t = 22, avg_loss = 0.5328\n",
            "t = 23, avg_loss = 0.6792\n",
            "t = 24, avg_loss = 0.5875\n",
            "t = 25, avg_loss = 0.6179\n",
            "Checking accuracy on test set\n",
            "Got 270 / 400 correct (67.50)\n",
            "acc = 0.675000\n",
            "Starting epoch 5 / 80\n",
            "t = 1, avg_loss = 0.6678\n",
            "t = 2, avg_loss = 0.6706\n",
            "t = 3, avg_loss = 0.6133\n",
            "t = 4, avg_loss = 0.6767\n",
            "t = 5, avg_loss = 0.6637\n",
            "t = 6, avg_loss = 0.6349\n",
            "t = 7, avg_loss = 0.7145\n",
            "t = 8, avg_loss = 0.6012\n",
            "t = 9, avg_loss = 0.6029\n",
            "t = 10, avg_loss = 0.5695\n",
            "t = 11, avg_loss = 0.5914\n",
            "t = 12, avg_loss = 0.6111\n",
            "t = 13, avg_loss = 0.6156\n",
            "t = 14, avg_loss = 0.5660\n",
            "t = 15, avg_loss = 0.7084\n",
            "t = 16, avg_loss = 0.6359\n",
            "t = 17, avg_loss = 0.6822\n",
            "t = 18, avg_loss = 0.6194\n",
            "t = 19, avg_loss = 0.5311\n",
            "t = 20, avg_loss = 0.6199\n",
            "t = 21, avg_loss = 0.5209\n",
            "t = 22, avg_loss = 0.5952\n",
            "t = 23, avg_loss = 0.5769\n",
            "t = 24, avg_loss = 0.6943\n",
            "t = 25, avg_loss = 0.6954\n",
            "Checking accuracy on test set\n",
            "Got 263 / 400 correct (65.75)\n",
            "acc = 0.657500\n",
            "Starting epoch 6 / 80\n",
            "t = 1, avg_loss = 0.6005\n",
            "t = 2, avg_loss = 0.6880\n",
            "t = 3, avg_loss = 0.6153\n",
            "t = 4, avg_loss = 0.5846\n",
            "t = 5, avg_loss = 0.6253\n",
            "t = 6, avg_loss = 0.7044\n",
            "t = 7, avg_loss = 0.6172\n",
            "t = 8, avg_loss = 0.5773\n",
            "t = 9, avg_loss = 0.6075\n",
            "t = 10, avg_loss = 0.6392\n",
            "t = 11, avg_loss = 0.6975\n",
            "t = 12, avg_loss = 0.6187\n",
            "t = 13, avg_loss = 0.6041\n",
            "t = 14, avg_loss = 0.6211\n",
            "t = 15, avg_loss = 0.7040\n",
            "t = 16, avg_loss = 0.6658\n",
            "t = 17, avg_loss = 0.5854\n",
            "t = 18, avg_loss = 0.5739\n",
            "t = 19, avg_loss = 0.6203\n",
            "t = 20, avg_loss = 0.5852\n",
            "t = 21, avg_loss = 0.5486\n",
            "t = 22, avg_loss = 0.6107\n",
            "t = 23, avg_loss = 0.5872\n",
            "t = 24, avg_loss = 0.6425\n",
            "t = 25, avg_loss = 0.7201\n",
            "Checking accuracy on test set\n",
            "Got 256 / 400 correct (64.00)\n",
            "acc = 0.640000\n",
            "Starting epoch 7 / 80\n",
            "t = 1, avg_loss = 0.6969\n",
            "t = 2, avg_loss = 0.6376\n",
            "t = 3, avg_loss = 0.6025\n",
            "t = 4, avg_loss = 0.6411\n",
            "t = 5, avg_loss = 0.5980\n",
            "t = 6, avg_loss = 0.7314\n",
            "t = 7, avg_loss = 0.6134\n",
            "t = 8, avg_loss = 0.5782\n",
            "t = 9, avg_loss = 0.6442\n",
            "t = 10, avg_loss = 0.5548\n",
            "t = 11, avg_loss = 0.6297\n",
            "t = 12, avg_loss = 0.6014\n",
            "t = 13, avg_loss = 0.7173\n",
            "t = 14, avg_loss = 0.6206\n",
            "t = 15, avg_loss = 0.5836\n",
            "t = 16, avg_loss = 0.5930\n",
            "t = 17, avg_loss = 0.5932\n",
            "t = 18, avg_loss = 0.5741\n",
            "t = 19, avg_loss = 0.5685\n",
            "t = 20, avg_loss = 0.5669\n",
            "t = 21, avg_loss = 0.6902\n",
            "t = 22, avg_loss = 0.6034\n",
            "t = 23, avg_loss = 0.6032\n",
            "t = 24, avg_loss = 0.5872\n",
            "t = 25, avg_loss = 0.6540\n",
            "Checking accuracy on test set\n",
            "Got 264 / 400 correct (66.00)\n",
            "acc = 0.660000\n",
            "Starting epoch 8 / 80\n",
            "t = 1, avg_loss = 0.5422\n",
            "t = 2, avg_loss = 0.5874\n",
            "t = 3, avg_loss = 0.5764\n",
            "t = 4, avg_loss = 0.6114\n",
            "t = 5, avg_loss = 0.7605\n",
            "t = 6, avg_loss = 0.6251\n",
            "t = 7, avg_loss = 0.5718\n",
            "t = 8, avg_loss = 0.6523\n",
            "t = 9, avg_loss = 0.5509\n",
            "t = 10, avg_loss = 0.6054\n",
            "t = 11, avg_loss = 0.6342\n",
            "t = 12, avg_loss = 0.6303\n",
            "t = 13, avg_loss = 0.5762\n",
            "t = 14, avg_loss = 0.5656\n",
            "t = 15, avg_loss = 0.5717\n",
            "t = 16, avg_loss = 0.6607\n",
            "t = 17, avg_loss = 0.5634\n",
            "t = 18, avg_loss = 0.5613\n",
            "t = 19, avg_loss = 0.6675\n",
            "t = 20, avg_loss = 0.5702\n",
            "t = 21, avg_loss = 0.6562\n",
            "t = 22, avg_loss = 0.7133\n",
            "t = 23, avg_loss = 0.6553\n",
            "t = 24, avg_loss = 0.5518\n",
            "t = 25, avg_loss = 0.5987\n",
            "Checking accuracy on test set\n",
            "Got 265 / 400 correct (66.25)\n",
            "acc = 0.662500\n",
            "Starting epoch 9 / 80\n",
            "t = 1, avg_loss = 0.6113\n",
            "t = 2, avg_loss = 0.5458\n",
            "t = 3, avg_loss = 0.5882\n",
            "t = 4, avg_loss = 0.6097\n",
            "t = 5, avg_loss = 0.6955\n",
            "t = 6, avg_loss = 0.5671\n",
            "t = 7, avg_loss = 0.6437\n",
            "t = 8, avg_loss = 0.5703\n",
            "t = 9, avg_loss = 0.6318\n",
            "t = 10, avg_loss = 0.6401\n",
            "t = 11, avg_loss = 0.5101\n",
            "t = 12, avg_loss = 0.5909\n",
            "t = 13, avg_loss = 0.5910\n",
            "t = 14, avg_loss = 0.6323\n",
            "t = 15, avg_loss = 0.5567\n",
            "t = 16, avg_loss = 0.6187\n",
            "t = 17, avg_loss = 0.6737\n",
            "t = 18, avg_loss = 0.6102\n",
            "t = 19, avg_loss = 0.6725\n",
            "t = 20, avg_loss = 0.5225\n",
            "t = 21, avg_loss = 0.6360\n",
            "t = 22, avg_loss = 0.6440\n",
            "t = 23, avg_loss = 0.5536\n",
            "t = 24, avg_loss = 0.5001\n",
            "t = 25, avg_loss = 0.6292\n",
            "Checking accuracy on test set\n",
            "Got 267 / 400 correct (66.75)\n",
            "acc = 0.667500\n",
            "Starting epoch 10 / 80\n",
            "t = 1, avg_loss = 0.5661\n",
            "t = 2, avg_loss = 0.6326\n",
            "t = 3, avg_loss = 0.6206\n",
            "t = 4, avg_loss = 0.6289\n",
            "t = 5, avg_loss = 0.6979\n",
            "t = 6, avg_loss = 0.6656\n",
            "t = 7, avg_loss = 0.6053\n",
            "t = 8, avg_loss = 0.5131\n",
            "t = 9, avg_loss = 0.6248\n",
            "t = 10, avg_loss = 0.6084\n",
            "t = 11, avg_loss = 0.6707\n",
            "t = 12, avg_loss = 0.5639\n",
            "t = 13, avg_loss = 0.5841\n",
            "t = 14, avg_loss = 0.6668\n",
            "t = 15, avg_loss = 0.6518\n",
            "t = 16, avg_loss = 0.6110\n",
            "t = 17, avg_loss = 0.5790\n",
            "t = 18, avg_loss = 0.6440\n",
            "t = 19, avg_loss = 0.5251\n",
            "t = 20, avg_loss = 0.6001\n",
            "t = 21, avg_loss = 0.5831\n",
            "t = 22, avg_loss = 0.5916\n",
            "t = 23, avg_loss = 0.6391\n",
            "t = 24, avg_loss = 0.5587\n",
            "t = 25, avg_loss = 0.7026\n",
            "Checking accuracy on test set\n",
            "Got 273 / 400 correct (68.25)\n",
            "acc = 0.682500\n",
            "Starting epoch 11 / 80\n",
            "t = 1, avg_loss = 0.5284\n",
            "t = 2, avg_loss = 0.6444\n",
            "t = 3, avg_loss = 0.5716\n",
            "t = 4, avg_loss = 0.6037\n",
            "t = 5, avg_loss = 0.5924\n",
            "t = 6, avg_loss = 0.5765\n",
            "t = 7, avg_loss = 0.5805\n",
            "t = 8, avg_loss = 0.6334\n",
            "t = 9, avg_loss = 0.6279\n",
            "t = 10, avg_loss = 0.6029\n",
            "t = 11, avg_loss = 0.5221\n",
            "t = 12, avg_loss = 0.6347\n",
            "t = 13, avg_loss = 0.7117\n",
            "t = 14, avg_loss = 0.6440\n",
            "t = 15, avg_loss = 0.6518\n",
            "t = 16, avg_loss = 0.6659\n",
            "t = 17, avg_loss = 0.5949\n",
            "t = 18, avg_loss = 0.6761\n",
            "t = 19, avg_loss = 0.5942\n",
            "t = 20, avg_loss = 0.6206\n",
            "t = 21, avg_loss = 0.6391\n",
            "t = 22, avg_loss = 0.6185\n",
            "t = 23, avg_loss = 0.6209\n",
            "t = 24, avg_loss = 0.6102\n",
            "t = 25, avg_loss = 0.5596\n",
            "Checking accuracy on test set\n",
            "Got 266 / 400 correct (66.50)\n",
            "acc = 0.665000\n",
            "Starting epoch 12 / 80\n",
            "t = 1, avg_loss = 0.6003\n",
            "t = 2, avg_loss = 0.6247\n",
            "t = 3, avg_loss = 0.5388\n",
            "t = 4, avg_loss = 0.6524\n",
            "t = 5, avg_loss = 0.5880\n",
            "t = 6, avg_loss = 0.5647\n",
            "t = 7, avg_loss = 0.6734\n",
            "t = 8, avg_loss = 0.6208\n",
            "t = 9, avg_loss = 0.6286\n",
            "t = 10, avg_loss = 0.6433\n",
            "t = 11, avg_loss = 0.6309\n",
            "t = 12, avg_loss = 0.7101\n",
            "t = 13, avg_loss = 0.5601\n",
            "t = 14, avg_loss = 0.4996\n",
            "t = 15, avg_loss = 0.6893\n",
            "t = 16, avg_loss = 0.6535\n",
            "t = 17, avg_loss = 0.6216\n",
            "t = 18, avg_loss = 0.5784\n",
            "t = 19, avg_loss = 0.6243\n",
            "t = 20, avg_loss = 0.5864\n",
            "t = 21, avg_loss = 0.5615\n",
            "t = 22, avg_loss = 0.5699\n",
            "t = 23, avg_loss = 0.6488\n",
            "t = 24, avg_loss = 0.6678\n",
            "t = 25, avg_loss = 0.6578\n",
            "Checking accuracy on test set\n",
            "Got 267 / 400 correct (66.75)\n",
            "acc = 0.667500\n",
            "Starting epoch 13 / 80\n",
            "t = 1, avg_loss = 0.6293\n",
            "t = 2, avg_loss = 0.6471\n",
            "t = 3, avg_loss = 0.6628\n",
            "t = 4, avg_loss = 0.5778\n",
            "t = 5, avg_loss = 0.6565\n",
            "t = 6, avg_loss = 0.6216\n",
            "t = 7, avg_loss = 0.6342\n",
            "t = 8, avg_loss = 0.6254\n",
            "t = 9, avg_loss = 0.6465\n",
            "t = 10, avg_loss = 0.6150\n",
            "t = 11, avg_loss = 0.6209\n",
            "t = 12, avg_loss = 0.6066\n",
            "t = 13, avg_loss = 0.6183\n",
            "t = 14, avg_loss = 0.5378\n",
            "t = 15, avg_loss = 0.5432\n",
            "t = 16, avg_loss = 0.6082\n",
            "t = 17, avg_loss = 0.7330\n",
            "t = 18, avg_loss = 0.7031\n",
            "t = 19, avg_loss = 0.6094\n",
            "t = 20, avg_loss = 0.5581\n",
            "t = 21, avg_loss = 0.5619\n",
            "t = 22, avg_loss = 0.5560\n",
            "t = 23, avg_loss = 0.5452\n",
            "t = 24, avg_loss = 0.6144\n",
            "t = 25, avg_loss = 0.5921\n",
            "Checking accuracy on test set\n",
            "Got 256 / 400 correct (64.00)\n",
            "acc = 0.640000\n",
            "Starting epoch 14 / 80\n",
            "t = 1, avg_loss = 0.6259\n",
            "t = 2, avg_loss = 0.6573\n",
            "t = 3, avg_loss = 0.5948\n",
            "t = 4, avg_loss = 0.6297\n",
            "t = 5, avg_loss = 0.5522\n",
            "t = 6, avg_loss = 0.5456\n",
            "t = 7, avg_loss = 0.5330\n",
            "t = 8, avg_loss = 0.5404\n",
            "t = 9, avg_loss = 0.5763\n",
            "t = 10, avg_loss = 0.7242\n",
            "t = 11, avg_loss = 0.7135\n",
            "t = 12, avg_loss = 0.6075\n",
            "t = 13, avg_loss = 0.6252\n",
            "t = 14, avg_loss = 0.6101\n",
            "t = 15, avg_loss = 0.6190\n",
            "t = 16, avg_loss = 0.5872\n",
            "t = 17, avg_loss = 0.5257\n",
            "t = 18, avg_loss = 0.6032\n",
            "t = 19, avg_loss = 0.6464\n",
            "t = 20, avg_loss = 0.5383\n",
            "t = 21, avg_loss = 0.6911\n",
            "t = 22, avg_loss = 0.7005\n",
            "t = 23, avg_loss = 0.6668\n",
            "t = 24, avg_loss = 0.6530\n",
            "t = 25, avg_loss = 0.5725\n",
            "Checking accuracy on test set\n",
            "Got 272 / 400 correct (68.00)\n",
            "acc = 0.680000\n",
            "Starting epoch 15 / 80\n",
            "t = 1, avg_loss = 0.6149\n",
            "t = 2, avg_loss = 0.6271\n",
            "t = 3, avg_loss = 0.5134\n",
            "t = 4, avg_loss = 0.6147\n",
            "t = 5, avg_loss = 0.5572\n",
            "t = 6, avg_loss = 0.6381\n",
            "t = 7, avg_loss = 0.6308\n",
            "t = 8, avg_loss = 0.5662\n",
            "t = 9, avg_loss = 0.6539\n",
            "t = 10, avg_loss = 0.5948\n",
            "t = 11, avg_loss = 0.6179\n",
            "t = 12, avg_loss = 0.6696\n",
            "t = 13, avg_loss = 0.6097\n",
            "t = 14, avg_loss = 0.6764\n",
            "t = 15, avg_loss = 0.6460\n",
            "t = 16, avg_loss = 0.5440\n",
            "t = 17, avg_loss = 0.5780\n",
            "t = 18, avg_loss = 0.5773\n",
            "t = 19, avg_loss = 0.5510\n",
            "t = 20, avg_loss = 0.6077\n",
            "t = 21, avg_loss = 0.6019\n",
            "t = 22, avg_loss = 0.6371\n",
            "t = 23, avg_loss = 0.6200\n",
            "t = 24, avg_loss = 0.6133\n",
            "t = 25, avg_loss = 0.6910\n",
            "Checking accuracy on test set\n",
            "Got 270 / 400 correct (67.50)\n",
            "acc = 0.675000\n",
            "Starting epoch 16 / 80\n",
            "t = 1, avg_loss = 0.6767\n",
            "t = 2, avg_loss = 0.5411\n",
            "t = 3, avg_loss = 0.5924\n",
            "t = 4, avg_loss = 0.5420\n",
            "t = 5, avg_loss = 0.6361\n",
            "t = 6, avg_loss = 0.5997\n",
            "t = 7, avg_loss = 0.6633\n",
            "t = 8, avg_loss = 0.6518\n",
            "t = 9, avg_loss = 0.5435\n",
            "t = 10, avg_loss = 0.5344\n",
            "t = 11, avg_loss = 0.5453\n",
            "t = 12, avg_loss = 0.5758\n",
            "t = 13, avg_loss = 0.6780\n",
            "t = 14, avg_loss = 0.6265\n",
            "t = 15, avg_loss = 0.6066\n",
            "t = 16, avg_loss = 0.6434\n",
            "t = 17, avg_loss = 0.5740\n",
            "t = 18, avg_loss = 0.6454\n",
            "t = 19, avg_loss = 0.6061\n",
            "t = 20, avg_loss = 0.5120\n",
            "t = 21, avg_loss = 0.5693\n",
            "t = 22, avg_loss = 0.5784\n",
            "t = 23, avg_loss = 0.6282\n",
            "t = 24, avg_loss = 0.5669\n",
            "t = 25, avg_loss = 0.6612\n",
            "Checking accuracy on test set\n",
            "Got 267 / 400 correct (66.75)\n",
            "acc = 0.667500\n",
            "Starting epoch 17 / 80\n",
            "t = 1, avg_loss = 0.5740\n",
            "t = 2, avg_loss = 0.6753\n",
            "t = 3, avg_loss = 0.6813\n",
            "t = 4, avg_loss = 0.6006\n",
            "t = 5, avg_loss = 0.6496\n",
            "t = 6, avg_loss = 0.4551\n",
            "t = 7, avg_loss = 0.5848\n",
            "t = 8, avg_loss = 0.6267\n",
            "t = 9, avg_loss = 0.5357\n",
            "t = 10, avg_loss = 0.6509\n",
            "t = 11, avg_loss = 0.5453\n",
            "t = 12, avg_loss = 0.6036\n",
            "t = 13, avg_loss = 0.5875\n",
            "t = 14, avg_loss = 0.6287\n",
            "t = 15, avg_loss = 0.6294\n",
            "t = 16, avg_loss = 0.6056\n",
            "t = 17, avg_loss = 0.6068\n",
            "t = 18, avg_loss = 0.5663\n",
            "t = 19, avg_loss = 0.5594\n",
            "t = 20, avg_loss = 0.5826\n",
            "t = 21, avg_loss = 0.5415\n",
            "t = 22, avg_loss = 0.4932\n",
            "t = 23, avg_loss = 0.6976\n",
            "t = 24, avg_loss = 0.6141\n",
            "t = 25, avg_loss = 0.7056\n",
            "Checking accuracy on test set\n",
            "Got 277 / 400 correct (69.25)\n",
            "acc = 0.692500\n",
            "Starting epoch 18 / 80\n",
            "t = 1, avg_loss = 0.4683\n",
            "t = 2, avg_loss = 0.5363\n",
            "t = 3, avg_loss = 0.5003\n",
            "t = 4, avg_loss = 0.6001\n",
            "t = 5, avg_loss = 0.5991\n",
            "t = 6, avg_loss = 0.5666\n",
            "t = 7, avg_loss = 0.5518\n",
            "t = 8, avg_loss = 0.6425\n",
            "t = 9, avg_loss = 0.6040\n",
            "t = 10, avg_loss = 0.6470\n",
            "t = 11, avg_loss = 0.6265\n",
            "t = 12, avg_loss = 0.6671\n",
            "t = 13, avg_loss = 0.4996\n",
            "t = 14, avg_loss = 0.6202\n",
            "t = 15, avg_loss = 0.6205\n",
            "t = 16, avg_loss = 0.6101\n",
            "t = 17, avg_loss = 0.6198\n",
            "t = 18, avg_loss = 0.6250\n",
            "t = 19, avg_loss = 0.5576\n",
            "t = 20, avg_loss = 0.6089\n",
            "t = 21, avg_loss = 0.6272\n",
            "t = 22, avg_loss = 0.5967\n",
            "t = 23, avg_loss = 0.6468\n",
            "t = 24, avg_loss = 0.5994\n",
            "t = 25, avg_loss = 0.5676\n",
            "Checking accuracy on test set\n",
            "Got 270 / 400 correct (67.50)\n",
            "acc = 0.675000\n",
            "Starting epoch 19 / 80\n",
            "t = 1, avg_loss = 0.6192\n",
            "t = 2, avg_loss = 0.6439\n",
            "t = 3, avg_loss = 0.5206\n",
            "t = 4, avg_loss = 0.5653\n",
            "t = 5, avg_loss = 0.5412\n",
            "t = 6, avg_loss = 0.6056\n",
            "t = 7, avg_loss = 0.5870\n",
            "t = 8, avg_loss = 0.6169\n",
            "t = 9, avg_loss = 0.6311\n",
            "t = 10, avg_loss = 0.5819\n",
            "t = 11, avg_loss = 0.7211\n",
            "t = 12, avg_loss = 0.6655\n",
            "t = 13, avg_loss = 0.5035\n",
            "t = 14, avg_loss = 0.6047\n",
            "t = 15, avg_loss = 0.5755\n",
            "t = 16, avg_loss = 0.5602\n",
            "t = 17, avg_loss = 0.5887\n",
            "t = 18, avg_loss = 0.5614\n",
            "t = 19, avg_loss = 0.5703\n",
            "t = 20, avg_loss = 0.4930\n",
            "t = 21, avg_loss = 0.6487\n",
            "t = 22, avg_loss = 0.6558\n",
            "t = 23, avg_loss = 0.5408\n",
            "t = 24, avg_loss = 0.6166\n",
            "t = 25, avg_loss = 0.5307\n",
            "Checking accuracy on test set\n",
            "Got 266 / 400 correct (66.50)\n",
            "acc = 0.665000\n",
            "Starting epoch 20 / 80\n",
            "t = 1, avg_loss = 0.6631\n",
            "t = 2, avg_loss = 0.6375\n",
            "t = 3, avg_loss = 0.6588\n",
            "t = 4, avg_loss = 0.5659\n",
            "t = 5, avg_loss = 0.6493\n",
            "t = 6, avg_loss = 0.6220\n",
            "t = 7, avg_loss = 0.5960\n",
            "t = 8, avg_loss = 0.5431\n",
            "t = 9, avg_loss = 0.5662\n",
            "t = 10, avg_loss = 0.5167\n",
            "t = 11, avg_loss = 0.5529\n",
            "t = 12, avg_loss = 0.5608\n",
            "t = 13, avg_loss = 0.5709\n",
            "t = 14, avg_loss = 0.5799\n",
            "t = 15, avg_loss = 0.6976\n",
            "t = 16, avg_loss = 0.5221\n",
            "t = 17, avg_loss = 0.7470\n",
            "t = 18, avg_loss = 0.5776\n",
            "t = 19, avg_loss = 0.5330\n",
            "t = 20, avg_loss = 0.5839\n",
            "t = 21, avg_loss = 0.6107\n",
            "t = 22, avg_loss = 0.5341\n",
            "t = 23, avg_loss = 0.5657\n",
            "t = 24, avg_loss = 0.6654\n",
            "t = 25, avg_loss = 0.6847\n",
            "Checking accuracy on test set\n",
            "Got 269 / 400 correct (67.25)\n",
            "acc = 0.672500\n",
            "Starting epoch 21 / 80\n",
            "t = 1, avg_loss = 0.5765\n",
            "t = 2, avg_loss = 0.6843\n",
            "t = 3, avg_loss = 0.6252\n",
            "t = 4, avg_loss = 0.6535\n",
            "t = 5, avg_loss = 0.6661\n",
            "t = 6, avg_loss = 0.5996\n",
            "t = 7, avg_loss = 0.6319\n",
            "t = 8, avg_loss = 0.6068\n",
            "t = 9, avg_loss = 0.6246\n",
            "t = 10, avg_loss = 0.5771\n",
            "t = 11, avg_loss = 0.6147\n",
            "t = 12, avg_loss = 0.6530\n",
            "t = 13, avg_loss = 0.5699\n",
            "t = 14, avg_loss = 0.5756\n",
            "t = 15, avg_loss = 0.6584\n",
            "t = 16, avg_loss = 0.6791\n",
            "t = 17, avg_loss = 0.5724\n",
            "t = 18, avg_loss = 0.6549\n",
            "t = 19, avg_loss = 0.6107\n",
            "t = 20, avg_loss = 0.5587\n",
            "t = 21, avg_loss = 0.5894\n",
            "t = 22, avg_loss = 0.5929\n",
            "t = 23, avg_loss = 0.6244\n",
            "t = 24, avg_loss = 0.6041\n",
            "t = 25, avg_loss = 0.5039\n",
            "Checking accuracy on test set\n",
            "Got 268 / 400 correct (67.00)\n",
            "acc = 0.670000\n",
            "Starting epoch 22 / 80\n",
            "t = 1, avg_loss = 0.4521\n",
            "t = 2, avg_loss = 0.6904\n",
            "t = 3, avg_loss = 0.6403\n",
            "t = 4, avg_loss = 0.5655\n",
            "t = 5, avg_loss = 0.5693\n",
            "t = 6, avg_loss = 0.6857\n",
            "t = 7, avg_loss = 0.6509\n",
            "t = 8, avg_loss = 0.5826\n",
            "t = 9, avg_loss = 0.6815\n",
            "t = 10, avg_loss = 0.5843\n",
            "t = 11, avg_loss = 0.5760\n",
            "t = 12, avg_loss = 0.5719\n",
            "t = 13, avg_loss = 0.5644\n",
            "t = 14, avg_loss = 0.5393\n",
            "t = 15, avg_loss = 0.6559\n",
            "t = 16, avg_loss = 0.5921\n",
            "t = 17, avg_loss = 0.6337\n",
            "t = 18, avg_loss = 0.6074\n",
            "t = 19, avg_loss = 0.5919\n",
            "t = 20, avg_loss = 0.5870\n",
            "t = 21, avg_loss = 0.5817\n",
            "t = 22, avg_loss = 0.5845\n",
            "t = 23, avg_loss = 0.7102\n",
            "t = 24, avg_loss = 0.5604\n",
            "t = 25, avg_loss = 0.5811\n",
            "Checking accuracy on test set\n",
            "Got 271 / 400 correct (67.75)\n",
            "acc = 0.677500\n",
            "Starting epoch 23 / 80\n",
            "t = 1, avg_loss = 0.6219\n",
            "t = 2, avg_loss = 0.5269\n",
            "t = 3, avg_loss = 0.5680\n",
            "t = 4, avg_loss = 0.6023\n",
            "t = 5, avg_loss = 0.5539\n",
            "t = 6, avg_loss = 0.6021\n",
            "t = 7, avg_loss = 0.5364\n",
            "t = 8, avg_loss = 0.6010\n",
            "t = 9, avg_loss = 0.5993\n",
            "t = 10, avg_loss = 0.6549\n",
            "t = 11, avg_loss = 0.5767\n",
            "t = 12, avg_loss = 0.5806\n",
            "t = 13, avg_loss = 0.5870\n",
            "t = 14, avg_loss = 0.6749\n",
            "t = 15, avg_loss = 0.5150\n",
            "t = 16, avg_loss = 0.5924\n",
            "t = 17, avg_loss = 0.5417\n",
            "t = 18, avg_loss = 0.5444\n",
            "t = 19, avg_loss = 0.5879\n",
            "t = 20, avg_loss = 0.5207\n",
            "t = 21, avg_loss = 0.7055\n",
            "t = 22, avg_loss = 0.6206\n",
            "t = 23, avg_loss = 0.6524\n",
            "t = 24, avg_loss = 0.5968\n",
            "t = 25, avg_loss = 0.6207\n",
            "Checking accuracy on test set\n",
            "Got 276 / 400 correct (69.00)\n",
            "acc = 0.690000\n",
            "Starting epoch 24 / 80\n",
            "t = 1, avg_loss = 0.5988\n",
            "t = 2, avg_loss = 0.6313\n",
            "t = 3, avg_loss = 0.5518\n",
            "t = 4, avg_loss = 0.5605\n",
            "t = 5, avg_loss = 0.5240\n",
            "t = 6, avg_loss = 0.5515\n",
            "t = 7, avg_loss = 0.6042\n",
            "t = 8, avg_loss = 0.5073\n",
            "t = 9, avg_loss = 0.6327\n",
            "t = 10, avg_loss = 0.5761\n",
            "t = 11, avg_loss = 0.5888\n",
            "t = 12, avg_loss = 0.5667\n",
            "t = 13, avg_loss = 0.5848\n",
            "t = 14, avg_loss = 0.5387\n",
            "t = 15, avg_loss = 0.5889\n",
            "t = 16, avg_loss = 0.6045\n",
            "t = 17, avg_loss = 0.6157\n",
            "t = 18, avg_loss = 0.5047\n",
            "t = 19, avg_loss = 0.7275\n",
            "t = 20, avg_loss = 0.7202\n",
            "t = 21, avg_loss = 0.6495\n",
            "t = 22, avg_loss = 0.5417\n",
            "t = 23, avg_loss = 0.6361\n",
            "t = 24, avg_loss = 0.6091\n",
            "t = 25, avg_loss = 0.5767\n",
            "Checking accuracy on test set\n",
            "Got 274 / 400 correct (68.50)\n",
            "acc = 0.685000\n",
            "Starting epoch 25 / 80\n",
            "t = 1, avg_loss = 0.5417\n",
            "t = 2, avg_loss = 0.6060\n",
            "t = 3, avg_loss = 0.5726\n",
            "t = 4, avg_loss = 0.6182\n",
            "t = 5, avg_loss = 0.5429\n",
            "t = 6, avg_loss = 0.5582\n",
            "t = 7, avg_loss = 0.5724\n",
            "t = 8, avg_loss = 0.6391\n",
            "t = 9, avg_loss = 0.5173\n",
            "t = 10, avg_loss = 0.6853\n",
            "t = 11, avg_loss = 0.5577\n",
            "t = 12, avg_loss = 0.6644\n",
            "t = 13, avg_loss = 0.6604\n",
            "t = 14, avg_loss = 0.5674\n",
            "t = 15, avg_loss = 0.5850\n",
            "t = 16, avg_loss = 0.5564\n",
            "t = 17, avg_loss = 0.5760\n",
            "t = 18, avg_loss = 0.5121\n",
            "t = 19, avg_loss = 0.6827\n",
            "t = 20, avg_loss = 0.5435\n",
            "t = 21, avg_loss = 0.5180\n",
            "t = 22, avg_loss = 0.5917\n",
            "t = 23, avg_loss = 0.6785\n",
            "t = 24, avg_loss = 0.5439\n",
            "t = 25, avg_loss = 0.5338\n",
            "Checking accuracy on test set\n",
            "Got 274 / 400 correct (68.50)\n",
            "acc = 0.685000\n",
            "Starting epoch 26 / 80\n",
            "t = 1, avg_loss = 0.5693\n",
            "t = 2, avg_loss = 0.5209\n",
            "t = 3, avg_loss = 0.5529\n",
            "t = 4, avg_loss = 0.6295\n",
            "t = 5, avg_loss = 0.5265\n",
            "t = 6, avg_loss = 0.6308\n",
            "t = 7, avg_loss = 0.5911\n",
            "t = 8, avg_loss = 0.5940\n",
            "t = 9, avg_loss = 0.5551\n",
            "t = 10, avg_loss = 0.5617\n",
            "t = 11, avg_loss = 0.4927\n",
            "t = 12, avg_loss = 0.5369\n",
            "t = 13, avg_loss = 0.6555\n",
            "t = 14, avg_loss = 0.6028\n",
            "t = 15, avg_loss = 0.5252\n",
            "t = 16, avg_loss = 0.5803\n",
            "t = 17, avg_loss = 0.6484\n",
            "t = 18, avg_loss = 0.5766\n",
            "t = 19, avg_loss = 0.5237\n",
            "t = 20, avg_loss = 0.6413\n",
            "t = 21, avg_loss = 0.5816\n",
            "t = 22, avg_loss = 0.5976\n",
            "t = 23, avg_loss = 0.6050\n",
            "t = 24, avg_loss = 0.5762\n",
            "t = 25, avg_loss = 0.5738\n",
            "Checking accuracy on test set\n",
            "Got 276 / 400 correct (69.00)\n",
            "acc = 0.690000\n",
            "Starting epoch 27 / 80\n",
            "t = 1, avg_loss = 0.6274\n",
            "t = 2, avg_loss = 0.5905\n",
            "t = 3, avg_loss = 0.5717\n",
            "t = 4, avg_loss = 0.6288\n",
            "t = 5, avg_loss = 0.7010\n",
            "t = 6, avg_loss = 0.6443\n",
            "t = 7, avg_loss = 0.5976\n",
            "t = 8, avg_loss = 0.5602\n",
            "t = 9, avg_loss = 0.6208\n",
            "t = 10, avg_loss = 0.5363\n",
            "t = 11, avg_loss = 0.5015\n",
            "t = 12, avg_loss = 0.5787\n",
            "t = 13, avg_loss = 0.6143\n",
            "t = 14, avg_loss = 0.5641\n",
            "t = 15, avg_loss = 0.5667\n",
            "t = 16, avg_loss = 0.5909\n",
            "t = 17, avg_loss = 0.6379\n",
            "t = 18, avg_loss = 0.5159\n",
            "t = 19, avg_loss = 0.6037\n",
            "t = 20, avg_loss = 0.6199\n",
            "t = 21, avg_loss = 0.6601\n",
            "t = 22, avg_loss = 0.6110\n",
            "t = 23, avg_loss = 0.5965\n",
            "t = 24, avg_loss = 0.6057\n",
            "t = 25, avg_loss = 0.6128\n",
            "Checking accuracy on test set\n",
            "Got 274 / 400 correct (68.50)\n",
            "acc = 0.685000\n",
            "Starting epoch 28 / 80\n",
            "t = 1, avg_loss = 0.5881\n",
            "t = 2, avg_loss = 0.5926\n",
            "t = 3, avg_loss = 0.5968\n",
            "t = 4, avg_loss = 0.6377\n",
            "t = 5, avg_loss = 0.5963\n",
            "t = 6, avg_loss = 0.5586\n",
            "t = 7, avg_loss = 0.5361\n",
            "t = 8, avg_loss = 0.6466\n",
            "t = 9, avg_loss = 0.5722\n",
            "t = 10, avg_loss = 0.5404\n",
            "t = 11, avg_loss = 0.5592\n",
            "t = 12, avg_loss = 0.5908\n",
            "t = 13, avg_loss = 0.4516\n",
            "t = 14, avg_loss = 0.6215\n",
            "t = 15, avg_loss = 0.6122\n",
            "t = 16, avg_loss = 0.6326\n",
            "t = 17, avg_loss = 0.6802\n",
            "t = 18, avg_loss = 0.5792\n",
            "t = 19, avg_loss = 0.5497\n",
            "t = 20, avg_loss = 0.5862\n",
            "t = 21, avg_loss = 0.5542\n",
            "t = 22, avg_loss = 0.5844\n",
            "t = 23, avg_loss = 0.5993\n",
            "t = 24, avg_loss = 0.6507\n",
            "t = 25, avg_loss = 0.5742\n",
            "Checking accuracy on test set\n",
            "Got 266 / 400 correct (66.50)\n",
            "acc = 0.665000\n",
            "Starting epoch 29 / 80\n",
            "t = 1, avg_loss = 0.5708\n",
            "t = 2, avg_loss = 0.4894\n",
            "t = 3, avg_loss = 0.5887\n",
            "t = 4, avg_loss = 0.6082\n",
            "t = 5, avg_loss = 0.5508\n",
            "t = 6, avg_loss = 0.6099\n",
            "t = 7, avg_loss = 0.7174\n",
            "t = 8, avg_loss = 0.5130\n",
            "t = 9, avg_loss = 0.5918\n",
            "t = 10, avg_loss = 0.6263\n",
            "t = 11, avg_loss = 0.6077\n",
            "t = 12, avg_loss = 0.5993\n",
            "t = 13, avg_loss = 0.6378\n",
            "t = 14, avg_loss = 0.6826\n",
            "t = 15, avg_loss = 0.5155\n",
            "t = 16, avg_loss = 0.6503\n",
            "t = 17, avg_loss = 0.5636\n",
            "t = 18, avg_loss = 0.5239\n",
            "t = 19, avg_loss = 0.5845\n",
            "t = 20, avg_loss = 0.5546\n",
            "t = 21, avg_loss = 0.6050\n",
            "t = 22, avg_loss = 0.5794\n",
            "t = 23, avg_loss = 0.5204\n",
            "t = 24, avg_loss = 0.6016\n",
            "t = 25, avg_loss = 0.5194\n",
            "Checking accuracy on test set\n",
            "Got 282 / 400 correct (70.50)\n",
            "acc = 0.705000\n",
            "Starting epoch 30 / 80\n",
            "t = 1, avg_loss = 0.5710\n",
            "t = 2, avg_loss = 0.5966\n",
            "t = 3, avg_loss = 0.5537\n",
            "t = 4, avg_loss = 0.6399\n",
            "t = 5, avg_loss = 0.6526\n",
            "t = 6, avg_loss = 0.5278\n",
            "t = 7, avg_loss = 0.5606\n",
            "t = 8, avg_loss = 0.6514\n",
            "t = 9, avg_loss = 0.5519\n",
            "t = 10, avg_loss = 0.6680\n",
            "t = 11, avg_loss = 0.5639\n",
            "t = 12, avg_loss = 0.6953\n",
            "t = 13, avg_loss = 0.5735\n",
            "t = 14, avg_loss = 0.5672\n",
            "t = 15, avg_loss = 0.6056\n",
            "t = 16, avg_loss = 0.6061\n",
            "t = 17, avg_loss = 0.6086\n",
            "t = 18, avg_loss = 0.6605\n",
            "t = 19, avg_loss = 0.5729\n",
            "t = 20, avg_loss = 0.5538\n",
            "t = 21, avg_loss = 0.5923\n",
            "t = 22, avg_loss = 0.5598\n",
            "t = 23, avg_loss = 0.4822\n",
            "t = 24, avg_loss = 0.5742\n",
            "t = 25, avg_loss = 0.5764\n",
            "Checking accuracy on test set\n",
            "Got 281 / 400 correct (70.25)\n",
            "acc = 0.702500\n",
            "Starting epoch 31 / 80\n",
            "t = 1, avg_loss = 0.5662\n",
            "t = 2, avg_loss = 0.5569\n",
            "t = 3, avg_loss = 0.5517\n",
            "t = 4, avg_loss = 0.5834\n",
            "t = 5, avg_loss = 0.5228\n",
            "t = 6, avg_loss = 0.5235\n",
            "t = 7, avg_loss = 0.5125\n",
            "t = 8, avg_loss = 0.6298\n",
            "t = 9, avg_loss = 0.6052\n",
            "t = 10, avg_loss = 0.5580\n",
            "t = 11, avg_loss = 0.5185\n",
            "t = 12, avg_loss = 0.4730\n",
            "t = 13, avg_loss = 0.6280\n",
            "t = 14, avg_loss = 0.6774\n",
            "t = 15, avg_loss = 0.5617\n",
            "t = 16, avg_loss = 0.6168\n",
            "t = 17, avg_loss = 0.5814\n",
            "t = 18, avg_loss = 0.4827\n",
            "t = 19, avg_loss = 0.5935\n",
            "t = 20, avg_loss = 0.5283\n",
            "t = 21, avg_loss = 0.6151\n",
            "t = 22, avg_loss = 0.5965\n",
            "t = 23, avg_loss = 0.6816\n",
            "t = 24, avg_loss = 0.6200\n",
            "t = 25, avg_loss = 0.7139\n",
            "Checking accuracy on test set\n",
            "Got 274 / 400 correct (68.50)\n",
            "acc = 0.685000\n",
            "Starting epoch 32 / 80\n",
            "t = 1, avg_loss = 0.5696\n",
            "t = 2, avg_loss = 0.5017\n",
            "t = 3, avg_loss = 0.6644\n",
            "t = 4, avg_loss = 0.6099\n",
            "t = 5, avg_loss = 0.5336\n",
            "t = 6, avg_loss = 0.5899\n",
            "t = 7, avg_loss = 0.6026\n",
            "t = 8, avg_loss = 0.5835\n",
            "t = 9, avg_loss = 0.4935\n",
            "t = 10, avg_loss = 0.5051\n",
            "t = 11, avg_loss = 0.5914\n",
            "t = 12, avg_loss = 0.5738\n",
            "t = 13, avg_loss = 0.5783\n",
            "t = 14, avg_loss = 0.6046\n",
            "t = 15, avg_loss = 0.5664\n",
            "t = 16, avg_loss = 0.5920\n",
            "t = 17, avg_loss = 0.6626\n",
            "t = 18, avg_loss = 0.5610\n",
            "t = 19, avg_loss = 0.5454\n",
            "t = 20, avg_loss = 0.5220\n",
            "t = 21, avg_loss = 0.6188\n",
            "t = 22, avg_loss = 0.6439\n",
            "t = 23, avg_loss = 0.5412\n",
            "t = 24, avg_loss = 0.6862\n",
            "t = 25, avg_loss = 0.5721\n",
            "Checking accuracy on test set\n",
            "Got 278 / 400 correct (69.50)\n",
            "acc = 0.695000\n",
            "Starting epoch 33 / 80\n",
            "t = 1, avg_loss = 0.6135\n",
            "t = 2, avg_loss = 0.5885\n",
            "t = 3, avg_loss = 0.6540\n",
            "t = 4, avg_loss = 0.5375\n",
            "t = 5, avg_loss = 0.6409\n",
            "t = 6, avg_loss = 0.5745\n",
            "t = 7, avg_loss = 0.5525\n",
            "t = 8, avg_loss = 0.5555\n",
            "t = 9, avg_loss = 0.5097\n",
            "t = 10, avg_loss = 0.5881\n",
            "t = 11, avg_loss = 0.5145\n",
            "t = 12, avg_loss = 0.7163\n",
            "t = 13, avg_loss = 0.5641\n",
            "t = 14, avg_loss = 0.6412\n",
            "t = 15, avg_loss = 0.6740\n",
            "t = 16, avg_loss = 0.5629\n",
            "t = 17, avg_loss = 0.4821\n",
            "t = 18, avg_loss = 0.5757\n",
            "t = 19, avg_loss = 0.5892\n",
            "t = 20, avg_loss = 0.6297\n",
            "t = 21, avg_loss = 0.5303\n",
            "t = 22, avg_loss = 0.6919\n",
            "t = 23, avg_loss = 0.5318\n",
            "t = 24, avg_loss = 0.6388\n",
            "t = 25, avg_loss = 0.6315\n",
            "Checking accuracy on test set\n",
            "Got 283 / 400 correct (70.75)\n",
            "acc = 0.707500\n",
            "Starting epoch 34 / 80\n",
            "t = 1, avg_loss = 0.4817\n",
            "t = 2, avg_loss = 0.6118\n",
            "t = 3, avg_loss = 0.7057\n",
            "t = 4, avg_loss = 0.5446\n",
            "t = 5, avg_loss = 0.5229\n",
            "t = 6, avg_loss = 0.5349\n",
            "t = 7, avg_loss = 0.5634\n",
            "t = 8, avg_loss = 0.5485\n",
            "t = 9, avg_loss = 0.5151\n",
            "t = 10, avg_loss = 0.5637\n",
            "t = 11, avg_loss = 0.5754\n",
            "t = 12, avg_loss = 0.6580\n",
            "t = 13, avg_loss = 0.5208\n",
            "t = 14, avg_loss = 0.5864\n",
            "t = 15, avg_loss = 0.5489\n",
            "t = 16, avg_loss = 0.5519\n",
            "t = 17, avg_loss = 0.4722\n",
            "t = 18, avg_loss = 0.5535\n",
            "t = 19, avg_loss = 0.6129\n",
            "t = 20, avg_loss = 0.5925\n",
            "t = 21, avg_loss = 0.5710\n",
            "t = 22, avg_loss = 0.5812\n",
            "t = 23, avg_loss = 0.5792\n",
            "t = 24, avg_loss = 0.6078\n",
            "t = 25, avg_loss = 0.6688\n",
            "Checking accuracy on test set\n",
            "Got 268 / 400 correct (67.00)\n",
            "acc = 0.670000\n",
            "Starting epoch 35 / 80\n",
            "t = 1, avg_loss = 0.6173\n",
            "t = 2, avg_loss = 0.6270\n",
            "t = 3, avg_loss = 0.4837\n",
            "t = 4, avg_loss = 0.6450\n",
            "t = 5, avg_loss = 0.5563\n",
            "t = 6, avg_loss = 0.6082\n",
            "t = 7, avg_loss = 0.5074\n",
            "t = 8, avg_loss = 0.4336\n",
            "t = 9, avg_loss = 0.5857\n",
            "t = 10, avg_loss = 0.5177\n",
            "t = 11, avg_loss = 0.5308\n",
            "t = 12, avg_loss = 0.5794\n",
            "t = 13, avg_loss = 0.4922\n",
            "t = 14, avg_loss = 0.5836\n",
            "t = 15, avg_loss = 0.6715\n",
            "t = 16, avg_loss = 0.5864\n",
            "t = 17, avg_loss = 0.5436\n",
            "t = 18, avg_loss = 0.5270\n",
            "t = 19, avg_loss = 0.6477\n",
            "t = 20, avg_loss = 0.5301\n",
            "t = 21, avg_loss = 0.5918\n",
            "t = 22, avg_loss = 0.6676\n",
            "t = 23, avg_loss = 0.6121\n",
            "t = 24, avg_loss = 0.7283\n",
            "t = 25, avg_loss = 0.6585\n",
            "Checking accuracy on test set\n",
            "Got 284 / 400 correct (71.00)\n",
            "acc = 0.710000\n",
            "Starting epoch 36 / 80\n",
            "t = 1, avg_loss = 0.5301\n",
            "t = 2, avg_loss = 0.5972\n",
            "t = 3, avg_loss = 0.6132\n",
            "t = 4, avg_loss = 0.6408\n",
            "t = 5, avg_loss = 0.5627\n",
            "t = 6, avg_loss = 0.5519\n",
            "t = 7, avg_loss = 0.5735\n",
            "t = 8, avg_loss = 0.5501\n",
            "t = 9, avg_loss = 0.4682\n",
            "t = 10, avg_loss = 0.5638\n",
            "t = 11, avg_loss = 0.4450\n",
            "t = 12, avg_loss = 0.5579\n",
            "t = 13, avg_loss = 0.5679\n",
            "t = 14, avg_loss = 0.7258\n",
            "t = 15, avg_loss = 0.5387\n",
            "t = 16, avg_loss = 0.5736\n",
            "t = 17, avg_loss = 0.6304\n",
            "t = 18, avg_loss = 0.5836\n",
            "t = 19, avg_loss = 0.6181\n",
            "t = 20, avg_loss = 0.6215\n",
            "t = 21, avg_loss = 0.5759\n",
            "t = 22, avg_loss = 0.6545\n",
            "t = 23, avg_loss = 0.4933\n",
            "t = 24, avg_loss = 0.5685\n",
            "t = 25, avg_loss = 0.6030\n",
            "Checking accuracy on test set\n",
            "Got 269 / 400 correct (67.25)\n",
            "acc = 0.672500\n",
            "Starting epoch 37 / 80\n",
            "t = 1, avg_loss = 0.5224\n",
            "t = 2, avg_loss = 0.5472\n",
            "t = 3, avg_loss = 0.6248\n",
            "t = 4, avg_loss = 0.5390\n",
            "t = 5, avg_loss = 0.5306\n",
            "t = 6, avg_loss = 0.5576\n",
            "t = 7, avg_loss = 0.6512\n",
            "t = 8, avg_loss = 0.5803\n",
            "t = 9, avg_loss = 0.5405\n",
            "t = 10, avg_loss = 0.5700\n",
            "t = 11, avg_loss = 0.5458\n",
            "t = 12, avg_loss = 0.6734\n",
            "t = 13, avg_loss = 0.5207\n",
            "t = 14, avg_loss = 0.6607\n",
            "t = 15, avg_loss = 0.5750\n",
            "t = 16, avg_loss = 0.5405\n",
            "t = 17, avg_loss = 0.5425\n",
            "t = 18, avg_loss = 0.5278\n",
            "t = 19, avg_loss = 0.5093\n",
            "t = 20, avg_loss = 0.5943\n",
            "t = 21, avg_loss = 0.5969\n",
            "t = 22, avg_loss = 0.5757\n",
            "t = 23, avg_loss = 0.5421\n",
            "t = 24, avg_loss = 0.7053\n",
            "t = 25, avg_loss = 0.5534\n",
            "Checking accuracy on test set\n",
            "Got 284 / 400 correct (71.00)\n",
            "acc = 0.710000\n",
            "Starting epoch 38 / 80\n",
            "t = 1, avg_loss = 0.4967\n",
            "t = 2, avg_loss = 0.5799\n",
            "t = 3, avg_loss = 0.5107\n",
            "t = 4, avg_loss = 0.6254\n",
            "t = 5, avg_loss = 0.5799\n",
            "t = 6, avg_loss = 0.6528\n",
            "t = 7, avg_loss = 0.5869\n",
            "t = 8, avg_loss = 0.5598\n",
            "t = 9, avg_loss = 0.5557\n",
            "t = 10, avg_loss = 0.5976\n",
            "t = 11, avg_loss = 0.5161\n",
            "t = 12, avg_loss = 0.6224\n",
            "t = 13, avg_loss = 0.5789\n",
            "t = 14, avg_loss = 0.6209\n",
            "t = 15, avg_loss = 0.5442\n",
            "t = 16, avg_loss = 0.5969\n",
            "t = 17, avg_loss = 0.5682\n",
            "t = 18, avg_loss = 0.5705\n",
            "t = 19, avg_loss = 0.5942\n",
            "t = 20, avg_loss = 0.4960\n",
            "t = 21, avg_loss = 0.6258\n",
            "t = 22, avg_loss = 0.5617\n",
            "t = 23, avg_loss = 0.5846\n",
            "t = 24, avg_loss = 0.6809\n",
            "t = 25, avg_loss = 0.5936\n",
            "Checking accuracy on test set\n",
            "Got 284 / 400 correct (71.00)\n",
            "acc = 0.710000\n",
            "Starting epoch 39 / 80\n",
            "t = 1, avg_loss = 0.5529\n",
            "t = 2, avg_loss = 0.6032\n",
            "t = 3, avg_loss = 0.4992\n",
            "t = 4, avg_loss = 0.5573\n",
            "t = 5, avg_loss = 0.5304\n",
            "t = 6, avg_loss = 0.6191\n",
            "t = 7, avg_loss = 0.5300\n",
            "t = 8, avg_loss = 0.6272\n",
            "t = 9, avg_loss = 0.5052\n",
            "t = 10, avg_loss = 0.6036\n",
            "t = 11, avg_loss = 0.5332\n",
            "t = 12, avg_loss = 0.6913\n",
            "t = 13, avg_loss = 0.5505\n",
            "t = 14, avg_loss = 0.5692\n",
            "t = 15, avg_loss = 0.5756\n",
            "t = 16, avg_loss = 0.5652\n",
            "t = 17, avg_loss = 0.5079\n",
            "t = 18, avg_loss = 0.5829\n",
            "t = 19, avg_loss = 0.5626\n",
            "t = 20, avg_loss = 0.5500\n",
            "t = 21, avg_loss = 0.5814\n",
            "t = 22, avg_loss = 0.6004\n",
            "t = 23, avg_loss = 0.5430\n",
            "t = 24, avg_loss = 0.7096\n",
            "t = 25, avg_loss = 0.5462\n",
            "Checking accuracy on test set\n",
            "Got 283 / 400 correct (70.75)\n",
            "acc = 0.707500\n",
            "Starting epoch 40 / 80\n",
            "t = 1, avg_loss = 0.5394\n",
            "t = 2, avg_loss = 0.5679\n",
            "t = 3, avg_loss = 0.6027\n",
            "t = 4, avg_loss = 0.5115\n",
            "t = 5, avg_loss = 0.6047\n",
            "t = 6, avg_loss = 0.6322\n",
            "t = 7, avg_loss = 0.5976\n",
            "t = 8, avg_loss = 0.6400\n",
            "t = 9, avg_loss = 0.5765\n",
            "t = 10, avg_loss = 0.5431\n",
            "t = 11, avg_loss = 0.6441\n",
            "t = 12, avg_loss = 0.5424\n",
            "t = 13, avg_loss = 0.6265\n",
            "t = 14, avg_loss = 0.5230\n",
            "t = 15, avg_loss = 0.5008\n",
            "t = 16, avg_loss = 0.6121\n",
            "t = 17, avg_loss = 0.5357\n",
            "t = 18, avg_loss = 0.5733\n",
            "t = 19, avg_loss = 0.5102\n",
            "t = 20, avg_loss = 0.5715\n",
            "t = 21, avg_loss = 0.6128\n",
            "t = 22, avg_loss = 0.5751\n",
            "t = 23, avg_loss = 0.5114\n",
            "t = 24, avg_loss = 0.4895\n",
            "t = 25, avg_loss = 0.5607\n",
            "Checking accuracy on test set\n",
            "Got 283 / 400 correct (70.75)\n",
            "acc = 0.707500\n",
            "Starting epoch 41 / 80\n",
            "t = 1, avg_loss = 0.5541\n",
            "t = 2, avg_loss = 0.5052\n",
            "t = 3, avg_loss = 0.5405\n",
            "t = 4, avg_loss = 0.5383\n",
            "t = 5, avg_loss = 0.4955\n",
            "t = 6, avg_loss = 0.5882\n",
            "t = 7, avg_loss = 0.6313\n",
            "t = 8, avg_loss = 0.6109\n",
            "t = 9, avg_loss = 0.5741\n",
            "t = 10, avg_loss = 0.4912\n",
            "t = 11, avg_loss = 0.5827\n",
            "t = 12, avg_loss = 0.5918\n",
            "t = 13, avg_loss = 0.7394\n",
            "t = 14, avg_loss = 0.6318\n",
            "t = 15, avg_loss = 0.4743\n",
            "t = 16, avg_loss = 0.6430\n",
            "t = 17, avg_loss = 0.5651\n",
            "t = 18, avg_loss = 0.5953\n",
            "t = 19, avg_loss = 0.6002\n",
            "t = 20, avg_loss = 0.4763\n",
            "t = 21, avg_loss = 0.5275\n",
            "t = 22, avg_loss = 0.5923\n",
            "t = 23, avg_loss = 0.6075\n",
            "t = 24, avg_loss = 0.5767\n",
            "t = 25, avg_loss = 0.5776\n",
            "Checking accuracy on test set\n",
            "Got 276 / 400 correct (69.00)\n",
            "acc = 0.690000\n",
            "Starting epoch 42 / 80\n",
            "t = 1, avg_loss = 0.6047\n",
            "t = 2, avg_loss = 0.6153\n",
            "t = 3, avg_loss = 0.4822\n",
            "t = 4, avg_loss = 0.4742\n",
            "t = 5, avg_loss = 0.5898\n",
            "t = 6, avg_loss = 0.5709\n",
            "t = 7, avg_loss = 0.5747\n",
            "t = 8, avg_loss = 0.5695\n",
            "t = 9, avg_loss = 0.5539\n",
            "t = 10, avg_loss = 0.5987\n",
            "t = 11, avg_loss = 0.5820\n",
            "t = 12, avg_loss = 0.5421\n",
            "t = 13, avg_loss = 0.5182\n",
            "t = 14, avg_loss = 0.5794\n",
            "t = 15, avg_loss = 0.6828\n",
            "t = 16, avg_loss = 0.4512\n",
            "t = 17, avg_loss = 0.5507\n",
            "t = 18, avg_loss = 0.5389\n",
            "t = 19, avg_loss = 0.5531\n",
            "t = 20, avg_loss = 0.5309\n",
            "t = 21, avg_loss = 0.5386\n",
            "t = 22, avg_loss = 0.5616\n",
            "t = 23, avg_loss = 0.6159\n",
            "t = 24, avg_loss = 0.6108\n",
            "t = 25, avg_loss = 0.5787\n",
            "Checking accuracy on test set\n",
            "Got 278 / 400 correct (69.50)\n",
            "acc = 0.695000\n",
            "Starting epoch 43 / 80\n",
            "t = 1, avg_loss = 0.5540\n",
            "t = 2, avg_loss = 0.6266\n",
            "t = 3, avg_loss = 0.5811\n",
            "t = 4, avg_loss = 0.5010\n",
            "t = 5, avg_loss = 0.6531\n",
            "t = 6, avg_loss = 0.5383\n",
            "t = 7, avg_loss = 0.5284\n",
            "t = 8, avg_loss = 0.5616\n",
            "t = 9, avg_loss = 0.6237\n",
            "t = 10, avg_loss = 0.5312\n",
            "t = 11, avg_loss = 0.5811\n",
            "t = 12, avg_loss = 0.5498\n",
            "t = 13, avg_loss = 0.5967\n",
            "t = 14, avg_loss = 0.5194\n",
            "t = 15, avg_loss = 0.4895\n",
            "t = 16, avg_loss = 0.6618\n",
            "t = 17, avg_loss = 0.5662\n",
            "t = 18, avg_loss = 0.5157\n",
            "t = 19, avg_loss = 0.5422\n",
            "t = 20, avg_loss = 0.6005\n",
            "t = 21, avg_loss = 0.6323\n",
            "t = 22, avg_loss = 0.5322\n",
            "t = 23, avg_loss = 0.6236\n",
            "t = 24, avg_loss = 0.5166\n",
            "t = 25, avg_loss = 0.5726\n",
            "Checking accuracy on test set\n",
            "Got 277 / 400 correct (69.25)\n",
            "acc = 0.692500\n",
            "Starting epoch 44 / 80\n",
            "t = 1, avg_loss = 0.5969\n",
            "t = 2, avg_loss = 0.5372\n",
            "t = 3, avg_loss = 0.5599\n",
            "t = 4, avg_loss = 0.5851\n",
            "t = 5, avg_loss = 0.5078\n",
            "t = 6, avg_loss = 0.5937\n",
            "t = 7, avg_loss = 0.6153\n",
            "t = 8, avg_loss = 0.5528\n",
            "t = 9, avg_loss = 0.5154\n",
            "t = 10, avg_loss = 0.5206\n",
            "t = 11, avg_loss = 0.5730\n",
            "t = 12, avg_loss = 0.5604\n",
            "t = 13, avg_loss = 0.4939\n",
            "t = 14, avg_loss = 0.6155\n",
            "t = 15, avg_loss = 0.5730\n",
            "t = 16, avg_loss = 0.6178\n",
            "t = 17, avg_loss = 0.6088\n",
            "t = 18, avg_loss = 0.6475\n",
            "t = 19, avg_loss = 0.5706\n",
            "t = 20, avg_loss = 0.4923\n",
            "t = 21, avg_loss = 0.6965\n",
            "t = 22, avg_loss = 0.6337\n",
            "t = 23, avg_loss = 0.5186\n",
            "t = 24, avg_loss = 0.5286\n",
            "t = 25, avg_loss = 0.7054\n",
            "Checking accuracy on test set\n",
            "Got 277 / 400 correct (69.25)\n",
            "acc = 0.692500\n",
            "Starting epoch 45 / 80\n",
            "t = 1, avg_loss = 0.5820\n",
            "t = 2, avg_loss = 0.6341\n",
            "t = 3, avg_loss = 0.6539\n",
            "t = 4, avg_loss = 0.5979\n",
            "t = 5, avg_loss = 0.6324\n",
            "t = 6, avg_loss = 0.5369\n",
            "t = 7, avg_loss = 0.6043\n",
            "t = 8, avg_loss = 0.6810\n",
            "t = 9, avg_loss = 0.5808\n",
            "t = 10, avg_loss = 0.5224\n",
            "t = 11, avg_loss = 0.6426\n",
            "t = 12, avg_loss = 0.6318\n",
            "t = 13, avg_loss = 0.6478\n",
            "t = 14, avg_loss = 0.5983\n",
            "t = 15, avg_loss = 0.5230\n",
            "t = 16, avg_loss = 0.5986\n",
            "t = 17, avg_loss = 0.5881\n",
            "t = 18, avg_loss = 0.5957\n",
            "t = 19, avg_loss = 0.6165\n",
            "t = 20, avg_loss = 0.5525\n",
            "t = 21, avg_loss = 0.5764\n",
            "t = 22, avg_loss = 0.5960\n",
            "t = 23, avg_loss = 0.5814\n",
            "t = 24, avg_loss = 0.4577\n",
            "t = 25, avg_loss = 0.6063\n",
            "Checking accuracy on test set\n",
            "Got 288 / 400 correct (72.00)\n",
            "acc = 0.720000\n",
            "Starting epoch 46 / 80\n",
            "t = 1, avg_loss = 0.5281\n",
            "t = 2, avg_loss = 0.5416\n",
            "t = 3, avg_loss = 0.6537\n",
            "t = 4, avg_loss = 0.4722\n",
            "t = 5, avg_loss = 0.5267\n",
            "t = 6, avg_loss = 0.6339\n",
            "t = 7, avg_loss = 0.5118\n",
            "t = 8, avg_loss = 0.5498\n",
            "t = 9, avg_loss = 0.5992\n",
            "t = 10, avg_loss = 0.6211\n",
            "t = 11, avg_loss = 0.4987\n",
            "t = 12, avg_loss = 0.7147\n",
            "t = 13, avg_loss = 0.6046\n",
            "t = 14, avg_loss = 0.5528\n",
            "t = 15, avg_loss = 0.5143\n",
            "t = 16, avg_loss = 0.5606\n",
            "t = 17, avg_loss = 0.5044\n",
            "t = 18, avg_loss = 0.6315\n",
            "t = 19, avg_loss = 0.5799\n",
            "t = 20, avg_loss = 0.5949\n",
            "t = 21, avg_loss = 0.5996\n",
            "t = 22, avg_loss = 0.5646\n",
            "t = 23, avg_loss = 0.6539\n",
            "t = 24, avg_loss = 0.5921\n",
            "t = 25, avg_loss = 0.5616\n",
            "Checking accuracy on test set\n",
            "Got 283 / 400 correct (70.75)\n",
            "acc = 0.707500\n",
            "Starting epoch 47 / 80\n",
            "t = 1, avg_loss = 0.7333\n",
            "t = 2, avg_loss = 0.5727\n",
            "t = 3, avg_loss = 0.5739\n",
            "t = 4, avg_loss = 0.5178\n",
            "t = 5, avg_loss = 0.5323\n",
            "t = 6, avg_loss = 0.5973\n",
            "t = 7, avg_loss = 0.5761\n",
            "t = 8, avg_loss = 0.5868\n",
            "t = 9, avg_loss = 0.5146\n",
            "t = 10, avg_loss = 0.6429\n",
            "t = 11, avg_loss = 0.5679\n",
            "t = 12, avg_loss = 0.5271\n",
            "t = 13, avg_loss = 0.6635\n",
            "t = 14, avg_loss = 0.5419\n",
            "t = 15, avg_loss = 0.5140\n",
            "t = 16, avg_loss = 0.5806\n",
            "t = 17, avg_loss = 0.5623\n",
            "t = 18, avg_loss = 0.5246\n",
            "t = 19, avg_loss = 0.6858\n",
            "t = 20, avg_loss = 0.5391\n",
            "t = 21, avg_loss = 0.5951\n",
            "t = 22, avg_loss = 0.5621\n",
            "t = 23, avg_loss = 0.5155\n",
            "t = 24, avg_loss = 0.5975\n",
            "t = 25, avg_loss = 0.5981\n",
            "Checking accuracy on test set\n",
            "Got 280 / 400 correct (70.00)\n",
            "acc = 0.700000\n",
            "Starting epoch 48 / 80\n",
            "t = 1, avg_loss = 0.5427\n",
            "t = 2, avg_loss = 0.5371\n",
            "t = 3, avg_loss = 0.5011\n",
            "t = 4, avg_loss = 0.6528\n",
            "t = 5, avg_loss = 0.6834\n",
            "t = 6, avg_loss = 0.6325\n",
            "t = 7, avg_loss = 0.5780\n",
            "t = 8, avg_loss = 0.5074\n",
            "t = 9, avg_loss = 0.5717\n",
            "t = 10, avg_loss = 0.5239\n",
            "t = 11, avg_loss = 0.5648\n",
            "t = 12, avg_loss = 0.6014\n",
            "t = 13, avg_loss = 0.6061\n",
            "t = 14, avg_loss = 0.5506\n",
            "t = 15, avg_loss = 0.5149\n",
            "t = 16, avg_loss = 0.5743\n",
            "t = 17, avg_loss = 0.5753\n",
            "t = 18, avg_loss = 0.5401\n",
            "t = 19, avg_loss = 0.5459\n",
            "t = 20, avg_loss = 0.5916\n",
            "t = 21, avg_loss = 0.5837\n",
            "t = 22, avg_loss = 0.6371\n",
            "t = 23, avg_loss = 0.6465\n",
            "t = 24, avg_loss = 0.5730\n",
            "t = 25, avg_loss = 0.5026\n",
            "Checking accuracy on test set\n",
            "Got 277 / 400 correct (69.25)\n",
            "acc = 0.692500\n",
            "Starting epoch 49 / 80\n",
            "t = 1, avg_loss = 0.4874\n",
            "t = 2, avg_loss = 0.4977\n",
            "t = 3, avg_loss = 0.6006\n",
            "t = 4, avg_loss = 0.5571\n",
            "t = 5, avg_loss = 0.7207\n",
            "t = 6, avg_loss = 0.5270\n",
            "t = 7, avg_loss = 0.5354\n",
            "t = 8, avg_loss = 0.6475\n",
            "t = 9, avg_loss = 0.6622\n",
            "t = 10, avg_loss = 0.6822\n",
            "t = 11, avg_loss = 0.5507\n",
            "t = 12, avg_loss = 0.6012\n",
            "t = 13, avg_loss = 0.5142\n",
            "t = 14, avg_loss = 0.5186\n",
            "t = 15, avg_loss = 0.5255\n",
            "t = 16, avg_loss = 0.6045\n",
            "t = 17, avg_loss = 0.5128\n",
            "t = 18, avg_loss = 0.5583\n",
            "t = 19, avg_loss = 0.5802\n",
            "t = 20, avg_loss = 0.5313\n",
            "t = 21, avg_loss = 0.4994\n",
            "t = 22, avg_loss = 0.5082\n",
            "t = 23, avg_loss = 0.5475\n",
            "t = 24, avg_loss = 0.5225\n",
            "t = 25, avg_loss = 0.5712\n",
            "Checking accuracy on test set\n",
            "Got 280 / 400 correct (70.00)\n",
            "acc = 0.700000\n",
            "Starting epoch 50 / 80\n",
            "t = 1, avg_loss = 0.5604\n",
            "t = 2, avg_loss = 0.6367\n",
            "t = 3, avg_loss = 0.6635\n",
            "t = 4, avg_loss = 0.5680\n",
            "t = 5, avg_loss = 0.5175\n",
            "t = 6, avg_loss = 0.5056\n",
            "t = 7, avg_loss = 0.6232\n",
            "t = 8, avg_loss = 0.5653\n",
            "t = 9, avg_loss = 0.5484\n",
            "t = 10, avg_loss = 0.6765\n",
            "t = 11, avg_loss = 0.5294\n",
            "t = 12, avg_loss = 0.5615\n",
            "t = 13, avg_loss = 0.5477\n",
            "t = 14, avg_loss = 0.6343\n",
            "t = 15, avg_loss = 0.5624\n",
            "t = 16, avg_loss = 0.5138\n",
            "t = 17, avg_loss = 0.6327\n",
            "t = 18, avg_loss = 0.6174\n",
            "t = 19, avg_loss = 0.4933\n",
            "t = 20, avg_loss = 0.6262\n",
            "t = 21, avg_loss = 0.5965\n",
            "t = 22, avg_loss = 0.5267\n",
            "t = 23, avg_loss = 0.4908\n",
            "t = 24, avg_loss = 0.5824\n",
            "t = 25, avg_loss = 0.7694\n",
            "Checking accuracy on test set\n",
            "Got 280 / 400 correct (70.00)\n",
            "acc = 0.700000\n",
            "Starting epoch 51 / 80\n",
            "t = 1, avg_loss = 0.5430\n",
            "t = 2, avg_loss = 0.6635\n",
            "t = 3, avg_loss = 0.7389\n",
            "t = 4, avg_loss = 0.4919\n",
            "t = 5, avg_loss = 0.5530\n",
            "t = 6, avg_loss = 0.5003\n",
            "t = 7, avg_loss = 0.5795\n",
            "t = 8, avg_loss = 0.5425\n",
            "t = 9, avg_loss = 0.5833\n",
            "t = 10, avg_loss = 0.5341\n",
            "t = 11, avg_loss = 0.5776\n",
            "t = 12, avg_loss = 0.5192\n",
            "t = 13, avg_loss = 0.5844\n",
            "t = 14, avg_loss = 0.5180\n",
            "t = 15, avg_loss = 0.6403\n",
            "t = 16, avg_loss = 0.5437\n",
            "t = 17, avg_loss = 0.5210\n",
            "t = 18, avg_loss = 0.6574\n",
            "t = 19, avg_loss = 0.4958\n",
            "t = 20, avg_loss = 0.5117\n",
            "t = 21, avg_loss = 0.5833\n",
            "t = 22, avg_loss = 0.5489\n",
            "t = 23, avg_loss = 0.5138\n",
            "t = 24, avg_loss = 0.5838\n",
            "t = 25, avg_loss = 0.5046\n",
            "Checking accuracy on test set\n",
            "Got 265 / 400 correct (66.25)\n",
            "acc = 0.662500\n",
            "Starting epoch 52 / 80\n",
            "t = 1, avg_loss = 0.5741\n",
            "t = 2, avg_loss = 0.4662\n",
            "t = 3, avg_loss = 0.5475\n",
            "t = 4, avg_loss = 0.4447\n",
            "t = 5, avg_loss = 0.6260\n",
            "t = 6, avg_loss = 0.6367\n",
            "t = 7, avg_loss = 0.5782\n",
            "t = 8, avg_loss = 0.5360\n",
            "t = 9, avg_loss = 0.5747\n",
            "t = 10, avg_loss = 0.5612\n",
            "t = 11, avg_loss = 0.5893\n",
            "t = 12, avg_loss = 0.5654\n",
            "t = 13, avg_loss = 0.5551\n",
            "t = 14, avg_loss = 0.5846\n",
            "t = 15, avg_loss = 0.5679\n",
            "t = 16, avg_loss = 0.5959\n",
            "t = 17, avg_loss = 0.5418\n",
            "t = 18, avg_loss = 0.7233\n",
            "t = 19, avg_loss = 0.5571\n",
            "t = 20, avg_loss = 0.6365\n",
            "t = 21, avg_loss = 0.5386\n",
            "t = 22, avg_loss = 0.5479\n",
            "t = 23, avg_loss = 0.6076\n",
            "t = 24, avg_loss = 0.4889\n",
            "t = 25, avg_loss = 0.4995\n",
            "Checking accuracy on test set\n",
            "Got 278 / 400 correct (69.50)\n",
            "acc = 0.695000\n",
            "Starting epoch 53 / 80\n",
            "t = 1, avg_loss = 0.5881\n",
            "t = 2, avg_loss = 0.5886\n",
            "t = 3, avg_loss = 0.5451\n",
            "t = 4, avg_loss = 0.6074\n",
            "t = 5, avg_loss = 0.7393\n",
            "t = 6, avg_loss = 0.4659\n",
            "t = 7, avg_loss = 0.5284\n",
            "t = 8, avg_loss = 0.5442\n",
            "t = 9, avg_loss = 0.5401\n",
            "t = 10, avg_loss = 0.5825\n",
            "t = 11, avg_loss = 0.5510\n",
            "t = 12, avg_loss = 0.6482\n",
            "t = 13, avg_loss = 0.6004\n",
            "t = 14, avg_loss = 0.5956\n",
            "t = 15, avg_loss = 0.6260\n",
            "t = 16, avg_loss = 0.6185\n",
            "t = 17, avg_loss = 0.5710\n",
            "t = 18, avg_loss = 0.5803\n",
            "t = 19, avg_loss = 0.6171\n",
            "t = 20, avg_loss = 0.5365\n",
            "t = 21, avg_loss = 0.5766\n",
            "t = 22, avg_loss = 0.5655\n",
            "t = 23, avg_loss = 0.6638\n",
            "t = 24, avg_loss = 0.5304\n",
            "t = 25, avg_loss = 0.5519\n",
            "Checking accuracy on test set\n",
            "Got 277 / 400 correct (69.25)\n",
            "acc = 0.692500\n",
            "Starting epoch 54 / 80\n",
            "t = 1, avg_loss = 0.5679\n",
            "t = 2, avg_loss = 0.4865\n",
            "t = 3, avg_loss = 0.5278\n",
            "t = 4, avg_loss = 0.6542\n",
            "t = 5, avg_loss = 0.6133\n",
            "t = 6, avg_loss = 0.5877\n",
            "t = 7, avg_loss = 0.4754\n",
            "t = 8, avg_loss = 0.7450\n",
            "t = 9, avg_loss = 0.5697\n",
            "t = 10, avg_loss = 0.5760\n",
            "t = 11, avg_loss = 0.5237\n",
            "t = 12, avg_loss = 0.5471\n",
            "t = 13, avg_loss = 0.5223\n",
            "t = 14, avg_loss = 0.6407\n",
            "t = 15, avg_loss = 0.5272\n",
            "t = 16, avg_loss = 0.6275\n",
            "t = 17, avg_loss = 0.5614\n",
            "t = 18, avg_loss = 0.5753\n",
            "t = 19, avg_loss = 0.5936\n",
            "t = 20, avg_loss = 0.5085\n",
            "t = 21, avg_loss = 0.6794\n",
            "t = 22, avg_loss = 0.5575\n",
            "t = 23, avg_loss = 0.4953\n",
            "t = 24, avg_loss = 0.4890\n",
            "t = 25, avg_loss = 0.6137\n",
            "Checking accuracy on test set\n",
            "Got 285 / 400 correct (71.25)\n",
            "acc = 0.712500\n",
            "Starting epoch 55 / 80\n",
            "t = 1, avg_loss = 0.5393\n",
            "t = 2, avg_loss = 0.5502\n",
            "t = 3, avg_loss = 0.5697\n",
            "t = 4, avg_loss = 0.5694\n",
            "t = 5, avg_loss = 0.5063\n",
            "t = 6, avg_loss = 0.5571\n",
            "t = 7, avg_loss = 0.5049\n",
            "t = 8, avg_loss = 0.6202\n",
            "t = 9, avg_loss = 0.5762\n",
            "t = 10, avg_loss = 0.5306\n",
            "t = 11, avg_loss = 0.4816\n",
            "t = 12, avg_loss = 0.5297\n",
            "t = 13, avg_loss = 0.6555\n",
            "t = 14, avg_loss = 0.6624\n",
            "t = 15, avg_loss = 0.5980\n",
            "t = 16, avg_loss = 0.5400\n",
            "t = 17, avg_loss = 0.4897\n",
            "t = 18, avg_loss = 0.5612\n",
            "t = 19, avg_loss = 0.5494\n",
            "t = 20, avg_loss = 0.5114\n",
            "t = 21, avg_loss = 0.5272\n",
            "t = 22, avg_loss = 0.5122\n",
            "t = 23, avg_loss = 0.6180\n",
            "t = 24, avg_loss = 0.5816\n",
            "t = 25, avg_loss = 0.5284\n",
            "Checking accuracy on test set\n",
            "Got 269 / 400 correct (67.25)\n",
            "acc = 0.672500\n",
            "Starting epoch 56 / 80\n",
            "t = 1, avg_loss = 0.5688\n",
            "t = 2, avg_loss = 0.6039\n",
            "t = 3, avg_loss = 0.6465\n",
            "t = 4, avg_loss = 0.5677\n",
            "t = 5, avg_loss = 0.5452\n",
            "t = 6, avg_loss = 0.6133\n",
            "t = 7, avg_loss = 0.5280\n",
            "t = 8, avg_loss = 0.6269\n",
            "t = 9, avg_loss = 0.7125\n",
            "t = 10, avg_loss = 0.5093\n",
            "t = 11, avg_loss = 0.6585\n",
            "t = 12, avg_loss = 0.5314\n",
            "t = 13, avg_loss = 0.5810\n",
            "t = 14, avg_loss = 0.5398\n",
            "t = 15, avg_loss = 0.5491\n",
            "t = 16, avg_loss = 0.6044\n",
            "t = 17, avg_loss = 0.5978\n",
            "t = 18, avg_loss = 0.5137\n",
            "t = 19, avg_loss = 0.6245\n",
            "t = 20, avg_loss = 0.5713\n",
            "t = 21, avg_loss = 0.5041\n",
            "t = 22, avg_loss = 0.5355\n",
            "t = 23, avg_loss = 0.6050\n",
            "t = 24, avg_loss = 0.6045\n",
            "t = 25, avg_loss = 0.5456\n",
            "Checking accuracy on test set\n",
            "Got 278 / 400 correct (69.50)\n",
            "acc = 0.695000\n",
            "Starting epoch 57 / 80\n",
            "t = 1, avg_loss = 0.5747\n",
            "t = 2, avg_loss = 0.5905\n",
            "t = 3, avg_loss = 0.4983\n",
            "t = 4, avg_loss = 0.5484\n",
            "t = 5, avg_loss = 0.5419\n",
            "t = 6, avg_loss = 0.5435\n",
            "t = 7, avg_loss = 0.5586\n",
            "t = 8, avg_loss = 0.5059\n",
            "t = 9, avg_loss = 0.6107\n",
            "t = 10, avg_loss = 0.4965\n",
            "t = 11, avg_loss = 0.5890\n",
            "t = 12, avg_loss = 0.5035\n",
            "t = 13, avg_loss = 0.5443\n",
            "t = 14, avg_loss = 0.5898\n",
            "t = 15, avg_loss = 0.5861\n",
            "t = 16, avg_loss = 0.5446\n",
            "t = 17, avg_loss = 0.6610\n",
            "t = 18, avg_loss = 0.6368\n",
            "t = 19, avg_loss = 0.6067\n",
            "t = 20, avg_loss = 0.5431\n",
            "t = 21, avg_loss = 0.5166\n",
            "t = 22, avg_loss = 0.5895\n",
            "t = 23, avg_loss = 0.6330\n",
            "t = 24, avg_loss = 0.5875\n",
            "t = 25, avg_loss = 0.5613\n",
            "Checking accuracy on test set\n",
            "Got 291 / 400 correct (72.75)\n",
            "acc = 0.727500\n",
            "Starting epoch 58 / 80\n",
            "t = 1, avg_loss = 0.5555\n",
            "t = 2, avg_loss = 0.6475\n",
            "t = 3, avg_loss = 0.5265\n",
            "t = 4, avg_loss = 0.5132\n",
            "t = 5, avg_loss = 0.5408\n",
            "t = 6, avg_loss = 0.5872\n",
            "t = 7, avg_loss = 0.5888\n",
            "t = 8, avg_loss = 0.4778\n",
            "t = 9, avg_loss = 0.5761\n",
            "t = 10, avg_loss = 0.5952\n",
            "t = 11, avg_loss = 0.6242\n",
            "t = 12, avg_loss = 0.5920\n",
            "t = 13, avg_loss = 0.3877\n",
            "t = 14, avg_loss = 0.5045\n",
            "t = 15, avg_loss = 0.5004\n",
            "t = 16, avg_loss = 0.5517\n",
            "t = 17, avg_loss = 0.5472\n",
            "t = 18, avg_loss = 0.5784\n",
            "t = 19, avg_loss = 0.6029\n",
            "t = 20, avg_loss = 0.4750\n",
            "t = 21, avg_loss = 0.6344\n",
            "t = 22, avg_loss = 0.5767\n",
            "t = 23, avg_loss = 0.6385\n",
            "t = 24, avg_loss = 0.5405\n",
            "t = 25, avg_loss = 0.5154\n",
            "Checking accuracy on test set\n",
            "Got 294 / 400 correct (73.50)\n",
            "acc = 0.735000\n",
            "Starting epoch 59 / 80\n",
            "t = 1, avg_loss = 0.5430\n",
            "t = 2, avg_loss = 0.5108\n",
            "t = 3, avg_loss = 0.5741\n",
            "t = 4, avg_loss = 0.5933\n",
            "t = 5, avg_loss = 0.5021\n",
            "t = 6, avg_loss = 0.5297\n",
            "t = 7, avg_loss = 0.5264\n",
            "t = 8, avg_loss = 0.5568\n",
            "t = 9, avg_loss = 0.6645\n",
            "t = 10, avg_loss = 0.6093\n",
            "t = 11, avg_loss = 0.5166\n",
            "t = 12, avg_loss = 0.5960\n",
            "t = 13, avg_loss = 0.6109\n",
            "t = 14, avg_loss = 0.5140\n",
            "t = 15, avg_loss = 0.5764\n",
            "t = 16, avg_loss = 0.5016\n",
            "t = 17, avg_loss = 0.5245\n",
            "t = 18, avg_loss = 0.4734\n",
            "t = 19, avg_loss = 0.5908\n",
            "t = 20, avg_loss = 0.5717\n",
            "t = 21, avg_loss = 0.6210\n",
            "t = 22, avg_loss = 0.4387\n",
            "t = 23, avg_loss = 0.5445\n",
            "t = 24, avg_loss = 0.4413\n",
            "t = 25, avg_loss = 0.5779\n",
            "Checking accuracy on test set\n",
            "Got 274 / 400 correct (68.50)\n",
            "acc = 0.685000\n",
            "Starting epoch 60 / 80\n",
            "t = 1, avg_loss = 0.5871\n",
            "t = 2, avg_loss = 0.5348\n",
            "t = 3, avg_loss = 0.5215\n",
            "t = 4, avg_loss = 0.6335\n",
            "t = 5, avg_loss = 0.5633\n",
            "t = 6, avg_loss = 0.6583\n",
            "t = 7, avg_loss = 0.6574\n",
            "t = 8, avg_loss = 0.5352\n",
            "t = 9, avg_loss = 0.6006\n",
            "t = 10, avg_loss = 0.5171\n",
            "t = 11, avg_loss = 0.5428\n",
            "t = 12, avg_loss = 0.5569\n",
            "t = 13, avg_loss = 0.5019\n",
            "t = 14, avg_loss = 0.5749\n",
            "t = 15, avg_loss = 0.4965\n",
            "t = 16, avg_loss = 0.5335\n",
            "t = 17, avg_loss = 0.5062\n",
            "t = 18, avg_loss = 0.5030\n",
            "t = 19, avg_loss = 0.5829\n",
            "t = 20, avg_loss = 0.4910\n",
            "t = 21, avg_loss = 0.5603\n",
            "t = 22, avg_loss = 0.5240\n",
            "t = 23, avg_loss = 0.6540\n",
            "t = 24, avg_loss = 0.5759\n",
            "t = 25, avg_loss = 0.5266\n",
            "Checking accuracy on test set\n",
            "Got 280 / 400 correct (70.00)\n",
            "acc = 0.700000\n",
            "Starting epoch 61 / 80\n",
            "t = 1, avg_loss = 0.4823\n",
            "t = 2, avg_loss = 0.6003\n",
            "t = 3, avg_loss = 0.5711\n",
            "t = 4, avg_loss = 0.5177\n",
            "t = 5, avg_loss = 0.5844\n",
            "t = 6, avg_loss = 0.5339\n",
            "t = 7, avg_loss = 0.5638\n",
            "t = 8, avg_loss = 0.5272\n",
            "t = 9, avg_loss = 0.5653\n",
            "t = 10, avg_loss = 0.6490\n",
            "t = 11, avg_loss = 0.6734\n",
            "t = 12, avg_loss = 0.5814\n",
            "t = 13, avg_loss = 0.4835\n",
            "t = 14, avg_loss = 0.6252\n",
            "t = 15, avg_loss = 0.4558\n",
            "t = 16, avg_loss = 0.6025\n",
            "t = 17, avg_loss = 0.4733\n",
            "t = 18, avg_loss = 0.5450\n",
            "t = 19, avg_loss = 0.4617\n",
            "t = 20, avg_loss = 0.5866\n",
            "t = 21, avg_loss = 0.5980\n",
            "t = 22, avg_loss = 0.4814\n",
            "t = 23, avg_loss = 0.5215\n",
            "t = 24, avg_loss = 0.5585\n",
            "t = 25, avg_loss = 0.5072\n",
            "Checking accuracy on test set\n",
            "Got 292 / 400 correct (73.00)\n",
            "acc = 0.730000\n",
            "Starting epoch 62 / 80\n",
            "t = 1, avg_loss = 0.5089\n",
            "t = 2, avg_loss = 0.4935\n",
            "t = 3, avg_loss = 0.5376\n",
            "t = 4, avg_loss = 0.4760\n",
            "t = 5, avg_loss = 0.5941\n",
            "t = 6, avg_loss = 0.4781\n",
            "t = 7, avg_loss = 0.5754\n",
            "t = 8, avg_loss = 0.6318\n",
            "t = 9, avg_loss = 0.4795\n",
            "t = 10, avg_loss = 0.5794\n",
            "t = 11, avg_loss = 0.6095\n",
            "t = 12, avg_loss = 0.4945\n",
            "t = 13, avg_loss = 0.4475\n",
            "t = 14, avg_loss = 0.5362\n",
            "t = 15, avg_loss = 0.5412\n",
            "t = 16, avg_loss = 0.5540\n",
            "t = 17, avg_loss = 0.6161\n",
            "t = 18, avg_loss = 0.5752\n",
            "t = 19, avg_loss = 0.4872\n",
            "t = 20, avg_loss = 0.5920\n",
            "t = 21, avg_loss = 0.6849\n",
            "t = 22, avg_loss = 0.5544\n",
            "t = 23, avg_loss = 0.5543\n",
            "t = 24, avg_loss = 0.6005\n",
            "t = 25, avg_loss = 0.5470\n",
            "Checking accuracy on test set\n",
            "Got 269 / 400 correct (67.25)\n",
            "acc = 0.672500\n",
            "Starting epoch 63 / 80\n",
            "t = 1, avg_loss = 0.6168\n",
            "t = 2, avg_loss = 0.5789\n",
            "t = 3, avg_loss = 0.6000\n",
            "t = 4, avg_loss = 0.4967\n",
            "t = 5, avg_loss = 0.4827\n",
            "t = 6, avg_loss = 0.4520\n",
            "t = 7, avg_loss = 0.5037\n",
            "t = 8, avg_loss = 0.4848\n",
            "t = 9, avg_loss = 0.5236\n",
            "t = 10, avg_loss = 0.5937\n",
            "t = 11, avg_loss = 0.5400\n",
            "t = 12, avg_loss = 0.5472\n",
            "t = 13, avg_loss = 0.6869\n",
            "t = 14, avg_loss = 0.5136\n",
            "t = 15, avg_loss = 0.6225\n",
            "t = 16, avg_loss = 0.5402\n",
            "t = 17, avg_loss = 0.5407\n",
            "t = 18, avg_loss = 0.5360\n",
            "t = 19, avg_loss = 0.5142\n",
            "t = 20, avg_loss = 0.5863\n",
            "t = 21, avg_loss = 0.4895\n",
            "t = 22, avg_loss = 0.7488\n",
            "t = 23, avg_loss = 0.5542\n",
            "t = 24, avg_loss = 0.5702\n",
            "t = 25, avg_loss = 0.7027\n",
            "Checking accuracy on test set\n",
            "Got 292 / 400 correct (73.00)\n",
            "acc = 0.730000\n",
            "Starting epoch 64 / 80\n",
            "t = 1, avg_loss = 0.5664\n",
            "t = 2, avg_loss = 0.6201\n",
            "t = 3, avg_loss = 0.5395\n",
            "t = 4, avg_loss = 0.6126\n",
            "t = 5, avg_loss = 0.6079\n",
            "t = 6, avg_loss = 0.5874\n",
            "t = 7, avg_loss = 0.6450\n",
            "t = 8, avg_loss = 0.5415\n",
            "t = 9, avg_loss = 0.6284\n",
            "t = 10, avg_loss = 0.5777\n",
            "t = 11, avg_loss = 0.5783\n",
            "t = 12, avg_loss = 0.4928\n",
            "t = 13, avg_loss = 0.4947\n",
            "t = 14, avg_loss = 0.6528\n",
            "t = 15, avg_loss = 0.6199\n",
            "t = 16, avg_loss = 0.5360\n",
            "t = 17, avg_loss = 0.5458\n",
            "t = 18, avg_loss = 0.4686\n",
            "t = 19, avg_loss = 0.5231\n",
            "t = 20, avg_loss = 0.5183\n",
            "t = 21, avg_loss = 0.4911\n",
            "t = 22, avg_loss = 0.5436\n",
            "t = 23, avg_loss = 0.4530\n",
            "t = 24, avg_loss = 0.5323\n",
            "t = 25, avg_loss = 0.5345\n",
            "Checking accuracy on test set\n",
            "Got 288 / 400 correct (72.00)\n",
            "acc = 0.720000\n",
            "Starting epoch 65 / 80\n",
            "t = 1, avg_loss = 0.5238\n",
            "t = 2, avg_loss = 0.6361\n",
            "t = 3, avg_loss = 0.5086\n",
            "t = 4, avg_loss = 0.5046\n",
            "t = 5, avg_loss = 0.5561\n",
            "t = 6, avg_loss = 0.6176\n",
            "t = 7, avg_loss = 0.4820\n",
            "t = 8, avg_loss = 0.5089\n",
            "t = 9, avg_loss = 0.5550\n",
            "t = 10, avg_loss = 0.5538\n",
            "t = 11, avg_loss = 0.4467\n",
            "t = 12, avg_loss = 0.5126\n",
            "t = 13, avg_loss = 0.5132\n",
            "t = 14, avg_loss = 0.4672\n",
            "t = 15, avg_loss = 0.5316\n",
            "t = 16, avg_loss = 0.6175\n",
            "t = 17, avg_loss = 0.5337\n",
            "t = 18, avg_loss = 0.6056\n",
            "t = 19, avg_loss = 0.6770\n",
            "t = 20, avg_loss = 0.5464\n",
            "t = 21, avg_loss = 0.5393\n",
            "t = 22, avg_loss = 0.5397\n",
            "t = 23, avg_loss = 0.5869\n",
            "t = 24, avg_loss = 0.5768\n",
            "t = 25, avg_loss = 0.5972\n",
            "Checking accuracy on test set\n",
            "Got 273 / 400 correct (68.25)\n",
            "acc = 0.682500\n",
            "Starting epoch 66 / 80\n",
            "t = 1, avg_loss = 0.5635\n",
            "t = 2, avg_loss = 0.5408\n",
            "t = 3, avg_loss = 0.5755\n",
            "t = 4, avg_loss = 0.5886\n",
            "t = 5, avg_loss = 0.5739\n",
            "t = 6, avg_loss = 0.5574\n",
            "t = 7, avg_loss = 0.5364\n",
            "t = 8, avg_loss = 0.5452\n",
            "t = 9, avg_loss = 0.6776\n",
            "t = 10, avg_loss = 0.4785\n",
            "t = 11, avg_loss = 0.6215\n",
            "t = 12, avg_loss = 0.5414\n",
            "t = 13, avg_loss = 0.6269\n",
            "t = 14, avg_loss = 0.5833\n",
            "t = 15, avg_loss = 0.6283\n",
            "t = 16, avg_loss = 0.5517\n",
            "t = 17, avg_loss = 0.5251\n",
            "t = 18, avg_loss = 0.6307\n",
            "t = 19, avg_loss = 0.5480\n",
            "t = 20, avg_loss = 0.5346\n",
            "t = 21, avg_loss = 0.5978\n",
            "t = 22, avg_loss = 0.5733\n",
            "t = 23, avg_loss = 0.4875\n",
            "t = 24, avg_loss = 0.5563\n",
            "t = 25, avg_loss = 0.5317\n",
            "Checking accuracy on test set\n",
            "Got 278 / 400 correct (69.50)\n",
            "acc = 0.695000\n",
            "Starting epoch 67 / 80\n",
            "t = 1, avg_loss = 0.5260\n",
            "t = 2, avg_loss = 0.5311\n",
            "t = 3, avg_loss = 0.5163\n",
            "t = 4, avg_loss = 0.5847\n",
            "t = 5, avg_loss = 0.5578\n",
            "t = 6, avg_loss = 0.6018\n",
            "t = 7, avg_loss = 0.5566\n",
            "t = 8, avg_loss = 0.5350\n",
            "t = 9, avg_loss = 0.5758\n",
            "t = 10, avg_loss = 0.5952\n",
            "t = 11, avg_loss = 0.6387\n",
            "t = 12, avg_loss = 0.5338\n",
            "t = 13, avg_loss = 0.4679\n",
            "t = 14, avg_loss = 0.5299\n",
            "t = 15, avg_loss = 0.5434\n",
            "t = 16, avg_loss = 0.5461\n",
            "t = 17, avg_loss = 0.5387\n",
            "t = 18, avg_loss = 0.5146\n",
            "t = 19, avg_loss = 0.5490\n",
            "t = 20, avg_loss = 0.6080\n",
            "t = 21, avg_loss = 0.4664\n",
            "t = 22, avg_loss = 0.4834\n",
            "t = 23, avg_loss = 0.5658\n",
            "t = 24, avg_loss = 0.4704\n",
            "t = 25, avg_loss = 0.4563\n",
            "Checking accuracy on test set\n",
            "Got 293 / 400 correct (73.25)\n",
            "acc = 0.732500\n",
            "Starting epoch 68 / 80\n",
            "t = 1, avg_loss = 0.6156\n",
            "t = 2, avg_loss = 0.5104\n",
            "t = 3, avg_loss = 0.5273\n",
            "t = 4, avg_loss = 0.4191\n",
            "t = 5, avg_loss = 0.6487\n",
            "t = 6, avg_loss = 0.4626\n",
            "t = 7, avg_loss = 0.5244\n",
            "t = 8, avg_loss = 0.7015\n",
            "t = 9, avg_loss = 0.5281\n",
            "t = 10, avg_loss = 0.5105\n",
            "t = 11, avg_loss = 0.5591\n",
            "t = 12, avg_loss = 0.4871\n",
            "t = 13, avg_loss = 0.5452\n",
            "t = 14, avg_loss = 0.6390\n",
            "t = 15, avg_loss = 0.5371\n",
            "t = 16, avg_loss = 0.5839\n",
            "t = 17, avg_loss = 0.4545\n",
            "t = 18, avg_loss = 0.6217\n",
            "t = 19, avg_loss = 0.6581\n",
            "t = 20, avg_loss = 0.4782\n",
            "t = 21, avg_loss = 0.5386\n",
            "t = 22, avg_loss = 0.4906\n",
            "t = 23, avg_loss = 0.5098\n",
            "t = 24, avg_loss = 0.5313\n",
            "t = 25, avg_loss = 0.5445\n",
            "Checking accuracy on test set\n",
            "Got 282 / 400 correct (70.50)\n",
            "acc = 0.705000\n",
            "Starting epoch 69 / 80\n",
            "t = 1, avg_loss = 0.5457\n",
            "t = 2, avg_loss = 0.5455\n",
            "t = 3, avg_loss = 0.5325\n",
            "t = 4, avg_loss = 0.6301\n",
            "t = 5, avg_loss = 0.6127\n",
            "t = 6, avg_loss = 0.6119\n",
            "t = 7, avg_loss = 0.5654\n",
            "t = 8, avg_loss = 0.4763\n",
            "t = 9, avg_loss = 0.6616\n",
            "t = 10, avg_loss = 0.4839\n",
            "t = 11, avg_loss = 0.5402\n",
            "t = 12, avg_loss = 0.5623\n",
            "t = 13, avg_loss = 0.6001\n",
            "t = 14, avg_loss = 0.5281\n",
            "t = 15, avg_loss = 0.6140\n",
            "t = 16, avg_loss = 0.5438\n",
            "t = 17, avg_loss = 0.6696\n",
            "t = 18, avg_loss = 0.5065\n",
            "t = 19, avg_loss = 0.5043\n",
            "t = 20, avg_loss = 0.4969\n",
            "t = 21, avg_loss = 0.6403\n",
            "t = 22, avg_loss = 0.5237\n",
            "t = 23, avg_loss = 0.6501\n",
            "t = 24, avg_loss = 0.6875\n",
            "t = 25, avg_loss = 0.5673\n",
            "Checking accuracy on test set\n",
            "Got 294 / 400 correct (73.50)\n",
            "acc = 0.735000\n",
            "Starting epoch 70 / 80\n",
            "t = 1, avg_loss = 0.4803\n",
            "t = 2, avg_loss = 0.5442\n",
            "t = 3, avg_loss = 0.5326\n",
            "t = 4, avg_loss = 0.5424\n",
            "t = 5, avg_loss = 0.5543\n",
            "t = 6, avg_loss = 0.5594\n",
            "t = 7, avg_loss = 0.6161\n",
            "t = 8, avg_loss = 0.5242\n",
            "t = 9, avg_loss = 0.5521\n",
            "t = 10, avg_loss = 0.6215\n",
            "t = 11, avg_loss = 0.5597\n",
            "t = 12, avg_loss = 0.5248\n",
            "t = 13, avg_loss = 0.5194\n",
            "t = 14, avg_loss = 0.6590\n",
            "t = 15, avg_loss = 0.5289\n",
            "t = 16, avg_loss = 0.5918\n",
            "t = 17, avg_loss = 0.4664\n",
            "t = 18, avg_loss = 0.5777\n",
            "t = 19, avg_loss = 0.5608\n",
            "t = 20, avg_loss = 0.5415\n",
            "t = 21, avg_loss = 0.5323\n",
            "t = 22, avg_loss = 0.4759\n",
            "t = 23, avg_loss = 0.5556\n",
            "t = 24, avg_loss = 0.5965\n",
            "t = 25, avg_loss = 0.5580\n",
            "Checking accuracy on test set\n",
            "Got 302 / 400 correct (75.50)\n",
            "acc = 0.755000\n",
            "Starting epoch 71 / 80\n",
            "t = 1, avg_loss = 0.6057\n",
            "t = 2, avg_loss = 0.4684\n",
            "t = 3, avg_loss = 0.5368\n",
            "t = 4, avg_loss = 0.5369\n",
            "t = 5, avg_loss = 0.5065\n",
            "t = 6, avg_loss = 0.5230\n",
            "t = 7, avg_loss = 0.5365\n",
            "t = 8, avg_loss = 0.5751\n",
            "t = 9, avg_loss = 0.5427\n",
            "t = 10, avg_loss = 0.5395\n",
            "t = 11, avg_loss = 0.4956\n",
            "t = 12, avg_loss = 0.5283\n",
            "t = 13, avg_loss = 0.5173\n",
            "t = 14, avg_loss = 0.5761\n",
            "t = 15, avg_loss = 0.4326\n",
            "t = 16, avg_loss = 0.5151\n",
            "t = 17, avg_loss = 0.5640\n",
            "t = 18, avg_loss = 0.5070\n",
            "t = 19, avg_loss = 0.5468\n",
            "t = 20, avg_loss = 0.5596\n",
            "t = 21, avg_loss = 0.6129\n",
            "t = 22, avg_loss = 0.4878\n",
            "t = 23, avg_loss = 0.5438\n",
            "t = 24, avg_loss = 0.5092\n",
            "t = 25, avg_loss = 0.5486\n",
            "Checking accuracy on test set\n",
            "Got 291 / 400 correct (72.75)\n",
            "acc = 0.727500\n",
            "Starting epoch 72 / 80\n",
            "t = 1, avg_loss = 0.5316\n",
            "t = 2, avg_loss = 0.5803\n",
            "t = 3, avg_loss = 0.5185\n",
            "t = 4, avg_loss = 0.5123\n",
            "t = 5, avg_loss = 0.5662\n",
            "t = 6, avg_loss = 0.5540\n",
            "t = 7, avg_loss = 0.6003\n",
            "t = 8, avg_loss = 0.5567\n",
            "t = 9, avg_loss = 0.6509\n",
            "t = 10, avg_loss = 0.5332\n",
            "t = 11, avg_loss = 0.5896\n",
            "t = 12, avg_loss = 0.5055\n",
            "t = 13, avg_loss = 0.4806\n",
            "t = 14, avg_loss = 0.5090\n",
            "t = 15, avg_loss = 0.6678\n",
            "t = 16, avg_loss = 0.4696\n",
            "t = 17, avg_loss = 0.5659\n",
            "t = 18, avg_loss = 0.5667\n",
            "t = 19, avg_loss = 0.5566\n",
            "t = 20, avg_loss = 0.5011\n",
            "t = 21, avg_loss = 0.4881\n",
            "t = 22, avg_loss = 0.5709\n",
            "t = 23, avg_loss = 0.4789\n",
            "t = 24, avg_loss = 0.5758\n",
            "t = 25, avg_loss = 0.5435\n",
            "Checking accuracy on test set\n",
            "Got 284 / 400 correct (71.00)\n",
            "acc = 0.710000\n",
            "Starting epoch 73 / 80\n",
            "t = 1, avg_loss = 0.5927\n",
            "t = 2, avg_loss = 0.5321\n",
            "t = 3, avg_loss = 0.4917\n",
            "t = 4, avg_loss = 0.5708\n",
            "t = 5, avg_loss = 0.4950\n",
            "t = 6, avg_loss = 0.4928\n",
            "t = 7, avg_loss = 0.5546\n",
            "t = 8, avg_loss = 0.5680\n",
            "t = 9, avg_loss = 0.7534\n",
            "t = 10, avg_loss = 0.5074\n",
            "t = 11, avg_loss = 0.5349\n",
            "t = 12, avg_loss = 0.5080\n",
            "t = 13, avg_loss = 0.4987\n",
            "t = 14, avg_loss = 0.5923\n",
            "t = 15, avg_loss = 0.5534\n",
            "t = 16, avg_loss = 0.5111\n",
            "t = 17, avg_loss = 0.4770\n",
            "t = 18, avg_loss = 0.5101\n",
            "t = 19, avg_loss = 0.4800\n",
            "t = 20, avg_loss = 0.4980\n",
            "t = 21, avg_loss = 0.6174\n",
            "t = 22, avg_loss = 0.6433\n",
            "t = 23, avg_loss = 0.4828\n",
            "t = 24, avg_loss = 0.4881\n",
            "t = 25, avg_loss = 0.5797\n",
            "Checking accuracy on test set\n",
            "Got 278 / 400 correct (69.50)\n",
            "acc = 0.695000\n",
            "Starting epoch 74 / 80\n",
            "t = 1, avg_loss = 0.4589\n",
            "t = 2, avg_loss = 0.5446\n",
            "t = 3, avg_loss = 0.5926\n",
            "t = 4, avg_loss = 0.4727\n",
            "t = 5, avg_loss = 0.6046\n",
            "t = 6, avg_loss = 0.4823\n",
            "t = 7, avg_loss = 0.5493\n",
            "t = 8, avg_loss = 0.5607\n",
            "t = 9, avg_loss = 0.4534\n",
            "t = 10, avg_loss = 0.6563\n",
            "t = 11, avg_loss = 0.5535\n",
            "t = 12, avg_loss = 0.6560\n",
            "t = 13, avg_loss = 0.6212\n",
            "t = 14, avg_loss = 0.5764\n",
            "t = 15, avg_loss = 0.5749\n",
            "t = 16, avg_loss = 0.6265\n",
            "t = 17, avg_loss = 0.5306\n",
            "t = 18, avg_loss = 0.5254\n",
            "t = 19, avg_loss = 0.4787\n",
            "t = 20, avg_loss = 0.4536\n",
            "t = 21, avg_loss = 0.5565\n",
            "t = 22, avg_loss = 0.5121\n",
            "t = 23, avg_loss = 0.6190\n",
            "t = 24, avg_loss = 0.5827\n",
            "t = 25, avg_loss = 0.5210\n",
            "Checking accuracy on test set\n",
            "Got 296 / 400 correct (74.00)\n",
            "acc = 0.740000\n",
            "Starting epoch 75 / 80\n",
            "t = 1, avg_loss = 0.5792\n",
            "t = 2, avg_loss = 0.6380\n",
            "t = 3, avg_loss = 0.4412\n",
            "t = 4, avg_loss = 0.4796\n",
            "t = 5, avg_loss = 0.5015\n",
            "t = 6, avg_loss = 0.5800\n",
            "t = 7, avg_loss = 0.5594\n",
            "t = 8, avg_loss = 0.4682\n",
            "t = 9, avg_loss = 0.5100\n",
            "t = 10, avg_loss = 0.5489\n",
            "t = 11, avg_loss = 0.4609\n",
            "t = 12, avg_loss = 0.4574\n",
            "t = 13, avg_loss = 0.4957\n",
            "t = 14, avg_loss = 0.5301\n",
            "t = 15, avg_loss = 0.6654\n",
            "t = 16, avg_loss = 0.5603\n",
            "t = 17, avg_loss = 0.5067\n",
            "t = 18, avg_loss = 0.5395\n",
            "t = 19, avg_loss = 0.5824\n",
            "t = 20, avg_loss = 0.5476\n",
            "t = 21, avg_loss = 0.5941\n",
            "t = 22, avg_loss = 0.5254\n",
            "t = 23, avg_loss = 0.5507\n",
            "t = 24, avg_loss = 0.4845\n",
            "t = 25, avg_loss = 0.5007\n",
            "Checking accuracy on test set\n",
            "Got 300 / 400 correct (75.00)\n",
            "acc = 0.750000\n",
            "Starting epoch 76 / 80\n",
            "t = 1, avg_loss = 0.4821\n",
            "t = 2, avg_loss = 0.5027\n",
            "t = 3, avg_loss = 0.6623\n",
            "t = 4, avg_loss = 0.4883\n",
            "t = 5, avg_loss = 0.5501\n",
            "t = 6, avg_loss = 0.6028\n",
            "t = 7, avg_loss = 0.4777\n",
            "t = 8, avg_loss = 0.5256\n",
            "t = 9, avg_loss = 0.4632\n",
            "t = 10, avg_loss = 0.4722\n",
            "t = 11, avg_loss = 0.5672\n",
            "t = 12, avg_loss = 0.4909\n",
            "t = 13, avg_loss = 0.6638\n",
            "t = 14, avg_loss = 0.6467\n",
            "t = 15, avg_loss = 0.5112\n",
            "t = 16, avg_loss = 0.6004\n",
            "t = 17, avg_loss = 0.4688\n",
            "t = 18, avg_loss = 0.5141\n",
            "t = 19, avg_loss = 0.5130\n",
            "t = 20, avg_loss = 0.5679\n",
            "t = 21, avg_loss = 0.5402\n",
            "t = 22, avg_loss = 0.5109\n",
            "t = 23, avg_loss = 0.5117\n",
            "t = 24, avg_loss = 0.5206\n",
            "t = 25, avg_loss = 0.5468\n",
            "Checking accuracy on test set\n",
            "Got 274 / 400 correct (68.50)\n",
            "acc = 0.685000\n",
            "Starting epoch 77 / 80\n",
            "t = 1, avg_loss = 0.6032\n",
            "t = 2, avg_loss = 0.6549\n",
            "t = 3, avg_loss = 0.5575\n",
            "t = 4, avg_loss = 0.4864\n",
            "t = 5, avg_loss = 0.5274\n",
            "t = 6, avg_loss = 0.5354\n",
            "t = 7, avg_loss = 0.5599\n",
            "t = 8, avg_loss = 0.5548\n",
            "t = 9, avg_loss = 0.6337\n",
            "t = 10, avg_loss = 0.5921\n",
            "t = 11, avg_loss = 0.5831\n",
            "t = 12, avg_loss = 0.5918\n",
            "t = 13, avg_loss = 0.3837\n",
            "t = 14, avg_loss = 0.5208\n",
            "t = 15, avg_loss = 0.5444\n",
            "t = 16, avg_loss = 0.6398\n",
            "t = 17, avg_loss = 0.5817\n",
            "t = 18, avg_loss = 0.5094\n",
            "t = 19, avg_loss = 0.5184\n",
            "t = 20, avg_loss = 0.4782\n",
            "t = 21, avg_loss = 0.6129\n",
            "t = 22, avg_loss = 0.5133\n",
            "t = 23, avg_loss = 0.5895\n",
            "t = 24, avg_loss = 0.5382\n",
            "t = 25, avg_loss = 0.5394\n",
            "Checking accuracy on test set\n",
            "Got 304 / 400 correct (76.00)\n",
            "acc = 0.760000\n",
            "Starting epoch 78 / 80\n",
            "t = 1, avg_loss = 0.5379\n",
            "t = 2, avg_loss = 0.5159\n",
            "t = 3, avg_loss = 0.5086\n",
            "t = 4, avg_loss = 0.5747\n",
            "t = 5, avg_loss = 0.5437\n",
            "t = 6, avg_loss = 0.5160\n",
            "t = 7, avg_loss = 0.5313\n",
            "t = 8, avg_loss = 0.5122\n",
            "t = 9, avg_loss = 0.4566\n",
            "t = 10, avg_loss = 0.6326\n",
            "t = 11, avg_loss = 0.5356\n",
            "t = 12, avg_loss = 0.5914\n",
            "t = 13, avg_loss = 0.4989\n",
            "t = 14, avg_loss = 0.5379\n",
            "t = 15, avg_loss = 0.5572\n",
            "t = 16, avg_loss = 0.5101\n",
            "t = 17, avg_loss = 0.5747\n",
            "t = 18, avg_loss = 0.5171\n",
            "t = 19, avg_loss = 0.4771\n",
            "t = 20, avg_loss = 0.4588\n",
            "t = 21, avg_loss = 0.5131\n",
            "t = 22, avg_loss = 0.5885\n",
            "t = 23, avg_loss = 0.5016\n",
            "t = 24, avg_loss = 0.6128\n",
            "t = 25, avg_loss = 0.5344\n",
            "Checking accuracy on test set\n",
            "Got 288 / 400 correct (72.00)\n",
            "acc = 0.720000\n",
            "Starting epoch 79 / 80\n",
            "t = 1, avg_loss = 0.6425\n",
            "t = 2, avg_loss = 0.6014\n",
            "t = 3, avg_loss = 0.5159\n",
            "t = 4, avg_loss = 0.5954\n",
            "t = 5, avg_loss = 0.5395\n",
            "t = 6, avg_loss = 0.5886\n",
            "t = 7, avg_loss = 0.4902\n",
            "t = 8, avg_loss = 0.5164\n",
            "t = 9, avg_loss = 0.4885\n",
            "t = 10, avg_loss = 0.5461\n",
            "t = 11, avg_loss = 0.5481\n",
            "t = 12, avg_loss = 0.5131\n",
            "t = 13, avg_loss = 0.4890\n",
            "t = 14, avg_loss = 0.4859\n",
            "t = 15, avg_loss = 0.4419\n",
            "t = 16, avg_loss = 0.5138\n",
            "t = 17, avg_loss = 0.5632\n",
            "t = 18, avg_loss = 0.5748\n",
            "t = 19, avg_loss = 0.6058\n",
            "t = 20, avg_loss = 0.5787\n",
            "t = 21, avg_loss = 0.5447\n",
            "t = 22, avg_loss = 0.5518\n",
            "t = 23, avg_loss = 0.4775\n",
            "t = 24, avg_loss = 0.4528\n",
            "t = 25, avg_loss = 0.8073\n",
            "Checking accuracy on test set\n",
            "Got 280 / 400 correct (70.00)\n",
            "acc = 0.700000\n",
            "Starting epoch 80 / 80\n",
            "t = 1, avg_loss = 0.5939\n",
            "t = 2, avg_loss = 0.5270\n",
            "t = 3, avg_loss = 0.5570\n",
            "t = 4, avg_loss = 0.4992\n",
            "t = 5, avg_loss = 0.5887\n",
            "t = 6, avg_loss = 0.5300\n",
            "t = 7, avg_loss = 0.5388\n",
            "t = 8, avg_loss = 0.5418\n",
            "t = 9, avg_loss = 0.5501\n",
            "t = 10, avg_loss = 0.4920\n",
            "t = 11, avg_loss = 0.5762\n",
            "t = 12, avg_loss = 0.5958\n",
            "t = 13, avg_loss = 0.5895\n",
            "t = 14, avg_loss = 0.4468\n",
            "t = 15, avg_loss = 0.5497\n",
            "t = 16, avg_loss = 0.4894\n",
            "t = 17, avg_loss = 0.5502\n",
            "t = 18, avg_loss = 0.5142\n",
            "t = 19, avg_loss = 0.5258\n",
            "t = 20, avg_loss = 0.5667\n",
            "t = 21, avg_loss = 0.5378\n",
            "t = 22, avg_loss = 0.4578\n",
            "t = 23, avg_loss = 0.5743\n",
            "t = 24, avg_loss = 0.4716\n",
            "t = 25, avg_loss = 0.5455\n",
            "Checking accuracy on test set\n",
            "Got 279 / 400 correct (69.75)\n",
            "acc = 0.697500\n",
            "Checking accuracy on test set\n",
            "Got 278 / 400 correct (69.50)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.695"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hm3h_Kyyp_6h",
        "colab_type": "code",
        "outputId": "020e372a-2b48-4901-cc19-bda4c8f2e26a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "check_accuracy(model_gpu, valid_loader)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking accuracy on test set\n",
            "Got 284 / 400 correct (71.00)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.71"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzuX5gLEeJfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def retry_from_backup():\n",
        "  model_gpu = model_base.type(gpu_dtype)\n",
        "  print(model_gpu)\n",
        "  loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) \n",
        "\n",
        "\n",
        "\n",
        "  checkpoint = torch.load(model_backup_path)\n",
        "  model_gpu.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  epoch = checkpoint['epoch']\n",
        "  loss = checkpoint['loss']\n",
        "  print(\"starting from epoch: \" + str(epoch))\n",
        "  print(\"starting from loss: \" + str(loss))\n",
        "  print(checkpoint['model_state_dict'])\n",
        "  print(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "  train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs, starting_from_epoch=epoch)\n",
        "  check_accuracy(model_gpu, valid_loader)\n",
        "#retry_from_backup()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDn-2g-TLY3k",
        "colab_type": "code",
        "outputId": "8b82cdb1-85e7-4c73-dfc6-c9bd4551c166",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot([print_every*batch_size*(i+1) for i in range((len(avg_loss_list)))],avg_loss_list)\n",
        "print(\"Loss:\")\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGer6hJv7-zR",
        "colab_type": "code",
        "outputId": "7517d730-9bc7-4c6e-bfbd-278cd5d7c39e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plt.plot([i+1 for i in range((len(acc_list)))],acc_list)\n",
        "print(\"Accurancy:\")\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accurancy:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBTReWHxz4Ml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}