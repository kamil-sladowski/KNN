{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of KNN2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP0fl0IHzL/kAJJ+d1joF3d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamilo116/KNN/blob/master/Copy_of_KNN2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7ReM7FU-xs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import sys\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "import timeit\n",
        "\n",
        "np.random.seed(5) \n",
        "torch.manual_seed(5) \n",
        "torch.cuda.manual_seed(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMOHez_kHZD6",
        "colab_type": "code",
        "outputId": "53ac2c7d-240a-4810-e302-98bb50444c31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYIMZ8QyYewD",
        "colab_type": "code",
        "outputId": "8965cbf3-3ce2-4445-a12e-aca6429eb3fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "! git clone https://github.com/wang-chen/kervolution.git \n",
        "#! git clone https://github.com/gan3sh500/kervolution-pytorch.git\n",
        "\n",
        "sys.path.append(\"kervolution/\")\n",
        "#sys.path.append(\"kervolution-pytorch\")\n",
        "from kervolution import Kerv2d\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'kervolution'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects:  16% (1/6)\u001b[K\rremote: Counting objects:  33% (2/6)\u001b[K\rremote: Counting objects:  50% (3/6)\u001b[K\rremote: Counting objects:  66% (4/6)\u001b[K\rremote: Counting objects:  83% (5/6)\u001b[K\rremote: Counting objects: 100% (6/6)\u001b[K\rremote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects:  16% (1/6)\u001b[K\rremote: Compressing objects:  33% (2/6)\u001b[K\rremote: Compressing objects:  50% (3/6)\u001b[K\rremote: Compressing objects:  66% (4/6)\u001b[K\rremote: Compressing objects:  83% (5/6)\u001b[K\rremote: Compressing objects: 100% (6/6)\u001b[K\rremote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "Unpacking objects:   1% (1/53)   \rUnpacking objects:   3% (2/53)   \rUnpacking objects:   5% (3/53)   \rUnpacking objects:   7% (4/53)   \rUnpacking objects:   9% (5/53)   \rUnpacking objects:  11% (6/53)   \rUnpacking objects:  13% (7/53)   \rUnpacking objects:  15% (8/53)   \rUnpacking objects:  16% (9/53)   \rUnpacking objects:  18% (10/53)   \rUnpacking objects:  20% (11/53)   \rUnpacking objects:  22% (12/53)   \rUnpacking objects:  24% (13/53)   \rUnpacking objects:  26% (14/53)   \rUnpacking objects:  28% (15/53)   \rUnpacking objects:  30% (16/53)   \rUnpacking objects:  32% (17/53)   \rUnpacking objects:  33% (18/53)   \rUnpacking objects:  35% (19/53)   \rUnpacking objects:  37% (20/53)   \rUnpacking objects:  39% (21/53)   \rUnpacking objects:  41% (22/53)   \rUnpacking objects:  43% (23/53)   \rUnpacking objects:  45% (24/53)   \rUnpacking objects:  47% (25/53)   \rUnpacking objects:  49% (26/53)   \rUnpacking objects:  50% (27/53)   \rUnpacking objects:  52% (28/53)   \rUnpacking objects:  54% (29/53)   \rUnpacking objects:  56% (30/53)   \rremote: Total 53 (delta 2), reused 0 (delta 0), pack-reused 47\u001b[K\n",
            "Unpacking objects:  58% (31/53)   \rUnpacking objects:  60% (32/53)   \rUnpacking objects:  62% (33/53)   \rUnpacking objects:  64% (34/53)   \rUnpacking objects:  66% (35/53)   \rUnpacking objects:  67% (36/53)   \rUnpacking objects:  69% (37/53)   \rUnpacking objects:  71% (38/53)   \rUnpacking objects:  73% (39/53)   \rUnpacking objects:  75% (40/53)   \rUnpacking objects:  77% (41/53)   \rUnpacking objects:  79% (42/53)   \rUnpacking objects:  81% (43/53)   \rUnpacking objects:  83% (44/53)   \rUnpacking objects:  84% (45/53)   \rUnpacking objects:  86% (46/53)   \rUnpacking objects:  88% (47/53)   \rUnpacking objects:  90% (48/53)   \rUnpacking objects:  92% (49/53)   \rUnpacking objects:  94% (50/53)   \rUnpacking objects:  96% (51/53)   \rUnpacking objects:  98% (52/53)   \rUnpacking objects: 100% (53/53)   \rUnpacking objects: 100% (53/53), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b8P1NdXfVdX",
        "colab_type": "code",
        "outputId": "229dc145-df6d-44e4-a4e3-93985c7c9c1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "MALIGNANT_DATASET = '/content/drive/My Drive/Colab_data/malignant/malignant/'\n",
        "BENIGN_DATASET = '/content/drive/My Drive/Colab_data/benign/benign/'\n",
        "DATA_FOLDER = '/content/drive/My Drive/Colab_data/'\n",
        "benign_file_list = os.listdir(BENIGN_DATASET)\n",
        "malignant_file_list = os.listdir(MALIGNANT_DATASET)\n",
        "\n",
        "print(f\"Number of benign {len(benign_file_list)} images\")\n",
        "print(f\"Number of benign {len(malignant_file_list)} images\")\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    #transforms.CenterCrop(),\n",
        "    transforms.Resize((64, 64)), #128\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1608\n",
            "1129\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGDQfal74BLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "benign_dict = {filename.split('.')[0]: 0 for filename in benign_file_list}\n",
        "malignant_dict = {filename.split('.')[0]: 1 for filename in malignant_file_list}\n",
        "img_class_dict = {**benign_dict , **malignant_dict}\n",
        "labeled_data = pd.Series(img_class_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvAAOqmVfVll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IsicDataset(Dataset):\n",
        "    def __init__(self, data_folder, labeled_data, \n",
        "                 transform=transforms.Compose([transforms.ToTensor()])):\n",
        "        self.labeled_data = labeled_data\n",
        "        self.transform = transform\n",
        "        self.data_folder = data_folder\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labeled_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        label = self.labeled_data[index]\n",
        "        if label == 0:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"benign\", \"benign\", index + \".jpeg\"))\n",
        "        else:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"malignant\", \"malignant\", index + \".jpeg\"))\n",
        "        image = self.transform(image)\n",
        "        #imshow(image)\n",
        "        return image, label\n",
        "\n",
        "    @property\n",
        "    def labels(self):\n",
        "      return self.labeled_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSuYqjLAYrWA",
        "colab_type": "code",
        "outputId": "dfe18ad6-f504-4fb8-b7f5-f2b0f9f71a59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        " \n",
        "dataset = IsicDataset(DATA_FOLDER, labeled_data, transform=data_transforms)\n",
        "#test_dataset = IsicDataset(DATA_FOLDER, labeled_data, transform=data_transforms)\n",
        "#test_set = ... todo\n",
        "print(dataset.labels)\n",
        "\n",
        "X_train, X_test = train_test_split(dataset.labels, test_size=0.1)\n",
        "print(\"number of training data: \",len(X_train))\n",
        "print(\"number of testing  data: \",len(X_test))\n",
        "\n",
        "train_sampler = SubsetRandomSampler(list(X_train.index))\n",
        "valid_sampler = SubsetRandomSampler(list(X_test.index))\n",
        "batch_size = 100\n",
        "num_workers = 0\n",
        "#print(train_sampler.indices)\n",
        "#print(valid_sampler.indices)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
        "#test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, num_workers=num_workers)\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ISIC_0000884    0\n",
            "ISIC_0000896    0\n",
            "ISIC_0000889    0\n",
            "ISIC_0000874    0\n",
            "ISIC_0000826    0\n",
            "               ..\n",
            "ISIC_0010131    1\n",
            "ISIC_0010011    1\n",
            "ISIC_0010050    1\n",
            "ISIC_0001151    1\n",
            "ISIC_0000520    1\n",
            "Length: 2737, dtype: int64\n",
            "number of training data:  2463\n",
            "number of testing  data:  274\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e8nFBR6Yug5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "def train(model, train_loader ,loss_fn, optimizer, num_epochs = 1):\n",
        "    total_loss =0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
        "        model.train()\n",
        "\n",
        "        for t, (x, y) in enumerate(train_loader):\n",
        "            x_var = Variable(x.type(gpu_dtype))\n",
        "            y_var = Variable(y.type(gpu_dtype).long())\n",
        "            scores = model(x_var)\n",
        "            loss = loss_fn(scores, y_var)\n",
        "            total_loss += loss.data\n",
        "            \n",
        "            if (t + 1) % print_every == 0:\n",
        "                avg_loss = total_loss/print_every\n",
        "                print('t = %d, avg_loss = %.4f' % (t + 1, avg_loss) )\n",
        "                avg_loss_list.append(avg_loss)\n",
        "                total_loss = 0\n",
        "                \n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        acc = check_accuracy(fixed_model_gpu, valid_loader)\n",
        "        print('acc = %f' %(acc))\n",
        "            \n",
        "def check_accuracy(model, loader):\n",
        "    print('Checking accuracy on test set')   \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval() \n",
        "    for x, y in loader:\n",
        "        x_var = Variable(x.type(gpu_dtype))\n",
        "\n",
        "        scores = model(x_var)\n",
        "        _, preds = scores.data.cpu().max(1)\n",
        "        num_correct += (preds == y).sum()\n",
        "        num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    acc_list.append(acc)\n",
        "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "    return acc\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggvpMu36Yw2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.size()\n",
        "        return x.view(N, -1)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgmexhBRZAK6",
        "colab_type": "code",
        "outputId": "2f2b9085-c3bf-4652-e29a-5958f8e4a9c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print_every = 1\n",
        "gpu_dtype = torch.cuda.FloatTensor\n",
        "\n",
        "out_1 = 64\n",
        "out_2 = 48\n",
        "out_3 = 32\n",
        "out_4 = 24\n",
        "out_5 = 16\n",
        "\n",
        "k_size_1 = 3\n",
        "padding_1 = 1\n",
        "in_channels = 3\n",
        "\n",
        "num_epochs = 5\n",
        "\n",
        "'''\n",
        "Kerv2d\n",
        "kervolution with following options:\n",
        "kernel_type: [linear, polynomial, gaussian, etc.]\n",
        "default is convolution:\n",
        "          kernel_type --> linear,\n",
        "balance, power, gamma is valid only when the kernel_type is specified\n",
        "if learnable_kernel = True,  they just be the initial value of learable parameters\n",
        "if learnable_kernel = False, they are the value of kernel_type's parameter\n",
        "the parameter [power] cannot be learned due to integer limitation\n",
        "balance: 0, 1\n",
        "power: 3, 4, 5\n",
        "gamma:\n",
        "'''\n",
        "fixed_model_base = nn.Sequential( \n",
        "                nn.Kerv2d(in_channels, out_1, padding= padding_1, kernel_size=k_size_1, \n",
        "                          stride=1, kernel_type='polynomial', learnable_kernel=True,\n",
        "                          kernel_regularizer=True, balance=1, power=4, gamma=1), \n",
        "                nn.BatchNorm2d(out_1),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                \n",
        "                \n",
        "    \n",
        "                nn.Conv2d(out_1 , out_2, padding= padding_1, kernel_size=k_size_1, stride=1), \n",
        "                nn.BatchNorm2d(out_2),\n",
        "                nn.Conv2d(out_2 , out_3, padding= padding_1, kernel_size=k_size_1, stride=1), \n",
        "                nn.BatchNorm2d(out_3),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_3 , out_4, padding= padding_1, kernel_size=k_size_1, stride=1), \n",
        "                nn.BatchNorm2d(out_4),\n",
        "                nn.Conv2d(out_4 , out_5, padding= padding_1, kernel_size=k_size_1, stride=1), \n",
        "                nn.BatchNorm2d(out_5),\n",
        "                nn.Dropout(0.5),\n",
        "                Flatten(),\n",
        "                nn.Linear(4096,64),\n",
        "                nn.Linear(64,10),\n",
        "                nn.Linear(10,2)\n",
        "            )\n",
        "fixed_model_gpu = fixed_model_base.type(gpu_dtype)\n",
        "print(fixed_model_gpu)\n",
        "loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(fixed_model_gpu.parameters(), lr = 0.0009) #0.00267\n",
        "\n",
        "train(fixed_model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs)\n",
        "check_accuracy(fixed_model_gpu, valid_loader)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Kerv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (3): Conv2d(64, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): Conv2d(48, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (7): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (8): Conv2d(32, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (9): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (10): Conv2d(24, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (12): Dropout(p=0.5, inplace=False)\n",
            "  (13): Flatten()\n",
            "  (14): Linear(in_features=4096, out_features=64, bias=True)\n",
            "  (15): Linear(in_features=64, out_features=10, bias=True)\n",
            "  (16): Linear(in_features=10, out_features=2, bias=True)\n",
            ")\n",
            "Starting epoch 1 / 5\n",
            "t = 1, avg_loss = 0.7993\n",
            "t = 2, avg_loss = 0.6562\n",
            "t = 3, avg_loss = 0.6469\n",
            "t = 4, avg_loss = 0.7037\n",
            "t = 5, avg_loss = 0.5335\n",
            "t = 6, avg_loss = 0.6455\n",
            "t = 7, avg_loss = 0.5183\n",
            "t = 8, avg_loss = 0.5506\n",
            "t = 9, avg_loss = 0.6668\n",
            "t = 10, avg_loss = 0.5585\n",
            "t = 11, avg_loss = 0.6599\n",
            "t = 12, avg_loss = 0.5966\n",
            "t = 13, avg_loss = 0.6014\n",
            "t = 14, avg_loss = 0.5557\n",
            "t = 15, avg_loss = 0.5869\n",
            "t = 16, avg_loss = 0.5162\n",
            "t = 17, avg_loss = 0.5677\n",
            "t = 18, avg_loss = 0.5108\n",
            "t = 19, avg_loss = 0.5599\n",
            "t = 20, avg_loss = 0.5495\n",
            "t = 21, avg_loss = 0.5554\n",
            "t = 22, avg_loss = 0.5477\n",
            "t = 23, avg_loss = 0.4945\n",
            "t = 24, avg_loss = 0.5365\n",
            "t = 25, avg_loss = 0.5201\n",
            "Checking accuracy on test set\n",
            "Got 199 / 274 correct (72.63)\n",
            "acc = 0.726277\n",
            "Starting epoch 2 / 5\n",
            "t = 1, avg_loss = 0.5084\n",
            "t = 2, avg_loss = 0.5383\n",
            "t = 3, avg_loss = 0.4815\n",
            "t = 4, avg_loss = 0.6902\n",
            "t = 5, avg_loss = 0.6029\n",
            "t = 6, avg_loss = 0.5460\n",
            "t = 7, avg_loss = 0.4775\n",
            "t = 8, avg_loss = 0.5616\n",
            "t = 9, avg_loss = 0.4927\n",
            "t = 10, avg_loss = 0.5468\n",
            "t = 11, avg_loss = 0.4947\n",
            "t = 12, avg_loss = 0.5684\n",
            "t = 13, avg_loss = 0.4308\n",
            "t = 14, avg_loss = 0.4995\n",
            "t = 15, avg_loss = 0.5109\n",
            "t = 16, avg_loss = 0.5694\n",
            "t = 17, avg_loss = 0.5002\n",
            "t = 18, avg_loss = 0.5266\n",
            "t = 19, avg_loss = 0.6271\n",
            "t = 20, avg_loss = 0.5917\n",
            "t = 21, avg_loss = 0.5197\n",
            "t = 22, avg_loss = 0.3887\n",
            "t = 23, avg_loss = 0.4543\n",
            "t = 24, avg_loss = 0.5058\n",
            "t = 25, avg_loss = 0.6261\n",
            "Checking accuracy on test set\n",
            "Got 202 / 274 correct (73.72)\n",
            "acc = 0.737226\n",
            "Starting epoch 3 / 5\n",
            "t = 1, avg_loss = 0.5137\n",
            "t = 2, avg_loss = 0.5185\n",
            "t = 3, avg_loss = 0.4771\n",
            "t = 4, avg_loss = 0.4344\n",
            "t = 5, avg_loss = 0.4910\n",
            "t = 6, avg_loss = 0.4784\n",
            "t = 7, avg_loss = 0.5105\n",
            "t = 8, avg_loss = 0.4332\n",
            "t = 9, avg_loss = 0.5287\n",
            "t = 10, avg_loss = 0.4177\n",
            "t = 11, avg_loss = 0.4444\n",
            "t = 12, avg_loss = 0.4868\n",
            "t = 13, avg_loss = 0.5416\n",
            "t = 14, avg_loss = 0.4669\n",
            "t = 15, avg_loss = 0.4364\n",
            "t = 16, avg_loss = 0.5387\n",
            "t = 17, avg_loss = 0.4260\n",
            "t = 18, avg_loss = 0.4786\n",
            "t = 19, avg_loss = 0.4284\n",
            "t = 20, avg_loss = 0.3674\n",
            "t = 21, avg_loss = 0.4157\n",
            "t = 22, avg_loss = 0.4715\n",
            "t = 23, avg_loss = 0.3972\n",
            "t = 24, avg_loss = 0.6885\n",
            "t = 25, avg_loss = 0.5441\n",
            "Checking accuracy on test set\n",
            "Got 210 / 274 correct (76.64)\n",
            "acc = 0.766423\n",
            "Starting epoch 4 / 5\n",
            "t = 1, avg_loss = 0.5876\n",
            "t = 2, avg_loss = 0.4599\n",
            "t = 3, avg_loss = 0.4501\n",
            "t = 4, avg_loss = 0.4455\n",
            "t = 5, avg_loss = 0.4699\n",
            "t = 6, avg_loss = 0.5029\n",
            "t = 7, avg_loss = 0.4667\n",
            "t = 8, avg_loss = 0.4895\n",
            "t = 9, avg_loss = 0.4555\n",
            "t = 10, avg_loss = 0.4954\n",
            "t = 11, avg_loss = 0.4612\n",
            "t = 12, avg_loss = 0.4232\n",
            "t = 13, avg_loss = 0.5095\n",
            "t = 14, avg_loss = 0.4105\n",
            "t = 15, avg_loss = 0.3890\n",
            "t = 16, avg_loss = 0.4292\n",
            "t = 17, avg_loss = 0.3702\n",
            "t = 18, avg_loss = 0.5987\n",
            "t = 19, avg_loss = 0.6111\n",
            "t = 20, avg_loss = 0.4240\n",
            "t = 21, avg_loss = 0.5094\n",
            "t = 22, avg_loss = 0.4124\n",
            "t = 23, avg_loss = 0.3920\n",
            "t = 24, avg_loss = 0.4651\n",
            "t = 25, avg_loss = 0.6179\n",
            "Checking accuracy on test set\n",
            "Got 217 / 274 correct (79.20)\n",
            "acc = 0.791971\n",
            "Starting epoch 5 / 5\n",
            "t = 1, avg_loss = 0.5053\n",
            "t = 2, avg_loss = 0.5287\n",
            "t = 3, avg_loss = 0.4144\n",
            "t = 4, avg_loss = 0.4512\n",
            "t = 5, avg_loss = 0.3963\n",
            "t = 6, avg_loss = 0.5172\n",
            "t = 7, avg_loss = 0.5804\n",
            "t = 8, avg_loss = 0.4326\n",
            "t = 9, avg_loss = 0.4574\n",
            "t = 10, avg_loss = 0.4832\n",
            "t = 11, avg_loss = 0.4455\n",
            "t = 12, avg_loss = 0.3735\n",
            "t = 13, avg_loss = 0.5051\n",
            "t = 14, avg_loss = 0.4939\n",
            "t = 15, avg_loss = 0.4403\n",
            "t = 16, avg_loss = 0.4702\n",
            "t = 17, avg_loss = 0.5003\n",
            "t = 18, avg_loss = 0.5000\n",
            "t = 19, avg_loss = 0.4827\n",
            "t = 20, avg_loss = 0.4349\n",
            "t = 21, avg_loss = 0.3773\n",
            "t = 22, avg_loss = 0.3609\n",
            "t = 23, avg_loss = 0.3744\n",
            "t = 24, avg_loss = 0.4226\n",
            "t = 25, avg_loss = 0.7000\n",
            "Checking accuracy on test set\n",
            "Got 206 / 274 correct (75.18)\n",
            "acc = 0.751825\n",
            "Checking accuracy on test set\n",
            "Got 205 / 274 correct (74.82)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7481751824817519"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDn-2g-TLY3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}