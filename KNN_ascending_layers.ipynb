{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN_ascending_layers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamilo116/KNN/blob/master/KNN_ascending_layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7ReM7FU-xs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import sys\n",
        "from random import shuffle\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms as transforms\n",
        "import timeit\n",
        "\n",
        "np.random.seed(4) \n",
        "torch.manual_seed(4) \n",
        "torch.cuda.manual_seed(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYIMZ8QyYewD",
        "colab_type": "code",
        "outputId": "1e360a44-fcc6-4203-83f5-55e50e277259",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "! git clone https://github.com/wang-chen/kervolution.git \n",
        "\n",
        "sys.path.append(\"kervolution/\")\n",
        "from kervolution import Kerv2d\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'kervolution'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects:  16% (1/6)\u001b[K\rremote: Counting objects:  33% (2/6)\u001b[K\rremote: Counting objects:  50% (3/6)\u001b[K\rremote: Counting objects:  66% (4/6)\u001b[K\rremote: Counting objects:  83% (5/6)\u001b[K\rremote: Counting objects: 100% (6/6)\u001b[K\rremote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects:  16% (1/6)\u001b[K\rremote: Compressing objects:  33% (2/6)\u001b[K\rremote: Compressing objects:  50% (3/6)\u001b[K\rremote: Compressing objects:  66% (4/6)\u001b[K\rremote: Compressing objects:  83% (5/6)\u001b[K\rremote: Compressing objects: 100% (6/6)\u001b[K\rremote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 53 (delta 2), reused 0 (delta 0), pack-reused 47\u001b[K\n",
            "Unpacking objects:   1% (1/53)   \rUnpacking objects:   3% (2/53)   \rUnpacking objects:   5% (3/53)   \rUnpacking objects:   7% (4/53)   \rUnpacking objects:   9% (5/53)   \rUnpacking objects:  11% (6/53)   \rUnpacking objects:  13% (7/53)   \rUnpacking objects:  15% (8/53)   \rUnpacking objects:  16% (9/53)   \rUnpacking objects:  18% (10/53)   \rUnpacking objects:  20% (11/53)   \rUnpacking objects:  22% (12/53)   \rUnpacking objects:  24% (13/53)   \rUnpacking objects:  26% (14/53)   \rUnpacking objects:  28% (15/53)   \rUnpacking objects:  30% (16/53)   \rUnpacking objects:  32% (17/53)   \rUnpacking objects:  33% (18/53)   \rUnpacking objects:  35% (19/53)   \rUnpacking objects:  37% (20/53)   \rUnpacking objects:  39% (21/53)   \rUnpacking objects:  41% (22/53)   \rUnpacking objects:  43% (23/53)   \rUnpacking objects:  45% (24/53)   \rUnpacking objects:  47% (25/53)   \rUnpacking objects:  49% (26/53)   \rUnpacking objects:  50% (27/53)   \rUnpacking objects:  52% (28/53)   \rUnpacking objects:  54% (29/53)   \rUnpacking objects:  56% (30/53)   \rUnpacking objects:  58% (31/53)   \rUnpacking objects:  60% (32/53)   \rUnpacking objects:  62% (33/53)   \rUnpacking objects:  64% (34/53)   \rUnpacking objects:  66% (35/53)   \rUnpacking objects:  67% (36/53)   \rUnpacking objects:  69% (37/53)   \rUnpacking objects:  71% (38/53)   \rUnpacking objects:  73% (39/53)   \rUnpacking objects:  75% (40/53)   \rUnpacking objects:  77% (41/53)   \rUnpacking objects:  79% (42/53)   \rUnpacking objects:  81% (43/53)   \rUnpacking objects:  83% (44/53)   \rUnpacking objects:  84% (45/53)   \rUnpacking objects:  86% (46/53)   \rUnpacking objects:  88% (47/53)   \rUnpacking objects:  90% (48/53)   \rUnpacking objects:  92% (49/53)   \rUnpacking objects:  94% (50/53)   \rUnpacking objects:  96% (51/53)   \rUnpacking objects:  98% (52/53)   \rUnpacking objects: 100% (53/53)   \rUnpacking objects: 100% (53/53), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvbKg4VJXKY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LIMIT_IMAGES_NUM = 1000\n",
        "train_test_split_size = 0.2\n",
        "image_resize = (100, 100)\n",
        "batch_size = 64\n",
        "num_workers = 0\n",
        "\n",
        "out_1 = 16\n",
        "out_2 = 32\n",
        "out_3 = 64\n",
        "out_4 = 128\n",
        "\n",
        "\n",
        "k_size_1 = 3\n",
        "padding_1 = 1\n",
        "in_channels = 3\n",
        "\n",
        "kernel_size = 3\n",
        "num_epochs = 100\n",
        "\n",
        "learning_rate = 0.0001\n",
        "weight_decay = 0.1\n",
        "\n",
        "MALIGNANT_DATASET = '/content/drive/My Drive/Colab_data/malignant/malignant/'\n",
        "BENIGN_DATASET = '/content/drive/My Drive/Colab_data/benign/benign/'\n",
        "DATA_FOLDER = '/content/drive/My Drive/Colab_data/'\n",
        "model_backup_path = os.path.join(DATA_FOLDER, 'backup_model2') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMOHez_kHZD6",
        "colab_type": "code",
        "outputId": "83271d00-f35c-4e52-b36b-aaecc438c763",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b8P1NdXfVdX",
        "colab_type": "code",
        "outputId": "552d27ab-4941-420c-c0fc-cfbf004fa645",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "benign_file_list = sorted(os.listdir(BENIGN_DATASET))\n",
        "malignant_file_list = sorted(os.listdir(MALIGNANT_DATASET))\n",
        "shuffle(benign_file_list)\n",
        "shuffle(malignant_file_list)\n",
        "benign_file_list = benign_file_list[:LIMIT_IMAGES_NUM]\n",
        "malignant_file_list = malignant_file_list[:LIMIT_IMAGES_NUM]\n",
        "\n",
        "print(f\"Number of benign {len(benign_file_list)} images\")\n",
        "print(f\"Number of malignant {len(malignant_file_list)} images\")\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize(image_resize),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of benign 1000 images\n",
            "Number of malignant 1000 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5O3me6ev_iCY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifhyvJA9_wsB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQ5XPRReIO4L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBd9A4bOo9Kb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Emwu3c60Idhr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVm8a09eIsLM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGDQfal74BLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "benign_dict = {filename: 0 for filename in benign_file_list}\n",
        "malignant_dict = {filename: 1 for filename in malignant_file_list}\n",
        "img_class_dict = {**benign_dict , **malignant_dict}\n",
        "labeled_data = pd.Series(img_class_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvAAOqmVfVll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IsicDataset(Dataset):\n",
        "    def __init__(self, data_folder, labeled_data, \n",
        "                 transform=transforms.Compose([transforms.ToTensor()])):\n",
        "        self.labeled_data = labeled_data\n",
        "        self.transform = transform\n",
        "        self.data_folder = data_folder\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labeled_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        label = self.labeled_data[index]\n",
        "        if label == 0:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"benign\", \"benign\", index ))\n",
        "        else:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"malignant\", \"malignant\", index ))\n",
        "        image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "    @property\n",
        "    def labels(self):\n",
        "      return self.labeled_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSuYqjLAYrWA",
        "colab_type": "code",
        "outputId": "26681e61-7233-44e4-8a30-3aad9f7f4104",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "dataset = IsicDataset(DATA_FOLDER, labeled_data, transform=data_transforms)\n",
        "print(dataset.labels)\n",
        "\n",
        "X_train, X_test = train_test_split(dataset.labels, test_size=train_test_split_size)\n",
        "print(\"number of training data: \",len(X_train))\n",
        "print(\"number of testing  data: \",len(X_test))\n",
        "\n",
        "train_sampler = SubsetRandomSampler(list(X_train.index))\n",
        "valid_sampler = SubsetRandomSampler(list(X_test.index))\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ISIC_0000679.jpeg    0\n",
            "ISIC_0000481.jpeg    0\n",
            "ISIC_0000183.jpeg    0\n",
            "ISIC_0000890.jpeg    0\n",
            "ISIC_0000822.jpeg    0\n",
            "                    ..\n",
            "ISIC_0011933.jpeg    1\n",
            "ISIC_0011519.jpeg    1\n",
            "ISIC_0024900.jpg     1\n",
            "ISIC_0014129.jpeg    1\n",
            "ISIC_0011429.jpeg    1\n",
            "Length: 2000, dtype: int64\n",
            "number of training data:  1600\n",
            "number of testing  data:  400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e8nFBR6Yug5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "def train(model, train_loader ,loss_fn, optimizer, num_epochs=1, starting_from_epoch=1):\n",
        "    total_loss =0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
        "        model.train()\n",
        "\n",
        "        for t, (x, y) in enumerate(train_loader):\n",
        "            x_var = Variable(x.type(gpu_dtype))\n",
        "            y_var = Variable(y.type(gpu_dtype).long())\n",
        "            scores = model(x_var)\n",
        "            loss = loss_fn(scores, y_var)\n",
        "            total_loss += loss.data\n",
        "            \n",
        "            if (t + 1) % print_every == 0:\n",
        "                avg_loss = total_loss/print_every\n",
        "                print('t = %d, avg_loss = %.4f' % (t + 1, avg_loss) )\n",
        "                avg_loss_list.append(avg_loss)\n",
        "                total_loss = 0\n",
        "                \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        acc = check_accuracy(model_gpu, valid_loader)\n",
        "        print('acc = %f' %(acc))\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model_gpu.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            'acc_list': acc_list,\n",
        "            }, model_backup_path)\n",
        "            \n",
        "def check_accuracy(model, loader):\n",
        "    print('Checking accuracy on test set')   \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval() \n",
        "    for x, y in loader:\n",
        "        x_var = Variable(x.type(gpu_dtype))\n",
        "\n",
        "        scores = model(x_var)\n",
        "        _, preds = scores.data.cpu().max(1)\n",
        "        num_correct += (preds == y).sum()\n",
        "        num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    acc_list.append(acc)\n",
        "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "    return acc\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.size()\n",
        "        return x.view(N, -1)      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-gYHw0Jlbwt",
        "colab_type": "code",
        "outputId": "7905fe8b-5b83-476a-fd55-6b7837d200a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "print_every = 2\n",
        "gpu_dtype = torch.cuda.FloatTensor\n",
        "\n",
        "\n",
        "'''\n",
        "Kerv2d\n",
        "kervolution with following options:\n",
        "kernel_type: [linear, polynomial, gaussian, etc.]\n",
        "default is convolution:\n",
        "          kernel_type --> linear,\n",
        "balance, power, gamma is valid only when the kernel_type is specified\n",
        "if learnable_kernel = True,  they just be the initial value of learable parameters\n",
        "if learnable_kernel = False, they are the value of kernel_type's parameter\n",
        "the parameter [power] cannot be learned due to integer limitation\n",
        "dilation (int or tuple, optional): Spacing between kernel\n",
        "elements. Default: 1\n",
        "groups (int, optional): Number of blocked connections from input\n",
        "channels to output channels. Default: 1\n",
        "bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n",
        "kernel_type (str), Default: 'linear'\n",
        "learnable_kernel (bool): Learnable kernel parameters.  Default: False \n",
        "balance: 0, 1\n",
        "power: 3, 4, 5\n",
        "gamma:\n",
        "'''\n",
        "\n",
        "\n",
        "model_base = nn.Sequential( \n",
        "                #nn.Conv2d(in_channels , out_1, padding= padding_1, kernel_size=k_size_1, stride=1),\n",
        "                nn.Kerv2d(in_channels , out_1, padding=padding_1, dilation=1, groups=1, bias=True, \n",
        "                          kernel_type='polynomial', kernel_size=k_size_1, learnable_kernel=True,\n",
        "                          kernel_regularizer=True, stride=1, balance=1, power=3, gamma=1\n",
        "                          ), \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_1),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_1 , out_2, padding= padding_1, kernel_size=k_size_1, stride=1), \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_2),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_2 , out_3, padding= padding_1, kernel_size=k_size_1, stride=1),  \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_3),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_3 , out_4, padding= padding_1, kernel_size=k_size_1, stride=1),  \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_4),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Dropout(0.5),\n",
        "                Flatten(),\n",
        "                nn.Linear(4608,64),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Linear(64,2)\n",
        "            )\n",
        "model_gpu = model_base.type(gpu_dtype)\n",
        "print(model_gpu)\n",
        "loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Kerv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (4): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (5): ReLU(inplace=True)\n",
            "  (6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (8): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (9): ReLU(inplace=True)\n",
            "  (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (12): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (13): ReLU(inplace=True)\n",
            "  (14): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (16): Dropout(p=0.5, inplace=False)\n",
            "  (17): Flatten()\n",
            "  (18): Linear(in_features=4608, out_features=64, bias=True)\n",
            "  (19): ReLU(inplace=True)\n",
            "  (20): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgmexhBRZAK6",
        "colab_type": "code",
        "outputId": "18d23cf0-ea61-49e0-a02d-a60ac7ec1efe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs)\n",
        "check_accuracy(model_gpu, valid_loader)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 1 / 100\n",
            "t = 2, avg_loss = 0.7237\n",
            "t = 4, avg_loss = 0.6841\n",
            "t = 6, avg_loss = 0.5898\n",
            "t = 8, avg_loss = 0.5556\n",
            "t = 10, avg_loss = 0.6073\n",
            "t = 12, avg_loss = 0.5208\n",
            "t = 14, avg_loss = 0.4990\n",
            "t = 16, avg_loss = 0.5077\n",
            "t = 18, avg_loss = 0.5264\n",
            "t = 20, avg_loss = 0.4820\n",
            "t = 22, avg_loss = 0.4315\n",
            "t = 24, avg_loss = 0.5124\n",
            "Checking accuracy on test set\n",
            "Got 234 / 400 correct (58.50)\n",
            "acc = 0.585000\n",
            "Starting epoch 2 / 100\n",
            "t = 2, avg_loss = 0.5784\n",
            "t = 4, avg_loss = 0.5387\n",
            "t = 6, avg_loss = 0.5224\n",
            "t = 8, avg_loss = 0.5528\n",
            "t = 10, avg_loss = 0.4736\n",
            "t = 12, avg_loss = 0.4111\n",
            "t = 14, avg_loss = 0.3922\n",
            "t = 16, avg_loss = 0.4788\n",
            "t = 18, avg_loss = 0.3918\n",
            "t = 20, avg_loss = 0.4408\n",
            "t = 22, avg_loss = 0.3780\n",
            "t = 24, avg_loss = 0.3308\n",
            "Checking accuracy on test set\n",
            "Got 334 / 400 correct (83.50)\n",
            "acc = 0.835000\n",
            "Starting epoch 3 / 100\n",
            "t = 2, avg_loss = 0.5567\n",
            "t = 4, avg_loss = 0.4190\n",
            "t = 6, avg_loss = 0.3932\n",
            "t = 8, avg_loss = 0.4089\n",
            "t = 10, avg_loss = 0.3874\n",
            "t = 12, avg_loss = 0.3340\n",
            "t = 14, avg_loss = 0.3604\n",
            "t = 16, avg_loss = 0.3808\n",
            "t = 18, avg_loss = 0.4062\n",
            "t = 20, avg_loss = 0.3595\n",
            "t = 22, avg_loss = 0.3887\n",
            "t = 24, avg_loss = 0.3596\n",
            "Checking accuracy on test set\n",
            "Got 346 / 400 correct (86.50)\n",
            "acc = 0.865000\n",
            "Starting epoch 4 / 100\n",
            "t = 2, avg_loss = 0.6159\n",
            "t = 4, avg_loss = 0.3841\n",
            "t = 6, avg_loss = 0.3945\n",
            "t = 8, avg_loss = 0.3435\n",
            "t = 10, avg_loss = 0.4098\n",
            "t = 12, avg_loss = 0.2882\n",
            "t = 14, avg_loss = 0.3377\n",
            "t = 16, avg_loss = 0.2804\n",
            "t = 18, avg_loss = 0.4497\n",
            "t = 20, avg_loss = 0.3973\n",
            "t = 22, avg_loss = 0.3172\n",
            "t = 24, avg_loss = 0.3976\n",
            "Checking accuracy on test set\n",
            "Got 342 / 400 correct (85.50)\n",
            "acc = 0.855000\n",
            "Starting epoch 5 / 100\n",
            "t = 2, avg_loss = 0.5312\n",
            "t = 4, avg_loss = 0.4765\n",
            "t = 6, avg_loss = 0.3543\n",
            "t = 8, avg_loss = 0.3768\n",
            "t = 10, avg_loss = 0.3122\n",
            "t = 12, avg_loss = 0.3207\n",
            "t = 14, avg_loss = 0.3263\n",
            "t = 16, avg_loss = 0.2861\n",
            "t = 18, avg_loss = 0.3207\n",
            "t = 20, avg_loss = 0.3229\n",
            "t = 22, avg_loss = 0.2693\n",
            "t = 24, avg_loss = 0.4234\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 6 / 100\n",
            "t = 2, avg_loss = 0.4893\n",
            "t = 4, avg_loss = 0.3334\n",
            "t = 6, avg_loss = 0.2950\n",
            "t = 8, avg_loss = 0.3594\n",
            "t = 10, avg_loss = 0.3185\n",
            "t = 12, avg_loss = 0.3305\n",
            "t = 14, avg_loss = 0.3422\n",
            "t = 16, avg_loss = 0.3748\n",
            "t = 18, avg_loss = 0.2543\n",
            "t = 20, avg_loss = 0.3073\n",
            "t = 22, avg_loss = 0.3727\n",
            "t = 24, avg_loss = 0.3618\n",
            "Checking accuracy on test set\n",
            "Got 343 / 400 correct (85.75)\n",
            "acc = 0.857500\n",
            "Starting epoch 7 / 100\n",
            "t = 2, avg_loss = 0.4497\n",
            "t = 4, avg_loss = 0.3004\n",
            "t = 6, avg_loss = 0.3305\n",
            "t = 8, avg_loss = 0.3134\n",
            "t = 10, avg_loss = 0.2636\n",
            "t = 12, avg_loss = 0.3515\n",
            "t = 14, avg_loss = 0.2823\n",
            "t = 16, avg_loss = 0.3146\n",
            "t = 18, avg_loss = 0.2964\n",
            "t = 20, avg_loss = 0.3771\n",
            "t = 22, avg_loss = 0.3310\n",
            "t = 24, avg_loss = 0.3206\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 8 / 100\n",
            "t = 2, avg_loss = 0.4728\n",
            "t = 4, avg_loss = 0.2939\n",
            "t = 6, avg_loss = 0.2565\n",
            "t = 8, avg_loss = 0.2517\n",
            "t = 10, avg_loss = 0.3371\n",
            "t = 12, avg_loss = 0.3999\n",
            "t = 14, avg_loss = 0.3662\n",
            "t = 16, avg_loss = 0.3316\n",
            "t = 18, avg_loss = 0.2905\n",
            "t = 20, avg_loss = 0.2970\n",
            "t = 22, avg_loss = 0.2888\n",
            "t = 24, avg_loss = 0.2849\n",
            "Checking accuracy on test set\n",
            "Got 351 / 400 correct (87.75)\n",
            "acc = 0.877500\n",
            "Starting epoch 9 / 100\n",
            "t = 2, avg_loss = 0.4829\n",
            "t = 4, avg_loss = 0.3224\n",
            "t = 6, avg_loss = 0.3066\n",
            "t = 8, avg_loss = 0.3260\n",
            "t = 10, avg_loss = 0.2905\n",
            "t = 12, avg_loss = 0.3129\n",
            "t = 14, avg_loss = 0.3407\n",
            "t = 16, avg_loss = 0.2437\n",
            "t = 18, avg_loss = 0.3243\n",
            "t = 20, avg_loss = 0.2474\n",
            "t = 22, avg_loss = 0.1893\n",
            "t = 24, avg_loss = 0.3406\n",
            "Checking accuracy on test set\n",
            "Got 345 / 400 correct (86.25)\n",
            "acc = 0.862500\n",
            "Starting epoch 10 / 100\n",
            "t = 2, avg_loss = 0.3855\n",
            "t = 4, avg_loss = 0.2969\n",
            "t = 6, avg_loss = 0.2667\n",
            "t = 8, avg_loss = 0.2351\n",
            "t = 10, avg_loss = 0.2921\n",
            "t = 12, avg_loss = 0.2734\n",
            "t = 14, avg_loss = 0.3558\n",
            "t = 16, avg_loss = 0.2524\n",
            "t = 18, avg_loss = 0.2947\n",
            "t = 20, avg_loss = 0.2762\n",
            "t = 22, avg_loss = 0.2441\n",
            "t = 24, avg_loss = 0.3221\n",
            "Checking accuracy on test set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 11 / 100\n",
            "t = 2, avg_loss = 0.3737\n",
            "t = 4, avg_loss = 0.2335\n",
            "t = 6, avg_loss = 0.3501\n",
            "t = 8, avg_loss = 0.2999\n",
            "t = 10, avg_loss = 0.3070\n",
            "t = 12, avg_loss = 0.2172\n",
            "t = 14, avg_loss = 0.4658\n",
            "t = 16, avg_loss = 0.2030\n",
            "t = 18, avg_loss = 0.2544\n",
            "t = 20, avg_loss = 0.2610\n",
            "t = 22, avg_loss = 0.2149\n",
            "t = 24, avg_loss = 0.2255\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 12 / 100\n",
            "t = 2, avg_loss = 0.4019\n",
            "t = 4, avg_loss = 0.3184\n",
            "t = 6, avg_loss = 0.2976\n",
            "t = 8, avg_loss = 0.2338\n",
            "t = 10, avg_loss = 0.2345\n",
            "t = 12, avg_loss = 0.2637\n",
            "t = 14, avg_loss = 0.3000\n",
            "t = 16, avg_loss = 0.2526\n",
            "t = 18, avg_loss = 0.2718\n",
            "t = 20, avg_loss = 0.2897\n",
            "t = 22, avg_loss = 0.2547\n",
            "t = 24, avg_loss = 0.2313\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 13 / 100\n",
            "t = 2, avg_loss = 0.3679\n",
            "t = 4, avg_loss = 0.2579\n",
            "t = 6, avg_loss = 0.1983\n",
            "t = 8, avg_loss = 0.2886\n",
            "t = 10, avg_loss = 0.1720\n",
            "t = 12, avg_loss = 0.3191\n",
            "t = 14, avg_loss = 0.2884\n",
            "t = 16, avg_loss = 0.2160\n",
            "t = 18, avg_loss = 0.2821\n",
            "t = 20, avg_loss = 0.3190\n",
            "t = 22, avg_loss = 0.3032\n",
            "t = 24, avg_loss = 0.2022\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 14 / 100\n",
            "t = 2, avg_loss = 0.3324\n",
            "t = 4, avg_loss = 0.1951\n",
            "t = 6, avg_loss = 0.2003\n",
            "t = 8, avg_loss = 0.3347\n",
            "t = 10, avg_loss = 0.2495\n",
            "t = 12, avg_loss = 0.1967\n",
            "t = 14, avg_loss = 0.3374\n",
            "t = 16, avg_loss = 0.2988\n",
            "t = 18, avg_loss = 0.1888\n",
            "t = 20, avg_loss = 0.2101\n",
            "t = 22, avg_loss = 0.2288\n",
            "t = 24, avg_loss = 0.3127\n",
            "Checking accuracy on test set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 15 / 100\n",
            "t = 2, avg_loss = 0.3098\n",
            "t = 4, avg_loss = 0.2271\n",
            "t = 6, avg_loss = 0.2633\n",
            "t = 8, avg_loss = 0.3049\n",
            "t = 10, avg_loss = 0.2595\n",
            "t = 12, avg_loss = 0.2254\n",
            "t = 14, avg_loss = 0.1829\n",
            "t = 16, avg_loss = 0.2627\n",
            "t = 18, avg_loss = 0.2009\n",
            "t = 20, avg_loss = 0.3388\n",
            "t = 22, avg_loss = 0.2608\n",
            "t = 24, avg_loss = 0.2498\n",
            "Checking accuracy on test set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 16 / 100\n",
            "t = 2, avg_loss = 0.3106\n",
            "t = 4, avg_loss = 0.2577\n",
            "t = 6, avg_loss = 0.2669\n",
            "t = 8, avg_loss = 0.2067\n",
            "t = 10, avg_loss = 0.1963\n",
            "t = 12, avg_loss = 0.3057\n",
            "t = 14, avg_loss = 0.1959\n",
            "t = 16, avg_loss = 0.2762\n",
            "t = 18, avg_loss = 0.2587\n",
            "t = 20, avg_loss = 0.2388\n",
            "t = 22, avg_loss = 0.2308\n",
            "t = 24, avg_loss = 0.3160\n",
            "Checking accuracy on test set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 17 / 100\n",
            "t = 2, avg_loss = 0.3361\n",
            "t = 4, avg_loss = 0.2181\n",
            "t = 6, avg_loss = 0.2783\n",
            "t = 8, avg_loss = 0.2895\n",
            "t = 10, avg_loss = 0.1614\n",
            "t = 12, avg_loss = 0.2218\n",
            "t = 14, avg_loss = 0.2623\n",
            "t = 16, avg_loss = 0.2209\n",
            "t = 18, avg_loss = 0.2207\n",
            "t = 20, avg_loss = 0.2548\n",
            "t = 22, avg_loss = 0.1938\n",
            "t = 24, avg_loss = 0.2683\n",
            "Checking accuracy on test set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 18 / 100\n",
            "t = 2, avg_loss = 0.3425\n",
            "t = 4, avg_loss = 0.2855\n",
            "t = 6, avg_loss = 0.2028\n",
            "t = 8, avg_loss = 0.2688\n",
            "t = 10, avg_loss = 0.2760\n",
            "t = 12, avg_loss = 0.1898\n",
            "t = 14, avg_loss = 0.2126\n",
            "t = 16, avg_loss = 0.2031\n",
            "t = 18, avg_loss = 0.2051\n",
            "t = 20, avg_loss = 0.1979\n",
            "t = 22, avg_loss = 0.1870\n",
            "t = 24, avg_loss = 0.2840\n",
            "Checking accuracy on test set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 19 / 100\n",
            "t = 2, avg_loss = 0.3655\n",
            "t = 4, avg_loss = 0.2494\n",
            "t = 6, avg_loss = 0.2170\n",
            "t = 8, avg_loss = 0.1385\n",
            "t = 10, avg_loss = 0.1957\n",
            "t = 12, avg_loss = 0.1619\n",
            "t = 14, avg_loss = 0.2002\n",
            "t = 16, avg_loss = 0.2262\n",
            "t = 18, avg_loss = 0.1993\n",
            "t = 20, avg_loss = 0.2095\n",
            "t = 22, avg_loss = 0.2134\n",
            "t = 24, avg_loss = 0.2414\n",
            "Checking accuracy on test set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 20 / 100\n",
            "t = 2, avg_loss = 0.3120\n",
            "t = 4, avg_loss = 0.1504\n",
            "t = 6, avg_loss = 0.2135\n",
            "t = 8, avg_loss = 0.2087\n",
            "t = 10, avg_loss = 0.2578\n",
            "t = 12, avg_loss = 0.1736\n",
            "t = 14, avg_loss = 0.2651\n",
            "t = 16, avg_loss = 0.2267\n",
            "t = 18, avg_loss = 0.2343\n",
            "t = 20, avg_loss = 0.1582\n",
            "t = 22, avg_loss = 0.2199\n",
            "t = 24, avg_loss = 0.2413\n",
            "Checking accuracy on test set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 21 / 100\n",
            "t = 2, avg_loss = 0.3003\n",
            "t = 4, avg_loss = 0.1886\n",
            "t = 6, avg_loss = 0.2018\n",
            "t = 8, avg_loss = 0.1733\n",
            "t = 10, avg_loss = 0.1876\n",
            "t = 12, avg_loss = 0.1595\n",
            "t = 14, avg_loss = 0.2470\n",
            "t = 16, avg_loss = 0.1948\n",
            "t = 18, avg_loss = 0.2153\n",
            "t = 20, avg_loss = 0.2709\n",
            "t = 22, avg_loss = 0.2048\n",
            "t = 24, avg_loss = 0.1917\n",
            "Checking accuracy on test set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 22 / 100\n",
            "t = 2, avg_loss = 0.2645\n",
            "t = 4, avg_loss = 0.1727\n",
            "t = 6, avg_loss = 0.1438\n",
            "t = 8, avg_loss = 0.2212\n",
            "t = 10, avg_loss = 0.2017\n",
            "t = 12, avg_loss = 0.2134\n",
            "t = 14, avg_loss = 0.1936\n",
            "t = 16, avg_loss = 0.1906\n",
            "t = 18, avg_loss = 0.2260\n",
            "t = 20, avg_loss = 0.2980\n",
            "t = 22, avg_loss = 0.2237\n",
            "t = 24, avg_loss = 0.1788\n",
            "Checking accuracy on test set\n",
            "Got 344 / 400 correct (86.00)\n",
            "acc = 0.860000\n",
            "Starting epoch 23 / 100\n",
            "t = 2, avg_loss = 0.2483\n",
            "t = 4, avg_loss = 0.1684\n",
            "t = 6, avg_loss = 0.1835\n",
            "t = 8, avg_loss = 0.2506\n",
            "t = 10, avg_loss = 0.1469\n",
            "t = 12, avg_loss = 0.2474\n",
            "t = 14, avg_loss = 0.2517\n",
            "t = 16, avg_loss = 0.1426\n",
            "t = 18, avg_loss = 0.2687\n",
            "t = 20, avg_loss = 0.2445\n",
            "t = 22, avg_loss = 0.2546\n",
            "t = 24, avg_loss = 0.1960\n",
            "Checking accuracy on test set\n",
            "Got 351 / 400 correct (87.75)\n",
            "acc = 0.877500\n",
            "Starting epoch 24 / 100\n",
            "t = 2, avg_loss = 0.2554\n",
            "t = 4, avg_loss = 0.2408\n",
            "t = 6, avg_loss = 0.1629\n",
            "t = 8, avg_loss = 0.1563\n",
            "t = 10, avg_loss = 0.2092\n",
            "t = 12, avg_loss = 0.2453\n",
            "t = 14, avg_loss = 0.2134\n",
            "t = 16, avg_loss = 0.2070\n",
            "t = 18, avg_loss = 0.1492\n",
            "t = 20, avg_loss = 0.1472\n",
            "t = 22, avg_loss = 0.1602\n",
            "t = 24, avg_loss = 0.1660\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 25 / 100\n",
            "t = 2, avg_loss = 0.2620\n",
            "t = 4, avg_loss = 0.2204\n",
            "t = 6, avg_loss = 0.1049\n",
            "t = 8, avg_loss = 0.1541\n",
            "t = 10, avg_loss = 0.1210\n",
            "t = 12, avg_loss = 0.1766\n",
            "t = 14, avg_loss = 0.2443\n",
            "t = 16, avg_loss = 0.1842\n",
            "t = 18, avg_loss = 0.1999\n",
            "t = 20, avg_loss = 0.1980\n",
            "t = 22, avg_loss = 0.1530\n",
            "t = 24, avg_loss = 0.1850\n",
            "Checking accuracy on test set\n",
            "Got 361 / 400 correct (90.25)\n",
            "acc = 0.902500\n",
            "Starting epoch 26 / 100\n",
            "t = 2, avg_loss = 0.2280\n",
            "t = 4, avg_loss = 0.1990\n",
            "t = 6, avg_loss = 0.2006\n",
            "t = 8, avg_loss = 0.1107\n",
            "t = 10, avg_loss = 0.2286\n",
            "t = 12, avg_loss = 0.0944\n",
            "t = 14, avg_loss = 0.1516\n",
            "t = 16, avg_loss = 0.1689\n",
            "t = 18, avg_loss = 0.2021\n",
            "t = 20, avg_loss = 0.2894\n",
            "t = 22, avg_loss = 0.2402\n",
            "t = 24, avg_loss = 0.1526\n",
            "Checking accuracy on test set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 27 / 100\n",
            "t = 2, avg_loss = 0.2942\n",
            "t = 4, avg_loss = 0.1886\n",
            "t = 6, avg_loss = 0.1496\n",
            "t = 8, avg_loss = 0.1655\n",
            "t = 10, avg_loss = 0.1686\n",
            "t = 12, avg_loss = 0.1512\n",
            "t = 14, avg_loss = 0.1534\n",
            "t = 16, avg_loss = 0.1994\n",
            "t = 18, avg_loss = 0.1643\n",
            "t = 20, avg_loss = 0.2304\n",
            "t = 22, avg_loss = 0.2150\n",
            "t = 24, avg_loss = 0.1843\n",
            "Checking accuracy on test set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 28 / 100\n",
            "t = 2, avg_loss = 0.3419\n",
            "t = 4, avg_loss = 0.1457\n",
            "t = 6, avg_loss = 0.1481\n",
            "t = 8, avg_loss = 0.1315\n",
            "t = 10, avg_loss = 0.1632\n",
            "t = 12, avg_loss = 0.1845\n",
            "t = 14, avg_loss = 0.1681\n",
            "t = 16, avg_loss = 0.2772\n",
            "t = 18, avg_loss = 0.1484\n",
            "t = 20, avg_loss = 0.1844\n",
            "t = 22, avg_loss = 0.2582\n",
            "t = 24, avg_loss = 0.1536\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 29 / 100\n",
            "t = 2, avg_loss = 0.2539\n",
            "t = 4, avg_loss = 0.2018\n",
            "t = 6, avg_loss = 0.1967\n",
            "t = 8, avg_loss = 0.1582\n",
            "t = 10, avg_loss = 0.1959\n",
            "t = 12, avg_loss = 0.1549\n",
            "t = 14, avg_loss = 0.1595\n",
            "t = 16, avg_loss = 0.1493\n",
            "t = 18, avg_loss = 0.1538\n",
            "t = 20, avg_loss = 0.1523\n",
            "t = 22, avg_loss = 0.1806\n",
            "t = 24, avg_loss = 0.1630\n",
            "Checking accuracy on test set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 30 / 100\n",
            "t = 2, avg_loss = 0.3656\n",
            "t = 4, avg_loss = 0.1255\n",
            "t = 6, avg_loss = 0.1720\n",
            "t = 8, avg_loss = 0.1658\n",
            "t = 10, avg_loss = 0.1311\n",
            "t = 12, avg_loss = 0.1411\n",
            "t = 14, avg_loss = 0.2190\n",
            "t = 16, avg_loss = 0.1445\n",
            "t = 18, avg_loss = 0.2304\n",
            "t = 20, avg_loss = 0.1399\n",
            "t = 22, avg_loss = 0.1509\n",
            "t = 24, avg_loss = 0.1561\n",
            "Checking accuracy on test set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 31 / 100\n",
            "t = 2, avg_loss = 0.2939\n",
            "t = 4, avg_loss = 0.2122\n",
            "t = 6, avg_loss = 0.1303\n",
            "t = 8, avg_loss = 0.1324\n",
            "t = 10, avg_loss = 0.1288\n",
            "t = 12, avg_loss = 0.1194\n",
            "t = 14, avg_loss = 0.2212\n",
            "t = 16, avg_loss = 0.1364\n",
            "t = 18, avg_loss = 0.1944\n",
            "t = 20, avg_loss = 0.1607\n",
            "t = 22, avg_loss = 0.1548\n",
            "t = 24, avg_loss = 0.1927\n",
            "Checking accuracy on test set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 32 / 100\n",
            "t = 2, avg_loss = 0.3331\n",
            "t = 4, avg_loss = 0.1875\n",
            "t = 6, avg_loss = 0.1464\n",
            "t = 8, avg_loss = 0.1424\n",
            "t = 10, avg_loss = 0.1288\n",
            "t = 12, avg_loss = 0.1717\n",
            "t = 14, avg_loss = 0.1421\n",
            "t = 16, avg_loss = 0.1691\n",
            "t = 18, avg_loss = 0.1948\n",
            "t = 20, avg_loss = 0.1445\n",
            "t = 22, avg_loss = 0.1254\n",
            "t = 24, avg_loss = 0.1261\n",
            "Checking accuracy on test set\n",
            "Got 360 / 400 correct (90.00)\n",
            "acc = 0.900000\n",
            "Starting epoch 33 / 100\n",
            "t = 2, avg_loss = 0.2818\n",
            "t = 4, avg_loss = 0.1194\n",
            "t = 6, avg_loss = 0.1281\n",
            "t = 8, avg_loss = 0.0988\n",
            "t = 10, avg_loss = 0.1437\n",
            "t = 12, avg_loss = 0.1530\n",
            "t = 14, avg_loss = 0.2204\n",
            "t = 16, avg_loss = 0.1511\n",
            "t = 18, avg_loss = 0.1418\n",
            "t = 20, avg_loss = 0.1799\n",
            "t = 22, avg_loss = 0.1123\n",
            "t = 24, avg_loss = 0.2110\n",
            "Checking accuracy on test set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 34 / 100\n",
            "t = 2, avg_loss = 0.1971\n",
            "t = 4, avg_loss = 0.1261\n",
            "t = 6, avg_loss = 0.1705\n",
            "t = 8, avg_loss = 0.1748\n",
            "t = 10, avg_loss = 0.1462\n",
            "t = 12, avg_loss = 0.1839\n",
            "t = 14, avg_loss = 0.1235\n",
            "t = 16, avg_loss = 0.2223\n",
            "t = 18, avg_loss = 0.1573\n",
            "t = 20, avg_loss = 0.1410\n",
            "t = 22, avg_loss = 0.0910\n",
            "t = 24, avg_loss = 0.2005\n",
            "Checking accuracy on test set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 35 / 100\n",
            "t = 2, avg_loss = 0.3393\n",
            "t = 4, avg_loss = 0.1136\n",
            "t = 6, avg_loss = 0.1198\n",
            "t = 8, avg_loss = 0.1126\n",
            "t = 10, avg_loss = 0.1473\n",
            "t = 12, avg_loss = 0.0945\n",
            "t = 14, avg_loss = 0.2688\n",
            "t = 16, avg_loss = 0.2665\n",
            "t = 18, avg_loss = 0.1188\n",
            "t = 20, avg_loss = 0.2207\n",
            "t = 22, avg_loss = 0.2108\n",
            "t = 24, avg_loss = 0.1407\n",
            "Checking accuracy on test set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 36 / 100\n",
            "t = 2, avg_loss = 0.2194\n",
            "t = 4, avg_loss = 0.1049\n",
            "t = 6, avg_loss = 0.1429\n",
            "t = 8, avg_loss = 0.1219\n",
            "t = 10, avg_loss = 0.1168\n",
            "t = 12, avg_loss = 0.1204\n",
            "t = 14, avg_loss = 0.1435\n",
            "t = 16, avg_loss = 0.0783\n",
            "t = 18, avg_loss = 0.1578\n",
            "t = 20, avg_loss = 0.1179\n",
            "t = 22, avg_loss = 0.1695\n",
            "t = 24, avg_loss = 0.1254\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 37 / 100\n",
            "t = 2, avg_loss = 0.2101\n",
            "t = 4, avg_loss = 0.1143\n",
            "t = 6, avg_loss = 0.2034\n",
            "t = 8, avg_loss = 0.1652\n",
            "t = 10, avg_loss = 0.1035\n",
            "t = 12, avg_loss = 0.1765\n",
            "t = 14, avg_loss = 0.1198\n",
            "t = 16, avg_loss = 0.1076\n",
            "t = 18, avg_loss = 0.0844\n",
            "t = 20, avg_loss = 0.2034\n",
            "t = 22, avg_loss = 0.1658\n",
            "t = 24, avg_loss = 0.1808\n",
            "Checking accuracy on test set\n",
            "Got 351 / 400 correct (87.75)\n",
            "acc = 0.877500\n",
            "Starting epoch 38 / 100\n",
            "t = 2, avg_loss = 0.1626\n",
            "t = 4, avg_loss = 0.1330\n",
            "t = 6, avg_loss = 0.1842\n",
            "t = 8, avg_loss = 0.1008\n",
            "t = 10, avg_loss = 0.1163\n",
            "t = 12, avg_loss = 0.1094\n",
            "t = 14, avg_loss = 0.1148\n",
            "t = 16, avg_loss = 0.1200\n",
            "t = 18, avg_loss = 0.1444\n",
            "t = 20, avg_loss = 0.1632\n",
            "t = 22, avg_loss = 0.1940\n",
            "t = 24, avg_loss = 0.1185\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 39 / 100\n",
            "t = 2, avg_loss = 0.1872\n",
            "t = 4, avg_loss = 0.1193\n",
            "t = 6, avg_loss = 0.1393\n",
            "t = 8, avg_loss = 0.1674\n",
            "t = 10, avg_loss = 0.1630\n",
            "t = 12, avg_loss = 0.2254\n",
            "t = 14, avg_loss = 0.1763\n",
            "t = 16, avg_loss = 0.1598\n",
            "t = 18, avg_loss = 0.1126\n",
            "t = 20, avg_loss = 0.0908\n",
            "t = 22, avg_loss = 0.1315\n",
            "t = 24, avg_loss = 0.1586\n",
            "Checking accuracy on test set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 40 / 100\n",
            "t = 2, avg_loss = 0.1668\n",
            "t = 4, avg_loss = 0.1390\n",
            "t = 6, avg_loss = 0.0869\n",
            "t = 8, avg_loss = 0.1834\n",
            "t = 10, avg_loss = 0.1364\n",
            "t = 12, avg_loss = 0.1389\n",
            "t = 14, avg_loss = 0.1313\n",
            "t = 16, avg_loss = 0.1739\n",
            "t = 18, avg_loss = 0.1106\n",
            "t = 20, avg_loss = 0.1868\n",
            "t = 22, avg_loss = 0.1389\n",
            "t = 24, avg_loss = 0.1324\n",
            "Checking accuracy on test set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 41 / 100\n",
            "t = 2, avg_loss = 0.1995\n",
            "t = 4, avg_loss = 0.1500\n",
            "t = 6, avg_loss = 0.1321\n",
            "t = 8, avg_loss = 0.1539\n",
            "t = 10, avg_loss = 0.1092\n",
            "t = 12, avg_loss = 0.1071\n",
            "t = 14, avg_loss = 0.1667\n",
            "t = 16, avg_loss = 0.1019\n",
            "t = 18, avg_loss = 0.1359\n",
            "t = 20, avg_loss = 0.0731\n",
            "t = 22, avg_loss = 0.1432\n",
            "t = 24, avg_loss = 0.0728\n",
            "Checking accuracy on test set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 42 / 100\n",
            "t = 2, avg_loss = 0.1806\n",
            "t = 4, avg_loss = 0.1356\n",
            "t = 6, avg_loss = 0.1609\n",
            "t = 8, avg_loss = 0.1073\n",
            "t = 10, avg_loss = 0.1102\n",
            "t = 12, avg_loss = 0.1096\n",
            "t = 14, avg_loss = 0.1185\n",
            "t = 16, avg_loss = 0.1341\n",
            "t = 18, avg_loss = 0.1018\n",
            "t = 20, avg_loss = 0.1343\n",
            "t = 22, avg_loss = 0.0799\n",
            "t = 24, avg_loss = 0.0700\n",
            "Checking accuracy on test set\n",
            "Got 351 / 400 correct (87.75)\n",
            "acc = 0.877500\n",
            "Starting epoch 43 / 100\n",
            "t = 2, avg_loss = 0.1822\n",
            "t = 4, avg_loss = 0.1418\n",
            "t = 6, avg_loss = 0.1280\n",
            "t = 8, avg_loss = 0.2041\n",
            "t = 10, avg_loss = 0.1492\n",
            "t = 12, avg_loss = 0.1349\n",
            "t = 14, avg_loss = 0.2510\n",
            "t = 16, avg_loss = 0.1482\n",
            "t = 18, avg_loss = 0.1220\n",
            "t = 20, avg_loss = 0.1503\n",
            "t = 22, avg_loss = 0.1329\n",
            "t = 24, avg_loss = 0.1045\n",
            "Checking accuracy on test set\n",
            "Got 351 / 400 correct (87.75)\n",
            "acc = 0.877500\n",
            "Starting epoch 44 / 100\n",
            "t = 2, avg_loss = 0.1503\n",
            "t = 4, avg_loss = 0.1363\n",
            "t = 6, avg_loss = 0.1193\n",
            "t = 8, avg_loss = 0.1021\n",
            "t = 10, avg_loss = 0.1223\n",
            "t = 12, avg_loss = 0.1242\n",
            "t = 14, avg_loss = 0.1755\n",
            "t = 16, avg_loss = 0.1164\n",
            "t = 18, avg_loss = 0.1290\n",
            "t = 20, avg_loss = 0.1690\n",
            "t = 22, avg_loss = 0.0932\n",
            "t = 24, avg_loss = 0.1681\n",
            "Checking accuracy on test set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 45 / 100\n",
            "t = 2, avg_loss = 0.1449\n",
            "t = 4, avg_loss = 0.1156\n",
            "t = 6, avg_loss = 0.0937\n",
            "t = 8, avg_loss = 0.2175\n",
            "t = 10, avg_loss = 0.1069\n",
            "t = 12, avg_loss = 0.0808\n",
            "t = 14, avg_loss = 0.0615\n",
            "t = 16, avg_loss = 0.1612\n",
            "t = 18, avg_loss = 0.1125\n",
            "t = 20, avg_loss = 0.1413\n",
            "t = 22, avg_loss = 0.0942\n",
            "t = 24, avg_loss = 0.1023\n",
            "Checking accuracy on test set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 46 / 100\n",
            "t = 2, avg_loss = 0.1970\n",
            "t = 4, avg_loss = 0.2085\n",
            "t = 6, avg_loss = 0.1119\n",
            "t = 8, avg_loss = 0.1093\n",
            "t = 10, avg_loss = 0.1328\n",
            "t = 12, avg_loss = 0.1759\n",
            "t = 14, avg_loss = 0.0836\n",
            "t = 16, avg_loss = 0.1647\n",
            "t = 18, avg_loss = 0.1263\n",
            "t = 20, avg_loss = 0.1595\n",
            "t = 22, avg_loss = 0.0944\n",
            "t = 24, avg_loss = 0.0916\n",
            "Checking accuracy on test set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 47 / 100\n",
            "t = 2, avg_loss = 0.1944\n",
            "t = 4, avg_loss = 0.1166\n",
            "t = 6, avg_loss = 0.0973\n",
            "t = 8, avg_loss = 0.0786\n",
            "t = 10, avg_loss = 0.1897\n",
            "t = 12, avg_loss = 0.2065\n",
            "t = 14, avg_loss = 0.0868\n",
            "t = 16, avg_loss = 0.1183\n",
            "t = 18, avg_loss = 0.1219\n",
            "t = 20, avg_loss = 0.1978\n",
            "t = 22, avg_loss = 0.1355\n",
            "t = 24, avg_loss = 0.0916\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 48 / 100\n",
            "t = 2, avg_loss = 0.1426\n",
            "t = 4, avg_loss = 0.1202\n",
            "t = 6, avg_loss = 0.1417\n",
            "t = 8, avg_loss = 0.1857\n",
            "t = 10, avg_loss = 0.1552\n",
            "t = 12, avg_loss = 0.1245\n",
            "t = 14, avg_loss = 0.1069\n",
            "t = 16, avg_loss = 0.0828\n",
            "t = 18, avg_loss = 0.1642\n",
            "t = 20, avg_loss = 0.1594\n",
            "t = 22, avg_loss = 0.0638\n",
            "t = 24, avg_loss = 0.1323\n",
            "Checking accuracy on test set\n",
            "Got 359 / 400 correct (89.75)\n",
            "acc = 0.897500\n",
            "Starting epoch 49 / 100\n",
            "t = 2, avg_loss = 0.2015\n",
            "t = 4, avg_loss = 0.1124\n",
            "t = 6, avg_loss = 0.1120\n",
            "t = 8, avg_loss = 0.0878\n",
            "t = 10, avg_loss = 0.1062\n",
            "t = 12, avg_loss = 0.1038\n",
            "t = 14, avg_loss = 0.0998\n",
            "t = 16, avg_loss = 0.1268\n",
            "t = 18, avg_loss = 0.1370\n",
            "t = 20, avg_loss = 0.1158\n",
            "t = 22, avg_loss = 0.0845\n",
            "t = 24, avg_loss = 0.1100\n",
            "Checking accuracy on test set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 50 / 100\n",
            "t = 2, avg_loss = 0.2155\n",
            "t = 4, avg_loss = 0.0748\n",
            "t = 6, avg_loss = 0.1263\n",
            "t = 8, avg_loss = 0.1041\n",
            "t = 10, avg_loss = 0.0764\n",
            "t = 12, avg_loss = 0.0915\n",
            "t = 14, avg_loss = 0.1266\n",
            "t = 16, avg_loss = 0.0959\n",
            "t = 18, avg_loss = 0.1205\n",
            "t = 20, avg_loss = 0.1287\n",
            "t = 22, avg_loss = 0.0688\n",
            "t = 24, avg_loss = 0.0680\n",
            "Checking accuracy on test set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 51 / 100\n",
            "t = 2, avg_loss = 0.2288\n",
            "t = 4, avg_loss = 0.0520\n",
            "t = 6, avg_loss = 0.1137\n",
            "t = 8, avg_loss = 0.1046\n",
            "t = 10, avg_loss = 0.1101\n",
            "t = 12, avg_loss = 0.0942\n",
            "t = 14, avg_loss = 0.0740\n",
            "t = 16, avg_loss = 0.0919\n",
            "t = 18, avg_loss = 0.1171\n",
            "t = 20, avg_loss = 0.0921\n",
            "t = 22, avg_loss = 0.1105\n",
            "t = 24, avg_loss = 0.1011\n",
            "Checking accuracy on test set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 52 / 100\n",
            "t = 2, avg_loss = 0.1694\n",
            "t = 4, avg_loss = 0.0789\n",
            "t = 6, avg_loss = 0.0625\n",
            "t = 8, avg_loss = 0.0700\n",
            "t = 10, avg_loss = 0.1515\n",
            "t = 12, avg_loss = 0.1132\n",
            "t = 14, avg_loss = 0.0743\n",
            "t = 16, avg_loss = 0.1341\n",
            "t = 18, avg_loss = 0.1002\n",
            "t = 20, avg_loss = 0.1071\n",
            "t = 22, avg_loss = 0.1061\n",
            "t = 24, avg_loss = 0.0832\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 53 / 100\n",
            "t = 2, avg_loss = 0.1031\n",
            "t = 4, avg_loss = 0.1444\n",
            "t = 6, avg_loss = 0.1077\n",
            "t = 8, avg_loss = 0.0888\n",
            "t = 10, avg_loss = 0.1217\n",
            "t = 12, avg_loss = 0.0782\n",
            "t = 14, avg_loss = 0.1070\n",
            "t = 16, avg_loss = 0.0640\n",
            "t = 18, avg_loss = 0.0821\n",
            "t = 20, avg_loss = 0.0808\n",
            "t = 22, avg_loss = 0.1565\n",
            "t = 24, avg_loss = 0.1417\n",
            "Checking accuracy on test set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 54 / 100\n",
            "t = 2, avg_loss = 0.1417\n",
            "t = 4, avg_loss = 0.1099\n",
            "t = 6, avg_loss = 0.0773\n",
            "t = 8, avg_loss = 0.0593\n",
            "t = 10, avg_loss = 0.0952\n",
            "t = 12, avg_loss = 0.0888\n",
            "t = 14, avg_loss = 0.0945\n",
            "t = 16, avg_loss = 0.1109\n",
            "t = 18, avg_loss = 0.1253\n",
            "t = 20, avg_loss = 0.1127\n",
            "t = 22, avg_loss = 0.1156\n",
            "t = 24, avg_loss = 0.2345\n",
            "Checking accuracy on test set\n",
            "Got 359 / 400 correct (89.75)\n",
            "acc = 0.897500\n",
            "Starting epoch 55 / 100\n",
            "t = 2, avg_loss = 0.1191\n",
            "t = 4, avg_loss = 0.1240\n",
            "t = 6, avg_loss = 0.0886\n",
            "t = 8, avg_loss = 0.0910\n",
            "t = 10, avg_loss = 0.0935\n",
            "t = 12, avg_loss = 0.1568\n",
            "t = 14, avg_loss = 0.0910\n",
            "t = 16, avg_loss = 0.0573\n",
            "t = 18, avg_loss = 0.0768\n",
            "t = 20, avg_loss = 0.1526\n",
            "t = 22, avg_loss = 0.1447\n",
            "t = 24, avg_loss = 0.1160\n",
            "Checking accuracy on test set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 56 / 100\n",
            "t = 2, avg_loss = 0.1313\n",
            "t = 4, avg_loss = 0.1176\n",
            "t = 6, avg_loss = 0.1220\n",
            "t = 8, avg_loss = 0.0945\n",
            "t = 10, avg_loss = 0.1045\n",
            "t = 12, avg_loss = 0.1512\n",
            "t = 14, avg_loss = 0.1047\n",
            "t = 16, avg_loss = 0.1125\n",
            "t = 18, avg_loss = 0.0773\n",
            "t = 20, avg_loss = 0.0992\n",
            "t = 22, avg_loss = 0.1151\n",
            "t = 24, avg_loss = 0.1052\n",
            "Checking accuracy on test set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 57 / 100\n",
            "t = 2, avg_loss = 0.1542\n",
            "t = 4, avg_loss = 0.0961\n",
            "t = 6, avg_loss = 0.1289\n",
            "t = 8, avg_loss = 0.1087\n",
            "t = 10, avg_loss = 0.1120\n",
            "t = 12, avg_loss = 0.0991\n",
            "t = 14, avg_loss = 0.1124\n",
            "t = 16, avg_loss = 0.1727\n",
            "t = 18, avg_loss = 0.1115\n",
            "t = 20, avg_loss = 0.0886\n",
            "t = 22, avg_loss = 0.0851\n",
            "t = 24, avg_loss = 0.1074\n",
            "Checking accuracy on test set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 58 / 100\n",
            "t = 2, avg_loss = 0.1515\n",
            "t = 4, avg_loss = 0.0972\n",
            "t = 6, avg_loss = 0.0677\n",
            "t = 8, avg_loss = 0.1183\n",
            "t = 10, avg_loss = 0.1240\n",
            "t = 12, avg_loss = 0.1153\n",
            "t = 14, avg_loss = 0.1035\n",
            "t = 16, avg_loss = 0.1039\n",
            "t = 18, avg_loss = 0.0692\n",
            "t = 20, avg_loss = 0.0676\n",
            "t = 22, avg_loss = 0.0857\n",
            "t = 24, avg_loss = 0.1207\n",
            "Checking accuracy on test set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 59 / 100\n",
            "t = 2, avg_loss = 0.0870\n",
            "t = 4, avg_loss = 0.0813\n",
            "t = 6, avg_loss = 0.0499\n",
            "t = 8, avg_loss = 0.0932\n",
            "t = 10, avg_loss = 0.0440\n",
            "t = 12, avg_loss = 0.1124\n",
            "t = 14, avg_loss = 0.0690\n",
            "t = 16, avg_loss = 0.1432\n",
            "t = 18, avg_loss = 0.0937\n",
            "t = 20, avg_loss = 0.0817\n",
            "t = 22, avg_loss = 0.0738\n",
            "t = 24, avg_loss = 0.1032\n",
            "Checking accuracy on test set\n",
            "Got 351 / 400 correct (87.75)\n",
            "acc = 0.877500\n",
            "Starting epoch 60 / 100\n",
            "t = 2, avg_loss = 0.0829\n",
            "t = 4, avg_loss = 0.0934\n",
            "t = 6, avg_loss = 0.1512\n",
            "t = 8, avg_loss = 0.0995\n",
            "t = 10, avg_loss = 0.1258\n",
            "t = 12, avg_loss = 0.1101\n",
            "t = 14, avg_loss = 0.1260\n",
            "t = 16, avg_loss = 0.0844\n",
            "t = 18, avg_loss = 0.1481\n",
            "t = 20, avg_loss = 0.0675\n",
            "t = 22, avg_loss = 0.1131\n",
            "t = 24, avg_loss = 0.1402\n",
            "Checking accuracy on test set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 61 / 100\n",
            "t = 2, avg_loss = 0.1503\n",
            "t = 4, avg_loss = 0.1097\n",
            "t = 6, avg_loss = 0.0690\n",
            "t = 8, avg_loss = 0.1038\n",
            "t = 10, avg_loss = 0.0817\n",
            "t = 12, avg_loss = 0.1377\n",
            "t = 14, avg_loss = 0.1067\n",
            "t = 16, avg_loss = 0.0913\n",
            "t = 18, avg_loss = 0.1104\n",
            "t = 20, avg_loss = 0.1082\n",
            "t = 22, avg_loss = 0.1315\n",
            "t = 24, avg_loss = 0.1097\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 62 / 100\n",
            "t = 2, avg_loss = 0.0721\n",
            "t = 4, avg_loss = 0.1206\n",
            "t = 6, avg_loss = 0.1009\n",
            "t = 8, avg_loss = 0.1397\n",
            "t = 10, avg_loss = 0.1055\n",
            "t = 12, avg_loss = 0.1019\n",
            "t = 14, avg_loss = 0.0927\n",
            "t = 16, avg_loss = 0.0970\n",
            "t = 18, avg_loss = 0.1567\n",
            "t = 20, avg_loss = 0.1202\n",
            "t = 22, avg_loss = 0.1000\n",
            "t = 24, avg_loss = 0.0840\n",
            "Checking accuracy on test set\n",
            "Got 337 / 400 correct (84.25)\n",
            "acc = 0.842500\n",
            "Starting epoch 63 / 100\n",
            "t = 2, avg_loss = 0.2549\n",
            "t = 4, avg_loss = 0.0866\n",
            "t = 6, avg_loss = 0.1047\n",
            "t = 8, avg_loss = 0.0998\n",
            "t = 10, avg_loss = 0.0515\n",
            "t = 12, avg_loss = 0.0569\n",
            "t = 14, avg_loss = 0.0676\n",
            "t = 16, avg_loss = 0.1933\n",
            "t = 18, avg_loss = 0.1409\n",
            "t = 20, avg_loss = 0.0886\n",
            "t = 22, avg_loss = 0.1133\n",
            "t = 24, avg_loss = 0.0739\n",
            "Checking accuracy on test set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 64 / 100\n",
            "t = 2, avg_loss = 0.1548\n",
            "t = 4, avg_loss = 0.1675\n",
            "t = 6, avg_loss = 0.0664\n",
            "t = 8, avg_loss = 0.0903\n",
            "t = 10, avg_loss = 0.1090\n",
            "t = 12, avg_loss = 0.1110\n",
            "t = 14, avg_loss = 0.0587\n",
            "t = 16, avg_loss = 0.1112\n",
            "t = 18, avg_loss = 0.1241\n",
            "t = 20, avg_loss = 0.0712\n",
            "t = 22, avg_loss = 0.0752\n",
            "t = 24, avg_loss = 0.1144\n",
            "Checking accuracy on test set\n",
            "Got 351 / 400 correct (87.75)\n",
            "acc = 0.877500\n",
            "Starting epoch 65 / 100\n",
            "t = 2, avg_loss = 0.1210\n",
            "t = 4, avg_loss = 0.1058\n",
            "t = 6, avg_loss = 0.0926\n",
            "t = 8, avg_loss = 0.1113\n",
            "t = 10, avg_loss = 0.0846\n",
            "t = 12, avg_loss = 0.1160\n",
            "t = 14, avg_loss = 0.0659\n",
            "t = 16, avg_loss = 0.1038\n",
            "t = 18, avg_loss = 0.0411\n",
            "t = 20, avg_loss = 0.0512\n",
            "t = 22, avg_loss = 0.1051\n",
            "t = 24, avg_loss = 0.0717\n",
            "Checking accuracy on test set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 66 / 100\n",
            "t = 2, avg_loss = 0.1162\n",
            "t = 4, avg_loss = 0.0531\n",
            "t = 6, avg_loss = 0.0944\n",
            "t = 8, avg_loss = 0.0628\n",
            "t = 10, avg_loss = 0.0858\n",
            "t = 12, avg_loss = 0.0460\n",
            "t = 14, avg_loss = 0.0993\n",
            "t = 16, avg_loss = 0.0957\n",
            "t = 18, avg_loss = 0.0569\n",
            "t = 20, avg_loss = 0.0874\n",
            "t = 22, avg_loss = 0.0957\n",
            "t = 24, avg_loss = 0.0497\n",
            "Checking accuracy on test set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 67 / 100\n",
            "t = 2, avg_loss = 0.1024\n",
            "t = 4, avg_loss = 0.0722\n",
            "t = 6, avg_loss = 0.0487\n",
            "t = 8, avg_loss = 0.0724\n",
            "t = 10, avg_loss = 0.0815\n",
            "t = 12, avg_loss = 0.0582\n",
            "t = 14, avg_loss = 0.0444\n",
            "t = 16, avg_loss = 0.0551\n",
            "t = 18, avg_loss = 0.0646\n",
            "t = 20, avg_loss = 0.0719\n",
            "t = 22, avg_loss = 0.0704\n",
            "t = 24, avg_loss = 0.0586\n",
            "Checking accuracy on test set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 68 / 100\n",
            "t = 2, avg_loss = 0.1069\n",
            "t = 4, avg_loss = 0.1287\n",
            "t = 6, avg_loss = 0.1988\n",
            "t = 8, avg_loss = 0.0573\n",
            "t = 10, avg_loss = 0.0878\n",
            "t = 12, avg_loss = 0.0830\n",
            "t = 14, avg_loss = 0.0990\n",
            "t = 16, avg_loss = 0.1053\n",
            "t = 18, avg_loss = 0.0929\n",
            "t = 20, avg_loss = 0.1154\n",
            "t = 22, avg_loss = 0.1819\n",
            "t = 24, avg_loss = 0.1313\n",
            "Checking accuracy on test set\n",
            "Got 345 / 400 correct (86.25)\n",
            "acc = 0.862500\n",
            "Starting epoch 69 / 100\n",
            "t = 2, avg_loss = 0.1321\n",
            "t = 4, avg_loss = 0.1366\n",
            "t = 6, avg_loss = 0.1819\n",
            "t = 8, avg_loss = 0.1362\n",
            "t = 10, avg_loss = 0.0797\n",
            "t = 12, avg_loss = 0.1376\n",
            "t = 14, avg_loss = 0.1302\n",
            "t = 16, avg_loss = 0.1179\n",
            "t = 18, avg_loss = 0.1053\n",
            "t = 20, avg_loss = 0.0840\n",
            "t = 22, avg_loss = 0.1189\n",
            "t = 24, avg_loss = 0.0737\n",
            "Checking accuracy on test set\n",
            "Got 359 / 400 correct (89.75)\n",
            "acc = 0.897500\n",
            "Starting epoch 70 / 100\n",
            "t = 2, avg_loss = 0.1299\n",
            "t = 4, avg_loss = 0.0856\n",
            "t = 6, avg_loss = 0.0584\n",
            "t = 8, avg_loss = 0.0943\n",
            "t = 10, avg_loss = 0.0817\n",
            "t = 12, avg_loss = 0.0974\n",
            "t = 14, avg_loss = 0.0880\n",
            "t = 16, avg_loss = 0.0640\n",
            "t = 18, avg_loss = 0.1032\n",
            "t = 20, avg_loss = 0.0635\n",
            "t = 22, avg_loss = 0.0781\n",
            "t = 24, avg_loss = 0.0725\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 71 / 100\n",
            "t = 2, avg_loss = 0.1069\n",
            "t = 4, avg_loss = 0.0650\n",
            "t = 6, avg_loss = 0.0551\n",
            "t = 8, avg_loss = 0.0451\n",
            "t = 10, avg_loss = 0.0877\n",
            "t = 12, avg_loss = 0.0546\n",
            "t = 14, avg_loss = 0.1208\n",
            "t = 16, avg_loss = 0.1075\n",
            "t = 18, avg_loss = 0.0872\n",
            "t = 20, avg_loss = 0.0847\n",
            "t = 22, avg_loss = 0.1140\n",
            "t = 24, avg_loss = 0.1041\n",
            "Checking accuracy on test set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 72 / 100\n",
            "t = 2, avg_loss = 0.1398\n",
            "t = 4, avg_loss = 0.0437\n",
            "t = 6, avg_loss = 0.0828\n",
            "t = 8, avg_loss = 0.0723\n",
            "t = 10, avg_loss = 0.0660\n",
            "t = 12, avg_loss = 0.0850\n",
            "t = 14, avg_loss = 0.0635\n",
            "t = 16, avg_loss = 0.0940\n",
            "t = 18, avg_loss = 0.0399\n",
            "t = 20, avg_loss = 0.1006\n",
            "t = 22, avg_loss = 0.0559\n",
            "t = 24, avg_loss = 0.1214\n",
            "Checking accuracy on test set\n",
            "Got 360 / 400 correct (90.00)\n",
            "acc = 0.900000\n",
            "Starting epoch 73 / 100\n",
            "t = 2, avg_loss = 0.0713\n",
            "t = 4, avg_loss = 0.0611\n",
            "t = 6, avg_loss = 0.0343\n",
            "t = 8, avg_loss = 0.1049\n",
            "t = 10, avg_loss = 0.0991\n",
            "t = 12, avg_loss = 0.1090\n",
            "t = 14, avg_loss = 0.0574\n",
            "t = 16, avg_loss = 0.0976\n",
            "t = 18, avg_loss = 0.0749\n",
            "t = 20, avg_loss = 0.0962\n",
            "t = 22, avg_loss = 0.0770\n",
            "t = 24, avg_loss = 0.0957\n",
            "Checking accuracy on test set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 74 / 100\n",
            "t = 2, avg_loss = 0.1100\n",
            "t = 4, avg_loss = 0.0377\n",
            "t = 6, avg_loss = 0.0549\n",
            "t = 8, avg_loss = 0.0522\n",
            "t = 10, avg_loss = 0.1093\n",
            "t = 12, avg_loss = 0.1017\n",
            "t = 14, avg_loss = 0.0428\n",
            "t = 16, avg_loss = 0.0639\n",
            "t = 18, avg_loss = 0.0524\n",
            "t = 20, avg_loss = 0.1263\n",
            "t = 22, avg_loss = 0.1067\n",
            "t = 24, avg_loss = 0.0700\n",
            "Checking accuracy on test set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 75 / 100\n",
            "t = 2, avg_loss = 0.1172\n",
            "t = 4, avg_loss = 0.0801\n",
            "t = 6, avg_loss = 0.0691\n",
            "t = 8, avg_loss = 0.0843\n",
            "t = 10, avg_loss = 0.1770\n",
            "t = 12, avg_loss = 0.0998\n",
            "t = 14, avg_loss = 0.1538\n",
            "t = 16, avg_loss = 0.0650\n",
            "t = 18, avg_loss = 0.0900\n",
            "t = 20, avg_loss = 0.1177\n",
            "t = 22, avg_loss = 0.1322\n",
            "t = 24, avg_loss = 0.0934\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 76 / 100\n",
            "t = 2, avg_loss = 0.1834\n",
            "t = 4, avg_loss = 0.0899\n",
            "t = 6, avg_loss = 0.1154\n",
            "t = 8, avg_loss = 0.0680\n",
            "t = 10, avg_loss = 0.1315\n",
            "t = 12, avg_loss = 0.1188\n",
            "t = 14, avg_loss = 0.0544\n",
            "t = 16, avg_loss = 0.0920\n",
            "t = 18, avg_loss = 0.0889\n",
            "t = 20, avg_loss = 0.0986\n",
            "t = 22, avg_loss = 0.0675\n",
            "t = 24, avg_loss = 0.0874\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 77 / 100\n",
            "t = 2, avg_loss = 0.1017\n",
            "t = 4, avg_loss = 0.0796\n",
            "t = 6, avg_loss = 0.0425\n",
            "t = 8, avg_loss = 0.0985\n",
            "t = 10, avg_loss = 0.0992\n",
            "t = 12, avg_loss = 0.0615\n",
            "t = 14, avg_loss = 0.0503\n",
            "t = 16, avg_loss = 0.0760\n",
            "t = 18, avg_loss = 0.0657\n",
            "t = 20, avg_loss = 0.0588\n",
            "t = 22, avg_loss = 0.0622\n",
            "t = 24, avg_loss = 0.0744\n",
            "Checking accuracy on test set\n",
            "Got 359 / 400 correct (89.75)\n",
            "acc = 0.897500\n",
            "Starting epoch 78 / 100\n",
            "t = 2, avg_loss = 0.1257\n",
            "t = 4, avg_loss = 0.0893\n",
            "t = 6, avg_loss = 0.1030\n",
            "t = 8, avg_loss = 0.0678\n",
            "t = 10, avg_loss = 0.1268\n",
            "t = 12, avg_loss = 0.0613\n",
            "t = 14, avg_loss = 0.1021\n",
            "t = 16, avg_loss = 0.0701\n",
            "t = 18, avg_loss = 0.1022\n",
            "t = 20, avg_loss = 0.1079\n",
            "t = 22, avg_loss = 0.0763\n",
            "t = 24, avg_loss = 0.0661\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 79 / 100\n",
            "t = 2, avg_loss = 0.1237\n",
            "t = 4, avg_loss = 0.0725\n",
            "t = 6, avg_loss = 0.0842\n",
            "t = 8, avg_loss = 0.0634\n",
            "t = 10, avg_loss = 0.0437\n",
            "t = 12, avg_loss = 0.0951\n",
            "t = 14, avg_loss = 0.0845\n",
            "t = 16, avg_loss = 0.1120\n",
            "t = 18, avg_loss = 0.0514\n",
            "t = 20, avg_loss = 0.0606\n",
            "t = 22, avg_loss = 0.0662\n",
            "t = 24, avg_loss = 0.0838\n",
            "Checking accuracy on test set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 80 / 100\n",
            "t = 2, avg_loss = 0.0845\n",
            "t = 4, avg_loss = 0.0438\n",
            "t = 6, avg_loss = 0.0949\n",
            "t = 8, avg_loss = 0.0601\n",
            "t = 10, avg_loss = 0.0649\n",
            "t = 12, avg_loss = 0.0943\n",
            "t = 14, avg_loss = 0.0996\n",
            "t = 16, avg_loss = 0.0722\n",
            "t = 18, avg_loss = 0.0440\n",
            "t = 20, avg_loss = 0.0723\n",
            "t = 22, avg_loss = 0.0727\n",
            "t = 24, avg_loss = 0.0588\n",
            "Checking accuracy on test set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 81 / 100\n",
            "t = 2, avg_loss = 0.1227\n",
            "t = 4, avg_loss = 0.0420\n",
            "t = 6, avg_loss = 0.0328\n",
            "t = 8, avg_loss = 0.0705\n",
            "t = 10, avg_loss = 0.0358\n",
            "t = 12, avg_loss = 0.0326\n",
            "t = 14, avg_loss = 0.0422\n",
            "t = 16, avg_loss = 0.0546\n",
            "t = 18, avg_loss = 0.0936\n",
            "t = 20, avg_loss = 0.0794\n",
            "t = 22, avg_loss = 0.0448\n",
            "t = 24, avg_loss = 0.0493\n",
            "Checking accuracy on test set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 82 / 100\n",
            "t = 2, avg_loss = 0.0539\n",
            "t = 4, avg_loss = 0.0517\n",
            "t = 6, avg_loss = 0.0704\n",
            "t = 8, avg_loss = 0.0879\n",
            "t = 10, avg_loss = 0.0940\n",
            "t = 12, avg_loss = 0.0649\n",
            "t = 14, avg_loss = 0.0576\n",
            "t = 16, avg_loss = 0.0453\n",
            "t = 18, avg_loss = 0.0431\n",
            "t = 20, avg_loss = 0.0662\n",
            "t = 22, avg_loss = 0.1063\n",
            "t = 24, avg_loss = 0.0739\n",
            "Checking accuracy on test set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 83 / 100\n",
            "t = 2, avg_loss = 0.1050\n",
            "t = 4, avg_loss = 0.0564\n",
            "t = 6, avg_loss = 0.0798\n",
            "t = 8, avg_loss = 0.0371\n",
            "t = 10, avg_loss = 0.0576\n",
            "t = 12, avg_loss = 0.0515\n",
            "t = 14, avg_loss = 0.0448\n",
            "t = 16, avg_loss = 0.0580\n",
            "t = 18, avg_loss = 0.0321\n",
            "t = 20, avg_loss = 0.0522\n",
            "t = 22, avg_loss = 0.0577\n",
            "t = 24, avg_loss = 0.0647\n",
            "Checking accuracy on test set\n",
            "Got 358 / 400 correct (89.50)\n",
            "acc = 0.895000\n",
            "Starting epoch 84 / 100\n",
            "t = 2, avg_loss = 0.0910\n",
            "t = 4, avg_loss = 0.0796\n",
            "t = 6, avg_loss = 0.0538\n",
            "t = 8, avg_loss = 0.0620\n",
            "t = 10, avg_loss = 0.0901\n",
            "t = 12, avg_loss = 0.0342\n",
            "t = 14, avg_loss = 0.0835\n",
            "t = 16, avg_loss = 0.0763\n",
            "t = 18, avg_loss = 0.0563\n",
            "t = 20, avg_loss = 0.0642\n",
            "t = 22, avg_loss = 0.0778\n",
            "t = 24, avg_loss = 0.0693\n",
            "Checking accuracy on test set\n",
            "Got 358 / 400 correct (89.50)\n",
            "acc = 0.895000\n",
            "Starting epoch 85 / 100\n",
            "t = 2, avg_loss = 0.1130\n",
            "t = 4, avg_loss = 0.0480\n",
            "t = 6, avg_loss = 0.0613\n",
            "t = 8, avg_loss = 0.0581\n",
            "t = 10, avg_loss = 0.0351\n",
            "t = 12, avg_loss = 0.0566\n",
            "t = 14, avg_loss = 0.0482\n",
            "t = 16, avg_loss = 0.0550\n",
            "t = 18, avg_loss = 0.0683\n",
            "t = 20, avg_loss = 0.0565\n",
            "t = 22, avg_loss = 0.0588\n",
            "t = 24, avg_loss = 0.1385\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 86 / 100\n",
            "t = 2, avg_loss = 0.1105\n",
            "t = 4, avg_loss = 0.0490\n",
            "t = 6, avg_loss = 0.0352\n",
            "t = 8, avg_loss = 0.0451\n",
            "t = 10, avg_loss = 0.0318\n",
            "t = 12, avg_loss = 0.1079\n",
            "t = 14, avg_loss = 0.0713\n",
            "t = 16, avg_loss = 0.1369\n",
            "t = 18, avg_loss = 0.0485\n",
            "t = 20, avg_loss = 0.0889\n",
            "t = 22, avg_loss = 0.1006\n",
            "t = 24, avg_loss = 0.0534\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 87 / 100\n",
            "t = 2, avg_loss = 0.1652\n",
            "t = 4, avg_loss = 0.0525\n",
            "t = 6, avg_loss = 0.0697\n",
            "t = 8, avg_loss = 0.0630\n",
            "t = 10, avg_loss = 0.1260\n",
            "t = 12, avg_loss = 0.0650\n",
            "t = 14, avg_loss = 0.1107\n",
            "t = 16, avg_loss = 0.1222\n",
            "t = 18, avg_loss = 0.0268\n",
            "t = 20, avg_loss = 0.0534\n",
            "t = 22, avg_loss = 0.0958\n",
            "t = 24, avg_loss = 0.0642\n",
            "Checking accuracy on test set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 88 / 100\n",
            "t = 2, avg_loss = 0.1189\n",
            "t = 4, avg_loss = 0.0409\n",
            "t = 6, avg_loss = 0.0579\n",
            "t = 8, avg_loss = 0.0700\n",
            "t = 10, avg_loss = 0.0385\n",
            "t = 12, avg_loss = 0.0868\n",
            "t = 14, avg_loss = 0.0377\n",
            "t = 16, avg_loss = 0.0663\n",
            "t = 18, avg_loss = 0.1291\n",
            "t = 20, avg_loss = 0.0712\n",
            "t = 22, avg_loss = 0.0513\n",
            "t = 24, avg_loss = 0.1010\n",
            "Checking accuracy on test set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 89 / 100\n",
            "t = 2, avg_loss = 0.0927\n",
            "t = 4, avg_loss = 0.0459\n",
            "t = 6, avg_loss = 0.0735\n",
            "t = 8, avg_loss = 0.0917\n",
            "t = 10, avg_loss = 0.0524\n",
            "t = 12, avg_loss = 0.0507\n",
            "t = 14, avg_loss = 0.0452\n",
            "t = 16, avg_loss = 0.0574\n",
            "t = 18, avg_loss = 0.0603\n",
            "t = 20, avg_loss = 0.0545\n",
            "t = 22, avg_loss = 0.0835\n",
            "t = 24, avg_loss = 0.0613\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 90 / 100\n",
            "t = 2, avg_loss = 0.0823\n",
            "t = 4, avg_loss = 0.0506\n",
            "t = 6, avg_loss = 0.0826\n",
            "t = 8, avg_loss = 0.0446\n",
            "t = 10, avg_loss = 0.0579\n",
            "t = 12, avg_loss = 0.0523\n",
            "t = 14, avg_loss = 0.0689\n",
            "t = 16, avg_loss = 0.0406\n",
            "t = 18, avg_loss = 0.0543\n",
            "t = 20, avg_loss = 0.0347\n",
            "t = 22, avg_loss = 0.0608\n",
            "t = 24, avg_loss = 0.0346\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 91 / 100\n",
            "t = 2, avg_loss = 0.0765\n",
            "t = 4, avg_loss = 0.0512\n",
            "t = 6, avg_loss = 0.0388\n",
            "t = 8, avg_loss = 0.0609\n",
            "t = 10, avg_loss = 0.0617\n",
            "t = 12, avg_loss = 0.0441\n",
            "t = 14, avg_loss = 0.0385\n",
            "t = 16, avg_loss = 0.0645\n",
            "t = 18, avg_loss = 0.0468\n",
            "t = 20, avg_loss = 0.0765\n",
            "t = 22, avg_loss = 0.0515\n",
            "t = 24, avg_loss = 0.0739\n",
            "Checking accuracy on test set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 92 / 100\n",
            "t = 2, avg_loss = 0.0790\n",
            "t = 4, avg_loss = 0.0633\n",
            "t = 6, avg_loss = 0.0620\n",
            "t = 8, avg_loss = 0.0400\n",
            "t = 10, avg_loss = 0.0308\n",
            "t = 12, avg_loss = 0.0384\n",
            "t = 14, avg_loss = 0.0399\n",
            "t = 16, avg_loss = 0.0446\n",
            "t = 18, avg_loss = 0.0547\n",
            "t = 20, avg_loss = 0.0484\n",
            "t = 22, avg_loss = 0.0647\n",
            "t = 24, avg_loss = 0.1010\n",
            "Checking accuracy on test set\n",
            "Got 365 / 400 correct (91.25)\n",
            "acc = 0.912500\n",
            "Starting epoch 93 / 100\n",
            "t = 2, avg_loss = 0.0629\n",
            "t = 4, avg_loss = 0.0700\n",
            "t = 6, avg_loss = 0.0754\n",
            "t = 8, avg_loss = 0.0520\n",
            "t = 10, avg_loss = 0.1252\n",
            "t = 12, avg_loss = 0.0601\n",
            "t = 14, avg_loss = 0.0424\n",
            "t = 16, avg_loss = 0.0817\n",
            "t = 18, avg_loss = 0.0742\n",
            "t = 20, avg_loss = 0.0696\n",
            "t = 22, avg_loss = 0.0510\n",
            "t = 24, avg_loss = 0.1142\n",
            "Checking accuracy on test set\n",
            "Got 363 / 400 correct (90.75)\n",
            "acc = 0.907500\n",
            "Starting epoch 94 / 100\n",
            "t = 2, avg_loss = 0.0864\n",
            "t = 4, avg_loss = 0.0780\n",
            "t = 6, avg_loss = 0.0669\n",
            "t = 8, avg_loss = 0.1143\n",
            "t = 10, avg_loss = 0.0777\n",
            "t = 12, avg_loss = 0.0751\n",
            "t = 14, avg_loss = 0.0495\n",
            "t = 16, avg_loss = 0.1047\n",
            "t = 18, avg_loss = 0.0932\n",
            "t = 20, avg_loss = 0.0659\n",
            "t = 22, avg_loss = 0.0476\n",
            "t = 24, avg_loss = 0.0868\n",
            "Checking accuracy on test set\n",
            "Got 351 / 400 correct (87.75)\n",
            "acc = 0.877500\n",
            "Starting epoch 95 / 100\n",
            "t = 2, avg_loss = 0.0816\n",
            "t = 4, avg_loss = 0.0505\n",
            "t = 6, avg_loss = 0.0575\n",
            "t = 8, avg_loss = 0.0882\n",
            "t = 10, avg_loss = 0.0454\n",
            "t = 12, avg_loss = 0.0590\n",
            "t = 14, avg_loss = 0.0491\n",
            "t = 16, avg_loss = 0.0532\n",
            "t = 18, avg_loss = 0.0538\n",
            "t = 20, avg_loss = 0.0987\n",
            "t = 22, avg_loss = 0.0739\n",
            "t = 24, avg_loss = 0.0697\n",
            "Checking accuracy on test set\n",
            "Got 358 / 400 correct (89.50)\n",
            "acc = 0.895000\n",
            "Starting epoch 96 / 100\n",
            "t = 2, avg_loss = 0.0728\n",
            "t = 4, avg_loss = 0.0427\n",
            "t = 6, avg_loss = 0.0480\n",
            "t = 8, avg_loss = 0.0509\n",
            "t = 10, avg_loss = 0.0894\n",
            "t = 12, avg_loss = 0.0549\n",
            "t = 14, avg_loss = 0.0357\n",
            "t = 16, avg_loss = 0.0921\n",
            "t = 18, avg_loss = 0.0837\n",
            "t = 20, avg_loss = 0.0305\n",
            "t = 22, avg_loss = 0.0465\n",
            "t = 24, avg_loss = 0.0349\n",
            "Checking accuracy on test set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 97 / 100\n",
            "t = 2, avg_loss = 0.0825\n",
            "t = 4, avg_loss = 0.0581\n",
            "t = 6, avg_loss = 0.0333\n",
            "t = 8, avg_loss = 0.0699\n",
            "t = 10, avg_loss = 0.0554\n",
            "t = 12, avg_loss = 0.0301\n",
            "t = 14, avg_loss = 0.0552\n",
            "t = 16, avg_loss = 0.0400\n",
            "t = 18, avg_loss = 0.0640\n",
            "t = 20, avg_loss = 0.0730\n",
            "t = 22, avg_loss = 0.0515\n",
            "t = 24, avg_loss = 0.0881\n",
            "Checking accuracy on test set\n",
            "Got 359 / 400 correct (89.75)\n",
            "acc = 0.897500\n",
            "Starting epoch 98 / 100\n",
            "t = 2, avg_loss = 0.0819\n",
            "t = 4, avg_loss = 0.0472\n",
            "t = 6, avg_loss = 0.0603\n",
            "t = 8, avg_loss = 0.0550\n",
            "t = 10, avg_loss = 0.0503\n",
            "t = 12, avg_loss = 0.0547\n",
            "t = 14, avg_loss = 0.0409\n",
            "t = 16, avg_loss = 0.0847\n",
            "t = 18, avg_loss = 0.0591\n",
            "t = 20, avg_loss = 0.0741\n",
            "t = 22, avg_loss = 0.0751\n",
            "t = 24, avg_loss = 0.0483\n",
            "Checking accuracy on test set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 99 / 100\n",
            "t = 2, avg_loss = 0.1368\n",
            "t = 4, avg_loss = 0.0837\n",
            "t = 6, avg_loss = 0.0738\n",
            "t = 8, avg_loss = 0.0335\n",
            "t = 10, avg_loss = 0.0708\n",
            "t = 12, avg_loss = 0.0882\n",
            "t = 14, avg_loss = 0.0547\n",
            "t = 16, avg_loss = 0.0515\n",
            "t = 18, avg_loss = 0.0431\n",
            "t = 20, avg_loss = 0.0547\n",
            "t = 22, avg_loss = 0.1063\n",
            "t = 24, avg_loss = 0.0557\n",
            "Checking accuracy on test set\n",
            "Got 358 / 400 correct (89.50)\n",
            "acc = 0.895000\n",
            "Starting epoch 100 / 100\n",
            "t = 2, avg_loss = 0.0554\n",
            "t = 4, avg_loss = 0.0739\n",
            "t = 6, avg_loss = 0.0571\n",
            "t = 8, avg_loss = 0.0447\n",
            "t = 10, avg_loss = 0.0505\n",
            "t = 12, avg_loss = 0.0899\n",
            "t = 14, avg_loss = 0.0441\n",
            "t = 16, avg_loss = 0.0700\n",
            "t = 18, avg_loss = 0.0825\n",
            "t = 20, avg_loss = 0.0675\n",
            "t = 22, avg_loss = 0.0575\n",
            "t = 24, avg_loss = 0.0639\n",
            "Checking accuracy on test set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.875"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvoCj5uscUsz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_accurancy(acc_list):\n",
        "  plt.plot([i+1 for i in range((len(acc_list)))],acc_list)\n",
        "  print(\"Accurancy:\")\n",
        "  plt.show()\n",
        "\n",
        "def plot_loss_function(avg_loss_list):\n",
        "  plt.plot([print_every*batch_size*(i+1) for i in range((len(avg_loss_list)))],avg_loss_list)\n",
        "  print(\"Loss:\")\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-c6h--nUIFMx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-Co5KBw-Yy4",
        "colab_type": "code",
        "outputId": "7efecf9c-e9dd-42bd-f89c-fa8d14868429",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "plot_accurancy(acc_list)\n",
        "plot_loss_function(avg_loss_list)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accurancy:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzuX5gLEeJfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def retry_from_backup():\n",
        "  model_gpu = model_base.type(gpu_dtype)\n",
        "  print(model_gpu)\n",
        "  loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) \n",
        "\n",
        "\n",
        "\n",
        "  checkpoint = torch.load(model_backup_path)\n",
        "  model_gpu.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  epoch = checkpoint['epoch']\n",
        "  loss = checkpoint['loss']\n",
        "  acc_list = checkpoint['acc_list']\n",
        "  #avg_loss_list = checkpoint['avg_loss_list']\n",
        "  print(\"starting from epoch: \" + str(epoch))\n",
        "  print(\"starting from loss: \" + str(loss))\n",
        "  print(acc_list)\n",
        "  \n",
        "  \n",
        "  train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=27, starting_from_epoch=epoch)\n",
        "  check_accuracy(model_gpu, valid_loader)\n",
        "\n",
        "  plot_accurancy(acc_list)\n",
        "  plot_loss_function(avg_loss_list)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--rQZKqOalaJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "retry_from_backup()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}