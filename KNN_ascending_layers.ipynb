{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN_ascending_layers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOA/mjp5yNDTuYyqNN3Gagg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamilo116/KNN/blob/master/KNN_ascending_layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7ReM7FU-xs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import sys\n",
        "from random import shuffle\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms as transforms\n",
        "import timeit\n",
        "\n",
        "np.random.seed(4) \n",
        "torch.manual_seed(4) \n",
        "torch.cuda.manual_seed(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYIMZ8QyYewD",
        "colab_type": "code",
        "outputId": "2c954202-c231-4c6d-9cbc-8ab29368272d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "! git clone https://github.com/wang-chen/kervolution.git \n",
        "\n",
        "sys.path.append(\"kervolution/\")\n",
        "from kervolution import Kerv2d\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'kervolution'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects:  16% (1/6)\u001b[K\rremote: Counting objects:  33% (2/6)\u001b[K\rremote: Counting objects:  50% (3/6)\u001b[K\rremote: Counting objects:  66% (4/6)\u001b[K\rremote: Counting objects:  83% (5/6)\u001b[K\rremote: Counting objects: 100% (6/6)\u001b[K\rremote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 53 (delta 2), reused 0 (delta 0), pack-reused 47\u001b[K\n",
            "Unpacking objects: 100% (53/53), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMOHez_kHZD6",
        "colab_type": "code",
        "outputId": "32dfc277-1942-4742-bde1-0caf4251e62d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvbKg4VJXKY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LIMIT_IMAGES_NUM = 1000\n",
        "train_test_split_size = 0.2\n",
        "image_resize = (100, 100)\n",
        "batch_size = 64\n",
        "num_workers = 0\n",
        "\n",
        "out_1 = 16\n",
        "out_2 = 32\n",
        "out_3 = 64\n",
        "out_4 = 128\n",
        "\n",
        "\n",
        "k_size_1 = 3\n",
        "padding_1 = 1\n",
        "in_channels = 3\n",
        "\n",
        "kernel_size = 3\n",
        "num_epochs = 80\n",
        "\n",
        "learning_rate = 0.0001\n",
        "weight_decay = 0.05\n",
        "\n",
        "MALIGNANT_DATASET = '/content/drive/My Drive/Colab_data/malignant/malignant/'\n",
        "BENIGN_DATASET = '/content/drive/My Drive/Colab_data/benign/benign/'\n",
        "DATA_FOLDER = '/content/drive/My Drive/Colab_data/'\n",
        "model_backup_path = os.path.join(DATA_FOLDER, 'backup_model') \n",
        "TRAIN_DATA_PER_CATEGORY = 101"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b8P1NdXfVdX",
        "colab_type": "code",
        "outputId": "ec79b1ec-3152-407f-cc36-1611f8f8ab39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "benign_train_list = sorted(os.listdir(BENIGN_DATASET))[:LIMIT_IMAGES_NUM]\n",
        "malignant_train_list = sorted(os.listdir(MALIGNANT_DATASET))[:LIMIT_IMAGES_NUM]\n",
        "\n",
        "shuffle(benign_train_list)\n",
        "shuffle(malignant_train_list)\n",
        "\n",
        "test_benign_file_list = os.listdir(BENIGN_DATASET + 'test_set')[:TRAIN_DATA_PER_CATEGORY]\n",
        "test_malignant_file_list = os.listdir(MALIGNANT_DATASET + 'test_set')[:TRAIN_DATA_PER_CATEGORY]\n",
        "\n",
        "print(f\"Number of training benign {len(benign_train_list)} images\")\n",
        "print(f\"Number of training malignant {len(malignant_train_list)} images\")\n",
        "print(f\"Number of test benign {len(test_benign_file_list)} images\")\n",
        "print(f\"Number of test malignant {len(test_malignant_file_list)} images\")\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize(image_resize),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "data_transforms_test = transforms.Compose([\n",
        "    transforms.Resize(image_resize),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training benign 1000 images\n",
            "Number of training malignant 1000 images\n",
            "Number of test benign 101 images\n",
            "Number of test malignant 101 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvAAOqmVfVll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IsicDataset(Dataset):\n",
        "    def __init__(self, data_folder, labeled_data, \n",
        "                 transform=transforms.Compose([transforms.ToTensor()])):\n",
        "        self.labeled_data = labeled_data\n",
        "        self.transform = transform\n",
        "        self.data_folder = data_folder\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labeled_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        label = self.labeled_data[index]\n",
        "        if label == 0:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"benign\", \"benign\", 'test_set', index ))\n",
        "        else:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"malignant\", \"malignant\", 'test_set', index ))\n",
        "        image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "    @property\n",
        "    def labels(self):\n",
        "      return self.labeled_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e8nFBR6Yug5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "def prepare_dataset(benign_file_list, malignant_file_list, transform):\n",
        "  benign_dict = {filename: 0 for filename in benign_file_list}\n",
        "  malignant_dict = {filename: 1 for filename in malignant_file_list}\n",
        "  img_class_dict = {**benign_dict , **malignant_dict}\n",
        "  labeled_data = pd.Series(img_class_dict)\n",
        "\n",
        "  dataset = IsicDataset(DATA_FOLDER, labeled_data, transform=transform)\n",
        "  print(dataset.labels)\n",
        "  return dataset\n",
        "\n",
        "def train(model, train_loader ,loss_fn, optimizer, num_epochs=1, starting_from_epoch=1):\n",
        "    total_loss =0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
        "        model.train()\n",
        "\n",
        "        for t, (x, y) in enumerate(train_loader):\n",
        "            x_var = Variable(x.type(gpu_dtype))\n",
        "            y_var = Variable(y.type(gpu_dtype).long())\n",
        "            scores = model(x_var)\n",
        "            loss = loss_fn(scores, y_var)\n",
        "            total_loss += loss.data\n",
        "            \n",
        "            if (t + 1) % print_every == 0:\n",
        "                avg_loss = total_loss/print_every\n",
        "                print('t = %d, avg_loss = %.4f' % (t + 1, avg_loss) )\n",
        "                avg_loss_list.append(avg_loss)\n",
        "                total_loss = 0\n",
        "                \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        acc = check_accuracy(model_gpu, valid_loader)\n",
        "        print('acc = %f' %(acc))\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model_gpu.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            'acc_list': acc_list,\n",
        "            }, model_backup_path)\n",
        "            \n",
        "def check_accuracy(model, loader, datatype='train'):\n",
        "    print(f'Checking accuracy on {datatype} set')   \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval() \n",
        "    for x, y in loader:\n",
        "        x_var = Variable(x.type(gpu_dtype))\n",
        "\n",
        "        scores = model(x_var)\n",
        "        _, preds = scores.data.cpu().max(1)\n",
        "        num_correct += (preds == y).sum()\n",
        "        num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    if datatype is 'train':\n",
        "      acc_list.append(acc)\n",
        "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "    return acc\n",
        "    \n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.size()\n",
        "        return x.view(N, -1)  \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSuYqjLAYrWA",
        "colab_type": "code",
        "outputId": "1ad859b4-69eb-4f21-e53c-ac2c75d76d57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "train_dataset = prepare_dataset(benign_train_list, malignant_train_list, data_transforms)\n",
        "\n",
        "X_train, X_valid = train_test_split(train_dataset.labels, test_size=train_test_split_size)\n",
        "\n",
        "\n",
        "print(\"number of test data: \",len(test_part))\n",
        "\n",
        "print(\"number of training data: \",len(X_train))\n",
        "print(\"number of valid  data: \",len(X_valid))\n",
        "\n",
        "\n",
        "train_sampler = SubsetRandomSampler(list(X_train.index))\n",
        "valid_sampler = SubsetRandomSampler(list(X_valid.index))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ISIC_0000546.jpeg    0\n",
            "ISIC_0000856.jpeg    0\n",
            "ISIC_0002739.jpeg    0\n",
            "ISIC_0000880.jpeg    0\n",
            "ISIC_0000889.jpeg    0\n",
            "                    ..\n",
            "ISIC_0010049.jpeg    1\n",
            "ISIC_0013455.jpeg    1\n",
            "ISIC_0011627.jpeg    1\n",
            "ISIC_0010550.jpeg    1\n",
            "ISIC_0014922.jpeg    1\n",
            "Length: 2000, dtype: int64\n",
            "ISIC_0000081.jpeg    0\n",
            "ISIC_0000033.jpeg    0\n",
            "ISIC_0000023.jpeg    0\n",
            "ISIC_0000137.jpeg    0\n",
            "ISIC_0000073.jpeg    0\n",
            "                    ..\n",
            "ISIC_0025783.jpg     1\n",
            "ISIC_0026604.jpg     1\n",
            "ISIC_0026754.jpg     1\n",
            "ISIC_0026847.jpg     1\n",
            "ISIC_0027060.jpg     1\n",
            "Length: 202, dtype: int64\n",
            "number of training data:  1600\n",
            "number of valid  data:  400\n",
            "number of test data:  201\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XSwl3mRsU36",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "a3f3f626-5c14-4d7b-e2e0-d57fe24443f3"
      },
      "source": [
        "class IsicDataset(Dataset):\n",
        "    def __init__(self, data_folder, labeled_data, \n",
        "                 transform=transforms.Compose([transforms.ToTensor()])):\n",
        "        self.labeled_data = labeled_data\n",
        "        self.transform = transform\n",
        "        self.data_folder = data_folder\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labeled_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        label = self.labeled_data[index]\n",
        "        if label == 0:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"benign\", \"benign\", 'test_set', index ))\n",
        "        else:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"malignant\", \"malignant\", 'test_set', index ))\n",
        "        image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "    @property\n",
        "    def labels(self):\n",
        "      return self.labeled_data\n",
        "\n",
        "test_dataset = prepare_dataset(test_benign_file_list, test_malignant_file_list, data_transforms_test)\n",
        "test_part, _ = train_test_split(test_dataset.labels, test_size=1)\n",
        "test_sampler = SubsetRandomSampler(list(test_part.index))\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=200, sampler=test_sampler, num_workers=num_workers)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ISIC_0000081.jpeg    0\n",
            "ISIC_0000033.jpeg    0\n",
            "ISIC_0000023.jpeg    0\n",
            "ISIC_0000137.jpeg    0\n",
            "ISIC_0000073.jpeg    0\n",
            "                    ..\n",
            "ISIC_0025783.jpg     1\n",
            "ISIC_0026604.jpg     1\n",
            "ISIC_0026754.jpg     1\n",
            "ISIC_0026847.jpg     1\n",
            "ISIC_0027060.jpg     1\n",
            "Length: 202, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJ1bqboAs3xW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-gYHw0Jlbwt",
        "colab_type": "code",
        "outputId": "fc90b0b1-dce1-4a92-8cd5-d77ab6cfa71c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "print_every = 2\n",
        "gpu_dtype = torch.cuda.FloatTensor\n",
        "\n",
        "\n",
        "'''\n",
        "Kerv2d\n",
        "kervolution with following options:\n",
        "kernel_type: [linear, polynomial, gaussian, etc.]\n",
        "default is convolution:\n",
        "          kernel_type --> linear,\n",
        "balance, power, gamma is valid only when the kernel_type is specified\n",
        "if learnable_kernel = True,  they just be the initial value of learable parameters\n",
        "if learnable_kernel = False, they are the value of kernel_type's parameter\n",
        "the parameter [power] cannot be learned due to integer limitation\n",
        "dilation (int or tuple, optional): Spacing between kernel\n",
        "elements. Default: 1\n",
        "groups (int, optional): Number of blocked connections from input\n",
        "channels to output channels. Default: 1\n",
        "bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n",
        "kernel_type (str), Default: 'linear'\n",
        "learnable_kernel (bool): Learnable kernel parameters.  Default: False \n",
        "balance: 0, 1\n",
        "power: 3, 4, 5\n",
        "gamma:\n",
        "'''\n",
        "\n",
        "\n",
        "model_base = nn.Sequential( \n",
        "                nn.Conv2d(in_channels , out_1, padding= padding_1, kernel_size=k_size_1, stride=1),\n",
        "                #nn.Kerv2d(in_channels , out_1, padding=padding_1, dilation=1, groups=1, bias=True, \n",
        "                #          kernel_type='polynomial', kernel_size=k_size_1, learnable_kernel=True,\n",
        "                #          kernel_regularizer=True, stride=1, balance=1, power=3, gamma=1\n",
        "                #          ), \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_1),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_1 , out_2, padding= padding_1, kernel_size=k_size_1, stride=1), \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_2),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_2 , out_3, padding= padding_1, kernel_size=k_size_1, stride=1),  \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_3),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_3 , out_4, padding= padding_1, kernel_size=k_size_1, stride=1),  \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_4),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Dropout(0.5),\n",
        "                Flatten(),\n",
        "                nn.Linear(4608,64),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Linear(64,2)\n",
        "            )\n",
        "model_gpu = model_base.type(gpu_dtype)\n",
        "print(model_gpu)\n",
        "loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (4): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (5): ReLU(inplace=True)\n",
            "  (6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (8): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (9): ReLU(inplace=True)\n",
            "  (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (12): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (13): ReLU(inplace=True)\n",
            "  (14): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (16): Dropout(p=0.5, inplace=False)\n",
            "  (17): Flatten()\n",
            "  (18): Linear(in_features=4608, out_features=64, bias=True)\n",
            "  (19): ReLU(inplace=True)\n",
            "  (20): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgmexhBRZAK6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4f66247f-8541-43c8-ac50-2438c34cd54c"
      },
      "source": [
        "train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 1 / 80\n",
            "t = 2, avg_loss = 0.7364\n",
            "t = 4, avg_loss = 0.6349\n",
            "t = 6, avg_loss = 0.5727\n",
            "t = 8, avg_loss = 0.5266\n",
            "t = 10, avg_loss = 0.4538\n",
            "t = 12, avg_loss = 0.6129\n",
            "t = 14, avg_loss = 0.5562\n",
            "t = 16, avg_loss = 0.4727\n",
            "t = 18, avg_loss = 0.3959\n",
            "t = 20, avg_loss = 0.4298\n",
            "t = 22, avg_loss = 0.4551\n",
            "t = 24, avg_loss = 0.4896\n",
            "Checking accuracy on train set\n",
            "Got 204 / 400 correct (51.00)\n",
            "acc = 0.510000\n",
            "Starting epoch 2 / 80\n",
            "t = 2, avg_loss = 0.6686\n",
            "t = 4, avg_loss = 0.4165\n",
            "t = 6, avg_loss = 0.4003\n",
            "t = 8, avg_loss = 0.4287\n",
            "t = 10, avg_loss = 0.4229\n",
            "t = 12, avg_loss = 0.4550\n",
            "t = 14, avg_loss = 0.4709\n",
            "t = 16, avg_loss = 0.4166\n",
            "t = 18, avg_loss = 0.4142\n",
            "t = 20, avg_loss = 0.4248\n",
            "t = 22, avg_loss = 0.3622\n",
            "t = 24, avg_loss = 0.3568\n",
            "Checking accuracy on train set\n",
            "Got 248 / 400 correct (62.00)\n",
            "acc = 0.620000\n",
            "Starting epoch 3 / 80\n",
            "t = 2, avg_loss = 0.5838\n",
            "t = 4, avg_loss = 0.3781\n",
            "t = 6, avg_loss = 0.3855\n",
            "t = 8, avg_loss = 0.4315\n",
            "t = 10, avg_loss = 0.3766\n",
            "t = 12, avg_loss = 0.4060\n",
            "t = 14, avg_loss = 0.3399\n",
            "t = 16, avg_loss = 0.3162\n",
            "t = 18, avg_loss = 0.3938\n",
            "t = 20, avg_loss = 0.3579\n",
            "t = 22, avg_loss = 0.3117\n",
            "t = 24, avg_loss = 0.3621\n",
            "Checking accuracy on train set\n",
            "Got 328 / 400 correct (82.00)\n",
            "acc = 0.820000\n",
            "Starting epoch 4 / 80\n",
            "t = 2, avg_loss = 0.5696\n",
            "t = 4, avg_loss = 0.3512\n",
            "t = 6, avg_loss = 0.3161\n",
            "t = 8, avg_loss = 0.2988\n",
            "t = 10, avg_loss = 0.3038\n",
            "t = 12, avg_loss = 0.3727\n",
            "t = 14, avg_loss = 0.3345\n",
            "t = 16, avg_loss = 0.4064\n",
            "t = 18, avg_loss = 0.2703\n",
            "t = 20, avg_loss = 0.4471\n",
            "t = 22, avg_loss = 0.3567\n",
            "t = 24, avg_loss = 0.3022\n",
            "Checking accuracy on train set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 5 / 80\n",
            "t = 2, avg_loss = 0.5441\n",
            "t = 4, avg_loss = 0.3073\n",
            "t = 6, avg_loss = 0.2924\n",
            "t = 8, avg_loss = 0.2857\n",
            "t = 10, avg_loss = 0.3767\n",
            "t = 12, avg_loss = 0.3101\n",
            "t = 14, avg_loss = 0.2786\n",
            "t = 16, avg_loss = 0.3299\n",
            "t = 18, avg_loss = 0.3290\n",
            "t = 20, avg_loss = 0.3355\n",
            "t = 22, avg_loss = 0.3175\n",
            "t = 24, avg_loss = 0.3360\n",
            "Checking accuracy on train set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 6 / 80\n",
            "t = 2, avg_loss = 0.5423\n",
            "t = 4, avg_loss = 0.3474\n",
            "t = 6, avg_loss = 0.3642\n",
            "t = 8, avg_loss = 0.3456\n",
            "t = 10, avg_loss = 0.2468\n",
            "t = 12, avg_loss = 0.3686\n",
            "t = 14, avg_loss = 0.3116\n",
            "t = 16, avg_loss = 0.2987\n",
            "t = 18, avg_loss = 0.3229\n",
            "t = 20, avg_loss = 0.2866\n",
            "t = 22, avg_loss = 0.3132\n",
            "t = 24, avg_loss = 0.2448\n",
            "Checking accuracy on train set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 7 / 80\n",
            "t = 2, avg_loss = 0.4618\n",
            "t = 4, avg_loss = 0.3255\n",
            "t = 6, avg_loss = 0.2542\n",
            "t = 8, avg_loss = 0.3029\n",
            "t = 10, avg_loss = 0.3087\n",
            "t = 12, avg_loss = 0.2437\n",
            "t = 14, avg_loss = 0.2633\n",
            "t = 16, avg_loss = 0.3711\n",
            "t = 18, avg_loss = 0.3011\n",
            "t = 20, avg_loss = 0.3822\n",
            "t = 22, avg_loss = 0.2521\n",
            "t = 24, avg_loss = 0.3022\n",
            "Checking accuracy on train set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 8 / 80\n",
            "t = 2, avg_loss = 0.4414\n",
            "t = 4, avg_loss = 0.2809\n",
            "t = 6, avg_loss = 0.3064\n",
            "t = 8, avg_loss = 0.2485\n",
            "t = 10, avg_loss = 0.2583\n",
            "t = 12, avg_loss = 0.2924\n",
            "t = 14, avg_loss = 0.2835\n",
            "t = 16, avg_loss = 0.2803\n",
            "t = 18, avg_loss = 0.3004\n",
            "t = 20, avg_loss = 0.3225\n",
            "t = 22, avg_loss = 0.2279\n",
            "t = 24, avg_loss = 0.3785\n",
            "Checking accuracy on train set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 9 / 80\n",
            "t = 2, avg_loss = 0.4567\n",
            "t = 4, avg_loss = 0.2130\n",
            "t = 6, avg_loss = 0.2663\n",
            "t = 8, avg_loss = 0.2440\n",
            "t = 10, avg_loss = 0.2622\n",
            "t = 12, avg_loss = 0.3424\n",
            "t = 14, avg_loss = 0.2771\n",
            "t = 16, avg_loss = 0.2786\n",
            "t = 18, avg_loss = 0.2812\n",
            "t = 20, avg_loss = 0.2359\n",
            "t = 22, avg_loss = 0.2959\n",
            "t = 24, avg_loss = 0.2080\n",
            "Checking accuracy on train set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 10 / 80\n",
            "t = 2, avg_loss = 0.3776\n",
            "t = 4, avg_loss = 0.3164\n",
            "t = 6, avg_loss = 0.2873\n",
            "t = 8, avg_loss = 0.2250\n",
            "t = 10, avg_loss = 0.3039\n",
            "t = 12, avg_loss = 0.3343\n",
            "t = 14, avg_loss = 0.2608\n",
            "t = 16, avg_loss = 0.2364\n",
            "t = 18, avg_loss = 0.3280\n",
            "t = 20, avg_loss = 0.2366\n",
            "t = 22, avg_loss = 0.2198\n",
            "t = 24, avg_loss = 0.3135\n",
            "Checking accuracy on train set\n",
            "Got 359 / 400 correct (89.75)\n",
            "acc = 0.897500\n",
            "Starting epoch 11 / 80\n",
            "t = 2, avg_loss = 0.4439\n",
            "t = 4, avg_loss = 0.2669\n",
            "t = 6, avg_loss = 0.2329\n",
            "t = 8, avg_loss = 0.2662\n",
            "t = 10, avg_loss = 0.3004\n",
            "t = 12, avg_loss = 0.2777\n",
            "t = 14, avg_loss = 0.2724\n",
            "t = 16, avg_loss = 0.2544\n",
            "t = 18, avg_loss = 0.2125\n",
            "t = 20, avg_loss = 0.2778\n",
            "t = 22, avg_loss = 0.2083\n",
            "t = 24, avg_loss = 0.2459\n",
            "Checking accuracy on train set\n",
            "Got 359 / 400 correct (89.75)\n",
            "acc = 0.897500\n",
            "Starting epoch 12 / 80\n",
            "t = 2, avg_loss = 0.3491\n",
            "t = 4, avg_loss = 0.2726\n",
            "t = 6, avg_loss = 0.2563\n",
            "t = 8, avg_loss = 0.2207\n",
            "t = 10, avg_loss = 0.1872\n",
            "t = 12, avg_loss = 0.2836\n",
            "t = 14, avg_loss = 0.2065\n",
            "t = 16, avg_loss = 0.2550\n",
            "t = 18, avg_loss = 0.2881\n",
            "t = 20, avg_loss = 0.2733\n",
            "t = 22, avg_loss = 0.2715\n",
            "t = 24, avg_loss = 0.2642\n",
            "Checking accuracy on train set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 13 / 80\n",
            "t = 2, avg_loss = 0.3876\n",
            "t = 4, avg_loss = 0.1965\n",
            "t = 6, avg_loss = 0.2337\n",
            "t = 8, avg_loss = 0.1937\n",
            "t = 10, avg_loss = 0.1768\n",
            "t = 12, avg_loss = 0.2503\n",
            "t = 14, avg_loss = 0.2474\n",
            "t = 16, avg_loss = 0.2805\n",
            "t = 18, avg_loss = 0.2964\n",
            "t = 20, avg_loss = 0.3033\n",
            "t = 22, avg_loss = 0.1438\n",
            "t = 24, avg_loss = 0.2741\n",
            "Checking accuracy on train set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 14 / 80\n",
            "t = 2, avg_loss = 0.2774\n",
            "t = 4, avg_loss = 0.2457\n",
            "t = 6, avg_loss = 0.1714\n",
            "t = 8, avg_loss = 0.1662\n",
            "t = 10, avg_loss = 0.2798\n",
            "t = 12, avg_loss = 0.2504\n",
            "t = 14, avg_loss = 0.2220\n",
            "t = 16, avg_loss = 0.2422\n",
            "t = 18, avg_loss = 0.2027\n",
            "t = 20, avg_loss = 0.2236\n",
            "t = 22, avg_loss = 0.2601\n",
            "t = 24, avg_loss = 0.2329\n",
            "Checking accuracy on train set\n",
            "Got 360 / 400 correct (90.00)\n",
            "acc = 0.900000\n",
            "Starting epoch 15 / 80\n",
            "t = 2, avg_loss = 0.3425\n",
            "t = 4, avg_loss = 0.1672\n",
            "t = 6, avg_loss = 0.1983\n",
            "t = 8, avg_loss = 0.2124\n",
            "t = 10, avg_loss = 0.2746\n",
            "t = 12, avg_loss = 0.2678\n",
            "t = 14, avg_loss = 0.1948\n",
            "t = 16, avg_loss = 0.2376\n",
            "t = 18, avg_loss = 0.1688\n",
            "t = 20, avg_loss = 0.2606\n",
            "t = 22, avg_loss = 0.2495\n",
            "t = 24, avg_loss = 0.2203\n",
            "Checking accuracy on train set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 16 / 80\n",
            "t = 2, avg_loss = 0.3168\n",
            "t = 4, avg_loss = 0.2419\n",
            "t = 6, avg_loss = 0.3328\n",
            "t = 8, avg_loss = 0.2187\n",
            "t = 10, avg_loss = 0.1544\n",
            "t = 12, avg_loss = 0.1774\n",
            "t = 14, avg_loss = 0.2389\n",
            "t = 16, avg_loss = 0.2398\n",
            "t = 18, avg_loss = 0.1453\n",
            "t = 20, avg_loss = 0.2111\n",
            "t = 22, avg_loss = 0.3040\n",
            "t = 24, avg_loss = 0.2689\n",
            "Checking accuracy on train set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 17 / 80\n",
            "t = 2, avg_loss = 0.2930\n",
            "t = 4, avg_loss = 0.2550\n",
            "t = 6, avg_loss = 0.2397\n",
            "t = 8, avg_loss = 0.2399\n",
            "t = 10, avg_loss = 0.2062\n",
            "t = 12, avg_loss = 0.1978\n",
            "t = 14, avg_loss = 0.2263\n",
            "t = 16, avg_loss = 0.2167\n",
            "t = 18, avg_loss = 0.2448\n",
            "t = 20, avg_loss = 0.1987\n",
            "t = 22, avg_loss = 0.1958\n",
            "t = 24, avg_loss = 0.3334\n",
            "Checking accuracy on train set\n",
            "Got 351 / 400 correct (87.75)\n",
            "acc = 0.877500\n",
            "Starting epoch 18 / 80\n",
            "t = 2, avg_loss = 0.3413\n",
            "t = 4, avg_loss = 0.1841\n",
            "t = 6, avg_loss = 0.2366\n",
            "t = 8, avg_loss = 0.1625\n",
            "t = 10, avg_loss = 0.2000\n",
            "t = 12, avg_loss = 0.2001\n",
            "t = 14, avg_loss = 0.1834\n",
            "t = 16, avg_loss = 0.2019\n",
            "t = 18, avg_loss = 0.3062\n",
            "t = 20, avg_loss = 0.1238\n",
            "t = 22, avg_loss = 0.1674\n",
            "t = 24, avg_loss = 0.2148\n",
            "Checking accuracy on train set\n",
            "Got 359 / 400 correct (89.75)\n",
            "acc = 0.897500\n",
            "Starting epoch 19 / 80\n",
            "t = 2, avg_loss = 0.2547\n",
            "t = 4, avg_loss = 0.2578\n",
            "t = 6, avg_loss = 0.1852\n",
            "t = 8, avg_loss = 0.2204\n",
            "t = 10, avg_loss = 0.2339\n",
            "t = 12, avg_loss = 0.1482\n",
            "t = 14, avg_loss = 0.3131\n",
            "t = 16, avg_loss = 0.1493\n",
            "t = 18, avg_loss = 0.1930\n",
            "t = 20, avg_loss = 0.2284\n",
            "t = 22, avg_loss = 0.2440\n",
            "t = 24, avg_loss = 0.1714\n",
            "Checking accuracy on train set\n",
            "Got 362 / 400 correct (90.50)\n",
            "acc = 0.905000\n",
            "Starting epoch 20 / 80\n",
            "t = 2, avg_loss = 0.3158\n",
            "t = 4, avg_loss = 0.1432\n",
            "t = 6, avg_loss = 0.2062\n",
            "t = 8, avg_loss = 0.2305\n",
            "t = 10, avg_loss = 0.1550\n",
            "t = 12, avg_loss = 0.1609\n",
            "t = 14, avg_loss = 0.1284\n",
            "t = 16, avg_loss = 0.1701\n",
            "t = 18, avg_loss = 0.1907\n",
            "t = 20, avg_loss = 0.1526\n",
            "t = 22, avg_loss = 0.2508\n",
            "t = 24, avg_loss = 0.2114\n",
            "Checking accuracy on train set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 21 / 80\n",
            "t = 2, avg_loss = 0.2823\n",
            "t = 4, avg_loss = 0.1937\n",
            "t = 6, avg_loss = 0.1435\n",
            "t = 8, avg_loss = 0.1949\n",
            "t = 10, avg_loss = 0.1586\n",
            "t = 12, avg_loss = 0.1830\n",
            "t = 14, avg_loss = 0.2171\n",
            "t = 16, avg_loss = 0.1975\n",
            "t = 18, avg_loss = 0.1924\n",
            "t = 20, avg_loss = 0.1967\n",
            "t = 22, avg_loss = 0.1855\n",
            "t = 24, avg_loss = 0.1486\n",
            "Checking accuracy on train set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 22 / 80\n",
            "t = 2, avg_loss = 0.2696\n",
            "t = 4, avg_loss = 0.2231\n",
            "t = 6, avg_loss = 0.1395\n",
            "t = 8, avg_loss = 0.1858\n",
            "t = 10, avg_loss = 0.2256\n",
            "t = 12, avg_loss = 0.1707\n",
            "t = 14, avg_loss = 0.1025\n",
            "t = 16, avg_loss = 0.1309\n",
            "t = 18, avg_loss = 0.1898\n",
            "t = 20, avg_loss = 0.2077\n",
            "t = 22, avg_loss = 0.1406\n",
            "t = 24, avg_loss = 0.1470\n",
            "Checking accuracy on train set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 23 / 80\n",
            "t = 2, avg_loss = 0.3213\n",
            "t = 4, avg_loss = 0.1732\n",
            "t = 6, avg_loss = 0.1715\n",
            "t = 8, avg_loss = 0.1869\n",
            "t = 10, avg_loss = 0.1912\n",
            "t = 12, avg_loss = 0.2076\n",
            "t = 14, avg_loss = 0.1809\n",
            "t = 16, avg_loss = 0.1250\n",
            "t = 18, avg_loss = 0.2133\n",
            "t = 20, avg_loss = 0.2315\n",
            "t = 22, avg_loss = 0.1309\n",
            "t = 24, avg_loss = 0.1432\n",
            "Checking accuracy on train set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 24 / 80\n",
            "t = 2, avg_loss = 0.2366\n",
            "t = 4, avg_loss = 0.1323\n",
            "t = 6, avg_loss = 0.1288\n",
            "t = 8, avg_loss = 0.1850\n",
            "t = 10, avg_loss = 0.1554\n",
            "t = 12, avg_loss = 0.2541\n",
            "t = 14, avg_loss = 0.3244\n",
            "t = 16, avg_loss = 0.2117\n",
            "t = 18, avg_loss = 0.1625\n",
            "t = 20, avg_loss = 0.1716\n",
            "t = 22, avg_loss = 0.1672\n",
            "t = 24, avg_loss = 0.1833\n",
            "Checking accuracy on train set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 25 / 80\n",
            "t = 2, avg_loss = 0.2678\n",
            "t = 4, avg_loss = 0.1096\n",
            "t = 6, avg_loss = 0.1258\n",
            "t = 8, avg_loss = 0.1693\n",
            "t = 10, avg_loss = 0.1983\n",
            "t = 12, avg_loss = 0.0893\n",
            "t = 14, avg_loss = 0.1813\n",
            "t = 16, avg_loss = 0.1449\n",
            "t = 18, avg_loss = 0.2503\n",
            "t = 20, avg_loss = 0.1942\n",
            "t = 22, avg_loss = 0.2587\n",
            "t = 24, avg_loss = 0.1476\n",
            "Checking accuracy on train set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 26 / 80\n",
            "t = 2, avg_loss = 0.2329\n",
            "t = 4, avg_loss = 0.1359\n",
            "t = 6, avg_loss = 0.1967\n",
            "t = 8, avg_loss = 0.1457\n",
            "t = 10, avg_loss = 0.1395\n",
            "t = 12, avg_loss = 0.1371\n",
            "t = 14, avg_loss = 0.1886\n",
            "t = 16, avg_loss = 0.1533\n",
            "t = 18, avg_loss = 0.1381\n",
            "t = 20, avg_loss = 0.2282\n",
            "t = 22, avg_loss = 0.2163\n",
            "t = 24, avg_loss = 0.2008\n",
            "Checking accuracy on train set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 27 / 80\n",
            "t = 2, avg_loss = 0.2131\n",
            "t = 4, avg_loss = 0.1920\n",
            "t = 6, avg_loss = 0.1457\n",
            "t = 8, avg_loss = 0.1592\n",
            "t = 10, avg_loss = 0.1475\n",
            "t = 12, avg_loss = 0.1544\n",
            "t = 14, avg_loss = 0.1529\n",
            "t = 16, avg_loss = 0.1347\n",
            "t = 18, avg_loss = 0.1560\n",
            "t = 20, avg_loss = 0.1249\n",
            "t = 22, avg_loss = 0.2443\n",
            "t = 24, avg_loss = 0.1741\n",
            "Checking accuracy on train set\n",
            "Got 361 / 400 correct (90.25)\n",
            "acc = 0.902500\n",
            "Starting epoch 28 / 80\n",
            "t = 2, avg_loss = 0.2237\n",
            "t = 4, avg_loss = 0.1047\n",
            "t = 6, avg_loss = 0.1391\n",
            "t = 8, avg_loss = 0.1747\n",
            "t = 10, avg_loss = 0.2129\n",
            "t = 12, avg_loss = 0.1667\n",
            "t = 14, avg_loss = 0.2048\n",
            "t = 16, avg_loss = 0.1633\n",
            "t = 18, avg_loss = 0.1582\n",
            "t = 20, avg_loss = 0.2010\n",
            "t = 22, avg_loss = 0.1252\n",
            "t = 24, avg_loss = 0.1187\n",
            "Checking accuracy on train set\n",
            "Got 360 / 400 correct (90.00)\n",
            "acc = 0.900000\n",
            "Starting epoch 29 / 80\n",
            "t = 2, avg_loss = 0.1727\n",
            "t = 4, avg_loss = 0.1555\n",
            "t = 6, avg_loss = 0.1423\n",
            "t = 8, avg_loss = 0.2067\n",
            "t = 10, avg_loss = 0.1029\n",
            "t = 12, avg_loss = 0.1921\n",
            "t = 14, avg_loss = 0.1267\n",
            "t = 16, avg_loss = 0.2042\n",
            "t = 18, avg_loss = 0.1959\n",
            "t = 20, avg_loss = 0.2152\n",
            "t = 22, avg_loss = 0.1425\n",
            "t = 24, avg_loss = 0.2186\n",
            "Checking accuracy on train set\n",
            "Got 359 / 400 correct (89.75)\n",
            "acc = 0.897500\n",
            "Starting epoch 30 / 80\n",
            "t = 2, avg_loss = 0.2228\n",
            "t = 4, avg_loss = 0.1137\n",
            "t = 6, avg_loss = 0.1817\n",
            "t = 8, avg_loss = 0.1454\n",
            "t = 10, avg_loss = 0.1503\n",
            "t = 12, avg_loss = 0.1331\n",
            "t = 14, avg_loss = 0.1680\n",
            "t = 16, avg_loss = 0.1661\n",
            "t = 18, avg_loss = 0.1853\n",
            "t = 20, avg_loss = 0.1051\n",
            "t = 22, avg_loss = 0.1547\n",
            "t = 24, avg_loss = 0.1288\n",
            "Checking accuracy on train set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 31 / 80\n",
            "t = 2, avg_loss = 0.1754\n",
            "t = 4, avg_loss = 0.1636\n",
            "t = 6, avg_loss = 0.1250\n",
            "t = 8, avg_loss = 0.1821\n",
            "t = 10, avg_loss = 0.1517\n",
            "t = 12, avg_loss = 0.1427\n",
            "t = 14, avg_loss = 0.1491\n",
            "t = 16, avg_loss = 0.1590\n",
            "t = 18, avg_loss = 0.1133\n",
            "t = 20, avg_loss = 0.1736\n",
            "t = 22, avg_loss = 0.1039\n",
            "t = 24, avg_loss = 0.1684\n",
            "Checking accuracy on train set\n",
            "Got 360 / 400 correct (90.00)\n",
            "acc = 0.900000\n",
            "Starting epoch 32 / 80\n",
            "t = 2, avg_loss = 0.1877\n",
            "t = 4, avg_loss = 0.1914\n",
            "t = 6, avg_loss = 0.1499\n",
            "t = 8, avg_loss = 0.1271\n",
            "t = 10, avg_loss = 0.1071\n",
            "t = 12, avg_loss = 0.0901\n",
            "t = 14, avg_loss = 0.1349\n",
            "t = 16, avg_loss = 0.1556\n",
            "t = 18, avg_loss = 0.1137\n",
            "t = 20, avg_loss = 0.1224\n",
            "t = 22, avg_loss = 0.1223\n",
            "t = 24, avg_loss = 0.1375\n",
            "Checking accuracy on train set\n",
            "Got 359 / 400 correct (89.75)\n",
            "acc = 0.897500\n",
            "Starting epoch 33 / 80\n",
            "t = 2, avg_loss = 0.1146\n",
            "t = 4, avg_loss = 0.1499\n",
            "t = 6, avg_loss = 0.1042\n",
            "t = 8, avg_loss = 0.1238\n",
            "t = 10, avg_loss = 0.2272\n",
            "t = 12, avg_loss = 0.1531\n",
            "t = 14, avg_loss = 0.1322\n",
            "t = 16, avg_loss = 0.1285\n",
            "t = 18, avg_loss = 0.1543\n",
            "t = 20, avg_loss = 0.1647\n",
            "t = 22, avg_loss = 0.1234\n",
            "t = 24, avg_loss = 0.0967\n",
            "Checking accuracy on train set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 34 / 80\n",
            "t = 2, avg_loss = 0.2870\n",
            "t = 4, avg_loss = 0.1378\n",
            "t = 6, avg_loss = 0.1153\n",
            "t = 8, avg_loss = 0.1119\n",
            "t = 10, avg_loss = 0.1075\n",
            "t = 12, avg_loss = 0.1351\n",
            "t = 14, avg_loss = 0.1534\n",
            "t = 16, avg_loss = 0.1639\n",
            "t = 18, avg_loss = 0.2086\n",
            "t = 20, avg_loss = 0.1690\n",
            "t = 22, avg_loss = 0.1507\n",
            "t = 24, avg_loss = 0.1840\n",
            "Checking accuracy on train set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 35 / 80\n",
            "t = 2, avg_loss = 0.1823\n",
            "t = 4, avg_loss = 0.0687\n",
            "t = 6, avg_loss = 0.1810\n",
            "t = 8, avg_loss = 0.1497\n",
            "t = 10, avg_loss = 0.0860\n",
            "t = 12, avg_loss = 0.1785\n",
            "t = 14, avg_loss = 0.1442\n",
            "t = 16, avg_loss = 0.1379\n",
            "t = 18, avg_loss = 0.1118\n",
            "t = 20, avg_loss = 0.1628\n",
            "t = 22, avg_loss = 0.1177\n",
            "t = 24, avg_loss = 0.1145\n",
            "Checking accuracy on train set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 36 / 80\n",
            "t = 2, avg_loss = 0.1656\n",
            "t = 4, avg_loss = 0.0957\n",
            "t = 6, avg_loss = 0.1003\n",
            "t = 8, avg_loss = 0.1450\n",
            "t = 10, avg_loss = 0.1298\n",
            "t = 12, avg_loss = 0.0982\n",
            "t = 14, avg_loss = 0.1286\n",
            "t = 16, avg_loss = 0.1331\n",
            "t = 18, avg_loss = 0.0828\n",
            "t = 20, avg_loss = 0.1097\n",
            "t = 22, avg_loss = 0.0888\n",
            "t = 24, avg_loss = 0.2071\n",
            "Checking accuracy on train set\n",
            "Got 358 / 400 correct (89.50)\n",
            "acc = 0.895000\n",
            "Starting epoch 37 / 80\n",
            "t = 2, avg_loss = 0.1854\n",
            "t = 4, avg_loss = 0.1015\n",
            "t = 6, avg_loss = 0.1066\n",
            "t = 8, avg_loss = 0.1119\n",
            "t = 10, avg_loss = 0.1258\n",
            "t = 12, avg_loss = 0.1685\n",
            "t = 14, avg_loss = 0.1265\n",
            "t = 16, avg_loss = 0.2183\n",
            "t = 18, avg_loss = 0.0729\n",
            "t = 20, avg_loss = 0.1104\n",
            "t = 22, avg_loss = 0.1124\n",
            "t = 24, avg_loss = 0.0937\n",
            "Checking accuracy on train set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 38 / 80\n",
            "t = 2, avg_loss = 0.1940\n",
            "t = 4, avg_loss = 0.1753\n",
            "t = 6, avg_loss = 0.1114\n",
            "t = 8, avg_loss = 0.0723\n",
            "t = 10, avg_loss = 0.1488\n",
            "t = 12, avg_loss = 0.1646\n",
            "t = 14, avg_loss = 0.0966\n",
            "t = 16, avg_loss = 0.1175\n",
            "t = 18, avg_loss = 0.0793\n",
            "t = 20, avg_loss = 0.1383\n",
            "t = 22, avg_loss = 0.0687\n",
            "t = 24, avg_loss = 0.0765\n",
            "Checking accuracy on train set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 39 / 80\n",
            "t = 2, avg_loss = 0.1569\n",
            "t = 4, avg_loss = 0.0811\n",
            "t = 6, avg_loss = 0.1227\n",
            "t = 8, avg_loss = 0.1262\n",
            "t = 10, avg_loss = 0.1809\n",
            "t = 12, avg_loss = 0.0976\n",
            "t = 14, avg_loss = 0.1343\n",
            "t = 16, avg_loss = 0.1452\n",
            "t = 18, avg_loss = 0.1198\n",
            "t = 20, avg_loss = 0.0951\n",
            "t = 22, avg_loss = 0.0894\n",
            "t = 24, avg_loss = 0.1121\n",
            "Checking accuracy on train set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 40 / 80\n",
            "t = 2, avg_loss = 0.1419\n",
            "t = 4, avg_loss = 0.1154\n",
            "t = 6, avg_loss = 0.0831\n",
            "t = 8, avg_loss = 0.1133\n",
            "t = 10, avg_loss = 0.0724\n",
            "t = 12, avg_loss = 0.1745\n",
            "t = 14, avg_loss = 0.1044\n",
            "t = 16, avg_loss = 0.0953\n",
            "t = 18, avg_loss = 0.1017\n",
            "t = 20, avg_loss = 0.0946\n",
            "t = 22, avg_loss = 0.1708\n",
            "t = 24, avg_loss = 0.1323\n",
            "Checking accuracy on train set\n",
            "Got 359 / 400 correct (89.75)\n",
            "acc = 0.897500\n",
            "Starting epoch 41 / 80\n",
            "t = 2, avg_loss = 0.1878\n",
            "t = 4, avg_loss = 0.1141\n",
            "t = 6, avg_loss = 0.0721\n",
            "t = 8, avg_loss = 0.1197\n",
            "t = 10, avg_loss = 0.0996\n",
            "t = 12, avg_loss = 0.0873\n",
            "t = 14, avg_loss = 0.1489\n",
            "t = 16, avg_loss = 0.1013\n",
            "t = 18, avg_loss = 0.1069\n",
            "t = 20, avg_loss = 0.0968\n",
            "t = 22, avg_loss = 0.1342\n",
            "t = 24, avg_loss = 0.1056\n",
            "Checking accuracy on train set\n",
            "Got 360 / 400 correct (90.00)\n",
            "acc = 0.900000\n",
            "Starting epoch 42 / 80\n",
            "t = 2, avg_loss = 0.1253\n",
            "t = 4, avg_loss = 0.0716\n",
            "t = 6, avg_loss = 0.0975\n",
            "t = 8, avg_loss = 0.0867\n",
            "t = 10, avg_loss = 0.1119\n",
            "t = 12, avg_loss = 0.1253\n",
            "t = 14, avg_loss = 0.1549\n",
            "t = 16, avg_loss = 0.0800\n",
            "t = 18, avg_loss = 0.1430\n",
            "t = 20, avg_loss = 0.0966\n",
            "t = 22, avg_loss = 0.1274\n",
            "t = 24, avg_loss = 0.0989\n",
            "Checking accuracy on train set\n",
            "Got 360 / 400 correct (90.00)\n",
            "acc = 0.900000\n",
            "Starting epoch 43 / 80\n",
            "t = 2, avg_loss = 0.1956\n",
            "t = 4, avg_loss = 0.1182\n",
            "t = 6, avg_loss = 0.1075\n",
            "t = 8, avg_loss = 0.0620\n",
            "t = 10, avg_loss = 0.0985\n",
            "t = 12, avg_loss = 0.0972\n",
            "t = 14, avg_loss = 0.1207\n",
            "t = 16, avg_loss = 0.1159\n",
            "t = 18, avg_loss = 0.0680\n",
            "t = 20, avg_loss = 0.1332\n",
            "t = 22, avg_loss = 0.1146\n",
            "t = 24, avg_loss = 0.1155\n",
            "Checking accuracy on train set\n",
            "Got 358 / 400 correct (89.50)\n",
            "acc = 0.895000\n",
            "Starting epoch 44 / 80\n",
            "t = 2, avg_loss = 0.2211\n",
            "t = 4, avg_loss = 0.0834\n",
            "t = 6, avg_loss = 0.0961\n",
            "t = 8, avg_loss = 0.1288\n",
            "t = 10, avg_loss = 0.1608\n",
            "t = 12, avg_loss = 0.1267\n",
            "t = 14, avg_loss = 0.1132\n",
            "t = 16, avg_loss = 0.1068\n",
            "t = 18, avg_loss = 0.1417\n",
            "t = 20, avg_loss = 0.1293\n",
            "t = 22, avg_loss = 0.1292\n",
            "t = 24, avg_loss = 0.0923\n",
            "Checking accuracy on train set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 45 / 80\n",
            "t = 2, avg_loss = 0.1247\n",
            "t = 4, avg_loss = 0.1331\n",
            "t = 6, avg_loss = 0.0883\n",
            "t = 8, avg_loss = 0.1349\n",
            "t = 10, avg_loss = 0.0627\n",
            "t = 12, avg_loss = 0.0899\n",
            "t = 14, avg_loss = 0.1449\n",
            "t = 16, avg_loss = 0.1097\n",
            "t = 18, avg_loss = 0.0803\n",
            "t = 20, avg_loss = 0.0979\n",
            "t = 22, avg_loss = 0.1212\n",
            "t = 24, avg_loss = 0.0727\n",
            "Checking accuracy on train set\n",
            "Got 362 / 400 correct (90.50)\n",
            "acc = 0.905000\n",
            "Starting epoch 46 / 80\n",
            "t = 2, avg_loss = 0.1317\n",
            "t = 4, avg_loss = 0.1167\n",
            "t = 6, avg_loss = 0.1396\n",
            "t = 8, avg_loss = 0.1188\n",
            "t = 10, avg_loss = 0.1040\n",
            "t = 12, avg_loss = 0.1106\n",
            "t = 14, avg_loss = 0.1096\n",
            "t = 16, avg_loss = 0.1182\n",
            "t = 18, avg_loss = 0.0935\n",
            "t = 20, avg_loss = 0.1034\n",
            "t = 22, avg_loss = 0.0955\n",
            "t = 24, avg_loss = 0.0787\n",
            "Checking accuracy on train set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 47 / 80\n",
            "t = 2, avg_loss = 0.1673\n",
            "t = 4, avg_loss = 0.0992\n",
            "t = 6, avg_loss = 0.0842\n",
            "t = 8, avg_loss = 0.0622\n",
            "t = 10, avg_loss = 0.0765\n",
            "t = 12, avg_loss = 0.0693\n",
            "t = 14, avg_loss = 0.1037\n",
            "t = 16, avg_loss = 0.1336\n",
            "t = 18, avg_loss = 0.0654\n",
            "t = 20, avg_loss = 0.0726\n",
            "t = 22, avg_loss = 0.1038\n",
            "t = 24, avg_loss = 0.1011\n",
            "Checking accuracy on train set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 48 / 80\n",
            "t = 2, avg_loss = 0.1144\n",
            "t = 4, avg_loss = 0.1295\n",
            "t = 6, avg_loss = 0.0664\n",
            "t = 8, avg_loss = 0.0814\n",
            "t = 10, avg_loss = 0.0676\n",
            "t = 12, avg_loss = 0.1028\n",
            "t = 14, avg_loss = 0.0847\n",
            "t = 16, avg_loss = 0.1021\n",
            "t = 18, avg_loss = 0.0749\n",
            "t = 20, avg_loss = 0.0645\n",
            "t = 22, avg_loss = 0.0993\n",
            "t = 24, avg_loss = 0.0429\n",
            "Checking accuracy on train set\n",
            "Got 360 / 400 correct (90.00)\n",
            "acc = 0.900000\n",
            "Starting epoch 49 / 80\n",
            "t = 2, avg_loss = 0.1596\n",
            "t = 4, avg_loss = 0.0815\n",
            "t = 6, avg_loss = 0.1091\n",
            "t = 8, avg_loss = 0.1255\n",
            "t = 10, avg_loss = 0.1014\n",
            "t = 12, avg_loss = 0.0675\n",
            "t = 14, avg_loss = 0.0793\n",
            "t = 16, avg_loss = 0.0637\n",
            "t = 18, avg_loss = 0.0634\n",
            "t = 20, avg_loss = 0.0456\n",
            "t = 22, avg_loss = 0.0965\n",
            "t = 24, avg_loss = 0.0583\n",
            "Checking accuracy on train set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 50 / 80\n",
            "t = 2, avg_loss = 0.1727\n",
            "t = 4, avg_loss = 0.0496\n",
            "t = 6, avg_loss = 0.0713\n",
            "t = 8, avg_loss = 0.0677\n",
            "t = 10, avg_loss = 0.0853\n",
            "t = 12, avg_loss = 0.1929\n",
            "t = 14, avg_loss = 0.0978\n",
            "t = 16, avg_loss = 0.0864\n",
            "t = 18, avg_loss = 0.1034\n",
            "t = 20, avg_loss = 0.0941\n",
            "t = 22, avg_loss = 0.1620\n",
            "t = 24, avg_loss = 0.0968\n",
            "Checking accuracy on train set\n",
            "Got 361 / 400 correct (90.25)\n",
            "acc = 0.902500\n",
            "Starting epoch 51 / 80\n",
            "t = 2, avg_loss = 0.1032\n",
            "t = 4, avg_loss = 0.0781\n",
            "t = 6, avg_loss = 0.0847\n",
            "t = 8, avg_loss = 0.0668\n",
            "t = 10, avg_loss = 0.0672\n",
            "t = 12, avg_loss = 0.0758\n",
            "t = 14, avg_loss = 0.0973\n",
            "t = 16, avg_loss = 0.1023\n",
            "t = 18, avg_loss = 0.0768\n",
            "t = 20, avg_loss = 0.0877\n",
            "t = 22, avg_loss = 0.0998\n",
            "t = 24, avg_loss = 0.1068\n",
            "Checking accuracy on train set\n",
            "Got 361 / 400 correct (90.25)\n",
            "acc = 0.902500\n",
            "Starting epoch 52 / 80\n",
            "t = 2, avg_loss = 0.1070\n",
            "t = 4, avg_loss = 0.0876\n",
            "t = 6, avg_loss = 0.0779\n",
            "t = 8, avg_loss = 0.0437\n",
            "t = 10, avg_loss = 0.0732\n",
            "t = 12, avg_loss = 0.0491\n",
            "t = 14, avg_loss = 0.0555\n",
            "t = 16, avg_loss = 0.1003\n",
            "t = 18, avg_loss = 0.0758\n",
            "t = 20, avg_loss = 0.0643\n",
            "t = 22, avg_loss = 0.1046\n",
            "t = 24, avg_loss = 0.1017\n",
            "Checking accuracy on train set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 53 / 80\n",
            "t = 2, avg_loss = 0.1542\n",
            "t = 4, avg_loss = 0.0838\n",
            "t = 6, avg_loss = 0.0662\n",
            "t = 8, avg_loss = 0.0774\n",
            "t = 10, avg_loss = 0.0919\n",
            "t = 12, avg_loss = 0.1026\n",
            "t = 14, avg_loss = 0.0780\n",
            "t = 16, avg_loss = 0.0846\n",
            "t = 18, avg_loss = 0.0497\n",
            "t = 20, avg_loss = 0.0716\n",
            "t = 22, avg_loss = 0.0801\n",
            "t = 24, avg_loss = 0.1012\n",
            "Checking accuracy on train set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 54 / 80\n",
            "t = 2, avg_loss = 0.1192\n",
            "t = 4, avg_loss = 0.1084\n",
            "t = 6, avg_loss = 0.0754\n",
            "t = 8, avg_loss = 0.0806\n",
            "t = 10, avg_loss = 0.0758\n",
            "t = 12, avg_loss = 0.0550\n",
            "t = 14, avg_loss = 0.0904\n",
            "t = 16, avg_loss = 0.0987\n",
            "t = 18, avg_loss = 0.0666\n",
            "t = 20, avg_loss = 0.1252\n",
            "t = 22, avg_loss = 0.1101\n",
            "t = 24, avg_loss = 0.1086\n",
            "Checking accuracy on train set\n",
            "Got 363 / 400 correct (90.75)\n",
            "acc = 0.907500\n",
            "Starting epoch 55 / 80\n",
            "t = 2, avg_loss = 0.1362\n",
            "t = 4, avg_loss = 0.1115\n",
            "t = 6, avg_loss = 0.0897\n",
            "t = 8, avg_loss = 0.0836\n",
            "t = 10, avg_loss = 0.0592\n",
            "t = 12, avg_loss = 0.0791\n",
            "t = 14, avg_loss = 0.0545\n",
            "t = 16, avg_loss = 0.0893\n",
            "t = 18, avg_loss = 0.1216\n",
            "t = 20, avg_loss = 0.0873\n",
            "t = 22, avg_loss = 0.0624\n",
            "t = 24, avg_loss = 0.0793\n",
            "Checking accuracy on train set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 56 / 80\n",
            "t = 2, avg_loss = 0.1392\n",
            "t = 4, avg_loss = 0.0641\n",
            "t = 6, avg_loss = 0.0851\n",
            "t = 8, avg_loss = 0.1138\n",
            "t = 10, avg_loss = 0.0785\n",
            "t = 12, avg_loss = 0.0723\n",
            "t = 14, avg_loss = 0.0797\n",
            "t = 16, avg_loss = 0.0757\n",
            "t = 18, avg_loss = 0.0512\n",
            "t = 20, avg_loss = 0.0760\n",
            "t = 22, avg_loss = 0.0711\n",
            "t = 24, avg_loss = 0.1636\n",
            "Checking accuracy on train set\n",
            "Got 358 / 400 correct (89.50)\n",
            "acc = 0.895000\n",
            "Starting epoch 57 / 80\n",
            "t = 2, avg_loss = 0.1331\n",
            "t = 4, avg_loss = 0.0899\n",
            "t = 6, avg_loss = 0.1305\n",
            "t = 8, avg_loss = 0.0720\n",
            "t = 10, avg_loss = 0.0546\n",
            "t = 12, avg_loss = 0.0839\n",
            "t = 14, avg_loss = 0.0818\n",
            "t = 16, avg_loss = 0.0553\n",
            "t = 18, avg_loss = 0.0850\n",
            "t = 20, avg_loss = 0.1220\n",
            "t = 22, avg_loss = 0.0854\n",
            "t = 24, avg_loss = 0.1293\n",
            "Checking accuracy on train set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 58 / 80\n",
            "t = 2, avg_loss = 0.1474\n",
            "t = 4, avg_loss = 0.1020\n",
            "t = 6, avg_loss = 0.0836\n",
            "t = 8, avg_loss = 0.0870\n",
            "t = 10, avg_loss = 0.0923\n",
            "t = 12, avg_loss = 0.0558\n",
            "t = 14, avg_loss = 0.0963\n",
            "t = 16, avg_loss = 0.0811\n",
            "t = 18, avg_loss = 0.1466\n",
            "t = 20, avg_loss = 0.0431\n",
            "t = 22, avg_loss = 0.1313\n",
            "t = 24, avg_loss = 0.0574\n",
            "Checking accuracy on train set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 59 / 80\n",
            "t = 2, avg_loss = 0.1222\n",
            "t = 4, avg_loss = 0.0784\n",
            "t = 6, avg_loss = 0.0895\n",
            "t = 8, avg_loss = 0.0652\n",
            "t = 10, avg_loss = 0.0992\n",
            "t = 12, avg_loss = 0.0764\n",
            "t = 14, avg_loss = 0.1042\n",
            "t = 16, avg_loss = 0.0993\n",
            "t = 18, avg_loss = 0.0994\n",
            "t = 20, avg_loss = 0.1116\n",
            "t = 22, avg_loss = 0.1377\n",
            "t = 24, avg_loss = 0.1186\n",
            "Checking accuracy on train set\n",
            "Got 366 / 400 correct (91.50)\n",
            "acc = 0.915000\n",
            "Starting epoch 60 / 80\n",
            "t = 2, avg_loss = 0.1274\n",
            "t = 4, avg_loss = 0.0374\n",
            "t = 6, avg_loss = 0.0543\n",
            "t = 8, avg_loss = 0.0643\n",
            "t = 10, avg_loss = 0.1226\n",
            "t = 12, avg_loss = 0.0814\n",
            "t = 14, avg_loss = 0.0503\n",
            "t = 16, avg_loss = 0.1239\n",
            "t = 18, avg_loss = 0.0675\n",
            "t = 20, avg_loss = 0.0732\n",
            "t = 22, avg_loss = 0.0937\n",
            "t = 24, avg_loss = 0.0991\n",
            "Checking accuracy on train set\n",
            "Got 361 / 400 correct (90.25)\n",
            "acc = 0.902500\n",
            "Starting epoch 61 / 80\n",
            "t = 2, avg_loss = 0.0993\n",
            "t = 4, avg_loss = 0.0474\n",
            "t = 6, avg_loss = 0.1055\n",
            "t = 8, avg_loss = 0.0444\n",
            "t = 10, avg_loss = 0.0889\n",
            "t = 12, avg_loss = 0.0925\n",
            "t = 14, avg_loss = 0.0697\n",
            "t = 16, avg_loss = 0.0691\n",
            "t = 18, avg_loss = 0.0920\n",
            "t = 20, avg_loss = 0.0763\n",
            "t = 22, avg_loss = 0.0819\n",
            "t = 24, avg_loss = 0.0432\n",
            "Checking accuracy on train set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 62 / 80\n",
            "t = 2, avg_loss = 0.1163\n",
            "t = 4, avg_loss = 0.0754\n",
            "t = 6, avg_loss = 0.0590\n",
            "t = 8, avg_loss = 0.0783\n",
            "t = 10, avg_loss = 0.0685\n",
            "t = 12, avg_loss = 0.0573\n",
            "t = 14, avg_loss = 0.0661\n",
            "t = 16, avg_loss = 0.0858\n",
            "t = 18, avg_loss = 0.0991\n",
            "t = 20, avg_loss = 0.0837\n",
            "t = 22, avg_loss = 0.0789\n",
            "t = 24, avg_loss = 0.0648\n",
            "Checking accuracy on train set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 63 / 80\n",
            "t = 2, avg_loss = 0.1129\n",
            "t = 4, avg_loss = 0.0689\n",
            "t = 6, avg_loss = 0.0902\n",
            "t = 8, avg_loss = 0.0768\n",
            "t = 10, avg_loss = 0.0733\n",
            "t = 12, avg_loss = 0.0641\n",
            "t = 14, avg_loss = 0.0631\n",
            "t = 16, avg_loss = 0.0796\n",
            "t = 18, avg_loss = 0.0674\n",
            "t = 20, avg_loss = 0.0442\n",
            "t = 22, avg_loss = 0.0452\n",
            "t = 24, avg_loss = 0.0524\n",
            "Checking accuracy on train set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 64 / 80\n",
            "t = 2, avg_loss = 0.1132\n",
            "t = 4, avg_loss = 0.0902\n",
            "t = 6, avg_loss = 0.0416\n",
            "t = 8, avg_loss = 0.0863\n",
            "t = 10, avg_loss = 0.1031\n",
            "t = 12, avg_loss = 0.0434\n",
            "t = 14, avg_loss = 0.1120\n",
            "t = 16, avg_loss = 0.0781\n",
            "t = 18, avg_loss = 0.0881\n",
            "t = 20, avg_loss = 0.0338\n",
            "t = 22, avg_loss = 0.0780\n",
            "t = 24, avg_loss = 0.0864\n",
            "Checking accuracy on train set\n",
            "Got 361 / 400 correct (90.25)\n",
            "acc = 0.902500\n",
            "Starting epoch 65 / 80\n",
            "t = 2, avg_loss = 0.1339\n",
            "t = 4, avg_loss = 0.0313\n",
            "t = 6, avg_loss = 0.0516\n",
            "t = 8, avg_loss = 0.1506\n",
            "t = 10, avg_loss = 0.0558\n",
            "t = 12, avg_loss = 0.0598\n",
            "t = 14, avg_loss = 0.0597\n",
            "t = 16, avg_loss = 0.0667\n",
            "t = 18, avg_loss = 0.0643\n",
            "t = 20, avg_loss = 0.0636\n",
            "t = 22, avg_loss = 0.0487\n",
            "t = 24, avg_loss = 0.0827\n",
            "Checking accuracy on train set\n",
            "Got 360 / 400 correct (90.00)\n",
            "acc = 0.900000\n",
            "Starting epoch 66 / 80\n",
            "t = 2, avg_loss = 0.0893\n",
            "t = 4, avg_loss = 0.0601\n",
            "t = 6, avg_loss = 0.0461\n",
            "t = 8, avg_loss = 0.0538\n",
            "t = 10, avg_loss = 0.1098\n",
            "t = 12, avg_loss = 0.0701\n",
            "t = 14, avg_loss = 0.0614\n",
            "t = 16, avg_loss = 0.1061\n",
            "t = 18, avg_loss = 0.1036\n",
            "t = 20, avg_loss = 0.0638\n",
            "t = 22, avg_loss = 0.0487\n",
            "t = 24, avg_loss = 0.1085\n",
            "Checking accuracy on train set\n",
            "Got 363 / 400 correct (90.75)\n",
            "acc = 0.907500\n",
            "Starting epoch 67 / 80\n",
            "t = 2, avg_loss = 0.0879\n",
            "t = 4, avg_loss = 0.0713\n",
            "t = 6, avg_loss = 0.0632\n",
            "t = 8, avg_loss = 0.0739\n",
            "t = 10, avg_loss = 0.0427\n",
            "t = 12, avg_loss = 0.0602\n",
            "t = 14, avg_loss = 0.0563\n",
            "t = 16, avg_loss = 0.0595\n",
            "t = 18, avg_loss = 0.1153\n",
            "t = 20, avg_loss = 0.0223\n",
            "t = 22, avg_loss = 0.0326\n",
            "t = 24, avg_loss = 0.0579\n",
            "Checking accuracy on train set\n",
            "Got 362 / 400 correct (90.50)\n",
            "acc = 0.905000\n",
            "Starting epoch 68 / 80\n",
            "t = 2, avg_loss = 0.0942\n",
            "t = 4, avg_loss = 0.0703\n",
            "t = 6, avg_loss = 0.0740\n",
            "t = 8, avg_loss = 0.0693\n",
            "t = 10, avg_loss = 0.0532\n",
            "t = 12, avg_loss = 0.0819\n",
            "t = 14, avg_loss = 0.0931\n",
            "t = 16, avg_loss = 0.0513\n",
            "t = 18, avg_loss = 0.0617\n",
            "t = 20, avg_loss = 0.1039\n",
            "t = 22, avg_loss = 0.0465\n",
            "t = 24, avg_loss = 0.0966\n",
            "Checking accuracy on train set\n",
            "Got 361 / 400 correct (90.25)\n",
            "acc = 0.902500\n",
            "Starting epoch 69 / 80\n",
            "t = 2, avg_loss = 0.1424\n",
            "t = 4, avg_loss = 0.0903\n",
            "t = 6, avg_loss = 0.0798\n",
            "t = 8, avg_loss = 0.0486\n",
            "t = 10, avg_loss = 0.0398\n",
            "t = 12, avg_loss = 0.1702\n",
            "t = 14, avg_loss = 0.0451\n",
            "t = 16, avg_loss = 0.0897\n",
            "t = 18, avg_loss = 0.0528\n",
            "t = 20, avg_loss = 0.0763\n",
            "t = 22, avg_loss = 0.0990\n",
            "t = 24, avg_loss = 0.0618\n",
            "Checking accuracy on train set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 70 / 80\n",
            "t = 2, avg_loss = 0.1448\n",
            "t = 4, avg_loss = 0.0613\n",
            "t = 6, avg_loss = 0.0476\n",
            "t = 8, avg_loss = 0.0362\n",
            "t = 10, avg_loss = 0.0568\n",
            "t = 12, avg_loss = 0.1065\n",
            "t = 14, avg_loss = 0.0620\n",
            "t = 16, avg_loss = 0.0649\n",
            "t = 18, avg_loss = 0.0552\n",
            "t = 20, avg_loss = 0.0675\n",
            "t = 22, avg_loss = 0.0561\n",
            "t = 24, avg_loss = 0.0536\n",
            "Checking accuracy on train set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 71 / 80\n",
            "t = 2, avg_loss = 0.0764\n",
            "t = 4, avg_loss = 0.0738\n",
            "t = 6, avg_loss = 0.0439\n",
            "t = 8, avg_loss = 0.0362\n",
            "t = 10, avg_loss = 0.0337\n",
            "t = 12, avg_loss = 0.0552\n",
            "t = 14, avg_loss = 0.0472\n",
            "t = 16, avg_loss = 0.0517\n",
            "t = 18, avg_loss = 0.0682\n",
            "t = 20, avg_loss = 0.0530\n",
            "t = 22, avg_loss = 0.0691\n",
            "t = 24, avg_loss = 0.0916\n",
            "Checking accuracy on train set\n",
            "Got 364 / 400 correct (91.00)\n",
            "acc = 0.910000\n",
            "Starting epoch 72 / 80\n",
            "t = 2, avg_loss = 0.1349\n",
            "t = 4, avg_loss = 0.0963\n",
            "t = 6, avg_loss = 0.0641\n",
            "t = 8, avg_loss = 0.0340\n",
            "t = 10, avg_loss = 0.0673\n",
            "t = 12, avg_loss = 0.0244\n",
            "t = 14, avg_loss = 0.0478\n",
            "t = 16, avg_loss = 0.0677\n",
            "t = 18, avg_loss = 0.0818\n",
            "t = 20, avg_loss = 0.0728\n",
            "t = 22, avg_loss = 0.0497\n",
            "t = 24, avg_loss = 0.0622\n",
            "Checking accuracy on train set\n",
            "Got 358 / 400 correct (89.50)\n",
            "acc = 0.895000\n",
            "Starting epoch 73 / 80\n",
            "t = 2, avg_loss = 0.0853\n",
            "t = 4, avg_loss = 0.0547\n",
            "t = 6, avg_loss = 0.0641\n",
            "t = 8, avg_loss = 0.0722\n",
            "t = 10, avg_loss = 0.0822\n",
            "t = 12, avg_loss = 0.1119\n",
            "t = 14, avg_loss = 0.0562\n",
            "t = 16, avg_loss = 0.0625\n",
            "t = 18, avg_loss = 0.1035\n",
            "t = 20, avg_loss = 0.0627\n",
            "t = 22, avg_loss = 0.0549\n",
            "t = 24, avg_loss = 0.0779\n",
            "Checking accuracy on train set\n",
            "Got 358 / 400 correct (89.50)\n",
            "acc = 0.895000\n",
            "Starting epoch 74 / 80\n",
            "t = 2, avg_loss = 0.0823\n",
            "t = 4, avg_loss = 0.0582\n",
            "t = 6, avg_loss = 0.0725\n",
            "t = 8, avg_loss = 0.0668\n",
            "t = 10, avg_loss = 0.0478\n",
            "t = 12, avg_loss = 0.0629\n",
            "t = 14, avg_loss = 0.0480\n",
            "t = 16, avg_loss = 0.0846\n",
            "t = 18, avg_loss = 0.0612\n",
            "t = 20, avg_loss = 0.0733\n",
            "t = 22, avg_loss = 0.0890\n",
            "t = 24, avg_loss = 0.0794\n",
            "Checking accuracy on train set\n",
            "Got 358 / 400 correct (89.50)\n",
            "acc = 0.895000\n",
            "Starting epoch 75 / 80\n",
            "t = 2, avg_loss = 0.1427\n",
            "t = 4, avg_loss = 0.0528\n",
            "t = 6, avg_loss = 0.0662\n",
            "t = 8, avg_loss = 0.0578\n",
            "t = 10, avg_loss = 0.0612\n",
            "t = 12, avg_loss = 0.0383\n",
            "t = 14, avg_loss = 0.0571\n",
            "t = 16, avg_loss = 0.0764\n",
            "t = 18, avg_loss = 0.0711\n",
            "t = 20, avg_loss = 0.0763\n",
            "t = 22, avg_loss = 0.0948\n",
            "t = 24, avg_loss = 0.0936\n",
            "Checking accuracy on train set\n",
            "Got 364 / 400 correct (91.00)\n",
            "acc = 0.910000\n",
            "Starting epoch 76 / 80\n",
            "t = 2, avg_loss = 0.0699\n",
            "t = 4, avg_loss = 0.0744\n",
            "t = 6, avg_loss = 0.0448\n",
            "t = 8, avg_loss = 0.0516\n",
            "t = 10, avg_loss = 0.0761\n",
            "t = 12, avg_loss = 0.0625\n",
            "t = 14, avg_loss = 0.0453\n",
            "t = 16, avg_loss = 0.0541\n",
            "t = 18, avg_loss = 0.0859\n",
            "t = 20, avg_loss = 0.0681\n",
            "t = 22, avg_loss = 0.0475\n",
            "t = 24, avg_loss = 0.0597\n",
            "Checking accuracy on train set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 77 / 80\n",
            "t = 2, avg_loss = 0.0981\n",
            "t = 4, avg_loss = 0.0559\n",
            "t = 6, avg_loss = 0.0300\n",
            "t = 8, avg_loss = 0.0499\n",
            "t = 10, avg_loss = 0.0628\n",
            "t = 12, avg_loss = 0.0530\n",
            "t = 14, avg_loss = 0.0768\n",
            "t = 16, avg_loss = 0.0501\n",
            "t = 18, avg_loss = 0.0653\n",
            "t = 20, avg_loss = 0.0744\n",
            "t = 22, avg_loss = 0.0782\n",
            "t = 24, avg_loss = 0.0474\n",
            "Checking accuracy on train set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 78 / 80\n",
            "t = 2, avg_loss = 0.0567\n",
            "t = 4, avg_loss = 0.0659\n",
            "t = 6, avg_loss = 0.0531\n",
            "t = 8, avg_loss = 0.0454\n",
            "t = 10, avg_loss = 0.0627\n",
            "t = 12, avg_loss = 0.0272\n",
            "t = 14, avg_loss = 0.0535\n",
            "t = 16, avg_loss = 0.0905\n",
            "t = 18, avg_loss = 0.0474\n",
            "t = 20, avg_loss = 0.0835\n",
            "t = 22, avg_loss = 0.0567\n",
            "t = 24, avg_loss = 0.0653\n",
            "Checking accuracy on train set\n",
            "Got 362 / 400 correct (90.50)\n",
            "acc = 0.905000\n",
            "Starting epoch 79 / 80\n",
            "t = 2, avg_loss = 0.0603\n",
            "t = 4, avg_loss = 0.0611\n",
            "t = 6, avg_loss = 0.0360\n",
            "t = 8, avg_loss = 0.0480\n",
            "t = 10, avg_loss = 0.0462\n",
            "t = 12, avg_loss = 0.0497\n",
            "t = 14, avg_loss = 0.0531\n",
            "t = 16, avg_loss = 0.0657\n",
            "t = 18, avg_loss = 0.0507\n",
            "t = 20, avg_loss = 0.0615\n",
            "t = 22, avg_loss = 0.0464\n",
            "t = 24, avg_loss = 0.0560\n",
            "Checking accuracy on train set\n",
            "Got 362 / 400 correct (90.50)\n",
            "acc = 0.905000\n",
            "Starting epoch 80 / 80\n",
            "t = 2, avg_loss = 0.0702\n",
            "t = 4, avg_loss = 0.0640\n",
            "t = 6, avg_loss = 0.0524\n",
            "t = 8, avg_loss = 0.0666\n",
            "t = 10, avg_loss = 0.0605\n",
            "t = 12, avg_loss = 0.1031\n",
            "t = 14, avg_loss = 0.0699\n",
            "t = 16, avg_loss = 0.0690\n",
            "t = 18, avg_loss = 0.0656\n",
            "t = 20, avg_loss = 0.1031\n",
            "t = 22, avg_loss = 0.0860\n",
            "t = 24, avg_loss = 0.0763\n",
            "Checking accuracy on train set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwQoVQhf5tgM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "348c13ad-50bb-48f0-c0e3-ea26f9e4c58d"
      },
      "source": [
        "check_accuracy(model_gpu, test_loader, datatype='test')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking accuracy on test set\n",
            "Got 183 / 201 correct (91.04)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9104477611940298"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqsuDwnXt0zj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hS98yd9q9tn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvoCj5uscUsz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_accurancy(acc_list):\n",
        "  plt.plot([i+1 for i in range((len(acc_list)))],acc_list)\n",
        "  print(\"Accurancy:\")\n",
        "  plt.show()\n",
        "\n",
        "def plot_loss_function(avg_loss_list):\n",
        "  plt.plot([print_every*batch_size*(i+1) for i in range((len(avg_loss_list)))],avg_loss_list)\n",
        "  print(\"Loss:\")\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfNGj_aLPv3d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "b6a02184-6461-465f-deb6-cb0ec091c6da"
      },
      "source": [
        "plot_accurancy(acc_list)\n",
        "plot_loss_function(avg_loss_list)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accurancy:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzuX5gLEeJfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def retry_from_backup():\n",
        "  model_gpu = model_base.type(gpu_dtype)\n",
        "  print(model_gpu)\n",
        "  loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) \n",
        "\n",
        "\n",
        "  checkpoint = torch.load(model_backup_path)\n",
        "  model_gpu.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  epoch = checkpoint['epoch']\n",
        "  loss = checkpoint['loss']\n",
        "  acc_list = checkpoint['acc_list']\n",
        "  print(\"starting from epoch: \" + str(epoch))\n",
        "  print(\"starting from loss: \" + str(loss))\n",
        "  print(acc_list)\n",
        "  \n",
        "  \n",
        "  train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=20, starting_from_epoch=epoch)\n",
        "  check_accuracy(model_gpu, valid_loader)\n",
        "\n",
        "  plot_accurancy(acc_list)\n",
        "  plot_loss_function(avg_loss_list)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4H8kjAjB36R0",
        "colab_type": "code",
        "outputId": "4ca5d371-0b4b-4dbe-b09c-4c2296a901f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "retry_from_backup()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (4): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (5): ReLU(inplace=True)\n",
            "  (6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (8): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (9): ReLU(inplace=True)\n",
            "  (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (12): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (13): ReLU(inplace=True)\n",
            "  (14): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (16): Dropout(p=0.5, inplace=False)\n",
            "  (17): Flatten()\n",
            "  (18): Linear(in_features=4608, out_features=64, bias=True)\n",
            "  (19): ReLU(inplace=True)\n",
            "  (20): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n",
            "starting from epoch: 79\n",
            "starting from loss: tensor(0.0644, device='cuda:0', requires_grad=True)\n",
            "[0.51, 0.62, 0.82, 0.875, 0.8825, 0.8675, 0.8925, 0.89, 0.87, 0.8975, 0.8975, 0.8825, 0.87, 0.9, 0.8925, 0.89, 0.8775, 0.8975, 0.905, 0.8875, 0.88, 0.89, 0.8875, 0.89, 0.8875, 0.88, 0.9025, 0.9, 0.8975, 0.87, 0.9, 0.8975, 0.8925, 0.8875, 0.89, 0.895, 0.8825, 0.8875, 0.885, 0.8975, 0.9, 0.9, 0.895, 0.8875, 0.905, 0.8825, 0.885, 0.9, 0.8925, 0.9025, 0.9025, 0.8925, 0.89, 0.9075, 0.89, 0.895, 0.8925, 0.885, 0.915, 0.9025, 0.88, 0.8875, 0.89, 0.9025, 0.9, 0.9075, 0.905, 0.9025, 0.8875, 0.8925, 0.91, 0.895, 0.895, 0.895, 0.91, 0.8925, 0.8875, 0.905, 0.905, 0.8675]\n",
            "Starting epoch 1 / 20\n",
            "t = 2, avg_loss = 0.0611\n",
            "t = 4, avg_loss = 0.0728\n",
            "t = 6, avg_loss = 0.0508\n",
            "t = 8, avg_loss = 0.0481\n",
            "t = 10, avg_loss = 0.0770\n",
            "t = 12, avg_loss = 0.0750\n",
            "t = 14, avg_loss = 0.0371\n",
            "t = 16, avg_loss = 0.0980\n",
            "t = 18, avg_loss = 0.0313\n",
            "t = 20, avg_loss = 0.0815\n",
            "t = 22, avg_loss = 0.0348\n",
            "t = 24, avg_loss = 0.0313\n",
            "Checking accuracy on train set\n",
            "Got 360 / 400 correct (90.00)\n",
            "acc = 0.900000\n",
            "Starting epoch 2 / 20\n",
            "t = 2, avg_loss = 0.0989\n",
            "t = 4, avg_loss = 0.1213\n",
            "t = 6, avg_loss = 0.0516\n",
            "t = 8, avg_loss = 0.0525\n",
            "t = 10, avg_loss = 0.0308\n",
            "t = 12, avg_loss = 0.0800\n",
            "t = 14, avg_loss = 0.0654\n",
            "t = 16, avg_loss = 0.0668\n",
            "t = 18, avg_loss = 0.0977\n",
            "t = 20, avg_loss = 0.0545\n",
            "t = 22, avg_loss = 0.0467\n",
            "t = 24, avg_loss = 0.0570\n",
            "Checking accuracy on train set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 3 / 20\n",
            "t = 2, avg_loss = 0.0775\n",
            "t = 4, avg_loss = 0.0660\n",
            "t = 6, avg_loss = 0.0390\n",
            "t = 8, avg_loss = 0.0383\n",
            "t = 10, avg_loss = 0.0551\n",
            "t = 12, avg_loss = 0.0521\n",
            "t = 14, avg_loss = 0.0471\n",
            "t = 16, avg_loss = 0.0545\n",
            "t = 18, avg_loss = 0.0504\n",
            "t = 20, avg_loss = 0.0535\n",
            "t = 22, avg_loss = 0.0502\n",
            "t = 24, avg_loss = 0.0524\n",
            "Checking accuracy on train set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 4 / 20\n",
            "t = 2, avg_loss = 0.0906\n",
            "t = 4, avg_loss = 0.0405\n",
            "t = 6, avg_loss = 0.0363\n",
            "t = 8, avg_loss = 0.0588\n",
            "t = 10, avg_loss = 0.0270\n",
            "t = 12, avg_loss = 0.0749\n",
            "t = 14, avg_loss = 0.0479\n",
            "t = 16, avg_loss = 0.0246\n",
            "t = 18, avg_loss = 0.0526\n",
            "t = 20, avg_loss = 0.0231\n",
            "t = 22, avg_loss = 0.0474\n",
            "t = 24, avg_loss = 0.0411\n",
            "Checking accuracy on train set\n",
            "Got 362 / 400 correct (90.50)\n",
            "acc = 0.905000\n",
            "Starting epoch 5 / 20\n",
            "t = 2, avg_loss = 0.0861\n",
            "t = 4, avg_loss = 0.0484\n",
            "t = 6, avg_loss = 0.0321\n",
            "t = 8, avg_loss = 0.0215\n",
            "t = 10, avg_loss = 0.0384\n",
            "t = 12, avg_loss = 0.0293\n",
            "t = 14, avg_loss = 0.0411\n",
            "t = 16, avg_loss = 0.0679\n",
            "t = 18, avg_loss = 0.0353\n",
            "t = 20, avg_loss = 0.0232\n",
            "t = 22, avg_loss = 0.0528\n",
            "t = 24, avg_loss = 0.0840\n",
            "Checking accuracy on train set\n",
            "Got 362 / 400 correct (90.50)\n",
            "acc = 0.905000\n",
            "Starting epoch 6 / 20\n",
            "t = 2, avg_loss = 0.0639\n",
            "t = 4, avg_loss = 0.0609\n",
            "t = 6, avg_loss = 0.0528\n",
            "t = 8, avg_loss = 0.0356\n",
            "t = 10, avg_loss = 0.0431\n",
            "t = 12, avg_loss = 0.0601\n",
            "t = 14, avg_loss = 0.0745\n",
            "t = 16, avg_loss = 0.0300\n",
            "t = 18, avg_loss = 0.0523\n",
            "t = 20, avg_loss = 0.0330\n",
            "t = 22, avg_loss = 0.0434\n",
            "t = 24, avg_loss = 0.0426\n",
            "Checking accuracy on train set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 7 / 20\n",
            "t = 2, avg_loss = 0.1392\n",
            "t = 4, avg_loss = 0.0933\n",
            "t = 6, avg_loss = 0.0754\n",
            "t = 8, avg_loss = 0.0390\n",
            "t = 10, avg_loss = 0.0617\n",
            "t = 12, avg_loss = 0.1124\n",
            "t = 14, avg_loss = 0.0574\n",
            "t = 16, avg_loss = 0.0289\n",
            "t = 18, avg_loss = 0.0585\n",
            "t = 20, avg_loss = 0.0469\n",
            "t = 22, avg_loss = 0.0374\n",
            "t = 24, avg_loss = 0.0600\n",
            "Checking accuracy on train set\n",
            "Got 358 / 400 correct (89.50)\n",
            "acc = 0.895000\n",
            "Starting epoch 8 / 20\n",
            "t = 2, avg_loss = 0.0653\n",
            "t = 4, avg_loss = 0.0393\n",
            "t = 6, avg_loss = 0.0576\n",
            "t = 8, avg_loss = 0.1085\n",
            "t = 10, avg_loss = 0.0330\n",
            "t = 12, avg_loss = 0.0641\n",
            "t = 14, avg_loss = 0.0400\n",
            "t = 16, avg_loss = 0.0865\n",
            "t = 18, avg_loss = 0.1395\n",
            "t = 20, avg_loss = 0.0304\n",
            "t = 22, avg_loss = 0.0676\n",
            "t = 24, avg_loss = 0.1012\n",
            "Checking accuracy on train set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 9 / 20\n",
            "t = 2, avg_loss = 0.0702\n",
            "t = 4, avg_loss = 0.0690\n",
            "t = 6, avg_loss = 0.0732\n",
            "t = 8, avg_loss = 0.0164\n",
            "t = 10, avg_loss = 0.0559\n",
            "t = 12, avg_loss = 0.0385\n",
            "t = 14, avg_loss = 0.0510\n",
            "t = 16, avg_loss = 0.0273\n",
            "t = 18, avg_loss = 0.0477\n",
            "t = 20, avg_loss = 0.0356\n",
            "t = 22, avg_loss = 0.0272\n",
            "t = 24, avg_loss = 0.0398\n",
            "Checking accuracy on train set\n",
            "Got 362 / 400 correct (90.50)\n",
            "acc = 0.905000\n",
            "Starting epoch 10 / 20\n",
            "t = 2, avg_loss = 0.0376\n",
            "t = 4, avg_loss = 0.0526\n",
            "t = 6, avg_loss = 0.0387\n",
            "t = 8, avg_loss = 0.0514\n",
            "t = 10, avg_loss = 0.0401\n",
            "t = 12, avg_loss = 0.0450\n",
            "t = 14, avg_loss = 0.0270\n",
            "t = 16, avg_loss = 0.1151\n",
            "t = 18, avg_loss = 0.0577\n",
            "t = 20, avg_loss = 0.0501\n",
            "t = 22, avg_loss = 0.0716\n",
            "t = 24, avg_loss = 0.0635\n",
            "Checking accuracy on train set\n",
            "Got 364 / 400 correct (91.00)\n",
            "acc = 0.910000\n",
            "Starting epoch 11 / 20\n",
            "t = 2, avg_loss = 0.0662\n",
            "t = 4, avg_loss = 0.0643\n",
            "t = 6, avg_loss = 0.0718\n",
            "t = 8, avg_loss = 0.0268\n",
            "t = 10, avg_loss = 0.1215\n",
            "t = 12, avg_loss = 0.0348\n",
            "t = 14, avg_loss = 0.0415\n",
            "t = 16, avg_loss = 0.0804\n",
            "t = 18, avg_loss = 0.0397\n",
            "t = 20, avg_loss = 0.0770\n",
            "t = 22, avg_loss = 0.0781\n",
            "t = 24, avg_loss = 0.0750\n",
            "Checking accuracy on train set\n",
            "Got 366 / 400 correct (91.50)\n",
            "acc = 0.915000\n",
            "Starting epoch 12 / 20\n",
            "t = 2, avg_loss = 0.0772\n",
            "t = 4, avg_loss = 0.0283\n",
            "t = 6, avg_loss = 0.0336\n",
            "t = 8, avg_loss = 0.0431\n",
            "t = 10, avg_loss = 0.0297\n",
            "t = 12, avg_loss = 0.0386\n",
            "t = 14, avg_loss = 0.0777\n",
            "t = 16, avg_loss = 0.0621\n",
            "t = 18, avg_loss = 0.0729\n",
            "t = 20, avg_loss = 0.0544\n",
            "t = 22, avg_loss = 0.0475\n",
            "t = 24, avg_loss = 0.0594\n",
            "Checking accuracy on train set\n",
            "Got 360 / 400 correct (90.00)\n",
            "acc = 0.900000\n",
            "Starting epoch 13 / 20\n",
            "t = 2, avg_loss = 0.0418\n",
            "t = 4, avg_loss = 0.0291\n",
            "t = 6, avg_loss = 0.0608\n",
            "t = 8, avg_loss = 0.0432\n",
            "t = 10, avg_loss = 0.0365\n",
            "t = 12, avg_loss = 0.0438\n",
            "t = 14, avg_loss = 0.0212\n",
            "t = 16, avg_loss = 0.0548\n",
            "t = 18, avg_loss = 0.0582\n",
            "t = 20, avg_loss = 0.0395\n",
            "t = 22, avg_loss = 0.0327\n",
            "t = 24, avg_loss = 0.0422\n",
            "Checking accuracy on train set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 14 / 20\n",
            "t = 2, avg_loss = 0.1245\n",
            "t = 4, avg_loss = 0.1007\n",
            "t = 6, avg_loss = 0.0370\n",
            "t = 8, avg_loss = 0.0376\n",
            "t = 10, avg_loss = 0.0366\n",
            "t = 12, avg_loss = 0.0341\n",
            "t = 14, avg_loss = 0.0571\n",
            "t = 16, avg_loss = 0.0529\n",
            "t = 18, avg_loss = 0.0293\n",
            "t = 20, avg_loss = 0.0516\n",
            "t = 22, avg_loss = 0.0488\n",
            "t = 24, avg_loss = 0.0663\n",
            "Checking accuracy on train set\n",
            "Got 361 / 400 correct (90.25)\n",
            "acc = 0.902500\n",
            "Starting epoch 15 / 20\n",
            "t = 2, avg_loss = 0.0933\n",
            "t = 4, avg_loss = 0.0309\n",
            "t = 6, avg_loss = 0.0539\n",
            "t = 8, avg_loss = 0.0327\n",
            "t = 10, avg_loss = 0.0692\n",
            "t = 12, avg_loss = 0.0544\n",
            "t = 14, avg_loss = 0.0451\n",
            "t = 16, avg_loss = 0.0589\n",
            "t = 18, avg_loss = 0.0583\n",
            "t = 20, avg_loss = 0.0653\n",
            "t = 22, avg_loss = 0.1081\n",
            "t = 24, avg_loss = 0.0334\n",
            "Checking accuracy on train set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 16 / 20\n",
            "t = 2, avg_loss = 0.0394\n",
            "t = 4, avg_loss = 0.0765\n",
            "t = 6, avg_loss = 0.0403\n",
            "t = 8, avg_loss = 0.0549\n",
            "t = 10, avg_loss = 0.0390\n",
            "t = 12, avg_loss = 0.0660\n",
            "t = 14, avg_loss = 0.0410\n",
            "t = 16, avg_loss = 0.0338\n",
            "t = 18, avg_loss = 0.0414\n",
            "t = 20, avg_loss = 0.0467\n",
            "t = 22, avg_loss = 0.0512\n",
            "t = 24, avg_loss = 0.0576\n",
            "Checking accuracy on train set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 17 / 20\n",
            "t = 2, avg_loss = 0.0916\n",
            "t = 4, avg_loss = 0.0328\n",
            "t = 6, avg_loss = 0.0324\n",
            "t = 8, avg_loss = 0.0598\n",
            "t = 10, avg_loss = 0.0345\n",
            "t = 12, avg_loss = 0.0364\n",
            "t = 14, avg_loss = 0.0713\n",
            "t = 16, avg_loss = 0.0338\n",
            "t = 18, avg_loss = 0.0386\n",
            "t = 20, avg_loss = 0.0330\n",
            "t = 22, avg_loss = 0.0353\n",
            "t = 24, avg_loss = 0.0614\n",
            "Checking accuracy on train set\n",
            "Got 366 / 400 correct (91.50)\n",
            "acc = 0.915000\n",
            "Starting epoch 18 / 20\n",
            "t = 2, avg_loss = 0.0780\n",
            "t = 4, avg_loss = 0.0795\n",
            "t = 6, avg_loss = 0.0479\n",
            "t = 8, avg_loss = 0.0271\n",
            "t = 10, avg_loss = 0.0591\n",
            "t = 12, avg_loss = 0.0718\n",
            "t = 14, avg_loss = 0.0529\n",
            "t = 16, avg_loss = 0.0502\n",
            "t = 18, avg_loss = 0.0420\n",
            "t = 20, avg_loss = 0.0656\n",
            "t = 22, avg_loss = 0.0547\n",
            "t = 24, avg_loss = 0.1051\n",
            "Checking accuracy on train set\n",
            "Got 358 / 400 correct (89.50)\n",
            "acc = 0.895000\n",
            "Starting epoch 19 / 20\n",
            "t = 2, avg_loss = 0.0940\n",
            "t = 4, avg_loss = 0.0835\n",
            "t = 6, avg_loss = 0.0868\n",
            "t = 8, avg_loss = 0.0282\n",
            "t = 10, avg_loss = 0.0282\n",
            "t = 12, avg_loss = 0.0336\n",
            "t = 14, avg_loss = 0.0654\n",
            "t = 16, avg_loss = 0.0312\n",
            "t = 18, avg_loss = 0.0283\n",
            "t = 20, avg_loss = 0.0320\n",
            "t = 22, avg_loss = 0.0354\n",
            "t = 24, avg_loss = 0.1099\n",
            "Checking accuracy on train set\n",
            "Got 360 / 400 correct (90.00)\n",
            "acc = 0.900000\n",
            "Starting epoch 20 / 20\n",
            "t = 2, avg_loss = 0.0410\n",
            "t = 4, avg_loss = 0.0457\n",
            "t = 6, avg_loss = 0.0290\n",
            "t = 8, avg_loss = 0.0685\n",
            "t = 10, avg_loss = 0.0786\n",
            "t = 12, avg_loss = 0.0313\n",
            "t = 14, avg_loss = 0.0598\n",
            "t = 16, avg_loss = 0.0217\n",
            "t = 18, avg_loss = 0.0429\n",
            "t = 20, avg_loss = 0.0413\n",
            "t = 22, avg_loss = 0.0455\n",
            "t = 24, avg_loss = 0.0201\n",
            "Checking accuracy on train set\n",
            "Got 359 / 400 correct (89.75)\n",
            "acc = 0.897500\n",
            "Checking accuracy on train set\n",
            "Got 353 / 400 correct (88.25)\n",
            "Accurancy:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOxTUL8x_vCJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_accurancy(acc_list)\n",
        "plot_loss_function(avg_loss_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2w74kXFV_5Rq",
        "colab_type": "code",
        "outputId": "c286b4db-5632-4760-e745-066878bce5eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "check_accuracy(model_gpu, test_loader, datatype='test')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking accuracy on test set\n",
            "Got 186 / 201 correct (92.54)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9253731343283582"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yLr-Xot3XJ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuvpQcD--GtM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6mupJny-_au",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}