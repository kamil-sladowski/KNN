{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN_ascending_layers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPu19mL2tKYhox1qmDW6Tar",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamilo116/KNN/blob/master/KNN_ascending_layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7ReM7FU-xs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import sys\n",
        "from random import shuffle\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms as transforms\n",
        "import timeit\n",
        "\n",
        "np.random.seed(4) \n",
        "torch.manual_seed(4) \n",
        "torch.cuda.manual_seed(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYIMZ8QyYewD",
        "colab_type": "code",
        "outputId": "da1618ca-90e8-4f6e-cd02-b240eed7c5c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "! git clone https://github.com/wang-chen/kervolution.git \n",
        "\n",
        "sys.path.append(\"kervolution/\")\n",
        "from kervolution import Kerv2d\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'kervolution'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects:  16% (1/6)\u001b[K\rremote: Counting objects:  33% (2/6)\u001b[K\rremote: Counting objects:  50% (3/6)\u001b[K\rremote: Counting objects:  66% (4/6)\u001b[K\rremote: Counting objects:  83% (5/6)\u001b[K\rremote: Counting objects: 100% (6/6)\u001b[K\rremote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 53 (delta 2), reused 0 (delta 0), pack-reused 47\u001b[K\n",
            "Unpacking objects: 100% (53/53), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvbKg4VJXKY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LIMIT_IMAGES_NUM = 1000\n",
        "train_test_split_size = 0.2\n",
        "image_resize = (100, 100)\n",
        "batch_size = 64\n",
        "num_workers = 0\n",
        "\n",
        "in_channels = 3\n",
        "out_channels_1 = 16\n",
        "out_channels_2 = 32\n",
        "out_channels_3 = 64\n",
        "out_channels_4 = 128\n",
        "\n",
        "kernel_size = 3\n",
        "padding_1 = 1\n",
        "num_epochs = 80\n",
        "\n",
        "learning_rate = 0.0001\n",
        "weight_decay = 0.1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMOHez_kHZD6",
        "colab_type": "code",
        "outputId": "d3402abb-68e3-4608-a97e-df08a27f1a90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b8P1NdXfVdX",
        "colab_type": "code",
        "outputId": "3ab3b8d7-58cb-4c8f-b594-d99a824ac0f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "MALIGNANT_DATASET = '/content/drive/My Drive/Colab_data/malignant/malignant/'\n",
        "BENIGN_DATASET = '/content/drive/My Drive/Colab_data/benign/benign/'\n",
        "DATA_FOLDER = '/content/drive/My Drive/Colab_data/'\n",
        "\n",
        "\n",
        "benign_file_list = sorted(os.listdir(BENIGN_DATASET))\n",
        "malignant_file_list = sorted(os.listdir(MALIGNANT_DATASET))\n",
        "shuffle(benign_file_list)\n",
        "shuffle(malignant_file_list)\n",
        "benign_file_list = benign_file_list[:LIMIT_IMAGES_NUM]\n",
        "malignant_file_list = malignant_file_list[:LIMIT_IMAGES_NUM]\n",
        "\n",
        "print(f\"Number of benign {len(benign_file_list)} images\")\n",
        "print(f\"Number of malignant {len(malignant_file_list)} images\")\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize(image_resize),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of benign 1000 images\n",
            "Number of malignant 1000 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGDQfal74BLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "benign_dict = {filename: 0 for filename in benign_file_list}\n",
        "malignant_dict = {filename: 1 for filename in malignant_file_list}\n",
        "img_class_dict = {**benign_dict , **malignant_dict}\n",
        "labeled_data = pd.Series(img_class_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvAAOqmVfVll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IsicDataset(Dataset):\n",
        "    def __init__(self, data_folder, labeled_data, \n",
        "                 transform=transforms.Compose([transforms.ToTensor()])):\n",
        "        self.labeled_data = labeled_data\n",
        "        self.transform = transform\n",
        "        self.data_folder = data_folder\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labeled_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        label = self.labeled_data[index]\n",
        "        if label == 0:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"benign\", \"benign\", index ))\n",
        "        else:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"malignant\", \"malignant\", index ))\n",
        "        image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "    @property\n",
        "    def labels(self):\n",
        "      return self.labeled_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSuYqjLAYrWA",
        "colab_type": "code",
        "outputId": "df086514-a860-4ea6-cd06-4f1efa5e3ee7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        }
      },
      "source": [
        " \n",
        "dataset = IsicDataset(DATA_FOLDER, labeled_data, transform=data_transforms)\n",
        "print(dataset.labels)\n",
        "\n",
        "X_train, X_test = train_test_split(dataset.labels, test_size=train_test_split_size)\n",
        "print(\"number of training data: \",len(X_train))\n",
        "print(\"number of testing  data: \",len(X_test))\n",
        "\n",
        "train_sampler = SubsetRandomSampler(list(X_train.index))\n",
        "valid_sampler = SubsetRandomSampler(list(X_test.index))\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ISIC_0002439.jpeg    0\n",
            "ISIC_0000099.jpeg    0\n",
            "ISIC_0002553.jpeg    0\n",
            "ISIC_0000838.jpeg    0\n",
            "ISIC_0002674.jpeg    0\n",
            "                    ..\n",
            "ISIC_0011130.jpeg    1\n",
            "ISIC_0000310.jpeg    1\n",
            "ISIC_0009993.jpeg    1\n",
            "ISIC_0000287.jpeg    1\n",
            "ISIC_0011529.jpeg    1\n",
            "Length: 2000, dtype: int64\n",
            "number of training data:  1600\n",
            "number of testing  data:  400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e8nFBR6Yug5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "def train(model, train_loader ,loss_fn, optimizer, num_epochs = 1):\n",
        "    total_loss =0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
        "        model.train()\n",
        "\n",
        "        for t, (x, y) in enumerate(train_loader):\n",
        "            x_var = Variable(x.type(gpu_dtype))\n",
        "            y_var = Variable(y.type(gpu_dtype).long())\n",
        "            scores = model(x_var)\n",
        "            loss = loss_fn(scores, y_var)\n",
        "            total_loss += loss.data\n",
        "            \n",
        "            if (t + 1) % print_every == 0:\n",
        "                avg_loss = total_loss/print_every\n",
        "                print('t = %d, avg_loss = %.4f' % (t + 1, avg_loss) )\n",
        "                avg_loss_list.append(avg_loss)\n",
        "                total_loss = 0\n",
        "                \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        acc = check_accuracy(model_gpu, valid_loader)\n",
        "        print('acc = %f' %(acc))\n",
        "            \n",
        "def check_accuracy(model, loader):\n",
        "    print('Checking accuracy on test set')   \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval() \n",
        "    for x, y in loader:\n",
        "        x_var = Variable(x.type(gpu_dtype))\n",
        "\n",
        "        scores = model(x_var)\n",
        "        _, preds = scores.data.cpu().max(1)\n",
        "        num_correct += (preds == y).sum()\n",
        "        num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    acc_list.append(acc)\n",
        "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "    return acc\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggvpMu36Yw2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.size()\n",
        "        return x.view(N, -1)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgmexhBRZAK6",
        "colab_type": "code",
        "outputId": "0a22c1a9-961c-44c6-f787-f1f7eeb0e3fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "gpu_dtype = torch.cuda.FloatTensor\n",
        "\n",
        "print_every = 2\n",
        "\n",
        "\n",
        "'''\n",
        "Kerv2d\n",
        "kervolution with following options:\n",
        "kernel_type: [linear, polynomial, gaussian, etc.]\n",
        "default is convolution:\n",
        "          kernel_type --> linear,\n",
        "balance, power, gamma is valid only when the kernel_type is specified\n",
        "if learnable_kernel = True,  they just be the initial value of learable parameters\n",
        "if learnable_kernel = False, they are the value of kernel_type's parameter\n",
        "the parameter [power] cannot be learned due to integer limitation\n",
        "dilation (int or tuple, optional): Spacing between kernel\n",
        "elements. Default: 1\n",
        "groups (int, optional): Number of blocked connections from input\n",
        "channels to output channels. Default: 1\n",
        "bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n",
        "kernel_type (str), Default: 'linear'\n",
        "learnable_kernel (bool): Learnable kernel parameters.  Default: False \n",
        "balance: 0, 1\n",
        "power: 3, 4, 5\n",
        "gamma:\n",
        "'''\n",
        "\n",
        "\n",
        "model_base = nn.Sequential( \n",
        "                nn.Kerv2d(in_channels , out_channels_1, padding=padding_1, dilation=1, groups=1, bias=True, \n",
        "                          kernel_type='polynomial', kernel_size=kernel_size, learnable_kernel=True,\n",
        "                          kernel_regularizer=True, stride=1, balance=1, power=3, gamma=1\n",
        "                          ),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_channels_1),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_1 , out_channels_2, padding= padding_1, kernel_size=kernel_size, stride=1), \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_channels_2),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_2 , out_channels_3, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_channels_3),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_3 , out_channels_4, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_channels_4),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Dropout(0.5),\n",
        "                Flatten(),\n",
        "                nn.Linear(4608,64),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Linear(64,2)\n",
        "            )\n",
        "model_gpu = model_base.type(gpu_dtype)\n",
        "print(model_gpu)\n",
        "loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) \n",
        "\n",
        "\n",
        "train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs)\n",
        "check_accuracy(model_gpu, valid_loader)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Kerv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (4): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (5): ReLU(inplace=True)\n",
            "  (6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (8): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (9): ReLU(inplace=True)\n",
            "  (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (12): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (13): ReLU(inplace=True)\n",
            "  (14): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (16): Dropout(p=0.5, inplace=False)\n",
            "  (17): Flatten()\n",
            "  (18): Linear(in_features=4608, out_features=64, bias=True)\n",
            "  (19): ReLU(inplace=True)\n",
            "  (20): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n",
            "Starting epoch 1 / 80\n",
            "t = 2, avg_loss = 0.7515\n",
            "t = 4, avg_loss = 0.6069\n",
            "t = 6, avg_loss = 0.6018\n",
            "t = 8, avg_loss = 0.5088\n",
            "t = 10, avg_loss = 0.5591\n",
            "t = 12, avg_loss = 0.5419\n",
            "t = 14, avg_loss = 0.5375\n",
            "t = 16, avg_loss = 0.4445\n",
            "t = 18, avg_loss = 0.4748\n",
            "t = 20, avg_loss = 0.4201\n",
            "t = 22, avg_loss = 0.4429\n",
            "t = 24, avg_loss = 0.4538\n",
            "Checking accuracy on test set\n",
            "Got 237 / 400 correct (59.25)\n",
            "acc = 0.592500\n",
            "Starting epoch 2 / 80\n",
            "t = 2, avg_loss = 0.7007\n",
            "t = 4, avg_loss = 0.4684\n",
            "t = 6, avg_loss = 0.3932\n",
            "t = 8, avg_loss = 0.3783\n",
            "t = 10, avg_loss = 0.4053\n",
            "t = 12, avg_loss = 0.3691\n",
            "t = 14, avg_loss = 0.3213\n",
            "t = 16, avg_loss = 0.5505\n",
            "t = 18, avg_loss = 0.3990\n",
            "t = 20, avg_loss = 0.3839\n",
            "t = 22, avg_loss = 0.4974\n",
            "t = 24, avg_loss = 0.3181\n",
            "Checking accuracy on test set\n",
            "Got 340 / 400 correct (85.00)\n",
            "acc = 0.850000\n",
            "Starting epoch 3 / 80\n",
            "t = 2, avg_loss = 0.5714\n",
            "t = 4, avg_loss = 0.3769\n",
            "t = 6, avg_loss = 0.3978\n",
            "t = 8, avg_loss = 0.2907\n",
            "t = 10, avg_loss = 0.4057\n",
            "t = 12, avg_loss = 0.3559\n",
            "t = 14, avg_loss = 0.4021\n",
            "t = 16, avg_loss = 0.3266\n",
            "t = 18, avg_loss = 0.4156\n",
            "t = 20, avg_loss = 0.3443\n",
            "t = 22, avg_loss = 0.3332\n",
            "t = 24, avg_loss = 0.2693\n",
            "Checking accuracy on test set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 4 / 80\n",
            "t = 2, avg_loss = 0.5108\n",
            "t = 4, avg_loss = 0.3433\n",
            "t = 6, avg_loss = 0.3966\n",
            "t = 8, avg_loss = 0.3090\n",
            "t = 10, avg_loss = 0.3816\n",
            "t = 12, avg_loss = 0.3296\n",
            "t = 14, avg_loss = 0.3013\n",
            "t = 16, avg_loss = 0.2827\n",
            "t = 18, avg_loss = 0.3369\n",
            "t = 20, avg_loss = 0.2905\n",
            "t = 22, avg_loss = 0.3179\n",
            "t = 24, avg_loss = 0.4381\n",
            "Checking accuracy on test set\n",
            "Got 351 / 400 correct (87.75)\n",
            "acc = 0.877500\n",
            "Starting epoch 5 / 80\n",
            "t = 2, avg_loss = 0.5333\n",
            "t = 4, avg_loss = 0.2564\n",
            "t = 6, avg_loss = 0.3382\n",
            "t = 8, avg_loss = 0.2634\n",
            "t = 10, avg_loss = 0.2592\n",
            "t = 12, avg_loss = 0.3397\n",
            "t = 14, avg_loss = 0.2881\n",
            "t = 16, avg_loss = 0.3508\n",
            "t = 18, avg_loss = 0.2973\n",
            "t = 20, avg_loss = 0.3457\n",
            "t = 22, avg_loss = 0.2656\n",
            "t = 24, avg_loss = 0.3638\n",
            "Checking accuracy on test set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 6 / 80\n",
            "t = 2, avg_loss = 0.5046\n",
            "t = 4, avg_loss = 0.2708\n",
            "t = 6, avg_loss = 0.2557\n",
            "t = 8, avg_loss = 0.3363\n",
            "t = 10, avg_loss = 0.2762\n",
            "t = 12, avg_loss = 0.2580\n",
            "t = 14, avg_loss = 0.2610\n",
            "t = 16, avg_loss = 0.2830\n",
            "t = 18, avg_loss = 0.2614\n",
            "t = 20, avg_loss = 0.3497\n",
            "t = 22, avg_loss = 0.3313\n",
            "t = 24, avg_loss = 0.2865\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 7 / 80\n",
            "t = 2, avg_loss = 0.4069\n",
            "t = 4, avg_loss = 0.3422\n",
            "t = 6, avg_loss = 0.2930\n",
            "t = 8, avg_loss = 0.3353\n",
            "t = 10, avg_loss = 0.2819\n",
            "t = 12, avg_loss = 0.2265\n",
            "t = 14, avg_loss = 0.3006\n",
            "t = 16, avg_loss = 0.1996\n",
            "t = 18, avg_loss = 0.2508\n",
            "t = 20, avg_loss = 0.2783\n",
            "t = 22, avg_loss = 0.3314\n",
            "t = 24, avg_loss = 0.3442\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 8 / 80\n",
            "t = 2, avg_loss = 0.4215\n",
            "t = 4, avg_loss = 0.1924\n",
            "t = 6, avg_loss = 0.2798\n",
            "t = 8, avg_loss = 0.2956\n",
            "t = 10, avg_loss = 0.2295\n",
            "t = 12, avg_loss = 0.4179\n",
            "t = 14, avg_loss = 0.2823\n",
            "t = 16, avg_loss = 0.1956\n",
            "t = 18, avg_loss = 0.3540\n",
            "t = 20, avg_loss = 0.2607\n",
            "t = 22, avg_loss = 0.2267\n",
            "t = 24, avg_loss = 0.3814\n",
            "Checking accuracy on test set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 9 / 80\n",
            "t = 2, avg_loss = 0.4109\n",
            "t = 4, avg_loss = 0.3046\n",
            "t = 6, avg_loss = 0.2196\n",
            "t = 8, avg_loss = 0.2354\n",
            "t = 10, avg_loss = 0.2540\n",
            "t = 12, avg_loss = 0.2213\n",
            "t = 14, avg_loss = 0.2510\n",
            "t = 16, avg_loss = 0.2880\n",
            "t = 18, avg_loss = 0.1907\n",
            "t = 20, avg_loss = 0.2367\n",
            "t = 22, avg_loss = 0.2722\n",
            "t = 24, avg_loss = 0.3707\n",
            "Checking accuracy on test set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 10 / 80\n",
            "t = 2, avg_loss = 0.4099\n",
            "t = 4, avg_loss = 0.2534\n",
            "t = 6, avg_loss = 0.3101\n",
            "t = 8, avg_loss = 0.2435\n",
            "t = 10, avg_loss = 0.3253\n",
            "t = 12, avg_loss = 0.2329\n",
            "t = 14, avg_loss = 0.2483\n",
            "t = 16, avg_loss = 0.3527\n",
            "t = 18, avg_loss = 0.2292\n",
            "t = 20, avg_loss = 0.3021\n",
            "t = 22, avg_loss = 0.2888\n",
            "t = 24, avg_loss = 0.2991\n",
            "Checking accuracy on test set\n",
            "Got 358 / 400 correct (89.50)\n",
            "acc = 0.895000\n",
            "Starting epoch 11 / 80\n",
            "t = 2, avg_loss = 0.4449\n",
            "t = 4, avg_loss = 0.2367\n",
            "t = 6, avg_loss = 0.1899\n",
            "t = 8, avg_loss = 0.2368\n",
            "t = 10, avg_loss = 0.2795\n",
            "t = 12, avg_loss = 0.3211\n",
            "t = 14, avg_loss = 0.3029\n",
            "t = 16, avg_loss = 0.2262\n",
            "t = 18, avg_loss = 0.3098\n",
            "t = 20, avg_loss = 0.3467\n",
            "t = 22, avg_loss = 0.2844\n",
            "t = 24, avg_loss = 0.1853\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 12 / 80\n",
            "t = 2, avg_loss = 0.4516\n",
            "t = 4, avg_loss = 0.2263\n",
            "t = 6, avg_loss = 0.2253\n",
            "t = 8, avg_loss = 0.2785\n",
            "t = 10, avg_loss = 0.2217\n",
            "t = 12, avg_loss = 0.2420\n",
            "t = 14, avg_loss = 0.2608\n",
            "t = 16, avg_loss = 0.2800\n",
            "t = 18, avg_loss = 0.1805\n",
            "t = 20, avg_loss = 0.2183\n",
            "t = 22, avg_loss = 0.2663\n",
            "t = 24, avg_loss = 0.2158\n",
            "Checking accuracy on test set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 13 / 80\n",
            "t = 2, avg_loss = 0.3386\n",
            "t = 4, avg_loss = 0.2779\n",
            "t = 6, avg_loss = 0.3153\n",
            "t = 8, avg_loss = 0.2003\n",
            "t = 10, avg_loss = 0.1753\n",
            "t = 12, avg_loss = 0.1906\n",
            "t = 14, avg_loss = 0.3079\n",
            "t = 16, avg_loss = 0.2991\n",
            "t = 18, avg_loss = 0.2885\n",
            "t = 20, avg_loss = 0.2132\n",
            "t = 22, avg_loss = 0.3057\n",
            "t = 24, avg_loss = 0.2624\n",
            "Checking accuracy on test set\n",
            "Got 359 / 400 correct (89.75)\n",
            "acc = 0.897500\n",
            "Starting epoch 14 / 80\n",
            "t = 2, avg_loss = 0.2906\n",
            "t = 4, avg_loss = 0.1642\n",
            "t = 6, avg_loss = 0.2390\n",
            "t = 8, avg_loss = 0.2175\n",
            "t = 10, avg_loss = 0.2667\n",
            "t = 12, avg_loss = 0.2678\n",
            "t = 14, avg_loss = 0.2310\n",
            "t = 16, avg_loss = 0.2334\n",
            "t = 18, avg_loss = 0.2155\n",
            "t = 20, avg_loss = 0.2022\n",
            "t = 22, avg_loss = 0.2394\n",
            "t = 24, avg_loss = 0.2222\n",
            "Checking accuracy on test set\n",
            "Got 366 / 400 correct (91.50)\n",
            "acc = 0.915000\n",
            "Starting epoch 15 / 80\n",
            "t = 2, avg_loss = 0.2686\n",
            "t = 4, avg_loss = 0.2984\n",
            "t = 6, avg_loss = 0.1915\n",
            "t = 8, avg_loss = 0.2216\n",
            "t = 10, avg_loss = 0.2283\n",
            "t = 12, avg_loss = 0.2133\n",
            "t = 14, avg_loss = 0.2073\n",
            "t = 16, avg_loss = 0.1899\n",
            "t = 18, avg_loss = 0.2164\n",
            "t = 20, avg_loss = 0.2165\n",
            "t = 22, avg_loss = 0.2493\n",
            "t = 24, avg_loss = 0.2013\n",
            "Checking accuracy on test set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 16 / 80\n",
            "t = 2, avg_loss = 0.3903\n",
            "t = 4, avg_loss = 0.2175\n",
            "t = 6, avg_loss = 0.2141\n",
            "t = 8, avg_loss = 0.2514\n",
            "t = 10, avg_loss = 0.1745\n",
            "t = 12, avg_loss = 0.2467\n",
            "t = 14, avg_loss = 0.1642\n",
            "t = 16, avg_loss = 0.3097\n",
            "t = 18, avg_loss = 0.2104\n",
            "t = 20, avg_loss = 0.2158\n",
            "t = 22, avg_loss = 0.2878\n",
            "t = 24, avg_loss = 0.3768\n",
            "Checking accuracy on test set\n",
            "Got 360 / 400 correct (90.00)\n",
            "acc = 0.900000\n",
            "Starting epoch 17 / 80\n",
            "t = 2, avg_loss = 0.2740\n",
            "t = 4, avg_loss = 0.2064\n",
            "t = 6, avg_loss = 0.2019\n",
            "t = 8, avg_loss = 0.1664\n",
            "t = 10, avg_loss = 0.1883\n",
            "t = 12, avg_loss = 0.1901\n",
            "t = 14, avg_loss = 0.2671\n",
            "t = 16, avg_loss = 0.2453\n",
            "t = 18, avg_loss = 0.2058\n",
            "t = 20, avg_loss = 0.1714\n",
            "t = 22, avg_loss = 0.2605\n",
            "t = 24, avg_loss = 0.2976\n",
            "Checking accuracy on test set\n",
            "Got 361 / 400 correct (90.25)\n",
            "acc = 0.902500\n",
            "Starting epoch 18 / 80\n",
            "t = 2, avg_loss = 0.2642\n",
            "t = 4, avg_loss = 0.2440\n",
            "t = 6, avg_loss = 0.1860\n",
            "t = 8, avg_loss = 0.1926\n",
            "t = 10, avg_loss = 0.2128\n",
            "t = 12, avg_loss = 0.2066\n",
            "t = 14, avg_loss = 0.1070\n",
            "t = 16, avg_loss = 0.2149\n",
            "t = 18, avg_loss = 0.2320\n",
            "t = 20, avg_loss = 0.1959\n",
            "t = 22, avg_loss = 0.2629\n",
            "t = 24, avg_loss = 0.2201\n",
            "Checking accuracy on test set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 19 / 80\n",
            "t = 2, avg_loss = 0.4949\n",
            "t = 4, avg_loss = 0.2311\n",
            "t = 6, avg_loss = 0.1516\n",
            "t = 8, avg_loss = 0.1336\n",
            "t = 10, avg_loss = 0.2394\n",
            "t = 12, avg_loss = 0.2299\n",
            "t = 14, avg_loss = 0.1980\n",
            "t = 16, avg_loss = 0.2087\n",
            "t = 18, avg_loss = 0.1978\n",
            "t = 20, avg_loss = 0.2990\n",
            "t = 22, avg_loss = 0.1964\n",
            "t = 24, avg_loss = 0.1732\n",
            "Checking accuracy on test set\n",
            "Got 362 / 400 correct (90.50)\n",
            "acc = 0.905000\n",
            "Starting epoch 20 / 80\n",
            "t = 2, avg_loss = 0.3226\n",
            "t = 4, avg_loss = 0.1607\n",
            "t = 6, avg_loss = 0.2477\n",
            "t = 8, avg_loss = 0.2404\n",
            "t = 10, avg_loss = 0.2081\n",
            "t = 12, avg_loss = 0.1844\n",
            "t = 14, avg_loss = 0.1807\n",
            "t = 16, avg_loss = 0.1527\n",
            "t = 18, avg_loss = 0.1378\n",
            "t = 20, avg_loss = 0.2495\n",
            "t = 22, avg_loss = 0.1617\n",
            "t = 24, avg_loss = 0.2110\n",
            "Checking accuracy on test set\n",
            "Got 360 / 400 correct (90.00)\n",
            "acc = 0.900000\n",
            "Starting epoch 21 / 80\n",
            "t = 2, avg_loss = 0.2765\n",
            "t = 4, avg_loss = 0.1812\n",
            "t = 6, avg_loss = 0.1960\n",
            "t = 8, avg_loss = 0.2362\n",
            "t = 10, avg_loss = 0.1304\n",
            "t = 12, avg_loss = 0.2184\n",
            "t = 14, avg_loss = 0.1942\n",
            "t = 16, avg_loss = 0.1974\n",
            "t = 18, avg_loss = 0.1561\n",
            "t = 20, avg_loss = 0.2154\n",
            "t = 22, avg_loss = 0.2328\n",
            "t = 24, avg_loss = 0.1765\n",
            "Checking accuracy on test set\n",
            "Got 358 / 400 correct (89.50)\n",
            "acc = 0.895000\n",
            "Starting epoch 22 / 80\n",
            "t = 2, avg_loss = 0.2581\n",
            "t = 4, avg_loss = 0.1697\n",
            "t = 6, avg_loss = 0.1864\n",
            "t = 8, avg_loss = 0.1803\n",
            "t = 10, avg_loss = 0.1919\n",
            "t = 12, avg_loss = 0.2484\n",
            "t = 14, avg_loss = 0.2177\n",
            "t = 16, avg_loss = 0.1835\n",
            "t = 18, avg_loss = 0.1515\n",
            "t = 20, avg_loss = 0.1881\n",
            "t = 22, avg_loss = 0.1873\n",
            "t = 24, avg_loss = 0.1542\n",
            "Checking accuracy on test set\n",
            "Got 359 / 400 correct (89.75)\n",
            "acc = 0.897500\n",
            "Starting epoch 23 / 80\n",
            "t = 2, avg_loss = 0.2775\n",
            "t = 4, avg_loss = 0.1953\n",
            "t = 6, avg_loss = 0.2629\n",
            "t = 8, avg_loss = 0.1921\n",
            "t = 10, avg_loss = 0.1712\n",
            "t = 12, avg_loss = 0.2243\n",
            "t = 14, avg_loss = 0.1809\n",
            "t = 16, avg_loss = 0.1114\n",
            "t = 18, avg_loss = 0.2145\n",
            "t = 20, avg_loss = 0.1709\n",
            "t = 22, avg_loss = 0.1960\n",
            "t = 24, avg_loss = 0.1302\n",
            "Checking accuracy on test set\n",
            "Got 361 / 400 correct (90.25)\n",
            "acc = 0.902500\n",
            "Starting epoch 24 / 80\n",
            "t = 2, avg_loss = 0.2986\n",
            "t = 4, avg_loss = 0.1990\n",
            "t = 6, avg_loss = 0.1489\n",
            "t = 8, avg_loss = 0.2257\n",
            "t = 10, avg_loss = 0.1588\n",
            "t = 12, avg_loss = 0.1540\n",
            "t = 14, avg_loss = 0.2560\n",
            "t = 16, avg_loss = 0.1871\n",
            "t = 18, avg_loss = 0.1980\n",
            "t = 20, avg_loss = 0.2618\n",
            "t = 22, avg_loss = 0.1911\n",
            "t = 24, avg_loss = 0.1641\n",
            "Checking accuracy on test set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 25 / 80\n",
            "t = 2, avg_loss = 0.2603\n",
            "t = 4, avg_loss = 0.2390\n",
            "t = 6, avg_loss = 0.1923\n",
            "t = 8, avg_loss = 0.2398\n",
            "t = 10, avg_loss = 0.1801\n",
            "t = 12, avg_loss = 0.1509\n",
            "t = 14, avg_loss = 0.1702\n",
            "t = 16, avg_loss = 0.2226\n",
            "t = 18, avg_loss = 0.1521\n",
            "t = 20, avg_loss = 0.2730\n",
            "t = 22, avg_loss = 0.2139\n",
            "t = 24, avg_loss = 0.1228\n",
            "Checking accuracy on test set\n",
            "Got 361 / 400 correct (90.25)\n",
            "acc = 0.902500\n",
            "Starting epoch 26 / 80\n",
            "t = 2, avg_loss = 0.3470\n",
            "t = 4, avg_loss = 0.1263\n",
            "t = 6, avg_loss = 0.1646\n",
            "t = 8, avg_loss = 0.1703\n",
            "t = 10, avg_loss = 0.1264\n",
            "t = 12, avg_loss = 0.1739\n",
            "t = 14, avg_loss = 0.1664\n",
            "t = 16, avg_loss = 0.2633\n",
            "t = 18, avg_loss = 0.2166\n",
            "t = 20, avg_loss = 0.2213\n",
            "t = 22, avg_loss = 0.1704\n",
            "t = 24, avg_loss = 0.2012\n",
            "Checking accuracy on test set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 27 / 80\n",
            "t = 2, avg_loss = 0.2392\n",
            "t = 4, avg_loss = 0.2438\n",
            "t = 6, avg_loss = 0.1423\n",
            "t = 8, avg_loss = 0.1491\n",
            "t = 10, avg_loss = 0.1728\n",
            "t = 12, avg_loss = 0.1298\n",
            "t = 14, avg_loss = 0.1934\n",
            "t = 16, avg_loss = 0.1689\n",
            "t = 18, avg_loss = 0.2105\n",
            "t = 20, avg_loss = 0.1938\n",
            "t = 22, avg_loss = 0.1420\n",
            "t = 24, avg_loss = 0.1848\n",
            "Checking accuracy on test set\n",
            "Got 362 / 400 correct (90.50)\n",
            "acc = 0.905000\n",
            "Starting epoch 28 / 80\n",
            "t = 2, avg_loss = 0.2278\n",
            "t = 4, avg_loss = 0.1162\n",
            "t = 6, avg_loss = 0.1328\n",
            "t = 8, avg_loss = 0.1731\n",
            "t = 10, avg_loss = 0.1874\n",
            "t = 12, avg_loss = 0.1657\n",
            "t = 14, avg_loss = 0.1387\n",
            "t = 16, avg_loss = 0.1829\n",
            "t = 18, avg_loss = 0.1588\n",
            "t = 20, avg_loss = 0.1463\n",
            "t = 22, avg_loss = 0.2236\n",
            "t = 24, avg_loss = 0.1847\n",
            "Checking accuracy on test set\n",
            "Got 370 / 400 correct (92.50)\n",
            "acc = 0.925000\n",
            "Starting epoch 29 / 80\n",
            "t = 2, avg_loss = 0.2681\n",
            "t = 4, avg_loss = 0.1681\n",
            "t = 6, avg_loss = 0.1920\n",
            "t = 8, avg_loss = 0.1658\n",
            "t = 10, avg_loss = 0.1460\n",
            "t = 12, avg_loss = 0.1400\n",
            "t = 14, avg_loss = 0.1935\n",
            "t = 16, avg_loss = 0.1564\n",
            "t = 18, avg_loss = 0.1679\n",
            "t = 20, avg_loss = 0.1971\n",
            "t = 22, avg_loss = 0.2058\n",
            "t = 24, avg_loss = 0.2003\n",
            "Checking accuracy on test set\n",
            "Got 366 / 400 correct (91.50)\n",
            "acc = 0.915000\n",
            "Starting epoch 30 / 80\n",
            "t = 2, avg_loss = 0.2590\n",
            "t = 4, avg_loss = 0.1237\n",
            "t = 6, avg_loss = 0.1825\n",
            "t = 8, avg_loss = 0.1889\n",
            "t = 10, avg_loss = 0.1247\n",
            "t = 12, avg_loss = 0.1689\n",
            "t = 14, avg_loss = 0.1285\n",
            "t = 16, avg_loss = 0.1367\n",
            "t = 18, avg_loss = 0.2221\n",
            "t = 20, avg_loss = 0.1690\n",
            "t = 22, avg_loss = 0.1376\n",
            "t = 24, avg_loss = 0.1600\n",
            "Checking accuracy on test set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 31 / 80\n",
            "t = 2, avg_loss = 0.2686\n",
            "t = 4, avg_loss = 0.1485\n",
            "t = 6, avg_loss = 0.1139\n",
            "t = 8, avg_loss = 0.1304\n",
            "t = 10, avg_loss = 0.1432\n",
            "t = 12, avg_loss = 0.1749\n",
            "t = 14, avg_loss = 0.1363\n",
            "t = 16, avg_loss = 0.1880\n",
            "t = 18, avg_loss = 0.1561\n",
            "t = 20, avg_loss = 0.1665\n",
            "t = 22, avg_loss = 0.1189\n",
            "t = 24, avg_loss = 0.1204\n",
            "Checking accuracy on test set\n",
            "Got 363 / 400 correct (90.75)\n",
            "acc = 0.907500\n",
            "Starting epoch 32 / 80\n",
            "t = 2, avg_loss = 0.1825\n",
            "t = 4, avg_loss = 0.1755\n",
            "t = 6, avg_loss = 0.1198\n",
            "t = 8, avg_loss = 0.1255\n",
            "t = 10, avg_loss = 0.1750\n",
            "t = 12, avg_loss = 0.1428\n",
            "t = 14, avg_loss = 0.1544\n",
            "t = 16, avg_loss = 0.1530\n",
            "t = 18, avg_loss = 0.2002\n",
            "t = 20, avg_loss = 0.1812\n",
            "t = 22, avg_loss = 0.1230\n",
            "t = 24, avg_loss = 0.1386\n",
            "Checking accuracy on test set\n",
            "Got 362 / 400 correct (90.50)\n",
            "acc = 0.905000\n",
            "Starting epoch 33 / 80\n",
            "t = 2, avg_loss = 0.2594\n",
            "t = 4, avg_loss = 0.1216\n",
            "t = 6, avg_loss = 0.1371\n",
            "t = 8, avg_loss = 0.1705\n",
            "t = 10, avg_loss = 0.2381\n",
            "t = 12, avg_loss = 0.1290\n",
            "t = 14, avg_loss = 0.2235\n",
            "t = 16, avg_loss = 0.1450\n",
            "t = 18, avg_loss = 0.1099\n",
            "t = 20, avg_loss = 0.1422\n",
            "t = 22, avg_loss = 0.1042\n",
            "t = 24, avg_loss = 0.1627\n",
            "Checking accuracy on test set\n",
            "Got 361 / 400 correct (90.25)\n",
            "acc = 0.902500\n",
            "Starting epoch 34 / 80\n",
            "t = 2, avg_loss = 0.1623\n",
            "t = 4, avg_loss = 0.1269\n",
            "t = 6, avg_loss = 0.1263\n",
            "t = 8, avg_loss = 0.2090\n",
            "t = 10, avg_loss = 0.1662\n",
            "t = 12, avg_loss = 0.1656\n",
            "t = 14, avg_loss = 0.1876\n",
            "t = 16, avg_loss = 0.1519\n",
            "t = 18, avg_loss = 0.1517\n",
            "t = 20, avg_loss = 0.1042\n",
            "t = 22, avg_loss = 0.1685\n",
            "t = 24, avg_loss = 0.1113\n",
            "Checking accuracy on test set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 35 / 80\n",
            "t = 2, avg_loss = 0.2819\n",
            "t = 4, avg_loss = 0.1291\n",
            "t = 6, avg_loss = 0.1286\n",
            "t = 8, avg_loss = 0.1440\n",
            "t = 10, avg_loss = 0.1282\n",
            "t = 12, avg_loss = 0.1178\n",
            "t = 14, avg_loss = 0.1414\n",
            "t = 16, avg_loss = 0.1327\n",
            "t = 18, avg_loss = 0.2470\n",
            "t = 20, avg_loss = 0.1819\n",
            "t = 22, avg_loss = 0.1689\n",
            "t = 24, avg_loss = 0.1717\n",
            "Checking accuracy on test set\n",
            "Got 362 / 400 correct (90.50)\n",
            "acc = 0.905000\n",
            "Starting epoch 36 / 80\n",
            "t = 2, avg_loss = 0.2292\n",
            "t = 4, avg_loss = 0.1368\n",
            "t = 6, avg_loss = 0.1242\n",
            "t = 8, avg_loss = 0.1266\n",
            "t = 10, avg_loss = 0.1063\n",
            "t = 12, avg_loss = 0.1375\n",
            "t = 14, avg_loss = 0.1855\n",
            "t = 16, avg_loss = 0.1472\n",
            "t = 18, avg_loss = 0.1556\n",
            "t = 20, avg_loss = 0.1031\n",
            "t = 22, avg_loss = 0.1680\n",
            "t = 24, avg_loss = 0.1261\n",
            "Checking accuracy on test set\n",
            "Got 358 / 400 correct (89.50)\n",
            "acc = 0.895000\n",
            "Starting epoch 37 / 80\n",
            "t = 2, avg_loss = 0.2662\n",
            "t = 4, avg_loss = 0.1025\n",
            "t = 6, avg_loss = 0.1397\n",
            "t = 8, avg_loss = 0.1286\n",
            "t = 10, avg_loss = 0.1693\n",
            "t = 12, avg_loss = 0.1249\n",
            "t = 14, avg_loss = 0.1558\n",
            "t = 16, avg_loss = 0.1228\n",
            "t = 18, avg_loss = 0.1516\n",
            "t = 20, avg_loss = 0.1320\n",
            "t = 22, avg_loss = 0.1609\n",
            "t = 24, avg_loss = 0.1332\n",
            "Checking accuracy on test set\n",
            "Got 358 / 400 correct (89.50)\n",
            "acc = 0.895000\n",
            "Starting epoch 38 / 80\n",
            "t = 2, avg_loss = 0.2829\n",
            "t = 4, avg_loss = 0.1069\n",
            "t = 6, avg_loss = 0.0860\n",
            "t = 8, avg_loss = 0.1534\n",
            "t = 10, avg_loss = 0.1945\n",
            "t = 12, avg_loss = 0.1048\n",
            "t = 14, avg_loss = 0.1170\n",
            "t = 16, avg_loss = 0.1218\n",
            "t = 18, avg_loss = 0.1044\n",
            "t = 20, avg_loss = 0.1446\n",
            "t = 22, avg_loss = 0.1426\n",
            "t = 24, avg_loss = 0.0935\n",
            "Checking accuracy on test set\n",
            "Got 359 / 400 correct (89.75)\n",
            "acc = 0.897500\n",
            "Starting epoch 39 / 80\n",
            "t = 2, avg_loss = 0.1973\n",
            "t = 4, avg_loss = 0.1269\n",
            "t = 6, avg_loss = 0.1112\n",
            "t = 8, avg_loss = 0.1519\n",
            "t = 10, avg_loss = 0.1063\n",
            "t = 12, avg_loss = 0.1019\n",
            "t = 14, avg_loss = 0.1845\n",
            "t = 16, avg_loss = 0.1113\n",
            "t = 18, avg_loss = 0.1650\n",
            "t = 20, avg_loss = 0.0900\n",
            "t = 22, avg_loss = 0.1184\n",
            "t = 24, avg_loss = 0.1550\n",
            "Checking accuracy on test set\n",
            "Got 359 / 400 correct (89.75)\n",
            "acc = 0.897500\n",
            "Starting epoch 40 / 80\n",
            "t = 2, avg_loss = 0.1378\n",
            "t = 4, avg_loss = 0.1177\n",
            "t = 6, avg_loss = 0.1210\n",
            "t = 8, avg_loss = 0.1333\n",
            "t = 10, avg_loss = 0.1181\n",
            "t = 12, avg_loss = 0.1231\n",
            "t = 14, avg_loss = 0.1102\n",
            "t = 16, avg_loss = 0.1387\n",
            "t = 18, avg_loss = 0.1972\n",
            "t = 20, avg_loss = 0.1184\n",
            "t = 22, avg_loss = 0.0926\n",
            "t = 24, avg_loss = 0.1457\n",
            "Checking accuracy on test set\n",
            "Got 360 / 400 correct (90.00)\n",
            "acc = 0.900000\n",
            "Starting epoch 41 / 80\n",
            "t = 2, avg_loss = 0.2221\n",
            "t = 4, avg_loss = 0.1434\n",
            "t = 6, avg_loss = 0.1414\n",
            "t = 8, avg_loss = 0.1097\n",
            "t = 10, avg_loss = 0.1224\n",
            "t = 12, avg_loss = 0.0571\n",
            "t = 14, avg_loss = 0.1181\n",
            "t = 16, avg_loss = 0.1572\n",
            "t = 18, avg_loss = 0.1351\n",
            "t = 20, avg_loss = 0.0974\n",
            "t = 22, avg_loss = 0.1461\n",
            "t = 24, avg_loss = 0.1599\n",
            "Checking accuracy on test set\n",
            "Got 366 / 400 correct (91.50)\n",
            "acc = 0.915000\n",
            "Starting epoch 42 / 80\n",
            "t = 2, avg_loss = 0.1147\n",
            "t = 4, avg_loss = 0.0929\n",
            "t = 6, avg_loss = 0.0826\n",
            "t = 8, avg_loss = 0.1071\n",
            "t = 10, avg_loss = 0.0954\n",
            "t = 12, avg_loss = 0.1586\n",
            "t = 14, avg_loss = 0.0813\n",
            "t = 16, avg_loss = 0.1484\n",
            "t = 18, avg_loss = 0.1270\n",
            "t = 20, avg_loss = 0.1500\n",
            "t = 22, avg_loss = 0.1325\n",
            "t = 24, avg_loss = 0.1367\n",
            "Checking accuracy on test set\n",
            "Got 361 / 400 correct (90.25)\n",
            "acc = 0.902500\n",
            "Starting epoch 43 / 80\n",
            "t = 2, avg_loss = 0.2014\n",
            "t = 4, avg_loss = 0.1010\n",
            "t = 6, avg_loss = 0.1441\n",
            "t = 8, avg_loss = 0.2030\n",
            "t = 10, avg_loss = 0.1539\n",
            "t = 12, avg_loss = 0.0917\n",
            "t = 14, avg_loss = 0.1703\n",
            "t = 16, avg_loss = 0.0701\n",
            "t = 18, avg_loss = 0.1199\n",
            "t = 20, avg_loss = 0.0863\n",
            "t = 22, avg_loss = 0.1348\n",
            "t = 24, avg_loss = 0.1229\n",
            "Checking accuracy on test set\n",
            "Got 363 / 400 correct (90.75)\n",
            "acc = 0.907500\n",
            "Starting epoch 44 / 80\n",
            "t = 2, avg_loss = 0.1213\n",
            "t = 4, avg_loss = 0.1151\n",
            "t = 6, avg_loss = 0.1577\n",
            "t = 8, avg_loss = 0.0958\n",
            "t = 10, avg_loss = 0.1414\n",
            "t = 12, avg_loss = 0.1014\n",
            "t = 14, avg_loss = 0.0772\n",
            "t = 16, avg_loss = 0.0700\n",
            "t = 18, avg_loss = 0.1621\n",
            "t = 20, avg_loss = 0.1299\n",
            "t = 22, avg_loss = 0.1133\n",
            "t = 24, avg_loss = 0.1300\n",
            "Checking accuracy on test set\n",
            "Got 363 / 400 correct (90.75)\n",
            "acc = 0.907500\n",
            "Starting epoch 45 / 80\n",
            "t = 2, avg_loss = 0.1426\n",
            "t = 4, avg_loss = 0.1539\n",
            "t = 6, avg_loss = 0.1053\n",
            "t = 8, avg_loss = 0.1097\n",
            "t = 10, avg_loss = 0.1406\n",
            "t = 12, avg_loss = 0.1350\n",
            "t = 14, avg_loss = 0.0708\n",
            "t = 16, avg_loss = 0.0991\n",
            "t = 18, avg_loss = 0.0818\n",
            "t = 20, avg_loss = 0.1055\n",
            "t = 22, avg_loss = 0.1425\n",
            "t = 24, avg_loss = 0.0958\n",
            "Checking accuracy on test set\n",
            "Got 361 / 400 correct (90.25)\n",
            "acc = 0.902500\n",
            "Starting epoch 46 / 80\n",
            "t = 2, avg_loss = 0.1736\n",
            "t = 4, avg_loss = 0.1008\n",
            "t = 6, avg_loss = 0.1306\n",
            "t = 8, avg_loss = 0.1459\n",
            "t = 10, avg_loss = 0.1565\n",
            "t = 12, avg_loss = 0.1896\n",
            "t = 14, avg_loss = 0.0876\n",
            "t = 16, avg_loss = 0.1171\n",
            "t = 18, avg_loss = 0.0971\n",
            "t = 20, avg_loss = 0.1237\n",
            "t = 22, avg_loss = 0.1039\n",
            "t = 24, avg_loss = 0.0871\n",
            "Checking accuracy on test set\n",
            "Got 359 / 400 correct (89.75)\n",
            "acc = 0.897500\n",
            "Starting epoch 47 / 80\n",
            "t = 2, avg_loss = 0.1805\n",
            "t = 4, avg_loss = 0.2552\n",
            "t = 6, avg_loss = 0.1000\n",
            "t = 8, avg_loss = 0.1128\n",
            "t = 10, avg_loss = 0.1129\n",
            "t = 12, avg_loss = 0.1160\n",
            "t = 14, avg_loss = 0.1100\n",
            "t = 16, avg_loss = 0.1166\n",
            "t = 18, avg_loss = 0.1231\n",
            "t = 20, avg_loss = 0.1007\n",
            "t = 22, avg_loss = 0.1188\n",
            "t = 24, avg_loss = 0.0765\n",
            "Checking accuracy on test set\n",
            "Got 359 / 400 correct (89.75)\n",
            "acc = 0.897500\n",
            "Starting epoch 48 / 80\n",
            "t = 2, avg_loss = 0.1456\n",
            "t = 4, avg_loss = 0.0750\n",
            "t = 6, avg_loss = 0.0913\n",
            "t = 8, avg_loss = 0.0717\n",
            "t = 10, avg_loss = 0.1063\n",
            "t = 12, avg_loss = 0.0881\n",
            "t = 14, avg_loss = 0.1757\n",
            "t = 16, avg_loss = 0.1080\n",
            "t = 18, avg_loss = 0.0981\n",
            "t = 20, avg_loss = 0.0490\n",
            "t = 22, avg_loss = 0.1098\n",
            "t = 24, avg_loss = 0.0955\n",
            "Checking accuracy on test set\n",
            "Got 361 / 400 correct (90.25)\n",
            "acc = 0.902500\n",
            "Starting epoch 49 / 80\n",
            "t = 2, avg_loss = 0.1913\n",
            "t = 4, avg_loss = 0.1514\n",
            "t = 6, avg_loss = 0.1324\n",
            "t = 8, avg_loss = 0.1110\n",
            "t = 10, avg_loss = 0.1094\n",
            "t = 12, avg_loss = 0.1845\n",
            "t = 14, avg_loss = 0.1384\n",
            "t = 16, avg_loss = 0.1972\n",
            "t = 18, avg_loss = 0.1022\n",
            "t = 20, avg_loss = 0.0962\n",
            "t = 22, avg_loss = 0.1149\n",
            "t = 24, avg_loss = 0.1405\n",
            "Checking accuracy on test set\n",
            "Got 363 / 400 correct (90.75)\n",
            "acc = 0.907500\n",
            "Starting epoch 50 / 80\n",
            "t = 2, avg_loss = 0.1311\n",
            "t = 4, avg_loss = 0.0922\n",
            "t = 6, avg_loss = 0.1359\n",
            "t = 8, avg_loss = 0.1697\n",
            "t = 10, avg_loss = 0.0971\n",
            "t = 12, avg_loss = 0.1673\n",
            "t = 14, avg_loss = 0.1418\n",
            "t = 16, avg_loss = 0.0977\n",
            "t = 18, avg_loss = 0.0951\n",
            "t = 20, avg_loss = 0.1057\n",
            "t = 22, avg_loss = 0.1292\n",
            "t = 24, avg_loss = 0.0821\n",
            "Checking accuracy on test set\n",
            "Got 358 / 400 correct (89.50)\n",
            "acc = 0.895000\n",
            "Starting epoch 51 / 80\n",
            "t = 2, avg_loss = 0.1331\n",
            "t = 4, avg_loss = 0.1101\n",
            "t = 6, avg_loss = 0.0755\n",
            "t = 8, avg_loss = 0.0766\n",
            "t = 10, avg_loss = 0.1722\n",
            "t = 12, avg_loss = 0.1163\n",
            "t = 14, avg_loss = 0.0957\n",
            "t = 16, avg_loss = 0.1092\n",
            "t = 18, avg_loss = 0.1394\n",
            "t = 20, avg_loss = 0.0819\n",
            "t = 22, avg_loss = 0.1599\n",
            "t = 24, avg_loss = 0.0972\n",
            "Checking accuracy on test set\n",
            "Got 368 / 400 correct (92.00)\n",
            "acc = 0.920000\n",
            "Starting epoch 52 / 80\n",
            "t = 2, avg_loss = 0.1359\n",
            "t = 4, avg_loss = 0.1106\n",
            "t = 6, avg_loss = 0.0887\n",
            "t = 8, avg_loss = 0.1090\n",
            "t = 10, avg_loss = 0.0829\n",
            "t = 12, avg_loss = 0.1631\n",
            "t = 14, avg_loss = 0.0699\n",
            "t = 16, avg_loss = 0.1318\n",
            "t = 18, avg_loss = 0.0738\n",
            "t = 20, avg_loss = 0.0800\n",
            "t = 22, avg_loss = 0.1033\n",
            "t = 24, avg_loss = 0.1168\n",
            "Checking accuracy on test set\n",
            "Got 358 / 400 correct (89.50)\n",
            "acc = 0.895000\n",
            "Starting epoch 53 / 80\n",
            "t = 2, avg_loss = 0.1481\n",
            "t = 4, avg_loss = 0.0982\n",
            "t = 6, avg_loss = 0.1047\n",
            "t = 8, avg_loss = 0.1371\n",
            "t = 10, avg_loss = 0.0669\n",
            "t = 12, avg_loss = 0.0873\n",
            "t = 14, avg_loss = 0.0704\n",
            "t = 16, avg_loss = 0.1037\n",
            "t = 18, avg_loss = 0.1114\n",
            "t = 20, avg_loss = 0.0805\n",
            "t = 22, avg_loss = 0.0953\n",
            "t = 24, avg_loss = 0.0697\n",
            "Checking accuracy on test set\n",
            "Got 361 / 400 correct (90.25)\n",
            "acc = 0.902500\n",
            "Starting epoch 54 / 80\n",
            "t = 2, avg_loss = 0.0917\n",
            "t = 4, avg_loss = 0.0872\n",
            "t = 6, avg_loss = 0.0723\n",
            "t = 8, avg_loss = 0.1393\n",
            "t = 10, avg_loss = 0.0951\n",
            "t = 12, avg_loss = 0.1092\n",
            "t = 14, avg_loss = 0.0691\n",
            "t = 16, avg_loss = 0.1295\n",
            "t = 18, avg_loss = 0.1822\n",
            "t = 20, avg_loss = 0.1305\n",
            "t = 22, avg_loss = 0.1074\n",
            "t = 24, avg_loss = 0.1041\n",
            "Checking accuracy on test set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 55 / 80\n",
            "t = 2, avg_loss = 0.1812\n",
            "t = 4, avg_loss = 0.0793\n",
            "t = 6, avg_loss = 0.1101\n",
            "t = 8, avg_loss = 0.0801\n",
            "t = 10, avg_loss = 0.1195\n",
            "t = 12, avg_loss = 0.1129\n",
            "t = 14, avg_loss = 0.1118\n",
            "t = 16, avg_loss = 0.0990\n",
            "t = 18, avg_loss = 0.1465\n",
            "t = 20, avg_loss = 0.1392\n",
            "t = 22, avg_loss = 0.0917\n",
            "t = 24, avg_loss = 0.1501\n",
            "Checking accuracy on test set\n",
            "Got 363 / 400 correct (90.75)\n",
            "acc = 0.907500\n",
            "Starting epoch 56 / 80\n",
            "t = 2, avg_loss = 0.1103\n",
            "t = 4, avg_loss = 0.0639\n",
            "t = 6, avg_loss = 0.0723\n",
            "t = 8, avg_loss = 0.1120\n",
            "t = 10, avg_loss = 0.0869\n",
            "t = 12, avg_loss = 0.0978\n",
            "t = 14, avg_loss = 0.0940\n",
            "t = 16, avg_loss = 0.1005\n",
            "t = 18, avg_loss = 0.1214\n",
            "t = 20, avg_loss = 0.1226\n",
            "t = 22, avg_loss = 0.0859\n",
            "t = 24, avg_loss = 0.1121\n",
            "Checking accuracy on test set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 57 / 80\n",
            "t = 2, avg_loss = 0.1203\n",
            "t = 4, avg_loss = 0.0796\n",
            "t = 6, avg_loss = 0.0782\n",
            "t = 8, avg_loss = 0.0561\n",
            "t = 10, avg_loss = 0.0464\n",
            "t = 12, avg_loss = 0.0866\n",
            "t = 14, avg_loss = 0.0793\n",
            "t = 16, avg_loss = 0.1166\n",
            "t = 18, avg_loss = 0.0534\n",
            "t = 20, avg_loss = 0.0829\n",
            "t = 22, avg_loss = 0.0913\n",
            "t = 24, avg_loss = 0.0972\n",
            "Checking accuracy on test set\n",
            "Got 366 / 400 correct (91.50)\n",
            "acc = 0.915000\n",
            "Starting epoch 58 / 80\n",
            "t = 2, avg_loss = 0.0780\n",
            "t = 4, avg_loss = 0.1333\n",
            "t = 6, avg_loss = 0.0834\n",
            "t = 8, avg_loss = 0.0833\n",
            "t = 10, avg_loss = 0.1041\n",
            "t = 12, avg_loss = 0.1447\n",
            "t = 14, avg_loss = 0.0586\n",
            "t = 16, avg_loss = 0.0986\n",
            "t = 18, avg_loss = 0.0557\n",
            "t = 20, avg_loss = 0.1014\n",
            "t = 22, avg_loss = 0.0623\n",
            "t = 24, avg_loss = 0.0661\n",
            "Checking accuracy on test set\n",
            "Got 360 / 400 correct (90.00)\n",
            "acc = 0.900000\n",
            "Starting epoch 59 / 80\n",
            "t = 2, avg_loss = 0.1070\n",
            "t = 4, avg_loss = 0.0596\n",
            "t = 6, avg_loss = 0.0786\n",
            "t = 8, avg_loss = 0.1198\n",
            "t = 10, avg_loss = 0.0929\n",
            "t = 12, avg_loss = 0.0965\n",
            "t = 14, avg_loss = 0.0596\n",
            "t = 16, avg_loss = 0.0830\n",
            "t = 18, avg_loss = 0.0711\n",
            "t = 20, avg_loss = 0.0908\n",
            "t = 22, avg_loss = 0.0866\n",
            "t = 24, avg_loss = 0.0807\n",
            "Checking accuracy on test set\n",
            "Got 366 / 400 correct (91.50)\n",
            "acc = 0.915000\n",
            "Starting epoch 60 / 80\n",
            "t = 2, avg_loss = 0.1391\n",
            "t = 4, avg_loss = 0.0816\n",
            "t = 6, avg_loss = 0.0597\n",
            "t = 8, avg_loss = 0.1068\n",
            "t = 10, avg_loss = 0.0921\n",
            "t = 12, avg_loss = 0.0619\n",
            "t = 14, avg_loss = 0.0950\n",
            "t = 16, avg_loss = 0.0750\n",
            "t = 18, avg_loss = 0.0783\n",
            "t = 20, avg_loss = 0.0722\n",
            "t = 22, avg_loss = 0.0699\n",
            "t = 24, avg_loss = 0.0683\n",
            "Checking accuracy on test set\n",
            "Got 362 / 400 correct (90.50)\n",
            "acc = 0.905000\n",
            "Starting epoch 61 / 80\n",
            "t = 2, avg_loss = 0.1356\n",
            "t = 4, avg_loss = 0.0703\n",
            "t = 6, avg_loss = 0.0674\n",
            "t = 8, avg_loss = 0.1376\n",
            "t = 10, avg_loss = 0.1683\n",
            "t = 12, avg_loss = 0.0851\n",
            "t = 14, avg_loss = 0.0774\n",
            "t = 16, avg_loss = 0.0730\n",
            "t = 18, avg_loss = 0.0699\n",
            "t = 20, avg_loss = 0.0920\n",
            "t = 22, avg_loss = 0.0991\n",
            "t = 24, avg_loss = 0.0615\n",
            "Checking accuracy on test set\n",
            "Got 366 / 400 correct (91.50)\n",
            "acc = 0.915000\n",
            "Starting epoch 62 / 80\n",
            "t = 2, avg_loss = 0.1457\n",
            "t = 4, avg_loss = 0.0818\n",
            "t = 6, avg_loss = 0.0810\n",
            "t = 8, avg_loss = 0.1127\n",
            "t = 10, avg_loss = 0.0662\n",
            "t = 12, avg_loss = 0.1066\n",
            "t = 14, avg_loss = 0.0649\n",
            "t = 16, avg_loss = 0.0767\n",
            "t = 18, avg_loss = 0.1419\n",
            "t = 20, avg_loss = 0.0858\n",
            "t = 22, avg_loss = 0.1026\n",
            "t = 24, avg_loss = 0.0791\n",
            "Checking accuracy on test set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 63 / 80\n",
            "t = 2, avg_loss = 0.1117\n",
            "t = 4, avg_loss = 0.1003\n",
            "t = 6, avg_loss = 0.0705\n",
            "t = 8, avg_loss = 0.1448\n",
            "t = 10, avg_loss = 0.0633\n",
            "t = 12, avg_loss = 0.0672\n",
            "t = 14, avg_loss = 0.0624\n",
            "t = 16, avg_loss = 0.0844\n",
            "t = 18, avg_loss = 0.0967\n",
            "t = 20, avg_loss = 0.0859\n",
            "t = 22, avg_loss = 0.1283\n",
            "t = 24, avg_loss = 0.0938\n",
            "Checking accuracy on test set\n",
            "Got 358 / 400 correct (89.50)\n",
            "acc = 0.895000\n",
            "Starting epoch 64 / 80\n",
            "t = 2, avg_loss = 0.1279\n",
            "t = 4, avg_loss = 0.0775\n",
            "t = 6, avg_loss = 0.1069\n",
            "t = 8, avg_loss = 0.0530\n",
            "t = 10, avg_loss = 0.0755\n",
            "t = 12, avg_loss = 0.0853\n",
            "t = 14, avg_loss = 0.0801\n",
            "t = 16, avg_loss = 0.0868\n",
            "t = 18, avg_loss = 0.1101\n",
            "t = 20, avg_loss = 0.0905\n",
            "t = 22, avg_loss = 0.0792\n",
            "t = 24, avg_loss = 0.0512\n",
            "Checking accuracy on test set\n",
            "Got 363 / 400 correct (90.75)\n",
            "acc = 0.907500\n",
            "Starting epoch 65 / 80\n",
            "t = 2, avg_loss = 0.1023\n",
            "t = 4, avg_loss = 0.0526\n",
            "t = 6, avg_loss = 0.0777\n",
            "t = 8, avg_loss = 0.1229\n",
            "t = 10, avg_loss = 0.0863\n",
            "t = 12, avg_loss = 0.0478\n",
            "t = 14, avg_loss = 0.0393\n",
            "t = 16, avg_loss = 0.0482\n",
            "t = 18, avg_loss = 0.0527\n",
            "t = 20, avg_loss = 0.0851\n",
            "t = 22, avg_loss = 0.0923\n",
            "t = 24, avg_loss = 0.0673\n",
            "Checking accuracy on test set\n",
            "Got 369 / 400 correct (92.25)\n",
            "acc = 0.922500\n",
            "Starting epoch 66 / 80\n",
            "t = 2, avg_loss = 0.1002\n",
            "t = 4, avg_loss = 0.0811\n",
            "t = 6, avg_loss = 0.0591\n",
            "t = 8, avg_loss = 0.0815\n",
            "t = 10, avg_loss = 0.0793\n",
            "t = 12, avg_loss = 0.0381\n",
            "t = 14, avg_loss = 0.0591\n",
            "t = 16, avg_loss = 0.0773\n",
            "t = 18, avg_loss = 0.0734\n",
            "t = 20, avg_loss = 0.0549\n",
            "t = 22, avg_loss = 0.0778\n",
            "t = 24, avg_loss = 0.0760\n",
            "Checking accuracy on test set\n",
            "Got 364 / 400 correct (91.00)\n",
            "acc = 0.910000\n",
            "Starting epoch 67 / 80\n",
            "t = 2, avg_loss = 0.1550\n",
            "t = 4, avg_loss = 0.0876\n",
            "t = 6, avg_loss = 0.0723\n",
            "t = 8, avg_loss = 0.0756\n",
            "t = 10, avg_loss = 0.0414\n",
            "t = 12, avg_loss = 0.0829\n",
            "t = 14, avg_loss = 0.0584\n",
            "t = 16, avg_loss = 0.0554\n",
            "t = 18, avg_loss = 0.0566\n",
            "t = 20, avg_loss = 0.0696\n",
            "t = 22, avg_loss = 0.0617\n",
            "t = 24, avg_loss = 0.0902\n",
            "Checking accuracy on test set\n",
            "Got 365 / 400 correct (91.25)\n",
            "acc = 0.912500\n",
            "Starting epoch 68 / 80\n",
            "t = 2, avg_loss = 0.0816\n",
            "t = 4, avg_loss = 0.0791\n",
            "t = 6, avg_loss = 0.0744\n",
            "t = 8, avg_loss = 0.0555\n",
            "t = 10, avg_loss = 0.0836\n",
            "t = 12, avg_loss = 0.0935\n",
            "t = 14, avg_loss = 0.0542\n",
            "t = 16, avg_loss = 0.0593\n",
            "t = 18, avg_loss = 0.0708\n",
            "t = 20, avg_loss = 0.0553\n",
            "t = 22, avg_loss = 0.0686\n",
            "t = 24, avg_loss = 0.0801\n",
            "Checking accuracy on test set\n",
            "Got 351 / 400 correct (87.75)\n",
            "acc = 0.877500\n",
            "Starting epoch 69 / 80\n",
            "t = 2, avg_loss = 0.1363\n",
            "t = 4, avg_loss = 0.0653\n",
            "t = 6, avg_loss = 0.0455\n",
            "t = 8, avg_loss = 0.0572\n",
            "t = 10, avg_loss = 0.0542\n",
            "t = 12, avg_loss = 0.0398\n",
            "t = 14, avg_loss = 0.1221\n",
            "t = 16, avg_loss = 0.0583\n",
            "t = 18, avg_loss = 0.1299\n",
            "t = 20, avg_loss = 0.1074\n",
            "t = 22, avg_loss = 0.0762\n",
            "t = 24, avg_loss = 0.0551\n",
            "Checking accuracy on test set\n",
            "Got 361 / 400 correct (90.25)\n",
            "acc = 0.902500\n",
            "Starting epoch 70 / 80\n",
            "t = 2, avg_loss = 0.0906\n",
            "t = 4, avg_loss = 0.1135\n",
            "t = 6, avg_loss = 0.0589\n",
            "t = 8, avg_loss = 0.0357\n",
            "t = 10, avg_loss = 0.0720\n",
            "t = 12, avg_loss = 0.0546\n",
            "t = 14, avg_loss = 0.0851\n",
            "t = 16, avg_loss = 0.0394\n",
            "t = 18, avg_loss = 0.1020\n",
            "t = 20, avg_loss = 0.0538\n",
            "t = 22, avg_loss = 0.0408\n",
            "t = 24, avg_loss = 0.0621\n",
            "Checking accuracy on test set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 71 / 80\n",
            "t = 2, avg_loss = 0.0960\n",
            "t = 4, avg_loss = 0.0709\n",
            "t = 6, avg_loss = 0.0505\n",
            "t = 8, avg_loss = 0.0927\n",
            "t = 10, avg_loss = 0.0400\n",
            "t = 12, avg_loss = 0.0383\n",
            "t = 14, avg_loss = 0.1087\n",
            "t = 16, avg_loss = 0.1526\n",
            "t = 18, avg_loss = 0.0407\n",
            "t = 20, avg_loss = 0.1015\n",
            "t = 22, avg_loss = 0.0698\n",
            "t = 24, avg_loss = 0.0442\n",
            "Checking accuracy on test set\n",
            "Got 363 / 400 correct (90.75)\n",
            "acc = 0.907500\n",
            "Starting epoch 72 / 80\n",
            "t = 2, avg_loss = 0.0869\n",
            "t = 4, avg_loss = 0.0464\n",
            "t = 6, avg_loss = 0.0919\n",
            "t = 8, avg_loss = 0.0938\n",
            "t = 10, avg_loss = 0.0937\n",
            "t = 12, avg_loss = 0.0531\n",
            "t = 14, avg_loss = 0.0645\n",
            "t = 16, avg_loss = 0.0933\n",
            "t = 18, avg_loss = 0.0998\n",
            "t = 20, avg_loss = 0.1056\n",
            "t = 22, avg_loss = 0.0746\n",
            "t = 24, avg_loss = 0.1106\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 73 / 80\n",
            "t = 2, avg_loss = 0.1063\n",
            "t = 4, avg_loss = 0.0632\n",
            "t = 6, avg_loss = 0.0534\n",
            "t = 8, avg_loss = 0.0748\n",
            "t = 10, avg_loss = 0.1069\n",
            "t = 12, avg_loss = 0.0749\n",
            "t = 14, avg_loss = 0.0692\n",
            "t = 16, avg_loss = 0.0762\n",
            "t = 18, avg_loss = 0.0685\n",
            "t = 20, avg_loss = 0.0798\n",
            "t = 22, avg_loss = 0.0786\n",
            "t = 24, avg_loss = 0.0830\n",
            "Checking accuracy on test set\n",
            "Got 368 / 400 correct (92.00)\n",
            "acc = 0.920000\n",
            "Starting epoch 74 / 80\n",
            "t = 2, avg_loss = 0.1716\n",
            "t = 4, avg_loss = 0.0528\n",
            "t = 6, avg_loss = 0.0311\n",
            "t = 8, avg_loss = 0.0724\n",
            "t = 10, avg_loss = 0.0888\n",
            "t = 12, avg_loss = 0.0771\n",
            "t = 14, avg_loss = 0.1223\n",
            "t = 16, avg_loss = 0.0644\n",
            "t = 18, avg_loss = 0.0977\n",
            "t = 20, avg_loss = 0.0618\n",
            "t = 22, avg_loss = 0.0582\n",
            "t = 24, avg_loss = 0.0939\n",
            "Checking accuracy on test set\n",
            "Got 360 / 400 correct (90.00)\n",
            "acc = 0.900000\n",
            "Starting epoch 75 / 80\n",
            "t = 2, avg_loss = 0.1098\n",
            "t = 4, avg_loss = 0.0632\n",
            "t = 6, avg_loss = 0.0436\n",
            "t = 8, avg_loss = 0.0508\n",
            "t = 10, avg_loss = 0.1025\n",
            "t = 12, avg_loss = 0.0877\n",
            "t = 14, avg_loss = 0.0892\n",
            "t = 16, avg_loss = 0.1182\n",
            "t = 18, avg_loss = 0.0614\n",
            "t = 20, avg_loss = 0.2531\n",
            "t = 22, avg_loss = 0.1312\n",
            "t = 24, avg_loss = 0.0963\n",
            "Checking accuracy on test set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 76 / 80\n",
            "t = 2, avg_loss = 0.1237\n",
            "t = 4, avg_loss = 0.0592\n",
            "t = 6, avg_loss = 0.0907\n",
            "t = 8, avg_loss = 0.0724\n",
            "t = 10, avg_loss = 0.0760\n",
            "t = 12, avg_loss = 0.0840\n",
            "t = 14, avg_loss = 0.0795\n",
            "t = 16, avg_loss = 0.0776\n",
            "t = 18, avg_loss = 0.0648\n",
            "t = 20, avg_loss = 0.0764\n",
            "t = 22, avg_loss = 0.0550\n",
            "t = 24, avg_loss = 0.0706\n",
            "Checking accuracy on test set\n",
            "Got 359 / 400 correct (89.75)\n",
            "acc = 0.897500\n",
            "Starting epoch 77 / 80\n",
            "t = 2, avg_loss = 0.1006\n",
            "t = 4, avg_loss = 0.0464\n",
            "t = 6, avg_loss = 0.0729\n",
            "t = 8, avg_loss = 0.0670\n",
            "t = 10, avg_loss = 0.0778\n",
            "t = 12, avg_loss = 0.0721\n",
            "t = 14, avg_loss = 0.0950\n",
            "t = 16, avg_loss = 0.1161\n",
            "t = 18, avg_loss = 0.0340\n",
            "t = 20, avg_loss = 0.0625\n",
            "t = 22, avg_loss = 0.0744\n",
            "t = 24, avg_loss = 0.0847\n",
            "Checking accuracy on test set\n",
            "Got 366 / 400 correct (91.50)\n",
            "acc = 0.915000\n",
            "Starting epoch 78 / 80\n",
            "t = 2, avg_loss = 0.1113\n",
            "t = 4, avg_loss = 0.0483\n",
            "t = 6, avg_loss = 0.0670\n",
            "t = 8, avg_loss = 0.0773\n",
            "t = 10, avg_loss = 0.0709\n",
            "t = 12, avg_loss = 0.0985\n",
            "t = 14, avg_loss = 0.0891\n",
            "t = 16, avg_loss = 0.0563\n",
            "t = 18, avg_loss = 0.0616\n",
            "t = 20, avg_loss = 0.0503\n",
            "t = 22, avg_loss = 0.0600\n",
            "t = 24, avg_loss = 0.0856\n",
            "Checking accuracy on test set\n",
            "Got 365 / 400 correct (91.25)\n",
            "acc = 0.912500\n",
            "Starting epoch 79 / 80\n",
            "t = 2, avg_loss = 0.0685\n",
            "t = 4, avg_loss = 0.0680\n",
            "t = 6, avg_loss = 0.0914\n",
            "t = 8, avg_loss = 0.0690\n",
            "t = 10, avg_loss = 0.0695\n",
            "t = 12, avg_loss = 0.1145\n",
            "t = 14, avg_loss = 0.0677\n",
            "t = 16, avg_loss = 0.0884\n",
            "t = 18, avg_loss = 0.0922\n",
            "t = 20, avg_loss = 0.0745\n",
            "t = 22, avg_loss = 0.0935\n",
            "t = 24, avg_loss = 0.0932\n",
            "Checking accuracy on test set\n",
            "Got 365 / 400 correct (91.25)\n",
            "acc = 0.912500\n",
            "Starting epoch 80 / 80\n",
            "t = 2, avg_loss = 0.0828\n",
            "t = 4, avg_loss = 0.0433\n",
            "t = 6, avg_loss = 0.0559\n",
            "t = 8, avg_loss = 0.0782\n",
            "t = 10, avg_loss = 0.0708\n",
            "t = 12, avg_loss = 0.0820\n",
            "t = 14, avg_loss = 0.0697\n",
            "t = 16, avg_loss = 0.1167\n",
            "t = 18, avg_loss = 0.0520\n",
            "t = 20, avg_loss = 0.0626\n",
            "t = 22, avg_loss = 0.0520\n",
            "t = 24, avg_loss = 0.0351\n",
            "Checking accuracy on test set\n",
            "Got 366 / 400 correct (91.50)\n",
            "acc = 0.915000\n",
            "Checking accuracy on test set\n",
            "Got 368 / 400 correct (92.00)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.92"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDn-2g-TLY3k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "777b8c9f-1618-4c2b-eb55-e2c21fe2c0e4"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot([print_every*batch_size*(i+1) for i in range((len(avg_loss_list)))],avg_loss_list)\n",
        "print(\"Loss:\")\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGer6hJv7-zR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "43cbf8ae-640c-45af-c494-11bf9ca17725"
      },
      "source": [
        "plt.plot([i+1 for i in range((len(acc_list)))],acc_list)\n",
        "print(\"Accurancy:\")\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accurancy:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBTReWHxz4Ml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}