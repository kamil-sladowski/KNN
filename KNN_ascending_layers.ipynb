{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN_ascending_layers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamilo116/KNN/blob/master/KNN_ascending_layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7ReM7FU-xs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import sys\n",
        "from random import shuffle\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms as transforms\n",
        "import timeit\n",
        "\n",
        "np.random.seed(4) \n",
        "torch.manual_seed(4) \n",
        "torch.cuda.manual_seed(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYIMZ8QyYewD",
        "colab_type": "code",
        "outputId": "6ab5c50f-c78a-4fef-ddea-5ed7ea253fee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "! git clone https://github.com/wang-chen/kervolution.git \n",
        "\n",
        "sys.path.append(\"kervolution/\")\n",
        "from kervolution import Kerv2d\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'kervolution' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvbKg4VJXKY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LIMIT_IMAGES_NUM = 1000\n",
        "train_test_split_size = 0.2\n",
        "image_resize = (100, 100)\n",
        "batch_size = 64\n",
        "num_workers = 0\n",
        "\n",
        "out_1 = 16\n",
        "out_2 = 32\n",
        "out_3 = 64\n",
        "out_4 = 128\n",
        "\n",
        "\n",
        "k_size_1 = 3\n",
        "padding_1 = 1\n",
        "in_channels = 3\n",
        "\n",
        "kernel_size = 3\n",
        "num_epochs = 100\n",
        "\n",
        "learning_rate = 0.00012\n",
        "weight_decay = 0\n",
        "\n",
        "MALIGNANT_DATASET = '/content/drive/My Drive/Colab_data/malignant/malignant/'\n",
        "BENIGN_DATASET = '/content/drive/My Drive/Colab_data/benign/benign/'\n",
        "DATA_FOLDER = '/content/drive/My Drive/Colab_data/'\n",
        "model_backup_path = os.path.join(DATA_FOLDER, 'backup_model2') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMOHez_kHZD6",
        "colab_type": "code",
        "outputId": "1bdd801e-3f14-45b2-e391-1cd80d71269e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b8P1NdXfVdX",
        "colab_type": "code",
        "outputId": "53e1f245-7cd9-4eb7-df94-89b734d31253",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "benign_file_list = sorted(os.listdir(BENIGN_DATASET))\n",
        "malignant_file_list = sorted(os.listdir(MALIGNANT_DATASET))\n",
        "shuffle(benign_file_list)\n",
        "shuffle(malignant_file_list)\n",
        "benign_file_list = benign_file_list[:LIMIT_IMAGES_NUM]\n",
        "malignant_file_list = malignant_file_list[:LIMIT_IMAGES_NUM]\n",
        "\n",
        "print(f\"Number of benign {len(benign_file_list)} images\")\n",
        "print(f\"Number of malignant {len(malignant_file_list)} images\")\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize(image_resize),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of benign 1000 images\n",
            "Number of malignant 1000 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGDQfal74BLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "benign_dict = {filename: 0 for filename in benign_file_list}\n",
        "malignant_dict = {filename: 1 for filename in malignant_file_list}\n",
        "img_class_dict = {**benign_dict , **malignant_dict}\n",
        "labeled_data = pd.Series(img_class_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvAAOqmVfVll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IsicDataset(Dataset):\n",
        "    def __init__(self, data_folder, labeled_data, \n",
        "                 transform=transforms.Compose([transforms.ToTensor()])):\n",
        "        self.labeled_data = labeled_data\n",
        "        self.transform = transform\n",
        "        self.data_folder = data_folder\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labeled_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        label = self.labeled_data[index]\n",
        "        if label == 0:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"benign\", \"benign\", index ))\n",
        "        else:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"malignant\", \"malignant\", index ))\n",
        "        image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "    @property\n",
        "    def labels(self):\n",
        "      return self.labeled_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSuYqjLAYrWA",
        "colab_type": "code",
        "outputId": "32cbf124-d380-467f-fb7b-74c6249d9fb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        }
      },
      "source": [
        "dataset = IsicDataset(DATA_FOLDER, labeled_data, transform=data_transforms)\n",
        "print(dataset.labels)\n",
        "\n",
        "X_train, X_test = train_test_split(dataset.labels, test_size=train_test_split_size)\n",
        "print(\"number of training data: \",len(X_train))\n",
        "print(\"number of testing  data: \",len(X_test))\n",
        "\n",
        "train_sampler = SubsetRandomSampler(list(X_train.index))\n",
        "valid_sampler = SubsetRandomSampler(list(X_test.index))\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ISIC_0001361.jpeg    0\n",
            "ISIC_0002598.jpeg    0\n",
            "ISIC_0000329.jpeg    0\n",
            "ISIC_0000180.jpeg    0\n",
            "ISIC_0002761.jpeg    0\n",
            "                    ..\n",
            "ISIC_0026746.jpg     1\n",
            "ISIC_0000049.jpeg    1\n",
            "ISIC_0013972.jpeg    1\n",
            "ISIC_0014975.jpeg    1\n",
            "ISIC_0026045.jpg     1\n",
            "Length: 2000, dtype: int64\n",
            "number of training data:  1600\n",
            "number of testing  data:  400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e8nFBR6Yug5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "def train(model, train_loader ,loss_fn, optimizer, num_epochs=1, starting_from_epoch=1):\n",
        "    total_loss =0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
        "        model.train()\n",
        "\n",
        "        for t, (x, y) in enumerate(train_loader):\n",
        "            x_var = Variable(x.type(gpu_dtype))\n",
        "            y_var = Variable(y.type(gpu_dtype).long())\n",
        "            scores = model(x_var)\n",
        "            loss = loss_fn(scores, y_var)\n",
        "            total_loss += loss.data\n",
        "            \n",
        "            if (t + 1) % print_every == 0:\n",
        "                avg_loss = total_loss/print_every\n",
        "                print('t = %d, avg_loss = %.4f' % (t + 1, avg_loss) )\n",
        "                avg_loss_list.append(avg_loss)\n",
        "                total_loss = 0\n",
        "                \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        acc = check_accuracy(model_gpu, valid_loader)\n",
        "        print('acc = %f' %(acc))\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model_gpu.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            'acc_list': acc_list,\n",
        "            }, model_backup_path)\n",
        "            \n",
        "def check_accuracy(model, loader):\n",
        "    print('Checking accuracy on test set')   \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval() \n",
        "    for x, y in loader:\n",
        "        x_var = Variable(x.type(gpu_dtype))\n",
        "\n",
        "        scores = model(x_var)\n",
        "        _, preds = scores.data.cpu().max(1)\n",
        "        num_correct += (preds == y).sum()\n",
        "        num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    acc_list.append(acc)\n",
        "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "    return acc\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggvpMu36Yw2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.size()\n",
        "        return x.view(N, -1)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-gYHw0Jlbwt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "b8385eeb-f0f1-4ebc-b7dc-68329f6500e4"
      },
      "source": [
        "print_every = 2\n",
        "gpu_dtype = torch.cuda.FloatTensor\n",
        "\n",
        "\n",
        "'''\n",
        "Kerv2d\n",
        "kervolution with following options:\n",
        "kernel_type: [linear, polynomial, gaussian, etc.]\n",
        "default is convolution:\n",
        "          kernel_type --> linear,\n",
        "balance, power, gamma is valid only when the kernel_type is specified\n",
        "if learnable_kernel = True,  they just be the initial value of learable parameters\n",
        "if learnable_kernel = False, they are the value of kernel_type's parameter\n",
        "the parameter [power] cannot be learned due to integer limitation\n",
        "dilation (int or tuple, optional): Spacing between kernel\n",
        "elements. Default: 1\n",
        "groups (int, optional): Number of blocked connections from input\n",
        "channels to output channels. Default: 1\n",
        "bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n",
        "kernel_type (str), Default: 'linear'\n",
        "learnable_kernel (bool): Learnable kernel parameters.  Default: False \n",
        "balance: 0, 1\n",
        "power: 3, 4, 5\n",
        "gamma:\n",
        "'''\n",
        "\n",
        "\n",
        "model_base = nn.Sequential( \n",
        "                nn.Kerv2d(in_channels , out_1, padding=padding_1, dilation=1, groups=1, bias=True, \n",
        "                          kernel_type='linear', kernel_size=k_size_1,# learnable_kernel=True,\n",
        "                          #kernel_regularizer=True, stride=1, balance=1, power=3, gamma=1\n",
        "                          ), \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_1),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_1 , out_2, padding= padding_1, kernel_size=k_size_1, stride=1), \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_2),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_2 , out_3, padding= padding_1, kernel_size=k_size_1, stride=1),  \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_3),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_3 , out_4, padding= padding_1, kernel_size=k_size_1, stride=1),  \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_4),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Dropout(0.5),\n",
        "                Flatten(),\n",
        "                nn.Linear(4608,64),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Linear(64,2)\n",
        "            )\n",
        "model_gpu = model_base.type(gpu_dtype)\n",
        "print(model_gpu)\n",
        "loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Kerv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (4): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (5): ReLU(inplace=True)\n",
            "  (6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (8): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (9): ReLU(inplace=True)\n",
            "  (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (12): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (13): ReLU(inplace=True)\n",
            "  (14): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (16): Dropout(p=0.5, inplace=False)\n",
            "  (17): Flatten()\n",
            "  (18): Linear(in_features=4608, out_features=64, bias=True)\n",
            "  (19): ReLU(inplace=True)\n",
            "  (20): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgmexhBRZAK6",
        "colab_type": "code",
        "outputId": "fb31b5ac-92a2-4307-9589-17e95c700e0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs)\n",
        "check_accuracy(model_gpu, valid_loader)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 1 / 100\n",
            "t = 2, avg_loss = 0.6755\n",
            "t = 4, avg_loss = 0.5442\n",
            "t = 6, avg_loss = 0.6624\n",
            "t = 8, avg_loss = 0.4260\n",
            "t = 10, avg_loss = 0.6115\n",
            "t = 12, avg_loss = 0.6081\n",
            "t = 14, avg_loss = 0.5176\n",
            "t = 16, avg_loss = 0.6003\n",
            "t = 18, avg_loss = 0.4849\n",
            "t = 20, avg_loss = 0.3776\n",
            "t = 22, avg_loss = 0.4107\n",
            "t = 24, avg_loss = 0.3302\n",
            "Checking accuracy on test set\n",
            "Got 204 / 400 correct (51.00)\n",
            "acc = 0.510000\n",
            "Starting epoch 2 / 100\n",
            "t = 2, avg_loss = 0.5906\n",
            "t = 4, avg_loss = 0.4207\n",
            "t = 6, avg_loss = 0.4396\n",
            "t = 8, avg_loss = 0.4746\n",
            "t = 10, avg_loss = 0.4256\n",
            "t = 12, avg_loss = 0.4081\n",
            "t = 14, avg_loss = 0.3613\n",
            "t = 16, avg_loss = 0.4956\n",
            "t = 18, avg_loss = 0.3283\n",
            "t = 20, avg_loss = 0.4344\n",
            "t = 22, avg_loss = 0.3572\n",
            "t = 24, avg_loss = 0.3203\n",
            "Checking accuracy on test set\n",
            "Got 262 / 400 correct (65.50)\n",
            "acc = 0.655000\n",
            "Starting epoch 3 / 100\n",
            "t = 2, avg_loss = 0.5263\n",
            "t = 4, avg_loss = 0.3691\n",
            "t = 6, avg_loss = 0.3771\n",
            "t = 8, avg_loss = 0.3958\n",
            "t = 10, avg_loss = 0.4240\n",
            "t = 12, avg_loss = 0.3505\n",
            "t = 14, avg_loss = 0.3649\n",
            "t = 16, avg_loss = 0.3238\n",
            "t = 18, avg_loss = 0.3578\n",
            "t = 20, avg_loss = 0.3067\n",
            "t = 22, avg_loss = 0.3710\n",
            "t = 24, avg_loss = 0.3276\n",
            "Checking accuracy on test set\n",
            "Got 336 / 400 correct (84.00)\n",
            "acc = 0.840000\n",
            "Starting epoch 4 / 100\n",
            "t = 2, avg_loss = 0.5679\n",
            "t = 4, avg_loss = 0.3272\n",
            "t = 6, avg_loss = 0.2393\n",
            "t = 8, avg_loss = 0.4245\n",
            "t = 10, avg_loss = 0.3604\n",
            "t = 12, avg_loss = 0.3369\n",
            "t = 14, avg_loss = 0.3068\n",
            "t = 16, avg_loss = 0.2634\n",
            "t = 18, avg_loss = 0.3544\n",
            "t = 20, avg_loss = 0.3436\n",
            "t = 22, avg_loss = 0.3504\n",
            "t = 24, avg_loss = 0.3675\n",
            "Checking accuracy on test set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 5 / 100\n",
            "t = 2, avg_loss = 0.4844\n",
            "t = 4, avg_loss = 0.3334\n",
            "t = 6, avg_loss = 0.3714\n",
            "t = 8, avg_loss = 0.3319\n",
            "t = 10, avg_loss = 0.2531\n",
            "t = 12, avg_loss = 0.3044\n",
            "t = 14, avg_loss = 0.2507\n",
            "t = 16, avg_loss = 0.3256\n",
            "t = 18, avg_loss = 0.3220\n",
            "t = 20, avg_loss = 0.3815\n",
            "t = 22, avg_loss = 0.3048\n",
            "t = 24, avg_loss = 0.3193\n",
            "Checking accuracy on test set\n",
            "Got 345 / 400 correct (86.25)\n",
            "acc = 0.862500\n",
            "Starting epoch 6 / 100\n",
            "t = 2, avg_loss = 0.4968\n",
            "t = 4, avg_loss = 0.2876\n",
            "t = 6, avg_loss = 0.2901\n",
            "t = 8, avg_loss = 0.2263\n",
            "t = 10, avg_loss = 0.2575\n",
            "t = 12, avg_loss = 0.3141\n",
            "t = 14, avg_loss = 0.2808\n",
            "t = 16, avg_loss = 0.3329\n",
            "t = 18, avg_loss = 0.2570\n",
            "t = 20, avg_loss = 0.3122\n",
            "t = 22, avg_loss = 0.3621\n",
            "t = 24, avg_loss = 0.3338\n",
            "Checking accuracy on test set\n",
            "Got 351 / 400 correct (87.75)\n",
            "acc = 0.877500\n",
            "Starting epoch 7 / 100\n",
            "t = 2, avg_loss = 0.4554\n",
            "t = 4, avg_loss = 0.3428\n",
            "t = 6, avg_loss = 0.2837\n",
            "t = 8, avg_loss = 0.3189\n",
            "t = 10, avg_loss = 0.2966\n",
            "t = 12, avg_loss = 0.2811\n",
            "t = 14, avg_loss = 0.2680\n",
            "t = 16, avg_loss = 0.2269\n",
            "t = 18, avg_loss = 0.2820\n",
            "t = 20, avg_loss = 0.2698\n",
            "t = 22, avg_loss = 0.2620\n",
            "t = 24, avg_loss = 0.2385\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 8 / 100\n",
            "t = 2, avg_loss = 0.4151\n",
            "t = 4, avg_loss = 0.4649\n",
            "t = 6, avg_loss = 0.2979\n",
            "t = 8, avg_loss = 0.2416\n",
            "t = 10, avg_loss = 0.2576\n",
            "t = 12, avg_loss = 0.3128\n",
            "t = 14, avg_loss = 0.2776\n",
            "t = 16, avg_loss = 0.2291\n",
            "t = 18, avg_loss = 0.2380\n",
            "t = 20, avg_loss = 0.4862\n",
            "t = 22, avg_loss = 0.2049\n",
            "t = 24, avg_loss = 0.3253\n",
            "Checking accuracy on test set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 9 / 100\n",
            "t = 2, avg_loss = 0.3867\n",
            "t = 4, avg_loss = 0.2726\n",
            "t = 6, avg_loss = 0.3159\n",
            "t = 8, avg_loss = 0.2135\n",
            "t = 10, avg_loss = 0.2784\n",
            "t = 12, avg_loss = 0.2667\n",
            "t = 14, avg_loss = 0.2807\n",
            "t = 16, avg_loss = 0.2297\n",
            "t = 18, avg_loss = 0.2327\n",
            "t = 20, avg_loss = 0.3001\n",
            "t = 22, avg_loss = 0.2524\n",
            "t = 24, avg_loss = 0.2841\n",
            "Checking accuracy on test set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 10 / 100\n",
            "t = 2, avg_loss = 0.4035\n",
            "t = 4, avg_loss = 0.2536\n",
            "t = 6, avg_loss = 0.3067\n",
            "t = 8, avg_loss = 0.1982\n",
            "t = 10, avg_loss = 0.3056\n",
            "t = 12, avg_loss = 0.3327\n",
            "t = 14, avg_loss = 0.2286\n",
            "t = 16, avg_loss = 0.2279\n",
            "t = 18, avg_loss = 0.2794\n",
            "t = 20, avg_loss = 0.3059\n",
            "t = 22, avg_loss = 0.2134\n",
            "t = 24, avg_loss = 0.2694\n",
            "Checking accuracy on test set\n",
            "Got 344 / 400 correct (86.00)\n",
            "acc = 0.860000\n",
            "Starting epoch 11 / 100\n",
            "t = 2, avg_loss = 0.3660\n",
            "t = 4, avg_loss = 0.1463\n",
            "t = 6, avg_loss = 0.2068\n",
            "t = 8, avg_loss = 0.2543\n",
            "t = 10, avg_loss = 0.2581\n",
            "t = 12, avg_loss = 0.2049\n",
            "t = 14, avg_loss = 0.2291\n",
            "t = 16, avg_loss = 0.2330\n",
            "t = 18, avg_loss = 0.2305\n",
            "t = 20, avg_loss = 0.2316\n",
            "t = 22, avg_loss = 0.2953\n",
            "t = 24, avg_loss = 0.3191\n",
            "Checking accuracy on test set\n",
            "Got 343 / 400 correct (85.75)\n",
            "acc = 0.857500\n",
            "Starting epoch 12 / 100\n",
            "t = 2, avg_loss = 0.4186\n",
            "t = 4, avg_loss = 0.2553\n",
            "t = 6, avg_loss = 0.1867\n",
            "t = 8, avg_loss = 0.2271\n",
            "t = 10, avg_loss = 0.2729\n",
            "t = 12, avg_loss = 0.2144\n",
            "t = 14, avg_loss = 0.2393\n",
            "t = 16, avg_loss = 0.3180\n",
            "t = 18, avg_loss = 0.1660\n",
            "t = 20, avg_loss = 0.2290\n",
            "t = 22, avg_loss = 0.2578\n",
            "t = 24, avg_loss = 0.1836\n",
            "Checking accuracy on test set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 13 / 100\n",
            "t = 2, avg_loss = 0.3224\n",
            "t = 4, avg_loss = 0.1786\n",
            "t = 6, avg_loss = 0.2784\n",
            "t = 8, avg_loss = 0.3080\n",
            "t = 10, avg_loss = 0.2804\n",
            "t = 12, avg_loss = 0.2599\n",
            "t = 14, avg_loss = 0.2502\n",
            "t = 16, avg_loss = 0.2406\n",
            "t = 18, avg_loss = 0.1746\n",
            "t = 20, avg_loss = 0.2773\n",
            "t = 22, avg_loss = 0.2768\n",
            "t = 24, avg_loss = 0.1945\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 14 / 100\n",
            "t = 2, avg_loss = 0.3154\n",
            "t = 4, avg_loss = 0.1788\n",
            "t = 6, avg_loss = 0.2408\n",
            "t = 8, avg_loss = 0.1956\n",
            "t = 10, avg_loss = 0.2050\n",
            "t = 12, avg_loss = 0.2213\n",
            "t = 14, avg_loss = 0.1873\n",
            "t = 16, avg_loss = 0.2054\n",
            "t = 18, avg_loss = 0.2146\n",
            "t = 20, avg_loss = 0.2437\n",
            "t = 22, avg_loss = 0.1450\n",
            "t = 24, avg_loss = 0.2267\n",
            "Checking accuracy on test set\n",
            "Got 351 / 400 correct (87.75)\n",
            "acc = 0.877500\n",
            "Starting epoch 15 / 100\n",
            "t = 2, avg_loss = 0.2583\n",
            "t = 4, avg_loss = 0.2640\n",
            "t = 6, avg_loss = 0.2690\n",
            "t = 8, avg_loss = 0.1783\n",
            "t = 10, avg_loss = 0.1858\n",
            "t = 12, avg_loss = 0.1998\n",
            "t = 14, avg_loss = 0.1528\n",
            "t = 16, avg_loss = 0.2535\n",
            "t = 18, avg_loss = 0.1665\n",
            "t = 20, avg_loss = 0.2033\n",
            "t = 22, avg_loss = 0.2126\n",
            "t = 24, avg_loss = 0.1688\n",
            "Checking accuracy on test set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 16 / 100\n",
            "t = 2, avg_loss = 0.2641\n",
            "t = 4, avg_loss = 0.1416\n",
            "t = 6, avg_loss = 0.2389\n",
            "t = 8, avg_loss = 0.1588\n",
            "t = 10, avg_loss = 0.1609\n",
            "t = 12, avg_loss = 0.2964\n",
            "t = 14, avg_loss = 0.2136\n",
            "t = 16, avg_loss = 0.2473\n",
            "t = 18, avg_loss = 0.1858\n",
            "t = 20, avg_loss = 0.1651\n",
            "t = 22, avg_loss = 0.2021\n",
            "t = 24, avg_loss = 0.2948\n",
            "Checking accuracy on test set\n",
            "Got 345 / 400 correct (86.25)\n",
            "acc = 0.862500\n",
            "Starting epoch 17 / 100\n",
            "t = 2, avg_loss = 0.2912\n",
            "t = 4, avg_loss = 0.1787\n",
            "t = 6, avg_loss = 0.1136\n",
            "t = 8, avg_loss = 0.1255\n",
            "t = 10, avg_loss = 0.1719\n",
            "t = 12, avg_loss = 0.2353\n",
            "t = 14, avg_loss = 0.3254\n",
            "t = 16, avg_loss = 0.2208\n",
            "t = 18, avg_loss = 0.1868\n",
            "t = 20, avg_loss = 0.1500\n",
            "t = 22, avg_loss = 0.1938\n",
            "t = 24, avg_loss = 0.2265\n",
            "Checking accuracy on test set\n",
            "Got 345 / 400 correct (86.25)\n",
            "acc = 0.862500\n",
            "Starting epoch 18 / 100\n",
            "t = 2, avg_loss = 0.2366\n",
            "t = 4, avg_loss = 0.2473\n",
            "t = 6, avg_loss = 0.1377\n",
            "t = 8, avg_loss = 0.2345\n",
            "t = 10, avg_loss = 0.2704\n",
            "t = 12, avg_loss = 0.1517\n",
            "t = 14, avg_loss = 0.1609\n",
            "t = 16, avg_loss = 0.2027\n",
            "t = 18, avg_loss = 0.2191\n",
            "t = 20, avg_loss = 0.1749\n",
            "t = 22, avg_loss = 0.1440\n",
            "t = 24, avg_loss = 0.2336\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 19 / 100\n",
            "t = 2, avg_loss = 0.1827\n",
            "t = 4, avg_loss = 0.1745\n",
            "t = 6, avg_loss = 0.2051\n",
            "t = 8, avg_loss = 0.1996\n",
            "t = 10, avg_loss = 0.1985\n",
            "t = 12, avg_loss = 0.3026\n",
            "t = 14, avg_loss = 0.1948\n",
            "t = 16, avg_loss = 0.1297\n",
            "t = 18, avg_loss = 0.2104\n",
            "t = 20, avg_loss = 0.2466\n",
            "t = 22, avg_loss = 0.1783\n",
            "t = 24, avg_loss = 0.1935\n",
            "Checking accuracy on test set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 20 / 100\n",
            "t = 2, avg_loss = 0.2716\n",
            "t = 4, avg_loss = 0.1745\n",
            "t = 6, avg_loss = 0.1969\n",
            "t = 8, avg_loss = 0.1697\n",
            "t = 10, avg_loss = 0.1973\n",
            "t = 12, avg_loss = 0.2233\n",
            "t = 14, avg_loss = 0.1317\n",
            "t = 16, avg_loss = 0.1846\n",
            "t = 18, avg_loss = 0.0999\n",
            "t = 20, avg_loss = 0.1929\n",
            "t = 22, avg_loss = 0.1743\n",
            "t = 24, avg_loss = 0.1976\n",
            "Checking accuracy on test set\n",
            "Got 346 / 400 correct (86.50)\n",
            "acc = 0.865000\n",
            "Starting epoch 21 / 100\n",
            "t = 2, avg_loss = 0.2670\n",
            "t = 4, avg_loss = 0.1793\n",
            "t = 6, avg_loss = 0.1222\n",
            "t = 8, avg_loss = 0.2338\n",
            "t = 10, avg_loss = 0.2080\n",
            "t = 12, avg_loss = 0.1740\n",
            "t = 14, avg_loss = 0.1581\n",
            "t = 16, avg_loss = 0.1809\n",
            "t = 18, avg_loss = 0.2283\n",
            "t = 20, avg_loss = 0.1741\n",
            "t = 22, avg_loss = 0.1398\n",
            "t = 24, avg_loss = 0.2054\n",
            "Checking accuracy on test set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 22 / 100\n",
            "t = 2, avg_loss = 0.2978\n",
            "t = 4, avg_loss = 0.1803\n",
            "t = 6, avg_loss = 0.2023\n",
            "t = 8, avg_loss = 0.1413\n",
            "t = 10, avg_loss = 0.1553\n",
            "t = 12, avg_loss = 0.1372\n",
            "t = 14, avg_loss = 0.1593\n",
            "t = 16, avg_loss = 0.1784\n",
            "t = 18, avg_loss = 0.1563\n",
            "t = 20, avg_loss = 0.1827\n",
            "t = 22, avg_loss = 0.1895\n",
            "t = 24, avg_loss = 0.1207\n",
            "Checking accuracy on test set\n",
            "Got 343 / 400 correct (85.75)\n",
            "acc = 0.857500\n",
            "Starting epoch 23 / 100\n",
            "t = 2, avg_loss = 0.2250\n",
            "t = 4, avg_loss = 0.1776\n",
            "t = 6, avg_loss = 0.1456\n",
            "t = 8, avg_loss = 0.1565\n",
            "t = 10, avg_loss = 0.1882\n",
            "t = 12, avg_loss = 0.1272\n",
            "t = 14, avg_loss = 0.1676\n",
            "t = 16, avg_loss = 0.1097\n",
            "t = 18, avg_loss = 0.1445\n",
            "t = 20, avg_loss = 0.1908\n",
            "t = 22, avg_loss = 0.1905\n",
            "t = 24, avg_loss = 0.1448\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 24 / 100\n",
            "t = 2, avg_loss = 0.2022\n",
            "t = 4, avg_loss = 0.0757\n",
            "t = 6, avg_loss = 0.1751\n",
            "t = 8, avg_loss = 0.1404\n",
            "t = 10, avg_loss = 0.1974\n",
            "t = 12, avg_loss = 0.1470\n",
            "t = 14, avg_loss = 0.1938\n",
            "t = 16, avg_loss = 0.1501\n",
            "t = 18, avg_loss = 0.1359\n",
            "t = 20, avg_loss = 0.1490\n",
            "t = 22, avg_loss = 0.1735\n",
            "t = 24, avg_loss = 0.1353\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 25 / 100\n",
            "t = 2, avg_loss = 0.2840\n",
            "t = 4, avg_loss = 0.1454\n",
            "t = 6, avg_loss = 0.1259\n",
            "t = 8, avg_loss = 0.1485\n",
            "t = 10, avg_loss = 0.1394\n",
            "t = 12, avg_loss = 0.2806\n",
            "t = 14, avg_loss = 0.1428\n",
            "t = 16, avg_loss = 0.1608\n",
            "t = 18, avg_loss = 0.1249\n",
            "t = 20, avg_loss = 0.1173\n",
            "t = 22, avg_loss = 0.1584\n",
            "t = 24, avg_loss = 0.1306\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 26 / 100\n",
            "t = 2, avg_loss = 0.2270\n",
            "t = 4, avg_loss = 0.1120\n",
            "t = 6, avg_loss = 0.1374\n",
            "t = 8, avg_loss = 0.1304\n",
            "t = 10, avg_loss = 0.0902\n",
            "t = 12, avg_loss = 0.1341\n",
            "t = 14, avg_loss = 0.1684\n",
            "t = 16, avg_loss = 0.1553\n",
            "t = 18, avg_loss = 0.1346\n",
            "t = 20, avg_loss = 0.1645\n",
            "t = 22, avg_loss = 0.1870\n",
            "t = 24, avg_loss = 0.1654\n",
            "Checking accuracy on test set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 27 / 100\n",
            "t = 2, avg_loss = 0.1813\n",
            "t = 4, avg_loss = 0.1075\n",
            "t = 6, avg_loss = 0.1499\n",
            "t = 8, avg_loss = 0.1635\n",
            "t = 10, avg_loss = 0.1273\n",
            "t = 12, avg_loss = 0.0976\n",
            "t = 14, avg_loss = 0.2008\n",
            "t = 16, avg_loss = 0.1206\n",
            "t = 18, avg_loss = 0.1087\n",
            "t = 20, avg_loss = 0.1990\n",
            "t = 22, avg_loss = 0.1602\n",
            "t = 24, avg_loss = 0.1247\n",
            "Checking accuracy on test set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 28 / 100\n",
            "t = 2, avg_loss = 0.2608\n",
            "t = 4, avg_loss = 0.1481\n",
            "t = 6, avg_loss = 0.0996\n",
            "t = 8, avg_loss = 0.1673\n",
            "t = 10, avg_loss = 0.1102\n",
            "t = 12, avg_loss = 0.1121\n",
            "t = 14, avg_loss = 0.0963\n",
            "t = 16, avg_loss = 0.1784\n",
            "t = 18, avg_loss = 0.1772\n",
            "t = 20, avg_loss = 0.1677\n",
            "t = 22, avg_loss = 0.1316\n",
            "t = 24, avg_loss = 0.1411\n",
            "Checking accuracy on test set\n",
            "Got 351 / 400 correct (87.75)\n",
            "acc = 0.877500\n",
            "Starting epoch 29 / 100\n",
            "t = 2, avg_loss = 0.2165\n",
            "t = 4, avg_loss = 0.1226\n",
            "t = 6, avg_loss = 0.1393\n",
            "t = 8, avg_loss = 0.1096\n",
            "t = 10, avg_loss = 0.0901\n",
            "t = 12, avg_loss = 0.1329\n",
            "t = 14, avg_loss = 0.1959\n",
            "t = 16, avg_loss = 0.1001\n",
            "t = 18, avg_loss = 0.1895\n",
            "t = 20, avg_loss = 0.1082\n",
            "t = 22, avg_loss = 0.1081\n",
            "t = 24, avg_loss = 0.1036\n",
            "Checking accuracy on test set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 30 / 100\n",
            "t = 2, avg_loss = 0.1578\n",
            "t = 4, avg_loss = 0.1563\n",
            "t = 6, avg_loss = 0.1216\n",
            "t = 8, avg_loss = 0.1074\n",
            "t = 10, avg_loss = 0.0891\n",
            "t = 12, avg_loss = 0.0919\n",
            "t = 14, avg_loss = 0.1451\n",
            "t = 16, avg_loss = 0.1201\n",
            "t = 18, avg_loss = 0.1626\n",
            "t = 20, avg_loss = 0.1108\n",
            "t = 22, avg_loss = 0.0896\n",
            "t = 24, avg_loss = 0.1320\n",
            "Checking accuracy on test set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 31 / 100\n",
            "t = 2, avg_loss = 0.1457\n",
            "t = 4, avg_loss = 0.0772\n",
            "t = 6, avg_loss = 0.1214\n",
            "t = 8, avg_loss = 0.1627\n",
            "t = 10, avg_loss = 0.1516\n",
            "t = 12, avg_loss = 0.1415\n",
            "t = 14, avg_loss = 0.1402\n",
            "t = 16, avg_loss = 0.1268\n",
            "t = 18, avg_loss = 0.1638\n",
            "t = 20, avg_loss = 0.1200\n",
            "t = 22, avg_loss = 0.1918\n",
            "t = 24, avg_loss = 0.1117\n",
            "Checking accuracy on test set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 32 / 100\n",
            "t = 2, avg_loss = 0.2031\n",
            "t = 4, avg_loss = 0.1009\n",
            "t = 6, avg_loss = 0.1629\n",
            "t = 8, avg_loss = 0.1132\n",
            "t = 10, avg_loss = 0.1122\n",
            "t = 12, avg_loss = 0.1309\n",
            "t = 14, avg_loss = 0.0997\n",
            "t = 16, avg_loss = 0.1940\n",
            "t = 18, avg_loss = 0.0933\n",
            "t = 20, avg_loss = 0.0947\n",
            "t = 22, avg_loss = 0.1009\n",
            "t = 24, avg_loss = 0.2151\n",
            "Checking accuracy on test set\n",
            "Got 341 / 400 correct (85.25)\n",
            "acc = 0.852500\n",
            "Starting epoch 33 / 100\n",
            "t = 2, avg_loss = 0.2149\n",
            "t = 4, avg_loss = 0.0824\n",
            "t = 6, avg_loss = 0.0904\n",
            "t = 8, avg_loss = 0.0652\n",
            "t = 10, avg_loss = 0.1178\n",
            "t = 12, avg_loss = 0.1050\n",
            "t = 14, avg_loss = 0.0811\n",
            "t = 16, avg_loss = 0.1755\n",
            "t = 18, avg_loss = 0.0991\n",
            "t = 20, avg_loss = 0.1243\n",
            "t = 22, avg_loss = 0.1104\n",
            "t = 24, avg_loss = 0.1018\n",
            "Checking accuracy on test set\n",
            "Got 340 / 400 correct (85.00)\n",
            "acc = 0.850000\n",
            "Starting epoch 34 / 100\n",
            "t = 2, avg_loss = 0.1621\n",
            "t = 4, avg_loss = 0.0992\n",
            "t = 6, avg_loss = 0.1347\n",
            "t = 8, avg_loss = 0.1020\n",
            "t = 10, avg_loss = 0.0845\n",
            "t = 12, avg_loss = 0.1284\n",
            "t = 14, avg_loss = 0.1749\n",
            "t = 16, avg_loss = 0.0944\n",
            "t = 18, avg_loss = 0.1155\n",
            "t = 20, avg_loss = 0.0891\n",
            "t = 22, avg_loss = 0.0790\n",
            "t = 24, avg_loss = 0.1756\n",
            "Checking accuracy on test set\n",
            "Got 346 / 400 correct (86.50)\n",
            "acc = 0.865000\n",
            "Starting epoch 35 / 100\n",
            "t = 2, avg_loss = 0.2137\n",
            "t = 4, avg_loss = 0.0774\n",
            "t = 6, avg_loss = 0.0809\n",
            "t = 8, avg_loss = 0.0780\n",
            "t = 10, avg_loss = 0.0849\n",
            "t = 12, avg_loss = 0.0574\n",
            "t = 14, avg_loss = 0.0990\n",
            "t = 16, avg_loss = 0.1200\n",
            "t = 18, avg_loss = 0.1056\n",
            "t = 20, avg_loss = 0.1408\n",
            "t = 22, avg_loss = 0.1241\n",
            "t = 24, avg_loss = 0.1323\n",
            "Checking accuracy on test set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 36 / 100\n",
            "t = 2, avg_loss = 0.1605\n",
            "t = 4, avg_loss = 0.0936\n",
            "t = 6, avg_loss = 0.0821\n",
            "t = 8, avg_loss = 0.0799\n",
            "t = 10, avg_loss = 0.1062\n",
            "t = 12, avg_loss = 0.0979\n",
            "t = 14, avg_loss = 0.1126\n",
            "t = 16, avg_loss = 0.0788\n",
            "t = 18, avg_loss = 0.0922\n",
            "t = 20, avg_loss = 0.0929\n",
            "t = 22, avg_loss = 0.1048\n",
            "t = 24, avg_loss = 0.1341\n",
            "Checking accuracy on test set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 37 / 100\n",
            "t = 2, avg_loss = 0.1184\n",
            "t = 4, avg_loss = 0.0993\n",
            "t = 6, avg_loss = 0.1144\n",
            "t = 8, avg_loss = 0.0863\n",
            "t = 10, avg_loss = 0.0862\n",
            "t = 12, avg_loss = 0.1153\n",
            "t = 14, avg_loss = 0.1278\n",
            "t = 16, avg_loss = 0.1046\n",
            "t = 18, avg_loss = 0.0972\n",
            "t = 20, avg_loss = 0.0830\n",
            "t = 22, avg_loss = 0.1290\n",
            "t = 24, avg_loss = 0.0966\n",
            "Checking accuracy on test set\n",
            "Got 342 / 400 correct (85.50)\n",
            "acc = 0.855000\n",
            "Starting epoch 38 / 100\n",
            "t = 2, avg_loss = 0.1137\n",
            "t = 4, avg_loss = 0.0899\n",
            "t = 6, avg_loss = 0.1163\n",
            "t = 8, avg_loss = 0.0820\n",
            "t = 10, avg_loss = 0.1170\n",
            "t = 12, avg_loss = 0.1063\n",
            "t = 14, avg_loss = 0.1320\n",
            "t = 16, avg_loss = 0.0970\n",
            "t = 18, avg_loss = 0.0970\n",
            "t = 20, avg_loss = 0.1053\n",
            "t = 22, avg_loss = 0.1224\n",
            "t = 24, avg_loss = 0.1041\n",
            "Checking accuracy on test set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 39 / 100\n",
            "t = 2, avg_loss = 0.1525\n",
            "t = 4, avg_loss = 0.1051\n",
            "t = 6, avg_loss = 0.1240\n",
            "t = 8, avg_loss = 0.1107\n",
            "t = 10, avg_loss = 0.0646\n",
            "t = 12, avg_loss = 0.1129\n",
            "t = 14, avg_loss = 0.0552\n",
            "t = 16, avg_loss = 0.0870\n",
            "t = 18, avg_loss = 0.0996\n",
            "t = 20, avg_loss = 0.0897\n",
            "t = 22, avg_loss = 0.0736\n",
            "t = 24, avg_loss = 0.0881\n",
            "Checking accuracy on test set\n",
            "Got 344 / 400 correct (86.00)\n",
            "acc = 0.860000\n",
            "Starting epoch 40 / 100\n",
            "t = 2, avg_loss = 0.0883\n",
            "t = 4, avg_loss = 0.0900\n",
            "t = 6, avg_loss = 0.0623\n",
            "t = 8, avg_loss = 0.0951\n",
            "t = 10, avg_loss = 0.0584\n",
            "t = 12, avg_loss = 0.0784\n",
            "t = 14, avg_loss = 0.0785\n",
            "t = 16, avg_loss = 0.0851\n",
            "t = 18, avg_loss = 0.1214\n",
            "t = 20, avg_loss = 0.0569\n",
            "t = 22, avg_loss = 0.1218\n",
            "t = 24, avg_loss = 0.1087\n",
            "Checking accuracy on test set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 41 / 100\n",
            "t = 2, avg_loss = 0.1339\n",
            "t = 4, avg_loss = 0.0827\n",
            "t = 6, avg_loss = 0.1291\n",
            "t = 8, avg_loss = 0.0435\n",
            "t = 10, avg_loss = 0.0551\n",
            "t = 12, avg_loss = 0.0780\n",
            "t = 14, avg_loss = 0.1208\n",
            "t = 16, avg_loss = 0.0751\n",
            "t = 18, avg_loss = 0.1209\n",
            "t = 20, avg_loss = 0.0880\n",
            "t = 22, avg_loss = 0.0845\n",
            "t = 24, avg_loss = 0.0706\n",
            "Checking accuracy on test set\n",
            "Got 351 / 400 correct (87.75)\n",
            "acc = 0.877500\n",
            "Starting epoch 42 / 100\n",
            "t = 2, avg_loss = 0.1028\n",
            "t = 4, avg_loss = 0.0645\n",
            "t = 6, avg_loss = 0.1352\n",
            "t = 8, avg_loss = 0.0740\n",
            "t = 10, avg_loss = 0.1150\n",
            "t = 12, avg_loss = 0.0522\n",
            "t = 14, avg_loss = 0.1248\n",
            "t = 16, avg_loss = 0.0879\n",
            "t = 18, avg_loss = 0.0819\n",
            "t = 20, avg_loss = 0.1184\n",
            "t = 22, avg_loss = 0.0659\n",
            "t = 24, avg_loss = 0.1235\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 43 / 100\n",
            "t = 2, avg_loss = 0.1193\n",
            "t = 4, avg_loss = 0.1069\n",
            "t = 6, avg_loss = 0.1126\n",
            "t = 8, avg_loss = 0.0801\n",
            "t = 10, avg_loss = 0.1187\n",
            "t = 12, avg_loss = 0.0961\n",
            "t = 14, avg_loss = 0.0988\n",
            "t = 16, avg_loss = 0.0661\n",
            "t = 18, avg_loss = 0.0612\n",
            "t = 20, avg_loss = 0.0914\n",
            "t = 22, avg_loss = 0.1310\n",
            "t = 24, avg_loss = 0.0508\n",
            "Checking accuracy on test set\n",
            "Got 346 / 400 correct (86.50)\n",
            "acc = 0.865000\n",
            "Starting epoch 44 / 100\n",
            "t = 2, avg_loss = 0.1320\n",
            "t = 4, avg_loss = 0.0950\n",
            "t = 6, avg_loss = 0.0657\n",
            "t = 8, avg_loss = 0.1231\n",
            "t = 10, avg_loss = 0.0947\n",
            "t = 12, avg_loss = 0.0494\n",
            "t = 14, avg_loss = 0.0883\n",
            "t = 16, avg_loss = 0.0829\n",
            "t = 18, avg_loss = 0.0689\n",
            "t = 20, avg_loss = 0.0676\n",
            "t = 22, avg_loss = 0.0504\n",
            "t = 24, avg_loss = 0.0978\n",
            "Checking accuracy on test set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 45 / 100\n",
            "t = 2, avg_loss = 0.0797\n",
            "t = 4, avg_loss = 0.0885\n",
            "t = 6, avg_loss = 0.0915\n",
            "t = 8, avg_loss = 0.1335\n",
            "t = 10, avg_loss = 0.0617\n",
            "t = 12, avg_loss = 0.0543\n",
            "t = 14, avg_loss = 0.0692\n",
            "t = 16, avg_loss = 0.0802\n",
            "t = 18, avg_loss = 0.0627\n",
            "t = 20, avg_loss = 0.0726\n",
            "t = 22, avg_loss = 0.0623\n",
            "t = 24, avg_loss = 0.0628\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 46 / 100\n",
            "t = 2, avg_loss = 0.0759\n",
            "t = 4, avg_loss = 0.0782\n",
            "t = 6, avg_loss = 0.0417\n",
            "t = 8, avg_loss = 0.1424\n",
            "t = 10, avg_loss = 0.0560\n",
            "t = 12, avg_loss = 0.0429\n",
            "t = 14, avg_loss = 0.0671\n",
            "t = 16, avg_loss = 0.0917\n",
            "t = 18, avg_loss = 0.1127\n",
            "t = 20, avg_loss = 0.0823\n",
            "t = 22, avg_loss = 0.0803\n",
            "t = 24, avg_loss = 0.0715\n",
            "Checking accuracy on test set\n",
            "Got 351 / 400 correct (87.75)\n",
            "acc = 0.877500\n",
            "Starting epoch 47 / 100\n",
            "t = 2, avg_loss = 0.0724\n",
            "t = 4, avg_loss = 0.0610\n",
            "t = 6, avg_loss = 0.0720\n",
            "t = 8, avg_loss = 0.0721\n",
            "t = 10, avg_loss = 0.0463\n",
            "t = 12, avg_loss = 0.0567\n",
            "t = 14, avg_loss = 0.0748\n",
            "t = 16, avg_loss = 0.1014\n",
            "t = 18, avg_loss = 0.0990\n",
            "t = 20, avg_loss = 0.1595\n",
            "t = 22, avg_loss = 0.0691\n",
            "t = 24, avg_loss = 0.0510\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 48 / 100\n",
            "t = 2, avg_loss = 0.0859\n",
            "t = 4, avg_loss = 0.0522\n",
            "t = 6, avg_loss = 0.0747\n",
            "t = 8, avg_loss = 0.0853\n",
            "t = 10, avg_loss = 0.0612\n",
            "t = 12, avg_loss = 0.0676\n",
            "t = 14, avg_loss = 0.0306\n",
            "t = 16, avg_loss = 0.0479\n",
            "t = 18, avg_loss = 0.0802\n",
            "t = 20, avg_loss = 0.0756\n",
            "t = 22, avg_loss = 0.0493\n",
            "t = 24, avg_loss = 0.1313\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 49 / 100\n",
            "t = 2, avg_loss = 0.0753\n",
            "t = 4, avg_loss = 0.0787\n",
            "t = 6, avg_loss = 0.0522\n",
            "t = 8, avg_loss = 0.1229\n",
            "t = 10, avg_loss = 0.0594\n",
            "t = 12, avg_loss = 0.0977\n",
            "t = 14, avg_loss = 0.1088\n",
            "t = 16, avg_loss = 0.0660\n",
            "t = 18, avg_loss = 0.0467\n",
            "t = 20, avg_loss = 0.0805\n",
            "t = 22, avg_loss = 0.1124\n",
            "t = 24, avg_loss = 0.0755\n",
            "Checking accuracy on test set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 50 / 100\n",
            "t = 2, avg_loss = 0.1326\n",
            "t = 4, avg_loss = 0.0484\n",
            "t = 6, avg_loss = 0.0530\n",
            "t = 8, avg_loss = 0.0999\n",
            "t = 10, avg_loss = 0.0437\n",
            "t = 12, avg_loss = 0.0584\n",
            "t = 14, avg_loss = 0.0491\n",
            "t = 16, avg_loss = 0.0922\n",
            "t = 18, avg_loss = 0.0473\n",
            "t = 20, avg_loss = 0.0751\n",
            "t = 22, avg_loss = 0.0861\n",
            "t = 24, avg_loss = 0.1092\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 51 / 100\n",
            "t = 2, avg_loss = 0.0503\n",
            "t = 4, avg_loss = 0.0485\n",
            "t = 6, avg_loss = 0.1033\n",
            "t = 8, avg_loss = 0.0385\n",
            "t = 10, avg_loss = 0.0676\n",
            "t = 12, avg_loss = 0.0538\n",
            "t = 14, avg_loss = 0.0546\n",
            "t = 16, avg_loss = 0.0743\n",
            "t = 18, avg_loss = 0.0221\n",
            "t = 20, avg_loss = 0.0810\n",
            "t = 22, avg_loss = 0.0585\n",
            "t = 24, avg_loss = 0.0706\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 52 / 100\n",
            "t = 2, avg_loss = 0.1126\n",
            "t = 4, avg_loss = 0.0553\n",
            "t = 6, avg_loss = 0.0632\n",
            "t = 8, avg_loss = 0.0840\n",
            "t = 10, avg_loss = 0.0695\n",
            "t = 12, avg_loss = 0.0690\n",
            "t = 14, avg_loss = 0.0472\n",
            "t = 16, avg_loss = 0.0427\n",
            "t = 18, avg_loss = 0.0462\n",
            "t = 20, avg_loss = 0.0849\n",
            "t = 22, avg_loss = 0.0450\n",
            "t = 24, avg_loss = 0.0292\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 53 / 100\n",
            "t = 2, avg_loss = 0.0787\n",
            "t = 4, avg_loss = 0.0526\n",
            "t = 6, avg_loss = 0.0604\n",
            "t = 8, avg_loss = 0.0491\n",
            "t = 10, avg_loss = 0.0537\n",
            "t = 12, avg_loss = 0.0495\n",
            "t = 14, avg_loss = 0.0799\n",
            "t = 16, avg_loss = 0.0902\n",
            "t = 18, avg_loss = 0.0595\n",
            "t = 20, avg_loss = 0.0267\n",
            "t = 22, avg_loss = 0.0602\n",
            "t = 24, avg_loss = 0.0693\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 54 / 100\n",
            "t = 2, avg_loss = 0.0987\n",
            "t = 4, avg_loss = 0.0467\n",
            "t = 6, avg_loss = 0.0382\n",
            "t = 8, avg_loss = 0.0323\n",
            "t = 10, avg_loss = 0.0811\n",
            "t = 12, avg_loss = 0.0522\n",
            "t = 14, avg_loss = 0.0427\n",
            "t = 16, avg_loss = 0.0600\n",
            "t = 18, avg_loss = 0.0569\n",
            "t = 20, avg_loss = 0.0561\n",
            "t = 22, avg_loss = 0.0740\n",
            "t = 24, avg_loss = 0.0646\n",
            "Checking accuracy on test set\n",
            "Got 346 / 400 correct (86.50)\n",
            "acc = 0.865000\n",
            "Starting epoch 55 / 100\n",
            "t = 2, avg_loss = 0.0677\n",
            "t = 4, avg_loss = 0.0355\n",
            "t = 6, avg_loss = 0.0834\n",
            "t = 8, avg_loss = 0.0593\n",
            "t = 10, avg_loss = 0.0482\n",
            "t = 12, avg_loss = 0.0474\n",
            "t = 14, avg_loss = 0.0180\n",
            "t = 16, avg_loss = 0.0456\n",
            "t = 18, avg_loss = 0.0544\n",
            "t = 20, avg_loss = 0.0652\n",
            "t = 22, avg_loss = 0.0524\n",
            "t = 24, avg_loss = 0.0897\n",
            "Checking accuracy on test set\n",
            "Got 359 / 400 correct (89.75)\n",
            "acc = 0.897500\n",
            "Starting epoch 56 / 100\n",
            "t = 2, avg_loss = 0.0693\n",
            "t = 4, avg_loss = 0.0635\n",
            "t = 6, avg_loss = 0.0429\n",
            "t = 8, avg_loss = 0.0329\n",
            "t = 10, avg_loss = 0.0220\n",
            "t = 12, avg_loss = 0.0378\n",
            "t = 14, avg_loss = 0.0498\n",
            "t = 16, avg_loss = 0.0298\n",
            "t = 18, avg_loss = 0.0632\n",
            "t = 20, avg_loss = 0.0763\n",
            "t = 22, avg_loss = 0.0350\n",
            "t = 24, avg_loss = 0.0542\n",
            "Checking accuracy on test set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 57 / 100\n",
            "t = 2, avg_loss = 0.0600\n",
            "t = 4, avg_loss = 0.0515\n",
            "t = 6, avg_loss = 0.0603\n",
            "t = 8, avg_loss = 0.0763\n",
            "t = 10, avg_loss = 0.0296\n",
            "t = 12, avg_loss = 0.0431\n",
            "t = 14, avg_loss = 0.0589\n",
            "t = 16, avg_loss = 0.0468\n",
            "t = 18, avg_loss = 0.0465\n",
            "t = 20, avg_loss = 0.0265\n",
            "t = 22, avg_loss = 0.0977\n",
            "t = 24, avg_loss = 0.0282\n",
            "Checking accuracy on test set\n",
            "Got 345 / 400 correct (86.25)\n",
            "acc = 0.862500\n",
            "Starting epoch 58 / 100\n",
            "t = 2, avg_loss = 0.0662\n",
            "t = 4, avg_loss = 0.0612\n",
            "t = 6, avg_loss = 0.0631\n",
            "t = 8, avg_loss = 0.0301\n",
            "t = 10, avg_loss = 0.0240\n",
            "t = 12, avg_loss = 0.0552\n",
            "t = 14, avg_loss = 0.0882\n",
            "t = 16, avg_loss = 0.0325\n",
            "t = 18, avg_loss = 0.0628\n",
            "t = 20, avg_loss = 0.0528\n",
            "t = 22, avg_loss = 0.0463\n",
            "t = 24, avg_loss = 0.0425\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 59 / 100\n",
            "t = 2, avg_loss = 0.0569\n",
            "t = 4, avg_loss = 0.0312\n",
            "t = 6, avg_loss = 0.0532\n",
            "t = 8, avg_loss = 0.0646\n",
            "t = 10, avg_loss = 0.0795\n",
            "t = 12, avg_loss = 0.0616\n",
            "t = 14, avg_loss = 0.0655\n",
            "t = 16, avg_loss = 0.0264\n",
            "t = 18, avg_loss = 0.0349\n",
            "t = 20, avg_loss = 0.0334\n",
            "t = 22, avg_loss = 0.0310\n",
            "t = 24, avg_loss = 0.0633\n",
            "Checking accuracy on test set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 60 / 100\n",
            "t = 2, avg_loss = 0.0988\n",
            "t = 4, avg_loss = 0.0232\n",
            "t = 6, avg_loss = 0.0297\n",
            "t = 8, avg_loss = 0.0614\n",
            "t = 10, avg_loss = 0.0395\n",
            "t = 12, avg_loss = 0.0363\n",
            "t = 14, avg_loss = 0.0482\n",
            "t = 16, avg_loss = 0.0183\n",
            "t = 18, avg_loss = 0.0635\n",
            "t = 20, avg_loss = 0.0381\n",
            "t = 22, avg_loss = 0.0346\n",
            "t = 24, avg_loss = 0.0654\n",
            "Checking accuracy on test set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 61 / 100\n",
            "t = 2, avg_loss = 0.0610\n",
            "t = 4, avg_loss = 0.0275\n",
            "t = 6, avg_loss = 0.0345\n",
            "t = 8, avg_loss = 0.0450\n",
            "t = 10, avg_loss = 0.0490\n",
            "t = 12, avg_loss = 0.0687\n",
            "t = 14, avg_loss = 0.0210\n",
            "t = 16, avg_loss = 0.0573\n",
            "t = 18, avg_loss = 0.0298\n",
            "t = 20, avg_loss = 0.0318\n",
            "t = 22, avg_loss = 0.0390\n",
            "t = 24, avg_loss = 0.0536\n",
            "Checking accuracy on test set\n",
            "Got 346 / 400 correct (86.50)\n",
            "acc = 0.865000\n",
            "Starting epoch 62 / 100\n",
            "t = 2, avg_loss = 0.0702\n",
            "t = 4, avg_loss = 0.0302\n",
            "t = 6, avg_loss = 0.0294\n",
            "t = 8, avg_loss = 0.0498\n",
            "t = 10, avg_loss = 0.0424\n",
            "t = 12, avg_loss = 0.0656\n",
            "t = 14, avg_loss = 0.0636\n",
            "t = 16, avg_loss = 0.0360\n",
            "t = 18, avg_loss = 0.0728\n",
            "t = 20, avg_loss = 0.0466\n",
            "t = 22, avg_loss = 0.0395\n",
            "t = 24, avg_loss = 0.0737\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 63 / 100\n",
            "t = 2, avg_loss = 0.0514\n",
            "t = 4, avg_loss = 0.0282\n",
            "t = 6, avg_loss = 0.0283\n",
            "t = 8, avg_loss = 0.0225\n",
            "t = 10, avg_loss = 0.0281\n",
            "t = 12, avg_loss = 0.0597\n",
            "t = 14, avg_loss = 0.0355\n",
            "t = 16, avg_loss = 0.0586\n",
            "t = 18, avg_loss = 0.0310\n",
            "t = 20, avg_loss = 0.0325\n",
            "t = 22, avg_loss = 0.0276\n",
            "t = 24, avg_loss = 0.0418\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 64 / 100\n",
            "t = 2, avg_loss = 0.0708\n",
            "t = 4, avg_loss = 0.0317\n",
            "t = 6, avg_loss = 0.0403\n",
            "t = 8, avg_loss = 0.0666\n",
            "t = 10, avg_loss = 0.0359\n",
            "t = 12, avg_loss = 0.0349\n",
            "t = 14, avg_loss = 0.0283\n",
            "t = 16, avg_loss = 0.0281\n",
            "t = 18, avg_loss = 0.0316\n",
            "t = 20, avg_loss = 0.0189\n",
            "t = 22, avg_loss = 0.0225\n",
            "t = 24, avg_loss = 0.0462\n",
            "Checking accuracy on test set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 65 / 100\n",
            "t = 2, avg_loss = 0.0708\n",
            "t = 4, avg_loss = 0.0626\n",
            "t = 6, avg_loss = 0.0496\n",
            "t = 8, avg_loss = 0.0429\n",
            "t = 10, avg_loss = 0.0271\n",
            "t = 12, avg_loss = 0.0545\n",
            "t = 14, avg_loss = 0.0457\n",
            "t = 16, avg_loss = 0.0233\n",
            "t = 18, avg_loss = 0.0364\n",
            "t = 20, avg_loss = 0.0628\n",
            "t = 22, avg_loss = 0.0365\n",
            "t = 24, avg_loss = 0.0222\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 66 / 100\n",
            "t = 2, avg_loss = 0.0442\n",
            "t = 4, avg_loss = 0.0960\n",
            "t = 6, avg_loss = 0.0799\n",
            "t = 8, avg_loss = 0.0203\n",
            "t = 10, avg_loss = 0.0464\n",
            "t = 12, avg_loss = 0.0204\n",
            "t = 14, avg_loss = 0.0257\n",
            "t = 16, avg_loss = 0.0429\n",
            "t = 18, avg_loss = 0.0695\n",
            "t = 20, avg_loss = 0.0422\n",
            "t = 22, avg_loss = 0.0493\n",
            "t = 24, avg_loss = 0.0503\n",
            "Checking accuracy on test set\n",
            "Got 340 / 400 correct (85.00)\n",
            "acc = 0.850000\n",
            "Starting epoch 67 / 100\n",
            "t = 2, avg_loss = 0.0598\n",
            "t = 4, avg_loss = 0.0410\n",
            "t = 6, avg_loss = 0.0136\n",
            "t = 8, avg_loss = 0.0702\n",
            "t = 10, avg_loss = 0.0731\n",
            "t = 12, avg_loss = 0.0257\n",
            "t = 14, avg_loss = 0.0270\n",
            "t = 16, avg_loss = 0.0406\n",
            "t = 18, avg_loss = 0.0446\n",
            "t = 20, avg_loss = 0.0342\n",
            "t = 22, avg_loss = 0.0681\n",
            "t = 24, avg_loss = 0.0435\n",
            "Checking accuracy on test set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 68 / 100\n",
            "t = 2, avg_loss = 0.0307\n",
            "t = 4, avg_loss = 0.0589\n",
            "t = 6, avg_loss = 0.0846\n",
            "t = 8, avg_loss = 0.0384\n",
            "t = 10, avg_loss = 0.0509\n",
            "t = 12, avg_loss = 0.0290\n",
            "t = 14, avg_loss = 0.0807\n",
            "t = 16, avg_loss = 0.0868\n",
            "t = 18, avg_loss = 0.0445\n",
            "t = 20, avg_loss = 0.0576\n",
            "t = 22, avg_loss = 0.0501\n",
            "t = 24, avg_loss = 0.0437\n",
            "Checking accuracy on test set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 69 / 100\n",
            "t = 2, avg_loss = 0.1161\n",
            "t = 4, avg_loss = 0.0304\n",
            "t = 6, avg_loss = 0.0467\n",
            "t = 8, avg_loss = 0.0616\n",
            "t = 10, avg_loss = 0.0559\n",
            "t = 12, avg_loss = 0.0194\n",
            "t = 14, avg_loss = 0.0509\n",
            "t = 16, avg_loss = 0.0534\n",
            "t = 18, avg_loss = 0.0583\n",
            "t = 20, avg_loss = 0.0387\n",
            "t = 22, avg_loss = 0.0253\n",
            "t = 24, avg_loss = 0.0304\n",
            "Checking accuracy on test set\n",
            "Got 337 / 400 correct (84.25)\n",
            "acc = 0.842500\n",
            "Starting epoch 70 / 100\n",
            "t = 2, avg_loss = 0.1030\n",
            "t = 4, avg_loss = 0.0329\n",
            "t = 6, avg_loss = 0.0380\n",
            "t = 8, avg_loss = 0.0551\n",
            "t = 10, avg_loss = 0.0424\n",
            "t = 12, avg_loss = 0.0296\n",
            "t = 14, avg_loss = 0.0182\n",
            "t = 16, avg_loss = 0.0368\n",
            "t = 18, avg_loss = 0.0855\n",
            "t = 20, avg_loss = 0.0200\n",
            "t = 22, avg_loss = 0.0289\n",
            "t = 24, avg_loss = 0.0333\n",
            "Checking accuracy on test set\n",
            "Got 344 / 400 correct (86.00)\n",
            "acc = 0.860000\n",
            "Starting epoch 71 / 100\n",
            "t = 2, avg_loss = 0.0835\n",
            "t = 4, avg_loss = 0.0252\n",
            "t = 6, avg_loss = 0.0265\n",
            "t = 8, avg_loss = 0.0421\n",
            "t = 10, avg_loss = 0.0167\n",
            "t = 12, avg_loss = 0.0732\n",
            "t = 14, avg_loss = 0.0600\n",
            "t = 16, avg_loss = 0.0143\n",
            "t = 18, avg_loss = 0.0816\n",
            "t = 20, avg_loss = 0.0460\n",
            "t = 22, avg_loss = 0.0515\n",
            "t = 24, avg_loss = 0.0450\n",
            "Checking accuracy on test set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 72 / 100\n",
            "t = 2, avg_loss = 0.0777\n",
            "t = 4, avg_loss = 0.0339\n",
            "t = 6, avg_loss = 0.0338\n",
            "t = 8, avg_loss = 0.0202\n",
            "t = 10, avg_loss = 0.0308\n",
            "t = 12, avg_loss = 0.0450\n",
            "t = 14, avg_loss = 0.0316\n",
            "t = 16, avg_loss = 0.0196\n",
            "t = 18, avg_loss = 0.0295\n",
            "t = 20, avg_loss = 0.0701\n",
            "t = 22, avg_loss = 0.0444\n",
            "t = 24, avg_loss = 0.0200\n",
            "Checking accuracy on test set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 73 / 100\n",
            "t = 2, avg_loss = 0.0360\n",
            "t = 4, avg_loss = 0.0347\n",
            "t = 6, avg_loss = 0.0234\n",
            "t = 8, avg_loss = 0.0558\n",
            "t = 10, avg_loss = 0.0460\n",
            "t = 12, avg_loss = 0.0826\n",
            "t = 14, avg_loss = 0.0184\n",
            "t = 16, avg_loss = 0.0506\n",
            "t = 18, avg_loss = 0.0432\n",
            "t = 20, avg_loss = 0.0918\n",
            "t = 22, avg_loss = 0.0679\n",
            "t = 24, avg_loss = 0.0615\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 74 / 100\n",
            "t = 2, avg_loss = 0.0523\n",
            "t = 4, avg_loss = 0.0910\n",
            "t = 6, avg_loss = 0.0317\n",
            "t = 8, avg_loss = 0.0743\n",
            "t = 10, avg_loss = 0.0585\n",
            "t = 12, avg_loss = 0.0190\n",
            "t = 14, avg_loss = 0.0220\n",
            "t = 16, avg_loss = 0.0444\n",
            "t = 18, avg_loss = 0.0341\n",
            "t = 20, avg_loss = 0.0414\n",
            "t = 22, avg_loss = 0.0241\n",
            "t = 24, avg_loss = 0.0598\n",
            "Checking accuracy on test set\n",
            "Got 343 / 400 correct (85.75)\n",
            "acc = 0.857500\n",
            "Starting epoch 75 / 100\n",
            "t = 2, avg_loss = 0.0842\n",
            "t = 4, avg_loss = 0.0513\n",
            "t = 6, avg_loss = 0.0177\n",
            "t = 8, avg_loss = 0.0328\n",
            "t = 10, avg_loss = 0.0333\n",
            "t = 12, avg_loss = 0.0330\n",
            "t = 14, avg_loss = 0.0396\n",
            "t = 16, avg_loss = 0.0181\n",
            "t = 18, avg_loss = 0.0489\n",
            "t = 20, avg_loss = 0.0417\n",
            "t = 22, avg_loss = 0.0221\n",
            "t = 24, avg_loss = 0.0369\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 76 / 100\n",
            "t = 2, avg_loss = 0.0435\n",
            "t = 4, avg_loss = 0.0309\n",
            "t = 6, avg_loss = 0.0231\n",
            "t = 8, avg_loss = 0.0247\n",
            "t = 10, avg_loss = 0.0247\n",
            "t = 12, avg_loss = 0.0182\n",
            "t = 14, avg_loss = 0.0473\n",
            "t = 16, avg_loss = 0.0235\n",
            "t = 18, avg_loss = 0.0325\n",
            "t = 20, avg_loss = 0.0281\n",
            "t = 22, avg_loss = 0.0195\n",
            "t = 24, avg_loss = 0.0375\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 77 / 100\n",
            "t = 2, avg_loss = 0.0234\n",
            "t = 4, avg_loss = 0.0312\n",
            "t = 6, avg_loss = 0.0352\n",
            "t = 8, avg_loss = 0.0224\n",
            "t = 10, avg_loss = 0.0185\n",
            "t = 12, avg_loss = 0.0367\n",
            "t = 14, avg_loss = 0.0396\n",
            "t = 16, avg_loss = 0.0299\n",
            "t = 18, avg_loss = 0.0193\n",
            "t = 20, avg_loss = 0.0190\n",
            "t = 22, avg_loss = 0.0750\n",
            "t = 24, avg_loss = 0.0213\n",
            "Checking accuracy on test set\n",
            "Got 345 / 400 correct (86.25)\n",
            "acc = 0.862500\n",
            "Starting epoch 78 / 100\n",
            "t = 2, avg_loss = 0.0469\n",
            "t = 4, avg_loss = 0.0281\n",
            "t = 6, avg_loss = 0.0558\n",
            "t = 8, avg_loss = 0.0356\n",
            "t = 10, avg_loss = 0.0284\n",
            "t = 12, avg_loss = 0.0469\n",
            "t = 14, avg_loss = 0.0131\n",
            "t = 16, avg_loss = 0.0258\n",
            "t = 18, avg_loss = 0.0650\n",
            "t = 20, avg_loss = 0.0384\n",
            "t = 22, avg_loss = 0.0628\n",
            "t = 24, avg_loss = 0.0129\n",
            "Checking accuracy on test set\n",
            "Got 341 / 400 correct (85.25)\n",
            "acc = 0.852500\n",
            "Starting epoch 79 / 100\n",
            "t = 2, avg_loss = 0.0310\n",
            "t = 4, avg_loss = 0.0179\n",
            "t = 6, avg_loss = 0.0509\n",
            "t = 8, avg_loss = 0.0444\n",
            "t = 10, avg_loss = 0.0323\n",
            "t = 12, avg_loss = 0.0286\n",
            "t = 14, avg_loss = 0.0209\n",
            "t = 16, avg_loss = 0.0307\n",
            "t = 18, avg_loss = 0.0294\n",
            "t = 20, avg_loss = 0.0625\n",
            "t = 22, avg_loss = 0.0348\n",
            "t = 24, avg_loss = 0.0169\n",
            "Checking accuracy on test set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 80 / 100\n",
            "t = 2, avg_loss = 0.0406\n",
            "t = 4, avg_loss = 0.0498\n",
            "t = 6, avg_loss = 0.0473\n",
            "t = 8, avg_loss = 0.0188\n",
            "t = 10, avg_loss = 0.0125\n",
            "t = 12, avg_loss = 0.0169\n",
            "t = 14, avg_loss = 0.0291\n",
            "t = 16, avg_loss = 0.0375\n",
            "t = 18, avg_loss = 0.0410\n",
            "t = 20, avg_loss = 0.0223\n",
            "t = 22, avg_loss = 0.0222\n",
            "t = 24, avg_loss = 0.0253\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 81 / 100\n",
            "t = 2, avg_loss = 0.0330\n",
            "t = 4, avg_loss = 0.0281\n",
            "t = 6, avg_loss = 0.0163\n",
            "t = 8, avg_loss = 0.0184\n",
            "t = 10, avg_loss = 0.0452\n",
            "t = 12, avg_loss = 0.0342\n",
            "t = 14, avg_loss = 0.0237\n",
            "t = 16, avg_loss = 0.0307\n",
            "t = 18, avg_loss = 0.0229\n",
            "t = 20, avg_loss = 0.0241\n",
            "t = 22, avg_loss = 0.0587\n",
            "t = 24, avg_loss = 0.0130\n",
            "Checking accuracy on test set\n",
            "Got 351 / 400 correct (87.75)\n",
            "acc = 0.877500\n",
            "Starting epoch 82 / 100\n",
            "t = 2, avg_loss = 0.0249\n",
            "t = 4, avg_loss = 0.0127\n",
            "t = 6, avg_loss = 0.0073\n",
            "t = 8, avg_loss = 0.0164\n",
            "t = 10, avg_loss = 0.0315\n",
            "t = 12, avg_loss = 0.0611\n",
            "t = 14, avg_loss = 0.0338\n",
            "t = 16, avg_loss = 0.0634\n",
            "t = 18, avg_loss = 0.0124\n",
            "t = 20, avg_loss = 0.0293\n",
            "t = 22, avg_loss = 0.0447\n",
            "t = 24, avg_loss = 0.0361\n",
            "Checking accuracy on test set\n",
            "Got 346 / 400 correct (86.50)\n",
            "acc = 0.865000\n",
            "Starting epoch 83 / 100\n",
            "t = 2, avg_loss = 0.0355\n",
            "t = 4, avg_loss = 0.0477\n",
            "t = 6, avg_loss = 0.0529\n",
            "t = 8, avg_loss = 0.0336\n",
            "t = 10, avg_loss = 0.0194\n",
            "t = 12, avg_loss = 0.0558\n",
            "t = 14, avg_loss = 0.0370\n",
            "t = 16, avg_loss = 0.0266\n",
            "t = 18, avg_loss = 0.0319\n",
            "t = 20, avg_loss = 0.0313\n",
            "t = 22, avg_loss = 0.0254\n",
            "t = 24, avg_loss = 0.0405\n",
            "Checking accuracy on test set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 84 / 100\n",
            "t = 2, avg_loss = 0.0420\n",
            "t = 4, avg_loss = 0.0125\n",
            "t = 6, avg_loss = 0.0213\n",
            "t = 8, avg_loss = 0.0228\n",
            "t = 10, avg_loss = 0.0212\n",
            "t = 12, avg_loss = 0.0137\n",
            "t = 14, avg_loss = 0.0236\n",
            "t = 16, avg_loss = 0.0119\n",
            "t = 18, avg_loss = 0.0363\n",
            "t = 20, avg_loss = 0.0294\n",
            "t = 22, avg_loss = 0.0303\n",
            "t = 24, avg_loss = 0.0276\n",
            "Checking accuracy on test set\n",
            "Got 343 / 400 correct (85.75)\n",
            "acc = 0.857500\n",
            "Starting epoch 85 / 100\n",
            "t = 2, avg_loss = 0.0110\n",
            "t = 4, avg_loss = 0.0170\n",
            "t = 6, avg_loss = 0.0160\n",
            "t = 8, avg_loss = 0.0352\n",
            "t = 10, avg_loss = 0.0315\n",
            "t = 12, avg_loss = 0.0238\n",
            "t = 14, avg_loss = 0.0160\n",
            "t = 16, avg_loss = 0.0166\n",
            "t = 18, avg_loss = 0.0102\n",
            "t = 20, avg_loss = 0.0259\n",
            "t = 22, avg_loss = 0.0493\n",
            "t = 24, avg_loss = 0.0109\n",
            "Checking accuracy on test set\n",
            "Got 345 / 400 correct (86.25)\n",
            "acc = 0.862500\n",
            "Starting epoch 86 / 100\n",
            "t = 2, avg_loss = 0.0326\n",
            "t = 4, avg_loss = 0.0199\n",
            "t = 6, avg_loss = 0.0293\n",
            "t = 8, avg_loss = 0.0208\n",
            "t = 10, avg_loss = 0.0106\n",
            "t = 12, avg_loss = 0.0315\n",
            "t = 14, avg_loss = 0.0188\n",
            "t = 16, avg_loss = 0.0096\n",
            "t = 18, avg_loss = 0.0383\n",
            "t = 20, avg_loss = 0.0082\n",
            "t = 22, avg_loss = 0.0129\n",
            "t = 24, avg_loss = 0.0089\n",
            "Checking accuracy on test set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 87 / 100\n",
            "t = 2, avg_loss = 0.0353\n",
            "t = 4, avg_loss = 0.0097\n",
            "t = 6, avg_loss = 0.0175\n",
            "t = 8, avg_loss = 0.0406\n",
            "t = 10, avg_loss = 0.0472\n",
            "t = 12, avg_loss = 0.0132\n",
            "t = 14, avg_loss = 0.0235\n",
            "t = 16, avg_loss = 0.0419\n",
            "t = 18, avg_loss = 0.0143\n",
            "t = 20, avg_loss = 0.0306\n",
            "t = 22, avg_loss = 0.0514\n",
            "t = 24, avg_loss = 0.0143\n",
            "Checking accuracy on test set\n",
            "Got 343 / 400 correct (85.75)\n",
            "acc = 0.857500\n",
            "Starting epoch 88 / 100\n",
            "t = 2, avg_loss = 0.0329\n",
            "t = 4, avg_loss = 0.0100\n",
            "t = 6, avg_loss = 0.0349\n",
            "t = 8, avg_loss = 0.0135\n",
            "t = 10, avg_loss = 0.0148\n",
            "t = 12, avg_loss = 0.0226\n",
            "t = 14, avg_loss = 0.0408\n",
            "t = 16, avg_loss = 0.0151\n",
            "t = 18, avg_loss = 0.0119\n",
            "t = 20, avg_loss = 0.0626\n",
            "t = 22, avg_loss = 0.0150\n",
            "t = 24, avg_loss = 0.0080\n",
            "Checking accuracy on test set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 89 / 100\n",
            "t = 2, avg_loss = 0.0317\n",
            "t = 4, avg_loss = 0.0066\n",
            "t = 6, avg_loss = 0.0298\n",
            "t = 8, avg_loss = 0.0136\n",
            "t = 10, avg_loss = 0.0071\n",
            "t = 12, avg_loss = 0.0153\n",
            "t = 14, avg_loss = 0.0094\n",
            "t = 16, avg_loss = 0.0203\n",
            "t = 18, avg_loss = 0.0134\n",
            "t = 20, avg_loss = 0.0088\n",
            "t = 22, avg_loss = 0.0077\n",
            "t = 24, avg_loss = 0.0287\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 90 / 100\n",
            "t = 2, avg_loss = 0.0230\n",
            "t = 4, avg_loss = 0.0241\n",
            "t = 6, avg_loss = 0.0116\n",
            "t = 8, avg_loss = 0.0247\n",
            "t = 10, avg_loss = 0.0154\n",
            "t = 12, avg_loss = 0.0409\n",
            "t = 14, avg_loss = 0.0545\n",
            "t = 16, avg_loss = 0.0296\n",
            "t = 18, avg_loss = 0.0137\n",
            "t = 20, avg_loss = 0.0119\n",
            "t = 22, avg_loss = 0.0489\n",
            "t = 24, avg_loss = 0.0641\n",
            "Checking accuracy on test set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 91 / 100\n",
            "t = 2, avg_loss = 0.0696\n",
            "t = 4, avg_loss = 0.0201\n",
            "t = 6, avg_loss = 0.0361\n",
            "t = 8, avg_loss = 0.0372\n",
            "t = 10, avg_loss = 0.0364\n",
            "t = 12, avg_loss = 0.0232\n",
            "t = 14, avg_loss = 0.0223\n",
            "t = 16, avg_loss = 0.0755\n",
            "t = 18, avg_loss = 0.0384\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-85c345babb3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcheck_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-87b2c8b33d30>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, loss_fn, optimizer, num_epochs, starting_from_epoch)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mx_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0my_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-50a9cd504daf>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabeled_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m           \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"benign\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"benign\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m           \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"malignant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"malignant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2808\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2809\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2810\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tk6_ZP_Csnx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "36cccd61-6ae8-4c04-9965-914b5a5f7608"
      },
      "source": [
        "check_accuracy(model_gpu, valid_loader)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking accuracy on test set\n",
            "Got 346 / 400 correct (86.50)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.865"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvoCj5uscUsz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_accurancy(acc_list):\n",
        "  plt.plot([i+1 for i in range((len(acc_list)))],acc_list)\n",
        "  print(\"Accurancy:\")\n",
        "  plt.show()\n",
        "\n",
        "def plot_loss_function(avg_loss_list):\n",
        "  plt.plot([print_every*batch_size*(i+1) for i in range((len(avg_loss_list)))],avg_loss_list)\n",
        "  print(\"Loss:\")\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-Co5KBw-Yy4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "outputId": "25ad398a-3128-45cd-ddb1-f789dec83b86"
      },
      "source": [
        "plot_accurancy(acc_list)\n",
        "plot_loss_function(avg_loss_list)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accurancy:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzuX5gLEeJfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def retry_from_backup():\n",
        "  model_gpu = model_base.type(gpu_dtype)\n",
        "  print(model_gpu)\n",
        "  loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) \n",
        "\n",
        "\n",
        "\n",
        "  checkpoint = torch.load(model_backup_path)\n",
        "  model_gpu.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  epoch = checkpoint['epoch']\n",
        "  loss = checkpoint['loss']\n",
        "  acc_list = checkpoint['acc_list']\n",
        "  #avg_loss_list = checkpoint['avg_loss_list']\n",
        "  print(\"starting from epoch: \" + str(epoch))\n",
        "  print(\"starting from loss: \" + str(loss))\n",
        "  print(acc_list)\n",
        "  \n",
        "  \n",
        "  train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=88, starting_from_epoch=epoch)\n",
        "  check_accuracy(model_gpu, valid_loader)\n",
        "\n",
        "  plot_accurancy(acc_list)\n",
        "  plot_loss_function(avg_loss_list)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--rQZKqOalaJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#retry_from_backup()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}