{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN_ascending_layers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNC227yS0tflmgN6iJOXA6V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamilo116/KNN/blob/master/KNN_ascending_layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7ReM7FU-xs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import sys\n",
        "from random import shuffle\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms as transforms\n",
        "import timeit\n",
        "\n",
        "np.random.seed(4) \n",
        "torch.manual_seed(4) \n",
        "torch.cuda.manual_seed(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYIMZ8QyYewD",
        "colab_type": "code",
        "outputId": "f7143126-add1-4e05-c900-c0dfe3cbd987",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "! git clone https://github.com/wang-chen/kervolution.git \n",
        "\n",
        "sys.path.append(\"kervolution/\")\n",
        "from kervolution import Kerv2d\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'kervolution'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects:  16% (1/6)\u001b[K\rremote: Counting objects:  33% (2/6)\u001b[K\rremote: Counting objects:  50% (3/6)\u001b[K\rremote: Counting objects:  66% (4/6)\u001b[K\rremote: Counting objects:  83% (5/6)\u001b[K\rremote: Counting objects: 100% (6/6)\u001b[K\rremote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects:  16% (1/6)\u001b[K\rremote: Compressing objects:  33% (2/6)\u001b[K\rremote: Compressing objects:  50% (3/6)\u001b[K\rremote: Compressing objects:  66% (4/6)\u001b[K\rremote: Compressing objects:  83% (5/6)\u001b[K\rremote: Compressing objects: 100% (6/6)\u001b[K\rremote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "Unpacking objects:   1% (1/53)   \rUnpacking objects:   3% (2/53)   \rUnpacking objects:   5% (3/53)   \rUnpacking objects:   7% (4/53)   \rUnpacking objects:   9% (5/53)   \rUnpacking objects:  11% (6/53)   \rUnpacking objects:  13% (7/53)   \rUnpacking objects:  15% (8/53)   \rUnpacking objects:  16% (9/53)   \rUnpacking objects:  18% (10/53)   \rUnpacking objects:  20% (11/53)   \rUnpacking objects:  22% (12/53)   \rUnpacking objects:  24% (13/53)   \rUnpacking objects:  26% (14/53)   \rUnpacking objects:  28% (15/53)   \rUnpacking objects:  30% (16/53)   \rUnpacking objects:  32% (17/53)   \rUnpacking objects:  33% (18/53)   \rUnpacking objects:  35% (19/53)   \rUnpacking objects:  37% (20/53)   \rUnpacking objects:  39% (21/53)   \rUnpacking objects:  41% (22/53)   \rUnpacking objects:  43% (23/53)   \rUnpacking objects:  45% (24/53)   \rremote: Total 53 (delta 2), reused 0 (delta 0), pack-reused 47\n",
            "Unpacking objects:  47% (25/53)   \rUnpacking objects:  49% (26/53)   \rUnpacking objects:  50% (27/53)   \rUnpacking objects:  52% (28/53)   \rUnpacking objects:  54% (29/53)   \rUnpacking objects:  56% (30/53)   \rUnpacking objects:  58% (31/53)   \rUnpacking objects:  60% (32/53)   \rUnpacking objects:  62% (33/53)   \rUnpacking objects:  64% (34/53)   \rUnpacking objects:  66% (35/53)   \rUnpacking objects:  67% (36/53)   \rUnpacking objects:  69% (37/53)   \rUnpacking objects:  71% (38/53)   \rUnpacking objects:  73% (39/53)   \rUnpacking objects:  75% (40/53)   \rUnpacking objects:  77% (41/53)   \rUnpacking objects:  79% (42/53)   \rUnpacking objects:  81% (43/53)   \rUnpacking objects:  83% (44/53)   \rUnpacking objects:  84% (45/53)   \rUnpacking objects:  86% (46/53)   \rUnpacking objects:  88% (47/53)   \rUnpacking objects:  90% (48/53)   \rUnpacking objects:  92% (49/53)   \rUnpacking objects:  94% (50/53)   \rUnpacking objects:  96% (51/53)   \rUnpacking objects:  98% (52/53)   \rUnpacking objects: 100% (53/53)   \rUnpacking objects: 100% (53/53), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvbKg4VJXKY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LIMIT_IMAGES_NUM = 1000\n",
        "train_test_split_size = 0.2\n",
        "image_resize = (100, 100)\n",
        "batch_size = 64\n",
        "num_workers = 0\n",
        "\n",
        "out_1 = 16\n",
        "out_2 = 32\n",
        "out_3 = 64\n",
        "out_4 = 128\n",
        "\n",
        "\n",
        "k_size_1 = 3\n",
        "padding_1 = 1\n",
        "in_channels = 3\n",
        "\n",
        "kernel_size = 3\n",
        "num_epochs = 100\n",
        "\n",
        "learning_rate = 0.0001\n",
        "weight_decay = 0.1\n",
        "\n",
        "MALIGNANT_DATASET = '/content/drive/My Drive/Colab_data/malignant/malignant/'\n",
        "BENIGN_DATASET = '/content/drive/My Drive/Colab_data/benign/benign/'\n",
        "DATA_FOLDER = '/content/drive/My Drive/Colab_data/'\n",
        "model_backup_path = os.path.join(DATA_FOLDER, 'backup_model') \n",
        "TRAIN_DATA_PER_CATEGORY = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMOHez_kHZD6",
        "colab_type": "code",
        "outputId": "26d84ed3-ac5a-4b41-baf0-88a0eb565dec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b8P1NdXfVdX",
        "colab_type": "code",
        "outputId": "f2c91796-d795-4852-f351-145c02624a41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "benign_file_list = sorted(os.listdir(BENIGN_DATASET))\n",
        "malignant_file_list = sorted(os.listdir(MALIGNANT_DATASET))\n",
        "shuffle(benign_file_list)\n",
        "shuffle(malignant_file_list)\n",
        "benign_file_list = benign_file_list[:LIMIT_IMAGES_NUM]\n",
        "malignant_file_list = malignant_file_list[:LIMIT_IMAGES_NUM]\n",
        "\n",
        "test_benign_file_list = benign_file_list[LIMIT_IMAGES_NUM : LIMIT_IMAGES_NUM+TRAIN_DATA_PER_CATEGORY]\n",
        "test_malignant_file_list = malignant_file_list[LIMIT_IMAGES_NUM : LIMIT_IMAGES_NUM + TRAIN_DATA_PER_CATEGORY]\n",
        "\n",
        "print(f\"Number of benign {len(benign_file_list)} images\")\n",
        "print(f\"Number of malignant {len(malignant_file_list)} images\")\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize(image_resize),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of benign 1000 images\n",
            "Number of malignant 1000 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XXmwQ21VU8Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8jqlpyodC8i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQsdCVTRfVbq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOer_Im0ft2L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rF_9WlBmdblM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_Ue-Fgjdz_m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sY40W_kSeMaL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVCGk8Rgek0i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRuOFo5Ke9O7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvAAOqmVfVll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IsicDataset(Dataset):\n",
        "    def __init__(self, data_folder, labeled_data, \n",
        "                 transform=transforms.Compose([transforms.ToTensor()])):\n",
        "        self.labeled_data = labeled_data\n",
        "        self.transform = transform\n",
        "        self.data_folder = data_folder\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labeled_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        label = self.labeled_data[index]\n",
        "        if label == 0:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"benign\", \"benign\", index ))\n",
        "        else:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"malignant\", \"malignant\", index ))\n",
        "        image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "    @property\n",
        "    def labels(self):\n",
        "      return self.labeled_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSuYqjLAYrWA",
        "colab_type": "code",
        "outputId": "1151b297-a973-43ab-b055-59549194c8cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "def get_dataset(benign_file_list, malignant_file_list):\n",
        "  benign_dict = {filename: 0 for filename in benign_file_list}\n",
        "  malignant_dict = {filename: 1 for filename in malignant_file_list}\n",
        "  img_class_dict = {**benign_dict , **malignant_dict}\n",
        "  labeled_data = pd.Series(img_class_dict)\n",
        "\n",
        "  dataset = IsicDataset(DATA_FOLDER, labeled_data, transform=data_transforms)\n",
        "  print(dataset.labels)\n",
        "  return dataset\n",
        "\n",
        "train_dataset = get_dataset(benign_file_list, malignant_file_list)\n",
        "\n",
        "X_train, X_test = train_test_split(train_dataset.labels, test_size=train_test_split_size)\n",
        "print(\"number of training data: \",len(X_train))\n",
        "print(\"number of testing  data: \",len(X_test))\n",
        "\n",
        "train_sampler = SubsetRandomSampler(list(X_train.index))\n",
        "valid_sampler = SubsetRandomSampler(list(X_test.index))\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
        "\n",
        "test_dataset = get_dataset(test_benign_file_list, test_malignant_file_list)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ISIC_0001755.jpeg    0\n",
            "ISIC_0002598.jpeg    0\n",
            "ISIC_0000560.jpeg    0\n",
            "ISIC_0000779.jpeg    0\n",
            "ISIC_0000731.jpeg    0\n",
            "                    ..\n",
            "ISIC_0011736.jpeg    1\n",
            "ISIC_0015185.jpeg    1\n",
            "ISIC_0024967.jpg     1\n",
            "ISIC_0014290.jpeg    1\n",
            "ISIC_0000169.jpeg    1\n",
            "Length: 2000, dtype: int64\n",
            "number of training data:  1600\n",
            "number of testing  data:  400\n",
            "Series([], dtype: float64)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUeAaHJ7JlsW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e8nFBR6Yug5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "def train(model, train_loader ,loss_fn, optimizer, num_epochs=1, starting_from_epoch=1):\n",
        "    total_loss =0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
        "        model.train()\n",
        "\n",
        "        for t, (x, y) in enumerate(train_loader):\n",
        "            x_var = Variable(x.type(gpu_dtype))\n",
        "            y_var = Variable(y.type(gpu_dtype).long())\n",
        "            scores = model(x_var)\n",
        "            loss = loss_fn(scores, y_var)\n",
        "            total_loss += loss.data\n",
        "            \n",
        "            if (t + 1) % print_every == 0:\n",
        "                avg_loss = total_loss/print_every\n",
        "                print('t = %d, avg_loss = %.4f' % (t + 1, avg_loss) )\n",
        "                avg_loss_list.append(avg_loss)\n",
        "                total_loss = 0\n",
        "                \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        acc = check_accuracy(model_gpu, valid_loader)\n",
        "        print('acc = %f' %(acc))\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model_gpu.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            'acc_list': acc_list,\n",
        "            }, model_backup_path)\n",
        "            \n",
        "def check_accuracy(model, loader):\n",
        "    print('Checking accuracy on test set')   \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval() \n",
        "    for x, y in loader:\n",
        "        x_var = Variable(x.type(gpu_dtype))\n",
        "\n",
        "        scores = model(x_var)\n",
        "        _, preds = scores.data.cpu().max(1)\n",
        "        num_correct += (preds == y).sum()\n",
        "        num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    acc_list.append(acc)\n",
        "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "    return acc\n",
        "    \n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.size()\n",
        "        return x.view(N, -1)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-gYHw0Jlbwt",
        "colab_type": "code",
        "outputId": "7ae5ff56-b651-4b08-cb99-47bcc1f897c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "print_every = 2\n",
        "gpu_dtype = torch.cuda.FloatTensor\n",
        "\n",
        "\n",
        "'''\n",
        "Kerv2d\n",
        "kervolution with following options:\n",
        "kernel_type: [linear, polynomial, gaussian, etc.]\n",
        "default is convolution:\n",
        "          kernel_type --> linear,\n",
        "balance, power, gamma is valid only when the kernel_type is specified\n",
        "if learnable_kernel = True,  they just be the initial value of learable parameters\n",
        "if learnable_kernel = False, they are the value of kernel_type's parameter\n",
        "the parameter [power] cannot be learned due to integer limitation\n",
        "dilation (int or tuple, optional): Spacing between kernel\n",
        "elements. Default: 1\n",
        "groups (int, optional): Number of blocked connections from input\n",
        "channels to output channels. Default: 1\n",
        "bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n",
        "kernel_type (str), Default: 'linear'\n",
        "learnable_kernel (bool): Learnable kernel parameters.  Default: False \n",
        "balance: 0, 1\n",
        "power: 3, 4, 5\n",
        "gamma:\n",
        "'''\n",
        "\n",
        "\n",
        "model_base = nn.Sequential( \n",
        "                nn.Conv2d(in_channels , out_1, padding= padding_1, kernel_size=k_size_1, stride=1),\n",
        "                #nn.Kerv2d(in_channels , out_1, padding=padding_1, dilation=1, groups=1, bias=True, \n",
        "                #          kernel_type='polynomial', kernel_size=k_size_1,# learnable_kernel=True,\n",
        "                          #kernel_regularizer=True, stride=1, balance=1, power=3, gamma=1\n",
        "                #          ), \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_1),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_1 , out_2, padding= padding_1, kernel_size=k_size_1, stride=1), \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_2),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_2 , out_3, padding= padding_1, kernel_size=k_size_1, stride=1),  \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_3),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_3 , out_4, padding= padding_1, kernel_size=k_size_1, stride=1),  \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_4),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Dropout(0.5),\n",
        "                Flatten(),\n",
        "                nn.Linear(4608,64),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Linear(64,2)\n",
        "            )\n",
        "model_gpu = model_base.type(gpu_dtype)\n",
        "print(model_gpu)\n",
        "loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (4): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (5): ReLU(inplace=True)\n",
            "  (6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (8): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (9): ReLU(inplace=True)\n",
            "  (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (12): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (13): ReLU(inplace=True)\n",
            "  (14): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (16): Dropout(p=0.5, inplace=False)\n",
            "  (17): Flatten()\n",
            "  (18): Linear(in_features=4608, out_features=64, bias=True)\n",
            "  (19): ReLU(inplace=True)\n",
            "  (20): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgmexhBRZAK6",
        "colab_type": "code",
        "outputId": "13fff68f-ea94-4f39-cfd8-cde2afeb43c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs)\n",
        "check_accuracy(model_gpu, valid_loader)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 1 / 100\n",
            "t = 2, avg_loss = 0.7425\n",
            "t = 4, avg_loss = 0.5883\n",
            "t = 6, avg_loss = 0.6203\n",
            "t = 8, avg_loss = 0.6307\n",
            "t = 10, avg_loss = 0.5410\n",
            "t = 12, avg_loss = 0.4790\n",
            "t = 14, avg_loss = 0.4681\n",
            "t = 16, avg_loss = 0.5099\n",
            "t = 18, avg_loss = 0.5273\n",
            "t = 20, avg_loss = 0.4435\n",
            "t = 22, avg_loss = 0.4322\n",
            "t = 24, avg_loss = 0.4022\n",
            "Checking accuracy on test set\n",
            "Got 204 / 400 correct (51.00)\n",
            "acc = 0.510000\n",
            "Starting epoch 2 / 100\n",
            "t = 2, avg_loss = 0.6048\n",
            "t = 4, avg_loss = 0.4505\n",
            "t = 6, avg_loss = 0.3899\n",
            "t = 8, avg_loss = 0.4292\n",
            "t = 10, avg_loss = 0.4610\n",
            "t = 12, avg_loss = 0.3190\n",
            "t = 14, avg_loss = 0.3584\n",
            "t = 16, avg_loss = 0.4589\n",
            "t = 18, avg_loss = 0.4051\n",
            "t = 20, avg_loss = 0.3498\n",
            "t = 22, avg_loss = 0.4939\n",
            "t = 24, avg_loss = 0.3961\n",
            "Checking accuracy on test set\n",
            "Got 241 / 400 correct (60.25)\n",
            "acc = 0.602500\n",
            "Starting epoch 3 / 100\n",
            "t = 2, avg_loss = 0.6265\n",
            "t = 4, avg_loss = 0.3452\n",
            "t = 6, avg_loss = 0.3333\n",
            "t = 8, avg_loss = 0.3745\n",
            "t = 10, avg_loss = 0.4050\n",
            "t = 12, avg_loss = 0.3351\n",
            "t = 14, avg_loss = 0.3705\n",
            "t = 16, avg_loss = 0.3505\n",
            "t = 18, avg_loss = 0.4124\n",
            "t = 20, avg_loss = 0.3365\n",
            "t = 22, avg_loss = 0.2754\n",
            "t = 24, avg_loss = 0.4231\n",
            "Checking accuracy on test set\n",
            "Got 337 / 400 correct (84.25)\n",
            "acc = 0.842500\n",
            "Starting epoch 4 / 100\n",
            "t = 2, avg_loss = 0.5502\n",
            "t = 4, avg_loss = 0.2733\n",
            "t = 6, avg_loss = 0.3710\n",
            "t = 8, avg_loss = 0.2923\n",
            "t = 10, avg_loss = 0.3660\n",
            "t = 12, avg_loss = 0.3004\n",
            "t = 14, avg_loss = 0.3679\n",
            "t = 16, avg_loss = 0.3654\n",
            "t = 18, avg_loss = 0.3338\n",
            "t = 20, avg_loss = 0.4042\n",
            "t = 22, avg_loss = 0.3243\n",
            "t = 24, avg_loss = 0.3599\n",
            "Checking accuracy on test set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 5 / 100\n",
            "t = 2, avg_loss = 0.5088\n",
            "t = 4, avg_loss = 0.2823\n",
            "t = 6, avg_loss = 0.2553\n",
            "t = 8, avg_loss = 0.4113\n",
            "t = 10, avg_loss = 0.2811\n",
            "t = 12, avg_loss = 0.2876\n",
            "t = 14, avg_loss = 0.3355\n",
            "t = 16, avg_loss = 0.2811\n",
            "t = 18, avg_loss = 0.2495\n",
            "t = 20, avg_loss = 0.3436\n",
            "t = 22, avg_loss = 0.2985\n",
            "t = 24, avg_loss = 0.2884\n",
            "Checking accuracy on test set\n",
            "Got 342 / 400 correct (85.50)\n",
            "acc = 0.855000\n",
            "Starting epoch 6 / 100\n",
            "t = 2, avg_loss = 0.4804\n",
            "t = 4, avg_loss = 0.2839\n",
            "t = 6, avg_loss = 0.3874\n",
            "t = 8, avg_loss = 0.3414\n",
            "t = 10, avg_loss = 0.2634\n",
            "t = 12, avg_loss = 0.2866\n",
            "t = 14, avg_loss = 0.3178\n",
            "t = 16, avg_loss = 0.2095\n",
            "t = 18, avg_loss = 0.3257\n",
            "t = 20, avg_loss = 0.2597\n",
            "t = 22, avg_loss = 0.2897\n",
            "t = 24, avg_loss = 0.3686\n",
            "Checking accuracy on test set\n",
            "Got 345 / 400 correct (86.25)\n",
            "acc = 0.862500\n",
            "Starting epoch 7 / 100\n",
            "t = 2, avg_loss = 0.3817\n",
            "t = 4, avg_loss = 0.2467\n",
            "t = 6, avg_loss = 0.3035\n",
            "t = 8, avg_loss = 0.3265\n",
            "t = 10, avg_loss = 0.2934\n",
            "t = 12, avg_loss = 0.3331\n",
            "t = 14, avg_loss = 0.3184\n",
            "t = 16, avg_loss = 0.3179\n",
            "t = 18, avg_loss = 0.3181\n",
            "t = 20, avg_loss = 0.2198\n",
            "t = 22, avg_loss = 0.2658\n",
            "t = 24, avg_loss = 0.3465\n",
            "Checking accuracy on test set\n",
            "Got 343 / 400 correct (85.75)\n",
            "acc = 0.857500\n",
            "Starting epoch 8 / 100\n",
            "t = 2, avg_loss = 0.5031\n",
            "t = 4, avg_loss = 0.2705\n",
            "t = 6, avg_loss = 0.2724\n",
            "t = 8, avg_loss = 0.2916\n",
            "t = 10, avg_loss = 0.3075\n",
            "t = 12, avg_loss = 0.3199\n",
            "t = 14, avg_loss = 0.2871\n",
            "t = 16, avg_loss = 0.2855\n",
            "t = 18, avg_loss = 0.2961\n",
            "t = 20, avg_loss = 0.3358\n",
            "t = 22, avg_loss = 0.2662\n",
            "t = 24, avg_loss = 0.2041\n",
            "Checking accuracy on test set\n",
            "Got 346 / 400 correct (86.50)\n",
            "acc = 0.865000\n",
            "Starting epoch 9 / 100\n",
            "t = 2, avg_loss = 0.3815\n",
            "t = 4, avg_loss = 0.2146\n",
            "t = 6, avg_loss = 0.2368\n",
            "t = 8, avg_loss = 0.2973\n",
            "t = 10, avg_loss = 0.2053\n",
            "t = 12, avg_loss = 0.3000\n",
            "t = 14, avg_loss = 0.2662\n",
            "t = 16, avg_loss = 0.2179\n",
            "t = 18, avg_loss = 0.2026\n",
            "t = 20, avg_loss = 0.2888\n",
            "t = 22, avg_loss = 0.2771\n",
            "t = 24, avg_loss = 0.2320\n",
            "Checking accuracy on test set\n",
            "Got 351 / 400 correct (87.75)\n",
            "acc = 0.877500\n",
            "Starting epoch 10 / 100\n",
            "t = 2, avg_loss = 0.4529\n",
            "t = 4, avg_loss = 0.2493\n",
            "t = 6, avg_loss = 0.2704\n",
            "t = 8, avg_loss = 0.2971\n",
            "t = 10, avg_loss = 0.3050\n",
            "t = 12, avg_loss = 0.2601\n",
            "t = 14, avg_loss = 0.2974\n",
            "t = 16, avg_loss = 0.2772\n",
            "t = 18, avg_loss = 0.2634\n",
            "t = 20, avg_loss = 0.2494\n",
            "t = 22, avg_loss = 0.2472\n",
            "t = 24, avg_loss = 0.2487\n",
            "Checking accuracy on test set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 11 / 100\n",
            "t = 2, avg_loss = 0.4434\n",
            "t = 4, avg_loss = 0.2314\n",
            "t = 6, avg_loss = 0.2990\n",
            "t = 8, avg_loss = 0.2793\n",
            "t = 10, avg_loss = 0.3082\n",
            "t = 12, avg_loss = 0.2316\n",
            "t = 14, avg_loss = 0.2195\n",
            "t = 16, avg_loss = 0.1884\n",
            "t = 18, avg_loss = 0.2359\n",
            "t = 20, avg_loss = 0.2923\n",
            "t = 22, avg_loss = 0.2558\n",
            "t = 24, avg_loss = 0.2725\n",
            "Checking accuracy on test set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 12 / 100\n",
            "t = 2, avg_loss = 0.2986\n",
            "t = 4, avg_loss = 0.2884\n",
            "t = 6, avg_loss = 0.2191\n",
            "t = 8, avg_loss = 0.2226\n",
            "t = 10, avg_loss = 0.2021\n",
            "t = 12, avg_loss = 0.1997\n",
            "t = 14, avg_loss = 0.3312\n",
            "t = 16, avg_loss = 0.2361\n",
            "t = 18, avg_loss = 0.2313\n",
            "t = 20, avg_loss = 0.2655\n",
            "t = 22, avg_loss = 0.2771\n",
            "t = 24, avg_loss = 0.2506\n",
            "Checking accuracy on test set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 13 / 100\n",
            "t = 2, avg_loss = 0.3237\n",
            "t = 4, avg_loss = 0.2853\n",
            "t = 6, avg_loss = 0.2534\n",
            "t = 8, avg_loss = 0.2361\n",
            "t = 10, avg_loss = 0.1924\n",
            "t = 12, avg_loss = 0.2730\n",
            "t = 14, avg_loss = 0.1649\n",
            "t = 16, avg_loss = 0.2586\n",
            "t = 18, avg_loss = 0.1827\n",
            "t = 20, avg_loss = 0.2752\n",
            "t = 22, avg_loss = 0.1854\n",
            "t = 24, avg_loss = 0.2765\n",
            "Checking accuracy on test set\n",
            "Got 346 / 400 correct (86.50)\n",
            "acc = 0.865000\n",
            "Starting epoch 14 / 100\n",
            "t = 2, avg_loss = 0.4406\n",
            "t = 4, avg_loss = 0.1342\n",
            "t = 6, avg_loss = 0.1825\n",
            "t = 8, avg_loss = 0.2282\n",
            "t = 10, avg_loss = 0.2064\n",
            "t = 12, avg_loss = 0.2629\n",
            "t = 14, avg_loss = 0.1580\n",
            "t = 16, avg_loss = 0.3344\n",
            "t = 18, avg_loss = 0.1753\n",
            "t = 20, avg_loss = 0.2820\n",
            "t = 22, avg_loss = 0.1934\n",
            "t = 24, avg_loss = 0.2562\n",
            "Checking accuracy on test set\n",
            "Got 345 / 400 correct (86.25)\n",
            "acc = 0.862500\n",
            "Starting epoch 15 / 100\n",
            "t = 2, avg_loss = 0.3056\n",
            "t = 4, avg_loss = 0.1401\n",
            "t = 6, avg_loss = 0.1728\n",
            "t = 8, avg_loss = 0.2398\n",
            "t = 10, avg_loss = 0.1958\n",
            "t = 12, avg_loss = 0.2198\n",
            "t = 14, avg_loss = 0.2262\n",
            "t = 16, avg_loss = 0.2762\n",
            "t = 18, avg_loss = 0.2729\n",
            "t = 20, avg_loss = 0.2796\n",
            "t = 22, avg_loss = 0.2304\n",
            "t = 24, avg_loss = 0.1976\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 16 / 100\n",
            "t = 2, avg_loss = 0.3081\n",
            "t = 4, avg_loss = 0.2087\n",
            "t = 6, avg_loss = 0.2329\n",
            "t = 8, avg_loss = 0.2388\n",
            "t = 10, avg_loss = 0.2133\n",
            "t = 12, avg_loss = 0.2618\n",
            "t = 14, avg_loss = 0.2418\n",
            "t = 16, avg_loss = 0.1867\n",
            "t = 18, avg_loss = 0.1881\n",
            "t = 20, avg_loss = 0.2562\n",
            "t = 22, avg_loss = 0.1999\n",
            "t = 24, avg_loss = 0.2707\n",
            "Checking accuracy on test set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 17 / 100\n",
            "t = 2, avg_loss = 0.2534\n",
            "t = 4, avg_loss = 0.1571\n",
            "t = 6, avg_loss = 0.1991\n",
            "t = 8, avg_loss = 0.2038\n",
            "t = 10, avg_loss = 0.1954\n",
            "t = 12, avg_loss = 0.2731\n",
            "t = 14, avg_loss = 0.2440\n",
            "t = 16, avg_loss = 0.1997\n",
            "t = 18, avg_loss = 0.2087\n",
            "t = 20, avg_loss = 0.2615\n",
            "t = 22, avg_loss = 0.2044\n",
            "t = 24, avg_loss = 0.1845\n",
            "Checking accuracy on test set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 18 / 100\n",
            "t = 2, avg_loss = 0.3093\n",
            "t = 4, avg_loss = 0.1546\n",
            "t = 6, avg_loss = 0.2169\n",
            "t = 8, avg_loss = 0.2066\n",
            "t = 10, avg_loss = 0.2220\n",
            "t = 12, avg_loss = 0.2326\n",
            "t = 14, avg_loss = 0.1945\n",
            "t = 16, avg_loss = 0.1985\n",
            "t = 18, avg_loss = 0.1927\n",
            "t = 20, avg_loss = 0.1443\n",
            "t = 22, avg_loss = 0.2206\n",
            "t = 24, avg_loss = 0.1939\n",
            "Checking accuracy on test set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 19 / 100\n",
            "t = 2, avg_loss = 0.3290\n",
            "t = 4, avg_loss = 0.1532\n",
            "t = 6, avg_loss = 0.2390\n",
            "t = 8, avg_loss = 0.1691\n",
            "t = 10, avg_loss = 0.1945\n",
            "t = 12, avg_loss = 0.2243\n",
            "t = 14, avg_loss = 0.1200\n",
            "t = 16, avg_loss = 0.2227\n",
            "t = 18, avg_loss = 0.2524\n",
            "t = 20, avg_loss = 0.2105\n",
            "t = 22, avg_loss = 0.1746\n",
            "t = 24, avg_loss = 0.2798\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 20 / 100\n",
            "t = 2, avg_loss = 0.3057\n",
            "t = 4, avg_loss = 0.2171\n",
            "t = 6, avg_loss = 0.1866\n",
            "t = 8, avg_loss = 0.1964\n",
            "t = 10, avg_loss = 0.1628\n",
            "t = 12, avg_loss = 0.2446\n",
            "t = 14, avg_loss = 0.1724\n",
            "t = 16, avg_loss = 0.1455\n",
            "t = 18, avg_loss = 0.1923\n",
            "t = 20, avg_loss = 0.2306\n",
            "t = 22, avg_loss = 0.1952\n",
            "t = 24, avg_loss = 0.1632\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 21 / 100\n",
            "t = 2, avg_loss = 0.2940\n",
            "t = 4, avg_loss = 0.1930\n",
            "t = 6, avg_loss = 0.2622\n",
            "t = 8, avg_loss = 0.1677\n",
            "t = 10, avg_loss = 0.1377\n",
            "t = 12, avg_loss = 0.1821\n",
            "t = 14, avg_loss = 0.2486\n",
            "t = 16, avg_loss = 0.1740\n",
            "t = 18, avg_loss = 0.2365\n",
            "t = 20, avg_loss = 0.1876\n",
            "t = 22, avg_loss = 0.2000\n",
            "t = 24, avg_loss = 0.2050\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 22 / 100\n",
            "t = 2, avg_loss = 0.2393\n",
            "t = 4, avg_loss = 0.1832\n",
            "t = 6, avg_loss = 0.1649\n",
            "t = 8, avg_loss = 0.2550\n",
            "t = 10, avg_loss = 0.1491\n",
            "t = 12, avg_loss = 0.1470\n",
            "t = 14, avg_loss = 0.1720\n",
            "t = 16, avg_loss = 0.1820\n",
            "t = 18, avg_loss = 0.1941\n",
            "t = 20, avg_loss = 0.1489\n",
            "t = 22, avg_loss = 0.2093\n",
            "t = 24, avg_loss = 0.1694\n",
            "Checking accuracy on test set\n",
            "Got 360 / 400 correct (90.00)\n",
            "acc = 0.900000\n",
            "Starting epoch 23 / 100\n",
            "t = 2, avg_loss = 0.2292\n",
            "t = 4, avg_loss = 0.1597\n",
            "t = 6, avg_loss = 0.1939\n",
            "t = 8, avg_loss = 0.1553\n",
            "t = 10, avg_loss = 0.1137\n",
            "t = 12, avg_loss = 0.2517\n",
            "t = 14, avg_loss = 0.1911\n",
            "t = 16, avg_loss = 0.1725\n",
            "t = 18, avg_loss = 0.1723\n",
            "t = 20, avg_loss = 0.1811\n",
            "t = 22, avg_loss = 0.1542\n",
            "t = 24, avg_loss = 0.2117\n",
            "Checking accuracy on test set\n",
            "Got 359 / 400 correct (89.75)\n",
            "acc = 0.897500\n",
            "Starting epoch 24 / 100\n",
            "t = 2, avg_loss = 0.2768\n",
            "t = 4, avg_loss = 0.2117\n",
            "t = 6, avg_loss = 0.2272\n",
            "t = 8, avg_loss = 0.2236\n",
            "t = 10, avg_loss = 0.1879\n",
            "t = 12, avg_loss = 0.1118\n",
            "t = 14, avg_loss = 0.1701\n",
            "t = 16, avg_loss = 0.1768\n",
            "t = 18, avg_loss = 0.1210\n",
            "t = 20, avg_loss = 0.1441\n",
            "t = 22, avg_loss = 0.1283\n",
            "t = 24, avg_loss = 0.1198\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 25 / 100\n",
            "t = 2, avg_loss = 0.2600\n",
            "t = 4, avg_loss = 0.1240\n",
            "t = 6, avg_loss = 0.1440\n",
            "t = 8, avg_loss = 0.1899\n",
            "t = 10, avg_loss = 0.1144\n",
            "t = 12, avg_loss = 0.2210\n",
            "t = 14, avg_loss = 0.1239\n",
            "t = 16, avg_loss = 0.2045\n",
            "t = 18, avg_loss = 0.1311\n",
            "t = 20, avg_loss = 0.1434\n",
            "t = 22, avg_loss = 0.2085\n",
            "t = 24, avg_loss = 0.1544\n",
            "Checking accuracy on test set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 26 / 100\n",
            "t = 2, avg_loss = 0.1998\n",
            "t = 4, avg_loss = 0.1395\n",
            "t = 6, avg_loss = 0.1492\n",
            "t = 8, avg_loss = 0.2065\n",
            "t = 10, avg_loss = 0.1596\n",
            "t = 12, avg_loss = 0.1378\n",
            "t = 14, avg_loss = 0.1336\n",
            "t = 16, avg_loss = 0.1972\n",
            "t = 18, avg_loss = 0.2065\n",
            "t = 20, avg_loss = 0.1573\n",
            "t = 22, avg_loss = 0.2151\n",
            "t = 24, avg_loss = 0.1364\n",
            "Checking accuracy on test set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 27 / 100\n",
            "t = 2, avg_loss = 0.3163\n",
            "t = 4, avg_loss = 0.1123\n",
            "t = 6, avg_loss = 0.1826\n",
            "t = 8, avg_loss = 0.1752\n",
            "t = 10, avg_loss = 0.1631\n",
            "t = 12, avg_loss = 0.1856\n",
            "t = 14, avg_loss = 0.1575\n",
            "t = 16, avg_loss = 0.1815\n",
            "t = 18, avg_loss = 0.1538\n",
            "t = 20, avg_loss = 0.1866\n",
            "t = 22, avg_loss = 0.1638\n",
            "t = 24, avg_loss = 0.1910\n",
            "Checking accuracy on test set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 28 / 100\n",
            "t = 2, avg_loss = 0.2160\n",
            "t = 4, avg_loss = 0.1153\n",
            "t = 6, avg_loss = 0.1396\n",
            "t = 8, avg_loss = 0.1691\n",
            "t = 10, avg_loss = 0.1221\n",
            "t = 12, avg_loss = 0.1743\n",
            "t = 14, avg_loss = 0.2089\n",
            "t = 16, avg_loss = 0.1425\n",
            "t = 18, avg_loss = 0.0859\n",
            "t = 20, avg_loss = 0.1063\n",
            "t = 22, avg_loss = 0.1288\n",
            "t = 24, avg_loss = 0.1437\n",
            "Checking accuracy on test set\n",
            "Got 351 / 400 correct (87.75)\n",
            "acc = 0.877500\n",
            "Starting epoch 29 / 100\n",
            "t = 2, avg_loss = 0.2253\n",
            "t = 4, avg_loss = 0.1644\n",
            "t = 6, avg_loss = 0.1446\n",
            "t = 8, avg_loss = 0.1233\n",
            "t = 10, avg_loss = 0.1255\n",
            "t = 12, avg_loss = 0.1963\n",
            "t = 14, avg_loss = 0.1344\n",
            "t = 16, avg_loss = 0.1795\n",
            "t = 18, avg_loss = 0.1382\n",
            "t = 20, avg_loss = 0.2266\n",
            "t = 22, avg_loss = 0.2041\n",
            "t = 24, avg_loss = 0.2040\n",
            "Checking accuracy on test set\n",
            "Got 351 / 400 correct (87.75)\n",
            "acc = 0.877500\n",
            "Starting epoch 30 / 100\n",
            "t = 2, avg_loss = 0.2860\n",
            "t = 4, avg_loss = 0.1417\n",
            "t = 6, avg_loss = 0.1554\n",
            "t = 8, avg_loss = 0.1590\n",
            "t = 10, avg_loss = 0.1434\n",
            "t = 12, avg_loss = 0.1626\n",
            "t = 14, avg_loss = 0.1413\n",
            "t = 16, avg_loss = 0.2281\n",
            "t = 18, avg_loss = 0.1587\n",
            "t = 20, avg_loss = 0.1497\n",
            "t = 22, avg_loss = 0.1479\n",
            "t = 24, avg_loss = 0.1583\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 31 / 100\n",
            "t = 2, avg_loss = 0.2087\n",
            "t = 4, avg_loss = 0.1779\n",
            "t = 6, avg_loss = 0.1412\n",
            "t = 8, avg_loss = 0.1543\n",
            "t = 10, avg_loss = 0.1685\n",
            "t = 12, avg_loss = 0.1643\n",
            "t = 14, avg_loss = 0.0712\n",
            "t = 16, avg_loss = 0.2705\n",
            "t = 18, avg_loss = 0.1508\n",
            "t = 20, avg_loss = 0.1470\n",
            "t = 22, avg_loss = 0.1038\n",
            "t = 24, avg_loss = 0.1760\n",
            "Checking accuracy on test set\n",
            "Got 351 / 400 correct (87.75)\n",
            "acc = 0.877500\n",
            "Starting epoch 32 / 100\n",
            "t = 2, avg_loss = 0.2197\n",
            "t = 4, avg_loss = 0.0970\n",
            "t = 6, avg_loss = 0.1640\n",
            "t = 8, avg_loss = 0.1292\n",
            "t = 10, avg_loss = 0.0989\n",
            "t = 12, avg_loss = 0.1691\n",
            "t = 14, avg_loss = 0.1011\n",
            "t = 16, avg_loss = 0.1571\n",
            "t = 18, avg_loss = 0.0903\n",
            "t = 20, avg_loss = 0.1074\n",
            "t = 22, avg_loss = 0.2075\n",
            "t = 24, avg_loss = 0.1477\n",
            "Checking accuracy on test set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 33 / 100\n",
            "t = 2, avg_loss = 0.2217\n",
            "t = 4, avg_loss = 0.1130\n",
            "t = 6, avg_loss = 0.1062\n",
            "t = 8, avg_loss = 0.1051\n",
            "t = 10, avg_loss = 0.1796\n",
            "t = 12, avg_loss = 0.0901\n",
            "t = 14, avg_loss = 0.2416\n",
            "t = 16, avg_loss = 0.2352\n",
            "t = 18, avg_loss = 0.1558\n",
            "t = 20, avg_loss = 0.1444\n",
            "t = 22, avg_loss = 0.1394\n",
            "t = 24, avg_loss = 0.1724\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 34 / 100\n",
            "t = 2, avg_loss = 0.1856\n",
            "t = 4, avg_loss = 0.1254\n",
            "t = 6, avg_loss = 0.1970\n",
            "t = 8, avg_loss = 0.0999\n",
            "t = 10, avg_loss = 0.0918\n",
            "t = 12, avg_loss = 0.1298\n",
            "t = 14, avg_loss = 0.1407\n",
            "t = 16, avg_loss = 0.1976\n",
            "t = 18, avg_loss = 0.1734\n",
            "t = 20, avg_loss = 0.0850\n",
            "t = 22, avg_loss = 0.1353\n",
            "t = 24, avg_loss = 0.1698\n",
            "Checking accuracy on test set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 35 / 100\n",
            "t = 2, avg_loss = 0.2776\n",
            "t = 4, avg_loss = 0.1150\n",
            "t = 6, avg_loss = 0.1278\n",
            "t = 8, avg_loss = 0.0786\n",
            "t = 10, avg_loss = 0.1630\n",
            "t = 12, avg_loss = 0.1477\n",
            "t = 14, avg_loss = 0.1663\n",
            "t = 16, avg_loss = 0.0948\n",
            "t = 18, avg_loss = 0.1074\n",
            "t = 20, avg_loss = 0.1503\n",
            "t = 22, avg_loss = 0.1314\n",
            "t = 24, avg_loss = 0.0697\n",
            "Checking accuracy on test set\n",
            "Got 358 / 400 correct (89.50)\n",
            "acc = 0.895000\n",
            "Starting epoch 36 / 100\n",
            "t = 2, avg_loss = 0.1782\n",
            "t = 4, avg_loss = 0.0855\n",
            "t = 6, avg_loss = 0.0960\n",
            "t = 8, avg_loss = 0.0767\n",
            "t = 10, avg_loss = 0.1731\n",
            "t = 12, avg_loss = 0.1768\n",
            "t = 14, avg_loss = 0.1346\n",
            "t = 16, avg_loss = 0.1380\n",
            "t = 18, avg_loss = 0.1071\n",
            "t = 20, avg_loss = 0.0942\n",
            "t = 22, avg_loss = 0.1039\n",
            "t = 24, avg_loss = 0.1244\n",
            "Checking accuracy on test set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 37 / 100\n",
            "t = 2, avg_loss = 0.1681\n",
            "t = 4, avg_loss = 0.1457\n",
            "t = 6, avg_loss = 0.0939\n",
            "t = 8, avg_loss = 0.1204\n",
            "t = 10, avg_loss = 0.0622\n",
            "t = 12, avg_loss = 0.1377\n",
            "t = 14, avg_loss = 0.1713\n",
            "t = 16, avg_loss = 0.1214\n",
            "t = 18, avg_loss = 0.0918\n",
            "t = 20, avg_loss = 0.0927\n",
            "t = 22, avg_loss = 0.1888\n",
            "t = 24, avg_loss = 0.0899\n",
            "Checking accuracy on test set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 38 / 100\n",
            "t = 2, avg_loss = 0.1404\n",
            "t = 4, avg_loss = 0.1365\n",
            "t = 6, avg_loss = 0.0974\n",
            "t = 8, avg_loss = 0.1668\n",
            "t = 10, avg_loss = 0.0859\n",
            "t = 12, avg_loss = 0.1183\n",
            "t = 14, avg_loss = 0.1603\n",
            "t = 16, avg_loss = 0.2650\n",
            "t = 18, avg_loss = 0.1259\n",
            "t = 20, avg_loss = 0.0965\n",
            "t = 22, avg_loss = 0.1419\n",
            "t = 24, avg_loss = 0.1101\n",
            "Checking accuracy on test set\n",
            "Got 361 / 400 correct (90.25)\n",
            "acc = 0.902500\n",
            "Starting epoch 39 / 100\n",
            "t = 2, avg_loss = 0.2615\n",
            "t = 4, avg_loss = 0.1007\n",
            "t = 6, avg_loss = 0.1295\n",
            "t = 8, avg_loss = 0.1587\n",
            "t = 10, avg_loss = 0.1166\n",
            "t = 12, avg_loss = 0.0872\n",
            "t = 14, avg_loss = 0.1254\n",
            "t = 16, avg_loss = 0.0782\n",
            "t = 18, avg_loss = 0.1102\n",
            "t = 20, avg_loss = 0.1507\n",
            "t = 22, avg_loss = 0.0870\n",
            "t = 24, avg_loss = 0.1506\n",
            "Checking accuracy on test set\n",
            "Got 360 / 400 correct (90.00)\n",
            "acc = 0.900000\n",
            "Starting epoch 40 / 100\n",
            "t = 2, avg_loss = 0.1760\n",
            "t = 4, avg_loss = 0.1263\n",
            "t = 6, avg_loss = 0.1000\n",
            "t = 8, avg_loss = 0.0978\n",
            "t = 10, avg_loss = 0.1431\n",
            "t = 12, avg_loss = 0.1668\n",
            "t = 14, avg_loss = 0.0992\n",
            "t = 16, avg_loss = 0.1307\n",
            "t = 18, avg_loss = 0.1051\n",
            "t = 20, avg_loss = 0.1286\n",
            "t = 22, avg_loss = 0.1169\n",
            "t = 24, avg_loss = 0.1126\n",
            "Checking accuracy on test set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 41 / 100\n",
            "t = 2, avg_loss = 0.2605\n",
            "t = 4, avg_loss = 0.1841\n",
            "t = 6, avg_loss = 0.2017\n",
            "t = 8, avg_loss = 0.1597\n",
            "t = 10, avg_loss = 0.1227\n",
            "t = 12, avg_loss = 0.1072\n",
            "t = 14, avg_loss = 0.1507\n",
            "t = 16, avg_loss = 0.1498\n",
            "t = 18, avg_loss = 0.1301\n",
            "t = 20, avg_loss = 0.1075\n",
            "t = 22, avg_loss = 0.1974\n",
            "t = 24, avg_loss = 0.1251\n",
            "Checking accuracy on test set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 42 / 100\n",
            "t = 2, avg_loss = 0.2143\n",
            "t = 4, avg_loss = 0.1317\n",
            "t = 6, avg_loss = 0.0868\n",
            "t = 8, avg_loss = 0.1164\n",
            "t = 10, avg_loss = 0.1093\n",
            "t = 12, avg_loss = 0.0884\n",
            "t = 14, avg_loss = 0.1392\n",
            "t = 16, avg_loss = 0.1087\n",
            "t = 18, avg_loss = 0.1622\n",
            "t = 20, avg_loss = 0.1268\n",
            "t = 22, avg_loss = 0.1110\n",
            "t = 24, avg_loss = 0.1806\n",
            "Checking accuracy on test set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 43 / 100\n",
            "t = 2, avg_loss = 0.1385\n",
            "t = 4, avg_loss = 0.0627\n",
            "t = 6, avg_loss = 0.1045\n",
            "t = 8, avg_loss = 0.1013\n",
            "t = 10, avg_loss = 0.1130\n",
            "t = 12, avg_loss = 0.0885\n",
            "t = 14, avg_loss = 0.1677\n",
            "t = 16, avg_loss = 0.1119\n",
            "t = 18, avg_loss = 0.1471\n",
            "t = 20, avg_loss = 0.1384\n",
            "t = 22, avg_loss = 0.0735\n",
            "t = 24, avg_loss = 0.1123\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 44 / 100\n",
            "t = 2, avg_loss = 0.1808\n",
            "t = 4, avg_loss = 0.1106\n",
            "t = 6, avg_loss = 0.1339\n",
            "t = 8, avg_loss = 0.0861\n",
            "t = 10, avg_loss = 0.1462\n",
            "t = 12, avg_loss = 0.1060\n",
            "t = 14, avg_loss = 0.1744\n",
            "t = 16, avg_loss = 0.1727\n",
            "t = 18, avg_loss = 0.1514\n",
            "t = 20, avg_loss = 0.0725\n",
            "t = 22, avg_loss = 0.1575\n",
            "t = 24, avg_loss = 0.0631\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 45 / 100\n",
            "t = 2, avg_loss = 0.1035\n",
            "t = 4, avg_loss = 0.0888\n",
            "t = 6, avg_loss = 0.1224\n",
            "t = 8, avg_loss = 0.1279\n",
            "t = 10, avg_loss = 0.0898\n",
            "t = 12, avg_loss = 0.0944\n",
            "t = 14, avg_loss = 0.1132\n",
            "t = 16, avg_loss = 0.0969\n",
            "t = 18, avg_loss = 0.1497\n",
            "t = 20, avg_loss = 0.1441\n",
            "t = 22, avg_loss = 0.0952\n",
            "t = 24, avg_loss = 0.0811\n",
            "Checking accuracy on test set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 46 / 100\n",
            "t = 2, avg_loss = 0.2252\n",
            "t = 4, avg_loss = 0.1017\n",
            "t = 6, avg_loss = 0.0703\n",
            "t = 8, avg_loss = 0.0964\n",
            "t = 10, avg_loss = 0.0902\n",
            "t = 12, avg_loss = 0.0938\n",
            "t = 14, avg_loss = 0.1359\n",
            "t = 16, avg_loss = 0.0756\n",
            "t = 18, avg_loss = 0.0884\n",
            "t = 20, avg_loss = 0.1070\n",
            "t = 22, avg_loss = 0.0912\n",
            "t = 24, avg_loss = 0.0893\n",
            "Checking accuracy on test set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 47 / 100\n",
            "t = 2, avg_loss = 0.1798\n",
            "t = 4, avg_loss = 0.1310\n",
            "t = 6, avg_loss = 0.1416\n",
            "t = 8, avg_loss = 0.1072\n",
            "t = 10, avg_loss = 0.1225\n",
            "t = 12, avg_loss = 0.0929\n",
            "t = 14, avg_loss = 0.0824\n",
            "t = 16, avg_loss = 0.1087\n",
            "t = 18, avg_loss = 0.1020\n",
            "t = 20, avg_loss = 0.0539\n",
            "t = 22, avg_loss = 0.1564\n",
            "t = 24, avg_loss = 0.1071\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 48 / 100\n",
            "t = 2, avg_loss = 0.1956\n",
            "t = 4, avg_loss = 0.1020\n",
            "t = 6, avg_loss = 0.0954\n",
            "t = 8, avg_loss = 0.1319\n",
            "t = 10, avg_loss = 0.1150\n",
            "t = 12, avg_loss = 0.0716\n",
            "t = 14, avg_loss = 0.1304\n",
            "t = 16, avg_loss = 0.1251\n",
            "t = 18, avg_loss = 0.0621\n",
            "t = 20, avg_loss = 0.0863\n",
            "t = 22, avg_loss = 0.0998\n",
            "t = 24, avg_loss = 0.1566\n",
            "Checking accuracy on test set\n",
            "Got 351 / 400 correct (87.75)\n",
            "acc = 0.877500\n",
            "Starting epoch 49 / 100\n",
            "t = 2, avg_loss = 0.1693\n",
            "t = 4, avg_loss = 0.1881\n",
            "t = 6, avg_loss = 0.1098\n",
            "t = 8, avg_loss = 0.0673\n",
            "t = 10, avg_loss = 0.0844\n",
            "t = 12, avg_loss = 0.1211\n",
            "t = 14, avg_loss = 0.0774\n",
            "t = 16, avg_loss = 0.0734\n",
            "t = 18, avg_loss = 0.1465\n",
            "t = 20, avg_loss = 0.1132\n",
            "t = 22, avg_loss = 0.1147\n",
            "t = 24, avg_loss = 0.1231\n",
            "Checking accuracy on test set\n",
            "Got 351 / 400 correct (87.75)\n",
            "acc = 0.877500\n",
            "Starting epoch 50 / 100\n",
            "t = 2, avg_loss = 0.1056\n",
            "t = 4, avg_loss = 0.1057\n",
            "t = 6, avg_loss = 0.0836\n",
            "t = 8, avg_loss = 0.1202\n",
            "t = 10, avg_loss = 0.1222\n",
            "t = 12, avg_loss = 0.0724\n",
            "t = 14, avg_loss = 0.1275\n",
            "t = 16, avg_loss = 0.1071\n",
            "t = 18, avg_loss = 0.1321\n",
            "t = 20, avg_loss = 0.0647\n",
            "t = 22, avg_loss = 0.1071\n",
            "t = 24, avg_loss = 0.0752\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 51 / 100\n",
            "t = 2, avg_loss = 0.1867\n",
            "t = 4, avg_loss = 0.0824\n",
            "t = 6, avg_loss = 0.0384\n",
            "t = 8, avg_loss = 0.0956\n",
            "t = 10, avg_loss = 0.0491\n",
            "t = 12, avg_loss = 0.1260\n",
            "t = 14, avg_loss = 0.1286\n",
            "t = 16, avg_loss = 0.0835\n",
            "t = 18, avg_loss = 0.0724\n",
            "t = 20, avg_loss = 0.1366\n",
            "t = 22, avg_loss = 0.1075\n",
            "t = 24, avg_loss = 0.0929\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 52 / 100\n",
            "t = 2, avg_loss = 0.1851\n",
            "t = 4, avg_loss = 0.0919\n",
            "t = 6, avg_loss = 0.0889\n",
            "t = 8, avg_loss = 0.0682\n",
            "t = 10, avg_loss = 0.0901\n",
            "t = 12, avg_loss = 0.1110\n",
            "t = 14, avg_loss = 0.0876\n",
            "t = 16, avg_loss = 0.0989\n",
            "t = 18, avg_loss = 0.0762\n",
            "t = 20, avg_loss = 0.0887\n",
            "t = 22, avg_loss = 0.1008\n",
            "t = 24, avg_loss = 0.1159\n",
            "Checking accuracy on test set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 53 / 100\n",
            "t = 2, avg_loss = 0.0918\n",
            "t = 4, avg_loss = 0.0497\n",
            "t = 6, avg_loss = 0.0832\n",
            "t = 8, avg_loss = 0.0688\n",
            "t = 10, avg_loss = 0.0730\n",
            "t = 12, avg_loss = 0.1017\n",
            "t = 14, avg_loss = 0.1048\n",
            "t = 16, avg_loss = 0.0914\n",
            "t = 18, avg_loss = 0.1612\n",
            "t = 20, avg_loss = 0.0637\n",
            "t = 22, avg_loss = 0.1526\n",
            "t = 24, avg_loss = 0.1077\n",
            "Checking accuracy on test set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 54 / 100\n",
            "t = 2, avg_loss = 0.1786\n",
            "t = 4, avg_loss = 0.0585\n",
            "t = 6, avg_loss = 0.0925\n",
            "t = 8, avg_loss = 0.0666\n",
            "t = 10, avg_loss = 0.1080\n",
            "t = 12, avg_loss = 0.1075\n",
            "t = 14, avg_loss = 0.0898\n",
            "t = 16, avg_loss = 0.1302\n",
            "t = 18, avg_loss = 0.0841\n",
            "t = 20, avg_loss = 0.1183\n",
            "t = 22, avg_loss = 0.1276\n",
            "t = 24, avg_loss = 0.0927\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 55 / 100\n",
            "t = 2, avg_loss = 0.1210\n",
            "t = 4, avg_loss = 0.0731\n",
            "t = 6, avg_loss = 0.0944\n",
            "t = 8, avg_loss = 0.0493\n",
            "t = 10, avg_loss = 0.1034\n",
            "t = 12, avg_loss = 0.0772\n",
            "t = 14, avg_loss = 0.0933\n",
            "t = 16, avg_loss = 0.0750\n",
            "t = 18, avg_loss = 0.0681\n",
            "t = 20, avg_loss = 0.0481\n",
            "t = 22, avg_loss = 0.0576\n",
            "t = 24, avg_loss = 0.1027\n",
            "Checking accuracy on test set\n",
            "Got 358 / 400 correct (89.50)\n",
            "acc = 0.895000\n",
            "Starting epoch 56 / 100\n",
            "t = 2, avg_loss = 0.1526\n",
            "t = 4, avg_loss = 0.0793\n",
            "t = 6, avg_loss = 0.0632\n",
            "t = 8, avg_loss = 0.1018\n",
            "t = 10, avg_loss = 0.0624\n",
            "t = 12, avg_loss = 0.0867\n",
            "t = 14, avg_loss = 0.0589\n",
            "t = 16, avg_loss = 0.0829\n",
            "t = 18, avg_loss = 0.0708\n",
            "t = 20, avg_loss = 0.0733\n",
            "t = 22, avg_loss = 0.1193\n",
            "t = 24, avg_loss = 0.0609\n",
            "Checking accuracy on test set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 57 / 100\n",
            "t = 2, avg_loss = 0.0896\n",
            "t = 4, avg_loss = 0.0722\n",
            "t = 6, avg_loss = 0.0634\n",
            "t = 8, avg_loss = 0.1408\n",
            "t = 10, avg_loss = 0.0482\n",
            "t = 12, avg_loss = 0.0816\n",
            "t = 14, avg_loss = 0.0788\n",
            "t = 16, avg_loss = 0.0808\n",
            "t = 18, avg_loss = 0.0759\n",
            "t = 20, avg_loss = 0.0749\n",
            "t = 22, avg_loss = 0.0738\n",
            "t = 24, avg_loss = 0.0894\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 58 / 100\n",
            "t = 2, avg_loss = 0.0947\n",
            "t = 4, avg_loss = 0.0610\n",
            "t = 6, avg_loss = 0.0486\n",
            "t = 8, avg_loss = 0.0672\n",
            "t = 10, avg_loss = 0.1107\n",
            "t = 12, avg_loss = 0.0719\n",
            "t = 14, avg_loss = 0.0835\n",
            "t = 16, avg_loss = 0.0843\n",
            "t = 18, avg_loss = 0.0509\n",
            "t = 20, avg_loss = 0.0557\n",
            "t = 22, avg_loss = 0.0613\n",
            "t = 24, avg_loss = 0.0719\n",
            "Checking accuracy on test set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 59 / 100\n",
            "t = 2, avg_loss = 0.1275\n",
            "t = 4, avg_loss = 0.0674\n",
            "t = 6, avg_loss = 0.0665\n",
            "t = 8, avg_loss = 0.0442\n",
            "t = 10, avg_loss = 0.1029\n",
            "t = 12, avg_loss = 0.1033\n",
            "t = 14, avg_loss = 0.0715\n",
            "t = 16, avg_loss = 0.0498\n",
            "t = 18, avg_loss = 0.0492\n",
            "t = 20, avg_loss = 0.0579\n",
            "t = 22, avg_loss = 0.0853\n",
            "t = 24, avg_loss = 0.0972\n",
            "Checking accuracy on test set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 60 / 100\n",
            "t = 2, avg_loss = 0.1338\n",
            "t = 4, avg_loss = 0.1165\n",
            "t = 6, avg_loss = 0.1054\n",
            "t = 8, avg_loss = 0.0646\n",
            "t = 10, avg_loss = 0.0974\n",
            "t = 12, avg_loss = 0.1144\n",
            "t = 14, avg_loss = 0.0792\n",
            "t = 16, avg_loss = 0.0796\n",
            "t = 18, avg_loss = 0.0444\n",
            "t = 20, avg_loss = 0.1397\n",
            "t = 22, avg_loss = 0.0641\n",
            "t = 24, avg_loss = 0.0717\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 61 / 100\n",
            "t = 2, avg_loss = 0.0973\n",
            "t = 4, avg_loss = 0.1061\n",
            "t = 6, avg_loss = 0.0380\n",
            "t = 8, avg_loss = 0.0804\n",
            "t = 10, avg_loss = 0.0606\n",
            "t = 12, avg_loss = 0.1348\n",
            "t = 14, avg_loss = 0.0844\n",
            "t = 16, avg_loss = 0.0818\n",
            "t = 18, avg_loss = 0.0494\n",
            "t = 20, avg_loss = 0.0842\n",
            "t = 22, avg_loss = 0.0647\n",
            "t = 24, avg_loss = 0.1135\n",
            "Checking accuracy on test set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 62 / 100\n",
            "t = 2, avg_loss = 0.1229\n",
            "t = 4, avg_loss = 0.0696\n",
            "t = 6, avg_loss = 0.0677\n",
            "t = 8, avg_loss = 0.0795\n",
            "t = 10, avg_loss = 0.0991\n",
            "t = 12, avg_loss = 0.0568\n",
            "t = 14, avg_loss = 0.1611\n",
            "t = 16, avg_loss = 0.0796\n",
            "t = 18, avg_loss = 0.0583\n",
            "t = 20, avg_loss = 0.0904\n",
            "t = 22, avg_loss = 0.1293\n",
            "t = 24, avg_loss = 0.0838\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 63 / 100\n",
            "t = 2, avg_loss = 0.1741\n",
            "t = 4, avg_loss = 0.0879\n",
            "t = 6, avg_loss = 0.0686\n",
            "t = 8, avg_loss = 0.1158\n",
            "t = 10, avg_loss = 0.0892\n",
            "t = 12, avg_loss = 0.0620\n",
            "t = 14, avg_loss = 0.0649\n",
            "t = 16, avg_loss = 0.0712\n",
            "t = 18, avg_loss = 0.0736\n",
            "t = 20, avg_loss = 0.0881\n",
            "t = 22, avg_loss = 0.0682\n",
            "t = 24, avg_loss = 0.0539\n",
            "Checking accuracy on test set\n",
            "Got 351 / 400 correct (87.75)\n",
            "acc = 0.877500\n",
            "Starting epoch 64 / 100\n",
            "t = 2, avg_loss = 0.1427\n",
            "t = 4, avg_loss = 0.0788\n",
            "t = 6, avg_loss = 0.0717\n",
            "t = 8, avg_loss = 0.0615\n",
            "t = 10, avg_loss = 0.0818\n",
            "t = 12, avg_loss = 0.1061\n",
            "t = 14, avg_loss = 0.0906\n",
            "t = 16, avg_loss = 0.1521\n",
            "t = 18, avg_loss = 0.0684\n",
            "t = 20, avg_loss = 0.0630\n",
            "t = 22, avg_loss = 0.0830\n",
            "t = 24, avg_loss = 0.2069\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 65 / 100\n",
            "t = 2, avg_loss = 0.1342\n",
            "t = 4, avg_loss = 0.0590\n",
            "t = 6, avg_loss = 0.0551\n",
            "t = 8, avg_loss = 0.0878\n",
            "t = 10, avg_loss = 0.0477\n",
            "t = 12, avg_loss = 0.0843\n",
            "t = 14, avg_loss = 0.0870\n",
            "t = 16, avg_loss = 0.0825\n",
            "t = 18, avg_loss = 0.0686\n",
            "t = 20, avg_loss = 0.1460\n",
            "t = 22, avg_loss = 0.0682\n",
            "t = 24, avg_loss = 0.1220\n",
            "Checking accuracy on test set\n",
            "Got 360 / 400 correct (90.00)\n",
            "acc = 0.900000\n",
            "Starting epoch 66 / 100\n",
            "t = 2, avg_loss = 0.1127\n",
            "t = 4, avg_loss = 0.0726\n",
            "t = 6, avg_loss = 0.0961\n",
            "t = 8, avg_loss = 0.0722\n",
            "t = 10, avg_loss = 0.0584\n",
            "t = 12, avg_loss = 0.0454\n",
            "t = 14, avg_loss = 0.1279\n",
            "t = 16, avg_loss = 0.0497\n",
            "t = 18, avg_loss = 0.1144\n",
            "t = 20, avg_loss = 0.1265\n",
            "t = 22, avg_loss = 0.1066\n",
            "t = 24, avg_loss = 0.0593\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 67 / 100\n",
            "t = 2, avg_loss = 0.1515\n",
            "t = 4, avg_loss = 0.0707\n",
            "t = 6, avg_loss = 0.0651\n",
            "t = 8, avg_loss = 0.0690\n",
            "t = 10, avg_loss = 0.1100\n",
            "t = 12, avg_loss = 0.0487\n",
            "t = 14, avg_loss = 0.0452\n",
            "t = 16, avg_loss = 0.0704\n",
            "t = 18, avg_loss = 0.0777\n",
            "t = 20, avg_loss = 0.0848\n",
            "t = 22, avg_loss = 0.0264\n",
            "t = 24, avg_loss = 0.0624\n",
            "Checking accuracy on test set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 68 / 100\n",
            "t = 2, avg_loss = 0.0797\n",
            "t = 4, avg_loss = 0.0426\n",
            "t = 6, avg_loss = 0.0661\n",
            "t = 8, avg_loss = 0.0858\n",
            "t = 10, avg_loss = 0.1219\n",
            "t = 12, avg_loss = 0.0464\n",
            "t = 14, avg_loss = 0.0446\n",
            "t = 16, avg_loss = 0.0761\n",
            "t = 18, avg_loss = 0.0408\n",
            "t = 20, avg_loss = 0.0557\n",
            "t = 22, avg_loss = 0.1102\n",
            "t = 24, avg_loss = 0.0757\n",
            "Checking accuracy on test set\n",
            "t = 2, avg_loss = 0.1085\n",
            "t = 4, avg_loss = 0.0471\n",
            "t = 6, avg_loss = 0.0601\n",
            "t = 8, avg_loss = 0.0474\n",
            "t = 10, avg_loss = 0.1078\n",
            "t = 12, avg_loss = 0.0480\n",
            "t = 14, avg_loss = 0.0609\n",
            "t = 16, avg_loss = 0.0632\n",
            "t = 18, avg_loss = 0.0671\n",
            "t = 20, avg_loss = 0.1274\n",
            "t = 22, avg_loss = 0.0605\n",
            "t = 24, avg_loss = 0.0457\n",
            "Checking accuracy on test set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 70 / 100\n",
            "t = 2, avg_loss = 0.0836\n",
            "t = 4, avg_loss = 0.0353\n",
            "t = 6, avg_loss = 0.0307\n",
            "t = 8, avg_loss = 0.0583\n",
            "t = 10, avg_loss = 0.0376\n",
            "t = 12, avg_loss = 0.0597\n",
            "t = 14, avg_loss = 0.0658\n",
            "t = 16, avg_loss = 0.0730\n",
            "t = 18, avg_loss = 0.1022\n",
            "t = 20, avg_loss = 0.0671\n",
            "t = 22, avg_loss = 0.0776\n",
            "t = 24, avg_loss = 0.0467\n",
            "Checking accuracy on test set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 71 / 100\n",
            "t = 2, avg_loss = 0.0745\n",
            "t = 4, avg_loss = 0.0591\n",
            "t = 6, avg_loss = 0.0559\n",
            "t = 8, avg_loss = 0.0424\n",
            "t = 10, avg_loss = 0.0909\n",
            "t = 12, avg_loss = 0.0681\n",
            "t = 14, avg_loss = 0.0617\n",
            "t = 16, avg_loss = 0.0566\n",
            "t = 18, avg_loss = 0.0583\n",
            "t = 20, avg_loss = 0.0761\n",
            "t = 22, avg_loss = 0.0419\n",
            "t = 24, avg_loss = 0.0558\n",
            "Checking accuracy on test set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 72 / 100\n",
            "t = 2, avg_loss = 0.0964\n",
            "t = 4, avg_loss = 0.0659\n",
            "t = 6, avg_loss = 0.0412\n",
            "t = 8, avg_loss = 0.0525\n",
            "t = 10, avg_loss = 0.0539\n",
            "t = 12, avg_loss = 0.0594\n",
            "t = 14, avg_loss = 0.0804\n",
            "t = 16, avg_loss = 0.0173\n",
            "t = 18, avg_loss = 0.0571\n",
            "t = 20, avg_loss = 0.0566\n",
            "t = 22, avg_loss = 0.0626\n",
            "t = 24, avg_loss = 0.0596\n",
            "Checking accuracy on test set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 73 / 100\n",
            "t = 2, avg_loss = 0.0458\n",
            "t = 4, avg_loss = 0.0395\n",
            "t = 6, avg_loss = 0.0713\n",
            "t = 8, avg_loss = 0.0674\n",
            "t = 10, avg_loss = 0.1102\n",
            "t = 12, avg_loss = 0.0761\n",
            "t = 14, avg_loss = 0.0831\n",
            "t = 16, avg_loss = 0.0866\n",
            "t = 18, avg_loss = 0.0817\n",
            "t = 20, avg_loss = 0.0674\n",
            "t = 22, avg_loss = 0.1075\n",
            "t = 24, avg_loss = 0.0704\n",
            "Checking accuracy on test set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 74 / 100\n",
            "t = 2, avg_loss = 0.1235\n",
            "t = 4, avg_loss = 0.0643\n",
            "t = 6, avg_loss = 0.0620\n",
            "t = 8, avg_loss = 0.1287\n",
            "t = 10, avg_loss = 0.0572\n",
            "t = 12, avg_loss = 0.0485\n",
            "t = 14, avg_loss = 0.0466\n",
            "t = 16, avg_loss = 0.0798\n",
            "t = 18, avg_loss = 0.0673\n",
            "t = 20, avg_loss = 0.0679\n",
            "t = 22, avg_loss = 0.0489\n",
            "t = 24, avg_loss = 0.0904\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 75 / 100\n",
            "t = 2, avg_loss = 0.1478\n",
            "t = 4, avg_loss = 0.0454\n",
            "t = 6, avg_loss = 0.0409\n",
            "t = 8, avg_loss = 0.0657\n",
            "t = 10, avg_loss = 0.0710\n",
            "t = 12, avg_loss = 0.0534\n",
            "t = 14, avg_loss = 0.0405\n",
            "t = 16, avg_loss = 0.0437\n",
            "t = 18, avg_loss = 0.0551\n",
            "t = 20, avg_loss = 0.0509\n",
            "t = 22, avg_loss = 0.0783\n",
            "t = 24, avg_loss = 0.0510\n",
            "Checking accuracy on test set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 76 / 100\n",
            "t = 2, avg_loss = 0.0750\n",
            "t = 4, avg_loss = 0.0912\n",
            "t = 6, avg_loss = 0.0644\n",
            "t = 8, avg_loss = 0.0811\n",
            "t = 10, avg_loss = 0.0414\n",
            "t = 12, avg_loss = 0.0697\n",
            "t = 14, avg_loss = 0.0579\n",
            "t = 16, avg_loss = 0.0475\n",
            "t = 18, avg_loss = 0.0916\n",
            "t = 20, avg_loss = 0.0509\n",
            "t = 22, avg_loss = 0.0793\n",
            "t = 24, avg_loss = 0.0588\n",
            "Checking accuracy on test set\n",
            "Got 358 / 400 correct (89.50)\n",
            "acc = 0.895000\n",
            "Starting epoch 77 / 100\n",
            "t = 2, avg_loss = 0.0938\n",
            "t = 4, avg_loss = 0.0389\n",
            "t = 6, avg_loss = 0.0548\n",
            "t = 8, avg_loss = 0.0724\n",
            "t = 10, avg_loss = 0.0898\n",
            "t = 12, avg_loss = 0.0354\n",
            "t = 14, avg_loss = 0.0740\n",
            "t = 16, avg_loss = 0.0852\n",
            "t = 18, avg_loss = 0.0188\n",
            "t = 20, avg_loss = 0.0749\n",
            "t = 22, avg_loss = 0.0620\n",
            "t = 24, avg_loss = 0.0484\n",
            "Checking accuracy on test set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 78 / 100\n",
            "t = 2, avg_loss = 0.0989\n",
            "t = 4, avg_loss = 0.0627\n",
            "t = 6, avg_loss = 0.0382\n",
            "t = 8, avg_loss = 0.0285\n",
            "t = 10, avg_loss = 0.0732\n",
            "t = 12, avg_loss = 0.0472\n",
            "t = 14, avg_loss = 0.0625\n",
            "t = 16, avg_loss = 0.0534\n",
            "t = 18, avg_loss = 0.0375\n",
            "t = 20, avg_loss = 0.0559\n",
            "t = 22, avg_loss = 0.0651\n",
            "t = 24, avg_loss = 0.0614\n",
            "Checking accuracy on test set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 79 / 100\n",
            "t = 2, avg_loss = 0.0659\n",
            "t = 4, avg_loss = 0.0512\n",
            "t = 6, avg_loss = 0.0596\n",
            "t = 8, avg_loss = 0.0867\n",
            "t = 10, avg_loss = 0.0321\n",
            "t = 12, avg_loss = 0.0703\n",
            "t = 14, avg_loss = 0.1321\n",
            "t = 16, avg_loss = 0.0694\n",
            "t = 18, avg_loss = 0.0800\n",
            "t = 20, avg_loss = 0.0502\n",
            "t = 22, avg_loss = 0.1095\n",
            "t = 24, avg_loss = 0.1042\n",
            "Checking accuracy on test set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 80 / 100\n",
            "t = 2, avg_loss = 0.0994\n",
            "t = 4, avg_loss = 0.0342\n",
            "t = 6, avg_loss = 0.0768\n",
            "t = 8, avg_loss = 0.0570\n",
            "t = 10, avg_loss = 0.0680\n",
            "t = 12, avg_loss = 0.0320\n",
            "t = 14, avg_loss = 0.0451\n",
            "t = 16, avg_loss = 0.0422\n",
            "t = 18, avg_loss = 0.0266\n",
            "t = 20, avg_loss = 0.0564\n",
            "t = 22, avg_loss = 0.0799\n",
            "t = 24, avg_loss = 0.0474\n",
            "Checking accuracy on test set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 81 / 100\n",
            "t = 2, avg_loss = 0.0851\n",
            "t = 4, avg_loss = 0.0586\n",
            "t = 6, avg_loss = 0.0394\n",
            "t = 8, avg_loss = 0.0807\n",
            "t = 10, avg_loss = 0.0362\n",
            "t = 12, avg_loss = 0.0413\n",
            "t = 14, avg_loss = 0.0526\n",
            "t = 16, avg_loss = 0.0402\n",
            "t = 18, avg_loss = 0.0420\n",
            "t = 20, avg_loss = 0.0594\n",
            "t = 22, avg_loss = 0.0471\n",
            "t = 24, avg_loss = 0.0581\n",
            "Checking accuracy on test set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 82 / 100\n",
            "t = 2, avg_loss = 0.0726\n",
            "t = 4, avg_loss = 0.0280\n",
            "t = 6, avg_loss = 0.0622\n",
            "t = 8, avg_loss = 0.0864\n",
            "t = 10, avg_loss = 0.1180\n",
            "t = 12, avg_loss = 0.0310\n",
            "t = 14, avg_loss = 0.0744\n",
            "t = 16, avg_loss = 0.0686\n",
            "t = 18, avg_loss = 0.0484\n",
            "t = 20, avg_loss = 0.0865\n",
            "t = 22, avg_loss = 0.0606\n",
            "t = 24, avg_loss = 0.0601\n",
            "Checking accuracy on test set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 83 / 100\n",
            "t = 2, avg_loss = 0.0964\n",
            "t = 4, avg_loss = 0.0819\n",
            "t = 6, avg_loss = 0.0496\n",
            "t = 8, avg_loss = 0.0419\n",
            "t = 10, avg_loss = 0.0632\n",
            "t = 12, avg_loss = 0.0634\n",
            "t = 14, avg_loss = 0.0690\n",
            "t = 16, avg_loss = 0.0528\n",
            "t = 18, avg_loss = 0.0428\n",
            "t = 20, avg_loss = 0.0721\n",
            "t = 22, avg_loss = 0.0635\n",
            "t = 24, avg_loss = 0.0941\n",
            "Checking accuracy on test set\n",
            "Got 358 / 400 correct (89.50)\n",
            "acc = 0.895000\n",
            "Starting epoch 84 / 100\n",
            "t = 2, avg_loss = 0.0869\n",
            "t = 4, avg_loss = 0.0484\n",
            "t = 6, avg_loss = 0.0564\n",
            "t = 8, avg_loss = 0.0920\n",
            "t = 10, avg_loss = 0.0504\n",
            "t = 12, avg_loss = 0.0285\n",
            "t = 14, avg_loss = 0.0449\n",
            "t = 16, avg_loss = 0.0880\n",
            "t = 18, avg_loss = 0.1299\n",
            "t = 20, avg_loss = 0.0973\n",
            "t = 22, avg_loss = 0.1459\n",
            "t = 24, avg_loss = 0.1235\n",
            "Checking accuracy on test set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 85 / 100\n",
            "t = 2, avg_loss = 0.0876\n",
            "t = 4, avg_loss = 0.0579\n",
            "t = 6, avg_loss = 0.0621\n",
            "t = 8, avg_loss = 0.0651\n",
            "t = 10, avg_loss = 0.0485\n",
            "t = 12, avg_loss = 0.0875\n",
            "t = 14, avg_loss = 0.0642\n",
            "t = 16, avg_loss = 0.0592\n",
            "t = 18, avg_loss = 0.0287\n",
            "t = 20, avg_loss = 0.0410\n",
            "t = 22, avg_loss = 0.1489\n",
            "t = 24, avg_loss = 0.0737\n",
            "Checking accuracy on test set\n",
            "Got 359 / 400 correct (89.75)\n",
            "acc = 0.897500\n",
            "Starting epoch 86 / 100\n",
            "t = 2, avg_loss = 0.1233\n",
            "t = 4, avg_loss = 0.0682\n",
            "t = 6, avg_loss = 0.0535\n",
            "t = 8, avg_loss = 0.0501\n",
            "t = 10, avg_loss = 0.0257\n",
            "t = 12, avg_loss = 0.0657\n",
            "t = 14, avg_loss = 0.0670\n",
            "t = 16, avg_loss = 0.0693\n",
            "t = 18, avg_loss = 0.0535\n",
            "t = 20, avg_loss = 0.1025\n",
            "t = 22, avg_loss = 0.0437\n",
            "t = 24, avg_loss = 0.0777\n",
            "Checking accuracy on test set\n",
            "Got 345 / 400 correct (86.25)\n",
            "acc = 0.862500\n",
            "Starting epoch 87 / 100\n",
            "t = 2, avg_loss = 0.0898\n",
            "t = 4, avg_loss = 0.1070\n",
            "t = 6, avg_loss = 0.0459\n",
            "t = 8, avg_loss = 0.0589\n",
            "t = 10, avg_loss = 0.0597\n",
            "t = 12, avg_loss = 0.0834\n",
            "t = 14, avg_loss = 0.0724\n",
            "t = 16, avg_loss = 0.0302\n",
            "t = 18, avg_loss = 0.0591\n",
            "t = 20, avg_loss = 0.0414\n",
            "t = 22, avg_loss = 0.0624\n",
            "t = 24, avg_loss = 0.0428\n",
            "Checking accuracy on test set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 88 / 100\n",
            "t = 2, avg_loss = 0.0529\n",
            "t = 4, avg_loss = 0.0868\n",
            "t = 6, avg_loss = 0.0323\n",
            "t = 8, avg_loss = 0.0662\n",
            "t = 10, avg_loss = 0.0669\n",
            "t = 12, avg_loss = 0.0490\n",
            "t = 14, avg_loss = 0.0699\n",
            "t = 16, avg_loss = 0.0392\n",
            "t = 18, avg_loss = 0.0327\n",
            "t = 20, avg_loss = 0.0632\n",
            "t = 22, avg_loss = 0.0414\n",
            "t = 24, avg_loss = 0.0538\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 89 / 100\n",
            "t = 2, avg_loss = 0.0767\n",
            "t = 4, avg_loss = 0.1028\n",
            "t = 6, avg_loss = 0.0504\n",
            "t = 8, avg_loss = 0.0418\n",
            "t = 10, avg_loss = 0.0924\n",
            "t = 12, avg_loss = 0.0385\n",
            "t = 14, avg_loss = 0.0636\n",
            "t = 16, avg_loss = 0.0285\n",
            "t = 18, avg_loss = 0.0419\n",
            "t = 20, avg_loss = 0.0263\n",
            "t = 22, avg_loss = 0.0681\n",
            "t = 24, avg_loss = 0.0563\n",
            "Checking accuracy on test set\n",
            "Got 360 / 400 correct (90.00)\n",
            "acc = 0.900000\n",
            "Starting epoch 90 / 100\n",
            "t = 2, avg_loss = 0.0462\n",
            "t = 4, avg_loss = 0.0554\n",
            "t = 6, avg_loss = 0.0526\n",
            "t = 8, avg_loss = 0.0606\n",
            "t = 10, avg_loss = 0.0452\n",
            "t = 12, avg_loss = 0.0842\n",
            "t = 14, avg_loss = 0.0708\n",
            "t = 16, avg_loss = 0.0454\n",
            "t = 18, avg_loss = 0.0332\n",
            "t = 20, avg_loss = 0.0947\n",
            "t = 22, avg_loss = 0.1097\n",
            "t = 24, avg_loss = 0.0462\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 91 / 100\n",
            "t = 2, avg_loss = 0.0651\n",
            "t = 4, avg_loss = 0.0661\n",
            "t = 6, avg_loss = 0.0611\n",
            "t = 8, avg_loss = 0.0258\n",
            "t = 10, avg_loss = 0.0667\n",
            "t = 12, avg_loss = 0.0469\n",
            "t = 14, avg_loss = 0.0457\n",
            "t = 16, avg_loss = 0.0519\n",
            "t = 18, avg_loss = 0.0466\n",
            "t = 20, avg_loss = 0.0744\n",
            "t = 22, avg_loss = 0.0368\n",
            "t = 24, avg_loss = 0.0445\n",
            "Checking accuracy on test set\n",
            "Got 359 / 400 correct (89.75)\n",
            "acc = 0.897500\n",
            "Starting epoch 92 / 100\n",
            "t = 2, avg_loss = 0.0706\n",
            "t = 4, avg_loss = 0.0338\n",
            "t = 6, avg_loss = 0.1358\n",
            "t = 8, avg_loss = 0.0682\n",
            "t = 10, avg_loss = 0.0500\n",
            "t = 12, avg_loss = 0.0992\n",
            "t = 14, avg_loss = 0.0443\n",
            "t = 16, avg_loss = 0.0367\n",
            "t = 18, avg_loss = 0.0413\n",
            "t = 20, avg_loss = 0.0782\n",
            "t = 22, avg_loss = 0.0360\n",
            "t = 24, avg_loss = 0.0560\n",
            "Checking accuracy on test set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 93 / 100\n",
            "t = 2, avg_loss = 0.0576\n",
            "t = 4, avg_loss = 0.0389\n",
            "t = 6, avg_loss = 0.0729\n",
            "t = 8, avg_loss = 0.0332\n",
            "t = 10, avg_loss = 0.0582\n",
            "t = 12, avg_loss = 0.0484\n",
            "t = 14, avg_loss = 0.0412\n",
            "t = 16, avg_loss = 0.0724\n",
            "t = 18, avg_loss = 0.0813\n",
            "t = 20, avg_loss = 0.0577\n",
            "t = 22, avg_loss = 0.0502\n",
            "t = 24, avg_loss = 0.0443\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 94 / 100\n",
            "t = 2, avg_loss = 0.0824\n",
            "t = 4, avg_loss = 0.0414\n",
            "t = 6, avg_loss = 0.0547\n",
            "t = 8, avg_loss = 0.0708\n",
            "t = 10, avg_loss = 0.0300\n",
            "t = 12, avg_loss = 0.0437\n",
            "t = 14, avg_loss = 0.0358\n",
            "t = 16, avg_loss = 0.0719\n",
            "t = 18, avg_loss = 0.0291\n",
            "t = 20, avg_loss = 0.0642\n",
            "t = 22, avg_loss = 0.0493\n",
            "t = 24, avg_loss = 0.0510\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 95 / 100\n",
            "t = 2, avg_loss = 0.0515\n",
            "t = 4, avg_loss = 0.0730\n",
            "t = 6, avg_loss = 0.0554\n",
            "t = 8, avg_loss = 0.0502\n",
            "t = 10, avg_loss = 0.0727\n",
            "t = 12, avg_loss = 0.0778\n",
            "t = 14, avg_loss = 0.0653\n",
            "t = 16, avg_loss = 0.0573\n",
            "t = 18, avg_loss = 0.0310\n",
            "t = 20, avg_loss = 0.0407\n",
            "t = 22, avg_loss = 0.0535\n",
            "t = 24, avg_loss = 0.0495\n",
            "Checking accuracy on test set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 96 / 100\n",
            "t = 2, avg_loss = 0.0485\n",
            "t = 4, avg_loss = 0.0384\n",
            "t = 6, avg_loss = 0.0749\n",
            "t = 8, avg_loss = 0.0443\n",
            "t = 10, avg_loss = 0.0444\n",
            "t = 12, avg_loss = 0.0312\n",
            "t = 14, avg_loss = 0.0551\n",
            "t = 16, avg_loss = 0.0552\n",
            "t = 18, avg_loss = 0.0377\n",
            "t = 20, avg_loss = 0.0376\n",
            "t = 22, avg_loss = 0.0298\n",
            "t = 24, avg_loss = 0.0674\n",
            "Checking accuracy on test set\n",
            "Got 358 / 400 correct (89.50)\n",
            "acc = 0.895000\n",
            "Starting epoch 97 / 100\n",
            "t = 2, avg_loss = 0.1005\n",
            "t = 4, avg_loss = 0.0803\n",
            "t = 6, avg_loss = 0.0450\n",
            "t = 8, avg_loss = 0.0505\n",
            "t = 10, avg_loss = 0.0770\n",
            "t = 12, avg_loss = 0.0402\n",
            "t = 14, avg_loss = 0.1095\n",
            "t = 16, avg_loss = 0.0332\n",
            "t = 18, avg_loss = 0.0509\n",
            "t = 20, avg_loss = 0.0833\n",
            "t = 22, avg_loss = 0.0615\n",
            "t = 24, avg_loss = 0.0249\n",
            "Checking accuracy on test set\n",
            "Got 358 / 400 correct (89.50)\n",
            "acc = 0.895000\n",
            "Starting epoch 98 / 100\n",
            "t = 2, avg_loss = 0.0435\n",
            "t = 4, avg_loss = 0.0720\n",
            "t = 6, avg_loss = 0.1021\n",
            "t = 8, avg_loss = 0.1341\n",
            "t = 10, avg_loss = 0.0420\n",
            "t = 12, avg_loss = 0.0643\n",
            "t = 14, avg_loss = 0.0512\n",
            "t = 16, avg_loss = 0.0482\n",
            "t = 18, avg_loss = 0.0319\n",
            "t = 20, avg_loss = 0.0537\n",
            "t = 22, avg_loss = 0.0407\n",
            "t = 24, avg_loss = 0.0394\n",
            "Checking accuracy on test set\n",
            "Got 359 / 400 correct (89.75)\n",
            "acc = 0.897500\n",
            "Starting epoch 99 / 100\n",
            "t = 2, avg_loss = 0.0987\n",
            "t = 4, avg_loss = 0.0552\n",
            "t = 6, avg_loss = 0.0287\n",
            "t = 8, avg_loss = 0.0453\n",
            "t = 10, avg_loss = 0.0530\n",
            "t = 12, avg_loss = 0.0481\n",
            "t = 14, avg_loss = 0.0407\n",
            "t = 16, avg_loss = 0.0259\n",
            "t = 18, avg_loss = 0.0305\n",
            "t = 20, avg_loss = 0.0406\n",
            "t = 22, avg_loss = 0.0459\n",
            "t = 24, avg_loss = 0.0182\n",
            "Checking accuracy on test set\n",
            "Got 359 / 400 correct (89.75)\n",
            "acc = 0.897500\n",
            "Starting epoch 100 / 100\n",
            "t = 2, avg_loss = 0.0404\n",
            "t = 4, avg_loss = 0.0208\n",
            "t = 6, avg_loss = 0.0353\n",
            "t = 8, avg_loss = 0.0412\n",
            "t = 10, avg_loss = 0.0640\n",
            "t = 12, avg_loss = 0.0291\n",
            "t = 14, avg_loss = 0.0226\n",
            "t = 16, avg_loss = 0.0297\n",
            "t = 18, avg_loss = 0.0808\n",
            "t = 20, avg_loss = 0.0433\n",
            "t = 22, avg_loss = 0.0312\n",
            "t = 24, avg_loss = 0.0594\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Checking accuracy on test set\n",
            "Got 351 / 400 correct (87.75)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8775"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvoCj5uscUsz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_accurancy(acc_list):\n",
        "  plt.plot([i+1 for i in range((len(acc_list)))],acc_list)\n",
        "  print(\"Accurancy:\")\n",
        "  plt.show()\n",
        "\n",
        "def plot_loss_function(avg_loss_list):\n",
        "  plt.plot([print_every*batch_size*(i+1) for i in range((len(avg_loss_list)))],avg_loss_list)\n",
        "  print(\"Loss:\")\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkH5XGsgqSg5",
        "colab_type": "code",
        "outputId": "be85afdd-f023-4478-b100-34b3fb5e65b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plot_accurancy(acc_list)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accurancy:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMY5hjrL-sEl",
        "colab_type": "code",
        "outputId": "460ec708-b5a6-47bd-93ef-8fcefc471742",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plot_loss_function(avg_loss_list)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzuX5gLEeJfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def retry_from_backup():\n",
        "  model_gpu = model_base.type(gpu_dtype)\n",
        "  print(model_gpu)\n",
        "  loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) \n",
        "\n",
        "\n",
        "\n",
        "  checkpoint = torch.load(model_backup_path)\n",
        "  model_gpu.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  epoch = checkpoint['epoch']\n",
        "  loss = checkpoint['loss']\n",
        "  acc_list = checkpoint['acc_list']\n",
        "  #avg_loss_list = checkpoint['avg_loss_list']\n",
        "  print(\"starting from epoch: \" + str(epoch))\n",
        "  print(\"starting from loss: \" + str(loss))\n",
        "  print(acc_list)\n",
        "  \n",
        "  \n",
        "  train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=33, starting_from_epoch=epoch)\n",
        "  check_accuracy(model_gpu, valid_loader)\n",
        "\n",
        "  plot_accurancy(acc_list)\n",
        "  plot_loss_function(avg_loss_list)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--rQZKqOalaJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#retry_from_backup()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2hn7hqGI56T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#test_submit_file = os.path.join(DATA_FOLDER, 'submission.csv') \n",
        "\n",
        "#model_gpu.eval()\n",
        "#preds = []\n",
        "#for batch_i, (data, target) in enumerate(test_loader):\n",
        "#    data, target = data.cuda(), target.cuda()\n",
        "#    output = model_gpu(data)\n",
        "#\n",
        "#    pr = output[:,1].detach().cpu().numpy()\n",
        "#    for i in pr:\n",
        "#        preds.append(i)\n",
        "        \n",
        "#test_preds = pd.DataFrame({'imgs': test_dataset.image_files_list, 'preds': preds})\n",
        "#test_preds = pd.DataFrame({'imgs': test_benign_file_list.extend(test_malignant_file_list), 'preds': preds})\n",
        "\n",
        "#data_to_submit = pd.read_csv(test_submit_file)\n",
        "#data_to_submit = pd.merge(data_to_submit, test_preds, left_on='id', right_on='imgs')\n",
        "#data_to_submit = data_to_submit[['id', 'preds']]\n",
        "#data_to_submit.columns = ['id', 'label']\n",
        "#data_to_submit.head()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}