{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN_ascending_layers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO1mHCWCLFmR4THPADqjTzv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamilo116/KNN/blob/master/KNN_ascending_layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7ReM7FU-xs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import sys\n",
        "from random import shuffle\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "import timeit\n",
        "\n",
        "np.random.seed(4) \n",
        "torch.manual_seed(4) \n",
        "torch.cuda.manual_seed(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMOHez_kHZD6",
        "colab_type": "code",
        "outputId": "c464c6df-33b0-4739-8379-a41517bc18c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYIMZ8QyYewD",
        "colab_type": "code",
        "outputId": "218b9e22-70db-4273-b493-c3129143325b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "! git clone https://github.com/wang-chen/kervolution.git \n",
        "\n",
        "sys.path.append(\"kervolution/\")\n",
        "from kervolution import Kerv2d\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'kervolution'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 53 (delta 2), reused 0 (delta 0), pack-reused 47\u001b[K\n",
            "Unpacking objects: 100% (53/53), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b8P1NdXfVdX",
        "colab_type": "code",
        "outputId": "242ec4b5-0391-4eb4-eb24-b4119a946b55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "MALIGNANT_DATASET = '/content/drive/My Drive/Colab_data/malignant/malignant/'\n",
        "BENIGN_DATASET = '/content/drive/My Drive/Colab_data/benign/benign/'\n",
        "DATA_FOLDER = '/content/drive/My Drive/Colab_data/'\n",
        "LIMIT_IMAGES_NUM = 700\n",
        "\n",
        "benign_file_list = sorted(os.listdir(BENIGN_DATASET))[:LIMIT_IMAGES_NUM]\n",
        "malignant_file_list = sorted(os.listdir(MALIGNANT_DATASET))[:LIMIT_IMAGES_NUM]\n",
        "shuffle(benign_file_list)\n",
        "shuffle(malignant_file_list)\n",
        "\n",
        "print(f\"Number of benign {len(benign_file_list)} images\")\n",
        "print(f\"Number of malignant {len(malignant_file_list)} images\")\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize((100, 100)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of benign 700 images\n",
            "Number of malignant 700 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGDQfal74BLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "benign_dict = {filename: 0 for filename in benign_file_list}\n",
        "malignant_dict = {filename: 1 for filename in malignant_file_list}\n",
        "img_class_dict = {**benign_dict , **malignant_dict}\n",
        "labeled_data = pd.Series(img_class_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvAAOqmVfVll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IsicDataset(Dataset):\n",
        "    def __init__(self, data_folder, labeled_data, \n",
        "                 transform=transforms.Compose([transforms.ToTensor()])):\n",
        "        self.labeled_data = labeled_data\n",
        "        self.transform = transform\n",
        "        self.data_folder = data_folder\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labeled_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        label = self.labeled_data[index]\n",
        "        if label == 0:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"benign\", \"benign\", index ))\n",
        "        else:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"malignant\", \"malignant\", index ))\n",
        "        image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "    @property\n",
        "    def labels(self):\n",
        "      return self.labeled_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSuYqjLAYrWA",
        "colab_type": "code",
        "outputId": "e3d3d50d-429f-4827-a731-31b893b68c0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        }
      },
      "source": [
        " \n",
        "dataset = IsicDataset(DATA_FOLDER, labeled_data, transform=data_transforms)\n",
        "print(dataset.labels)\n",
        "\n",
        "X_train, X_test = train_test_split(dataset.labels, test_size=0.2)\n",
        "print(\"number of training data: \",len(X_train))\n",
        "print(\"number of testing  data: \",len(X_test))\n",
        "\n",
        "train_sampler = SubsetRandomSampler(list(X_train.index))\n",
        "valid_sampler = SubsetRandomSampler(list(X_test.index))\n",
        "batch_size = 64\n",
        "num_workers = 0\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ISIC_0000746.jpeg    0\n",
            "ISIC_0000356.jpeg    0\n",
            "ISIC_0001022.jpeg    0\n",
            "ISIC_0000262.jpeg    0\n",
            "ISIC_0000977.jpeg    0\n",
            "                    ..\n",
            "ISIC_0011349.jpeg    1\n",
            "ISIC_0011289.jpeg    1\n",
            "ISIC_0011594.jpeg    1\n",
            "ISIC_0011052.jpeg    1\n",
            "ISIC_0010029.jpeg    1\n",
            "Length: 1400, dtype: int64\n",
            "number of training data:  1120\n",
            "number of testing  data:  280\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e8nFBR6Yug5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "def train(model, train_loader ,loss_fn, optimizer, num_epochs = 1):\n",
        "    total_loss =0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
        "        model.train()\n",
        "\n",
        "        for t, (x, y) in enumerate(train_loader):\n",
        "            x_var = Variable(x.type(gpu_dtype))\n",
        "            y_var = Variable(y.type(gpu_dtype).long())\n",
        "            scores = model(x_var)\n",
        "            loss = loss_fn(scores, y_var)\n",
        "            total_loss += loss.data\n",
        "            \n",
        "            if (t + 1) % print_every == 0:\n",
        "                avg_loss = total_loss/print_every\n",
        "                print('t = %d, avg_loss = %.4f' % (t + 1, avg_loss) )\n",
        "                avg_loss_list.append(avg_loss)\n",
        "                total_loss = 0\n",
        "                \n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        acc = check_accuracy(fixed_model_gpu, valid_loader)\n",
        "        print('acc = %f' %(acc))\n",
        "            \n",
        "def check_accuracy(model, loader):\n",
        "    print('Checking accuracy on test set')   \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval() \n",
        "    for x, y in loader:\n",
        "        x_var = Variable(x.type(gpu_dtype))\n",
        "\n",
        "        scores = model(x_var)\n",
        "        _, preds = scores.data.cpu().max(1)\n",
        "        num_correct += (preds == y).sum()\n",
        "        num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    acc_list.append(acc)\n",
        "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "    return acc\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggvpMu36Yw2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.size()\n",
        "        return x.view(N, -1)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgmexhBRZAK6",
        "colab_type": "code",
        "outputId": "4c885ab6-8923-4897-b2b4-3f0b862cded0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "\n",
        "print_every = 1\n",
        "gpu_dtype = torch.cuda.FloatTensor\n",
        "\n",
        "out_1 = 16\n",
        "out_2 = 32\n",
        "out_3 = 64\n",
        "out_4 = 128\n",
        "\n",
        "\n",
        "\n",
        "k_size_1 = 3\n",
        "padding_1 = 1\n",
        "in_channels = 3\n",
        "\n",
        "num_epochs = 100\n",
        "\n",
        "'''\n",
        "Kerv2d\n",
        "kervolution with following options:\n",
        "kernel_type: [linear, polynomial, gaussian, etc.]\n",
        "default is convolution:\n",
        "          kernel_type --> linear,\n",
        "balance, power, gamma is valid only when the kernel_type is specified\n",
        "if learnable_kernel = True,  they just be the initial value of learable parameters\n",
        "if learnable_kernel = False, they are the value of kernel_type's parameter\n",
        "the parameter [power] cannot be learned due to integer limitation\n",
        "dilation (int or tuple, optional): Spacing between kernel\n",
        "elements. Default: 1\n",
        "groups (int, optional): Number of blocked connections from input\n",
        "channels to output channels. Default: 1\n",
        "bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n",
        "kernel_type (str), Default: 'linear'\n",
        "learnable_kernel (bool): Learnable kernel parameters.  Default: False \n",
        "balance: 0, 1\n",
        "power: 3, 4, 5\n",
        "gamma:\n",
        "'''\n",
        "\n",
        "\n",
        "fixed_model_base = nn.Sequential( \n",
        "                nn.Kerv2d(in_channels , out_1, padding=padding_1, dilation=1, groups=1, bias=True, \n",
        "                          kernel_type='linear', kernel_size=k_size_1,# learnable_kernel=True,\n",
        "                          #kernel_regularizer=True, stride=1, balance=1, power=3, gamma=1\n",
        "                          ), \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_1),\n",
        "                nn.Conv2d(out_1 , out_2, padding= padding_1, kernel_size=k_size_1, stride=1), \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_2),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_2 , out_3, padding= padding_1, kernel_size=k_size_1, stride=1),  \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_3),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_3 , out_4, padding= padding_1, kernel_size=k_size_1, stride=1),  \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_4),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Dropout(0.5),\n",
        "                Flatten(),\n",
        "                nn.Linear(18432,64),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Linear(64,2)\n",
        "            )\n",
        "fixed_model_gpu = fixed_model_base.type(gpu_dtype)\n",
        "print(fixed_model_gpu)\n",
        "loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(fixed_model_gpu.parameters(), lr = 0.00012, weight_decay=0) \n",
        "\n",
        "train(fixed_model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs)\n",
        "check_accuracy(fixed_model_gpu, valid_loader)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Kerv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (4): ReLU(inplace=True)\n",
            "  (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (7): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (8): ReLU(inplace=True)\n",
            "  (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (11): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (12): ReLU(inplace=True)\n",
            "  (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (15): Dropout(p=0.5, inplace=False)\n",
            "  (16): Flatten()\n",
            "  (17): Linear(in_features=18432, out_features=64, bias=True)\n",
            "  (18): ReLU(inplace=True)\n",
            "  (19): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n",
            "Starting epoch 1 / 100\n",
            "t = 1, avg_loss = 0.6776\n",
            "t = 2, avg_loss = 0.6109\n",
            "t = 3, avg_loss = 0.5662\n",
            "t = 4, avg_loss = 0.5408\n",
            "t = 5, avg_loss = 0.5390\n",
            "t = 6, avg_loss = 0.6157\n",
            "t = 7, avg_loss = 0.5122\n",
            "t = 8, avg_loss = 0.5800\n",
            "t = 9, avg_loss = 0.4509\n",
            "t = 10, avg_loss = 0.4329\n",
            "t = 11, avg_loss = 0.5913\n",
            "t = 12, avg_loss = 0.3662\n",
            "t = 13, avg_loss = 0.3493\n",
            "t = 14, avg_loss = 0.3722\n",
            "t = 15, avg_loss = 0.4139\n",
            "t = 16, avg_loss = 0.3294\n",
            "t = 17, avg_loss = 0.4986\n",
            "t = 18, avg_loss = 0.3667\n",
            "Checking accuracy on test set\n",
            "Got 136 / 280 correct (48.57)\n",
            "acc = 0.485714\n",
            "Starting epoch 2 / 100\n",
            "t = 1, avg_loss = 0.4011\n",
            "t = 2, avg_loss = 0.3922\n",
            "t = 3, avg_loss = 0.3935\n",
            "t = 4, avg_loss = 0.3888\n",
            "t = 5, avg_loss = 0.3901\n",
            "t = 6, avg_loss = 0.2598\n",
            "t = 7, avg_loss = 0.4231\n",
            "t = 8, avg_loss = 0.4159\n",
            "t = 9, avg_loss = 0.4223\n",
            "t = 10, avg_loss = 0.2999\n",
            "t = 11, avg_loss = 0.4778\n",
            "t = 12, avg_loss = 0.2484\n",
            "t = 13, avg_loss = 0.4442\n",
            "t = 14, avg_loss = 0.2736\n",
            "t = 15, avg_loss = 0.4587\n",
            "t = 16, avg_loss = 0.2776\n",
            "t = 17, avg_loss = 0.3167\n",
            "t = 18, avg_loss = 0.2802\n",
            "Checking accuracy on test set\n",
            "Got 141 / 280 correct (50.36)\n",
            "acc = 0.503571\n",
            "Starting epoch 3 / 100\n",
            "t = 1, avg_loss = 0.3131\n",
            "t = 2, avg_loss = 0.3004\n",
            "t = 3, avg_loss = 0.3574\n",
            "t = 4, avg_loss = 0.4499\n",
            "t = 5, avg_loss = 0.4770\n",
            "t = 6, avg_loss = 0.3875\n",
            "t = 7, avg_loss = 0.3168\n",
            "t = 8, avg_loss = 0.2700\n",
            "t = 9, avg_loss = 0.4045\n",
            "t = 10, avg_loss = 0.3855\n",
            "t = 11, avg_loss = 0.3801\n",
            "t = 12, avg_loss = 0.2286\n",
            "t = 13, avg_loss = 0.3176\n",
            "t = 14, avg_loss = 0.2186\n",
            "t = 15, avg_loss = 0.5160\n",
            "t = 16, avg_loss = 0.2730\n",
            "t = 17, avg_loss = 0.3658\n",
            "t = 18, avg_loss = 0.3298\n",
            "Checking accuracy on test set\n",
            "Got 215 / 280 correct (76.79)\n",
            "acc = 0.767857\n",
            "Starting epoch 4 / 100\n",
            "t = 1, avg_loss = 0.2522\n",
            "t = 2, avg_loss = 0.3674\n",
            "t = 3, avg_loss = 0.2758\n",
            "t = 4, avg_loss = 0.3714\n",
            "t = 5, avg_loss = 0.2901\n",
            "t = 6, avg_loss = 0.2847\n",
            "t = 7, avg_loss = 0.3480\n",
            "t = 8, avg_loss = 0.3692\n",
            "t = 9, avg_loss = 0.2965\n",
            "t = 10, avg_loss = 0.2580\n",
            "t = 11, avg_loss = 0.2454\n",
            "t = 12, avg_loss = 0.3384\n",
            "t = 13, avg_loss = 0.3393\n",
            "t = 14, avg_loss = 0.3206\n",
            "t = 15, avg_loss = 0.2777\n",
            "t = 16, avg_loss = 0.3252\n",
            "t = 17, avg_loss = 0.3341\n",
            "t = 18, avg_loss = 0.3703\n",
            "Checking accuracy on test set\n",
            "Got 245 / 280 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 5 / 100\n",
            "t = 1, avg_loss = 0.3500\n",
            "t = 2, avg_loss = 0.2777\n",
            "t = 3, avg_loss = 0.2253\n",
            "t = 4, avg_loss = 0.3241\n",
            "t = 5, avg_loss = 0.2420\n",
            "t = 6, avg_loss = 0.2979\n",
            "t = 7, avg_loss = 0.2919\n",
            "t = 8, avg_loss = 0.3079\n",
            "t = 9, avg_loss = 0.1996\n",
            "t = 10, avg_loss = 0.3656\n",
            "t = 11, avg_loss = 0.3045\n",
            "t = 12, avg_loss = 0.2449\n",
            "t = 13, avg_loss = 0.1911\n",
            "t = 14, avg_loss = 0.2631\n",
            "t = 15, avg_loss = 0.3268\n",
            "t = 16, avg_loss = 0.1654\n",
            "t = 17, avg_loss = 0.2589\n",
            "t = 18, avg_loss = 0.2448\n",
            "Checking accuracy on test set\n",
            "Got 249 / 280 correct (88.93)\n",
            "acc = 0.889286\n",
            "Starting epoch 6 / 100\n",
            "t = 1, avg_loss = 0.2912\n",
            "t = 2, avg_loss = 0.2894\n",
            "t = 3, avg_loss = 0.1508\n",
            "t = 4, avg_loss = 0.2655\n",
            "t = 5, avg_loss = 0.1811\n",
            "t = 6, avg_loss = 0.2628\n",
            "t = 7, avg_loss = 0.2968\n",
            "t = 8, avg_loss = 0.2121\n",
            "t = 9, avg_loss = 0.2305\n",
            "t = 10, avg_loss = 0.3061\n",
            "t = 11, avg_loss = 0.1652\n",
            "t = 12, avg_loss = 0.1709\n",
            "t = 13, avg_loss = 0.2489\n",
            "t = 14, avg_loss = 0.2526\n",
            "t = 15, avg_loss = 0.2870\n",
            "t = 16, avg_loss = 0.3344\n",
            "t = 17, avg_loss = 0.2662\n",
            "t = 18, avg_loss = 0.3239\n",
            "Checking accuracy on test set\n",
            "Got 249 / 280 correct (88.93)\n",
            "acc = 0.889286\n",
            "Starting epoch 7 / 100\n",
            "t = 1, avg_loss = 0.2461\n",
            "t = 2, avg_loss = 0.3345\n",
            "t = 3, avg_loss = 0.2022\n",
            "t = 4, avg_loss = 0.2757\n",
            "t = 5, avg_loss = 0.2271\n",
            "t = 6, avg_loss = 0.1512\n",
            "t = 7, avg_loss = 0.1724\n",
            "t = 8, avg_loss = 0.2264\n",
            "t = 9, avg_loss = 0.2523\n",
            "t = 10, avg_loss = 0.3100\n",
            "t = 11, avg_loss = 0.3052\n",
            "t = 12, avg_loss = 0.2368\n",
            "t = 13, avg_loss = 0.2545\n",
            "t = 14, avg_loss = 0.2293\n",
            "t = 15, avg_loss = 0.2272\n",
            "t = 16, avg_loss = 0.2030\n",
            "t = 17, avg_loss = 0.1609\n",
            "t = 18, avg_loss = 0.4233\n",
            "Checking accuracy on test set\n",
            "Got 245 / 280 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 8 / 100\n",
            "t = 1, avg_loss = 0.1955\n",
            "t = 2, avg_loss = 0.2175\n",
            "t = 3, avg_loss = 0.2033\n",
            "t = 4, avg_loss = 0.1736\n",
            "t = 5, avg_loss = 0.2467\n",
            "t = 6, avg_loss = 0.2551\n",
            "t = 7, avg_loss = 0.2555\n",
            "t = 8, avg_loss = 0.2674\n",
            "t = 9, avg_loss = 0.2248\n",
            "t = 10, avg_loss = 0.1471\n",
            "t = 11, avg_loss = 0.1490\n",
            "t = 12, avg_loss = 0.2178\n",
            "t = 13, avg_loss = 0.1854\n",
            "t = 14, avg_loss = 0.2896\n",
            "t = 15, avg_loss = 0.1627\n",
            "t = 16, avg_loss = 0.2645\n",
            "t = 17, avg_loss = 0.2735\n",
            "t = 18, avg_loss = 0.2460\n",
            "Checking accuracy on test set\n",
            "Got 251 / 280 correct (89.64)\n",
            "acc = 0.896429\n",
            "Starting epoch 9 / 100\n",
            "t = 1, avg_loss = 0.1847\n",
            "t = 2, avg_loss = 0.2262\n",
            "t = 3, avg_loss = 0.1563\n",
            "t = 4, avg_loss = 0.2769\n",
            "t = 5, avg_loss = 0.1979\n",
            "t = 6, avg_loss = 0.1666\n",
            "t = 7, avg_loss = 0.1700\n",
            "t = 8, avg_loss = 0.1902\n",
            "t = 9, avg_loss = 0.1788\n",
            "t = 10, avg_loss = 0.1693\n",
            "t = 11, avg_loss = 0.1454\n",
            "t = 12, avg_loss = 0.2120\n",
            "t = 13, avg_loss = 0.1617\n",
            "t = 14, avg_loss = 0.2262\n",
            "t = 15, avg_loss = 0.2323\n",
            "t = 16, avg_loss = 0.2312\n",
            "t = 17, avg_loss = 0.2537\n",
            "t = 18, avg_loss = 0.3753\n",
            "Checking accuracy on test set\n",
            "Got 245 / 280 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 10 / 100\n",
            "t = 1, avg_loss = 0.1400\n",
            "t = 2, avg_loss = 0.2072\n",
            "t = 3, avg_loss = 0.2126\n",
            "t = 4, avg_loss = 0.1611\n",
            "t = 5, avg_loss = 0.2153\n",
            "t = 6, avg_loss = 0.1538\n",
            "t = 7, avg_loss = 0.2364\n",
            "t = 8, avg_loss = 0.1408\n",
            "t = 9, avg_loss = 0.2973\n",
            "t = 10, avg_loss = 0.2954\n",
            "t = 11, avg_loss = 0.1812\n",
            "t = 12, avg_loss = 0.3421\n",
            "t = 13, avg_loss = 0.2102\n",
            "t = 14, avg_loss = 0.2701\n",
            "t = 15, avg_loss = 0.2550\n",
            "t = 16, avg_loss = 0.2628\n",
            "t = 17, avg_loss = 0.1696\n",
            "t = 18, avg_loss = 0.1228\n",
            "Checking accuracy on test set\n",
            "Got 249 / 280 correct (88.93)\n",
            "acc = 0.889286\n",
            "Starting epoch 11 / 100\n",
            "t = 1, avg_loss = 0.1956\n",
            "t = 2, avg_loss = 0.1493\n",
            "t = 3, avg_loss = 0.1732\n",
            "t = 4, avg_loss = 0.2185\n",
            "t = 5, avg_loss = 0.0893\n",
            "t = 6, avg_loss = 0.1902\n",
            "t = 7, avg_loss = 0.1986\n",
            "t = 8, avg_loss = 0.2389\n",
            "t = 9, avg_loss = 0.1998\n",
            "t = 10, avg_loss = 0.1641\n",
            "t = 11, avg_loss = 0.2053\n",
            "t = 12, avg_loss = 0.2830\n",
            "t = 13, avg_loss = 0.1575\n",
            "t = 14, avg_loss = 0.1808\n",
            "t = 15, avg_loss = 0.1963\n",
            "t = 16, avg_loss = 0.1971\n",
            "t = 17, avg_loss = 0.2022\n",
            "t = 18, avg_loss = 0.1665\n",
            "Checking accuracy on test set\n",
            "Got 249 / 280 correct (88.93)\n",
            "acc = 0.889286\n",
            "Starting epoch 12 / 100\n",
            "t = 1, avg_loss = 0.1456\n",
            "t = 2, avg_loss = 0.1089\n",
            "t = 3, avg_loss = 0.1100\n",
            "t = 4, avg_loss = 0.1236\n",
            "t = 5, avg_loss = 0.1895\n",
            "t = 6, avg_loss = 0.1078\n",
            "t = 7, avg_loss = 0.1986\n",
            "t = 8, avg_loss = 0.2638\n",
            "t = 9, avg_loss = 0.1653\n",
            "t = 10, avg_loss = 0.2278\n",
            "t = 11, avg_loss = 0.2100\n",
            "t = 12, avg_loss = 0.1036\n",
            "t = 13, avg_loss = 0.2399\n",
            "t = 14, avg_loss = 0.1783\n",
            "t = 15, avg_loss = 0.2035\n",
            "t = 16, avg_loss = 0.1866\n",
            "t = 17, avg_loss = 0.2187\n",
            "t = 18, avg_loss = 0.0974\n",
            "Checking accuracy on test set\n",
            "Got 251 / 280 correct (89.64)\n",
            "acc = 0.896429\n",
            "Starting epoch 13 / 100\n",
            "t = 1, avg_loss = 0.2177\n",
            "t = 2, avg_loss = 0.1856\n",
            "t = 3, avg_loss = 0.1790\n",
            "t = 4, avg_loss = 0.1447\n",
            "t = 5, avg_loss = 0.1919\n",
            "t = 6, avg_loss = 0.1737\n",
            "t = 7, avg_loss = 0.1512\n",
            "t = 8, avg_loss = 0.1179\n",
            "t = 9, avg_loss = 0.0685\n",
            "t = 10, avg_loss = 0.1911\n",
            "t = 11, avg_loss = 0.1302\n",
            "t = 12, avg_loss = 0.0990\n",
            "t = 13, avg_loss = 0.1209\n",
            "t = 14, avg_loss = 0.1081\n",
            "t = 15, avg_loss = 0.1965\n",
            "t = 16, avg_loss = 0.1934\n",
            "t = 17, avg_loss = 0.1320\n",
            "t = 18, avg_loss = 0.1790\n",
            "Checking accuracy on test set\n",
            "Got 246 / 280 correct (87.86)\n",
            "acc = 0.878571\n",
            "Starting epoch 14 / 100\n",
            "t = 1, avg_loss = 0.0981\n",
            "t = 2, avg_loss = 0.1444\n",
            "t = 3, avg_loss = 0.1246\n",
            "t = 4, avg_loss = 0.2078\n",
            "t = 5, avg_loss = 0.1180\n",
            "t = 6, avg_loss = 0.1535\n",
            "t = 7, avg_loss = 0.1648\n",
            "t = 8, avg_loss = 0.0674\n",
            "t = 9, avg_loss = 0.1405\n",
            "t = 10, avg_loss = 0.1220\n",
            "t = 11, avg_loss = 0.0913\n",
            "t = 12, avg_loss = 0.1824\n",
            "t = 13, avg_loss = 0.1790\n",
            "t = 14, avg_loss = 0.2285\n",
            "t = 15, avg_loss = 0.1020\n",
            "t = 16, avg_loss = 0.1409\n",
            "t = 17, avg_loss = 0.2129\n",
            "t = 18, avg_loss = 0.1731\n",
            "Checking accuracy on test set\n",
            "Got 250 / 280 correct (89.29)\n",
            "acc = 0.892857\n",
            "Starting epoch 15 / 100\n",
            "t = 1, avg_loss = 0.1354\n",
            "t = 2, avg_loss = 0.1289\n",
            "t = 3, avg_loss = 0.1086\n",
            "t = 4, avg_loss = 0.1684\n",
            "t = 5, avg_loss = 0.2173\n",
            "t = 6, avg_loss = 0.1279\n",
            "t = 7, avg_loss = 0.1018\n",
            "t = 8, avg_loss = 0.1387\n",
            "t = 9, avg_loss = 0.1199\n",
            "t = 10, avg_loss = 0.1802\n",
            "t = 11, avg_loss = 0.0715\n",
            "t = 12, avg_loss = 0.1259\n",
            "t = 13, avg_loss = 0.1592\n",
            "t = 14, avg_loss = 0.1516\n",
            "t = 15, avg_loss = 0.1134\n",
            "t = 16, avg_loss = 0.1714\n",
            "t = 17, avg_loss = 0.0757\n",
            "t = 18, avg_loss = 0.0566\n",
            "Checking accuracy on test set\n",
            "Got 245 / 280 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 16 / 100\n",
            "t = 1, avg_loss = 0.0898\n",
            "t = 2, avg_loss = 0.0976\n",
            "t = 3, avg_loss = 0.1026\n",
            "t = 4, avg_loss = 0.1109\n",
            "t = 5, avg_loss = 0.1475\n",
            "t = 6, avg_loss = 0.0556\n",
            "t = 7, avg_loss = 0.1619\n",
            "t = 8, avg_loss = 0.1069\n",
            "t = 9, avg_loss = 0.1136\n",
            "t = 10, avg_loss = 0.0736\n",
            "t = 11, avg_loss = 0.1329\n",
            "t = 12, avg_loss = 0.1439\n",
            "t = 13, avg_loss = 0.1069\n",
            "t = 14, avg_loss = 0.2007\n",
            "t = 15, avg_loss = 0.1232\n",
            "t = 16, avg_loss = 0.1626\n",
            "t = 17, avg_loss = 0.1595\n",
            "t = 18, avg_loss = 0.1747\n",
            "Checking accuracy on test set\n",
            "Got 248 / 280 correct (88.57)\n",
            "acc = 0.885714\n",
            "Starting epoch 17 / 100\n",
            "t = 1, avg_loss = 0.0731\n",
            "t = 2, avg_loss = 0.1632\n",
            "t = 3, avg_loss = 0.1247\n",
            "t = 4, avg_loss = 0.1272\n",
            "t = 5, avg_loss = 0.1776\n",
            "t = 6, avg_loss = 0.1034\n",
            "t = 7, avg_loss = 0.0678\n",
            "t = 8, avg_loss = 0.1069\n",
            "t = 9, avg_loss = 0.1299\n",
            "t = 10, avg_loss = 0.1475\n",
            "t = 11, avg_loss = 0.1024\n",
            "t = 12, avg_loss = 0.1156\n",
            "t = 13, avg_loss = 0.1108\n",
            "t = 14, avg_loss = 0.1468\n",
            "t = 15, avg_loss = 0.0923\n",
            "t = 16, avg_loss = 0.0938\n",
            "t = 17, avg_loss = 0.1803\n",
            "t = 18, avg_loss = 0.0759\n",
            "Checking accuracy on test set\n",
            "Got 246 / 280 correct (87.86)\n",
            "acc = 0.878571\n",
            "Starting epoch 18 / 100\n",
            "t = 1, avg_loss = 0.1214\n",
            "t = 2, avg_loss = 0.0443\n",
            "t = 3, avg_loss = 0.1738\n",
            "t = 4, avg_loss = 0.1405\n",
            "t = 5, avg_loss = 0.1270\n",
            "t = 6, avg_loss = 0.1618\n",
            "t = 7, avg_loss = 0.0995\n",
            "t = 8, avg_loss = 0.0368\n",
            "t = 9, avg_loss = 0.0504\n",
            "t = 10, avg_loss = 0.0814\n",
            "t = 11, avg_loss = 0.0433\n",
            "t = 12, avg_loss = 0.0870\n",
            "t = 13, avg_loss = 0.1398\n",
            "t = 14, avg_loss = 0.0857\n",
            "t = 15, avg_loss = 0.0862\n",
            "t = 16, avg_loss = 0.0855\n",
            "t = 17, avg_loss = 0.0615\n",
            "t = 18, avg_loss = 0.1557\n",
            "Checking accuracy on test set\n",
            "Got 243 / 280 correct (86.79)\n",
            "acc = 0.867857\n",
            "Starting epoch 19 / 100\n",
            "t = 1, avg_loss = 0.0523\n",
            "t = 2, avg_loss = 0.0890\n",
            "t = 3, avg_loss = 0.0577\n",
            "t = 4, avg_loss = 0.1131\n",
            "t = 5, avg_loss = 0.1515\n",
            "t = 6, avg_loss = 0.1266\n",
            "t = 7, avg_loss = 0.0920\n",
            "t = 8, avg_loss = 0.1294\n",
            "t = 9, avg_loss = 0.2140\n",
            "t = 10, avg_loss = 0.0760\n",
            "t = 11, avg_loss = 0.0790\n",
            "t = 12, avg_loss = 0.0816\n",
            "t = 13, avg_loss = 0.0568\n",
            "t = 14, avg_loss = 0.0509\n",
            "t = 15, avg_loss = 0.1363\n",
            "t = 16, avg_loss = 0.1335\n",
            "t = 17, avg_loss = 0.1429\n",
            "t = 18, avg_loss = 0.1431\n",
            "Checking accuracy on test set\n",
            "Got 242 / 280 correct (86.43)\n",
            "acc = 0.864286\n",
            "Starting epoch 20 / 100\n",
            "t = 1, avg_loss = 0.1038\n",
            "t = 2, avg_loss = 0.0521\n",
            "t = 3, avg_loss = 0.0605\n",
            "t = 4, avg_loss = 0.0568\n",
            "t = 5, avg_loss = 0.0896\n",
            "t = 6, avg_loss = 0.0775\n",
            "t = 7, avg_loss = 0.0288\n",
            "t = 8, avg_loss = 0.1467\n",
            "t = 9, avg_loss = 0.0932\n",
            "t = 10, avg_loss = 0.1006\n",
            "t = 11, avg_loss = 0.0910\n",
            "t = 12, avg_loss = 0.1302\n",
            "t = 13, avg_loss = 0.0624\n",
            "t = 14, avg_loss = 0.0640\n",
            "t = 15, avg_loss = 0.0884\n",
            "t = 16, avg_loss = 0.1959\n",
            "t = 17, avg_loss = 0.0975\n",
            "t = 18, avg_loss = 0.1723\n",
            "Checking accuracy on test set\n",
            "Got 243 / 280 correct (86.79)\n",
            "acc = 0.867857\n",
            "Starting epoch 21 / 100\n",
            "t = 1, avg_loss = 0.0902\n",
            "t = 2, avg_loss = 0.0758\n",
            "t = 3, avg_loss = 0.1834\n",
            "t = 4, avg_loss = 0.0618\n",
            "t = 5, avg_loss = 0.0830\n",
            "t = 6, avg_loss = 0.1124\n",
            "t = 7, avg_loss = 0.0593\n",
            "t = 8, avg_loss = 0.1356\n",
            "t = 9, avg_loss = 0.1145\n",
            "t = 10, avg_loss = 0.0786\n",
            "t = 11, avg_loss = 0.0546\n",
            "t = 12, avg_loss = 0.2033\n",
            "t = 13, avg_loss = 0.0776\n",
            "t = 14, avg_loss = 0.0528\n",
            "t = 15, avg_loss = 0.1019\n",
            "t = 16, avg_loss = 0.1425\n",
            "t = 17, avg_loss = 0.1151\n",
            "t = 18, avg_loss = 0.1169\n",
            "Checking accuracy on test set\n",
            "Got 248 / 280 correct (88.57)\n",
            "acc = 0.885714\n",
            "Starting epoch 22 / 100\n",
            "t = 1, avg_loss = 0.0562\n",
            "t = 2, avg_loss = 0.0772\n",
            "t = 3, avg_loss = 0.0747\n",
            "t = 4, avg_loss = 0.1080\n",
            "t = 5, avg_loss = 0.0397\n",
            "t = 6, avg_loss = 0.0797\n",
            "t = 7, avg_loss = 0.0791\n",
            "t = 8, avg_loss = 0.0805\n",
            "t = 9, avg_loss = 0.1240\n",
            "t = 10, avg_loss = 0.1398\n",
            "t = 11, avg_loss = 0.0994\n",
            "t = 12, avg_loss = 0.1092\n",
            "t = 13, avg_loss = 0.0989\n",
            "t = 14, avg_loss = 0.0923\n",
            "t = 15, avg_loss = 0.1317\n",
            "t = 16, avg_loss = 0.0850\n",
            "t = 17, avg_loss = 0.0730\n",
            "t = 18, avg_loss = 0.0806\n",
            "Checking accuracy on test set\n",
            "Got 252 / 280 correct (90.00)\n",
            "acc = 0.900000\n",
            "Starting epoch 23 / 100\n",
            "t = 1, avg_loss = 0.0711\n",
            "t = 2, avg_loss = 0.1009\n",
            "t = 3, avg_loss = 0.1096\n",
            "t = 4, avg_loss = 0.0462\n",
            "t = 5, avg_loss = 0.0586\n",
            "t = 6, avg_loss = 0.0569\n",
            "t = 7, avg_loss = 0.1794\n",
            "t = 8, avg_loss = 0.0741\n",
            "t = 9, avg_loss = 0.0913\n",
            "t = 10, avg_loss = 0.0824\n",
            "t = 11, avg_loss = 0.0938\n",
            "t = 12, avg_loss = 0.0659\n",
            "t = 13, avg_loss = 0.0459\n",
            "t = 14, avg_loss = 0.0389\n",
            "t = 15, avg_loss = 0.1563\n",
            "t = 16, avg_loss = 0.0773\n",
            "t = 17, avg_loss = 0.1380\n",
            "t = 18, avg_loss = 0.0777\n",
            "Checking accuracy on test set\n",
            "Got 249 / 280 correct (88.93)\n",
            "acc = 0.889286\n",
            "Starting epoch 24 / 100\n",
            "t = 1, avg_loss = 0.0394\n",
            "t = 2, avg_loss = 0.0348\n",
            "t = 3, avg_loss = 0.0298\n",
            "t = 4, avg_loss = 0.0899\n",
            "t = 5, avg_loss = 0.0733\n",
            "t = 6, avg_loss = 0.0903\n",
            "t = 7, avg_loss = 0.1128\n",
            "t = 8, avg_loss = 0.1260\n",
            "t = 9, avg_loss = 0.0461\n",
            "t = 10, avg_loss = 0.0458\n",
            "t = 11, avg_loss = 0.1025\n",
            "t = 12, avg_loss = 0.0848\n",
            "t = 13, avg_loss = 0.0493\n",
            "t = 14, avg_loss = 0.0811\n",
            "t = 15, avg_loss = 0.0377\n",
            "t = 16, avg_loss = 0.0926\n",
            "t = 17, avg_loss = 0.1055\n",
            "t = 18, avg_loss = 0.0981\n",
            "Checking accuracy on test set\n",
            "Got 246 / 280 correct (87.86)\n",
            "acc = 0.878571\n",
            "Starting epoch 25 / 100\n",
            "t = 1, avg_loss = 0.0365\n",
            "t = 2, avg_loss = 0.0539\n",
            "t = 3, avg_loss = 0.0385\n",
            "t = 4, avg_loss = 0.0426\n",
            "t = 5, avg_loss = 0.0642\n",
            "t = 6, avg_loss = 0.0282\n",
            "t = 7, avg_loss = 0.1011\n",
            "t = 8, avg_loss = 0.0253\n",
            "t = 9, avg_loss = 0.0376\n",
            "t = 10, avg_loss = 0.1289\n",
            "t = 11, avg_loss = 0.1120\n",
            "t = 12, avg_loss = 0.0574\n",
            "t = 13, avg_loss = 0.0340\n",
            "t = 14, avg_loss = 0.0587\n",
            "t = 15, avg_loss = 0.0585\n",
            "t = 16, avg_loss = 0.0829\n",
            "t = 17, avg_loss = 0.0613\n",
            "t = 18, avg_loss = 0.0450\n",
            "Checking accuracy on test set\n",
            "Got 246 / 280 correct (87.86)\n",
            "acc = 0.878571\n",
            "Starting epoch 26 / 100\n",
            "t = 1, avg_loss = 0.0627\n",
            "t = 2, avg_loss = 0.0977\n",
            "t = 3, avg_loss = 0.0665\n",
            "t = 4, avg_loss = 0.0444\n",
            "t = 5, avg_loss = 0.0404\n",
            "t = 6, avg_loss = 0.0634\n",
            "t = 7, avg_loss = 0.0269\n",
            "t = 8, avg_loss = 0.0681\n",
            "t = 9, avg_loss = 0.0725\n",
            "t = 10, avg_loss = 0.1245\n",
            "t = 11, avg_loss = 0.0547\n",
            "t = 12, avg_loss = 0.0605\n",
            "t = 13, avg_loss = 0.0807\n",
            "t = 14, avg_loss = 0.0883\n",
            "t = 15, avg_loss = 0.0529\n",
            "t = 16, avg_loss = 0.0418\n",
            "t = 17, avg_loss = 0.0621\n",
            "t = 18, avg_loss = 0.0521\n",
            "Checking accuracy on test set\n",
            "Got 248 / 280 correct (88.57)\n",
            "acc = 0.885714\n",
            "Starting epoch 27 / 100\n",
            "t = 1, avg_loss = 0.0468\n",
            "t = 2, avg_loss = 0.0443\n",
            "t = 3, avg_loss = 0.0677\n",
            "t = 4, avg_loss = 0.0564\n",
            "t = 5, avg_loss = 0.0541\n",
            "t = 6, avg_loss = 0.0885\n",
            "t = 7, avg_loss = 0.0610\n",
            "t = 8, avg_loss = 0.0347\n",
            "t = 9, avg_loss = 0.0298\n",
            "t = 10, avg_loss = 0.0576\n",
            "t = 11, avg_loss = 0.0518\n",
            "t = 12, avg_loss = 0.0515\n",
            "t = 13, avg_loss = 0.0555\n",
            "t = 14, avg_loss = 0.0226\n",
            "t = 15, avg_loss = 0.0564\n",
            "t = 16, avg_loss = 0.0668\n",
            "t = 17, avg_loss = 0.0402\n",
            "t = 18, avg_loss = 0.0676\n",
            "Checking accuracy on test set\n",
            "Got 247 / 280 correct (88.21)\n",
            "acc = 0.882143\n",
            "Starting epoch 28 / 100\n",
            "t = 1, avg_loss = 0.0752\n",
            "t = 2, avg_loss = 0.0798\n",
            "t = 3, avg_loss = 0.0271\n",
            "t = 4, avg_loss = 0.0368\n",
            "t = 5, avg_loss = 0.0340\n",
            "t = 6, avg_loss = 0.0487\n",
            "t = 7, avg_loss = 0.1121\n",
            "t = 8, avg_loss = 0.0836\n",
            "t = 9, avg_loss = 0.0372\n",
            "t = 10, avg_loss = 0.0542\n",
            "t = 11, avg_loss = 0.0801\n",
            "t = 12, avg_loss = 0.0307\n",
            "t = 13, avg_loss = 0.0294\n",
            "t = 14, avg_loss = 0.0880\n",
            "t = 15, avg_loss = 0.0481\n",
            "t = 16, avg_loss = 0.0662\n",
            "t = 17, avg_loss = 0.0625\n",
            "t = 18, avg_loss = 0.0252\n",
            "Checking accuracy on test set\n",
            "Got 243 / 280 correct (86.79)\n",
            "acc = 0.867857\n",
            "Starting epoch 29 / 100\n",
            "t = 1, avg_loss = 0.0283\n",
            "t = 2, avg_loss = 0.0660\n",
            "t = 3, avg_loss = 0.0460\n",
            "t = 4, avg_loss = 0.0593\n",
            "t = 5, avg_loss = 0.0268\n",
            "t = 6, avg_loss = 0.0565\n",
            "t = 7, avg_loss = 0.0216\n",
            "t = 8, avg_loss = 0.1071\n",
            "t = 9, avg_loss = 0.0576\n",
            "t = 10, avg_loss = 0.0763\n",
            "t = 11, avg_loss = 0.0737\n",
            "t = 12, avg_loss = 0.0226\n",
            "t = 13, avg_loss = 0.0529\n",
            "t = 14, avg_loss = 0.0396\n",
            "t = 15, avg_loss = 0.0653\n",
            "t = 16, avg_loss = 0.0863\n",
            "t = 17, avg_loss = 0.0272\n",
            "t = 18, avg_loss = 0.0206\n",
            "Checking accuracy on test set\n",
            "Got 248 / 280 correct (88.57)\n",
            "acc = 0.885714\n",
            "Starting epoch 30 / 100\n",
            "t = 1, avg_loss = 0.0334\n",
            "t = 2, avg_loss = 0.0624\n",
            "t = 3, avg_loss = 0.0725\n",
            "t = 4, avg_loss = 0.0622\n",
            "t = 5, avg_loss = 0.0623\n",
            "t = 6, avg_loss = 0.0348\n",
            "t = 7, avg_loss = 0.0734\n",
            "t = 8, avg_loss = 0.0326\n",
            "t = 9, avg_loss = 0.0340\n",
            "t = 10, avg_loss = 0.0445\n",
            "t = 11, avg_loss = 0.0506\n",
            "t = 12, avg_loss = 0.0872\n",
            "t = 13, avg_loss = 0.0696\n",
            "t = 14, avg_loss = 0.0652\n",
            "t = 15, avg_loss = 0.1043\n",
            "t = 16, avg_loss = 0.0275\n",
            "t = 17, avg_loss = 0.0448\n",
            "t = 18, avg_loss = 0.1198\n",
            "Checking accuracy on test set\n",
            "Got 247 / 280 correct (88.21)\n",
            "acc = 0.882143\n",
            "Starting epoch 31 / 100\n",
            "t = 1, avg_loss = 0.0420\n",
            "t = 2, avg_loss = 0.0475\n",
            "t = 3, avg_loss = 0.0478\n",
            "t = 4, avg_loss = 0.0530\n",
            "t = 5, avg_loss = 0.0539\n",
            "t = 6, avg_loss = 0.0843\n",
            "t = 7, avg_loss = 0.1125\n",
            "t = 8, avg_loss = 0.0531\n",
            "t = 9, avg_loss = 0.1192\n",
            "t = 10, avg_loss = 0.0241\n",
            "t = 11, avg_loss = 0.0411\n",
            "t = 12, avg_loss = 0.0341\n",
            "t = 13, avg_loss = 0.0575\n",
            "t = 14, avg_loss = 0.0502\n",
            "t = 15, avg_loss = 0.0648\n",
            "t = 16, avg_loss = 0.0651\n",
            "t = 17, avg_loss = 0.0458\n",
            "t = 18, avg_loss = 0.0789\n",
            "Checking accuracy on test set\n",
            "Got 246 / 280 correct (87.86)\n",
            "acc = 0.878571\n",
            "Starting epoch 32 / 100\n",
            "t = 1, avg_loss = 0.0336\n",
            "t = 2, avg_loss = 0.0652\n",
            "t = 3, avg_loss = 0.0523\n",
            "t = 4, avg_loss = 0.0387\n",
            "t = 5, avg_loss = 0.0719\n",
            "t = 6, avg_loss = 0.0314\n",
            "t = 7, avg_loss = 0.0596\n",
            "t = 8, avg_loss = 0.0266\n",
            "t = 9, avg_loss = 0.0309\n",
            "t = 10, avg_loss = 0.0295\n",
            "t = 11, avg_loss = 0.0835\n",
            "t = 12, avg_loss = 0.0403\n",
            "t = 13, avg_loss = 0.0371\n",
            "t = 14, avg_loss = 0.0899\n",
            "t = 15, avg_loss = 0.0447\n",
            "t = 16, avg_loss = 0.0789\n",
            "t = 17, avg_loss = 0.0412\n",
            "t = 18, avg_loss = 0.0865\n",
            "Checking accuracy on test set\n",
            "Got 250 / 280 correct (89.29)\n",
            "acc = 0.892857\n",
            "Starting epoch 33 / 100\n",
            "t = 1, avg_loss = 0.0445\n",
            "t = 2, avg_loss = 0.0951\n",
            "t = 3, avg_loss = 0.0613\n",
            "t = 4, avg_loss = 0.0275\n",
            "t = 5, avg_loss = 0.0326\n",
            "t = 6, avg_loss = 0.0387\n",
            "t = 7, avg_loss = 0.1325\n",
            "t = 8, avg_loss = 0.1764\n",
            "t = 9, avg_loss = 0.0268\n",
            "t = 10, avg_loss = 0.0733\n",
            "t = 11, avg_loss = 0.0465\n",
            "t = 12, avg_loss = 0.0728\n",
            "t = 13, avg_loss = 0.0644\n",
            "t = 14, avg_loss = 0.0416\n",
            "t = 15, avg_loss = 0.0287\n",
            "t = 16, avg_loss = 0.0708\n",
            "t = 17, avg_loss = 0.0563\n",
            "t = 18, avg_loss = 0.0372\n",
            "Checking accuracy on test set\n",
            "Got 242 / 280 correct (86.43)\n",
            "acc = 0.864286\n",
            "Starting epoch 34 / 100\n",
            "t = 1, avg_loss = 0.0231\n",
            "t = 2, avg_loss = 0.0493\n",
            "t = 3, avg_loss = 0.0498\n",
            "t = 4, avg_loss = 0.0267\n",
            "t = 5, avg_loss = 0.0744\n",
            "t = 6, avg_loss = 0.0541\n",
            "t = 7, avg_loss = 0.0403\n",
            "t = 8, avg_loss = 0.0491\n",
            "t = 9, avg_loss = 0.0211\n",
            "t = 10, avg_loss = 0.0172\n",
            "t = 11, avg_loss = 0.0843\n",
            "t = 12, avg_loss = 0.0684\n",
            "t = 13, avg_loss = 0.0184\n",
            "t = 14, avg_loss = 0.0429\n",
            "t = 15, avg_loss = 0.0252\n",
            "t = 16, avg_loss = 0.0335\n",
            "t = 17, avg_loss = 0.0299\n",
            "t = 18, avg_loss = 0.0463\n",
            "Checking accuracy on test set\n",
            "Got 246 / 280 correct (87.86)\n",
            "acc = 0.878571\n",
            "Starting epoch 35 / 100\n",
            "t = 1, avg_loss = 0.0277\n",
            "t = 2, avg_loss = 0.0364\n",
            "t = 3, avg_loss = 0.0186\n",
            "t = 4, avg_loss = 0.0398\n",
            "t = 5, avg_loss = 0.0352\n",
            "t = 6, avg_loss = 0.1014\n",
            "t = 7, avg_loss = 0.0477\n",
            "t = 8, avg_loss = 0.0325\n",
            "t = 9, avg_loss = 0.0706\n",
            "t = 10, avg_loss = 0.0149\n",
            "t = 11, avg_loss = 0.0401\n",
            "t = 12, avg_loss = 0.0357\n",
            "t = 13, avg_loss = 0.0892\n",
            "t = 14, avg_loss = 0.0381\n",
            "t = 15, avg_loss = 0.0540\n",
            "t = 16, avg_loss = 0.0462\n",
            "t = 17, avg_loss = 0.0611\n",
            "t = 18, avg_loss = 0.0239\n",
            "Checking accuracy on test set\n",
            "Got 247 / 280 correct (88.21)\n",
            "acc = 0.882143\n",
            "Starting epoch 36 / 100\n",
            "t = 1, avg_loss = 0.0443\n",
            "t = 2, avg_loss = 0.0295\n",
            "t = 3, avg_loss = 0.0462\n",
            "t = 4, avg_loss = 0.0994\n",
            "t = 5, avg_loss = 0.0187\n",
            "t = 6, avg_loss = 0.0181\n",
            "t = 7, avg_loss = 0.0437\n",
            "t = 8, avg_loss = 0.0277\n",
            "t = 9, avg_loss = 0.2237\n",
            "t = 10, avg_loss = 0.0332\n",
            "t = 11, avg_loss = 0.0282\n",
            "t = 12, avg_loss = 0.0110\n",
            "t = 13, avg_loss = 0.0271\n",
            "t = 14, avg_loss = 0.0293\n",
            "t = 15, avg_loss = 0.0411\n",
            "t = 16, avg_loss = 0.0420\n",
            "t = 17, avg_loss = 0.0577\n",
            "t = 18, avg_loss = 0.0137\n",
            "Checking accuracy on test set\n",
            "Got 250 / 280 correct (89.29)\n",
            "acc = 0.892857\n",
            "Starting epoch 37 / 100\n",
            "t = 1, avg_loss = 0.0697\n",
            "t = 2, avg_loss = 0.0278\n",
            "t = 3, avg_loss = 0.0572\n",
            "t = 4, avg_loss = 0.0114\n",
            "t = 5, avg_loss = 0.0158\n",
            "t = 6, avg_loss = 0.0211\n",
            "t = 7, avg_loss = 0.0349\n",
            "t = 8, avg_loss = 0.0995\n",
            "t = 9, avg_loss = 0.0974\n",
            "t = 10, avg_loss = 0.0145\n",
            "t = 11, avg_loss = 0.0488\n",
            "t = 12, avg_loss = 0.0269\n",
            "t = 13, avg_loss = 0.0325\n",
            "t = 14, avg_loss = 0.0169\n",
            "t = 15, avg_loss = 0.0698\n",
            "t = 16, avg_loss = 0.0438\n",
            "t = 17, avg_loss = 0.0277\n",
            "t = 18, avg_loss = 0.1856\n",
            "Checking accuracy on test set\n",
            "Got 247 / 280 correct (88.21)\n",
            "acc = 0.882143\n",
            "Starting epoch 38 / 100\n",
            "t = 1, avg_loss = 0.0217\n",
            "t = 2, avg_loss = 0.0309\n",
            "t = 3, avg_loss = 0.0243\n",
            "t = 4, avg_loss = 0.0249\n",
            "t = 5, avg_loss = 0.0209\n",
            "t = 6, avg_loss = 0.0260\n",
            "t = 7, avg_loss = 0.0411\n",
            "t = 8, avg_loss = 0.0325\n",
            "t = 9, avg_loss = 0.0174\n",
            "t = 10, avg_loss = 0.0446\n",
            "t = 11, avg_loss = 0.0377\n",
            "t = 12, avg_loss = 0.0189\n",
            "t = 13, avg_loss = 0.0468\n",
            "t = 14, avg_loss = 0.0200\n",
            "t = 15, avg_loss = 0.0211\n",
            "t = 16, avg_loss = 0.0266\n",
            "t = 17, avg_loss = 0.0392\n",
            "t = 18, avg_loss = 0.0424\n",
            "Checking accuracy on test set\n",
            "Got 246 / 280 correct (87.86)\n",
            "acc = 0.878571\n",
            "Starting epoch 39 / 100\n",
            "t = 1, avg_loss = 0.0259\n",
            "t = 2, avg_loss = 0.0168\n",
            "t = 3, avg_loss = 0.0222\n",
            "t = 4, avg_loss = 0.0204\n",
            "t = 5, avg_loss = 0.0088\n",
            "t = 6, avg_loss = 0.0572\n",
            "t = 7, avg_loss = 0.0284\n",
            "t = 8, avg_loss = 0.0286\n",
            "t = 9, avg_loss = 0.0164\n",
            "t = 10, avg_loss = 0.0113\n",
            "t = 11, avg_loss = 0.0479\n",
            "t = 12, avg_loss = 0.0463\n",
            "t = 13, avg_loss = 0.0421\n",
            "t = 14, avg_loss = 0.0300\n",
            "t = 15, avg_loss = 0.0108\n",
            "t = 16, avg_loss = 0.0432\n",
            "t = 17, avg_loss = 0.0575\n",
            "t = 18, avg_loss = 0.0116\n",
            "Checking accuracy on test set\n",
            "Got 247 / 280 correct (88.21)\n",
            "acc = 0.882143\n",
            "Starting epoch 40 / 100\n",
            "t = 1, avg_loss = 0.0197\n",
            "t = 2, avg_loss = 0.0261\n",
            "t = 3, avg_loss = 0.0187\n",
            "t = 4, avg_loss = 0.0099\n",
            "t = 5, avg_loss = 0.0106\n",
            "t = 6, avg_loss = 0.0377\n",
            "t = 7, avg_loss = 0.0308\n",
            "t = 8, avg_loss = 0.0112\n",
            "t = 9, avg_loss = 0.0111\n",
            "t = 10, avg_loss = 0.0061\n",
            "t = 11, avg_loss = 0.0981\n",
            "t = 12, avg_loss = 0.0909\n",
            "t = 13, avg_loss = 0.0187\n",
            "t = 14, avg_loss = 0.0409\n",
            "t = 15, avg_loss = 0.0919\n",
            "t = 16, avg_loss = 0.0132\n",
            "t = 17, avg_loss = 0.0263\n",
            "t = 18, avg_loss = 0.0172\n",
            "Checking accuracy on test set\n",
            "Got 251 / 280 correct (89.64)\n",
            "acc = 0.896429\n",
            "Starting epoch 41 / 100\n",
            "t = 1, avg_loss = 0.0262\n",
            "t = 2, avg_loss = 0.0174\n",
            "t = 3, avg_loss = 0.0119\n",
            "t = 4, avg_loss = 0.0376\n",
            "t = 5, avg_loss = 0.0071\n",
            "t = 6, avg_loss = 0.0113\n",
            "t = 7, avg_loss = 0.0189\n",
            "t = 8, avg_loss = 0.0341\n",
            "t = 9, avg_loss = 0.0125\n",
            "t = 10, avg_loss = 0.0287\n",
            "t = 11, avg_loss = 0.0241\n",
            "t = 12, avg_loss = 0.0317\n",
            "t = 13, avg_loss = 0.0186\n",
            "t = 14, avg_loss = 0.0120\n",
            "t = 15, avg_loss = 0.0254\n",
            "t = 16, avg_loss = 0.0377\n",
            "t = 17, avg_loss = 0.0477\n",
            "t = 18, avg_loss = 0.0479\n",
            "Checking accuracy on test set\n",
            "Got 247 / 280 correct (88.21)\n",
            "acc = 0.882143\n",
            "Starting epoch 42 / 100\n",
            "t = 1, avg_loss = 0.0305\n",
            "t = 2, avg_loss = 0.0308\n",
            "t = 3, avg_loss = 0.0184\n",
            "t = 4, avg_loss = 0.0254\n",
            "t = 5, avg_loss = 0.0229\n",
            "t = 6, avg_loss = 0.0238\n",
            "t = 7, avg_loss = 0.0368\n",
            "t = 8, avg_loss = 0.0460\n",
            "t = 9, avg_loss = 0.0506\n",
            "t = 10, avg_loss = 0.0236\n",
            "t = 11, avg_loss = 0.0145\n",
            "t = 12, avg_loss = 0.0144\n",
            "t = 13, avg_loss = 0.0201\n",
            "t = 14, avg_loss = 0.0207\n",
            "t = 15, avg_loss = 0.0716\n",
            "t = 16, avg_loss = 0.0315\n",
            "t = 17, avg_loss = 0.0106\n",
            "t = 18, avg_loss = 0.0206\n",
            "Checking accuracy on test set\n",
            "Got 251 / 280 correct (89.64)\n",
            "acc = 0.896429\n",
            "Starting epoch 43 / 100\n",
            "t = 1, avg_loss = 0.0460\n",
            "t = 2, avg_loss = 0.0208\n",
            "t = 3, avg_loss = 0.0201\n",
            "t = 4, avg_loss = 0.0052\n",
            "t = 5, avg_loss = 0.0123\n",
            "t = 6, avg_loss = 0.0148\n",
            "t = 7, avg_loss = 0.0335\n",
            "t = 8, avg_loss = 0.0387\n",
            "t = 9, avg_loss = 0.0253\n",
            "t = 10, avg_loss = 0.0247\n",
            "t = 11, avg_loss = 0.0359\n",
            "t = 12, avg_loss = 0.0201\n",
            "t = 13, avg_loss = 0.0131\n",
            "t = 14, avg_loss = 0.0690\n",
            "t = 15, avg_loss = 0.0284\n",
            "t = 16, avg_loss = 0.0922\n",
            "t = 17, avg_loss = 0.0296\n",
            "t = 18, avg_loss = 0.0383\n",
            "Checking accuracy on test set\n",
            "Got 242 / 280 correct (86.43)\n",
            "acc = 0.864286\n",
            "Starting epoch 44 / 100\n",
            "t = 1, avg_loss = 0.0368\n",
            "t = 2, avg_loss = 0.0158\n",
            "t = 3, avg_loss = 0.0225\n",
            "t = 4, avg_loss = 0.0191\n",
            "t = 5, avg_loss = 0.0316\n",
            "t = 6, avg_loss = 0.0995\n",
            "t = 7, avg_loss = 0.0359\n",
            "t = 8, avg_loss = 0.0215\n",
            "t = 9, avg_loss = 0.0178\n",
            "t = 10, avg_loss = 0.0167\n",
            "t = 11, avg_loss = 0.0188\n",
            "t = 12, avg_loss = 0.0607\n",
            "t = 13, avg_loss = 0.0206\n",
            "t = 14, avg_loss = 0.0379\n",
            "t = 15, avg_loss = 0.0445\n",
            "t = 16, avg_loss = 0.0047\n",
            "t = 17, avg_loss = 0.0191\n",
            "t = 18, avg_loss = 0.0433\n",
            "Checking accuracy on test set\n",
            "Got 247 / 280 correct (88.21)\n",
            "acc = 0.882143\n",
            "Starting epoch 45 / 100\n",
            "t = 1, avg_loss = 0.0140\n",
            "t = 2, avg_loss = 0.0101\n",
            "t = 3, avg_loss = 0.0138\n",
            "t = 4, avg_loss = 0.0335\n",
            "t = 5, avg_loss = 0.0326\n",
            "t = 6, avg_loss = 0.0197\n",
            "t = 7, avg_loss = 0.0331\n",
            "t = 8, avg_loss = 0.0142\n",
            "t = 9, avg_loss = 0.0135\n",
            "t = 10, avg_loss = 0.0242\n",
            "t = 11, avg_loss = 0.0171\n",
            "t = 12, avg_loss = 0.0111\n",
            "t = 13, avg_loss = 0.0152\n",
            "t = 14, avg_loss = 0.0136\n",
            "t = 15, avg_loss = 0.0145\n",
            "t = 16, avg_loss = 0.0141\n",
            "t = 17, avg_loss = 0.0123\n",
            "t = 18, avg_loss = 0.0187\n",
            "Checking accuracy on test set\n",
            "Got 247 / 280 correct (88.21)\n",
            "acc = 0.882143\n",
            "Starting epoch 46 / 100\n",
            "t = 1, avg_loss = 0.0380\n",
            "t = 2, avg_loss = 0.0300\n",
            "t = 3, avg_loss = 0.0250\n",
            "t = 4, avg_loss = 0.0163\n",
            "t = 5, avg_loss = 0.0100\n",
            "t = 6, avg_loss = 0.0111\n",
            "t = 7, avg_loss = 0.0202\n",
            "t = 8, avg_loss = 0.0678\n",
            "t = 9, avg_loss = 0.0030\n",
            "t = 10, avg_loss = 0.0129\n",
            "t = 11, avg_loss = 0.0120\n",
            "t = 12, avg_loss = 0.0357\n",
            "t = 13, avg_loss = 0.0079\n",
            "t = 14, avg_loss = 0.0462\n",
            "t = 15, avg_loss = 0.0077\n",
            "t = 16, avg_loss = 0.0198\n",
            "t = 17, avg_loss = 0.0157\n",
            "t = 18, avg_loss = 0.0390\n",
            "Checking accuracy on test set\n",
            "Got 247 / 280 correct (88.21)\n",
            "acc = 0.882143\n",
            "Starting epoch 47 / 100\n",
            "t = 1, avg_loss = 0.0157\n",
            "t = 2, avg_loss = 0.0183\n",
            "t = 3, avg_loss = 0.0138\n",
            "t = 4, avg_loss = 0.0136\n",
            "t = 5, avg_loss = 0.0125\n",
            "t = 6, avg_loss = 0.0188\n",
            "t = 7, avg_loss = 0.0079\n",
            "t = 8, avg_loss = 0.0286\n",
            "t = 9, avg_loss = 0.0392\n",
            "t = 10, avg_loss = 0.0170\n",
            "t = 11, avg_loss = 0.0147\n",
            "t = 12, avg_loss = 0.0069\n",
            "t = 13, avg_loss = 0.0218\n",
            "t = 14, avg_loss = 0.0643\n",
            "t = 15, avg_loss = 0.0265\n",
            "t = 16, avg_loss = 0.0444\n",
            "t = 17, avg_loss = 0.0249\n",
            "t = 18, avg_loss = 0.0065\n",
            "Checking accuracy on test set\n",
            "Got 249 / 280 correct (88.93)\n",
            "acc = 0.889286\n",
            "Starting epoch 48 / 100\n",
            "t = 1, avg_loss = 0.0082\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-c87d1392f8b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfixed_model_gpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.00012\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfixed_model_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0mcheck_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfixed_model_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-2d469a18a779>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, loss_fn, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mx_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0my_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-50a9cd504daf>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m           \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"malignant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"malignant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \"\"\"\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   1856\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1858\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreducing_gap\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresample\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mNEAREST\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDn-2g-TLY3k",
        "colab_type": "code",
        "outputId": "69a57c0d-3241-444d-ddd5-ac596905d558",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot([print_every*batch_size*(i+1) for i in range((len(avg_loss_list)))],avg_loss_list)\n",
        "print(\"Loss:\")\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD5CAYAAAA3Os7hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZVTeP0BaHTwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGer6hJv7-zR",
        "colab_type": "code",
        "outputId": "e6eec334-b5a5-4e39-9a0d-047a89401551",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "plt.plot([i+1 for i in range((len(acc_list)))],acc_list)\n",
        "print(\"Accurancy:\")\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accurancy:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3dd3hUZfo+8PtJBZIQIIQaSCAEEKVE\nQkfFjsjafy5gY0Wxoa5lBXddd8UtlnWt6AKKiiLFDpGfrAoiJZTQAqFIEkoSQjrpM8nMPN8/ZmBD\nEpIJTDLhnPtzXbmYc+bkzJPD5M4773nPe0RVQURE5z8fbxdARESewUAnIjIIBjoRkUEw0ImIDIKB\nTkRkEH7eeuGOHTtqVFSUt16eiOi8tG3btjxVDa/rOa8FelRUFBITE7318kRE5yUROXKm59jlQkRk\nEAx0IiKDYKATERkEA52IyCAY6EREBuFWoIvIeBE5ICIpIjKrjucjReQnEUkSkZ9FJMLzpRIRUX0a\nDHQR8QUwB8B1AAYAmCwiA2ps9i8AC1V1EIDZAP7p6UKJiKh+7rTQhwNIUdU0Va0EsATAjTW2GQBg\ntevxmjqeJ2p2h/PKsCwxHXYHp4gmc3An0LsDSK+2nOFaV90uALe4Ht8MIEREwmruSESmi0iiiCTm\n5uaeTb1EbknNLcVt/0nAM18kYeqHW1BQVuntkoianKdOij4N4DIR2QHgMgCZAOw1N1LVeaoap6px\n4eF1XrlqWPmlVjzy2XbsySxq0tfJPFGBP329Gy+sSIZZb15yJL8MU+ZvAqB4+pq+2HyoABPfWocd\nRwu9XRp5yJoDOZi+MBE5xRa3v+dQXhke/GQbDuWVNWFl3uXOpf+ZAHpUW45wrTtFVY/B1UIXkWAA\nt6rqCU8VaQSz4/fiu6QsHDhegu8eG4tAP1+P7j+n2II5a1KweEs6bA4HHAp0DW2F6ZdGu72PSpsD\nAX7n98CnjMJyTJm/GZU2B5ZMH4V+XUJwWd9OeGjRNtw+NwHPTxyAO0dGQkS8XWqzqrI74O/b9P+3\nVpsd/j4+8PFpuuO79tdcPLBwGyrtDqTllWHJ9JHoGBxY7/ekF5RjyvxNyCqyICjQD6/dPrjJ6vMm\nd/6HtwKIEZFeIhIAYBKA5dU3EJGOInJyX88CWODZMs9vq/dn49udxzCuXzhSckoxZ3WKx/adX2rF\nP1buwyWvrMGizUdx69DuWDfzCkwY2AUvf38Am9LyG9yHquLP3+zB0Bd/wN5jxR6rrbkdL7JgyvzN\nKLFU4ZNpI9CvSwgAYGBEKOIfHYtLYsLx52+T8cTSnSivtHm52ubz9k8HETv7B/yaXdKkr7MxNQ9j\nXlqDm9/biMwTFU32GtMXJqJPp2DMu2soMgrLcef7m1FYT5fasRMVmDx/E8or7bi8XzhW7DqG3BJr\nk9TnbeLOx3IRmQDgDQC+ABao6t9FZDaARFVdLiK3wTmyRQH8AuARVa33iMXFxWlLn5xrQ0oejhaU\n1/lch6AAXDOgc4MtvRJLFa55/Re0beWPFY+Oxawvk7B81zGseHQsLujatsEaEg8X4GBOaZ3PHckv\nxycJh1FRZcdNsd3x+JUxiAwLAgCUWm244Z31KK6w4bvHxqJz21Z17kNVMTt+Lz7ccBiBfj7oEtoK\ny2eMRWhr/wZra0lySiyYNHcTckqs+PS+ERjSo12tbRwOxbs/p+C1H35FTKdgvHfnUESHB3uh2ubz\n3s+pePn7/QCA3wzuhrcnx3r8NVQV/1mbhldX7UdkWBDySqzw8xW8MSkWl/X1XNfq1sMFuPuDLejR\noTWWTB+FDkEBWH8wD/d+vBV9Owdj0X0ja71vs4st+O3cBOSXVmLR/SMQFOiHK19biyev7ovHrozx\nWG3uqrQ5sDQxHdcM6HzG38mGiMg2VY2r8zlv9bO29EBfsP4QZsfvrXeb342JwvMTB9Qb6s99sxuL\nNh/FVw+NRmzP9igsq8RV/16L7u1b46uHRsOvno/BX+/IwJPLdqG+/6LrB3XFE1fFoE+nkFrPHcwu\nwY1zNmBA17ZYPH1krY/cqoqXvt+PuWvTcO+YXpgwsAsmzduEcf06Yd5dQ5v0Y7Mn5ZdaMWneJmSe\nqMDCe4cjLqpDvduvO5iLx5fsRKXNgVduG4QJA7s2U6XN64P1h/Bi/F7cMLgbuoS2wvx1afjxycs8\n+kesqKIKT3++Cz/szcbEQV3x0q2DkFtixUOfbsOB7BI8fmUMHrsi5pzfSzuOFuKuD7agU9tALJ0+\nCuEh/+tiOdmffmG3UHwybThCWjlDPa/Uit/OTcDxIgsWThuBoZHtAQD3LNiCvVnF2DDzimbrYrTZ\nHfhqRybe/PGg8zzXhAtw/6W9z2pf9QU6VNUrX0OHDtWW6pOEwxo5M16nL9yqx06Ua9aJilpff12+\nRyNnxus/Vu5Vh8NR5342peZp5Mx4nb0i+bT1y3dmauTMeJ23NvWMNcTvOqa9ZsXrpLkJml5QVmcN\nBaXWBn+Wk6/1wvLkWs+99t8DGjkzXv/0ddKpn+GDdWkaOTNe56w52OC+U3NK9OllO/WnfcfPeAya\nWomlSse/8Yv2e26lbkzJc/v7MgvL9aY56zVyZry+uCJZK232s65hf1axzvoySV/9fr9uSMnVikrb\nWe9LVTW/1KpPL9up76w+qNuOFGjVWdS20PUefvCTRK2y2TW3xKL9nlupTy3beU61VZecWaSXvrJa\no5/9ThesTzvtPVButekTS3do5Mx4vfuDzW69V89kd8YJvegv3+ulr6zWrBMVdW6zak+WRj/7nd72\n3gYttVRpQalVr319rfZ/7v/rptTT3xer92dr5Mx4/WZHxlnX5C673aHf7MjQca+u0ciZ8fqbt9fp\nzwdyzun3Bc6ekTpzlS30GpYlpuOZL5JwRf9O+M+dQ8/4F1xV8edv9+DTTUfx2JUxePLqvqc9b6my\n47o318HmcGDV7y9FmwC/0773/oXbsD4lF6t+f+mpbpKT/pt8HA8v2o7Ynu3w8b3DT/ves/HCimR8\nuOEw3pkSi4mDugEA5qxJwaurDuD2uAi8dMugUy0oVcWji3dg5e4sfDJtBMb06VjnPr/fk4WnP09C\nqdXZFx3bsx2evqYfRkeHNdsJR1XFI59tx6rkbCyYOqzRH+8rbQ78Y+U+fLTxMIZFtcc7Uy5u1Mfg\ntNxSvPHjQaxIOoZAPx9U2pwnowP8fBAX2R6jo8MwKrojBkWEun1C0u5Q3LNgCzam5uHk8PngQD+M\n6NUBo6LDMDq6I/p3Cam3xbt061HM/HI3rrqgE96943/v4RdWJGNhwhH8/PQ49OjQxu2fsy6fJ6bj\nuW/2oF0bf7x7x8UYGln7U5GqYvGWdPx1eTLCQwLx7h0XY3AdXWH12X+8GJPmbUJQgB+WPTgK3du1\nPuO23yVl4dHF2zGiVxiKLVU4mFOKD6cOq/UedjgUV/17LUJa++PbR8Y0qh53qSpWJWfj9R9+xYHs\nEvTvEoInr+6Lq93opm0Iu1zc9O3OTPx+6U6M7dMR8++OQyv/+keiOByKWV8lYVliBv5wbT88cnmf\nU8+9/P1+vPdzKj6dNgJjY2qH4vEiC67+91pc1D0Un90/4tR/8pr9OZj+Se2Pj+ei0ubA5PmbsC+r\nGMtnjMGa/bn4+8p9uDm2O/71/wbDt0Y4lFltuGnOBhSUVSL+sbHoGvq/XyKb3YFXVh3AvF/SMDgi\nFG9NjsXG1Hy89dNBZBVZMLJ3Bzx1TT8Ma6DbwxPeX5eGv323D3+c0L9Ro3lq+nZnJmZ9uRtBgX54\nZ0osRvaudQnFadILyvHWTwfx5fYMBPr5YuqYKEy/pDd8fQVbDxVgY2o+NqbmY1+W8wRzx+BAfHzv\nMFzYLbTBWl777wG8vToFL90yEFcN6IxNac59JaTmnxpu176NP0b2Djv1ByM6POjU++dkN90lMeGY\nf/fQ00ZTHS+y4NJX1uC2uAj84+aBjTpGxZYqbEk7+bPlYf/xEozqHYa3p8Q2OMIkKeMEHvp0O7KL\nLRga2R6joztidJ8wDI5oV6vB5HAo9h8vwcbUPCSk5iMhLR9tW/lj2QOj0DOs4T9C3+zIxBPLdsLf\nxwdz7x6Ky/t1qnO7jzcexl+WJ+Prh51doWdyorwSU+ZvxoFGnlBWVTgU6B0ehCeu6ovrB3b1WBcm\nA90NK3dn4dHFOzAsqj0+nDocrQPcG1ZodyieWrYT3+w8hueuvwD3XdIbezKLcOOcDbj14u545bYz\nD4/6bPNR/PHr3XjploGYNLxngyd4zsXxIgsmvr0OAJBXWonrB3bFm5OGnLEPPyWnFDe+sx59u4Rg\n6fRRCPDzQU6xBTMW78CWQwW4a2Qknpt4wanAsFTZsWTLUbyzJhV5pVZc2jccz1zbDxd1bzjEzsbm\ntHxMeX8zrr6gM9678+JzbvX8ml2CBz/dhiP55Xj8yhgMiqhdtwL4aV82lm5Nh4jgrpGRePCy6NP6\nc6srKKvEprR8/C1+Lyw2B5ZMH4m+nWuf6zjpp33ZmPZxIm6Pi6jzfZNVVIGNKc6Q25iSh2NFzjHY\nnUICMTo6DD06tMGcNSkY0SsMH/5uWJ0Nkj99vRufJ2Zg7TPjTvtDXZcthwqwen8OEtLysTvjBBwK\nBPr5IC6qPa7s3xl3j4qs9xxQdYVllZj7Sxo2pORhz7EiqAKt/X0xrFcHjI4OQ1CALxLSnH+4Csur\nAAC9OgZhZO8wPHhZ71qfYuuz9tdctAnwrbdRUWq1YdQ/fsLl/TvhrTOcKHY4FPd+vBUbUvJw75he\njR72GdM5GNcP7Or2MXIXA70BP+zNxkOfbsOQHs4ujqDAxnVx2OwOPLZkB1buPo4/TxyAr7ZnIKfE\nih+fuAyhbc4cyg6HYsr7m5B8rBh/v3kgnvliF6LCgrD4/pFoHxRwrj9WLQmp+bjzg824on8nvHvH\nxQ2+QVfuzsLDi7bjnlGRmDCwK2Ys3oESSxX+ectA3Bxb9/xrFZV2fLLpMN77ORXFFhueva4/po3t\n5dFumJxiC65/ez1CAv3w7YwxHvkUAzh/yWd+kYTvdmedcRt/X8Fvh/XAjMtj0CXUve6Zw3lluH1u\nAhwKLH1gZJ0nJY/ml2Pi2+vQo0MbfPnQ6AY/HaoqjhaUn/o0kJCah7zSSgyLal9vN116QTku/9fP\nuGtUJP7ymwvPuP+Tn378fASxPdthVHRHjI4Ow5Ae7RqsrSFF5VXYdMgZ3htT8/BrtnMUV9fQVs7W\ne3QYRkWHoVs93SueMHvFXixMOIwNs66os6vtjR9/xRs/HsSLN12Eu0ZGNmktjcFAr0dCaj7uWbAF\nF3Rri0/PoYujyu7AQ59ux4/7sgEA/7lzKMZf1KXB7zucV4Zr3/gFVpsD0eFBWPrAqAY/wp6LnGIL\nwoIDa3WznMnf4vfi/fWH4CNAVFgQ3rtz6Knx3fUptlThmc+T8H3ycVx3URe8ctsgjwRvld2BKfM3\nYU9mMb6dMabeFu/ZUFXsyyqBxVbrQmcAQPd2rc9quFlKTikmzUuAr49g2QOjTmtxWqrsuOVd59jt\n+EfHnlX/tqoio7ACXUNbNdgi/MPnu7Ai6RjWPXNFnZ8uFiYcxvPfJmPCwC549bbBjW7gNFZuiRUV\nlXb06NC6WS/4OpJfhnH/+hkzLu+Dp67pd9pzPx/Iwe8+2oqbh3THa7cPblEXonGUSz0eXrRNh774\ng54oqzznfVmqbPrY4u36p6+TGvV9izcf0dve26DHi+o+g+9NlTa7Tl+4VR9fvF2LKxp3jBwOh85b\nm6q9n/1OL391je7PKj7nel5ckdxsIxQ8bV9WkQ55YZWO/udPml5QpqrOY/TUsp0aOTNeV+/LbpY6\nUnNKtNcs5witmhZvPqKRM+N12kdbz2nkz/li2kdb9OLZ/z1tZNLR/DId/MIqvfb1tVpuPbcRS00B\n9YxyOb+v8/aAjIJyXNA1pN6uEXcF+vnizUmx+NtNjTvhNGl4T3z+4OizvtCgKfn7+mDuXXF4Y1Js\no1vYIoL7L+2Nz+4bgRLXidZvdmQ2/I1n8F1SFt5ffwhTR0fhxiE154dr+fp3aYtPpo1AiaUKU+Zv\nRlZRBRZvSccX2zLw2BV9cHn/uk/geVrv8GBMHNQNnyYcOe0Ky6+2Z+DZr3fjsr7hmHNHbLNMFeBt\nU0f3Qn5ZJeKTnN1slio7Hl60HXa74j93DnX7XFpLYfz/sQakF1Ygov25DeGi+o3oHYbvHh2Lgd1D\n8fulO/HcN7sbfen9r9kleOaLXbi4Zzv8ccIFTVRp07uoeygWThuBgrJK3D43AX9dnoxLYjri8av6\nNvzNHvTI5X1QVmnHhxsPAwBW7DqGpz/fhVG9wzD3rqEen2uopRrTJwwxnYLx4YZDUFW8sCIZuzOL\n8NrtgxHV0f0TsS1F03aOtXClVhsKyirRo0PTnnwhoFPbVlh0/wi86hryuHRrOmJ7Osdqj+nTsdYQ\nthJLFbYeLsDGFNcQwOPF6NAmAHPuuPi8n0BsSI92+Oh3w3D3gi0IDwnEW5Ni3T6n4Sn9uoRg/IVd\n8OGGQ+jZoQ1mfpmEoZHt8f49DQ/XNRIRwdQxUfjT13vwx6/3YPGWdDw0LhrXXNjw+a+WyNQnRfdl\nFeO6N9fh7cmx+M3gbl6txUy2Hi7Aj3uzsTE1v9YQtj7hwdiRXoikjCLYHXraRTq/GdytUcPXWroj\n+WVo7e+LTl7qatuTWYSJb68H4Pwj46nrHs435ZU2jPrnahRVVGF0dBgW3jvc40MNPam+k6KmbqGn\nuybeOter5qhxhkV1ODVGuOYQto0peRjcox0eHheNUdFhuLhne8O2GL39x+mi7qG4aUg3ZJ6owPv3\nDDNlmANAmwA/PDQuGl9sy8Bbk2NbdJg3xNyBXuic4rNHe3a5eEtoG39ce2EXXOv6iOtw6HkzKZgR\nvP7bIS1qSJ63PHhZNB64tPd5fyzO3z9FHpBeUI6gAF90aIKLeOjsMMyb1/keYJ5khGNh6kDPKCxH\njw5tDPEfSURk6kBPL+CQRSIyDtMGuqoivbCcQxaJyDBMG+j5ZZUor7SjB1voRGQQpg10DlkkIqMx\nb6CfHLLILhciMgjzBvrJFjq7XIjIIEwb6BmF5QgLCmjyuZ6JiJqLaQM9vaACEew/JyIDMW+gF5bz\nkn8iMhRTBrrdocgsrOAIFyIyFFMGelZRBWwO5QlRIjIUUwZ6egGHLBKR8Zgz0As5ZJGIjMeUgZ5R\nUA4fAbq1YwudiIzDlIGeXliBrqGtz/t7UxIRVWfKREsvKEcEhywSkcGYM9BdN7YgIjIS0wW6pcqO\n7GIrT4gSkeGYLtAzOMsiERmU6QL91JBFdrkQkcGYLtAzXNPm9mSgE5HBmC7Q0wsrEODng/DgQG+X\nQkTkUeYLdNeQRR8f8XYpREQeZb5ALyznCBciMiS3Al1ExovIARFJEZFZdTzfU0TWiMgOEUkSkQme\nL9UzjuaXc4QLERlSg4EuIr4A5gC4DsAAAJNFZECNzZ4DsExVYwFMAvCupwv1hKKKKhRbbGyhE5Eh\nudNCHw4gRVXTVLUSwBIAN9bYRgG0dT0OBXDMcyV6zqkbQ3OECxEZkDuB3h1AerXlDNe66v4K4E4R\nyQCwEsCjde1IRKaLSKKIJObm5p5Fuecmo5BDFonIuDx1UnQygI9UNQLABACfiEitfavqPFWNU9W4\n8PBwD720+07d2IJdLkRkQO4EeiaAHtWWI1zrqpsGYBkAqGoCgFYAOnqiQE9KLyxHSCs/hLbx93Yp\nREQe506gbwUQIyK9RCQAzpOey2tscxTAlQAgIhfAGejN36fSgPQCDlkkIuNqMNBV1QZgBoBVAPbB\nOZolWURmi8gNrs2eAnC/iOwCsBjAVFXVpir6bKUXVnDIIhEZlp87G6nqSjhPdlZf93y1x3sBjPFs\naZ6lqkgvKMe4vs3fd09E1BxMc6VobokVVpuDQxaJyLBME+j/mzaXXS5EZEzmCXTXkEWOQSciozJR\noDtb6BEc5UJEBmWeQC8sR3hIIFr5+3q7FCKiJmGeQC+oQI/27D8nIuMyTaAfLSjnCBciMjRTBHqV\n3YGsogpeJUpEhmaKQM86YYFDOWSRiIzNFIF+vNgCAOgaykAnIuMyRaCXWqsAACGt3JrpgIjovGSS\nQLcDYKATkbGZI9AtNgBAUCADnYiMyxSBXmZ1BnowA52IDMwUgV7iCvSgAAY6ERmXKQK9zGpDUIAv\nfHzE26UQETUZ8wQ6u1uIyOBMEeglVhv7z4nI8EwR6GVWG4I5ZJGIDM4UgV5qsfGEKBEZnjkCnS10\nIjIB8wQ6+9CJyOBMEehlDHQiMgFTBHophy0SkQkYPtCtNjuq7IrgQN5LlIiMzfCBXuaaaZFdLkRk\ndIYPdM60SERmYfxAd03MxbnQicjoTBPobKETkdEZPtA5FzoRmYXhA72EgU5EJmH4QC9jlwsRmYRp\nAp1zuRCR0Rk+0EssvP0cEZmD4QO9zGpDmwBf+PL2c0RkcIYPdM7jQkRmYYpAD2GgE5EJmCLQ2UIn\nIjMwfKCXWW0I4kyLRGQCbgW6iIwXkQMikiIis+p4/nUR2en6+lVETni+1LNTarUjONDf22UQETW5\nBvsiRMQXwBwAVwPIALBVRJar6t6T26jqE9W2fxRAbBPUelZKrVUIDgz2dhlERE3OnRb6cAApqpqm\nqpUAlgC4sZ7tJwNY7IniPKHMaudFRURkCu4EencA6dWWM1zrahGRSAC9AKw+w/PTRSRRRBJzc3Mb\nW+tZKbXwpCgRmYOnT4pOAvCFqtrrelJV56lqnKrGhYeHe/ila7Pa7Ki0OzhskYhMwZ1AzwTQo9py\nhGtdXSahhXW3AJyYi4jMwZ1A3wogRkR6iUgAnKG9vOZGItIfQHsACZ4t8exxpkUiMpMGA11VbQBm\nAFgFYB+AZaqaLCKzReSGaptOArBEVbVpSm28U7efY6ATkQm4lXSquhLAyhrrnq+x/FfPleUZvP0c\nEZmJoa8ULeVc6ERkIsYOdAtvP0dE5mHoQOcNoonITAwd6OxDJyIzMUegB3C2RSIyPkMHepnVhtb+\nvvDzNfSPSUQEwOCBzptbEJGZGDzQ7QjhkEUiMgljB7qlincrIiLTMHSgl1ntHLJIRKZh6EAvsdoY\n6ERkGoYO9DIGOhGZiOEDnaNciMgsDB3o7HIhIjMxbKBX2hyotDkY6ERkGoYNdN6tiIjMxrCBzrnQ\nichsjB/obKETkUkYNtA5FzoRmY1hA72EfehEZDKGDXS20InIbIwf6DwpSkQmYdhALzl5g+gABjoR\nmYNhA73MagcATp9LRKZh2EAvtVahlb8Pbz9HRKZh2LQrtdoRHOjv7TKIiJqNgQPdhmB2txCRiRg2\n0Dl1LhGZjWEDvZRT5xKRyRg30C0MdCIyF8MGelmljRcVEZGpGDbQSy3sQyciczFuoFttCGGgE5GJ\nGDLQq+wOWG0OttCJyFQMGei8/RwRmZEhA/3k3YrY5UJEZmLoQGcLnYjMxJCBzrnQiciM3Ap0ERkv\nIgdEJEVEZp1hm9tFZK+IJIvIZ54ts3FOzYXOuVyIyEQabMKKiC+AOQCuBpABYKuILFfVvdW2iQHw\nLIAxqlooIp2aqmB3nJwLnbMtEpGZuNNCHw4gRVXTVLUSwBIAN9bY5n4Ac1S1EABUNcezZTZOqbUK\nAG9uQUTm4k6gdweQXm05w7Wuur4A+orIBhHZJCLj69qRiEwXkUQRSczNzT27it1QeqqFzj50IjIP\nT50U9QMQA2AcgMkA5otIu5obqeo8VY1T1bjw8HAPvXRtHIdORGbkTqBnAuhRbTnCta66DADLVbVK\nVQ8B+BXOgPeKUqsNgX4+8Oft54jIRNxJvK0AYkSkl4gEAJgEYHmNbb6Bs3UOEekIZxdMmgfrbJRS\nqw0hHLJIRCbTYKCrqg3ADACrAOwDsExVk0Vktojc4NpsFYB8EdkLYA2AP6hqflMV3RDOtEhEZuRW\n6qnqSgAra6x7vtpjBfCk68vryni3IiIyIUN2MpfwfqJEZEKGDHS20InIjBjoREQGYchAL2WXCxGZ\nkGEDncMWichsDBfoNrsDlioHggIY6ERkLoYL9FMzLbKFTkQmY7hAL3HNtMi50InIbAwX6Cdb6Dwp\nSkRmY7hAP3k/UQ5bJCKzYaATERmE4QKdN4gmIrMyXKCXum4QzWGLRGQ2xgt0VwudFxYRkdkYNtA5\nyoWIzMZwgV5mtSGAt58jIhMyXOqVWG0IYeuciEzIcIFexpkWicikDBnoHINORGZkuEAvsTDQicic\nDBfoZZU2XlRERKZkuEAvtbAPnYjMyXiBbrVz6lwiMiUDBnoV+9CJyJQMFeinbj/HQCciEzJUoJdV\num4/x0AnIhMyVKBzLnQiMjNDBTrnQiciMzNUoJdYONMiEZmXoQK9jF0uRGRihgp09qETkZkx0ImI\nDMJQgc4uFyIyM0MFeilPihKRiRkr0Cudt58L8DPUj0VE5BZDJV8p50InIhMzVKA7bz/HmRaJyJwM\nFeilVhuCA/29XQYRkVcYMNDZQicic3Ir0EVkvIgcEJEUEZlVx/NTRSRXRHa6vu7zfKkNK7Pa2YdO\nRKbVYPqJiC+AOQCuBpABYKuILFfVvTU2XaqqM5qgRrccOF6CgzkluKh7d2+VQETkVe600IcDSFHV\nNFWtBLAEwI1NW1bjlFiq8NCn2xAc6I8nrurr7XKIiLzCnUDvDiC92nKGa11Nt4pIkoh8ISI96tqR\niEwXkUQRSczNzT2LcmtTVfzh8yQcKSjHnCmx6NS2lUf2S0R0vvHUSdEVAKJUdRCAHwB8XNdGqjpP\nVeNUNS48PNwjLzx/XRq+Tz6OWeP7Y0TvMI/sk4jofOROoGcCqN7ijnCtO0VV81XV6lp8H8BQz5RX\nv01p+Xj5+wOYMLAL7rukV3O8JBFRi+VOoG8FECMivUQkAMAkAMurbyAiXast3gBgn+dKrFt2sQUz\nPtuByLA2ePnWQRCRpn5JIqIWrcFRLqpqE5EZAFYB8AWwQFWTRWQ2gERVXQ7gMRG5AYANQAGAqU1Y\nM6rsDjyyaDvKrDZ8dv8IhLTixURERG4N2lbVlQBW1lj3fLXHzwJ41rOlndk/V+5H4pFCvDU5Fn07\nhzTXyxIRtWjn3ZWi8UnHsDT1KUIAAAPJSURBVGDDIUwdHYUbBnfzdjlERC3GeRfo7dsE4OoBnfHH\nCRd4uxQiohblvLtOfkyfjhjTp6O3yyAianHOuxY6ERHVjYFORGQQDHQiIoNgoBMRGQQDnYjIIBjo\nREQGwUAnIjIIBjoRkUGIqnrnhUVyARxpYLOOAPKaoZyWjsfBicfBicfByazHIVJV67yhhNcC3R0i\nkqiqcd6uw9t4HJx4HJx4HJx4HGpjlwsRkUEw0ImIDKKlB/o8bxfQQvA4OPE4OPE4OPE41NCi+9CJ\niMh9Lb2FTkREbmKgExEZRIsMdBEZLyIHRCRFRGZ5u57mJCILRCRHRPZUW9dBRH4QkYOuf9t7s8am\nJiI9RGSNiOwVkWQRedy13lTHAQBEpJWIbBGRXa5j8YJrfS8R2ez6HVkqIgHerrU5iIiviOwQkXjX\nsimPw5m0uEAXEV8AcwBcB2AAgMkiMsC7VTWrjwCMr7FuFoCfVDUGwE+uZSOzAXhKVQcAGAngEdd7\nwGzHAQCsAK5Q1cEAhgAYLyIjAbwM4HVV7QOgEMA0L9bYnB4HsK/aslmPQ51aXKADGA4gRVXTVLUS\nwBIAN3q5pmajqr8AKKix+kYAH7sefwzgpmYtqpmpapaqbnc9LoHzF7g7THYcAECdSl2L/q4vBXAF\ngC9c601xLEQkAsD1AN53LQtMeBzq0xIDvTuA9GrLGa51ZtZZVbNcj48D6OzNYpqTiEQBiAWwGSY9\nDq5uhp0AcgD8ACAVwAlVtbk2McvvyBsAngHgcC2HwZzH4YxaYqBTPdQ5ztQUY01FJBjAlwB+r6rF\n1Z8z03FQVbuqDgEQAecn2P5eLqnZichEADmqus3btbRkft4uoA6ZAHpUW45wrTOzbBHpqqpZItIV\nzpaaoYmIP5xhvkhVv3KtNt1xqE5VT4jIGgCjALQTET9X69QMvyNjANwgIhMAtALQFsCbMN9xqFdL\nbKFvBRDjOnsdAGASgOVersnblgO4x/X4HgDferGWJufqG/0AwD5V/Xe1p0x1HABARMJFpJ3rcWsA\nV8N5TmENgNtcmxn+WKjqs6oaoapRcGbCalW9AyY7Dg1pkVeKuv4KvwHAF8ACVf27l0tqNiKyGMA4\nOKcGzQbwFwDfAFgGoCecUw7frqo1T5wahoiMBbAOwG78r7/0j3D2o5vmOACAiAyC82SfL5wNsGWq\nOltEesM5YKADgB0A7lRVq/cqbT4iMg7A06o60czHoS4tMtCJiKjxWmKXCxERnQUGOhGRQTDQiYgM\ngoFORGQQDHQiIoNgoBMRGQQDnYjIIP4Puhy3LlVZejAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBTReWHxz4Ml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}