{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN_ascending_layers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM/dbymC1lA6ut5LdMQrzRy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamilo116/KNN/blob/master/KNN_ascending_layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7ReM7FU-xs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import sys\n",
        "from random import shuffle\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms as transforms\n",
        "import timeit\n",
        "\n",
        "np.random.seed(4) \n",
        "torch.manual_seed(4) \n",
        "torch.cuda.manual_seed(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYIMZ8QyYewD",
        "colab_type": "code",
        "outputId": "f5791a5e-b848-4b07-963b-2dd470466963",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "! git clone https://github.com/wang-chen/kervolution.git \n",
        "\n",
        "sys.path.append(\"kervolution/\")\n",
        "from kervolution import Kerv2d\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'kervolution'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects:  16% (1/6)\u001b[K\rremote: Counting objects:  33% (2/6)\u001b[K\rremote: Counting objects:  50% (3/6)\u001b[K\rremote: Counting objects:  66% (4/6)\u001b[K\rremote: Counting objects:  83% (5/6)\u001b[K\rremote: Counting objects: 100% (6/6)\u001b[K\rremote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects:  16% (1/6)\u001b[K\rremote: Compressing objects:  33% (2/6)\u001b[K\rremote: Compressing objects:  50% (3/6)\u001b[K\rremote: Compressing objects:  66% (4/6)\u001b[K\rremote: Compressing objects:  83% (5/6)\u001b[K\rremote: Compressing objects: 100% (6/6)\u001b[K\rremote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 53 (delta 2), reused 0 (delta 0), pack-reused 47\u001b[K\n",
            "Unpacking objects:   1% (1/53)   \rUnpacking objects:   3% (2/53)   \rUnpacking objects:   5% (3/53)   \rUnpacking objects:   7% (4/53)   \rUnpacking objects:   9% (5/53)   \rUnpacking objects:  11% (6/53)   \rUnpacking objects:  13% (7/53)   \rUnpacking objects:  15% (8/53)   \rUnpacking objects:  16% (9/53)   \rUnpacking objects:  18% (10/53)   \rUnpacking objects:  20% (11/53)   \rUnpacking objects:  22% (12/53)   \rUnpacking objects:  24% (13/53)   \rUnpacking objects:  26% (14/53)   \rUnpacking objects:  28% (15/53)   \rUnpacking objects:  30% (16/53)   \rUnpacking objects:  32% (17/53)   \rUnpacking objects:  33% (18/53)   \rUnpacking objects:  35% (19/53)   \rUnpacking objects:  37% (20/53)   \rUnpacking objects:  39% (21/53)   \rUnpacking objects:  41% (22/53)   \rUnpacking objects:  43% (23/53)   \rUnpacking objects:  45% (24/53)   \rUnpacking objects:  47% (25/53)   \rUnpacking objects:  49% (26/53)   \rUnpacking objects:  50% (27/53)   \rUnpacking objects:  52% (28/53)   \rUnpacking objects:  54% (29/53)   \rUnpacking objects:  56% (30/53)   \rUnpacking objects:  58% (31/53)   \rUnpacking objects:  60% (32/53)   \rUnpacking objects:  62% (33/53)   \rUnpacking objects:  64% (34/53)   \rUnpacking objects:  66% (35/53)   \rUnpacking objects:  67% (36/53)   \rUnpacking objects:  69% (37/53)   \rUnpacking objects:  71% (38/53)   \rUnpacking objects:  73% (39/53)   \rUnpacking objects:  75% (40/53)   \rUnpacking objects:  77% (41/53)   \rUnpacking objects:  79% (42/53)   \rUnpacking objects:  81% (43/53)   \rUnpacking objects:  83% (44/53)   \rUnpacking objects:  84% (45/53)   \rUnpacking objects:  86% (46/53)   \rUnpacking objects:  88% (47/53)   \rUnpacking objects:  90% (48/53)   \rUnpacking objects:  92% (49/53)   \rUnpacking objects:  94% (50/53)   \rUnpacking objects:  96% (51/53)   \rUnpacking objects:  98% (52/53)   \rUnpacking objects: 100% (53/53)   \rUnpacking objects: 100% (53/53), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvbKg4VJXKY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LIMIT_IMAGES_NUM = 1000\n",
        "train_test_split_size = 0.2\n",
        "image_resize = (100, 100)\n",
        "batch_size = 64\n",
        "num_workers = 0\n",
        "\n",
        "out_1 = 16\n",
        "out_2 = 32\n",
        "out_3 = 64\n",
        "out_4 = 128\n",
        "\n",
        "\n",
        "k_size_1 = 3\n",
        "padding_1 = 1\n",
        "in_channels = 3\n",
        "\n",
        "kernel_size = 3\n",
        "num_epochs = 100\n",
        "\n",
        "learning_rate = 0.00012\n",
        "weight_decay = 0\n",
        "\n",
        "MALIGNANT_DATASET = '/content/drive/My Drive/Colab_data/malignant/malignant/'\n",
        "BENIGN_DATASET = '/content/drive/My Drive/Colab_data/benign/benign/'\n",
        "DATA_FOLDER = '/content/drive/My Drive/Colab_data/'\n",
        "model_backup_path = os.path.join(DATA_FOLDER, 'backup_model') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMOHez_kHZD6",
        "colab_type": "code",
        "outputId": "eb5e029a-e3df-44ca-c621-f8ac0061464b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b8P1NdXfVdX",
        "colab_type": "code",
        "outputId": "f954088c-9f86-4178-8daf-551fda310d61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "benign_file_list = sorted(os.listdir(BENIGN_DATASET))\n",
        "malignant_file_list = sorted(os.listdir(MALIGNANT_DATASET))\n",
        "shuffle(benign_file_list)\n",
        "shuffle(malignant_file_list)\n",
        "benign_file_list = benign_file_list[:LIMIT_IMAGES_NUM]\n",
        "malignant_file_list = malignant_file_list[:LIMIT_IMAGES_NUM]\n",
        "\n",
        "print(f\"Number of benign {len(benign_file_list)} images\")\n",
        "print(f\"Number of malignant {len(malignant_file_list)} images\")\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize(image_resize),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of benign 1000 images\n",
            "Number of malignant 1000 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGDQfal74BLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "benign_dict = {filename: 0 for filename in benign_file_list}\n",
        "malignant_dict = {filename: 1 for filename in malignant_file_list}\n",
        "img_class_dict = {**benign_dict , **malignant_dict}\n",
        "labeled_data = pd.Series(img_class_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvAAOqmVfVll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IsicDataset(Dataset):\n",
        "    def __init__(self, data_folder, labeled_data, \n",
        "                 transform=transforms.Compose([transforms.ToTensor()])):\n",
        "        self.labeled_data = labeled_data\n",
        "        self.transform = transform\n",
        "        self.data_folder = data_folder\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labeled_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        label = self.labeled_data[index]\n",
        "        if label == 0:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"benign\", \"benign\", index ))\n",
        "        else:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"malignant\", \"malignant\", index ))\n",
        "        image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "    @property\n",
        "    def labels(self):\n",
        "      return self.labeled_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSuYqjLAYrWA",
        "colab_type": "code",
        "outputId": "812fa755-10bf-4edf-8a4c-d99b577df88c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        }
      },
      "source": [
        "dataset = IsicDataset(DATA_FOLDER, labeled_data, transform=data_transforms)\n",
        "print(dataset.labels)\n",
        "\n",
        "X_train, X_test = train_test_split(dataset.labels, test_size=train_test_split_size)\n",
        "print(\"number of training data: \",len(X_train))\n",
        "print(\"number of testing  data: \",len(X_test))\n",
        "\n",
        "train_sampler = SubsetRandomSampler(list(X_train.index))\n",
        "valid_sampler = SubsetRandomSampler(list(X_test.index))\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ISIC_0000113.jpeg    0\n",
            "ISIC_0001328.jpeg    0\n",
            "ISIC_0000095.jpeg    0\n",
            "ISIC_0000200.jpeg    0\n",
            "ISIC_0001279.jpeg    0\n",
            "                    ..\n",
            "ISIC_0010872.jpeg    1\n",
            "ISIC_0011039.jpeg    1\n",
            "ISIC_0012435.jpeg    1\n",
            "ISIC_0013472.jpeg    1\n",
            "ISIC_0024853.jpg     1\n",
            "Length: 2000, dtype: int64\n",
            "number of training data:  1600\n",
            "number of testing  data:  400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e8nFBR6Yug5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "def train(model, train_loader ,loss_fn, optimizer, num_epochs=1, starting_from_epoch=1):\n",
        "    total_loss =0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
        "        model.train()\n",
        "\n",
        "        for t, (x, y) in enumerate(train_loader):\n",
        "            x_var = Variable(x.type(gpu_dtype))\n",
        "            y_var = Variable(y.type(gpu_dtype).long())\n",
        "            scores = model(x_var)\n",
        "            loss = loss_fn(scores, y_var)\n",
        "            total_loss += loss.data\n",
        "            \n",
        "            if (t + 1) % print_every == 0:\n",
        "                avg_loss = total_loss/print_every\n",
        "                print('t = %d, avg_loss = %.4f' % (t + 1, avg_loss) )\n",
        "                avg_loss_list.append(avg_loss)\n",
        "                total_loss = 0\n",
        "                \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        acc = check_accuracy(model_gpu, valid_loader)\n",
        "        print('acc = %f' %(acc))\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model_gpu.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            'acc_list': acc_list,\n",
        "            }, model_backup_path)\n",
        "            \n",
        "def check_accuracy(model, loader):\n",
        "    print('Checking accuracy on test set')   \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval() \n",
        "    for x, y in loader:\n",
        "        x_var = Variable(x.type(gpu_dtype))\n",
        "\n",
        "        scores = model(x_var)\n",
        "        _, preds = scores.data.cpu().max(1)\n",
        "        num_correct += (preds == y).sum()\n",
        "        num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    acc_list.append(acc)\n",
        "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "    return acc\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggvpMu36Yw2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.size()\n",
        "        return x.view(N, -1)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-gYHw0Jlbwt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "outputId": "64564b49-2d63-4105-a906-61d00a4c4408"
      },
      "source": [
        "print_every = 2\n",
        "gpu_dtype = torch.cuda.FloatTensor\n",
        "\n",
        "\n",
        "'''\n",
        "Kerv2d\n",
        "kervolution with following options:\n",
        "kernel_type: [linear, polynomial, gaussian, etc.]\n",
        "default is convolution:\n",
        "          kernel_type --> linear,\n",
        "balance, power, gamma is valid only when the kernel_type is specified\n",
        "if learnable_kernel = True,  they just be the initial value of learable parameters\n",
        "if learnable_kernel = False, they are the value of kernel_type's parameter\n",
        "the parameter [power] cannot be learned due to integer limitation\n",
        "dilation (int or tuple, optional): Spacing between kernel\n",
        "elements. Default: 1\n",
        "groups (int, optional): Number of blocked connections from input\n",
        "channels to output channels. Default: 1\n",
        "bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n",
        "kernel_type (str), Default: 'linear'\n",
        "learnable_kernel (bool): Learnable kernel parameters.  Default: False \n",
        "balance: 0, 1\n",
        "power: 3, 4, 5\n",
        "gamma:\n",
        "'''\n",
        "\n",
        "\n",
        "model_base = nn.Sequential( \n",
        "                nn.Kerv2d(in_channels , out_1, padding=padding_1, dilation=1, groups=1, bias=True, \n",
        "                          kernel_type='linear', kernel_size=k_size_1,# learnable_kernel=True,\n",
        "                          #kernel_regularizer=True, stride=1, balance=1, power=3, gamma=1\n",
        "                          ), \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_1),\n",
        "                nn.Conv2d(out_1 , out_2, padding= padding_1, kernel_size=k_size_1, stride=1), \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_2),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_2 , out_3, padding= padding_1, kernel_size=k_size_1, stride=1),  \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_3),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_3 , out_4, padding= padding_1, kernel_size=k_size_1, stride=1),  \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_4),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Dropout(0.5),\n",
        "                Flatten(),\n",
        "                nn.Linear(18432,64),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Linear(64,2)\n",
        "            )\n",
        "model_gpu = model_base.type(gpu_dtype)\n",
        "print(model_gpu)\n",
        "loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Kerv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (4): ReLU(inplace=True)\n",
            "  (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (7): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (8): ReLU(inplace=True)\n",
            "  (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (11): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (12): ReLU(inplace=True)\n",
            "  (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (15): Dropout(p=0.5, inplace=False)\n",
            "  (16): Flatten()\n",
            "  (17): Linear(in_features=18432, out_features=64, bias=True)\n",
            "  (18): ReLU(inplace=True)\n",
            "  (19): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgmexhBRZAK6",
        "colab_type": "code",
        "outputId": "03c9a964-82db-4186-9a92-e197fb0a0609",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs)\n",
        "check_accuracy(model_gpu, valid_loader)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 1 / 100\n",
            "t = 2, avg_loss = 0.7343\n",
            "t = 4, avg_loss = 0.4845\n",
            "t = 6, avg_loss = 0.5169\n",
            "t = 8, avg_loss = 0.4695\n",
            "t = 10, avg_loss = 0.5214\n",
            "t = 12, avg_loss = 0.4723\n",
            "t = 14, avg_loss = 0.4714\n",
            "t = 16, avg_loss = 0.3732\n",
            "t = 18, avg_loss = 0.3732\n",
            "t = 20, avg_loss = 0.4001\n",
            "t = 22, avg_loss = 0.3897\n",
            "t = 24, avg_loss = 0.5058\n",
            "Checking accuracy on test set\n",
            "Got 204 / 400 correct (51.00)\n",
            "acc = 0.510000\n",
            "Starting epoch 2 / 100\n",
            "t = 2, avg_loss = 0.6267\n",
            "t = 4, avg_loss = 0.3363\n",
            "t = 6, avg_loss = 0.3615\n",
            "t = 8, avg_loss = 0.3992\n",
            "t = 10, avg_loss = 0.4310\n",
            "t = 12, avg_loss = 0.3216\n",
            "t = 14, avg_loss = 0.3284\n",
            "t = 16, avg_loss = 0.2763\n",
            "t = 18, avg_loss = 0.3513\n",
            "t = 20, avg_loss = 0.2985\n",
            "t = 22, avg_loss = 0.3314\n",
            "t = 24, avg_loss = 0.3484\n",
            "Checking accuracy on test set\n",
            "Got 264 / 400 correct (66.00)\n",
            "acc = 0.660000\n",
            "Starting epoch 3 / 100\n",
            "t = 2, avg_loss = 0.3745\n",
            "t = 4, avg_loss = 0.2499\n",
            "t = 6, avg_loss = 0.2651\n",
            "t = 8, avg_loss = 0.2812\n",
            "t = 10, avg_loss = 0.3406\n",
            "t = 12, avg_loss = 0.3771\n",
            "t = 14, avg_loss = 0.3368\n",
            "t = 16, avg_loss = 0.4151\n",
            "t = 18, avg_loss = 0.2835\n",
            "t = 20, avg_loss = 0.3923\n",
            "t = 22, avg_loss = 0.3893\n",
            "t = 24, avg_loss = 0.2424\n",
            "Checking accuracy on test set\n",
            "Got 336 / 400 correct (84.00)\n",
            "acc = 0.840000\n",
            "Starting epoch 4 / 100\n",
            "t = 2, avg_loss = 0.4351\n",
            "t = 4, avg_loss = 0.2822\n",
            "t = 6, avg_loss = 0.2132\n",
            "t = 8, avg_loss = 0.2148\n",
            "t = 10, avg_loss = 0.3509\n",
            "t = 12, avg_loss = 0.2992\n",
            "t = 14, avg_loss = 0.2612\n",
            "t = 16, avg_loss = 0.3251\n",
            "t = 18, avg_loss = 0.2419\n",
            "t = 20, avg_loss = 0.2605\n",
            "t = 22, avg_loss = 0.2694\n",
            "t = 24, avg_loss = 0.2528\n",
            "Checking accuracy on test set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 5 / 100\n",
            "t = 2, avg_loss = 0.3545\n",
            "t = 4, avg_loss = 0.1840\n",
            "t = 6, avg_loss = 0.2555\n",
            "t = 8, avg_loss = 0.2063\n",
            "t = 10, avg_loss = 0.2436\n",
            "t = 12, avg_loss = 0.3749\n",
            "t = 14, avg_loss = 0.2758\n",
            "t = 16, avg_loss = 0.2424\n",
            "t = 18, avg_loss = 0.2364\n",
            "t = 20, avg_loss = 0.2556\n",
            "t = 22, avg_loss = 0.2853\n",
            "t = 24, avg_loss = 0.2987\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 6 / 100\n",
            "t = 2, avg_loss = 0.3364\n",
            "t = 4, avg_loss = 0.2516\n",
            "t = 6, avg_loss = 0.1918\n",
            "t = 8, avg_loss = 0.3199\n",
            "t = 10, avg_loss = 0.2695\n",
            "t = 12, avg_loss = 0.2870\n",
            "t = 14, avg_loss = 0.2559\n",
            "t = 16, avg_loss = 0.2196\n",
            "t = 18, avg_loss = 0.1930\n",
            "t = 20, avg_loss = 0.1956\n",
            "t = 22, avg_loss = 0.3119\n",
            "t = 24, avg_loss = 0.2449\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 7 / 100\n",
            "t = 2, avg_loss = 0.2646\n",
            "t = 4, avg_loss = 0.2622\n",
            "t = 6, avg_loss = 0.1779\n",
            "t = 8, avg_loss = 0.1916\n",
            "t = 10, avg_loss = 0.2143\n",
            "t = 12, avg_loss = 0.3074\n",
            "t = 14, avg_loss = 0.1785\n",
            "t = 16, avg_loss = 0.2212\n",
            "t = 18, avg_loss = 0.2441\n",
            "t = 20, avg_loss = 0.1868\n",
            "t = 22, avg_loss = 0.1827\n",
            "t = 24, avg_loss = 0.2671\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 8 / 100\n",
            "t = 2, avg_loss = 0.3312\n",
            "t = 4, avg_loss = 0.1529\n",
            "t = 6, avg_loss = 0.1865\n",
            "t = 8, avg_loss = 0.2302\n",
            "t = 10, avg_loss = 0.1695\n",
            "t = 12, avg_loss = 0.2996\n",
            "t = 14, avg_loss = 0.2229\n",
            "t = 16, avg_loss = 0.1870\n",
            "t = 18, avg_loss = 0.2225\n",
            "t = 20, avg_loss = 0.1294\n",
            "t = 22, avg_loss = 0.1351\n",
            "t = 24, avg_loss = 0.2384\n",
            "Checking accuracy on test set\n",
            "Got 351 / 400 correct (87.75)\n",
            "acc = 0.877500\n",
            "Starting epoch 9 / 100\n",
            "t = 2, avg_loss = 0.2830\n",
            "t = 4, avg_loss = 0.1813\n",
            "t = 6, avg_loss = 0.1277\n",
            "t = 8, avg_loss = 0.1816\n",
            "t = 10, avg_loss = 0.2102\n",
            "t = 12, avg_loss = 0.2353\n",
            "t = 14, avg_loss = 0.1976\n",
            "t = 16, avg_loss = 0.1602\n",
            "t = 18, avg_loss = 0.2053\n",
            "t = 20, avg_loss = 0.2700\n",
            "t = 22, avg_loss = 0.1644\n",
            "t = 24, avg_loss = 0.2357\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 10 / 100\n",
            "t = 2, avg_loss = 0.2296\n",
            "t = 4, avg_loss = 0.1876\n",
            "t = 6, avg_loss = 0.1948\n",
            "t = 8, avg_loss = 0.1814\n",
            "t = 10, avg_loss = 0.1772\n",
            "t = 12, avg_loss = 0.1947\n",
            "t = 14, avg_loss = 0.1717\n",
            "t = 16, avg_loss = 0.2065\n",
            "t = 18, avg_loss = 0.1864\n",
            "t = 20, avg_loss = 0.1332\n",
            "t = 22, avg_loss = 0.1835\n",
            "t = 24, avg_loss = 0.1871\n",
            "Checking accuracy on test set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 11 / 100\n",
            "t = 2, avg_loss = 0.2073\n",
            "t = 4, avg_loss = 0.1529\n",
            "t = 6, avg_loss = 0.1743\n",
            "t = 8, avg_loss = 0.1827\n",
            "t = 10, avg_loss = 0.1017\n",
            "t = 12, avg_loss = 0.1599\n",
            "t = 14, avg_loss = 0.2028\n",
            "t = 16, avg_loss = 0.1135\n",
            "t = 18, avg_loss = 0.2112\n",
            "t = 20, avg_loss = 0.1547\n",
            "t = 22, avg_loss = 0.1707\n",
            "t = 24, avg_loss = 0.1776\n",
            "Checking accuracy on test set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 12 / 100\n",
            "t = 2, avg_loss = 0.2489\n",
            "t = 4, avg_loss = 0.1018\n",
            "t = 6, avg_loss = 0.1441\n",
            "t = 8, avg_loss = 0.1521\n",
            "t = 10, avg_loss = 0.1905\n",
            "t = 12, avg_loss = 0.1705\n",
            "t = 14, avg_loss = 0.1360\n",
            "t = 16, avg_loss = 0.1783\n",
            "t = 18, avg_loss = 0.1468\n",
            "t = 20, avg_loss = 0.2262\n",
            "t = 22, avg_loss = 0.1792\n",
            "t = 24, avg_loss = 0.2112\n",
            "Checking accuracy on test set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 13 / 100\n",
            "t = 2, avg_loss = 0.2363\n",
            "t = 4, avg_loss = 0.1520\n",
            "t = 6, avg_loss = 0.1332\n",
            "t = 8, avg_loss = 0.2575\n",
            "t = 10, avg_loss = 0.1578\n",
            "t = 12, avg_loss = 0.1310\n",
            "t = 14, avg_loss = 0.1629\n",
            "t = 16, avg_loss = 0.1030\n",
            "t = 18, avg_loss = 0.1260\n",
            "t = 20, avg_loss = 0.1960\n",
            "t = 22, avg_loss = 0.2211\n",
            "t = 24, avg_loss = 0.1462\n",
            "Checking accuracy on test set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 14 / 100\n",
            "t = 2, avg_loss = 0.2006\n",
            "t = 4, avg_loss = 0.1650\n",
            "t = 6, avg_loss = 0.1402\n",
            "t = 8, avg_loss = 0.0868\n",
            "t = 10, avg_loss = 0.1004\n",
            "t = 12, avg_loss = 0.0983\n",
            "t = 14, avg_loss = 0.1309\n",
            "t = 16, avg_loss = 0.1374\n",
            "t = 18, avg_loss = 0.1387\n",
            "t = 20, avg_loss = 0.1350\n",
            "t = 22, avg_loss = 0.1228\n",
            "t = 24, avg_loss = 0.1313\n",
            "Checking accuracy on test set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 15 / 100\n",
            "t = 2, avg_loss = 0.1310\n",
            "t = 4, avg_loss = 0.0934\n",
            "t = 6, avg_loss = 0.1930\n",
            "t = 8, avg_loss = 0.1242\n",
            "t = 10, avg_loss = 0.1055\n",
            "t = 12, avg_loss = 0.1637\n",
            "t = 14, avg_loss = 0.1229\n",
            "t = 16, avg_loss = 0.1228\n",
            "t = 18, avg_loss = 0.1691\n",
            "t = 20, avg_loss = 0.0935\n",
            "t = 22, avg_loss = 0.1291\n",
            "t = 24, avg_loss = 0.0996\n",
            "Checking accuracy on test set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 16 / 100\n",
            "t = 2, avg_loss = 0.1585\n",
            "t = 4, avg_loss = 0.1290\n",
            "t = 6, avg_loss = 0.1334\n",
            "t = 8, avg_loss = 0.1413\n",
            "t = 10, avg_loss = 0.1505\n",
            "t = 12, avg_loss = 0.1238\n",
            "t = 14, avg_loss = 0.1148\n",
            "t = 16, avg_loss = 0.1066\n",
            "t = 18, avg_loss = 0.1105\n",
            "t = 20, avg_loss = 0.1359\n",
            "t = 22, avg_loss = 0.0920\n",
            "t = 24, avg_loss = 0.1139\n",
            "Checking accuracy on test set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 17 / 100\n",
            "t = 2, avg_loss = 0.0968\n",
            "t = 4, avg_loss = 0.0848\n",
            "t = 6, avg_loss = 0.1007\n",
            "t = 8, avg_loss = 0.0512\n",
            "t = 10, avg_loss = 0.1163\n",
            "t = 12, avg_loss = 0.1137\n",
            "t = 14, avg_loss = 0.1079\n",
            "t = 16, avg_loss = 0.1363\n",
            "t = 18, avg_loss = 0.1179\n",
            "t = 20, avg_loss = 0.1015\n",
            "t = 22, avg_loss = 0.0801\n",
            "t = 24, avg_loss = 0.0997\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 18 / 100\n",
            "t = 2, avg_loss = 0.1678\n",
            "t = 4, avg_loss = 0.1184\n",
            "t = 6, avg_loss = 0.0760\n",
            "t = 8, avg_loss = 0.0583\n",
            "t = 10, avg_loss = 0.0955\n",
            "t = 12, avg_loss = 0.1674\n",
            "t = 14, avg_loss = 0.1758\n",
            "t = 16, avg_loss = 0.1064\n",
            "t = 18, avg_loss = 0.0954\n",
            "t = 20, avg_loss = 0.0507\n",
            "t = 22, avg_loss = 0.0895\n",
            "t = 24, avg_loss = 0.1416\n",
            "Checking accuracy on test set\n",
            "Got 345 / 400 correct (86.25)\n",
            "acc = 0.862500\n",
            "Starting epoch 19 / 100\n",
            "t = 2, avg_loss = 0.1772\n",
            "t = 4, avg_loss = 0.1132\n",
            "t = 6, avg_loss = 0.0389\n",
            "t = 8, avg_loss = 0.1133\n",
            "t = 10, avg_loss = 0.1130\n",
            "t = 12, avg_loss = 0.0860\n",
            "t = 14, avg_loss = 0.0466\n",
            "t = 16, avg_loss = 0.1155\n",
            "t = 18, avg_loss = 0.0751\n",
            "t = 20, avg_loss = 0.1033\n",
            "t = 22, avg_loss = 0.0793\n",
            "t = 24, avg_loss = 0.1194\n",
            "Checking accuracy on test set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 20 / 100\n",
            "t = 2, avg_loss = 0.1625\n",
            "t = 4, avg_loss = 0.0648\n",
            "t = 6, avg_loss = 0.0617\n",
            "t = 8, avg_loss = 0.1203\n",
            "t = 10, avg_loss = 0.0575\n",
            "t = 12, avg_loss = 0.0757\n",
            "t = 14, avg_loss = 0.0477\n",
            "t = 16, avg_loss = 0.0690\n",
            "t = 18, avg_loss = 0.0630\n",
            "t = 20, avg_loss = 0.0708\n",
            "t = 22, avg_loss = 0.0934\n",
            "t = 24, avg_loss = 0.1097\n",
            "Checking accuracy on test set\n",
            "Got 351 / 400 correct (87.75)\n",
            "acc = 0.877500\n",
            "Starting epoch 21 / 100\n",
            "t = 2, avg_loss = 0.0740\n",
            "t = 4, avg_loss = 0.1279\n",
            "t = 6, avg_loss = 0.0950\n",
            "t = 8, avg_loss = 0.0567\n",
            "t = 10, avg_loss = 0.0446\n",
            "t = 12, avg_loss = 0.0460\n",
            "t = 14, avg_loss = 0.0449\n",
            "t = 16, avg_loss = 0.0957\n",
            "t = 18, avg_loss = 0.0410\n",
            "t = 20, avg_loss = 0.0612\n",
            "t = 22, avg_loss = 0.0639\n",
            "t = 24, avg_loss = 0.1175\n",
            "Checking accuracy on test set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 22 / 100\n",
            "t = 2, avg_loss = 0.1130\n",
            "t = 4, avg_loss = 0.0736\n",
            "t = 6, avg_loss = 0.0716\n",
            "t = 8, avg_loss = 0.0345\n",
            "t = 10, avg_loss = 0.0579\n",
            "t = 12, avg_loss = 0.1157\n",
            "t = 14, avg_loss = 0.0533\n",
            "t = 16, avg_loss = 0.0646\n",
            "t = 18, avg_loss = 0.0685\n",
            "t = 20, avg_loss = 0.0553\n",
            "t = 22, avg_loss = 0.0440\n",
            "t = 24, avg_loss = 0.1087\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 23 / 100\n",
            "t = 2, avg_loss = 0.0780\n",
            "t = 4, avg_loss = 0.0952\n",
            "t = 6, avg_loss = 0.0772\n",
            "t = 8, avg_loss = 0.0761\n",
            "t = 10, avg_loss = 0.0976\n",
            "t = 12, avg_loss = 0.0684\n",
            "t = 14, avg_loss = 0.0750\n",
            "t = 16, avg_loss = 0.0616\n",
            "t = 18, avg_loss = 0.1036\n",
            "t = 20, avg_loss = 0.0555\n",
            "t = 22, avg_loss = 0.0472\n",
            "t = 24, avg_loss = 0.0812\n",
            "Checking accuracy on test set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 24 / 100\n",
            "t = 2, avg_loss = 0.1256\n",
            "t = 4, avg_loss = 0.1155\n",
            "t = 6, avg_loss = 0.0778\n",
            "t = 8, avg_loss = 0.0344\n",
            "t = 10, avg_loss = 0.1547\n",
            "t = 12, avg_loss = 0.0494\n",
            "t = 14, avg_loss = 0.0503\n",
            "t = 16, avg_loss = 0.0651\n",
            "t = 18, avg_loss = 0.0626\n",
            "t = 20, avg_loss = 0.0914\n",
            "t = 22, avg_loss = 0.0706\n",
            "t = 24, avg_loss = 0.0974\n",
            "Checking accuracy on test set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 25 / 100\n",
            "t = 2, avg_loss = 0.0656\n",
            "t = 4, avg_loss = 0.0517\n",
            "t = 6, avg_loss = 0.0434\n",
            "t = 8, avg_loss = 0.0774\n",
            "t = 10, avg_loss = 0.0413\n",
            "t = 12, avg_loss = 0.0706\n",
            "t = 14, avg_loss = 0.0571\n",
            "t = 16, avg_loss = 0.0723\n",
            "t = 18, avg_loss = 0.0533\n",
            "t = 20, avg_loss = 0.0327\n",
            "t = 22, avg_loss = 0.0261\n",
            "t = 24, avg_loss = 0.0880\n",
            "Checking accuracy on test set\n",
            "Got 343 / 400 correct (85.75)\n",
            "acc = 0.857500\n",
            "Starting epoch 26 / 100\n",
            "t = 2, avg_loss = 0.1011\n",
            "t = 4, avg_loss = 0.0574\n",
            "t = 6, avg_loss = 0.0484\n",
            "t = 8, avg_loss = 0.0641\n",
            "t = 10, avg_loss = 0.0622\n",
            "t = 12, avg_loss = 0.0897\n",
            "t = 14, avg_loss = 0.0694\n",
            "t = 16, avg_loss = 0.0413\n",
            "t = 18, avg_loss = 0.0985\n",
            "t = 20, avg_loss = 0.1688\n",
            "t = 22, avg_loss = 0.0910\n",
            "t = 24, avg_loss = 0.0898\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 27 / 100\n",
            "t = 2, avg_loss = 0.0899\n",
            "t = 4, avg_loss = 0.0681\n",
            "t = 6, avg_loss = 0.0418\n",
            "t = 8, avg_loss = 0.0536\n",
            "t = 10, avg_loss = 0.0581\n",
            "t = 12, avg_loss = 0.0684\n",
            "t = 14, avg_loss = 0.0650\n",
            "t = 16, avg_loss = 0.0558\n",
            "t = 18, avg_loss = 0.0545\n",
            "t = 20, avg_loss = 0.0573\n",
            "t = 22, avg_loss = 0.0375\n",
            "t = 24, avg_loss = 0.0573\n",
            "Checking accuracy on test set\n",
            "Got 351 / 400 correct (87.75)\n",
            "acc = 0.877500\n",
            "Starting epoch 28 / 100\n",
            "t = 2, avg_loss = 0.0843\n",
            "t = 4, avg_loss = 0.0333\n",
            "t = 6, avg_loss = 0.0745\n",
            "t = 8, avg_loss = 0.0397\n",
            "t = 10, avg_loss = 0.0397\n",
            "t = 12, avg_loss = 0.0659\n",
            "t = 14, avg_loss = 0.0435\n",
            "t = 16, avg_loss = 0.0749\n",
            "t = 18, avg_loss = 0.0479\n",
            "t = 20, avg_loss = 0.0475\n",
            "t = 22, avg_loss = 0.0747\n",
            "t = 24, avg_loss = 0.0362\n",
            "Checking accuracy on test set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 29 / 100\n",
            "t = 2, avg_loss = 0.0641\n",
            "t = 4, avg_loss = 0.0507\n",
            "t = 6, avg_loss = 0.0379\n",
            "t = 8, avg_loss = 0.0549\n",
            "t = 10, avg_loss = 0.0701\n",
            "t = 12, avg_loss = 0.0766\n",
            "t = 14, avg_loss = 0.0464\n",
            "t = 16, avg_loss = 0.0293\n",
            "t = 18, avg_loss = 0.0289\n",
            "t = 20, avg_loss = 0.0378\n",
            "t = 22, avg_loss = 0.0455\n",
            "t = 24, avg_loss = 0.0628\n",
            "Checking accuracy on test set\n",
            "Got 351 / 400 correct (87.75)\n",
            "acc = 0.877500\n",
            "Starting epoch 30 / 100\n",
            "t = 2, avg_loss = 0.0724\n",
            "t = 4, avg_loss = 0.0620\n",
            "t = 6, avg_loss = 0.0466\n",
            "t = 8, avg_loss = 0.0415\n",
            "t = 10, avg_loss = 0.0905\n",
            "t = 12, avg_loss = 0.0600\n",
            "t = 14, avg_loss = 0.0573\n",
            "t = 16, avg_loss = 0.0555\n",
            "t = 18, avg_loss = 0.0517\n",
            "t = 20, avg_loss = 0.0298\n",
            "t = 22, avg_loss = 0.0473\n",
            "t = 24, avg_loss = 0.0264\n",
            "Checking accuracy on test set\n",
            "Got 344 / 400 correct (86.00)\n",
            "acc = 0.860000\n",
            "Starting epoch 31 / 100\n",
            "t = 2, avg_loss = 0.0815\n",
            "t = 4, avg_loss = 0.0410\n",
            "t = 6, avg_loss = 0.0395\n",
            "t = 8, avg_loss = 0.0601\n",
            "t = 10, avg_loss = 0.0838\n",
            "t = 12, avg_loss = 0.0671\n",
            "t = 14, avg_loss = 0.0330\n",
            "t = 16, avg_loss = 0.0711\n",
            "t = 18, avg_loss = 0.0726\n",
            "t = 20, avg_loss = 0.0715\n",
            "t = 22, avg_loss = 0.0415\n",
            "t = 24, avg_loss = 0.0454\n",
            "Checking accuracy on test set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 32 / 100\n",
            "t = 2, avg_loss = 0.0757\n",
            "t = 4, avg_loss = 0.0274\n",
            "t = 6, avg_loss = 0.0613\n",
            "t = 8, avg_loss = 0.0259\n",
            "t = 10, avg_loss = 0.0392\n",
            "t = 12, avg_loss = 0.0415\n",
            "t = 14, avg_loss = 0.0208\n",
            "t = 16, avg_loss = 0.0538\n",
            "t = 18, avg_loss = 0.0643\n",
            "t = 20, avg_loss = 0.0449\n",
            "t = 22, avg_loss = 0.0278\n",
            "t = 24, avg_loss = 0.0282\n",
            "Checking accuracy on test set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 33 / 100\n",
            "t = 2, avg_loss = 0.0521\n",
            "t = 4, avg_loss = 0.0214\n",
            "t = 6, avg_loss = 0.0341\n",
            "t = 8, avg_loss = 0.0582\n",
            "t = 10, avg_loss = 0.0219\n",
            "t = 12, avg_loss = 0.0395\n",
            "t = 14, avg_loss = 0.0311\n",
            "t = 16, avg_loss = 0.0683\n",
            "t = 18, avg_loss = 0.0497\n",
            "t = 20, avg_loss = 0.0215\n",
            "t = 22, avg_loss = 0.0289\n",
            "t = 24, avg_loss = 0.0253\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 34 / 100\n",
            "t = 2, avg_loss = 0.0449\n",
            "t = 4, avg_loss = 0.0790\n",
            "t = 6, avg_loss = 0.0326\n",
            "t = 8, avg_loss = 0.0159\n",
            "t = 10, avg_loss = 0.0328\n",
            "t = 12, avg_loss = 0.0259\n",
            "t = 14, avg_loss = 0.0214\n",
            "t = 16, avg_loss = 0.0205\n",
            "t = 18, avg_loss = 0.0472\n",
            "t = 20, avg_loss = 0.0250\n",
            "t = 22, avg_loss = 0.0703\n",
            "t = 24, avg_loss = 0.0400\n",
            "Checking accuracy on test set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 35 / 100\n",
            "t = 2, avg_loss = 0.0488\n",
            "t = 4, avg_loss = 0.0162\n",
            "t = 6, avg_loss = 0.0234\n",
            "t = 8, avg_loss = 0.0149\n",
            "t = 10, avg_loss = 0.0325\n",
            "t = 12, avg_loss = 0.0175\n",
            "t = 14, avg_loss = 0.0148\n",
            "t = 16, avg_loss = 0.0186\n",
            "t = 18, avg_loss = 0.0173\n",
            "t = 20, avg_loss = 0.0212\n",
            "t = 22, avg_loss = 0.0395\n",
            "t = 24, avg_loss = 0.0311\n",
            "Checking accuracy on test set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 36 / 100\n",
            "t = 2, avg_loss = 0.0342\n",
            "t = 4, avg_loss = 0.0228\n",
            "t = 6, avg_loss = 0.0189\n",
            "t = 8, avg_loss = 0.0151\n",
            "t = 10, avg_loss = 0.0257\n",
            "t = 12, avg_loss = 0.0310\n",
            "t = 14, avg_loss = 0.0237\n",
            "t = 16, avg_loss = 0.0189\n",
            "t = 18, avg_loss = 0.0295\n",
            "t = 20, avg_loss = 0.0351\n",
            "t = 22, avg_loss = 0.0132\n",
            "t = 24, avg_loss = 0.0142\n",
            "Checking accuracy on test set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 37 / 100\n",
            "t = 2, avg_loss = 0.0372\n",
            "t = 4, avg_loss = 0.0122\n",
            "t = 6, avg_loss = 0.0177\n",
            "t = 8, avg_loss = 0.0043\n",
            "t = 10, avg_loss = 0.0323\n",
            "t = 12, avg_loss = 0.0187\n",
            "t = 14, avg_loss = 0.0301\n",
            "t = 16, avg_loss = 0.0476\n",
            "t = 18, avg_loss = 0.0215\n",
            "t = 20, avg_loss = 0.0442\n",
            "t = 22, avg_loss = 0.0413\n",
            "t = 24, avg_loss = 0.0238\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 38 / 100\n",
            "t = 2, avg_loss = 0.0206\n",
            "t = 4, avg_loss = 0.0465\n",
            "t = 6, avg_loss = 0.0261\n",
            "t = 8, avg_loss = 0.0176\n",
            "t = 10, avg_loss = 0.0124\n",
            "t = 12, avg_loss = 0.0225\n",
            "t = 14, avg_loss = 0.0331\n",
            "t = 16, avg_loss = 0.0215\n",
            "t = 18, avg_loss = 0.0263\n",
            "t = 20, avg_loss = 0.0334\n",
            "t = 22, avg_loss = 0.0227\n",
            "t = 24, avg_loss = 0.0237\n",
            "Checking accuracy on test set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 39 / 100\n",
            "t = 2, avg_loss = 0.0539\n",
            "t = 4, avg_loss = 0.0297\n",
            "t = 6, avg_loss = 0.0130\n",
            "t = 8, avg_loss = 0.0324\n",
            "t = 10, avg_loss = 0.0179\n",
            "t = 12, avg_loss = 0.0199\n",
            "t = 14, avg_loss = 0.0293\n",
            "t = 16, avg_loss = 0.0196\n",
            "t = 18, avg_loss = 0.0260\n",
            "t = 20, avg_loss = 0.0220\n",
            "t = 22, avg_loss = 0.0367\n",
            "t = 24, avg_loss = 0.0412\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 40 / 100\n",
            "t = 2, avg_loss = 0.0296\n",
            "t = 4, avg_loss = 0.0179\n",
            "t = 6, avg_loss = 0.0347\n",
            "t = 8, avg_loss = 0.0150\n",
            "t = 10, avg_loss = 0.0369\n",
            "t = 12, avg_loss = 0.0108\n",
            "t = 14, avg_loss = 0.0174\n",
            "t = 16, avg_loss = 0.0178\n",
            "t = 18, avg_loss = 0.0210\n",
            "t = 20, avg_loss = 0.0069\n",
            "t = 22, avg_loss = 0.0171\n",
            "t = 24, avg_loss = 0.0200\n",
            "Checking accuracy on test set\n",
            "Got 359 / 400 correct (89.75)\n",
            "acc = 0.897500\n",
            "Starting epoch 41 / 100\n",
            "t = 2, avg_loss = 0.0578\n",
            "t = 4, avg_loss = 0.0099\n",
            "t = 6, avg_loss = 0.0066\n",
            "t = 8, avg_loss = 0.0167\n",
            "t = 10, avg_loss = 0.0199\n",
            "t = 12, avg_loss = 0.0228\n",
            "t = 14, avg_loss = 0.0506\n",
            "t = 16, avg_loss = 0.0162\n",
            "t = 18, avg_loss = 0.0192\n",
            "t = 20, avg_loss = 0.0087\n",
            "t = 22, avg_loss = 0.0083\n",
            "t = 24, avg_loss = 0.0294\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 42 / 100\n",
            "t = 2, avg_loss = 0.0265\n",
            "t = 4, avg_loss = 0.0144\n",
            "t = 6, avg_loss = 0.0152\n",
            "t = 8, avg_loss = 0.0080\n",
            "t = 10, avg_loss = 0.0198\n",
            "t = 12, avg_loss = 0.0108\n",
            "t = 14, avg_loss = 0.0135\n",
            "t = 16, avg_loss = 0.0157\n",
            "t = 18, avg_loss = 0.0397\n",
            "t = 20, avg_loss = 0.0226\n",
            "t = 22, avg_loss = 0.0275\n",
            "t = 24, avg_loss = 0.0365\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 43 / 100\n",
            "t = 2, avg_loss = 0.0222\n",
            "t = 4, avg_loss = 0.0154\n",
            "t = 6, avg_loss = 0.0313\n",
            "t = 8, avg_loss = 0.0060\n",
            "t = 10, avg_loss = 0.0094\n",
            "t = 12, avg_loss = 0.0078\n",
            "t = 14, avg_loss = 0.0349\n",
            "t = 16, avg_loss = 0.0294\n",
            "t = 18, avg_loss = 0.0097\n",
            "t = 20, avg_loss = 0.0442\n",
            "t = 22, avg_loss = 0.0122\n",
            "t = 24, avg_loss = 0.0086\n",
            "Checking accuracy on test set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 44 / 100\n",
            "t = 2, avg_loss = 0.0257\n",
            "t = 4, avg_loss = 0.0157\n",
            "t = 6, avg_loss = 0.0200\n",
            "t = 8, avg_loss = 0.0118\n",
            "t = 10, avg_loss = 0.0346\n",
            "t = 12, avg_loss = 0.0243\n",
            "t = 14, avg_loss = 0.0082\n",
            "t = 16, avg_loss = 0.0099\n",
            "t = 18, avg_loss = 0.0125\n",
            "t = 20, avg_loss = 0.0283\n",
            "t = 22, avg_loss = 0.0141\n",
            "t = 24, avg_loss = 0.0202\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 45 / 100\n",
            "t = 2, avg_loss = 0.0183\n",
            "t = 4, avg_loss = 0.0241\n",
            "t = 6, avg_loss = 0.0238\n",
            "t = 8, avg_loss = 0.0208\n",
            "t = 10, avg_loss = 0.0350\n",
            "t = 12, avg_loss = 0.0152\n",
            "t = 14, avg_loss = 0.0207\n",
            "t = 16, avg_loss = 0.0133\n",
            "t = 18, avg_loss = 0.0154\n",
            "t = 20, avg_loss = 0.0316\n",
            "t = 22, avg_loss = 0.0083\n",
            "t = 24, avg_loss = 0.0148\n",
            "Checking accuracy on test set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 46 / 100\n",
            "t = 2, avg_loss = 0.0290\n",
            "t = 4, avg_loss = 0.0161\n",
            "t = 6, avg_loss = 0.0364\n",
            "t = 8, avg_loss = 0.0099\n",
            "t = 10, avg_loss = 0.0343\n",
            "t = 12, avg_loss = 0.0156\n",
            "t = 14, avg_loss = 0.0244\n",
            "t = 16, avg_loss = 0.0356\n",
            "t = 18, avg_loss = 0.0325\n",
            "t = 20, avg_loss = 0.0113\n",
            "t = 22, avg_loss = 0.0541\n",
            "t = 24, avg_loss = 0.0127\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 47 / 100\n",
            "t = 2, avg_loss = 0.0226\n",
            "t = 4, avg_loss = 0.0216\n",
            "t = 6, avg_loss = 0.0210\n",
            "t = 8, avg_loss = 0.0122\n",
            "t = 10, avg_loss = 0.0149\n",
            "t = 12, avg_loss = 0.0641\n",
            "t = 14, avg_loss = 0.0079\n",
            "t = 16, avg_loss = 0.0124\n",
            "t = 18, avg_loss = 0.0107\n",
            "t = 20, avg_loss = 0.0100\n",
            "t = 22, avg_loss = 0.0087\n",
            "t = 24, avg_loss = 0.0186\n",
            "Checking accuracy on test set\n",
            "Got 362 / 400 correct (90.50)\n",
            "acc = 0.905000\n",
            "Starting epoch 48 / 100\n",
            "t = 2, avg_loss = 0.0416\n",
            "t = 4, avg_loss = 0.0069\n",
            "t = 6, avg_loss = 0.0113\n",
            "t = 8, avg_loss = 0.0199\n",
            "t = 10, avg_loss = 0.0124\n",
            "t = 12, avg_loss = 0.0102\n",
            "t = 14, avg_loss = 0.0308\n",
            "t = 16, avg_loss = 0.0091\n",
            "t = 18, avg_loss = 0.0170\n",
            "t = 20, avg_loss = 0.0120\n",
            "t = 22, avg_loss = 0.0139\n",
            "t = 24, avg_loss = 0.0173\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 49 / 100\n",
            "t = 2, avg_loss = 0.0306\n",
            "t = 4, avg_loss = 0.0128\n",
            "t = 6, avg_loss = 0.0143\n",
            "t = 8, avg_loss = 0.0194\n",
            "t = 10, avg_loss = 0.0051\n",
            "t = 12, avg_loss = 0.0170\n",
            "t = 14, avg_loss = 0.0148\n",
            "t = 16, avg_loss = 0.0128\n",
            "t = 18, avg_loss = 0.0089\n",
            "t = 20, avg_loss = 0.0090\n",
            "t = 22, avg_loss = 0.0035\n",
            "t = 24, avg_loss = 0.0289\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 50 / 100\n",
            "t = 2, avg_loss = 0.0209\n",
            "t = 4, avg_loss = 0.0116\n",
            "t = 6, avg_loss = 0.0154\n",
            "t = 8, avg_loss = 0.0081\n",
            "t = 10, avg_loss = 0.0081\n",
            "t = 12, avg_loss = 0.0109\n",
            "t = 14, avg_loss = 0.0060\n",
            "t = 16, avg_loss = 0.0117\n",
            "t = 18, avg_loss = 0.0119\n",
            "t = 20, avg_loss = 0.0171\n",
            "t = 22, avg_loss = 0.0162\n",
            "t = 24, avg_loss = 0.0098\n",
            "Checking accuracy on test set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 51 / 100\n",
            "t = 2, avg_loss = 0.0220\n",
            "t = 4, avg_loss = 0.0145\n",
            "t = 6, avg_loss = 0.0164\n",
            "t = 8, avg_loss = 0.0139\n",
            "t = 10, avg_loss = 0.0214\n",
            "t = 12, avg_loss = 0.0182\n",
            "t = 14, avg_loss = 0.0131\n",
            "t = 16, avg_loss = 0.0161\n",
            "t = 18, avg_loss = 0.0074\n",
            "t = 20, avg_loss = 0.0235\n",
            "t = 22, avg_loss = 0.0062\n",
            "t = 24, avg_loss = 0.0189\n",
            "Checking accuracy on test set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 52 / 100\n",
            "t = 2, avg_loss = 0.0105\n",
            "t = 4, avg_loss = 0.0073\n",
            "t = 6, avg_loss = 0.0093\n",
            "t = 8, avg_loss = 0.0128\n",
            "t = 10, avg_loss = 0.0097\n",
            "t = 12, avg_loss = 0.0075\n",
            "t = 14, avg_loss = 0.0066\n",
            "t = 16, avg_loss = 0.0269\n",
            "t = 18, avg_loss = 0.0124\n",
            "t = 20, avg_loss = 0.0187\n",
            "t = 22, avg_loss = 0.0155\n",
            "t = 24, avg_loss = 0.0155\n",
            "Checking accuracy on test set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 53 / 100\n",
            "t = 2, avg_loss = 0.0156\n",
            "t = 4, avg_loss = 0.0067\n",
            "t = 6, avg_loss = 0.0132\n",
            "t = 8, avg_loss = 0.0190\n",
            "t = 10, avg_loss = 0.0237\n",
            "t = 12, avg_loss = 0.0275\n",
            "t = 14, avg_loss = 0.0137\n",
            "t = 16, avg_loss = 0.0155\n",
            "t = 18, avg_loss = 0.0277\n",
            "t = 20, avg_loss = 0.0151\n",
            "t = 22, avg_loss = 0.0622\n",
            "t = 24, avg_loss = 0.0177\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 54 / 100\n",
            "t = 2, avg_loss = 0.0224\n",
            "t = 4, avg_loss = 0.0082\n",
            "t = 6, avg_loss = 0.0280\n",
            "t = 8, avg_loss = 0.0215\n",
            "t = 10, avg_loss = 0.0213\n",
            "t = 12, avg_loss = 0.0234\n",
            "t = 14, avg_loss = 0.0209\n",
            "t = 16, avg_loss = 0.0073\n",
            "t = 18, avg_loss = 0.0270\n",
            "t = 20, avg_loss = 0.0175\n",
            "t = 22, avg_loss = 0.0203\n",
            "t = 24, avg_loss = 0.0681\n",
            "Checking accuracy on test set\n",
            "Got 359 / 400 correct (89.75)\n",
            "acc = 0.897500\n",
            "Starting epoch 55 / 100\n",
            "t = 2, avg_loss = 0.0170\n",
            "t = 4, avg_loss = 0.0063\n",
            "t = 6, avg_loss = 0.0204\n",
            "t = 8, avg_loss = 0.0051\n",
            "t = 10, avg_loss = 0.0095\n",
            "t = 12, avg_loss = 0.0152\n",
            "t = 14, avg_loss = 0.0111\n",
            "t = 16, avg_loss = 0.0204\n",
            "t = 18, avg_loss = 0.0153\n",
            "t = 20, avg_loss = 0.0114\n",
            "t = 22, avg_loss = 0.0218\n",
            "t = 24, avg_loss = 0.0171\n",
            "Checking accuracy on test set\n",
            "Got 344 / 400 correct (86.00)\n",
            "acc = 0.860000\n",
            "Starting epoch 56 / 100\n",
            "t = 2, avg_loss = 0.0397\n",
            "t = 4, avg_loss = 0.0081\n",
            "t = 6, avg_loss = 0.0119\n",
            "t = 8, avg_loss = 0.0113\n",
            "t = 10, avg_loss = 0.0123\n",
            "t = 12, avg_loss = 0.0340\n",
            "t = 14, avg_loss = 0.0163\n",
            "t = 16, avg_loss = 0.0222\n",
            "t = 18, avg_loss = 0.0235\n",
            "t = 20, avg_loss = 0.0095\n",
            "t = 22, avg_loss = 0.0075\n",
            "t = 24, avg_loss = 0.0108\n",
            "Checking accuracy on test set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 57 / 100\n",
            "t = 2, avg_loss = 0.0152\n",
            "t = 4, avg_loss = 0.0247\n",
            "t = 6, avg_loss = 0.0080\n",
            "t = 8, avg_loss = 0.0119\n",
            "t = 10, avg_loss = 0.0248\n",
            "t = 12, avg_loss = 0.0071\n",
            "t = 14, avg_loss = 0.0156\n",
            "t = 16, avg_loss = 0.0085\n",
            "t = 18, avg_loss = 0.0280\n",
            "t = 20, avg_loss = 0.0087\n",
            "t = 22, avg_loss = 0.0088\n",
            "t = 24, avg_loss = 0.0123\n",
            "Checking accuracy on test set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 58 / 100\n",
            "t = 2, avg_loss = 0.0446\n",
            "t = 4, avg_loss = 0.0132\n",
            "t = 6, avg_loss = 0.0147\n",
            "t = 8, avg_loss = 0.0219\n",
            "t = 10, avg_loss = 0.0166\n",
            "t = 12, avg_loss = 0.0041\n",
            "t = 14, avg_loss = 0.0113\n",
            "t = 16, avg_loss = 0.0293\n",
            "t = 18, avg_loss = 0.0397\n",
            "t = 20, avg_loss = 0.0295\n",
            "t = 22, avg_loss = 0.0170\n",
            "t = 24, avg_loss = 0.0421\n",
            "Checking accuracy on test set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 59 / 100\n",
            "t = 2, avg_loss = 0.0213\n",
            "t = 4, avg_loss = 0.0262\n",
            "t = 6, avg_loss = 0.0270\n",
            "t = 8, avg_loss = 0.0096\n",
            "t = 10, avg_loss = 0.0407\n",
            "t = 12, avg_loss = 0.0066\n",
            "t = 14, avg_loss = 0.0258\n",
            "t = 16, avg_loss = 0.0655\n",
            "t = 18, avg_loss = 0.0185\n",
            "t = 20, avg_loss = 0.0113\n",
            "t = 22, avg_loss = 0.0264\n",
            "t = 24, avg_loss = 0.0062\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 60 / 100\n",
            "t = 2, avg_loss = 0.0431\n",
            "t = 4, avg_loss = 0.0124\n",
            "t = 6, avg_loss = 0.0847\n",
            "t = 8, avg_loss = 0.0077\n",
            "t = 10, avg_loss = 0.0117\n",
            "t = 12, avg_loss = 0.0324\n",
            "t = 14, avg_loss = 0.0166\n",
            "t = 16, avg_loss = 0.0273\n",
            "t = 18, avg_loss = 0.0124\n",
            "t = 20, avg_loss = 0.0660\n",
            "t = 22, avg_loss = 0.0247\n",
            "t = 24, avg_loss = 0.0167\n",
            "Checking accuracy on test set\n",
            "Got 346 / 400 correct (86.50)\n",
            "acc = 0.865000\n",
            "Starting epoch 61 / 100\n",
            "t = 2, avg_loss = 0.0130\n",
            "t = 4, avg_loss = 0.0249\n",
            "t = 6, avg_loss = 0.0128\n",
            "t = 8, avg_loss = 0.0148\n",
            "t = 10, avg_loss = 0.0348\n",
            "t = 12, avg_loss = 0.0140\n",
            "t = 14, avg_loss = 0.0367\n",
            "t = 16, avg_loss = 0.0228\n",
            "t = 18, avg_loss = 0.0163\n",
            "t = 20, avg_loss = 0.0270\n",
            "t = 22, avg_loss = 0.0092\n",
            "t = 24, avg_loss = 0.0144\n",
            "Checking accuracy on test set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 62 / 100\n",
            "t = 2, avg_loss = 0.0263\n",
            "t = 4, avg_loss = 0.0097\n",
            "t = 6, avg_loss = 0.0047\n",
            "t = 8, avg_loss = 0.0160\n",
            "t = 10, avg_loss = 0.0050\n",
            "t = 12, avg_loss = 0.0068\n",
            "t = 14, avg_loss = 0.0114\n",
            "t = 16, avg_loss = 0.0043\n",
            "t = 18, avg_loss = 0.0179\n",
            "t = 20, avg_loss = 0.0226\n",
            "t = 22, avg_loss = 0.0096\n",
            "t = 24, avg_loss = 0.0049\n",
            "Checking accuracy on test set\n",
            "Got 351 / 400 correct (87.75)\n",
            "acc = 0.877500\n",
            "Starting epoch 63 / 100\n",
            "t = 2, avg_loss = 0.0161\n",
            "t = 4, avg_loss = 0.0126\n",
            "t = 6, avg_loss = 0.0307\n",
            "t = 8, avg_loss = 0.0055\n",
            "t = 10, avg_loss = 0.0171\n",
            "t = 12, avg_loss = 0.0075\n",
            "t = 14, avg_loss = 0.0036\n",
            "t = 16, avg_loss = 0.0469\n",
            "t = 18, avg_loss = 0.0100\n",
            "t = 20, avg_loss = 0.0112\n",
            "t = 22, avg_loss = 0.0444\n",
            "t = 24, avg_loss = 0.0338\n",
            "Checking accuracy on test set\n",
            "Got 351 / 400 correct (87.75)\n",
            "acc = 0.877500\n",
            "Starting epoch 64 / 100\n",
            "t = 2, avg_loss = 0.0250\n",
            "t = 4, avg_loss = 0.0064\n",
            "t = 6, avg_loss = 0.0068\n",
            "t = 8, avg_loss = 0.0078\n",
            "t = 10, avg_loss = 0.0129\n",
            "t = 12, avg_loss = 0.0115\n",
            "t = 14, avg_loss = 0.0269\n",
            "t = 16, avg_loss = 0.0050\n",
            "t = 18, avg_loss = 0.0167\n",
            "t = 20, avg_loss = 0.0037\n",
            "t = 22, avg_loss = 0.0107\n",
            "t = 24, avg_loss = 0.0244\n",
            "Checking accuracy on test set\n",
            "Got 359 / 400 correct (89.75)\n",
            "acc = 0.897500\n",
            "Starting epoch 65 / 100\n",
            "t = 2, avg_loss = 0.0226\n",
            "t = 4, avg_loss = 0.0046\n",
            "t = 6, avg_loss = 0.0042\n",
            "t = 8, avg_loss = 0.0076\n",
            "t = 10, avg_loss = 0.0227\n",
            "t = 12, avg_loss = 0.0410\n",
            "t = 14, avg_loss = 0.0184\n",
            "t = 16, avg_loss = 0.0116\n",
            "t = 18, avg_loss = 0.0207\n",
            "t = 20, avg_loss = 0.0197\n",
            "t = 22, avg_loss = 0.0196\n",
            "t = 24, avg_loss = 0.0103\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 66 / 100\n",
            "t = 2, avg_loss = 0.0085\n",
            "t = 4, avg_loss = 0.0035\n",
            "t = 6, avg_loss = 0.0293\n",
            "t = 8, avg_loss = 0.0079\n",
            "t = 10, avg_loss = 0.0101\n",
            "t = 12, avg_loss = 0.0078\n",
            "t = 14, avg_loss = 0.0047\n",
            "t = 16, avg_loss = 0.0153\n",
            "t = 18, avg_loss = 0.0063\n",
            "t = 20, avg_loss = 0.0042\n",
            "t = 22, avg_loss = 0.0504\n",
            "t = 24, avg_loss = 0.0126\n",
            "Checking accuracy on test set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 67 / 100\n",
            "t = 2, avg_loss = 0.0288\n",
            "t = 4, avg_loss = 0.0115\n",
            "t = 6, avg_loss = 0.0083\n",
            "t = 8, avg_loss = 0.0097\n",
            "t = 10, avg_loss = 0.0070\n",
            "t = 12, avg_loss = 0.0348\n",
            "t = 14, avg_loss = 0.0077\n",
            "t = 16, avg_loss = 0.0096\n",
            "t = 18, avg_loss = 0.0089\n",
            "t = 20, avg_loss = 0.0176\n",
            "t = 22, avg_loss = 0.0158\n",
            "t = 24, avg_loss = 0.0078\n",
            "Checking accuracy on test set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 68 / 100\n",
            "t = 2, avg_loss = 0.0120\n",
            "t = 4, avg_loss = 0.0112\n",
            "t = 6, avg_loss = 0.0015\n",
            "t = 8, avg_loss = 0.0072\n",
            "t = 10, avg_loss = 0.0037\n",
            "t = 12, avg_loss = 0.0042\n",
            "t = 14, avg_loss = 0.0016\n",
            "t = 16, avg_loss = 0.0109\n",
            "t = 18, avg_loss = 0.0035\n",
            "t = 20, avg_loss = 0.0167\n",
            "t = 22, avg_loss = 0.0049\n",
            "t = 24, avg_loss = 0.0044\n",
            "Checking accuracy on test set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 69 / 100\n",
            "t = 2, avg_loss = 0.0094\n",
            "t = 4, avg_loss = 0.0322\n",
            "t = 6, avg_loss = 0.0068\n",
            "t = 8, avg_loss = 0.0090\n",
            "t = 10, avg_loss = 0.0080\n",
            "t = 12, avg_loss = 0.0064\n",
            "t = 14, avg_loss = 0.0306\n",
            "t = 16, avg_loss = 0.0019\n",
            "t = 18, avg_loss = 0.0055\n",
            "t = 20, avg_loss = 0.0176\n",
            "t = 22, avg_loss = 0.0104\n",
            "t = 24, avg_loss = 0.0054\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 70 / 100\n",
            "t = 2, avg_loss = 0.0076\n",
            "t = 4, avg_loss = 0.0030\n",
            "t = 6, avg_loss = 0.0027\n",
            "t = 8, avg_loss = 0.0058\n",
            "t = 10, avg_loss = 0.0088\n",
            "t = 12, avg_loss = 0.0161\n",
            "t = 14, avg_loss = 0.0032\n",
            "t = 16, avg_loss = 0.0045\n",
            "t = 18, avg_loss = 0.0045\n",
            "t = 20, avg_loss = 0.0106\n",
            "t = 22, avg_loss = 0.0173\n",
            "t = 24, avg_loss = 0.0131\n",
            "Checking accuracy on test set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 71 / 100\n",
            "t = 2, avg_loss = 0.0085\n",
            "t = 4, avg_loss = 0.0102\n",
            "t = 6, avg_loss = 0.0065\n",
            "t = 8, avg_loss = 0.0047\n",
            "t = 10, avg_loss = 0.0131\n",
            "t = 12, avg_loss = 0.0089\n",
            "t = 14, avg_loss = 0.0061\n",
            "t = 16, avg_loss = 0.0143\n",
            "t = 18, avg_loss = 0.0031\n",
            "t = 20, avg_loss = 0.0339\n",
            "t = 22, avg_loss = 0.0482\n",
            "t = 24, avg_loss = 0.0057\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 72 / 100\n",
            "t = 2, avg_loss = 0.0156\n",
            "t = 4, avg_loss = 0.0247\n",
            "t = 6, avg_loss = 0.0290\n",
            "t = 8, avg_loss = 0.0217\n",
            "t = 10, avg_loss = 0.0057\n",
            "t = 12, avg_loss = 0.0054\n",
            "t = 14, avg_loss = 0.0096\n",
            "t = 16, avg_loss = 0.0109\n",
            "t = 18, avg_loss = 0.0112\n",
            "t = 20, avg_loss = 0.0304\n",
            "t = 22, avg_loss = 0.0546\n",
            "t = 24, avg_loss = 0.0089\n",
            "Checking accuracy on test set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 73 / 100\n",
            "t = 2, avg_loss = 0.0138\n",
            "t = 4, avg_loss = 0.0312\n",
            "t = 6, avg_loss = 0.0025\n",
            "t = 8, avg_loss = 0.0262\n",
            "t = 10, avg_loss = 0.0142\n",
            "t = 12, avg_loss = 0.0186\n",
            "t = 14, avg_loss = 0.0161\n",
            "t = 16, avg_loss = 0.0320\n",
            "t = 18, avg_loss = 0.0082\n",
            "t = 20, avg_loss = 0.0073\n",
            "t = 22, avg_loss = 0.0453\n",
            "t = 24, avg_loss = 0.0341\n",
            "Checking accuracy on test set\n",
            "Got 343 / 400 correct (85.75)\n",
            "acc = 0.857500\n",
            "Starting epoch 74 / 100\n",
            "t = 2, avg_loss = 0.0295\n",
            "t = 4, avg_loss = 0.0050\n",
            "t = 6, avg_loss = 0.0123\n",
            "t = 8, avg_loss = 0.0261\n",
            "t = 10, avg_loss = 0.0041\n",
            "t = 12, avg_loss = 0.0074\n",
            "t = 14, avg_loss = 0.0138\n",
            "t = 16, avg_loss = 0.0798\n",
            "t = 18, avg_loss = 0.0187\n",
            "t = 20, avg_loss = 0.0140\n",
            "t = 22, avg_loss = 0.0100\n",
            "t = 24, avg_loss = 0.0381\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 75 / 100\n",
            "t = 2, avg_loss = 0.0203\n",
            "t = 4, avg_loss = 0.0421\n",
            "t = 6, avg_loss = 0.0259\n",
            "t = 8, avg_loss = 0.0065\n",
            "t = 10, avg_loss = 0.0177\n",
            "t = 12, avg_loss = 0.0089\n",
            "t = 14, avg_loss = 0.0165\n",
            "t = 16, avg_loss = 0.0059\n",
            "t = 18, avg_loss = 0.0051\n",
            "t = 20, avg_loss = 0.0037\n",
            "t = 22, avg_loss = 0.0129\n",
            "t = 24, avg_loss = 0.0045\n",
            "Checking accuracy on test set\n",
            "Got 346 / 400 correct (86.50)\n",
            "acc = 0.865000\n",
            "Starting epoch 76 / 100\n",
            "t = 2, avg_loss = 0.0068\n",
            "t = 4, avg_loss = 0.0208\n",
            "t = 6, avg_loss = 0.0094\n",
            "t = 8, avg_loss = 0.0087\n",
            "t = 10, avg_loss = 0.0115\n",
            "t = 12, avg_loss = 0.0044\n",
            "t = 14, avg_loss = 0.0113\n",
            "t = 16, avg_loss = 0.0077\n",
            "t = 18, avg_loss = 0.0222\n",
            "t = 20, avg_loss = 0.0294\n",
            "t = 22, avg_loss = 0.0039\n",
            "t = 24, avg_loss = 0.0061\n",
            "Checking accuracy on test set\n",
            "Got 360 / 400 correct (90.00)\n",
            "acc = 0.900000\n",
            "Starting epoch 77 / 100\n",
            "t = 2, avg_loss = 0.0087\n",
            "t = 4, avg_loss = 0.0072\n",
            "t = 6, avg_loss = 0.0115\n",
            "t = 8, avg_loss = 0.0067\n",
            "t = 10, avg_loss = 0.0231\n",
            "t = 12, avg_loss = 0.0172\n",
            "t = 14, avg_loss = 0.0215\n",
            "t = 16, avg_loss = 0.0031\n",
            "t = 18, avg_loss = 0.0029\n",
            "t = 20, avg_loss = 0.0088\n",
            "t = 22, avg_loss = 0.0117\n",
            "t = 24, avg_loss = 0.0082\n",
            "Checking accuracy on test set\n",
            "Got 362 / 400 correct (90.50)\n",
            "acc = 0.905000\n",
            "Starting epoch 78 / 100\n",
            "t = 2, avg_loss = 0.0271\n",
            "t = 4, avg_loss = 0.0090\n",
            "t = 6, avg_loss = 0.0114\n",
            "t = 8, avg_loss = 0.0075\n",
            "t = 10, avg_loss = 0.0039\n",
            "t = 12, avg_loss = 0.0035\n",
            "t = 14, avg_loss = 0.0061\n",
            "t = 16, avg_loss = 0.0019\n",
            "t = 18, avg_loss = 0.0282\n",
            "t = 20, avg_loss = 0.0023\n",
            "t = 22, avg_loss = 0.0060\n",
            "t = 24, avg_loss = 0.0082\n",
            "Checking accuracy on test set\n",
            "Got 351 / 400 correct (87.75)\n",
            "acc = 0.877500\n",
            "Starting epoch 79 / 100\n",
            "t = 2, avg_loss = 0.0118\n",
            "t = 4, avg_loss = 0.0063\n",
            "t = 6, avg_loss = 0.0251\n",
            "t = 8, avg_loss = 0.0025\n",
            "t = 10, avg_loss = 0.0100\n",
            "t = 12, avg_loss = 0.0132\n",
            "t = 14, avg_loss = 0.0040\n",
            "t = 16, avg_loss = 0.0062\n",
            "t = 18, avg_loss = 0.0013\n",
            "t = 20, avg_loss = 0.0116\n",
            "t = 22, avg_loss = 0.0075\n",
            "t = 24, avg_loss = 0.0137\n",
            "Checking accuracy on test set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 80 / 100\n",
            "t = 2, avg_loss = 0.0045\n",
            "t = 4, avg_loss = 0.0217\n",
            "t = 6, avg_loss = 0.0224\n",
            "t = 8, avg_loss = 0.0105\n",
            "t = 10, avg_loss = 0.0114\n",
            "t = 12, avg_loss = 0.0100\n",
            "t = 14, avg_loss = 0.0031\n",
            "t = 16, avg_loss = 0.0036\n",
            "t = 18, avg_loss = 0.0223\n",
            "t = 20, avg_loss = 0.0126\n",
            "t = 22, avg_loss = 0.0029\n",
            "t = 24, avg_loss = 0.0044\n",
            "Checking accuracy on test set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 81 / 100\n",
            "t = 2, avg_loss = 0.0071\n",
            "t = 4, avg_loss = 0.0244\n",
            "t = 6, avg_loss = 0.0169\n",
            "t = 8, avg_loss = 0.0560\n",
            "t = 10, avg_loss = 0.0087\n",
            "t = 12, avg_loss = 0.0192\n",
            "t = 14, avg_loss = 0.0073\n",
            "t = 16, avg_loss = 0.0073\n",
            "t = 18, avg_loss = 0.0034\n",
            "t = 20, avg_loss = 0.0317\n",
            "t = 22, avg_loss = 0.0143\n",
            "t = 24, avg_loss = 0.0105\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 82 / 100\n",
            "t = 2, avg_loss = 0.0036\n",
            "t = 4, avg_loss = 0.0320\n",
            "t = 6, avg_loss = 0.0116\n",
            "t = 8, avg_loss = 0.0028\n",
            "t = 10, avg_loss = 0.0097\n",
            "t = 12, avg_loss = 0.0138\n",
            "t = 14, avg_loss = 0.0094\n",
            "t = 16, avg_loss = 0.0140\n",
            "t = 18, avg_loss = 0.0297\n",
            "t = 20, avg_loss = 0.0076\n",
            "t = 22, avg_loss = 0.0369\n",
            "t = 24, avg_loss = 0.0151\n",
            "Checking accuracy on test set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 83 / 100\n",
            "t = 2, avg_loss = 0.0089\n",
            "t = 4, avg_loss = 0.0043\n",
            "t = 6, avg_loss = 0.0124\n",
            "t = 8, avg_loss = 0.0103\n",
            "t = 10, avg_loss = 0.0107\n",
            "t = 12, avg_loss = 0.0050\n",
            "t = 14, avg_loss = 0.0100\n",
            "t = 16, avg_loss = 0.0056\n",
            "t = 18, avg_loss = 0.0033\n",
            "t = 20, avg_loss = 0.0016\n",
            "t = 22, avg_loss = 0.0100\n",
            "t = 24, avg_loss = 0.0075\n",
            "Checking accuracy on test set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 84 / 100\n",
            "t = 2, avg_loss = 0.0088\n",
            "t = 4, avg_loss = 0.0082\n",
            "t = 6, avg_loss = 0.0017\n",
            "t = 8, avg_loss = 0.0031\n",
            "t = 10, avg_loss = 0.0029\n",
            "t = 12, avg_loss = 0.0043\n",
            "t = 14, avg_loss = 0.0128\n",
            "t = 16, avg_loss = 0.0067\n",
            "t = 18, avg_loss = 0.0028\n",
            "t = 20, avg_loss = 0.0025\n",
            "t = 22, avg_loss = 0.0060\n",
            "t = 24, avg_loss = 0.0152\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 85 / 100\n",
            "t = 2, avg_loss = 0.0039\n",
            "t = 4, avg_loss = 0.0030\n",
            "t = 6, avg_loss = 0.0266\n",
            "t = 8, avg_loss = 0.0047\n",
            "t = 10, avg_loss = 0.0062\n",
            "t = 12, avg_loss = 0.0024\n",
            "t = 14, avg_loss = 0.0034\n",
            "t = 16, avg_loss = 0.0024\n",
            "t = 18, avg_loss = 0.0125\n",
            "t = 20, avg_loss = 0.0074\n",
            "t = 22, avg_loss = 0.0067\n",
            "t = 24, avg_loss = 0.0074\n",
            "Checking accuracy on test set\n",
            "Got 351 / 400 correct (87.75)\n",
            "acc = 0.877500\n",
            "Starting epoch 86 / 100\n",
            "t = 2, avg_loss = 0.0088\n",
            "t = 4, avg_loss = 0.0032\n",
            "t = 6, avg_loss = 0.0017\n",
            "t = 8, avg_loss = 0.0033\n",
            "t = 10, avg_loss = 0.0182\n",
            "t = 12, avg_loss = 0.0024\n",
            "t = 14, avg_loss = 0.0037\n",
            "t = 16, avg_loss = 0.0063\n",
            "t = 18, avg_loss = 0.0091\n",
            "t = 20, avg_loss = 0.0009\n",
            "t = 22, avg_loss = 0.0129\n",
            "t = 24, avg_loss = 0.0047\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 87 / 100\n",
            "t = 2, avg_loss = 0.0097\n",
            "t = 4, avg_loss = 0.0022\n",
            "t = 6, avg_loss = 0.0115\n",
            "t = 8, avg_loss = 0.0175\n",
            "t = 10, avg_loss = 0.0033\n",
            "t = 12, avg_loss = 0.0051\n",
            "t = 14, avg_loss = 0.0040\n",
            "t = 16, avg_loss = 0.0193\n",
            "t = 18, avg_loss = 0.0014\n",
            "t = 20, avg_loss = 0.0083\n",
            "t = 22, avg_loss = 0.0045\n",
            "t = 24, avg_loss = 0.0065\n",
            "Checking accuracy on test set\n",
            "Got 358 / 400 correct (89.50)\n",
            "acc = 0.895000\n",
            "Starting epoch 88 / 100\n",
            "t = 2, avg_loss = 0.0273\n",
            "t = 4, avg_loss = 0.0045\n",
            "t = 6, avg_loss = 0.0269\n",
            "t = 8, avg_loss = 0.0047\n",
            "t = 10, avg_loss = 0.0057\n",
            "t = 12, avg_loss = 0.0077\n",
            "t = 14, avg_loss = 0.0191\n",
            "t = 16, avg_loss = 0.0014\n",
            "t = 18, avg_loss = 0.0114\n",
            "t = 20, avg_loss = 0.0024\n",
            "t = 22, avg_loss = 0.0012\n",
            "t = 24, avg_loss = 0.0037\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 89 / 100\n",
            "t = 2, avg_loss = 0.0204\n",
            "t = 4, avg_loss = 0.0028\n",
            "t = 6, avg_loss = 0.0029\n",
            "t = 8, avg_loss = 0.0043\n",
            "t = 10, avg_loss = 0.0194\n",
            "t = 12, avg_loss = 0.0039\n",
            "t = 14, avg_loss = 0.0091\n",
            "t = 16, avg_loss = 0.0513\n",
            "t = 18, avg_loss = 0.0071\n",
            "t = 20, avg_loss = 0.0466\n",
            "t = 22, avg_loss = 0.0279\n",
            "t = 24, avg_loss = 0.0330\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 90 / 100\n",
            "t = 2, avg_loss = 0.0235\n",
            "t = 4, avg_loss = 0.0749\n",
            "t = 6, avg_loss = 0.0061\n",
            "t = 8, avg_loss = 0.0034\n",
            "t = 10, avg_loss = 0.0035\n",
            "t = 12, avg_loss = 0.0072\n",
            "t = 14, avg_loss = 0.0095\n",
            "t = 16, avg_loss = 0.0109\n",
            "t = 18, avg_loss = 0.0071\n",
            "t = 20, avg_loss = 0.0096\n",
            "t = 22, avg_loss = 0.0122\n",
            "t = 24, avg_loss = 0.0095\n",
            "Checking accuracy on test set\n",
            "Got 345 / 400 correct (86.25)\n",
            "acc = 0.862500\n",
            "Starting epoch 91 / 100\n",
            "t = 2, avg_loss = 0.0160\n",
            "t = 4, avg_loss = 0.0024\n",
            "t = 6, avg_loss = 0.0128\n",
            "t = 8, avg_loss = 0.0034\n",
            "t = 10, avg_loss = 0.0133\n",
            "t = 12, avg_loss = 0.0059\n",
            "t = 14, avg_loss = 0.0024\n",
            "t = 16, avg_loss = 0.0040\n",
            "t = 18, avg_loss = 0.0061\n",
            "t = 20, avg_loss = 0.0081\n",
            "t = 22, avg_loss = 0.0052\n",
            "t = 24, avg_loss = 0.0311\n",
            "Checking accuracy on test set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 92 / 100\n",
            "t = 2, avg_loss = 0.0424\n",
            "t = 4, avg_loss = 0.0053\n",
            "t = 6, avg_loss = 0.0034\n",
            "t = 8, avg_loss = 0.0119\n",
            "t = 10, avg_loss = 0.0119\n",
            "t = 12, avg_loss = 0.0146\n",
            "t = 14, avg_loss = 0.0031\n",
            "t = 16, avg_loss = 0.0051\n",
            "t = 18, avg_loss = 0.0095\n",
            "t = 20, avg_loss = 0.0124\n",
            "t = 22, avg_loss = 0.0175\n",
            "t = 24, avg_loss = 0.0069\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 93 / 100\n",
            "t = 2, avg_loss = 0.0203\n",
            "t = 4, avg_loss = 0.0053\n",
            "t = 6, avg_loss = 0.0136\n",
            "t = 8, avg_loss = 0.0041\n",
            "t = 10, avg_loss = 0.0145\n",
            "t = 12, avg_loss = 0.0096\n",
            "t = 14, avg_loss = 0.0287\n",
            "t = 16, avg_loss = 0.0042\n",
            "t = 18, avg_loss = 0.0028\n",
            "t = 20, avg_loss = 0.0081\n",
            "t = 22, avg_loss = 0.0086\n",
            "t = 24, avg_loss = 0.0117\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 94 / 100\n",
            "t = 2, avg_loss = 0.0244\n",
            "t = 4, avg_loss = 0.0086\n",
            "t = 6, avg_loss = 0.0035\n",
            "t = 8, avg_loss = 0.0107\n",
            "t = 10, avg_loss = 0.0092\n",
            "t = 12, avg_loss = 0.0008\n",
            "t = 14, avg_loss = 0.0086\n",
            "t = 16, avg_loss = 0.0170\n",
            "t = 18, avg_loss = 0.0046\n",
            "t = 20, avg_loss = 0.0038\n",
            "t = 22, avg_loss = 0.0038\n",
            "t = 24, avg_loss = 0.0056\n",
            "Checking accuracy on test set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 95 / 100\n",
            "t = 2, avg_loss = 0.0102\n",
            "t = 4, avg_loss = 0.0027\n",
            "t = 6, avg_loss = 0.0046\n",
            "t = 8, avg_loss = 0.0055\n",
            "t = 10, avg_loss = 0.0034\n",
            "t = 12, avg_loss = 0.0185\n",
            "t = 14, avg_loss = 0.0041\n",
            "t = 16, avg_loss = 0.0273\n",
            "t = 18, avg_loss = 0.0474\n",
            "t = 20, avg_loss = 0.0059\n",
            "t = 22, avg_loss = 0.0073\n",
            "t = 24, avg_loss = 0.0283\n",
            "Checking accuracy on test set\n",
            "Got 344 / 400 correct (86.00)\n",
            "acc = 0.860000\n",
            "Starting epoch 96 / 100\n",
            "t = 2, avg_loss = 0.0441\n",
            "t = 4, avg_loss = 0.0376\n",
            "t = 6, avg_loss = 0.0028\n",
            "t = 8, avg_loss = 0.0083\n",
            "t = 10, avg_loss = 0.0110\n",
            "t = 12, avg_loss = 0.1939\n",
            "t = 14, avg_loss = 0.0015\n",
            "t = 16, avg_loss = 0.0229\n",
            "t = 18, avg_loss = 0.0860\n",
            "t = 20, avg_loss = 0.0353\n",
            "t = 22, avg_loss = 0.0585\n",
            "t = 24, avg_loss = 0.0207\n",
            "Checking accuracy on test set\n",
            "Got 346 / 400 correct (86.50)\n",
            "acc = 0.865000\n",
            "Starting epoch 97 / 100\n",
            "t = 2, avg_loss = 0.0299\n",
            "t = 4, avg_loss = 0.0226\n",
            "t = 6, avg_loss = 0.0805\n",
            "t = 8, avg_loss = 0.0038\n",
            "t = 10, avg_loss = 0.0190\n",
            "t = 12, avg_loss = 0.0362\n",
            "t = 14, avg_loss = 0.0249\n",
            "t = 16, avg_loss = 0.0458\n",
            "t = 18, avg_loss = 0.0166\n",
            "t = 20, avg_loss = 0.0176\n",
            "t = 22, avg_loss = 0.0249\n",
            "t = 24, avg_loss = 0.0261\n",
            "Checking accuracy on test set\n",
            "Got 346 / 400 correct (86.50)\n",
            "acc = 0.865000\n",
            "Starting epoch 98 / 100\n",
            "t = 2, avg_loss = 0.0958\n",
            "t = 4, avg_loss = 0.0243\n",
            "t = 6, avg_loss = 0.0095\n",
            "t = 8, avg_loss = 0.0126\n",
            "t = 10, avg_loss = 0.0398\n",
            "t = 12, avg_loss = 0.0266\n",
            "t = 14, avg_loss = 0.0092\n",
            "t = 16, avg_loss = 0.0092\n",
            "t = 18, avg_loss = 0.0316\n",
            "t = 20, avg_loss = 0.0167\n",
            "t = 22, avg_loss = 0.0721\n",
            "t = 24, avg_loss = 0.0135\n",
            "Checking accuracy on test set\n",
            "Got 351 / 400 correct (87.75)\n",
            "acc = 0.877500\n",
            "Starting epoch 99 / 100\n",
            "t = 2, avg_loss = 0.0563\n",
            "t = 4, avg_loss = 0.0126\n",
            "t = 6, avg_loss = 0.0119\n",
            "t = 8, avg_loss = 0.0213\n",
            "t = 10, avg_loss = 0.0030\n",
            "t = 12, avg_loss = 0.0153\n",
            "t = 14, avg_loss = 0.0086\n",
            "t = 16, avg_loss = 0.0043\n",
            "t = 18, avg_loss = 0.0198\n",
            "t = 20, avg_loss = 0.0037\n",
            "t = 22, avg_loss = 0.0087\n",
            "t = 24, avg_loss = 0.0078\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 100 / 100\n",
            "t = 2, avg_loss = 0.0432\n",
            "t = 4, avg_loss = 0.0040\n",
            "t = 6, avg_loss = 0.0137\n",
            "t = 8, avg_loss = 0.0012\n",
            "t = 10, avg_loss = 0.0072\n",
            "t = 12, avg_loss = 0.0106\n",
            "t = 14, avg_loss = 0.0105\n",
            "t = 16, avg_loss = 0.0029\n",
            "t = 18, avg_loss = 0.0008\n",
            "t = 20, avg_loss = 0.0065\n",
            "t = 22, avg_loss = 0.0036\n",
            "t = 24, avg_loss = 0.0134\n",
            "Checking accuracy on test set\n",
            "Got 346 / 400 correct (86.50)\n",
            "acc = 0.865000\n",
            "Checking accuracy on test set\n",
            "Got 349 / 400 correct (87.25)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8725"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvoCj5uscUsz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_accurancy(acc_list):\n",
        "  plt.plot([i+1 for i in range((len(acc_list)))],acc_list)\n",
        "  print(\"Accurancy:\")\n",
        "  plt.show()\n",
        "\n",
        "def plot_loss_function(avg_loss_list):\n",
        "  plt.plot([print_every*batch_size*(i+1) for i in range((len(avg_loss_list)))],avg_loss_list)\n",
        "  print(\"Loss:\")\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkH5XGsgqSg5",
        "colab_type": "code",
        "outputId": "a8fac632-d044-4f74-a98c-f66fb3965db3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "plot_accurancy(acc_list)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accurancy:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMY5hjrL-sEl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "e2309877-d84a-410c-8a3f-49114f312a40"
      },
      "source": [
        "plot_loss_function(avg_loss_list)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzuX5gLEeJfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def retry_from_backup():\n",
        "  model_gpu = model_base.type(gpu_dtype)\n",
        "  print(model_gpu)\n",
        "  loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) \n",
        "\n",
        "\n",
        "\n",
        "  checkpoint = torch.load(model_backup_path)\n",
        "  model_gpu.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  epoch = checkpoint['epoch']\n",
        "  loss = checkpoint['loss']\n",
        "  acc_list = checkpoint['acc_list']\n",
        "  #avg_loss_list = checkpoint['avg_loss_list']\n",
        "  print(\"starting from epoch: \" + str(epoch))\n",
        "  print(\"starting from loss: \" + str(loss))\n",
        "  print(acc_list)\n",
        "  \n",
        "  \n",
        "  train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=88, starting_from_epoch=epoch)\n",
        "  check_accuracy(model_gpu, valid_loader)\n",
        "\n",
        "  plot_accurancy(acc_list)\n",
        "  plot_loss_function(avg_loss_list)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--rQZKqOalaJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#retry_from_backup()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHmJdkirqU1u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}