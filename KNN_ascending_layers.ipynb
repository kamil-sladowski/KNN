{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN_ascending_layers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMl8eP0Il4JIfvZ/LfDQA9C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamilo116/KNN/blob/master/KNN_ascending_layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7ReM7FU-xs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import sys\n",
        "from random import shuffle\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "import timeit\n",
        "\n",
        "np.random.seed(4) \n",
        "torch.manual_seed(4) \n",
        "torch.cuda.manual_seed(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMOHez_kHZD6",
        "colab_type": "code",
        "outputId": "23dd1716-4481-42ff-a10d-d341f879b9e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYIMZ8QyYewD",
        "colab_type": "code",
        "outputId": "91c4a0d6-a6bd-40b7-8f0d-d957eb8a3822",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "! git clone https://github.com/wang-chen/kervolution.git \n",
        "\n",
        "sys.path.append(\"kervolution/\")\n",
        "from kervolution import Kerv2d\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'kervolution'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects:  16% (1/6)\u001b[K\rremote: Counting objects:  33% (2/6)\u001b[K\rremote: Counting objects:  50% (3/6)\u001b[K\rremote: Counting objects:  66% (4/6)\u001b[K\rremote: Counting objects:  83% (5/6)\u001b[K\rremote: Counting objects: 100% (6/6)\u001b[K\rremote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects:  16% (1/6)\u001b[K\rremote: Compressing objects:  33% (2/6)\u001b[K\rremote: Compressing objects:  50% (3/6)\u001b[K\rremote: Compressing objects:  66% (4/6)\u001b[K\rremote: Compressing objects:  83% (5/6)\u001b[K\rremote: Compressing objects: 100% (6/6)\u001b[K\rremote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 53 (delta 2), reused 0 (delta 0), pack-reused 47\u001b[K\n",
            "Unpacking objects:   1% (1/53)   \rUnpacking objects:   3% (2/53)   \rUnpacking objects:   5% (3/53)   \rUnpacking objects:   7% (4/53)   \rUnpacking objects:   9% (5/53)   \rUnpacking objects:  11% (6/53)   \rUnpacking objects:  13% (7/53)   \rUnpacking objects:  15% (8/53)   \rUnpacking objects:  16% (9/53)   \rUnpacking objects:  18% (10/53)   \rUnpacking objects:  20% (11/53)   \rUnpacking objects:  22% (12/53)   \rUnpacking objects:  24% (13/53)   \rUnpacking objects:  26% (14/53)   \rUnpacking objects:  28% (15/53)   \rUnpacking objects:  30% (16/53)   \rUnpacking objects:  32% (17/53)   \rUnpacking objects:  33% (18/53)   \rUnpacking objects:  35% (19/53)   \rUnpacking objects:  37% (20/53)   \rUnpacking objects:  39% (21/53)   \rUnpacking objects:  41% (22/53)   \rUnpacking objects:  43% (23/53)   \rUnpacking objects:  45% (24/53)   \rUnpacking objects:  47% (25/53)   \rUnpacking objects:  49% (26/53)   \rUnpacking objects:  50% (27/53)   \rUnpacking objects:  52% (28/53)   \rUnpacking objects:  54% (29/53)   \rUnpacking objects:  56% (30/53)   \rUnpacking objects:  58% (31/53)   \rUnpacking objects:  60% (32/53)   \rUnpacking objects:  62% (33/53)   \rUnpacking objects:  64% (34/53)   \rUnpacking objects:  66% (35/53)   \rUnpacking objects:  67% (36/53)   \rUnpacking objects:  69% (37/53)   \rUnpacking objects:  71% (38/53)   \rUnpacking objects:  73% (39/53)   \rUnpacking objects:  75% (40/53)   \rUnpacking objects:  77% (41/53)   \rUnpacking objects:  79% (42/53)   \rUnpacking objects:  81% (43/53)   \rUnpacking objects:  83% (44/53)   \rUnpacking objects:  84% (45/53)   \rUnpacking objects:  86% (46/53)   \rUnpacking objects:  88% (47/53)   \rUnpacking objects:  90% (48/53)   \rUnpacking objects:  92% (49/53)   \rUnpacking objects:  94% (50/53)   \rUnpacking objects:  96% (51/53)   \rUnpacking objects:  98% (52/53)   \rUnpacking objects: 100% (53/53)   \rUnpacking objects: 100% (53/53), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b8P1NdXfVdX",
        "colab_type": "code",
        "outputId": "ab12bf6b-ac4d-4115-e9bc-1a6625166a02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "MALIGNANT_DATASET = '/content/drive/My Drive/Colab_data/malignant/malignant/'\n",
        "BENIGN_DATASET = '/content/drive/My Drive/Colab_data/benign/benign/'\n",
        "DATA_FOLDER = '/content/drive/My Drive/Colab_data/'\n",
        "LIMIT_IMAGES_NUM = 600\n",
        "\n",
        "benign_file_list = sorted(os.listdir(BENIGN_DATASET))[:LIMIT_IMAGES_NUM]\n",
        "malignant_file_list = sorted(os.listdir(MALIGNANT_DATASET))[:LIMIT_IMAGES_NUM]\n",
        "shuffle(benign_file_list)\n",
        "shuffle(malignant_file_list)\n",
        "\n",
        "print(f\"Number of benign {len(benign_file_list)} images\")\n",
        "print(f\"Number of malignant {len(malignant_file_list)} images\")\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize((100, 100)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of benign 600 images\n",
            "Number of malignant 600 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGDQfal74BLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "benign_dict = {filename: 0 for filename in benign_file_list}\n",
        "malignant_dict = {filename: 1 for filename in malignant_file_list}\n",
        "img_class_dict = {**benign_dict , **malignant_dict}\n",
        "labeled_data = pd.Series(img_class_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvAAOqmVfVll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IsicDataset(Dataset):\n",
        "    def __init__(self, data_folder, labeled_data, \n",
        "                 transform=transforms.Compose([transforms.ToTensor()])):\n",
        "        self.labeled_data = labeled_data\n",
        "        self.transform = transform\n",
        "        self.data_folder = data_folder\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labeled_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        label = self.labeled_data[index]\n",
        "        if label == 0:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"benign\", \"benign\", index ))\n",
        "        else:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"malignant\", \"malignant\", index ))\n",
        "        image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "    @property\n",
        "    def labels(self):\n",
        "      return self.labeled_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSuYqjLAYrWA",
        "colab_type": "code",
        "outputId": "050d4f6b-f4ef-4e05-9958-0094e73a2278",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        }
      },
      "source": [
        " \n",
        "dataset = IsicDataset(DATA_FOLDER, labeled_data, transform=data_transforms)\n",
        "print(dataset.labels)\n",
        "\n",
        "X_train, X_test = train_test_split(dataset.labels, test_size=0.2)\n",
        "print(\"number of training data: \",len(X_train))\n",
        "print(\"number of testing  data: \",len(X_test))\n",
        "\n",
        "train_sampler = SubsetRandomSampler(list(X_train.index))\n",
        "valid_sampler = SubsetRandomSampler(list(X_test.index))\n",
        "batch_size = 64\n",
        "num_workers = 0\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ISIC_0000129.jpeg    0\n",
            "ISIC_0000730.jpeg    0\n",
            "ISIC_0000195.jpeg    0\n",
            "ISIC_0000506.jpeg    0\n",
            "ISIC_0000262.jpeg    0\n",
            "                    ..\n",
            "ISIC_0010664.jpeg    1\n",
            "ISIC_0010767.jpeg    1\n",
            "ISIC_0011276.jpeg    1\n",
            "ISIC_0010597.jpeg    1\n",
            "ISIC_0010468.jpeg    1\n",
            "Length: 1200, dtype: int64\n",
            "number of training data:  960\n",
            "number of testing  data:  240\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e8nFBR6Yug5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "def train(model, train_loader ,loss_fn, optimizer, num_epochs = 1):\n",
        "    total_loss =0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
        "        model.train()\n",
        "\n",
        "        for t, (x, y) in enumerate(train_loader):\n",
        "            x_var = Variable(x.type(gpu_dtype))\n",
        "            y_var = Variable(y.type(gpu_dtype).long())\n",
        "            scores = model(x_var)\n",
        "            loss = loss_fn(scores, y_var)\n",
        "            total_loss += loss.data\n",
        "            \n",
        "            if (t + 1) % print_every == 0:\n",
        "                avg_loss = total_loss/print_every\n",
        "                print('t = %d, avg_loss = %.4f' % (t + 1, avg_loss) )\n",
        "                avg_loss_list.append(avg_loss)\n",
        "                total_loss = 0\n",
        "                \n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        acc = check_accuracy(fixed_model_gpu, valid_loader)\n",
        "        print('acc = %f' %(acc))\n",
        "            \n",
        "def check_accuracy(model, loader):\n",
        "    print('Checking accuracy on test set')   \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval() \n",
        "    for x, y in loader:\n",
        "        x_var = Variable(x.type(gpu_dtype))\n",
        "\n",
        "        scores = model(x_var)\n",
        "        _, preds = scores.data.cpu().max(1)\n",
        "        num_correct += (preds == y).sum()\n",
        "        num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    acc_list.append(acc)\n",
        "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "    return acc\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggvpMu36Yw2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.size()\n",
        "        return x.view(N, -1)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgmexhBRZAK6",
        "colab_type": "code",
        "outputId": "3057bcc0-28b7-4f01-8fc9-ddc2dc896512",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "\n",
        "print_every = 1\n",
        "gpu_dtype = torch.cuda.FloatTensor\n",
        "\n",
        "out_1 = 32\n",
        "out_2 = 64\n",
        "out_3 = 128\n",
        "\n",
        "\n",
        "\n",
        "k_size_1 = 3\n",
        "padding_1 = 1\n",
        "in_channels = 3\n",
        "\n",
        "num_epochs = 100\n",
        "\n",
        "'''\n",
        "Kerv2d\n",
        "kervolution with following options:\n",
        "kernel_type: [linear, polynomial, gaussian, etc.]\n",
        "default is convolution:\n",
        "          kernel_type --> linear,\n",
        "balance, power, gamma is valid only when the kernel_type is specified\n",
        "if learnable_kernel = True,  they just be the initial value of learable parameters\n",
        "if learnable_kernel = False, they are the value of kernel_type's parameter\n",
        "the parameter [power] cannot be learned due to integer limitation\n",
        "dilation (int or tuple, optional): Spacing between kernel\n",
        "elements. Default: 1\n",
        "groups (int, optional): Number of blocked connections from input\n",
        "channels to output channels. Default: 1\n",
        "bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n",
        "kernel_type (str), Default: 'linear'\n",
        "learnable_kernel (bool): Learnable kernel parameters.  Default: False \n",
        "balance: 0, 1\n",
        "power: 3, 4, 5\n",
        "gamma:\n",
        "'''\n",
        "\n",
        "\n",
        "fixed_model_base = nn.Sequential( \n",
        "                nn.Kerv2d(in_channels , out_1, padding=padding_1, dilation=1, groups=1, bias=True, \n",
        "                          kernel_type='gaussian', kernel_size=k_size_1, learnable_kernel=True,\n",
        "                          kernel_regularizer=True, stride=1, balance=1, power=4, gamma=1), \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_1),\n",
        "                nn.Conv2d(out_1 , out_2, padding= padding_1, kernel_size=k_size_1, stride=1), \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_2),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_2 , out_3, padding= padding_1, kernel_size=k_size_1, stride=1),  \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_3),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "\n",
        "                nn.Dropout(0.5),\n",
        "                Flatten(),\n",
        "                nn.Linear(80000,64),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Linear(64,2)\n",
        "            )\n",
        "fixed_model_gpu = fixed_model_base.type(gpu_dtype)\n",
        "print(fixed_model_gpu)\n",
        "loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(fixed_model_gpu.parameters(), lr = 0.00012, weight_decay=0) \n",
        "\n",
        "train(fixed_model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs)\n",
        "check_accuracy(fixed_model_gpu, valid_loader)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Kerv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (4): ReLU(inplace=True)\n",
            "  (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (8): ReLU(inplace=True)\n",
            "  (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (11): Dropout(p=0.5, inplace=False)\n",
            "  (12): Flatten()\n",
            "  (13): Linear(in_features=80000, out_features=64, bias=True)\n",
            "  (14): ReLU(inplace=True)\n",
            "  (15): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n",
            "Starting epoch 1 / 100\n",
            "t = 1, avg_loss = 0.7587\n",
            "t = 2, avg_loss = 1.5828\n",
            "t = 3, avg_loss = 1.5484\n",
            "t = 4, avg_loss = 0.6134\n",
            "t = 5, avg_loss = 0.5131\n",
            "t = 6, avg_loss = 0.8940\n",
            "t = 7, avg_loss = 0.8725\n",
            "t = 8, avg_loss = 0.5574\n",
            "t = 9, avg_loss = 0.5491\n",
            "t = 10, avg_loss = 0.5224\n",
            "t = 11, avg_loss = 0.5905\n",
            "t = 12, avg_loss = 0.7885\n",
            "t = 13, avg_loss = 0.6543\n",
            "t = 14, avg_loss = 0.4908\n",
            "t = 15, avg_loss = 0.5716\n",
            "Checking accuracy on test set\n",
            "Got 118 / 240 correct (49.17)\n",
            "acc = 0.491667\n",
            "Starting epoch 2 / 100\n",
            "t = 1, avg_loss = 0.4414\n",
            "t = 2, avg_loss = 0.6260\n",
            "t = 3, avg_loss = 0.5267\n",
            "t = 4, avg_loss = 0.5361\n",
            "t = 5, avg_loss = 0.5173\n",
            "t = 6, avg_loss = 0.4391\n",
            "t = 7, avg_loss = 0.5026\n",
            "t = 8, avg_loss = 0.4614\n",
            "t = 9, avg_loss = 0.4360\n",
            "t = 10, avg_loss = 0.3598\n",
            "t = 11, avg_loss = 0.5421\n",
            "t = 12, avg_loss = 0.4651\n",
            "t = 13, avg_loss = 0.4410\n",
            "t = 14, avg_loss = 0.4915\n",
            "t = 15, avg_loss = 0.4758\n",
            "Checking accuracy on test set\n",
            "Got 118 / 240 correct (49.17)\n",
            "acc = 0.491667\n",
            "Starting epoch 3 / 100\n",
            "t = 1, avg_loss = 0.5400\n",
            "t = 2, avg_loss = 0.5431\n",
            "t = 3, avg_loss = 0.4690\n",
            "t = 4, avg_loss = 0.4353\n",
            "t = 5, avg_loss = 0.3950\n",
            "t = 6, avg_loss = 0.4314\n",
            "t = 7, avg_loss = 0.4447\n",
            "t = 8, avg_loss = 0.3544\n",
            "t = 9, avg_loss = 0.4167\n",
            "t = 10, avg_loss = 0.3479\n",
            "t = 11, avg_loss = 0.3475\n",
            "t = 12, avg_loss = 0.3937\n",
            "t = 13, avg_loss = 0.4459\n",
            "t = 14, avg_loss = 0.4864\n",
            "t = 15, avg_loss = 0.3342\n",
            "Checking accuracy on test set\n",
            "Got 133 / 240 correct (55.42)\n",
            "acc = 0.554167\n",
            "Starting epoch 4 / 100\n",
            "t = 1, avg_loss = 0.5806\n",
            "t = 2, avg_loss = 0.4218\n",
            "t = 3, avg_loss = 0.2989\n",
            "t = 4, avg_loss = 0.3723\n",
            "t = 5, avg_loss = 0.3642\n",
            "t = 6, avg_loss = 0.2995\n",
            "t = 7, avg_loss = 0.2612\n",
            "t = 8, avg_loss = 0.3874\n",
            "t = 9, avg_loss = 0.2816\n",
            "t = 10, avg_loss = 0.3743\n",
            "t = 11, avg_loss = 0.3862\n",
            "t = 12, avg_loss = 0.4644\n",
            "t = 13, avg_loss = 0.4057\n",
            "t = 14, avg_loss = 0.4587\n",
            "t = 15, avg_loss = 0.3965\n",
            "Checking accuracy on test set\n",
            "Got 164 / 240 correct (68.33)\n",
            "acc = 0.683333\n",
            "Starting epoch 5 / 100\n",
            "t = 1, avg_loss = 0.4408\n",
            "t = 2, avg_loss = 0.4431\n",
            "t = 3, avg_loss = 0.4038\n",
            "t = 4, avg_loss = 0.2583\n",
            "t = 5, avg_loss = 0.3225\n",
            "t = 6, avg_loss = 0.5569\n",
            "t = 7, avg_loss = 0.3251\n",
            "t = 8, avg_loss = 0.4720\n",
            "t = 9, avg_loss = 0.3716\n",
            "t = 10, avg_loss = 0.3493\n",
            "t = 11, avg_loss = 0.3305\n",
            "t = 12, avg_loss = 0.3641\n",
            "t = 13, avg_loss = 0.3157\n",
            "t = 14, avg_loss = 0.3240\n",
            "t = 15, avg_loss = 0.4569\n",
            "Checking accuracy on test set\n",
            "Got 174 / 240 correct (72.50)\n",
            "acc = 0.725000\n",
            "Starting epoch 6 / 100\n",
            "t = 1, avg_loss = 0.3585\n",
            "t = 2, avg_loss = 0.4228\n",
            "t = 3, avg_loss = 0.3552\n",
            "t = 4, avg_loss = 0.3079\n",
            "t = 5, avg_loss = 0.3134\n",
            "t = 6, avg_loss = 0.2922\n",
            "t = 7, avg_loss = 0.3021\n",
            "t = 8, avg_loss = 0.3291\n",
            "t = 9, avg_loss = 0.2434\n",
            "t = 10, avg_loss = 0.3527\n",
            "t = 11, avg_loss = 0.3503\n",
            "t = 12, avg_loss = 0.4210\n",
            "t = 13, avg_loss = 0.3346\n",
            "t = 14, avg_loss = 0.2609\n",
            "t = 15, avg_loss = 0.3147\n",
            "Checking accuracy on test set\n",
            "Got 182 / 240 correct (75.83)\n",
            "acc = 0.758333\n",
            "Starting epoch 7 / 100\n",
            "t = 1, avg_loss = 0.2328\n",
            "t = 2, avg_loss = 0.2743\n",
            "t = 3, avg_loss = 0.2591\n",
            "t = 4, avg_loss = 0.4493\n",
            "t = 5, avg_loss = 0.2524\n",
            "t = 6, avg_loss = 0.3243\n",
            "t = 7, avg_loss = 0.4784\n",
            "t = 8, avg_loss = 0.3762\n",
            "t = 9, avg_loss = 0.3174\n",
            "t = 10, avg_loss = 0.4361\n",
            "t = 11, avg_loss = 0.2341\n",
            "t = 12, avg_loss = 0.3684\n",
            "t = 13, avg_loss = 0.2689\n",
            "t = 14, avg_loss = 0.3568\n",
            "t = 15, avg_loss = 0.3274\n",
            "Checking accuracy on test set\n",
            "Got 177 / 240 correct (73.75)\n",
            "acc = 0.737500\n",
            "Starting epoch 8 / 100\n",
            "t = 1, avg_loss = 0.3429\n",
            "t = 2, avg_loss = 0.2378\n",
            "t = 3, avg_loss = 0.3601\n",
            "t = 4, avg_loss = 0.2759\n",
            "t = 5, avg_loss = 0.2659\n",
            "t = 6, avg_loss = 0.2292\n",
            "t = 7, avg_loss = 0.3161\n",
            "t = 8, avg_loss = 0.2931\n",
            "t = 9, avg_loss = 0.3051\n",
            "t = 10, avg_loss = 0.3025\n",
            "t = 11, avg_loss = 0.3992\n",
            "t = 12, avg_loss = 0.2620\n",
            "t = 13, avg_loss = 0.3145\n",
            "t = 14, avg_loss = 0.2876\n",
            "t = 15, avg_loss = 0.2924\n",
            "Checking accuracy on test set\n",
            "Got 178 / 240 correct (74.17)\n",
            "acc = 0.741667\n",
            "Starting epoch 9 / 100\n",
            "t = 1, avg_loss = 0.3115\n",
            "t = 2, avg_loss = 0.1929\n",
            "t = 3, avg_loss = 0.2638\n",
            "t = 4, avg_loss = 0.2586\n",
            "t = 5, avg_loss = 0.2653\n",
            "t = 6, avg_loss = 0.2376\n",
            "t = 7, avg_loss = 0.2237\n",
            "t = 8, avg_loss = 0.2716\n",
            "t = 9, avg_loss = 0.2472\n",
            "t = 10, avg_loss = 0.2333\n",
            "t = 11, avg_loss = 0.3642\n",
            "t = 12, avg_loss = 0.3159\n",
            "t = 13, avg_loss = 0.2006\n",
            "t = 14, avg_loss = 0.5420\n",
            "t = 15, avg_loss = 0.3196\n",
            "Checking accuracy on test set\n",
            "Got 181 / 240 correct (75.42)\n",
            "acc = 0.754167\n",
            "Starting epoch 10 / 100\n",
            "t = 1, avg_loss = 0.3154\n",
            "t = 2, avg_loss = 0.3058\n",
            "t = 3, avg_loss = 0.1919\n",
            "t = 4, avg_loss = 0.2052\n",
            "t = 5, avg_loss = 0.2752\n",
            "t = 6, avg_loss = 0.3241\n",
            "t = 7, avg_loss = 0.4267\n",
            "t = 8, avg_loss = 0.1993\n",
            "t = 9, avg_loss = 0.2739\n",
            "t = 10, avg_loss = 0.2163\n",
            "t = 11, avg_loss = 0.2131\n",
            "t = 12, avg_loss = 0.2314\n",
            "t = 13, avg_loss = 0.1735\n",
            "t = 14, avg_loss = 0.1827\n",
            "t = 15, avg_loss = 0.3889\n",
            "Checking accuracy on test set\n",
            "Got 179 / 240 correct (74.58)\n",
            "acc = 0.745833\n",
            "Starting epoch 11 / 100\n",
            "t = 1, avg_loss = 0.2541\n",
            "t = 2, avg_loss = 0.1519\n",
            "t = 3, avg_loss = 0.2784\n",
            "t = 4, avg_loss = 0.1859\n",
            "t = 5, avg_loss = 0.2222\n",
            "t = 6, avg_loss = 0.2290\n",
            "t = 7, avg_loss = 0.3372\n",
            "t = 8, avg_loss = 0.2658\n",
            "t = 9, avg_loss = 0.2580\n",
            "t = 10, avg_loss = 0.1964\n",
            "t = 11, avg_loss = 0.1998\n",
            "t = 12, avg_loss = 0.2900\n",
            "t = 13, avg_loss = 0.2298\n",
            "t = 14, avg_loss = 0.2487\n",
            "t = 15, avg_loss = 0.2105\n",
            "Checking accuracy on test set\n",
            "Got 181 / 240 correct (75.42)\n",
            "acc = 0.754167\n",
            "Starting epoch 12 / 100\n",
            "t = 1, avg_loss = 0.2497\n",
            "t = 2, avg_loss = 0.2079\n",
            "t = 3, avg_loss = 0.1909\n",
            "t = 4, avg_loss = 0.2051\n",
            "t = 5, avg_loss = 0.2335\n",
            "t = 6, avg_loss = 0.1847\n",
            "t = 7, avg_loss = 0.2346\n",
            "t = 8, avg_loss = 0.2189\n",
            "t = 9, avg_loss = 0.2709\n",
            "t = 10, avg_loss = 0.1655\n",
            "t = 11, avg_loss = 0.1960\n",
            "t = 12, avg_loss = 0.1920\n",
            "t = 13, avg_loss = 0.2039\n",
            "t = 14, avg_loss = 0.1915\n",
            "t = 15, avg_loss = 0.3008\n",
            "Checking accuracy on test set\n",
            "Got 177 / 240 correct (73.75)\n",
            "acc = 0.737500\n",
            "Starting epoch 13 / 100\n",
            "t = 1, avg_loss = 0.1029\n",
            "t = 2, avg_loss = 0.2792\n",
            "t = 3, avg_loss = 0.1798\n",
            "t = 4, avg_loss = 0.2840\n",
            "t = 5, avg_loss = 0.1501\n",
            "t = 6, avg_loss = 0.2039\n",
            "t = 7, avg_loss = 0.2836\n",
            "t = 8, avg_loss = 0.3693\n",
            "t = 9, avg_loss = 0.2159\n",
            "t = 10, avg_loss = 0.3437\n",
            "t = 11, avg_loss = 0.2446\n",
            "t = 12, avg_loss = 0.2204\n",
            "t = 13, avg_loss = 0.2742\n",
            "t = 14, avg_loss = 0.3006\n",
            "t = 15, avg_loss = 0.2093\n",
            "Checking accuracy on test set\n",
            "Got 184 / 240 correct (76.67)\n",
            "acc = 0.766667\n",
            "Starting epoch 14 / 100\n",
            "t = 1, avg_loss = 0.2031\n",
            "t = 2, avg_loss = 0.2085\n",
            "t = 3, avg_loss = 0.2816\n",
            "t = 4, avg_loss = 0.2920\n",
            "t = 5, avg_loss = 0.2652\n",
            "t = 6, avg_loss = 0.2840\n",
            "t = 7, avg_loss = 0.2134\n",
            "t = 8, avg_loss = 0.1552\n",
            "t = 9, avg_loss = 0.2058\n",
            "t = 10, avg_loss = 0.1756\n",
            "t = 11, avg_loss = 0.1587\n",
            "t = 12, avg_loss = 0.1966\n",
            "t = 13, avg_loss = 0.1996\n",
            "t = 14, avg_loss = 0.3077\n",
            "t = 15, avg_loss = 0.2418\n",
            "Checking accuracy on test set\n",
            "Got 186 / 240 correct (77.50)\n",
            "acc = 0.775000\n",
            "Starting epoch 15 / 100\n",
            "t = 1, avg_loss = 0.1872\n",
            "t = 2, avg_loss = 0.2002\n",
            "t = 3, avg_loss = 0.1250\n",
            "t = 4, avg_loss = 0.1790\n",
            "t = 5, avg_loss = 0.2826\n",
            "t = 6, avg_loss = 0.1545\n",
            "t = 7, avg_loss = 0.3256\n",
            "t = 8, avg_loss = 0.1745\n",
            "t = 9, avg_loss = 0.3344\n",
            "t = 10, avg_loss = 0.2782\n",
            "t = 11, avg_loss = 0.2850\n",
            "t = 12, avg_loss = 0.2415\n",
            "t = 13, avg_loss = 0.1110\n",
            "t = 14, avg_loss = 0.2339\n",
            "t = 15, avg_loss = 0.3449\n",
            "Checking accuracy on test set\n",
            "Got 181 / 240 correct (75.42)\n",
            "acc = 0.754167\n",
            "Starting epoch 16 / 100\n",
            "t = 1, avg_loss = 0.1837\n",
            "t = 2, avg_loss = 0.2938\n",
            "t = 3, avg_loss = 0.1483\n",
            "t = 4, avg_loss = 0.1642\n",
            "t = 5, avg_loss = 0.2123\n",
            "t = 6, avg_loss = 0.1903\n",
            "t = 7, avg_loss = 0.2420\n",
            "t = 8, avg_loss = 0.1998\n",
            "t = 9, avg_loss = 0.2241\n",
            "t = 10, avg_loss = 0.1991\n",
            "t = 11, avg_loss = 0.1557\n",
            "t = 12, avg_loss = 0.1837\n",
            "t = 13, avg_loss = 0.1802\n",
            "t = 14, avg_loss = 0.1301\n",
            "t = 15, avg_loss = 0.1902\n",
            "Checking accuracy on test set\n",
            "Got 181 / 240 correct (75.42)\n",
            "acc = 0.754167\n",
            "Starting epoch 17 / 100\n",
            "t = 1, avg_loss = 0.1473\n",
            "t = 2, avg_loss = 0.2171\n",
            "t = 3, avg_loss = 0.2019\n",
            "t = 4, avg_loss = 0.2574\n",
            "t = 5, avg_loss = 0.2523\n",
            "t = 6, avg_loss = 0.1350\n",
            "t = 7, avg_loss = 0.1947\n",
            "t = 8, avg_loss = 0.1509\n",
            "t = 9, avg_loss = 0.1962\n",
            "t = 10, avg_loss = 0.2230\n",
            "t = 11, avg_loss = 0.1922\n",
            "t = 12, avg_loss = 0.0978\n",
            "t = 13, avg_loss = 0.3065\n",
            "t = 14, avg_loss = 0.2367\n",
            "t = 15, avg_loss = 0.0949\n",
            "Checking accuracy on test set\n",
            "Got 182 / 240 correct (75.83)\n",
            "acc = 0.758333\n",
            "Starting epoch 18 / 100\n",
            "t = 1, avg_loss = 0.2536\n",
            "t = 2, avg_loss = 0.1708\n",
            "t = 3, avg_loss = 0.1730\n",
            "t = 4, avg_loss = 0.1838\n",
            "t = 5, avg_loss = 0.2335\n",
            "t = 6, avg_loss = 0.1906\n",
            "t = 7, avg_loss = 0.1469\n",
            "t = 8, avg_loss = 0.1843\n",
            "t = 9, avg_loss = 0.1624\n",
            "t = 10, avg_loss = 0.1289\n",
            "t = 11, avg_loss = 0.1149\n",
            "t = 12, avg_loss = 0.1646\n",
            "t = 13, avg_loss = 0.2522\n",
            "t = 14, avg_loss = 0.1784\n",
            "t = 15, avg_loss = 0.1840\n",
            "Checking accuracy on test set\n",
            "Got 179 / 240 correct (74.58)\n",
            "acc = 0.745833\n",
            "Starting epoch 19 / 100\n",
            "t = 1, avg_loss = 0.1598\n",
            "t = 2, avg_loss = 0.1485\n",
            "t = 3, avg_loss = 0.1650\n",
            "t = 4, avg_loss = 0.1840\n",
            "t = 5, avg_loss = 0.1762\n",
            "t = 6, avg_loss = 0.1616\n",
            "t = 7, avg_loss = 0.1335\n",
            "t = 8, avg_loss = 0.1597\n",
            "t = 9, avg_loss = 0.1553\n",
            "t = 10, avg_loss = 0.1458\n",
            "t = 11, avg_loss = 0.2499\n",
            "t = 12, avg_loss = 0.2033\n",
            "t = 13, avg_loss = 0.1212\n",
            "t = 14, avg_loss = 0.1991\n",
            "t = 15, avg_loss = 0.1471\n",
            "Checking accuracy on test set\n",
            "Got 182 / 240 correct (75.83)\n",
            "acc = 0.758333\n",
            "Starting epoch 20 / 100\n",
            "t = 1, avg_loss = 0.1309\n",
            "t = 2, avg_loss = 0.1795\n",
            "t = 3, avg_loss = 0.2622\n",
            "t = 4, avg_loss = 0.2158\n",
            "t = 5, avg_loss = 0.1574\n",
            "t = 6, avg_loss = 0.1005\n",
            "t = 7, avg_loss = 0.1957\n",
            "t = 8, avg_loss = 0.1542\n",
            "t = 9, avg_loss = 0.1844\n",
            "t = 10, avg_loss = 0.1851\n",
            "t = 11, avg_loss = 0.1081\n",
            "t = 12, avg_loss = 0.1676\n",
            "t = 13, avg_loss = 0.1770\n",
            "t = 14, avg_loss = 0.1681\n",
            "t = 15, avg_loss = 0.3393\n",
            "Checking accuracy on test set\n",
            "Got 183 / 240 correct (76.25)\n",
            "acc = 0.762500\n",
            "Starting epoch 21 / 100\n",
            "t = 1, avg_loss = 0.1506\n",
            "t = 2, avg_loss = 0.1121\n",
            "t = 3, avg_loss = 0.1205\n",
            "t = 4, avg_loss = 0.1168\n",
            "t = 5, avg_loss = 0.0754\n",
            "t = 6, avg_loss = 0.2084\n",
            "t = 7, avg_loss = 0.1699\n",
            "t = 8, avg_loss = 0.1348\n",
            "t = 9, avg_loss = 0.1709\n",
            "t = 10, avg_loss = 0.2242\n",
            "t = 11, avg_loss = 0.1442\n",
            "t = 12, avg_loss = 0.1611\n",
            "t = 13, avg_loss = 0.1347\n",
            "t = 14, avg_loss = 0.1907\n",
            "t = 15, avg_loss = 0.2062\n",
            "Checking accuracy on test set\n",
            "Got 190 / 240 correct (79.17)\n",
            "acc = 0.791667\n",
            "Starting epoch 22 / 100\n",
            "t = 1, avg_loss = 0.0975\n",
            "t = 2, avg_loss = 0.1423\n",
            "t = 3, avg_loss = 0.1528\n",
            "t = 4, avg_loss = 0.1348\n",
            "t = 5, avg_loss = 0.1183\n",
            "t = 6, avg_loss = 0.1165\n",
            "t = 7, avg_loss = 0.0832\n",
            "t = 8, avg_loss = 0.1033\n",
            "t = 9, avg_loss = 0.1276\n",
            "t = 10, avg_loss = 0.1201\n",
            "t = 11, avg_loss = 0.1679\n",
            "t = 12, avg_loss = 0.2200\n",
            "t = 13, avg_loss = 0.1552\n",
            "t = 14, avg_loss = 0.1376\n",
            "t = 15, avg_loss = 0.1363\n",
            "Checking accuracy on test set\n",
            "Got 192 / 240 correct (80.00)\n",
            "acc = 0.800000\n",
            "Starting epoch 23 / 100\n",
            "t = 1, avg_loss = 0.2099\n",
            "t = 2, avg_loss = 0.1370\n",
            "t = 3, avg_loss = 0.1665\n",
            "t = 4, avg_loss = 0.1818\n",
            "t = 5, avg_loss = 0.1544\n",
            "t = 6, avg_loss = 0.1964\n",
            "t = 7, avg_loss = 0.1248\n",
            "t = 8, avg_loss = 0.0683\n",
            "t = 9, avg_loss = 0.1207\n",
            "t = 10, avg_loss = 0.2246\n",
            "t = 11, avg_loss = 0.1150\n",
            "t = 12, avg_loss = 0.1516\n",
            "t = 13, avg_loss = 0.1175\n",
            "t = 14, avg_loss = 0.1418\n",
            "t = 15, avg_loss = 0.1499\n",
            "Checking accuracy on test set\n",
            "Got 182 / 240 correct (75.83)\n",
            "acc = 0.758333\n",
            "Starting epoch 24 / 100\n",
            "t = 1, avg_loss = 0.1379\n",
            "t = 2, avg_loss = 0.1077\n",
            "t = 3, avg_loss = 0.0785\n",
            "t = 4, avg_loss = 0.1279\n",
            "t = 5, avg_loss = 0.0867\n",
            "t = 6, avg_loss = 0.1529\n",
            "t = 7, avg_loss = 0.1155\n",
            "t = 8, avg_loss = 0.1782\n",
            "t = 9, avg_loss = 0.1080\n",
            "t = 10, avg_loss = 0.1019\n",
            "t = 11, avg_loss = 0.1438\n",
            "t = 12, avg_loss = 0.1754\n",
            "t = 13, avg_loss = 0.1452\n",
            "t = 14, avg_loss = 0.2632\n",
            "t = 15, avg_loss = 0.1239\n",
            "Checking accuracy on test set\n",
            "Got 180 / 240 correct (75.00)\n",
            "acc = 0.750000\n",
            "Starting epoch 25 / 100\n",
            "t = 1, avg_loss = 0.1423\n",
            "t = 2, avg_loss = 0.1788\n",
            "t = 3, avg_loss = 0.1919\n",
            "t = 4, avg_loss = 0.1053\n",
            "t = 5, avg_loss = 0.1630\n",
            "t = 6, avg_loss = 0.1723\n",
            "t = 7, avg_loss = 0.1209\n",
            "t = 8, avg_loss = 0.2011\n",
            "t = 9, avg_loss = 0.1107\n",
            "t = 10, avg_loss = 0.1399\n",
            "t = 11, avg_loss = 0.1390\n",
            "t = 12, avg_loss = 0.2117\n",
            "t = 13, avg_loss = 0.1671\n",
            "t = 14, avg_loss = 0.0958\n",
            "t = 15, avg_loss = 0.1811\n",
            "Checking accuracy on test set\n",
            "Got 189 / 240 correct (78.75)\n",
            "acc = 0.787500\n",
            "Starting epoch 26 / 100\n",
            "t = 1, avg_loss = 0.0916\n",
            "t = 2, avg_loss = 0.1670\n",
            "t = 3, avg_loss = 0.1973\n",
            "t = 4, avg_loss = 0.1026\n",
            "t = 5, avg_loss = 0.1097\n",
            "t = 6, avg_loss = 0.1142\n",
            "t = 7, avg_loss = 0.1281\n",
            "t = 8, avg_loss = 0.2056\n",
            "t = 9, avg_loss = 0.1704\n",
            "t = 10, avg_loss = 0.1745\n",
            "t = 11, avg_loss = 0.1444\n",
            "t = 12, avg_loss = 0.1403\n",
            "t = 13, avg_loss = 0.1114\n",
            "t = 14, avg_loss = 0.1676\n",
            "t = 15, avg_loss = 0.0937\n",
            "Checking accuracy on test set\n",
            "Got 186 / 240 correct (77.50)\n",
            "acc = 0.775000\n",
            "Starting epoch 27 / 100\n",
            "t = 1, avg_loss = 0.1383\n",
            "t = 2, avg_loss = 0.1039\n",
            "t = 3, avg_loss = 0.1169\n",
            "t = 4, avg_loss = 0.0963\n",
            "t = 5, avg_loss = 0.1294\n",
            "t = 6, avg_loss = 0.1260\n",
            "t = 7, avg_loss = 0.2014\n",
            "t = 8, avg_loss = 0.1176\n",
            "t = 9, avg_loss = 0.0609\n",
            "t = 10, avg_loss = 0.1454\n",
            "t = 11, avg_loss = 0.1314\n",
            "t = 12, avg_loss = 0.1333\n",
            "t = 13, avg_loss = 0.1307\n",
            "t = 14, avg_loss = 0.1410\n",
            "t = 15, avg_loss = 0.1519\n",
            "Checking accuracy on test set\n",
            "Got 184 / 240 correct (76.67)\n",
            "acc = 0.766667\n",
            "Starting epoch 28 / 100\n",
            "t = 1, avg_loss = 0.1096\n",
            "t = 2, avg_loss = 0.1443\n",
            "t = 3, avg_loss = 0.1131\n",
            "t = 4, avg_loss = 0.1249\n",
            "t = 5, avg_loss = 0.1427\n",
            "t = 6, avg_loss = 0.1678\n",
            "t = 7, avg_loss = 0.0879\n",
            "t = 8, avg_loss = 0.0968\n",
            "t = 9, avg_loss = 0.0702\n",
            "t = 10, avg_loss = 0.1130\n",
            "t = 11, avg_loss = 0.0930\n",
            "t = 12, avg_loss = 0.1624\n",
            "t = 13, avg_loss = 0.1459\n",
            "t = 14, avg_loss = 0.1309\n",
            "t = 15, avg_loss = 0.2084\n",
            "Checking accuracy on test set\n",
            "Got 185 / 240 correct (77.08)\n",
            "acc = 0.770833\n",
            "Starting epoch 29 / 100\n",
            "t = 1, avg_loss = 0.1372\n",
            "t = 2, avg_loss = 0.1832\n",
            "t = 3, avg_loss = 0.1522\n",
            "t = 4, avg_loss = 0.1122\n",
            "t = 5, avg_loss = 0.0799\n",
            "t = 6, avg_loss = 0.2074\n",
            "t = 7, avg_loss = 0.1419\n",
            "t = 8, avg_loss = 0.1185\n",
            "t = 9, avg_loss = 0.1123\n",
            "t = 10, avg_loss = 0.1188\n",
            "t = 11, avg_loss = 0.1294\n",
            "t = 12, avg_loss = 0.2245\n",
            "t = 13, avg_loss = 0.0912\n",
            "t = 14, avg_loss = 0.1529\n",
            "t = 15, avg_loss = 0.0863\n",
            "Checking accuracy on test set\n",
            "Got 178 / 240 correct (74.17)\n",
            "acc = 0.741667\n",
            "Starting epoch 30 / 100\n",
            "t = 1, avg_loss = 0.0573\n",
            "t = 2, avg_loss = 0.1402\n",
            "t = 3, avg_loss = 0.1030\n",
            "t = 4, avg_loss = 0.0851\n",
            "t = 5, avg_loss = 0.1464\n",
            "t = 6, avg_loss = 0.0776\n",
            "t = 7, avg_loss = 0.1610\n",
            "t = 8, avg_loss = 0.1272\n",
            "t = 9, avg_loss = 0.1242\n",
            "t = 10, avg_loss = 0.1567\n",
            "t = 11, avg_loss = 0.1129\n",
            "t = 12, avg_loss = 0.1082\n",
            "t = 13, avg_loss = 0.1010\n",
            "t = 14, avg_loss = 0.1295\n",
            "t = 15, avg_loss = 0.1163\n",
            "Checking accuracy on test set\n",
            "Got 191 / 240 correct (79.58)\n",
            "acc = 0.795833\n",
            "Starting epoch 31 / 100\n",
            "t = 1, avg_loss = 0.0969\n",
            "t = 2, avg_loss = 0.0694\n",
            "t = 3, avg_loss = 0.1759\n",
            "t = 4, avg_loss = 0.1710\n",
            "t = 5, avg_loss = 0.1468\n",
            "t = 6, avg_loss = 0.1412\n",
            "t = 7, avg_loss = 0.1188\n",
            "t = 8, avg_loss = 0.1656\n",
            "t = 9, avg_loss = 0.0647\n",
            "t = 10, avg_loss = 0.0979\n",
            "t = 11, avg_loss = 0.1329\n",
            "t = 12, avg_loss = 0.0923\n",
            "t = 13, avg_loss = 0.0873\n",
            "t = 14, avg_loss = 0.0795\n",
            "t = 15, avg_loss = 0.1423\n",
            "Checking accuracy on test set\n",
            "Got 188 / 240 correct (78.33)\n",
            "acc = 0.783333\n",
            "Starting epoch 32 / 100\n",
            "t = 1, avg_loss = 0.1284\n",
            "t = 2, avg_loss = 0.1141\n",
            "t = 3, avg_loss = 0.1302\n",
            "t = 4, avg_loss = 0.1013\n",
            "t = 5, avg_loss = 0.1844\n",
            "t = 6, avg_loss = 0.0713\n",
            "t = 7, avg_loss = 0.1597\n",
            "t = 8, avg_loss = 0.0962\n",
            "t = 9, avg_loss = 0.0853\n",
            "t = 10, avg_loss = 0.1182\n",
            "t = 11, avg_loss = 0.1495\n",
            "t = 12, avg_loss = 0.0805\n",
            "t = 13, avg_loss = 0.1200\n",
            "t = 14, avg_loss = 0.0916\n",
            "t = 15, avg_loss = 0.0776\n",
            "Checking accuracy on test set\n",
            "Got 186 / 240 correct (77.50)\n",
            "acc = 0.775000\n",
            "Starting epoch 33 / 100\n",
            "t = 1, avg_loss = 0.0579\n",
            "t = 2, avg_loss = 0.0694\n",
            "t = 3, avg_loss = 0.1144\n",
            "t = 4, avg_loss = 0.1498\n",
            "t = 5, avg_loss = 0.0507\n",
            "t = 6, avg_loss = 0.0899\n",
            "t = 7, avg_loss = 0.1411\n",
            "t = 8, avg_loss = 0.0624\n",
            "t = 9, avg_loss = 0.0827\n",
            "t = 10, avg_loss = 0.0807\n",
            "t = 11, avg_loss = 0.0650\n",
            "t = 12, avg_loss = 0.1006\n",
            "t = 13, avg_loss = 0.1067\n",
            "t = 14, avg_loss = 0.1142\n",
            "t = 15, avg_loss = 0.0708\n",
            "Checking accuracy on test set\n",
            "Got 186 / 240 correct (77.50)\n",
            "acc = 0.775000\n",
            "Starting epoch 34 / 100\n",
            "t = 1, avg_loss = 0.0354\n",
            "t = 2, avg_loss = 0.0664\n",
            "t = 3, avg_loss = 0.0762\n",
            "t = 4, avg_loss = 0.0741\n",
            "t = 5, avg_loss = 0.0718\n",
            "t = 6, avg_loss = 0.1020\n",
            "t = 7, avg_loss = 0.0894\n",
            "t = 8, avg_loss = 0.0513\n",
            "t = 9, avg_loss = 0.0608\n",
            "t = 10, avg_loss = 0.1130\n",
            "t = 11, avg_loss = 0.1160\n",
            "t = 12, avg_loss = 0.1250\n",
            "t = 13, avg_loss = 0.0634\n",
            "t = 14, avg_loss = 0.1088\n",
            "t = 15, avg_loss = 0.1457\n",
            "Checking accuracy on test set\n",
            "Got 190 / 240 correct (79.17)\n",
            "acc = 0.791667\n",
            "Starting epoch 35 / 100\n",
            "t = 1, avg_loss = 0.0659\n",
            "t = 2, avg_loss = 0.0842\n",
            "t = 3, avg_loss = 0.0890\n",
            "t = 4, avg_loss = 0.0950\n",
            "t = 5, avg_loss = 0.0480\n",
            "t = 6, avg_loss = 0.1685\n",
            "t = 7, avg_loss = 0.1172\n",
            "t = 8, avg_loss = 0.0765\n",
            "t = 9, avg_loss = 0.0813\n",
            "t = 10, avg_loss = 0.1062\n",
            "t = 11, avg_loss = 0.0584\n",
            "t = 12, avg_loss = 0.1928\n",
            "t = 13, avg_loss = 0.0764\n",
            "t = 14, avg_loss = 0.0505\n",
            "t = 15, avg_loss = 0.0872\n",
            "Checking accuracy on test set\n",
            "Got 179 / 240 correct (74.58)\n",
            "acc = 0.745833\n",
            "Starting epoch 36 / 100\n",
            "t = 1, avg_loss = 0.1142\n",
            "t = 2, avg_loss = 0.0615\n",
            "t = 3, avg_loss = 0.0612\n",
            "t = 4, avg_loss = 0.0659\n",
            "t = 5, avg_loss = 0.1013\n",
            "t = 6, avg_loss = 0.1139\n",
            "t = 7, avg_loss = 0.1712\n",
            "t = 8, avg_loss = 0.0604\n",
            "t = 9, avg_loss = 0.1381\n",
            "t = 10, avg_loss = 0.0567\n",
            "t = 11, avg_loss = 0.1144\n",
            "t = 12, avg_loss = 0.0700\n",
            "t = 13, avg_loss = 0.0682\n",
            "t = 14, avg_loss = 0.0949\n",
            "t = 15, avg_loss = 0.0706\n",
            "Checking accuracy on test set\n",
            "Got 181 / 240 correct (75.42)\n",
            "acc = 0.754167\n",
            "Starting epoch 37 / 100\n",
            "t = 1, avg_loss = 0.0454\n",
            "t = 2, avg_loss = 0.3286\n",
            "t = 3, avg_loss = 0.0626\n",
            "t = 4, avg_loss = 0.0794\n",
            "t = 5, avg_loss = 0.0425\n",
            "t = 6, avg_loss = 0.1487\n",
            "t = 7, avg_loss = 0.1377\n",
            "t = 8, avg_loss = 0.1083\n",
            "t = 9, avg_loss = 0.1100\n",
            "t = 10, avg_loss = 0.0863\n",
            "t = 11, avg_loss = 0.0865\n",
            "t = 12, avg_loss = 0.0837\n",
            "t = 13, avg_loss = 0.1498\n",
            "t = 14, avg_loss = 0.1034\n",
            "t = 15, avg_loss = 0.1262\n",
            "Checking accuracy on test set\n",
            "Got 189 / 240 correct (78.75)\n",
            "acc = 0.787500\n",
            "Starting epoch 38 / 100\n",
            "t = 1, avg_loss = 0.1274\n",
            "t = 2, avg_loss = 0.1298\n",
            "t = 3, avg_loss = 0.0407\n",
            "t = 4, avg_loss = 0.0595\n",
            "t = 5, avg_loss = 0.0708\n",
            "t = 6, avg_loss = 0.0910\n",
            "t = 7, avg_loss = 0.0576\n",
            "t = 8, avg_loss = 0.0635\n",
            "t = 9, avg_loss = 0.0486\n",
            "t = 10, avg_loss = 0.1031\n",
            "t = 11, avg_loss = 0.0755\n",
            "t = 12, avg_loss = 0.1008\n",
            "t = 13, avg_loss = 0.0964\n",
            "t = 14, avg_loss = 0.0915\n",
            "t = 15, avg_loss = 0.1351\n",
            "Checking accuracy on test set\n",
            "Got 192 / 240 correct (80.00)\n",
            "acc = 0.800000\n",
            "Starting epoch 39 / 100\n",
            "t = 1, avg_loss = 0.1147\n",
            "t = 2, avg_loss = 0.0895\n",
            "t = 3, avg_loss = 0.0611\n",
            "t = 4, avg_loss = 0.0379\n",
            "t = 5, avg_loss = 0.1933\n",
            "t = 6, avg_loss = 0.0825\n",
            "t = 7, avg_loss = 0.0955\n",
            "t = 8, avg_loss = 0.1017\n",
            "t = 9, avg_loss = 0.0518\n",
            "t = 10, avg_loss = 0.1147\n",
            "t = 11, avg_loss = 0.0554\n",
            "t = 12, avg_loss = 0.0975\n",
            "t = 13, avg_loss = 0.0443\n",
            "t = 14, avg_loss = 0.1243\n",
            "t = 15, avg_loss = 0.1267\n",
            "Checking accuracy on test set\n",
            "Got 191 / 240 correct (79.58)\n",
            "acc = 0.795833\n",
            "Starting epoch 40 / 100\n",
            "t = 1, avg_loss = 0.0527\n",
            "t = 2, avg_loss = 0.0581\n",
            "t = 3, avg_loss = 0.0768\n",
            "t = 4, avg_loss = 0.0686\n",
            "t = 5, avg_loss = 0.0726\n",
            "t = 6, avg_loss = 0.0618\n",
            "t = 7, avg_loss = 0.0532\n",
            "t = 8, avg_loss = 0.1416\n",
            "t = 9, avg_loss = 0.0708\n",
            "t = 10, avg_loss = 0.1024\n",
            "t = 11, avg_loss = 0.1540\n",
            "t = 12, avg_loss = 0.1161\n",
            "t = 13, avg_loss = 0.0885\n",
            "t = 14, avg_loss = 0.0969\n",
            "t = 15, avg_loss = 0.0717\n",
            "Checking accuracy on test set\n",
            "Got 187 / 240 correct (77.92)\n",
            "acc = 0.779167\n",
            "Starting epoch 41 / 100\n",
            "t = 1, avg_loss = 0.0471\n",
            "t = 2, avg_loss = 0.0481\n",
            "t = 3, avg_loss = 0.0740\n",
            "t = 4, avg_loss = 0.1140\n",
            "t = 5, avg_loss = 0.0779\n",
            "t = 6, avg_loss = 0.0664\n",
            "t = 7, avg_loss = 0.0847\n",
            "t = 8, avg_loss = 0.1151\n",
            "t = 9, avg_loss = 0.0409\n",
            "t = 10, avg_loss = 0.0854\n",
            "t = 11, avg_loss = 0.0420\n",
            "t = 12, avg_loss = 0.1207\n",
            "t = 13, avg_loss = 0.0906\n",
            "t = 14, avg_loss = 0.0840\n",
            "t = 15, avg_loss = 0.0766\n",
            "Checking accuracy on test set\n",
            "Got 189 / 240 correct (78.75)\n",
            "acc = 0.787500\n",
            "Starting epoch 42 / 100\n",
            "t = 1, avg_loss = 0.0684\n",
            "t = 2, avg_loss = 0.0355\n",
            "t = 3, avg_loss = 0.1088\n",
            "t = 4, avg_loss = 0.0583\n",
            "t = 5, avg_loss = 0.0596\n",
            "t = 6, avg_loss = 0.1323\n",
            "t = 7, avg_loss = 0.0703\n",
            "t = 8, avg_loss = 0.0563\n",
            "t = 9, avg_loss = 0.0385\n",
            "t = 10, avg_loss = 0.0696\n",
            "t = 11, avg_loss = 0.0344\n",
            "t = 12, avg_loss = 0.1186\n",
            "t = 13, avg_loss = 0.0158\n",
            "t = 14, avg_loss = 0.0333\n",
            "t = 15, avg_loss = 0.0799\n",
            "Checking accuracy on test set\n",
            "Got 195 / 240 correct (81.25)\n",
            "acc = 0.812500\n",
            "Starting epoch 43 / 100\n",
            "t = 1, avg_loss = 0.0473\n",
            "t = 2, avg_loss = 0.0393\n",
            "t = 3, avg_loss = 0.0648\n",
            "t = 4, avg_loss = 0.0483\n",
            "t = 5, avg_loss = 0.1066\n",
            "t = 6, avg_loss = 0.0318\n",
            "t = 7, avg_loss = 0.0644\n",
            "t = 8, avg_loss = 0.1010\n",
            "t = 9, avg_loss = 0.1102\n",
            "t = 10, avg_loss = 0.0658\n",
            "t = 11, avg_loss = 0.0475\n",
            "t = 12, avg_loss = 0.0865\n",
            "t = 13, avg_loss = 0.0842\n",
            "t = 14, avg_loss = 0.0324\n",
            "t = 15, avg_loss = 0.0495\n",
            "Checking accuracy on test set\n",
            "Got 184 / 240 correct (76.67)\n",
            "acc = 0.766667\n",
            "Starting epoch 44 / 100\n",
            "t = 1, avg_loss = 0.1012\n",
            "t = 2, avg_loss = 0.0543\n",
            "t = 3, avg_loss = 0.0291\n",
            "t = 4, avg_loss = 0.0534\n",
            "t = 5, avg_loss = 0.0690\n",
            "t = 6, avg_loss = 0.0429\n",
            "t = 7, avg_loss = 0.0740\n",
            "t = 8, avg_loss = 0.0492\n",
            "t = 9, avg_loss = 0.0730\n",
            "t = 10, avg_loss = 0.0706\n",
            "t = 11, avg_loss = 0.0614\n",
            "t = 12, avg_loss = 0.0867\n",
            "t = 13, avg_loss = 0.0685\n",
            "t = 14, avg_loss = 0.0733\n",
            "t = 15, avg_loss = 0.0510\n",
            "Checking accuracy on test set\n",
            "Got 183 / 240 correct (76.25)\n",
            "acc = 0.762500\n",
            "Starting epoch 45 / 100\n",
            "t = 1, avg_loss = 0.0883\n",
            "t = 2, avg_loss = 0.0587\n",
            "t = 3, avg_loss = 0.0405\n",
            "t = 4, avg_loss = 0.0438\n",
            "t = 5, avg_loss = 0.0662\n",
            "t = 6, avg_loss = 0.0845\n",
            "t = 7, avg_loss = 0.1028\n",
            "t = 8, avg_loss = 0.0372\n",
            "t = 9, avg_loss = 0.0947\n",
            "t = 10, avg_loss = 0.0739\n",
            "t = 11, avg_loss = 0.0741\n",
            "t = 12, avg_loss = 0.0557\n",
            "t = 13, avg_loss = 0.0293\n",
            "t = 14, avg_loss = 0.0225\n",
            "t = 15, avg_loss = 0.0545\n",
            "Checking accuracy on test set\n",
            "Got 183 / 240 correct (76.25)\n",
            "acc = 0.762500\n",
            "Starting epoch 46 / 100\n",
            "t = 1, avg_loss = 0.0934\n",
            "t = 2, avg_loss = 0.1165\n",
            "t = 3, avg_loss = 0.0706\n",
            "t = 4, avg_loss = 0.0769\n",
            "t = 5, avg_loss = 0.0369\n",
            "t = 6, avg_loss = 0.0554\n",
            "t = 7, avg_loss = 0.0661\n",
            "t = 8, avg_loss = 0.0836\n",
            "t = 9, avg_loss = 0.0534\n",
            "t = 10, avg_loss = 0.0431\n",
            "t = 11, avg_loss = 0.0196\n",
            "t = 12, avg_loss = 0.0426\n",
            "t = 13, avg_loss = 0.0586\n",
            "t = 14, avg_loss = 0.0824\n",
            "t = 15, avg_loss = 0.0460\n",
            "Checking accuracy on test set\n",
            "Got 187 / 240 correct (77.92)\n",
            "acc = 0.779167\n",
            "Starting epoch 47 / 100\n",
            "t = 1, avg_loss = 0.0830\n",
            "t = 2, avg_loss = 0.0638\n",
            "t = 3, avg_loss = 0.0448\n",
            "t = 4, avg_loss = 0.0324\n",
            "t = 5, avg_loss = 0.0516\n",
            "t = 6, avg_loss = 0.0511\n",
            "t = 7, avg_loss = 0.0720\n",
            "t = 8, avg_loss = 0.0521\n",
            "t = 9, avg_loss = 0.0415\n",
            "t = 10, avg_loss = 0.0583\n",
            "t = 11, avg_loss = 0.0400\n",
            "t = 12, avg_loss = 0.0487\n",
            "t = 13, avg_loss = 0.0832\n",
            "t = 14, avg_loss = 0.0647\n",
            "t = 15, avg_loss = 0.0303\n",
            "Checking accuracy on test set\n",
            "Got 192 / 240 correct (80.00)\n",
            "acc = 0.800000\n",
            "Starting epoch 48 / 100\n",
            "t = 1, avg_loss = 0.0493\n",
            "t = 2, avg_loss = 0.0623\n",
            "t = 3, avg_loss = 0.0288\n",
            "t = 4, avg_loss = 0.0424\n",
            "t = 5, avg_loss = 0.0599\n",
            "t = 6, avg_loss = 0.0288\n",
            "t = 7, avg_loss = 0.0371\n",
            "t = 8, avg_loss = 0.0435\n",
            "t = 9, avg_loss = 0.0564\n",
            "t = 10, avg_loss = 0.0349\n",
            "t = 11, avg_loss = 0.0467\n",
            "t = 12, avg_loss = 0.1435\n",
            "t = 13, avg_loss = 0.0370\n",
            "t = 14, avg_loss = 0.0575\n",
            "t = 15, avg_loss = 0.1256\n",
            "Checking accuracy on test set\n",
            "Got 188 / 240 correct (78.33)\n",
            "acc = 0.783333\n",
            "Starting epoch 49 / 100\n",
            "t = 1, avg_loss = 0.0326\n",
            "t = 2, avg_loss = 0.0471\n",
            "t = 3, avg_loss = 0.0501\n",
            "t = 4, avg_loss = 0.0306\n",
            "t = 5, avg_loss = 0.0866\n",
            "t = 6, avg_loss = 0.0490\n",
            "t = 7, avg_loss = 0.0714\n",
            "t = 8, avg_loss = 0.0921\n",
            "t = 9, avg_loss = 0.0502\n",
            "t = 10, avg_loss = 0.0429\n",
            "t = 11, avg_loss = 0.0726\n",
            "t = 12, avg_loss = 0.0524\n",
            "t = 13, avg_loss = 0.0327\n",
            "t = 14, avg_loss = 0.0227\n",
            "t = 15, avg_loss = 0.0658\n",
            "Checking accuracy on test set\n",
            "Got 190 / 240 correct (79.17)\n",
            "acc = 0.791667\n",
            "Starting epoch 50 / 100\n",
            "t = 1, avg_loss = 0.0298\n",
            "t = 2, avg_loss = 0.0407\n",
            "t = 3, avg_loss = 0.0585\n",
            "t = 4, avg_loss = 0.0237\n",
            "t = 5, avg_loss = 0.0530\n",
            "t = 6, avg_loss = 0.0908\n",
            "t = 7, avg_loss = 0.1650\n",
            "t = 8, avg_loss = 0.0387\n",
            "t = 9, avg_loss = 0.0464\n",
            "t = 10, avg_loss = 0.0738\n",
            "t = 11, avg_loss = 0.0585\n",
            "t = 12, avg_loss = 0.0564\n",
            "t = 13, avg_loss = 0.0889\n",
            "t = 14, avg_loss = 0.0660\n",
            "t = 15, avg_loss = 0.0627\n",
            "Checking accuracy on test set\n",
            "Got 175 / 240 correct (72.92)\n",
            "acc = 0.729167\n",
            "Starting epoch 51 / 100\n",
            "t = 1, avg_loss = 0.0885\n",
            "t = 2, avg_loss = 0.0538\n",
            "t = 3, avg_loss = 0.0472\n",
            "t = 4, avg_loss = 0.0305\n",
            "t = 5, avg_loss = 0.0353\n",
            "t = 6, avg_loss = 0.0614\n",
            "t = 7, avg_loss = 0.0543\n",
            "t = 8, avg_loss = 0.0646\n",
            "t = 9, avg_loss = 0.0305\n",
            "t = 10, avg_loss = 0.0427\n",
            "t = 11, avg_loss = 0.0482\n",
            "t = 12, avg_loss = 0.0433\n",
            "t = 13, avg_loss = 0.1059\n",
            "t = 14, avg_loss = 0.0682\n",
            "t = 15, avg_loss = 0.0472\n",
            "Checking accuracy on test set\n",
            "Got 186 / 240 correct (77.50)\n",
            "acc = 0.775000\n",
            "Starting epoch 52 / 100\n",
            "t = 1, avg_loss = 0.0785\n",
            "t = 2, avg_loss = 0.0493\n",
            "t = 3, avg_loss = 0.0642\n",
            "t = 4, avg_loss = 0.0445\n",
            "t = 5, avg_loss = 0.0526\n",
            "t = 6, avg_loss = 0.0725\n",
            "t = 7, avg_loss = 0.0628\n",
            "t = 8, avg_loss = 0.0301\n",
            "t = 9, avg_loss = 0.0789\n",
            "t = 10, avg_loss = 0.0434\n",
            "t = 11, avg_loss = 0.0321\n",
            "t = 12, avg_loss = 0.0310\n",
            "t = 13, avg_loss = 0.0354\n",
            "t = 14, avg_loss = 0.0751\n",
            "t = 15, avg_loss = 0.0192\n",
            "Checking accuracy on test set\n",
            "Got 188 / 240 correct (78.33)\n",
            "acc = 0.783333\n",
            "Starting epoch 53 / 100\n",
            "t = 1, avg_loss = 0.0585\n",
            "t = 2, avg_loss = 0.0171\n",
            "t = 3, avg_loss = 0.0634\n",
            "t = 4, avg_loss = 0.0441\n",
            "t = 5, avg_loss = 0.0408\n",
            "t = 6, avg_loss = 0.0899\n",
            "t = 7, avg_loss = 0.0803\n",
            "t = 8, avg_loss = 0.0694\n",
            "t = 9, avg_loss = 0.0210\n",
            "t = 10, avg_loss = 0.0636\n",
            "t = 11, avg_loss = 0.0514\n",
            "t = 12, avg_loss = 0.0460\n",
            "t = 13, avg_loss = 0.0214\n",
            "t = 14, avg_loss = 0.0729\n",
            "t = 15, avg_loss = 0.0379\n",
            "Checking accuracy on test set\n",
            "Got 188 / 240 correct (78.33)\n",
            "acc = 0.783333\n",
            "Starting epoch 54 / 100\n",
            "t = 1, avg_loss = 0.0491\n",
            "t = 2, avg_loss = 0.0547\n",
            "t = 3, avg_loss = 0.0212\n",
            "t = 4, avg_loss = 0.0259\n",
            "t = 5, avg_loss = 0.0217\n",
            "t = 6, avg_loss = 0.0534\n",
            "t = 7, avg_loss = 0.0536\n",
            "t = 8, avg_loss = 0.0717\n",
            "t = 9, avg_loss = 0.0797\n",
            "t = 10, avg_loss = 0.0423\n",
            "t = 11, avg_loss = 0.0966\n",
            "t = 12, avg_loss = 0.0743\n",
            "t = 13, avg_loss = 0.1253\n",
            "t = 14, avg_loss = 0.0601\n",
            "t = 15, avg_loss = 0.0534\n",
            "Checking accuracy on test set\n",
            "Got 177 / 240 correct (73.75)\n",
            "acc = 0.737500\n",
            "Starting epoch 55 / 100\n",
            "t = 1, avg_loss = 0.0395\n",
            "t = 2, avg_loss = 0.0256\n",
            "t = 3, avg_loss = 0.0889\n",
            "t = 4, avg_loss = 0.0383\n",
            "t = 5, avg_loss = 0.0766\n",
            "t = 6, avg_loss = 0.0964\n",
            "t = 7, avg_loss = 0.0464\n",
            "t = 8, avg_loss = 0.0680\n",
            "t = 9, avg_loss = 0.0594\n",
            "t = 10, avg_loss = 0.0467\n",
            "t = 11, avg_loss = 0.0777\n",
            "t = 12, avg_loss = 0.0693\n",
            "t = 13, avg_loss = 0.0461\n",
            "t = 14, avg_loss = 0.0510\n",
            "t = 15, avg_loss = 0.0447\n",
            "Checking accuracy on test set\n",
            "Got 184 / 240 correct (76.67)\n",
            "acc = 0.766667\n",
            "Starting epoch 56 / 100\n",
            "t = 1, avg_loss = 0.1152\n",
            "t = 2, avg_loss = 0.0554\n",
            "t = 3, avg_loss = 0.0685\n",
            "t = 4, avg_loss = 0.0341\n",
            "t = 5, avg_loss = 0.0583\n",
            "t = 6, avg_loss = 0.0410\n",
            "t = 7, avg_loss = 0.0120\n",
            "t = 8, avg_loss = 0.0397\n",
            "t = 9, avg_loss = 0.0218\n",
            "t = 10, avg_loss = 0.0917\n",
            "t = 11, avg_loss = 0.0892\n",
            "t = 12, avg_loss = 0.0435\n",
            "t = 13, avg_loss = 0.0362\n",
            "t = 14, avg_loss = 0.0201\n",
            "t = 15, avg_loss = 0.0614\n",
            "Checking accuracy on test set\n",
            "Got 187 / 240 correct (77.92)\n",
            "acc = 0.779167\n",
            "Starting epoch 57 / 100\n",
            "t = 1, avg_loss = 0.0239\n",
            "t = 2, avg_loss = 0.1120\n",
            "t = 3, avg_loss = 0.0177\n",
            "t = 4, avg_loss = 0.0371\n",
            "t = 5, avg_loss = 0.0804\n",
            "t = 6, avg_loss = 0.0578\n",
            "t = 7, avg_loss = 0.0287\n",
            "t = 8, avg_loss = 0.0736\n",
            "t = 9, avg_loss = 0.0730\n",
            "t = 10, avg_loss = 0.0686\n",
            "t = 11, avg_loss = 0.0473\n",
            "t = 12, avg_loss = 0.0455\n",
            "t = 13, avg_loss = 0.0553\n",
            "t = 14, avg_loss = 0.0794\n",
            "t = 15, avg_loss = 0.0234\n",
            "Checking accuracy on test set\n",
            "Got 187 / 240 correct (77.92)\n",
            "acc = 0.779167\n",
            "Starting epoch 58 / 100\n",
            "t = 1, avg_loss = 0.0209\n",
            "t = 2, avg_loss = 0.0334\n",
            "t = 3, avg_loss = 0.0415\n",
            "t = 4, avg_loss = 0.0412\n",
            "t = 5, avg_loss = 0.0934\n",
            "t = 6, avg_loss = 0.0241\n",
            "t = 7, avg_loss = 0.0137\n",
            "t = 8, avg_loss = 0.0410\n",
            "t = 9, avg_loss = 0.1150\n",
            "t = 10, avg_loss = 0.0590\n",
            "t = 11, avg_loss = 0.0486\n",
            "t = 12, avg_loss = 0.0723\n",
            "t = 13, avg_loss = 0.0373\n",
            "t = 14, avg_loss = 0.0416\n",
            "t = 15, avg_loss = 0.0369\n",
            "Checking accuracy on test set\n",
            "Got 181 / 240 correct (75.42)\n",
            "acc = 0.754167\n",
            "Starting epoch 59 / 100\n",
            "t = 1, avg_loss = 0.0351\n",
            "t = 2, avg_loss = 0.0269\n",
            "t = 3, avg_loss = 0.0584\n",
            "t = 4, avg_loss = 0.0630\n",
            "t = 5, avg_loss = 0.0804\n",
            "t = 6, avg_loss = 0.1043\n",
            "t = 7, avg_loss = 0.0489\n",
            "t = 8, avg_loss = 0.0523\n",
            "t = 9, avg_loss = 0.0412\n",
            "t = 10, avg_loss = 0.0288\n",
            "t = 11, avg_loss = 0.0336\n",
            "t = 12, avg_loss = 0.0160\n",
            "t = 13, avg_loss = 0.0254\n",
            "t = 14, avg_loss = 0.0161\n",
            "t = 15, avg_loss = 0.0495\n",
            "Checking accuracy on test set\n",
            "Got 189 / 240 correct (78.75)\n",
            "acc = 0.787500\n",
            "Starting epoch 60 / 100\n",
            "t = 1, avg_loss = 0.0445\n",
            "t = 2, avg_loss = 0.0485\n",
            "t = 3, avg_loss = 0.0431\n",
            "t = 4, avg_loss = 0.0308\n",
            "t = 5, avg_loss = 0.0728\n",
            "t = 6, avg_loss = 0.0103\n",
            "t = 7, avg_loss = 0.0827\n",
            "t = 8, avg_loss = 0.0352\n",
            "t = 9, avg_loss = 0.0225\n",
            "t = 10, avg_loss = 0.0458\n",
            "t = 11, avg_loss = 0.0380\n",
            "t = 12, avg_loss = 0.0222\n",
            "t = 13, avg_loss = 0.0214\n",
            "t = 14, avg_loss = 0.0740\n",
            "t = 15, avg_loss = 0.0391\n",
            "Checking accuracy on test set\n",
            "Got 190 / 240 correct (79.17)\n",
            "acc = 0.791667\n",
            "Starting epoch 61 / 100\n",
            "t = 1, avg_loss = 0.0613\n",
            "t = 2, avg_loss = 0.0083\n",
            "t = 3, avg_loss = 0.0201\n",
            "t = 4, avg_loss = 0.0494\n",
            "t = 5, avg_loss = 0.0482\n",
            "t = 6, avg_loss = 0.0252\n",
            "t = 7, avg_loss = 0.0255\n",
            "t = 8, avg_loss = 0.0420\n",
            "t = 9, avg_loss = 0.0540\n",
            "t = 10, avg_loss = 0.0330\n",
            "t = 11, avg_loss = 0.0235\n",
            "t = 12, avg_loss = 0.0309\n",
            "t = 13, avg_loss = 0.0622\n",
            "t = 14, avg_loss = 0.0232\n",
            "t = 15, avg_loss = 0.0955\n",
            "Checking accuracy on test set\n",
            "Got 180 / 240 correct (75.00)\n",
            "acc = 0.750000\n",
            "Starting epoch 62 / 100\n",
            "t = 1, avg_loss = 0.0430\n",
            "t = 2, avg_loss = 0.0466\n",
            "t = 3, avg_loss = 0.0420\n",
            "t = 4, avg_loss = 0.0107\n",
            "t = 5, avg_loss = 0.0366\n",
            "t = 6, avg_loss = 0.0296\n",
            "t = 7, avg_loss = 0.0334\n",
            "t = 8, avg_loss = 0.0819\n",
            "t = 9, avg_loss = 0.0363\n",
            "t = 10, avg_loss = 0.0792\n",
            "t = 11, avg_loss = 0.1079\n",
            "t = 12, avg_loss = 0.0154\n",
            "t = 13, avg_loss = 0.0564\n",
            "t = 14, avg_loss = 0.0780\n",
            "t = 15, avg_loss = 0.0527\n",
            "Checking accuracy on test set\n",
            "Got 189 / 240 correct (78.75)\n",
            "acc = 0.787500\n",
            "Starting epoch 63 / 100\n",
            "t = 1, avg_loss = 0.0172\n",
            "t = 2, avg_loss = 0.0369\n",
            "t = 3, avg_loss = 0.0422\n",
            "t = 4, avg_loss = 0.0419\n",
            "t = 5, avg_loss = 0.0555\n",
            "t = 6, avg_loss = 0.1204\n",
            "t = 7, avg_loss = 0.0491\n",
            "t = 8, avg_loss = 0.0195\n",
            "t = 9, avg_loss = 0.0687\n",
            "t = 10, avg_loss = 0.0444\n",
            "t = 11, avg_loss = 0.0350\n",
            "t = 12, avg_loss = 0.0897\n",
            "t = 13, avg_loss = 0.0617\n",
            "t = 14, avg_loss = 0.0416\n",
            "t = 15, avg_loss = 0.0366\n",
            "Checking accuracy on test set\n",
            "Got 186 / 240 correct (77.50)\n",
            "acc = 0.775000\n",
            "Starting epoch 64 / 100\n",
            "t = 1, avg_loss = 0.0158\n",
            "t = 2, avg_loss = 0.0441\n",
            "t = 3, avg_loss = 0.0207\n",
            "t = 4, avg_loss = 0.0369\n",
            "t = 5, avg_loss = 0.0258\n",
            "t = 6, avg_loss = 0.0848\n",
            "t = 7, avg_loss = 0.0292\n",
            "t = 8, avg_loss = 0.0700\n",
            "t = 9, avg_loss = 0.0115\n",
            "t = 10, avg_loss = 0.0391\n",
            "t = 11, avg_loss = 0.0560\n",
            "t = 12, avg_loss = 0.0453\n",
            "t = 13, avg_loss = 0.0307\n",
            "t = 14, avg_loss = 0.0431\n",
            "t = 15, avg_loss = 0.0883\n",
            "Checking accuracy on test set\n",
            "Got 186 / 240 correct (77.50)\n",
            "acc = 0.775000\n",
            "Starting epoch 65 / 100\n",
            "t = 1, avg_loss = 0.0145\n",
            "t = 2, avg_loss = 0.0468\n",
            "t = 3, avg_loss = 0.0375\n",
            "t = 4, avg_loss = 0.0198\n",
            "t = 5, avg_loss = 0.0358\n",
            "t = 6, avg_loss = 0.0436\n",
            "t = 7, avg_loss = 0.0510\n",
            "t = 8, avg_loss = 0.0233\n",
            "t = 9, avg_loss = 0.0526\n",
            "t = 10, avg_loss = 0.1218\n",
            "t = 11, avg_loss = 0.0248\n",
            "t = 12, avg_loss = 0.0218\n",
            "t = 13, avg_loss = 0.0402\n",
            "t = 14, avg_loss = 0.0422\n",
            "t = 15, avg_loss = 0.0690\n",
            "Checking accuracy on test set\n",
            "Got 189 / 240 correct (78.75)\n",
            "acc = 0.787500\n",
            "Starting epoch 66 / 100\n",
            "t = 1, avg_loss = 0.0376\n",
            "t = 2, avg_loss = 0.0538\n",
            "t = 3, avg_loss = 0.0288\n",
            "t = 4, avg_loss = 0.0315\n",
            "t = 5, avg_loss = 0.0487\n",
            "t = 6, avg_loss = 0.0303\n",
            "t = 7, avg_loss = 0.0405\n",
            "t = 8, avg_loss = 0.1038\n",
            "t = 9, avg_loss = 0.0913\n",
            "t = 10, avg_loss = 0.0671\n",
            "t = 11, avg_loss = 0.0363\n",
            "t = 12, avg_loss = 0.0731\n",
            "t = 13, avg_loss = 0.0603\n",
            "t = 14, avg_loss = 0.1060\n",
            "t = 15, avg_loss = 0.0602\n",
            "Checking accuracy on test set\n",
            "Got 172 / 240 correct (71.67)\n",
            "acc = 0.716667\n",
            "Starting epoch 67 / 100\n",
            "t = 1, avg_loss = 0.0543\n",
            "t = 2, avg_loss = 0.0638\n",
            "t = 3, avg_loss = 0.0144\n",
            "t = 4, avg_loss = 0.0736\n",
            "t = 5, avg_loss = 0.0428\n",
            "t = 6, avg_loss = 0.0379\n",
            "t = 7, avg_loss = 0.0562\n",
            "t = 8, avg_loss = 0.0052\n",
            "t = 9, avg_loss = 0.1000\n",
            "t = 10, avg_loss = 0.0363\n",
            "t = 11, avg_loss = 0.0399\n",
            "t = 12, avg_loss = 0.0391\n",
            "t = 13, avg_loss = 0.0258\n",
            "t = 14, avg_loss = 0.0309\n",
            "t = 15, avg_loss = 0.0503\n",
            "Checking accuracy on test set\n",
            "Got 188 / 240 correct (78.33)\n",
            "acc = 0.783333\n",
            "Starting epoch 68 / 100\n",
            "t = 1, avg_loss = 0.0234\n",
            "t = 2, avg_loss = 0.0226\n",
            "t = 3, avg_loss = 0.0427\n",
            "t = 4, avg_loss = 0.0279\n",
            "t = 5, avg_loss = 0.0233\n",
            "t = 6, avg_loss = 0.0493\n",
            "t = 7, avg_loss = 0.0416\n",
            "t = 8, avg_loss = 0.0506\n",
            "t = 9, avg_loss = 0.0561\n",
            "t = 10, avg_loss = 0.1486\n",
            "t = 11, avg_loss = 0.0331\n",
            "t = 12, avg_loss = 0.0669\n",
            "t = 13, avg_loss = 0.0677\n",
            "t = 14, avg_loss = 0.0563\n",
            "t = 15, avg_loss = 0.0419\n",
            "Checking accuracy on test set\n",
            "Got 183 / 240 correct (76.25)\n",
            "acc = 0.762500\n",
            "Starting epoch 69 / 100\n",
            "t = 1, avg_loss = 0.0221\n",
            "t = 2, avg_loss = 0.0854\n",
            "t = 3, avg_loss = 0.0190\n",
            "t = 4, avg_loss = 0.0310\n",
            "t = 5, avg_loss = 0.0243\n",
            "t = 6, avg_loss = 0.0191\n",
            "t = 7, avg_loss = 0.0236\n",
            "t = 8, avg_loss = 0.0392\n",
            "t = 9, avg_loss = 0.0399\n",
            "t = 10, avg_loss = 0.0534\n",
            "t = 11, avg_loss = 0.0805\n",
            "t = 12, avg_loss = 0.0540\n",
            "t = 13, avg_loss = 0.0312\n",
            "t = 14, avg_loss = 0.0674\n",
            "t = 15, avg_loss = 0.0407\n",
            "Checking accuracy on test set\n",
            "Got 190 / 240 correct (79.17)\n",
            "acc = 0.791667\n",
            "Starting epoch 70 / 100\n",
            "t = 1, avg_loss = 0.0201\n",
            "t = 2, avg_loss = 0.0147\n",
            "t = 3, avg_loss = 0.0651\n",
            "t = 4, avg_loss = 0.1261\n",
            "t = 5, avg_loss = 0.0311\n",
            "t = 6, avg_loss = 0.0506\n",
            "t = 7, avg_loss = 0.1193\n",
            "t = 8, avg_loss = 0.0240\n",
            "t = 9, avg_loss = 0.0216\n",
            "t = 10, avg_loss = 0.0325\n",
            "t = 11, avg_loss = 0.0677\n",
            "t = 12, avg_loss = 0.0212\n",
            "t = 13, avg_loss = 0.0609\n",
            "t = 14, avg_loss = 0.0311\n",
            "t = 15, avg_loss = 0.0766\n",
            "Checking accuracy on test set\n",
            "Got 190 / 240 correct (79.17)\n",
            "acc = 0.791667\n",
            "Starting epoch 71 / 100\n",
            "t = 1, avg_loss = 0.0230\n",
            "t = 2, avg_loss = 0.0121\n",
            "t = 3, avg_loss = 0.0320\n",
            "t = 4, avg_loss = 0.0599\n",
            "t = 5, avg_loss = 0.0660\n",
            "t = 6, avg_loss = 0.0403\n",
            "t = 7, avg_loss = 0.0370\n",
            "t = 8, avg_loss = 0.0174\n",
            "t = 9, avg_loss = 0.0704\n",
            "t = 10, avg_loss = 0.0246\n",
            "t = 11, avg_loss = 0.0155\n",
            "t = 12, avg_loss = 0.0399\n",
            "t = 13, avg_loss = 0.0267\n",
            "t = 14, avg_loss = 0.0539\n",
            "t = 15, avg_loss = 0.0420\n",
            "Checking accuracy on test set\n",
            "Got 185 / 240 correct (77.08)\n",
            "acc = 0.770833\n",
            "Starting epoch 72 / 100\n",
            "t = 1, avg_loss = 0.0243\n",
            "t = 2, avg_loss = 0.0413\n",
            "t = 3, avg_loss = 0.0270\n",
            "t = 4, avg_loss = 0.0255\n",
            "t = 5, avg_loss = 0.0329\n",
            "t = 6, avg_loss = 0.0342\n",
            "t = 7, avg_loss = 0.0494\n",
            "t = 8, avg_loss = 0.0273\n",
            "t = 9, avg_loss = 0.0835\n",
            "t = 10, avg_loss = 0.0650\n",
            "t = 11, avg_loss = 0.0448\n",
            "t = 12, avg_loss = 0.0886\n",
            "t = 13, avg_loss = 0.0322\n",
            "t = 14, avg_loss = 0.0860\n",
            "t = 15, avg_loss = 0.0338\n",
            "Checking accuracy on test set\n",
            "Got 186 / 240 correct (77.50)\n",
            "acc = 0.775000\n",
            "Starting epoch 73 / 100\n",
            "t = 1, avg_loss = 0.0103\n",
            "t = 2, avg_loss = 0.0265\n",
            "t = 3, avg_loss = 0.0401\n",
            "t = 4, avg_loss = 0.0916\n",
            "t = 5, avg_loss = 0.0287\n",
            "t = 6, avg_loss = 0.0503\n",
            "t = 7, avg_loss = 0.0232\n",
            "t = 8, avg_loss = 0.0209\n",
            "t = 9, avg_loss = 0.0386\n",
            "t = 10, avg_loss = 0.0324\n",
            "t = 11, avg_loss = 0.0705\n",
            "t = 12, avg_loss = 0.0259\n",
            "t = 13, avg_loss = 0.0384\n",
            "t = 14, avg_loss = 0.0151\n",
            "t = 15, avg_loss = 0.0467\n",
            "Checking accuracy on test set\n",
            "Got 181 / 240 correct (75.42)\n",
            "acc = 0.754167\n",
            "Starting epoch 74 / 100\n",
            "t = 1, avg_loss = 0.0158\n",
            "t = 2, avg_loss = 0.0292\n",
            "t = 3, avg_loss = 0.0251\n",
            "t = 4, avg_loss = 0.0634\n",
            "t = 5, avg_loss = 0.0399\n",
            "t = 6, avg_loss = 0.0349\n",
            "t = 7, avg_loss = 0.0219\n",
            "t = 8, avg_loss = 0.0412\n",
            "t = 9, avg_loss = 0.0203\n",
            "t = 10, avg_loss = 0.0446\n",
            "t = 11, avg_loss = 0.0396\n",
            "t = 12, avg_loss = 0.0493\n",
            "t = 13, avg_loss = 0.0507\n",
            "t = 14, avg_loss = 0.0115\n",
            "t = 15, avg_loss = 0.0505\n",
            "Checking accuracy on test set\n",
            "Got 191 / 240 correct (79.58)\n",
            "acc = 0.795833\n",
            "Starting epoch 75 / 100\n",
            "t = 1, avg_loss = 0.1263\n",
            "t = 2, avg_loss = 0.0137\n",
            "t = 3, avg_loss = 0.0239\n",
            "t = 4, avg_loss = 0.0265\n",
            "t = 5, avg_loss = 0.0144\n",
            "t = 6, avg_loss = 0.0225\n",
            "t = 7, avg_loss = 0.0358\n",
            "t = 8, avg_loss = 0.0147\n",
            "t = 9, avg_loss = 0.0156\n",
            "t = 10, avg_loss = 0.0438\n",
            "t = 11, avg_loss = 0.0375\n",
            "t = 12, avg_loss = 0.0224\n",
            "t = 13, avg_loss = 0.0388\n",
            "t = 14, avg_loss = 0.0434\n",
            "t = 15, avg_loss = 0.0317\n",
            "Checking accuracy on test set\n",
            "Got 187 / 240 correct (77.92)\n",
            "acc = 0.779167\n",
            "Starting epoch 76 / 100\n",
            "t = 1, avg_loss = 0.0238\n",
            "t = 2, avg_loss = 0.0579\n",
            "t = 3, avg_loss = 0.0515\n",
            "t = 4, avg_loss = 0.0100\n",
            "t = 5, avg_loss = 0.0270\n",
            "t = 6, avg_loss = 0.0355\n",
            "t = 7, avg_loss = 0.0383\n",
            "t = 8, avg_loss = 0.0442\n",
            "t = 9, avg_loss = 0.0187\n",
            "t = 10, avg_loss = 0.0193\n",
            "t = 11, avg_loss = 0.0146\n",
            "t = 12, avg_loss = 0.0293\n",
            "t = 13, avg_loss = 0.0421\n",
            "t = 14, avg_loss = 0.0657\n",
            "t = 15, avg_loss = 0.0445\n",
            "Checking accuracy on test set\n",
            "Got 189 / 240 correct (78.75)\n",
            "acc = 0.787500\n",
            "Starting epoch 77 / 100\n",
            "t = 1, avg_loss = 0.0171\n",
            "t = 2, avg_loss = 0.0257\n",
            "t = 3, avg_loss = 0.0184\n",
            "t = 4, avg_loss = 0.0185\n",
            "t = 5, avg_loss = 0.0638\n",
            "t = 6, avg_loss = 0.0315\n",
            "t = 7, avg_loss = 0.0565\n",
            "t = 8, avg_loss = 0.0095\n",
            "t = 9, avg_loss = 0.0675\n",
            "t = 10, avg_loss = 0.0191\n",
            "t = 11, avg_loss = 0.0283\n",
            "t = 12, avg_loss = 0.1117\n",
            "t = 13, avg_loss = 0.0446\n",
            "t = 14, avg_loss = 0.0167\n",
            "t = 15, avg_loss = 0.0182\n",
            "Checking accuracy on test set\n",
            "Got 187 / 240 correct (77.92)\n",
            "acc = 0.779167\n",
            "Starting epoch 78 / 100\n",
            "t = 1, avg_loss = 0.0079\n",
            "t = 2, avg_loss = 0.1165\n",
            "t = 3, avg_loss = 0.0834\n",
            "t = 4, avg_loss = 0.0064\n",
            "t = 5, avg_loss = 0.0248\n",
            "t = 6, avg_loss = 0.0471\n",
            "t = 7, avg_loss = 0.0221\n",
            "t = 8, avg_loss = 0.0387\n",
            "t = 9, avg_loss = 0.0462\n",
            "t = 10, avg_loss = 0.0284\n",
            "t = 11, avg_loss = 0.0367\n",
            "t = 12, avg_loss = 0.1632\n",
            "t = 13, avg_loss = 0.0365\n",
            "t = 14, avg_loss = 0.0998\n",
            "t = 15, avg_loss = 0.0529\n",
            "Checking accuracy on test set\n",
            "Got 186 / 240 correct (77.50)\n",
            "acc = 0.775000\n",
            "Starting epoch 79 / 100\n",
            "t = 1, avg_loss = 0.0463\n",
            "t = 2, avg_loss = 0.0573\n",
            "t = 3, avg_loss = 0.0538\n",
            "t = 4, avg_loss = 0.0159\n",
            "t = 5, avg_loss = 0.1414\n",
            "t = 6, avg_loss = 0.0410\n",
            "t = 7, avg_loss = 0.0372\n",
            "t = 8, avg_loss = 0.0506\n",
            "t = 9, avg_loss = 0.0136\n",
            "t = 10, avg_loss = 0.0450\n",
            "t = 11, avg_loss = 0.0368\n",
            "t = 12, avg_loss = 0.0273\n",
            "t = 13, avg_loss = 0.0444\n",
            "t = 14, avg_loss = 0.0795\n",
            "t = 15, avg_loss = 0.0237\n",
            "Checking accuracy on test set\n",
            "Got 185 / 240 correct (77.08)\n",
            "acc = 0.770833\n",
            "Starting epoch 80 / 100\n",
            "t = 1, avg_loss = 0.0363\n",
            "t = 2, avg_loss = 0.0241\n",
            "t = 3, avg_loss = 0.0177\n",
            "t = 4, avg_loss = 0.0717\n",
            "t = 5, avg_loss = 0.0163\n",
            "t = 6, avg_loss = 0.0853\n",
            "t = 7, avg_loss = 0.0302\n",
            "t = 8, avg_loss = 0.0446\n",
            "t = 9, avg_loss = 0.0288\n",
            "t = 10, avg_loss = 0.0255\n",
            "t = 11, avg_loss = 0.0448\n",
            "t = 12, avg_loss = 0.0386\n",
            "t = 13, avg_loss = 0.0109\n",
            "t = 14, avg_loss = 0.0468\n",
            "t = 15, avg_loss = 0.0232\n",
            "Checking accuracy on test set\n",
            "Got 188 / 240 correct (78.33)\n",
            "acc = 0.783333\n",
            "Starting epoch 81 / 100\n",
            "t = 1, avg_loss = 0.0706\n",
            "t = 2, avg_loss = 0.0094\n",
            "t = 3, avg_loss = 0.0332\n",
            "t = 4, avg_loss = 0.0391\n",
            "t = 5, avg_loss = 0.0192\n",
            "t = 6, avg_loss = 0.0174\n",
            "t = 7, avg_loss = 0.0344\n",
            "t = 8, avg_loss = 0.0283\n",
            "t = 9, avg_loss = 0.0083\n",
            "t = 10, avg_loss = 0.0346\n",
            "t = 11, avg_loss = 0.0266\n",
            "t = 12, avg_loss = 0.0415\n",
            "t = 13, avg_loss = 0.1385\n",
            "t = 14, avg_loss = 0.0635\n",
            "t = 15, avg_loss = 0.0474\n",
            "Checking accuracy on test set\n",
            "Got 183 / 240 correct (76.25)\n",
            "acc = 0.762500\n",
            "Starting epoch 82 / 100\n",
            "t = 1, avg_loss = 0.0281\n",
            "t = 2, avg_loss = 0.0497\n",
            "t = 3, avg_loss = 0.0489\n",
            "t = 4, avg_loss = 0.1047\n",
            "t = 5, avg_loss = 0.0602\n",
            "t = 6, avg_loss = 0.0108\n",
            "t = 7, avg_loss = 0.0601\n",
            "t = 8, avg_loss = 0.0376\n",
            "t = 9, avg_loss = 0.0521\n",
            "t = 10, avg_loss = 0.0931\n",
            "t = 11, avg_loss = 0.0268\n",
            "t = 12, avg_loss = 0.0156\n",
            "t = 13, avg_loss = 0.0854\n",
            "t = 14, avg_loss = 0.0754\n",
            "t = 15, avg_loss = 0.1360\n",
            "Checking accuracy on test set\n",
            "Got 177 / 240 correct (73.75)\n",
            "acc = 0.737500\n",
            "Starting epoch 83 / 100\n",
            "t = 1, avg_loss = 0.0234\n",
            "t = 2, avg_loss = 0.0785\n",
            "t = 3, avg_loss = 0.1319\n",
            "t = 4, avg_loss = 0.0671\n",
            "t = 5, avg_loss = 0.0777\n",
            "t = 6, avg_loss = 0.0189\n",
            "t = 7, avg_loss = 0.0469\n",
            "t = 8, avg_loss = 0.0453\n",
            "t = 9, avg_loss = 0.0465\n",
            "t = 10, avg_loss = 0.0877\n",
            "t = 11, avg_loss = 0.0363\n",
            "t = 12, avg_loss = 0.0626\n",
            "t = 13, avg_loss = 0.0256\n",
            "t = 14, avg_loss = 0.0217\n",
            "t = 15, avg_loss = 0.0511\n",
            "Checking accuracy on test set\n",
            "Got 186 / 240 correct (77.50)\n",
            "acc = 0.775000\n",
            "Starting epoch 84 / 100\n",
            "t = 1, avg_loss = 0.0417\n",
            "t = 2, avg_loss = 0.0631\n",
            "t = 3, avg_loss = 0.0742\n",
            "t = 4, avg_loss = 0.0289\n",
            "t = 5, avg_loss = 0.1118\n",
            "t = 6, avg_loss = 0.0543\n",
            "t = 7, avg_loss = 0.0604\n",
            "t = 8, avg_loss = 0.0479\n",
            "t = 9, avg_loss = 0.0484\n",
            "t = 10, avg_loss = 0.0229\n",
            "t = 11, avg_loss = 0.0427\n",
            "t = 12, avg_loss = 0.0338\n",
            "t = 13, avg_loss = 0.0250\n",
            "t = 14, avg_loss = 0.0529\n",
            "t = 15, avg_loss = 0.1136\n",
            "Checking accuracy on test set\n",
            "Got 183 / 240 correct (76.25)\n",
            "acc = 0.762500\n",
            "Starting epoch 85 / 100\n",
            "t = 1, avg_loss = 0.0160\n",
            "t = 2, avg_loss = 0.0704\n",
            "t = 3, avg_loss = 0.0331\n",
            "t = 4, avg_loss = 0.0730\n",
            "t = 5, avg_loss = 0.2510\n",
            "t = 6, avg_loss = 0.0450\n",
            "t = 7, avg_loss = 0.0562\n",
            "t = 8, avg_loss = 0.1081\n",
            "t = 9, avg_loss = 0.0710\n",
            "t = 10, avg_loss = 0.0197\n",
            "t = 11, avg_loss = 0.0354\n",
            "t = 12, avg_loss = 0.0333\n",
            "t = 13, avg_loss = 0.0344\n",
            "t = 14, avg_loss = 0.0510\n",
            "t = 15, avg_loss = 0.0973\n",
            "Checking accuracy on test set\n",
            "Got 178 / 240 correct (74.17)\n",
            "acc = 0.741667\n",
            "Starting epoch 86 / 100\n",
            "t = 1, avg_loss = 0.0528\n",
            "t = 2, avg_loss = 0.0348\n",
            "t = 3, avg_loss = 0.1472\n",
            "t = 4, avg_loss = 0.0991\n",
            "t = 5, avg_loss = 0.0952\n",
            "t = 6, avg_loss = 0.0617\n",
            "t = 7, avg_loss = 0.0275\n",
            "t = 8, avg_loss = 0.1251\n",
            "t = 9, avg_loss = 0.0138\n",
            "t = 10, avg_loss = 0.0599\n",
            "t = 11, avg_loss = 0.0217\n",
            "t = 12, avg_loss = 0.0840\n",
            "t = 13, avg_loss = 0.0541\n",
            "t = 14, avg_loss = 0.0845\n",
            "t = 15, avg_loss = 0.0538\n",
            "Checking accuracy on test set\n",
            "Got 179 / 240 correct (74.58)\n",
            "acc = 0.745833\n",
            "Starting epoch 87 / 100\n",
            "t = 1, avg_loss = 0.0248\n",
            "t = 2, avg_loss = 0.0584\n",
            "t = 3, avg_loss = 0.0485\n",
            "t = 4, avg_loss = 0.0590\n",
            "t = 5, avg_loss = 0.0613\n",
            "t = 6, avg_loss = 0.0687\n",
            "t = 7, avg_loss = 0.0900\n",
            "t = 8, avg_loss = 0.0859\n",
            "t = 9, avg_loss = 0.0626\n",
            "t = 10, avg_loss = 0.0837\n",
            "t = 11, avg_loss = 0.0705\n",
            "t = 12, avg_loss = 0.0800\n",
            "t = 13, avg_loss = 0.1746\n",
            "t = 14, avg_loss = 0.0578\n",
            "t = 15, avg_loss = 0.0273\n",
            "Checking accuracy on test set\n",
            "Got 187 / 240 correct (77.92)\n",
            "acc = 0.779167\n",
            "Starting epoch 88 / 100\n",
            "t = 1, avg_loss = 0.0289\n",
            "t = 2, avg_loss = 0.0259\n",
            "t = 3, avg_loss = 0.0827\n",
            "t = 4, avg_loss = 0.0222\n",
            "t = 5, avg_loss = 0.0504\n",
            "t = 6, avg_loss = 0.0887\n",
            "t = 7, avg_loss = 0.0263\n",
            "t = 8, avg_loss = 0.2186\n",
            "t = 9, avg_loss = 0.0686\n",
            "t = 10, avg_loss = 0.0219\n",
            "t = 11, avg_loss = 0.0268\n",
            "t = 12, avg_loss = 0.0853\n",
            "t = 13, avg_loss = 0.1284\n",
            "t = 14, avg_loss = 0.0495\n",
            "t = 15, avg_loss = 0.0202\n",
            "Checking accuracy on test set\n",
            "Got 174 / 240 correct (72.50)\n",
            "acc = 0.725000\n",
            "Starting epoch 89 / 100\n",
            "t = 1, avg_loss = 0.0454\n",
            "t = 2, avg_loss = 0.0411\n",
            "t = 3, avg_loss = 0.0946\n",
            "t = 4, avg_loss = 0.0620\n",
            "t = 5, avg_loss = 0.0304\n",
            "t = 6, avg_loss = 0.0299\n",
            "t = 7, avg_loss = 0.0310\n",
            "t = 8, avg_loss = 0.1408\n",
            "t = 9, avg_loss = 0.0370\n",
            "t = 10, avg_loss = 0.1223\n",
            "t = 11, avg_loss = 0.0886\n",
            "t = 12, avg_loss = 0.0274\n",
            "t = 13, avg_loss = 0.0537\n",
            "t = 14, avg_loss = 0.0716\n",
            "t = 15, avg_loss = 0.0327\n",
            "Checking accuracy on test set\n",
            "Got 192 / 240 correct (80.00)\n",
            "acc = 0.800000\n",
            "Starting epoch 90 / 100\n",
            "t = 1, avg_loss = 0.0305\n",
            "t = 2, avg_loss = 0.0542\n",
            "t = 3, avg_loss = 0.1326\n",
            "t = 4, avg_loss = 0.0730\n",
            "t = 5, avg_loss = 0.0936\n",
            "t = 6, avg_loss = 0.0815\n",
            "t = 7, avg_loss = 0.0412\n",
            "t = 8, avg_loss = 0.0387\n",
            "t = 9, avg_loss = 0.0344\n",
            "t = 10, avg_loss = 0.0534\n",
            "t = 11, avg_loss = 0.0643\n",
            "t = 12, avg_loss = 0.0789\n",
            "t = 13, avg_loss = 0.1210\n",
            "t = 14, avg_loss = 0.0599\n",
            "t = 15, avg_loss = 0.0696\n",
            "Checking accuracy on test set\n",
            "Got 179 / 240 correct (74.58)\n",
            "acc = 0.745833\n",
            "Starting epoch 91 / 100\n",
            "t = 1, avg_loss = 0.1447\n",
            "t = 2, avg_loss = 0.0285\n",
            "t = 3, avg_loss = 0.0880\n",
            "t = 4, avg_loss = 0.0138\n",
            "t = 5, avg_loss = 0.0403\n",
            "t = 6, avg_loss = 0.0360\n",
            "t = 7, avg_loss = 0.0850\n",
            "t = 8, avg_loss = 0.0233\n",
            "t = 9, avg_loss = 0.0287\n",
            "t = 10, avg_loss = 0.0588\n",
            "t = 11, avg_loss = 0.0930\n",
            "t = 12, avg_loss = 0.0205\n",
            "t = 13, avg_loss = 0.0706\n",
            "t = 14, avg_loss = 0.0155\n",
            "t = 15, avg_loss = 0.0105\n",
            "Checking accuracy on test set\n",
            "Got 185 / 240 correct (77.08)\n",
            "acc = 0.770833\n",
            "Starting epoch 92 / 100\n",
            "t = 1, avg_loss = 0.0318\n",
            "t = 2, avg_loss = 0.0283\n",
            "t = 3, avg_loss = 0.0159\n",
            "t = 4, avg_loss = 0.0694\n",
            "t = 5, avg_loss = 0.0366\n",
            "t = 6, avg_loss = 0.0332\n",
            "t = 7, avg_loss = 0.0618\n",
            "t = 8, avg_loss = 0.0308\n",
            "t = 9, avg_loss = 0.0239\n",
            "t = 10, avg_loss = 0.0288\n",
            "t = 11, avg_loss = 0.0405\n",
            "t = 12, avg_loss = 0.0110\n",
            "t = 13, avg_loss = 0.0133\n",
            "t = 14, avg_loss = 0.0798\n",
            "t = 15, avg_loss = 0.0089\n",
            "Checking accuracy on test set\n",
            "Got 188 / 240 correct (78.33)\n",
            "acc = 0.783333\n",
            "Starting epoch 93 / 100\n",
            "t = 1, avg_loss = 0.0569\n",
            "t = 2, avg_loss = 0.0761\n",
            "t = 3, avg_loss = 0.1432\n",
            "t = 4, avg_loss = 0.0182\n",
            "t = 5, avg_loss = 0.0436\n",
            "t = 6, avg_loss = 0.0280\n",
            "t = 7, avg_loss = 0.0891\n",
            "t = 8, avg_loss = 0.0364\n",
            "t = 9, avg_loss = 0.0604\n",
            "t = 10, avg_loss = 0.0203\n",
            "t = 11, avg_loss = 0.0422\n",
            "t = 12, avg_loss = 0.0410\n",
            "t = 13, avg_loss = 0.0221\n",
            "t = 14, avg_loss = 0.0635\n",
            "t = 15, avg_loss = 0.0271\n",
            "Checking accuracy on test set\n",
            "Got 185 / 240 correct (77.08)\n",
            "acc = 0.770833\n",
            "Starting epoch 94 / 100\n",
            "t = 1, avg_loss = 0.0269\n",
            "t = 2, avg_loss = 0.0353\n",
            "t = 3, avg_loss = 0.0443\n",
            "t = 4, avg_loss = 0.0245\n",
            "t = 5, avg_loss = 0.0205\n",
            "t = 6, avg_loss = 0.0177\n",
            "t = 7, avg_loss = 0.1701\n",
            "t = 8, avg_loss = 0.0177\n",
            "t = 9, avg_loss = 0.0216\n",
            "t = 10, avg_loss = 0.1007\n",
            "t = 11, avg_loss = 0.0926\n",
            "t = 12, avg_loss = 0.0256\n",
            "t = 13, avg_loss = 0.1037\n",
            "t = 14, avg_loss = 0.0634\n",
            "t = 15, avg_loss = 0.0224\n",
            "Checking accuracy on test set\n",
            "Got 189 / 240 correct (78.75)\n",
            "acc = 0.787500\n",
            "Starting epoch 95 / 100\n",
            "t = 1, avg_loss = 0.0433\n",
            "t = 2, avg_loss = 0.0478\n",
            "t = 3, avg_loss = 0.0416\n",
            "t = 4, avg_loss = 0.0259\n",
            "t = 5, avg_loss = 0.0438\n",
            "t = 6, avg_loss = 0.0094\n",
            "t = 7, avg_loss = 0.0190\n",
            "t = 8, avg_loss = 0.0488\n",
            "t = 9, avg_loss = 0.0440\n",
            "t = 10, avg_loss = 0.0707\n",
            "t = 11, avg_loss = 0.0648\n",
            "t = 12, avg_loss = 0.0667\n",
            "t = 13, avg_loss = 0.0092\n",
            "t = 14, avg_loss = 0.0187\n",
            "t = 15, avg_loss = 0.0429\n",
            "Checking accuracy on test set\n",
            "Got 187 / 240 correct (77.92)\n",
            "acc = 0.779167\n",
            "Starting epoch 96 / 100\n",
            "t = 1, avg_loss = 0.0220\n",
            "t = 2, avg_loss = 0.0185\n",
            "t = 3, avg_loss = 0.0211\n",
            "t = 4, avg_loss = 0.0268\n",
            "t = 5, avg_loss = 0.0471\n",
            "t = 6, avg_loss = 0.0371\n",
            "t = 7, avg_loss = 0.0101\n",
            "t = 8, avg_loss = 0.0135\n",
            "t = 9, avg_loss = 0.0158\n",
            "t = 10, avg_loss = 0.0131\n",
            "t = 11, avg_loss = 0.0538\n",
            "t = 12, avg_loss = 0.0245\n",
            "t = 13, avg_loss = 0.0379\n",
            "t = 14, avg_loss = 0.0056\n",
            "t = 15, avg_loss = 0.0593\n",
            "Checking accuracy on test set\n",
            "Got 188 / 240 correct (78.33)\n",
            "acc = 0.783333\n",
            "Starting epoch 97 / 100\n",
            "t = 1, avg_loss = 0.0348\n",
            "t = 2, avg_loss = 0.0149\n",
            "t = 3, avg_loss = 0.0102\n",
            "t = 4, avg_loss = 0.0186\n",
            "t = 5, avg_loss = 0.0133\n",
            "t = 6, avg_loss = 0.0258\n",
            "t = 7, avg_loss = 0.0789\n",
            "t = 8, avg_loss = 0.0152\n",
            "t = 9, avg_loss = 0.0222\n",
            "t = 10, avg_loss = 0.0117\n",
            "t = 11, avg_loss = 0.0334\n",
            "t = 12, avg_loss = 0.0424\n",
            "t = 13, avg_loss = 0.0399\n",
            "t = 14, avg_loss = 0.0139\n",
            "t = 15, avg_loss = 0.0655\n",
            "Checking accuracy on test set\n",
            "Got 189 / 240 correct (78.75)\n",
            "acc = 0.787500\n",
            "Starting epoch 98 / 100\n",
            "t = 1, avg_loss = 0.0357\n",
            "t = 2, avg_loss = 0.0232\n",
            "t = 3, avg_loss = 0.0091\n",
            "t = 4, avg_loss = 0.0194\n",
            "t = 5, avg_loss = 0.0565\n",
            "t = 6, avg_loss = 0.0168\n",
            "t = 7, avg_loss = 0.0148\n",
            "t = 8, avg_loss = 0.0110\n",
            "t = 9, avg_loss = 0.0076\n",
            "t = 10, avg_loss = 0.0489\n",
            "t = 11, avg_loss = 0.0070\n",
            "t = 12, avg_loss = 0.0460\n",
            "t = 13, avg_loss = 0.0140\n",
            "t = 14, avg_loss = 0.0088\n",
            "t = 15, avg_loss = 0.0086\n",
            "Checking accuracy on test set\n",
            "Got 189 / 240 correct (78.75)\n",
            "acc = 0.787500\n",
            "Starting epoch 99 / 100\n",
            "t = 1, avg_loss = 0.0100\n",
            "t = 2, avg_loss = 0.0139\n",
            "t = 3, avg_loss = 0.0106\n",
            "t = 4, avg_loss = 0.0161\n",
            "t = 5, avg_loss = 0.0281\n",
            "t = 6, avg_loss = 0.0226\n",
            "t = 7, avg_loss = 0.0185\n",
            "t = 8, avg_loss = 0.0246\n",
            "t = 9, avg_loss = 0.0672\n",
            "t = 10, avg_loss = 0.0306\n",
            "t = 11, avg_loss = 0.0514\n",
            "t = 12, avg_loss = 0.0130\n",
            "t = 13, avg_loss = 0.0260\n",
            "t = 14, avg_loss = 0.0499\n",
            "t = 15, avg_loss = 0.0147\n",
            "Checking accuracy on test set\n",
            "Got 188 / 240 correct (78.33)\n",
            "acc = 0.783333\n",
            "Starting epoch 100 / 100\n",
            "t = 1, avg_loss = 0.0256\n",
            "t = 2, avg_loss = 0.0308\n",
            "t = 3, avg_loss = 0.0126\n",
            "t = 4, avg_loss = 0.0081\n",
            "t = 5, avg_loss = 0.0093\n",
            "t = 6, avg_loss = 0.0082\n",
            "t = 7, avg_loss = 0.0122\n",
            "t = 8, avg_loss = 0.0184\n",
            "t = 9, avg_loss = 0.0109\n",
            "t = 10, avg_loss = 0.0125\n",
            "t = 11, avg_loss = 0.0533\n",
            "t = 12, avg_loss = 0.0480\n",
            "t = 13, avg_loss = 0.0813\n",
            "t = 14, avg_loss = 0.0173\n",
            "t = 15, avg_loss = 0.0680\n",
            "Checking accuracy on test set\n",
            "Got 191 / 240 correct (79.58)\n",
            "acc = 0.795833\n",
            "Checking accuracy on test set\n",
            "Got 188 / 240 correct (78.33)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7833333333333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDn-2g-TLY3k",
        "colab_type": "code",
        "outputId": "592a3c3e-9a24-408f-d44c-199f8c72d39f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot([print_every*batch_size*(i+1) for i in range((len(avg_loss_list)))],avg_loss_list)\n",
        "print(\"Loss:\")\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD4CAYAAADsKpHdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nf3Pjj/cvZFEjAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGer6hJv7-zR",
        "colab_type": "code",
        "outputId": "c8da25f9-fcb6-4086-95a4-acd260091395",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "plt.plot([i+1 for i in range((len(acc_list)))],acc_list)\n",
        "print(\"Accurancy:\")\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accurancy:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njgq9oihKkqNCryiKkuSo0CuKoiQ5/x/KKyVF/yrcBgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBTReWHxz4Ml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}