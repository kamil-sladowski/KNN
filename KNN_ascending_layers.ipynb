{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN_ascending_layers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNUCQ4nsGBzT1gPaSqUth/b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamilo116/KNN/blob/master/KNN_ascending_layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7ReM7FU-xs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import sys\n",
        "from random import shuffle\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms as transforms\n",
        "import timeit\n",
        "\n",
        "np.random.seed(4) \n",
        "torch.manual_seed(4) \n",
        "torch.cuda.manual_seed(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYIMZ8QyYewD",
        "colab_type": "code",
        "outputId": "ff5be003-2da9-47ad-f42e-79e9a842a155",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "! git clone https://github.com/wang-chen/kervolution.git \n",
        "\n",
        "sys.path.append(\"kervolution/\")\n",
        "from kervolution import Kerv2d\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'kervolution'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 53 (delta 2), reused 0 (delta 0), pack-reused 47\u001b[K\n",
            "Unpacking objects: 100% (53/53), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvbKg4VJXKY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LIMIT_IMAGES_NUM = 1000\n",
        "train_test_split_size = 0.2\n",
        "image_resize = (100, 100)\n",
        "batch_size = 64\n",
        "num_workers = 0\n",
        "\n",
        "out_1 = 16\n",
        "out_2 = 32\n",
        "out_3 = 64\n",
        "out_4 = 128\n",
        "\n",
        "\n",
        "k_size_1 = 3\n",
        "padding_1 = 1\n",
        "in_channels = 3\n",
        "\n",
        "kernel_size = 3\n",
        "num_epochs = 100\n",
        "\n",
        "learning_rate = 0.00012\n",
        "weight_decay = 0\n",
        "\n",
        "MALIGNANT_DATASET = '/content/drive/My Drive/Colab_data/malignant/malignant/'\n",
        "BENIGN_DATASET = '/content/drive/My Drive/Colab_data/benign/benign/'\n",
        "DATA_FOLDER = '/content/drive/My Drive/Colab_data/'\n",
        "model_backup_path = os.path.join(DATA_FOLDER, 'backup_model') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMOHez_kHZD6",
        "colab_type": "code",
        "outputId": "91bb203b-660e-4c8c-c854-b0adff36dd82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b8P1NdXfVdX",
        "colab_type": "code",
        "outputId": "ca9e0894-793a-4018-8158-fc3cc3c766bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "benign_file_list = sorted(os.listdir(BENIGN_DATASET))\n",
        "malignant_file_list = sorted(os.listdir(MALIGNANT_DATASET))\n",
        "shuffle(benign_file_list)\n",
        "shuffle(malignant_file_list)\n",
        "benign_file_list = benign_file_list[:LIMIT_IMAGES_NUM]\n",
        "malignant_file_list = malignant_file_list[:LIMIT_IMAGES_NUM]\n",
        "\n",
        "print(f\"Number of benign {len(benign_file_list)} images\")\n",
        "print(f\"Number of malignant {len(malignant_file_list)} images\")\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize(image_resize),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of benign 1000 images\n",
            "Number of malignant 1000 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGDQfal74BLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "benign_dict = {filename: 0 for filename in benign_file_list}\n",
        "malignant_dict = {filename: 1 for filename in malignant_file_list}\n",
        "img_class_dict = {**benign_dict , **malignant_dict}\n",
        "labeled_data = pd.Series(img_class_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvAAOqmVfVll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IsicDataset(Dataset):\n",
        "    def __init__(self, data_folder, labeled_data, \n",
        "                 transform=transforms.Compose([transforms.ToTensor()])):\n",
        "        self.labeled_data = labeled_data\n",
        "        self.transform = transform\n",
        "        self.data_folder = data_folder\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labeled_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        label = self.labeled_data[index]\n",
        "        if label == 0:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"benign\", \"benign\", index ))\n",
        "        else:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"malignant\", \"malignant\", index ))\n",
        "        image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "    @property\n",
        "    def labels(self):\n",
        "      return self.labeled_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSuYqjLAYrWA",
        "colab_type": "code",
        "outputId": "ecf1eea3-c2b0-4555-ed4b-eb6b9003ef7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        }
      },
      "source": [
        "dataset = IsicDataset(DATA_FOLDER, labeled_data, transform=data_transforms)\n",
        "print(dataset.labels)\n",
        "\n",
        "X_train, X_test = train_test_split(dataset.labels, test_size=train_test_split_size)\n",
        "print(\"number of training data: \",len(X_train))\n",
        "print(\"number of testing  data: \",len(X_test))\n",
        "\n",
        "train_sampler = SubsetRandomSampler(list(X_train.index))\n",
        "valid_sampler = SubsetRandomSampler(list(X_test.index))\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ISIC_0000566.jpeg    0\n",
            "ISIC_0000950.jpeg    0\n",
            "ISIC_0000957.jpeg    0\n",
            "ISIC_0001379.jpeg    0\n",
            "ISIC_0001145.jpeg    0\n",
            "                    ..\n",
            "ISIC_0025316.jpg     1\n",
            "ISIC_0010280.jpeg    1\n",
            "ISIC_0013815.jpeg    1\n",
            "ISIC_0011196.jpeg    1\n",
            "ISIC_0025128.jpg     1\n",
            "Length: 2000, dtype: int64\n",
            "number of training data:  1600\n",
            "number of testing  data:  400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e8nFBR6Yug5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "def train(model, train_loader ,loss_fn, optimizer, num_epochs=1, starting_from_epoch=1):\n",
        "    total_loss =0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
        "        model.train()\n",
        "\n",
        "        for t, (x, y) in enumerate(train_loader):\n",
        "            x_var = Variable(x.type(gpu_dtype))\n",
        "            y_var = Variable(y.type(gpu_dtype).long())\n",
        "            scores = model(x_var)\n",
        "            loss = loss_fn(scores, y_var)\n",
        "            total_loss += loss.data\n",
        "            \n",
        "            if (t + 1) % print_every == 0:\n",
        "                avg_loss = total_loss/print_every\n",
        "                print('t = %d, avg_loss = %.4f' % (t + 1, avg_loss) )\n",
        "                avg_loss_list.append(avg_loss)\n",
        "                total_loss = 0\n",
        "                \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        acc = check_accuracy(model_gpu, valid_loader)\n",
        "        print('acc = %f' %(acc))\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model_gpu.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            'acc_list': acc_list,\n",
        "            }, model_backup_path)\n",
        "            \n",
        "def check_accuracy(model, loader):\n",
        "    print('Checking accuracy on test set')   \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval() \n",
        "    for x, y in loader:\n",
        "        x_var = Variable(x.type(gpu_dtype))\n",
        "\n",
        "        scores = model(x_var)\n",
        "        _, preds = scores.data.cpu().max(1)\n",
        "        num_correct += (preds == y).sum()\n",
        "        num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    acc_list.append(acc)\n",
        "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "    return acc\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggvpMu36Yw2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.size()\n",
        "        return x.view(N, -1)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-gYHw0Jlbwt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print_every = 2\n",
        "gpu_dtype = torch.cuda.FloatTensor\n",
        "\n",
        "\n",
        "'''\n",
        "Kerv2d\n",
        "kervolution with following options:\n",
        "kernel_type: [linear, polynomial, gaussian, etc.]\n",
        "default is convolution:\n",
        "          kernel_type --> linear,\n",
        "balance, power, gamma is valid only when the kernel_type is specified\n",
        "if learnable_kernel = True,  they just be the initial value of learable parameters\n",
        "if learnable_kernel = False, they are the value of kernel_type's parameter\n",
        "the parameter [power] cannot be learned due to integer limitation\n",
        "dilation (int or tuple, optional): Spacing between kernel\n",
        "elements. Default: 1\n",
        "groups (int, optional): Number of blocked connections from input\n",
        "channels to output channels. Default: 1\n",
        "bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n",
        "kernel_type (str), Default: 'linear'\n",
        "learnable_kernel (bool): Learnable kernel parameters.  Default: False \n",
        "balance: 0, 1\n",
        "power: 3, 4, 5\n",
        "gamma:\n",
        "'''\n",
        "\n",
        "\n",
        "model_base = nn.Sequential( \n",
        "                nn.Kerv2d(in_channels , out_1, padding=padding_1, dilation=1, groups=1, bias=True, \n",
        "                          kernel_type='linear', kernel_size=k_size_1,# learnable_kernel=True,\n",
        "                          #kernel_regularizer=True, stride=1, balance=1, power=3, gamma=1\n",
        "                          ), \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_1),\n",
        "                nn.Conv2d(out_1 , out_2, padding= padding_1, kernel_size=k_size_1, stride=1), \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_2),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_2 , out_3, padding= padding_1, kernel_size=k_size_1, stride=1),  \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_3),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_3 , out_4, padding= padding_1, kernel_size=k_size_1, stride=1),  \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_4),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Dropout(0.5),\n",
        "                Flatten(),\n",
        "                nn.Linear(18432,64),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Linear(64,2)\n",
        "            )\n",
        "model_gpu = model_base.type(gpu_dtype)\n",
        "print(model_gpu)\n",
        "loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgmexhBRZAK6",
        "colab_type": "code",
        "outputId": "c16b7c60-43a6-40d8-e0d7-796f0129d1c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs)\n",
        "check_accuracy(model_gpu, valid_loader)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Kerv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (4): ReLU(inplace=True)\n",
            "  (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (7): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (8): ReLU(inplace=True)\n",
            "  (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (11): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (12): ReLU(inplace=True)\n",
            "  (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (15): Dropout(p=0.5, inplace=False)\n",
            "  (16): Flatten()\n",
            "  (17): Linear(in_features=18432, out_features=64, bias=True)\n",
            "  (18): ReLU(inplace=True)\n",
            "  (19): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n",
            "Starting epoch 1 / 100\n",
            "t = 2, avg_loss = 0.6769\n",
            "t = 4, avg_loss = 0.4503\n",
            "t = 6, avg_loss = 0.6346\n",
            "t = 8, avg_loss = 0.5326\n",
            "t = 10, avg_loss = 0.4922\n",
            "t = 12, avg_loss = 0.4598\n",
            "t = 14, avg_loss = 0.4810\n",
            "t = 16, avg_loss = 0.4296\n",
            "t = 18, avg_loss = 0.4138\n",
            "t = 20, avg_loss = 0.4499\n",
            "t = 22, avg_loss = 0.3857\n",
            "t = 24, avg_loss = 0.4742\n",
            "Checking accuracy on test set\n",
            "Got 204 / 400 correct (51.00)\n",
            "acc = 0.510000\n",
            "Starting epoch 2 / 100\n",
            "t = 2, avg_loss = 0.6559\n",
            "t = 4, avg_loss = 0.4454\n",
            "t = 6, avg_loss = 0.4245\n",
            "t = 8, avg_loss = 0.3368\n",
            "t = 10, avg_loss = 0.3517\n",
            "t = 12, avg_loss = 0.3781\n",
            "t = 14, avg_loss = 0.4071\n",
            "t = 16, avg_loss = 0.4257\n",
            "t = 18, avg_loss = 0.3256\n",
            "t = 20, avg_loss = 0.2454\n",
            "t = 22, avg_loss = 0.3077\n",
            "t = 24, avg_loss = 0.2707\n",
            "Checking accuracy on test set\n",
            "Got 267 / 400 correct (66.75)\n",
            "acc = 0.667500\n",
            "Starting epoch 3 / 100\n",
            "t = 2, avg_loss = 0.5678\n",
            "t = 4, avg_loss = 0.3456\n",
            "t = 6, avg_loss = 0.2759\n",
            "t = 8, avg_loss = 0.2700\n",
            "t = 10, avg_loss = 0.3576\n",
            "t = 12, avg_loss = 0.2450\n",
            "t = 14, avg_loss = 0.2683\n",
            "t = 16, avg_loss = 0.3313\n",
            "t = 18, avg_loss = 0.3039\n",
            "t = 20, avg_loss = 0.3185\n",
            "t = 22, avg_loss = 0.2991\n",
            "t = 24, avg_loss = 0.2450\n",
            "Checking accuracy on test set\n",
            "Got 328 / 400 correct (82.00)\n",
            "acc = 0.820000\n",
            "Starting epoch 4 / 100\n",
            "t = 2, avg_loss = 0.4427\n",
            "t = 4, avg_loss = 0.2102\n",
            "t = 6, avg_loss = 0.3356\n",
            "t = 8, avg_loss = 0.2392\n",
            "t = 10, avg_loss = 0.3647\n",
            "t = 12, avg_loss = 0.2597\n",
            "t = 14, avg_loss = 0.2568\n",
            "t = 16, avg_loss = 0.3014\n",
            "t = 18, avg_loss = 0.3670\n",
            "t = 20, avg_loss = 0.2300\n",
            "t = 22, avg_loss = 0.2733\n",
            "t = 24, avg_loss = 0.2157\n",
            "Checking accuracy on test set\n",
            "Got 330 / 400 correct (82.50)\n",
            "acc = 0.825000\n",
            "Starting epoch 5 / 100\n",
            "t = 2, avg_loss = 0.3167\n",
            "t = 4, avg_loss = 0.2477\n",
            "t = 6, avg_loss = 0.3477\n",
            "t = 8, avg_loss = 0.2752\n",
            "t = 10, avg_loss = 0.2434\n",
            "t = 12, avg_loss = 0.2289\n",
            "t = 14, avg_loss = 0.2310\n",
            "t = 16, avg_loss = 0.2648\n",
            "t = 18, avg_loss = 0.2731\n",
            "t = 20, avg_loss = 0.2965\n",
            "t = 22, avg_loss = 0.2667\n",
            "t = 24, avg_loss = 0.3049\n",
            "Checking accuracy on test set\n",
            "Got 340 / 400 correct (85.00)\n",
            "acc = 0.850000\n",
            "Starting epoch 6 / 100\n",
            "t = 2, avg_loss = 0.3089\n",
            "t = 4, avg_loss = 0.2828\n",
            "t = 6, avg_loss = 0.1886\n",
            "t = 8, avg_loss = 0.2590\n",
            "t = 10, avg_loss = 0.3410\n",
            "t = 12, avg_loss = 0.2432\n",
            "t = 14, avg_loss = 0.2242\n",
            "t = 16, avg_loss = 0.2302\n",
            "t = 18, avg_loss = 0.1862\n",
            "t = 20, avg_loss = 0.3214\n",
            "t = 22, avg_loss = 0.2479\n",
            "t = 24, avg_loss = 0.2642\n",
            "Checking accuracy on test set\n",
            "Got 332 / 400 correct (83.00)\n",
            "acc = 0.830000\n",
            "Starting epoch 7 / 100\n",
            "t = 2, avg_loss = 0.3464\n",
            "t = 4, avg_loss = 0.2473\n",
            "t = 6, avg_loss = 0.2136\n",
            "t = 8, avg_loss = 0.2156\n",
            "t = 10, avg_loss = 0.2483\n",
            "t = 12, avg_loss = 0.2373\n",
            "t = 14, avg_loss = 0.1800\n",
            "t = 16, avg_loss = 0.1628\n",
            "t = 18, avg_loss = 0.1894\n",
            "t = 20, avg_loss = 0.2361\n",
            "t = 22, avg_loss = 0.2054\n",
            "t = 24, avg_loss = 0.2137\n",
            "Checking accuracy on test set\n",
            "Got 334 / 400 correct (83.50)\n",
            "acc = 0.835000\n",
            "Starting epoch 8 / 100\n",
            "t = 2, avg_loss = 0.3172\n",
            "t = 4, avg_loss = 0.2798\n",
            "t = 6, avg_loss = 0.1701\n",
            "t = 8, avg_loss = 0.1651\n",
            "t = 10, avg_loss = 0.2324\n",
            "t = 12, avg_loss = 0.2428\n",
            "t = 14, avg_loss = 0.1318\n",
            "t = 16, avg_loss = 0.2771\n",
            "t = 18, avg_loss = 0.2197\n",
            "t = 20, avg_loss = 0.1993\n",
            "t = 22, avg_loss = 0.2193\n",
            "t = 24, avg_loss = 0.2106\n",
            "Checking accuracy on test set\n",
            "Got 335 / 400 correct (83.75)\n",
            "acc = 0.837500\n",
            "Starting epoch 9 / 100\n",
            "t = 2, avg_loss = 0.2632\n",
            "t = 4, avg_loss = 0.1369\n",
            "t = 6, avg_loss = 0.1588\n",
            "t = 8, avg_loss = 0.2262\n",
            "t = 10, avg_loss = 0.1950\n",
            "t = 12, avg_loss = 0.1971\n",
            "t = 14, avg_loss = 0.2480\n",
            "t = 16, avg_loss = 0.2245\n",
            "t = 18, avg_loss = 0.2135\n",
            "t = 20, avg_loss = 0.1710\n",
            "t = 22, avg_loss = 0.2643\n",
            "t = 24, avg_loss = 0.2586\n",
            "Checking accuracy on test set\n",
            "Got 331 / 400 correct (82.75)\n",
            "acc = 0.827500\n",
            "Starting epoch 10 / 100\n",
            "t = 2, avg_loss = 0.2509\n",
            "t = 4, avg_loss = 0.1953\n",
            "t = 6, avg_loss = 0.1992\n",
            "t = 8, avg_loss = 0.1603\n",
            "t = 10, avg_loss = 0.1971\n",
            "t = 12, avg_loss = 0.1455\n",
            "t = 14, avg_loss = 0.1692\n",
            "t = 16, avg_loss = 0.1621\n",
            "t = 18, avg_loss = 0.2187\n",
            "t = 20, avg_loss = 0.1703\n",
            "t = 22, avg_loss = 0.2474\n",
            "t = 24, avg_loss = 0.2030\n",
            "Checking accuracy on test set\n",
            "Got 333 / 400 correct (83.25)\n",
            "acc = 0.832500\n",
            "Starting epoch 11 / 100\n",
            "t = 2, avg_loss = 0.3942\n",
            "t = 4, avg_loss = 0.1730\n",
            "t = 6, avg_loss = 0.1448\n",
            "t = 8, avg_loss = 0.1924\n",
            "t = 10, avg_loss = 0.1411\n",
            "t = 12, avg_loss = 0.1601\n",
            "t = 14, avg_loss = 0.1274\n",
            "t = 16, avg_loss = 0.1803\n",
            "t = 18, avg_loss = 0.1790\n",
            "t = 20, avg_loss = 0.1773\n",
            "t = 22, avg_loss = 0.1230\n",
            "t = 24, avg_loss = 0.1623\n",
            "Checking accuracy on test set\n",
            "Got 341 / 400 correct (85.25)\n",
            "acc = 0.852500\n",
            "Starting epoch 12 / 100\n",
            "t = 2, avg_loss = 0.1667\n",
            "t = 4, avg_loss = 0.1319\n",
            "t = 6, avg_loss = 0.1780\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-120e130bd11a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_gpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0mcheck_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-87b2c8b33d30>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, loss_fn, optimizer, num_epochs, starting_from_epoch)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mx_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0my_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-50a9cd504daf>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m           \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"malignant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"malignant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \"\"\"\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   1856\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1858\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreducing_gap\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresample\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mNEAREST\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvoCj5uscUsz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_accurancy(acc_list):\n",
        "  plt.plot([i+1 for i in range((len(acc_list)))],acc_list)\n",
        "  print(\"Accurancy:\")\n",
        "  plt.show()\n",
        "\n",
        "def plot_loss_function(avg_loss_list):\n",
        "  plt.plot([print_every*batch_size*(i+1) for i in range((len(avg_loss_list)))],avg_loss_list)\n",
        "  print(\"Loss:\")\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzuX5gLEeJfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def retry_from_backup():\n",
        "  model_gpu = model_base.type(gpu_dtype)\n",
        "  print(model_gpu)\n",
        "  loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) \n",
        "\n",
        "\n",
        "\n",
        "  checkpoint = torch.load(model_backup_path)\n",
        "  model_gpu.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  epoch = checkpoint['epoch']\n",
        "  loss = checkpoint['loss']\n",
        "  acc_list = checkpoint['acc_list']\n",
        "  #avg_loss_list = checkpoint['avg_loss_list']\n",
        "  print(\"starting from epoch: \" + str(epoch))\n",
        "  print(\"starting from loss: \" + str(loss))\n",
        "  print(acc_list)\n",
        "  \n",
        "  \n",
        "  train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=88, starting_from_epoch=epoch)\n",
        "  check_accuracy(model_gpu, valid_loader)\n",
        "\n",
        "  plot_accurancy(acc_list)\n",
        "  plot_loss_function(avg_loss_list)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--rQZKqOalaJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fab658a8-fcb8-4640-c871-c99549bcefb5"
      },
      "source": [
        "retry_from_backup()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Kerv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (4): ReLU(inplace=True)\n",
            "  (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (7): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (8): ReLU(inplace=True)\n",
            "  (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (11): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (12): ReLU(inplace=True)\n",
            "  (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (15): Dropout(p=0.5, inplace=False)\n",
            "  (16): Flatten()\n",
            "  (17): Linear(in_features=18432, out_features=64, bias=True)\n",
            "  (18): ReLU(inplace=True)\n",
            "  (19): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n",
            "Sequential(\n",
            "  (0): Kerv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (4): ReLU(inplace=True)\n",
            "  (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (7): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (8): ReLU(inplace=True)\n",
            "  (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (11): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (12): ReLU(inplace=True)\n",
            "  (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (15): Dropout(p=0.5, inplace=False)\n",
            "  (16): Flatten()\n",
            "  (17): Linear(in_features=18432, out_features=64, bias=True)\n",
            "  (18): ReLU(inplace=True)\n",
            "  (19): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n",
            "starting from epoch: 10\n",
            "starting from loss: tensor(0.1353, device='cuda:0', requires_grad=True)\n",
            "[0.51, 0.6675, 0.82, 0.825, 0.85, 0.83, 0.835, 0.8375, 0.8275, 0.8325, 0.8525]\n",
            "Accurancy:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 1 / 88\n",
            "t = 2, avg_loss = 0.2595\n",
            "t = 4, avg_loss = 0.1803\n",
            "t = 6, avg_loss = 0.1734\n",
            "t = 8, avg_loss = 0.2217\n",
            "t = 10, avg_loss = 0.2101\n",
            "t = 12, avg_loss = 0.2879\n",
            "t = 14, avg_loss = 0.2265\n",
            "t = 16, avg_loss = 0.2763\n",
            "t = 18, avg_loss = 0.2107\n",
            "t = 20, avg_loss = 0.2760\n",
            "t = 22, avg_loss = 0.1483\n",
            "t = 24, avg_loss = 0.1814\n",
            "Checking accuracy on test set\n",
            "Got 368 / 400 correct (92.00)\n",
            "acc = 0.920000\n",
            "Starting epoch 2 / 88\n",
            "t = 2, avg_loss = 0.2973\n",
            "t = 4, avg_loss = 0.1668\n",
            "t = 6, avg_loss = 0.1329\n",
            "t = 8, avg_loss = 0.1517\n",
            "t = 10, avg_loss = 0.2732\n",
            "t = 12, avg_loss = 0.1872\n",
            "t = 14, avg_loss = 0.2116\n",
            "t = 16, avg_loss = 0.1611\n",
            "t = 18, avg_loss = 0.1959\n",
            "t = 20, avg_loss = 0.1792\n",
            "t = 22, avg_loss = 0.1702\n",
            "t = 24, avg_loss = 0.1986\n",
            "Checking accuracy on test set\n",
            "Got 360 / 400 correct (90.00)\n",
            "acc = 0.900000\n",
            "Starting epoch 3 / 88\n",
            "t = 2, avg_loss = 0.2188\n",
            "t = 4, avg_loss = 0.1232\n",
            "t = 6, avg_loss = 0.1434\n",
            "t = 8, avg_loss = 0.1575\n",
            "t = 10, avg_loss = 0.1523\n",
            "t = 12, avg_loss = 0.2383\n",
            "t = 14, avg_loss = 0.1505\n",
            "t = 16, avg_loss = 0.2139\n",
            "t = 18, avg_loss = 0.2041\n",
            "t = 20, avg_loss = 0.2422\n",
            "t = 22, avg_loss = 0.1647\n",
            "t = 24, avg_loss = 0.1953\n",
            "Checking accuracy on test set\n",
            "Got 362 / 400 correct (90.50)\n",
            "acc = 0.905000\n",
            "Starting epoch 4 / 88\n",
            "t = 2, avg_loss = 0.3329\n",
            "t = 4, avg_loss = 0.1634\n",
            "t = 6, avg_loss = 0.1414\n",
            "t = 8, avg_loss = 0.0966\n",
            "t = 10, avg_loss = 0.1248\n",
            "t = 12, avg_loss = 0.1156\n",
            "t = 14, avg_loss = 0.2697\n",
            "t = 16, avg_loss = 0.1559\n",
            "t = 18, avg_loss = 0.1995\n",
            "t = 20, avg_loss = 0.1408\n",
            "t = 22, avg_loss = 0.1637\n",
            "t = 24, avg_loss = 0.1327\n",
            "Checking accuracy on test set\n",
            "Got 359 / 400 correct (89.75)\n",
            "acc = 0.897500\n",
            "Starting epoch 5 / 88\n",
            "t = 2, avg_loss = 0.1445\n",
            "t = 4, avg_loss = 0.1594\n",
            "t = 6, avg_loss = 0.2034\n",
            "t = 8, avg_loss = 0.1210\n",
            "t = 10, avg_loss = 0.1485\n",
            "t = 12, avg_loss = 0.1914\n",
            "t = 14, avg_loss = 0.1748\n",
            "t = 16, avg_loss = 0.1145\n",
            "t = 18, avg_loss = 0.2950\n",
            "t = 20, avg_loss = 0.1240\n",
            "t = 22, avg_loss = 0.1797\n",
            "t = 24, avg_loss = 0.1532\n",
            "Checking accuracy on test set\n",
            "Got 358 / 400 correct (89.50)\n",
            "acc = 0.895000\n",
            "Starting epoch 6 / 88\n",
            "t = 2, avg_loss = 0.2033\n",
            "t = 4, avg_loss = 0.1340\n",
            "t = 6, avg_loss = 0.0974\n",
            "t = 8, avg_loss = 0.1603\n",
            "t = 10, avg_loss = 0.1455\n",
            "t = 12, avg_loss = 0.2115\n",
            "t = 14, avg_loss = 0.1691\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}