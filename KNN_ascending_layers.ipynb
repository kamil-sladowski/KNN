{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN_ascending_layers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMFkmKVOFzdfmHoOmbZINFX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamilo116/KNN/blob/master/KNN_ascending_layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7ReM7FU-xs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import sys\n",
        "from random import shuffle\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "import timeit\n",
        "\n",
        "np.random.seed(4) \n",
        "torch.manual_seed(4) \n",
        "torch.cuda.manual_seed(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMOHez_kHZD6",
        "colab_type": "code",
        "outputId": "9adeea1f-aae1-4059-8207-bc9142f35ce4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYIMZ8QyYewD",
        "colab_type": "code",
        "outputId": "eeb94b29-5607-4ddf-d12a-6bd8ae8b2960",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "! git clone https://github.com/wang-chen/kervolution.git \n",
        "\n",
        "sys.path.append(\"kervolution/\")\n",
        "from kervolution import Kerv2d\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'kervolution'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects:  16% (1/6)\u001b[K\rremote: Counting objects:  33% (2/6)\u001b[K\rremote: Counting objects:  50% (3/6)\u001b[K\rremote: Counting objects:  66% (4/6)\u001b[K\rremote: Counting objects:  83% (5/6)\u001b[K\rremote: Counting objects: 100% (6/6)\u001b[K\rremote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects:  16% (1/6)\u001b[K\rremote: Compressing objects:  33% (2/6)\u001b[K\rremote: Compressing objects:  50% (3/6)\u001b[K\rremote: Compressing objects:  66% (4/6)\u001b[K\rremote: Compressing objects:  83% (5/6)\u001b[K\rremote: Compressing objects: 100% (6/6)\u001b[K\rremote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "Unpacking objects:   1% (1/53)   \rUnpacking objects:   3% (2/53)   \rUnpacking objects:   5% (3/53)   \rUnpacking objects:   7% (4/53)   \rUnpacking objects:   9% (5/53)   \rUnpacking objects:  11% (6/53)   \rUnpacking objects:  13% (7/53)   \rUnpacking objects:  15% (8/53)   \rUnpacking objects:  16% (9/53)   \rUnpacking objects:  18% (10/53)   \rUnpacking objects:  20% (11/53)   \rUnpacking objects:  22% (12/53)   \rUnpacking objects:  24% (13/53)   \rUnpacking objects:  26% (14/53)   \rUnpacking objects:  28% (15/53)   \rUnpacking objects:  30% (16/53)   \rUnpacking objects:  32% (17/53)   \rUnpacking objects:  33% (18/53)   \rremote: Total 53 (delta 2), reused 0 (delta 0), pack-reused 47\u001b[K\n",
            "Unpacking objects:  35% (19/53)   \rUnpacking objects:  37% (20/53)   \rUnpacking objects:  39% (21/53)   \rUnpacking objects:  41% (22/53)   \rUnpacking objects:  43% (23/53)   \rUnpacking objects:  45% (24/53)   \rUnpacking objects:  47% (25/53)   \rUnpacking objects:  49% (26/53)   \rUnpacking objects:  50% (27/53)   \rUnpacking objects:  52% (28/53)   \rUnpacking objects:  54% (29/53)   \rUnpacking objects:  56% (30/53)   \rUnpacking objects:  58% (31/53)   \rUnpacking objects:  60% (32/53)   \rUnpacking objects:  62% (33/53)   \rUnpacking objects:  64% (34/53)   \rUnpacking objects:  66% (35/53)   \rUnpacking objects:  67% (36/53)   \rUnpacking objects:  69% (37/53)   \rUnpacking objects:  71% (38/53)   \rUnpacking objects:  73% (39/53)   \rUnpacking objects:  75% (40/53)   \rUnpacking objects:  77% (41/53)   \rUnpacking objects:  79% (42/53)   \rUnpacking objects:  81% (43/53)   \rUnpacking objects:  83% (44/53)   \rUnpacking objects:  84% (45/53)   \rUnpacking objects:  86% (46/53)   \rUnpacking objects:  88% (47/53)   \rUnpacking objects:  90% (48/53)   \rUnpacking objects:  92% (49/53)   \rUnpacking objects:  94% (50/53)   \rUnpacking objects:  96% (51/53)   \rUnpacking objects:  98% (52/53)   \rUnpacking objects: 100% (53/53)   \rUnpacking objects: 100% (53/53), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b8P1NdXfVdX",
        "colab_type": "code",
        "outputId": "f0cd28ca-3eed-45c7-c6c0-175a8954bc62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "MALIGNANT_DATASET = '/content/drive/My Drive/Colab_data/malignant/malignant/'\n",
        "BENIGN_DATASET = '/content/drive/My Drive/Colab_data/benign/benign/'\n",
        "DATA_FOLDER = '/content/drive/My Drive/Colab_data/'\n",
        "LIMIT_IMAGES_NUM = 600\n",
        "\n",
        "benign_file_list = sorted(os.listdir(BENIGN_DATASET))[:LIMIT_IMAGES_NUM]\n",
        "malignant_file_list = sorted(os.listdir(MALIGNANT_DATASET))[:LIMIT_IMAGES_NUM]\n",
        "shuffle(benign_file_list)\n",
        "shuffle(malignant_file_list)\n",
        "\n",
        "print(f\"Number of benign {len(benign_file_list)} images\")\n",
        "print(f\"Number of malignant {len(malignant_file_list)} images\")\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize((100, 100)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of benign 600 images\n",
            "Number of malignant 600 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGDQfal74BLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "benign_dict = {filename: 0 for filename in benign_file_list}\n",
        "malignant_dict = {filename: 1 for filename in malignant_file_list}\n",
        "img_class_dict = {**benign_dict , **malignant_dict}\n",
        "labeled_data = pd.Series(img_class_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvAAOqmVfVll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IsicDataset(Dataset):\n",
        "    def __init__(self, data_folder, labeled_data, \n",
        "                 transform=transforms.Compose([transforms.ToTensor()])):\n",
        "        self.labeled_data = labeled_data\n",
        "        self.transform = transform\n",
        "        self.data_folder = data_folder\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labeled_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        label = self.labeled_data[index]\n",
        "        if label == 0:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"benign\", \"benign\", index ))\n",
        "        else:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"malignant\", \"malignant\", index ))\n",
        "        image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "    @property\n",
        "    def labels(self):\n",
        "      return self.labeled_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSuYqjLAYrWA",
        "colab_type": "code",
        "outputId": "94f854f0-a26a-461a-d2ac-7889bf249eff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        " \n",
        "dataset = IsicDataset(DATA_FOLDER, labeled_data, transform=data_transforms)\n",
        "print(dataset.labels)\n",
        "\n",
        "X_train, X_test = train_test_split(dataset.labels, test_size=0.2)\n",
        "print(\"number of training data: \",len(X_train))\n",
        "print(\"number of testing  data: \",len(X_test))\n",
        "\n",
        "train_sampler = SubsetRandomSampler(list(X_train.index))\n",
        "valid_sampler = SubsetRandomSampler(list(X_test.index))\n",
        "batch_size = 64\n",
        "num_workers = 0\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ISIC_0000431.jpeg    0\n",
            "ISIC_0000324.jpeg    0\n",
            "ISIC_0000863.jpeg    0\n",
            "ISIC_0000210.jpeg    0\n",
            "ISIC_0000094.jpeg    0\n",
            "                    ..\n",
            "ISIC_0011503.jpeg    1\n",
            "ISIC_0011486.jpeg    1\n",
            "ISIC_0011494.jpeg    1\n",
            "ISIC_0001134.jpeg    1\n",
            "ISIC_0010120.jpeg    1\n",
            "Length: 1200, dtype: int64\n",
            "number of training data:  960\n",
            "number of testing  data:  240\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e8nFBR6Yug5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "def train(model, train_loader ,loss_fn, optimizer, num_epochs = 1):\n",
        "    total_loss =0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
        "        model.train()\n",
        "\n",
        "        for t, (x, y) in enumerate(train_loader):\n",
        "            x_var = Variable(x.type(gpu_dtype))\n",
        "            y_var = Variable(y.type(gpu_dtype).long())\n",
        "            scores = model(x_var)\n",
        "            loss = loss_fn(scores, y_var)\n",
        "            total_loss += loss.data\n",
        "            \n",
        "            if (t + 1) % print_every == 0:\n",
        "                avg_loss = total_loss/print_every\n",
        "                print('t = %d, avg_loss = %.4f' % (t + 1, avg_loss) )\n",
        "                avg_loss_list.append(avg_loss)\n",
        "                total_loss = 0\n",
        "                \n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        acc = check_accuracy(fixed_model_gpu, valid_loader)\n",
        "        print('acc = %f' %(acc))\n",
        "            \n",
        "def check_accuracy(model, loader):\n",
        "    print('Checking accuracy on test set')   \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval() \n",
        "    for x, y in loader:\n",
        "        x_var = Variable(x.type(gpu_dtype))\n",
        "\n",
        "        scores = model(x_var)\n",
        "        _, preds = scores.data.cpu().max(1)\n",
        "        num_correct += (preds == y).sum()\n",
        "        num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    acc_list.append(acc)\n",
        "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "    return acc\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggvpMu36Yw2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.size()\n",
        "        return x.view(N, -1)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgmexhBRZAK6",
        "colab_type": "code",
        "outputId": "6f02d067-87b8-4388-abdd-7e5d537a0d6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "\n",
        "print_every = 1\n",
        "gpu_dtype = torch.cuda.FloatTensor\n",
        "\n",
        "out_1 = 32\n",
        "out_2 = 64\n",
        "out_3 = 128\n",
        "out_4 = 256\n",
        "\n",
        "\n",
        "k_size_1 = 3\n",
        "padding_1 = 1\n",
        "in_channels = 3\n",
        "\n",
        "num_epochs = 100\n",
        "\n",
        "'''\n",
        "Kerv2d\n",
        "kervolution with following options:\n",
        "kernel_type: [linear, polynomial, gaussian, etc.]\n",
        "default is convolution:\n",
        "          kernel_type --> linear,\n",
        "balance, power, gamma is valid only when the kernel_type is specified\n",
        "if learnable_kernel = True,  they just be the initial value of learable parameters\n",
        "if learnable_kernel = False, they are the value of kernel_type's parameter\n",
        "the parameter [power] cannot be learned due to integer limitation\n",
        "dilation (int or tuple, optional): Spacing between kernel\n",
        "elements. Default: 1\n",
        "groups (int, optional): Number of blocked connections from input\n",
        "channels to output channels. Default: 1\n",
        "bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n",
        "kernel_type (str), Default: 'linear'\n",
        "learnable_kernel (bool): Learnable kernel parameters.  Default: False \n",
        "balance: 0, 1\n",
        "power: 3, 4, 5\n",
        "gamma:\n",
        "'''\n",
        "\n",
        "\n",
        "fixed_model_base = nn.Sequential( \n",
        "                nn.Kerv2d(in_channels , out_1, padding=padding_1, dilation=1, groups=1, bias=True, \n",
        "                          kernel_type='polynomial', kernel_size=k_size_1, learnable_kernel=True,\n",
        "                          kernel_regularizer=True, stride=1, balance=1, power=3, gamma=1), \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_1),\n",
        "                nn.Conv2d(out_1 , out_2, padding= padding_1, kernel_size=k_size_1, stride=1), \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_2),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_2 , out_3, padding= padding_1, kernel_size=k_size_1, stride=1),  \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_3),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_3 , out_4, padding= padding_1, kernel_size=k_size_1, stride=1),  \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_4),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Dropout(0.5),\n",
        "                Flatten(),\n",
        "                nn.Linear(36864,64),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Linear(64,2)\n",
        "            )\n",
        "fixed_model_gpu = fixed_model_base.type(gpu_dtype)\n",
        "print(fixed_model_gpu)\n",
        "loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(fixed_model_gpu.parameters(), lr = 0.00012, weight_decay=0) \n",
        "\n",
        "train(fixed_model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs)\n",
        "check_accuracy(fixed_model_gpu, valid_loader)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Kerv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (4): ReLU(inplace=True)\n",
            "  (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (8): ReLU(inplace=True)\n",
            "  (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (11): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (12): ReLU(inplace=True)\n",
            "  (13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (15): Dropout(p=0.5, inplace=False)\n",
            "  (16): Flatten()\n",
            "  (17): Linear(in_features=36864, out_features=64, bias=True)\n",
            "  (18): ReLU(inplace=True)\n",
            "  (19): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n",
            "Starting epoch 1 / 100\n",
            "t = 1, avg_loss = 0.7595\n",
            "t = 2, avg_loss = 0.6998\n",
            "t = 3, avg_loss = 0.7135\n",
            "t = 4, avg_loss = 0.6159\n",
            "t = 5, avg_loss = 0.6779\n",
            "t = 6, avg_loss = 0.4807\n",
            "t = 7, avg_loss = 0.5181\n",
            "t = 8, avg_loss = 0.6931\n",
            "t = 9, avg_loss = 0.5042\n",
            "t = 10, avg_loss = 0.3613\n",
            "t = 11, avg_loss = 0.4760\n",
            "t = 12, avg_loss = 0.4630\n",
            "t = 13, avg_loss = 0.4417\n",
            "t = 14, avg_loss = 0.3922\n",
            "t = 15, avg_loss = 0.4501\n",
            "Checking accuracy on test set\n",
            "Got 120 / 240 correct (50.00)\n",
            "acc = 0.500000\n",
            "Starting epoch 2 / 100\n",
            "t = 1, avg_loss = 0.3150\n",
            "t = 2, avg_loss = 0.3332\n",
            "t = 3, avg_loss = 0.3392\n",
            "t = 4, avg_loss = 0.3721\n",
            "t = 5, avg_loss = 0.3879\n",
            "t = 6, avg_loss = 0.4176\n",
            "t = 7, avg_loss = 0.4632\n",
            "t = 8, avg_loss = 0.2964\n",
            "t = 9, avg_loss = 0.2375\n",
            "t = 10, avg_loss = 0.6738\n",
            "t = 11, avg_loss = 0.4432\n",
            "t = 12, avg_loss = 0.2728\n",
            "t = 13, avg_loss = 0.4196\n",
            "t = 14, avg_loss = 0.3137\n",
            "t = 15, avg_loss = 0.3669\n",
            "Checking accuracy on test set\n",
            "Got 154 / 240 correct (64.17)\n",
            "acc = 0.641667\n",
            "Starting epoch 3 / 100\n",
            "t = 1, avg_loss = 0.4429\n",
            "t = 2, avg_loss = 0.3189\n",
            "t = 3, avg_loss = 0.2671\n",
            "t = 4, avg_loss = 0.2458\n",
            "t = 5, avg_loss = 0.3381\n",
            "t = 6, avg_loss = 0.3167\n",
            "t = 7, avg_loss = 0.3750\n",
            "t = 8, avg_loss = 0.3042\n",
            "t = 9, avg_loss = 0.2500\n",
            "t = 10, avg_loss = 0.3650\n",
            "t = 11, avg_loss = 0.4205\n",
            "t = 12, avg_loss = 0.3106\n",
            "t = 13, avg_loss = 0.2679\n",
            "t = 14, avg_loss = 0.3363\n",
            "t = 15, avg_loss = 0.3867\n",
            "Checking accuracy on test set\n",
            "Got 188 / 240 correct (78.33)\n",
            "acc = 0.783333\n",
            "Starting epoch 4 / 100\n",
            "t = 1, avg_loss = 0.3388\n",
            "t = 2, avg_loss = 0.2856\n",
            "t = 3, avg_loss = 0.3188\n",
            "t = 4, avg_loss = 0.3830\n",
            "t = 5, avg_loss = 0.2323\n",
            "t = 6, avg_loss = 0.5164\n",
            "t = 7, avg_loss = 0.2744\n",
            "t = 8, avg_loss = 0.2640\n",
            "t = 9, avg_loss = 0.2963\n",
            "t = 10, avg_loss = 0.3104\n",
            "t = 11, avg_loss = 0.4049\n",
            "t = 12, avg_loss = 0.2074\n",
            "t = 13, avg_loss = 0.3192\n",
            "t = 14, avg_loss = 0.2183\n",
            "t = 15, avg_loss = 0.3720\n",
            "Checking accuracy on test set\n",
            "Got 193 / 240 correct (80.42)\n",
            "acc = 0.804167\n",
            "Starting epoch 5 / 100\n",
            "t = 1, avg_loss = 0.2473\n",
            "t = 2, avg_loss = 0.2256\n",
            "t = 3, avg_loss = 0.3076\n",
            "t = 4, avg_loss = 0.2649\n",
            "t = 5, avg_loss = 0.1899\n",
            "t = 6, avg_loss = 0.2637\n",
            "t = 7, avg_loss = 0.3312\n",
            "t = 8, avg_loss = 0.3806\n",
            "t = 9, avg_loss = 0.2269\n",
            "t = 10, avg_loss = 0.4163\n",
            "t = 11, avg_loss = 0.3383\n",
            "t = 12, avg_loss = 0.2679\n",
            "t = 13, avg_loss = 0.3558\n",
            "t = 14, avg_loss = 0.2961\n",
            "t = 15, avg_loss = 0.3207\n",
            "Checking accuracy on test set\n",
            "Got 200 / 240 correct (83.33)\n",
            "acc = 0.833333\n",
            "Starting epoch 6 / 100\n",
            "t = 1, avg_loss = 0.2886\n",
            "t = 2, avg_loss = 0.3631\n",
            "t = 3, avg_loss = 0.2256\n",
            "t = 4, avg_loss = 0.2322\n",
            "t = 5, avg_loss = 0.2365\n",
            "t = 6, avg_loss = 0.2665\n",
            "t = 7, avg_loss = 0.3215\n",
            "t = 8, avg_loss = 0.2360\n",
            "t = 9, avg_loss = 0.3632\n",
            "t = 10, avg_loss = 0.1896\n",
            "t = 11, avg_loss = 0.2313\n",
            "t = 12, avg_loss = 0.2952\n",
            "t = 13, avg_loss = 0.2562\n",
            "t = 14, avg_loss = 0.2751\n",
            "t = 15, avg_loss = 0.2288\n",
            "Checking accuracy on test set\n",
            "Got 194 / 240 correct (80.83)\n",
            "acc = 0.808333\n",
            "Starting epoch 7 / 100\n",
            "t = 1, avg_loss = 0.1905\n",
            "t = 2, avg_loss = 0.3032\n",
            "t = 3, avg_loss = 0.2277\n",
            "t = 4, avg_loss = 0.1892\n",
            "t = 5, avg_loss = 0.2841\n",
            "t = 6, avg_loss = 0.2835\n",
            "t = 7, avg_loss = 0.1462\n",
            "t = 8, avg_loss = 0.3117\n",
            "t = 9, avg_loss = 0.1475\n",
            "t = 10, avg_loss = 0.3267\n",
            "t = 11, avg_loss = 0.1717\n",
            "t = 12, avg_loss = 0.2234\n",
            "t = 13, avg_loss = 0.1866\n",
            "t = 14, avg_loss = 0.2235\n",
            "t = 15, avg_loss = 0.2446\n",
            "Checking accuracy on test set\n",
            "Got 196 / 240 correct (81.67)\n",
            "acc = 0.816667\n",
            "Starting epoch 8 / 100\n",
            "t = 1, avg_loss = 0.2167\n",
            "t = 2, avg_loss = 0.3600\n",
            "t = 3, avg_loss = 0.2783\n",
            "t = 4, avg_loss = 0.2087\n",
            "t = 5, avg_loss = 0.1151\n",
            "t = 6, avg_loss = 0.2804\n",
            "t = 7, avg_loss = 0.3061\n",
            "t = 8, avg_loss = 0.1869\n",
            "t = 9, avg_loss = 0.2535\n",
            "t = 10, avg_loss = 0.2899\n",
            "t = 11, avg_loss = 0.4165\n",
            "t = 12, avg_loss = 0.2120\n",
            "t = 13, avg_loss = 0.1763\n",
            "t = 14, avg_loss = 0.2659\n",
            "t = 15, avg_loss = 0.2160\n",
            "Checking accuracy on test set\n",
            "Got 191 / 240 correct (79.58)\n",
            "acc = 0.795833\n",
            "Starting epoch 9 / 100\n",
            "t = 1, avg_loss = 0.1755\n",
            "t = 2, avg_loss = 0.3704\n",
            "t = 3, avg_loss = 0.2657\n",
            "t = 4, avg_loss = 0.2174\n",
            "t = 5, avg_loss = 0.2648\n",
            "t = 6, avg_loss = 0.2728\n",
            "t = 7, avg_loss = 0.1159\n",
            "t = 8, avg_loss = 0.3213\n",
            "t = 9, avg_loss = 0.1325\n",
            "t = 10, avg_loss = 0.2176\n",
            "t = 11, avg_loss = 0.2212\n",
            "t = 12, avg_loss = 0.2954\n",
            "t = 13, avg_loss = 0.1810\n",
            "t = 14, avg_loss = 0.3297\n",
            "t = 15, avg_loss = 0.1948\n",
            "Checking accuracy on test set\n",
            "Got 198 / 240 correct (82.50)\n",
            "acc = 0.825000\n",
            "Starting epoch 10 / 100\n",
            "t = 1, avg_loss = 0.2442\n",
            "t = 2, avg_loss = 0.1730\n",
            "t = 3, avg_loss = 0.1351\n",
            "t = 4, avg_loss = 0.1547\n",
            "t = 5, avg_loss = 0.1576\n",
            "t = 6, avg_loss = 0.1189\n",
            "t = 7, avg_loss = 0.2044\n",
            "t = 8, avg_loss = 0.1235\n",
            "t = 9, avg_loss = 0.2018\n",
            "t = 10, avg_loss = 0.1122\n",
            "t = 11, avg_loss = 0.1591\n",
            "t = 12, avg_loss = 0.1421\n",
            "t = 13, avg_loss = 0.1972\n",
            "t = 14, avg_loss = 0.2932\n",
            "t = 15, avg_loss = 0.1830\n",
            "Checking accuracy on test set\n",
            "Got 201 / 240 correct (83.75)\n",
            "acc = 0.837500\n",
            "Starting epoch 11 / 100\n",
            "t = 1, avg_loss = 0.1953\n",
            "t = 2, avg_loss = 0.2018\n",
            "t = 3, avg_loss = 0.1980\n",
            "t = 4, avg_loss = 0.1214\n",
            "t = 5, avg_loss = 0.1336\n",
            "t = 6, avg_loss = 0.1457\n",
            "t = 7, avg_loss = 0.2081\n",
            "t = 8, avg_loss = 0.1046\n",
            "t = 9, avg_loss = 0.2492\n",
            "t = 10, avg_loss = 0.1595\n",
            "t = 11, avg_loss = 0.2501\n",
            "t = 12, avg_loss = 0.1652\n",
            "t = 13, avg_loss = 0.1144\n",
            "t = 14, avg_loss = 0.1436\n",
            "t = 15, avg_loss = 0.2264\n",
            "Checking accuracy on test set\n",
            "Got 201 / 240 correct (83.75)\n",
            "acc = 0.837500\n",
            "Starting epoch 12 / 100\n",
            "t = 1, avg_loss = 0.1703\n",
            "t = 2, avg_loss = 0.1817\n",
            "t = 3, avg_loss = 0.1888\n",
            "t = 4, avg_loss = 0.0954\n",
            "t = 5, avg_loss = 0.1901\n",
            "t = 6, avg_loss = 0.1695\n",
            "t = 7, avg_loss = 0.1621\n",
            "t = 8, avg_loss = 0.1677\n",
            "t = 9, avg_loss = 0.2567\n",
            "t = 10, avg_loss = 0.1024\n",
            "t = 11, avg_loss = 0.1269\n",
            "t = 12, avg_loss = 0.1999\n",
            "t = 13, avg_loss = 0.1908\n",
            "t = 14, avg_loss = 0.2043\n",
            "t = 15, avg_loss = 0.0884\n",
            "Checking accuracy on test set\n",
            "Got 204 / 240 correct (85.00)\n",
            "acc = 0.850000\n",
            "Starting epoch 13 / 100\n",
            "t = 1, avg_loss = 0.0999\n",
            "t = 2, avg_loss = 0.1543\n",
            "t = 3, avg_loss = 0.1222\n",
            "t = 4, avg_loss = 0.1406\n",
            "t = 5, avg_loss = 0.1423\n",
            "t = 6, avg_loss = 0.1994\n",
            "t = 7, avg_loss = 0.1719\n",
            "t = 8, avg_loss = 0.1107\n",
            "t = 9, avg_loss = 0.0981\n",
            "t = 10, avg_loss = 0.1463\n",
            "t = 11, avg_loss = 0.0861\n",
            "t = 12, avg_loss = 0.1475\n",
            "t = 13, avg_loss = 0.2163\n",
            "t = 14, avg_loss = 0.1977\n",
            "t = 15, avg_loss = 0.1254\n",
            "Checking accuracy on test set\n",
            "Got 199 / 240 correct (82.92)\n",
            "acc = 0.829167\n",
            "Starting epoch 14 / 100\n",
            "t = 1, avg_loss = 0.0854\n",
            "t = 2, avg_loss = 0.1033\n",
            "t = 3, avg_loss = 0.0875\n",
            "t = 4, avg_loss = 0.0769\n",
            "t = 5, avg_loss = 0.1220\n",
            "t = 6, avg_loss = 0.2125\n",
            "t = 7, avg_loss = 0.1068\n",
            "t = 8, avg_loss = 0.1430\n",
            "t = 9, avg_loss = 0.1337\n",
            "t = 10, avg_loss = 0.1377\n",
            "t = 11, avg_loss = 0.1547\n",
            "t = 12, avg_loss = 0.1215\n",
            "t = 13, avg_loss = 0.1189\n",
            "t = 14, avg_loss = 0.1853\n",
            "t = 15, avg_loss = 0.2238\n",
            "Checking accuracy on test set\n",
            "Got 200 / 240 correct (83.33)\n",
            "acc = 0.833333\n",
            "Starting epoch 15 / 100\n",
            "t = 1, avg_loss = 0.0835\n",
            "t = 2, avg_loss = 0.1763\n",
            "t = 3, avg_loss = 0.1487\n",
            "t = 4, avg_loss = 0.1253\n",
            "t = 5, avg_loss = 0.1116\n",
            "t = 6, avg_loss = 0.1149\n",
            "t = 7, avg_loss = 0.1077\n",
            "t = 8, avg_loss = 0.2143\n",
            "t = 9, avg_loss = 0.1037\n",
            "t = 10, avg_loss = 0.1201\n",
            "t = 11, avg_loss = 0.1677\n",
            "t = 12, avg_loss = 0.1746\n",
            "t = 13, avg_loss = 0.1507\n",
            "t = 14, avg_loss = 0.0927\n",
            "t = 15, avg_loss = 0.0981\n",
            "Checking accuracy on test set\n",
            "Got 193 / 240 correct (80.42)\n",
            "acc = 0.804167\n",
            "Starting epoch 16 / 100\n",
            "t = 1, avg_loss = 0.0605\n",
            "t = 2, avg_loss = 0.1130\n",
            "t = 3, avg_loss = 0.1280\n",
            "t = 4, avg_loss = 0.0857\n",
            "t = 5, avg_loss = 0.1235\n",
            "t = 6, avg_loss = 0.1134\n",
            "t = 7, avg_loss = 0.0683\n",
            "t = 8, avg_loss = 0.0869\n",
            "t = 9, avg_loss = 0.1711\n",
            "t = 10, avg_loss = 0.0900\n",
            "t = 11, avg_loss = 0.1892\n",
            "t = 12, avg_loss = 0.1364\n",
            "t = 13, avg_loss = 0.1226\n",
            "t = 14, avg_loss = 0.1921\n",
            "t = 15, avg_loss = 0.1619\n",
            "Checking accuracy on test set\n",
            "Got 199 / 240 correct (82.92)\n",
            "acc = 0.829167\n",
            "Starting epoch 17 / 100\n",
            "t = 1, avg_loss = 0.0757\n",
            "t = 2, avg_loss = 0.1228\n",
            "t = 3, avg_loss = 0.0768\n",
            "t = 4, avg_loss = 0.2309\n",
            "t = 5, avg_loss = 0.1685\n",
            "t = 6, avg_loss = 0.0993\n",
            "t = 7, avg_loss = 0.1681\n",
            "t = 8, avg_loss = 0.1576\n",
            "t = 9, avg_loss = 0.1484\n",
            "t = 10, avg_loss = 0.1525\n",
            "t = 11, avg_loss = 0.1137\n",
            "t = 12, avg_loss = 0.0795\n",
            "t = 13, avg_loss = 0.1159\n",
            "t = 14, avg_loss = 0.0503\n",
            "t = 15, avg_loss = 0.1455\n",
            "Checking accuracy on test set\n",
            "Got 208 / 240 correct (86.67)\n",
            "acc = 0.866667\n",
            "Starting epoch 18 / 100\n",
            "t = 1, avg_loss = 0.1131\n",
            "t = 2, avg_loss = 0.1010\n",
            "t = 3, avg_loss = 0.1428\n",
            "t = 4, avg_loss = 0.1138\n",
            "t = 5, avg_loss = 0.1079\n",
            "t = 6, avg_loss = 0.0824\n",
            "t = 7, avg_loss = 0.1125\n",
            "t = 8, avg_loss = 0.0444\n",
            "t = 9, avg_loss = 0.0970\n",
            "t = 10, avg_loss = 0.1075\n",
            "t = 11, avg_loss = 0.1336\n",
            "t = 12, avg_loss = 0.1014\n",
            "t = 13, avg_loss = 0.0821\n",
            "t = 14, avg_loss = 0.0617\n",
            "t = 15, avg_loss = 0.0636\n",
            "Checking accuracy on test set\n",
            "Got 198 / 240 correct (82.50)\n",
            "acc = 0.825000\n",
            "Starting epoch 19 / 100\n",
            "t = 1, avg_loss = 0.0516\n",
            "t = 2, avg_loss = 0.0371\n",
            "t = 3, avg_loss = 0.1448\n",
            "t = 4, avg_loss = 0.1021\n",
            "t = 5, avg_loss = 0.0597\n",
            "t = 6, avg_loss = 0.0618\n",
            "t = 7, avg_loss = 0.1211\n",
            "t = 8, avg_loss = 0.0505\n",
            "t = 9, avg_loss = 0.0750\n",
            "t = 10, avg_loss = 0.1072\n",
            "t = 11, avg_loss = 0.0587\n",
            "t = 12, avg_loss = 0.0802\n",
            "t = 13, avg_loss = 0.1027\n",
            "t = 14, avg_loss = 0.0942\n",
            "t = 15, avg_loss = 0.1531\n",
            "Checking accuracy on test set\n",
            "Got 201 / 240 correct (83.75)\n",
            "acc = 0.837500\n",
            "Starting epoch 20 / 100\n",
            "t = 1, avg_loss = 0.0939\n",
            "t = 2, avg_loss = 0.0463\n",
            "t = 3, avg_loss = 0.0727\n",
            "t = 4, avg_loss = 0.0534\n",
            "t = 5, avg_loss = 0.1169\n",
            "t = 6, avg_loss = 0.0990\n",
            "t = 7, avg_loss = 0.0568\n",
            "t = 8, avg_loss = 0.0578\n",
            "t = 9, avg_loss = 0.0512\n",
            "t = 10, avg_loss = 0.0970\n",
            "t = 11, avg_loss = 0.1528\n",
            "t = 12, avg_loss = 0.1496\n",
            "t = 13, avg_loss = 0.0598\n",
            "t = 14, avg_loss = 0.0718\n",
            "t = 15, avg_loss = 0.0602\n",
            "Checking accuracy on test set\n",
            "Got 199 / 240 correct (82.92)\n",
            "acc = 0.829167\n",
            "Starting epoch 21 / 100\n",
            "t = 1, avg_loss = 0.0872\n",
            "t = 2, avg_loss = 0.1435\n",
            "t = 3, avg_loss = 0.1134\n",
            "t = 4, avg_loss = 0.0568\n",
            "t = 5, avg_loss = 0.1089\n",
            "t = 6, avg_loss = 0.1192\n",
            "t = 7, avg_loss = 0.0995\n",
            "t = 8, avg_loss = 0.1224\n",
            "t = 9, avg_loss = 0.0640\n",
            "t = 10, avg_loss = 0.0510\n",
            "t = 11, avg_loss = 0.0767\n",
            "t = 12, avg_loss = 0.1021\n",
            "t = 13, avg_loss = 0.0646\n",
            "t = 14, avg_loss = 0.0636\n",
            "t = 15, avg_loss = 0.1072\n",
            "Checking accuracy on test set\n",
            "Got 195 / 240 correct (81.25)\n",
            "acc = 0.812500\n",
            "Starting epoch 22 / 100\n",
            "t = 1, avg_loss = 0.0378\n",
            "t = 2, avg_loss = 0.0532\n",
            "t = 3, avg_loss = 0.1598\n",
            "t = 4, avg_loss = 0.0817\n",
            "t = 5, avg_loss = 0.0775\n",
            "t = 6, avg_loss = 0.0353\n",
            "t = 7, avg_loss = 0.0864\n",
            "t = 8, avg_loss = 0.0353\n",
            "t = 9, avg_loss = 0.0663\n",
            "t = 10, avg_loss = 0.0545\n",
            "t = 11, avg_loss = 0.0952\n",
            "t = 12, avg_loss = 0.1374\n",
            "t = 13, avg_loss = 0.0716\n",
            "t = 14, avg_loss = 0.0399\n",
            "t = 15, avg_loss = 0.0733\n",
            "Checking accuracy on test set\n",
            "Got 201 / 240 correct (83.75)\n",
            "acc = 0.837500\n",
            "Starting epoch 23 / 100\n",
            "t = 1, avg_loss = 0.0616\n",
            "t = 2, avg_loss = 0.1057\n",
            "t = 3, avg_loss = 0.0522\n",
            "t = 4, avg_loss = 0.0495\n",
            "t = 5, avg_loss = 0.0368\n",
            "t = 6, avg_loss = 0.0195\n",
            "t = 7, avg_loss = 0.1186\n",
            "t = 8, avg_loss = 0.0450\n",
            "t = 9, avg_loss = 0.0404\n",
            "t = 10, avg_loss = 0.0857\n",
            "t = 11, avg_loss = 0.0691\n",
            "t = 12, avg_loss = 0.0709\n",
            "t = 13, avg_loss = 0.0505\n",
            "t = 14, avg_loss = 0.0757\n",
            "t = 15, avg_loss = 0.0694\n",
            "Checking accuracy on test set\n",
            "Got 200 / 240 correct (83.33)\n",
            "acc = 0.833333\n",
            "Starting epoch 24 / 100\n",
            "t = 1, avg_loss = 0.0806\n",
            "t = 2, avg_loss = 0.0235\n",
            "t = 3, avg_loss = 0.0390\n",
            "t = 4, avg_loss = 0.0458\n",
            "t = 5, avg_loss = 0.0393\n",
            "t = 6, avg_loss = 0.0450\n",
            "t = 7, avg_loss = 0.0613\n",
            "t = 8, avg_loss = 0.0428\n",
            "t = 9, avg_loss = 0.0592\n",
            "t = 10, avg_loss = 0.0618\n",
            "t = 11, avg_loss = 0.0650\n",
            "t = 12, avg_loss = 0.0706\n",
            "t = 13, avg_loss = 0.0418\n",
            "t = 14, avg_loss = 0.0491\n",
            "t = 15, avg_loss = 0.0554\n",
            "Checking accuracy on test set\n",
            "Got 198 / 240 correct (82.50)\n",
            "acc = 0.825000\n",
            "Starting epoch 25 / 100\n",
            "t = 1, avg_loss = 0.0769\n",
            "t = 2, avg_loss = 0.0583\n",
            "t = 3, avg_loss = 0.0204\n",
            "t = 4, avg_loss = 0.0577\n",
            "t = 5, avg_loss = 0.1840\n",
            "t = 6, avg_loss = 0.0685\n",
            "t = 7, avg_loss = 0.0471\n",
            "t = 8, avg_loss = 0.0697\n",
            "t = 9, avg_loss = 0.0714\n",
            "t = 10, avg_loss = 0.0503\n",
            "t = 11, avg_loss = 0.0640\n",
            "t = 12, avg_loss = 0.0689\n",
            "t = 13, avg_loss = 0.0500\n",
            "t = 14, avg_loss = 0.0214\n",
            "t = 15, avg_loss = 0.0553\n",
            "Checking accuracy on test set\n",
            "Got 201 / 240 correct (83.75)\n",
            "acc = 0.837500\n",
            "Starting epoch 26 / 100\n",
            "t = 1, avg_loss = 0.0520\n",
            "t = 2, avg_loss = 0.1135\n",
            "t = 3, avg_loss = 0.0798\n",
            "t = 4, avg_loss = 0.1013\n",
            "t = 5, avg_loss = 0.0844\n",
            "t = 6, avg_loss = 0.0592\n",
            "t = 7, avg_loss = 0.0286\n",
            "t = 8, avg_loss = 0.0265\n",
            "t = 9, avg_loss = 0.1115\n",
            "t = 10, avg_loss = 0.0702\n",
            "t = 11, avg_loss = 0.1119\n",
            "t = 12, avg_loss = 0.0731\n",
            "t = 13, avg_loss = 0.0370\n",
            "t = 14, avg_loss = 0.0306\n",
            "t = 15, avg_loss = 0.0343\n",
            "Checking accuracy on test set\n",
            "Got 200 / 240 correct (83.33)\n",
            "acc = 0.833333\n",
            "Starting epoch 27 / 100\n",
            "t = 1, avg_loss = 0.0907\n",
            "t = 2, avg_loss = 0.0321\n",
            "t = 3, avg_loss = 0.0491\n",
            "t = 4, avg_loss = 0.0864\n",
            "t = 5, avg_loss = 0.0628\n",
            "t = 6, avg_loss = 0.0535\n",
            "t = 7, avg_loss = 0.0441\n",
            "t = 8, avg_loss = 0.0446\n",
            "t = 9, avg_loss = 0.0479\n",
            "t = 10, avg_loss = 0.0677\n",
            "t = 11, avg_loss = 0.0778\n",
            "t = 12, avg_loss = 0.0435\n",
            "t = 13, avg_loss = 0.0211\n",
            "t = 14, avg_loss = 0.0501\n",
            "t = 15, avg_loss = 0.0570\n",
            "Checking accuracy on test set\n",
            "Got 200 / 240 correct (83.33)\n",
            "acc = 0.833333\n",
            "Starting epoch 28 / 100\n",
            "t = 1, avg_loss = 0.0562\n",
            "t = 2, avg_loss = 0.0737\n",
            "t = 3, avg_loss = 0.0618\n",
            "t = 4, avg_loss = 0.0524\n",
            "t = 5, avg_loss = 0.0243\n",
            "t = 6, avg_loss = 0.0654\n",
            "t = 7, avg_loss = 0.0369\n",
            "t = 8, avg_loss = 0.0300\n",
            "t = 9, avg_loss = 0.0567\n",
            "t = 10, avg_loss = 0.0376\n",
            "t = 11, avg_loss = 0.0237\n",
            "t = 12, avg_loss = 0.0508\n",
            "t = 13, avg_loss = 0.0534\n",
            "t = 14, avg_loss = 0.0206\n",
            "t = 15, avg_loss = 0.0311\n",
            "Checking accuracy on test set\n",
            "Got 200 / 240 correct (83.33)\n",
            "acc = 0.833333\n",
            "Starting epoch 29 / 100\n",
            "t = 1, avg_loss = 0.0467\n",
            "t = 2, avg_loss = 0.0492\n",
            "t = 3, avg_loss = 0.0156\n",
            "t = 4, avg_loss = 0.1039\n",
            "t = 5, avg_loss = 0.0384\n",
            "t = 6, avg_loss = 0.0412\n",
            "t = 7, avg_loss = 0.0240\n",
            "t = 8, avg_loss = 0.0609\n",
            "t = 9, avg_loss = 0.0517\n",
            "t = 10, avg_loss = 0.0538\n",
            "t = 11, avg_loss = 0.0307\n",
            "t = 12, avg_loss = 0.0576\n",
            "t = 13, avg_loss = 0.0420\n",
            "t = 14, avg_loss = 0.0220\n",
            "t = 15, avg_loss = 0.0341\n",
            "Checking accuracy on test set\n",
            "Got 195 / 240 correct (81.25)\n",
            "acc = 0.812500\n",
            "Starting epoch 30 / 100\n",
            "t = 1, avg_loss = 0.0241\n",
            "t = 2, avg_loss = 0.0566\n",
            "t = 3, avg_loss = 0.0491\n",
            "t = 4, avg_loss = 0.0573\n",
            "t = 5, avg_loss = 0.0400\n",
            "t = 6, avg_loss = 0.0222\n",
            "t = 7, avg_loss = 0.0795\n",
            "t = 8, avg_loss = 0.0485\n",
            "t = 9, avg_loss = 0.0320\n",
            "t = 10, avg_loss = 0.0340\n",
            "t = 11, avg_loss = 0.0174\n",
            "t = 12, avg_loss = 0.0359\n",
            "t = 13, avg_loss = 0.0429\n",
            "t = 14, avg_loss = 0.0472\n",
            "t = 15, avg_loss = 0.0208\n",
            "Checking accuracy on test set\n",
            "Got 195 / 240 correct (81.25)\n",
            "acc = 0.812500\n",
            "Starting epoch 31 / 100\n",
            "t = 1, avg_loss = 0.0274\n",
            "t = 2, avg_loss = 0.0347\n",
            "t = 3, avg_loss = 0.0197\n",
            "t = 4, avg_loss = 0.0256\n",
            "t = 5, avg_loss = 0.0389\n",
            "t = 6, avg_loss = 0.0191\n",
            "t = 7, avg_loss = 0.0326\n",
            "t = 8, avg_loss = 0.0136\n",
            "t = 9, avg_loss = 0.0161\n",
            "t = 10, avg_loss = 0.0393\n",
            "t = 11, avg_loss = 0.0079\n",
            "t = 12, avg_loss = 0.0359\n",
            "t = 13, avg_loss = 0.0314\n",
            "t = 14, avg_loss = 0.0692\n",
            "t = 15, avg_loss = 0.0272\n",
            "Checking accuracy on test set\n",
            "Got 203 / 240 correct (84.58)\n",
            "acc = 0.845833\n",
            "Starting epoch 32 / 100\n",
            "t = 1, avg_loss = 0.0416\n",
            "t = 2, avg_loss = 0.0103\n",
            "t = 3, avg_loss = 0.0163\n",
            "t = 4, avg_loss = 0.0188\n",
            "t = 5, avg_loss = 0.0221\n",
            "t = 6, avg_loss = 0.0593\n",
            "t = 7, avg_loss = 0.0187\n",
            "t = 8, avg_loss = 0.0228\n",
            "t = 9, avg_loss = 0.0437\n",
            "t = 10, avg_loss = 0.0482\n",
            "t = 11, avg_loss = 0.0428\n",
            "t = 12, avg_loss = 0.0166\n",
            "t = 13, avg_loss = 0.0553\n",
            "t = 14, avg_loss = 0.0189\n",
            "t = 15, avg_loss = 0.0110\n",
            "Checking accuracy on test set\n",
            "Got 194 / 240 correct (80.83)\n",
            "acc = 0.808333\n",
            "Starting epoch 33 / 100\n",
            "t = 1, avg_loss = 0.0846\n",
            "t = 2, avg_loss = 0.0320\n",
            "t = 3, avg_loss = 0.0225\n",
            "t = 4, avg_loss = 0.0590\n",
            "t = 5, avg_loss = 0.0209\n",
            "t = 6, avg_loss = 0.0152\n",
            "t = 7, avg_loss = 0.0215\n",
            "t = 8, avg_loss = 0.0124\n",
            "t = 9, avg_loss = 0.0531\n",
            "t = 10, avg_loss = 0.0773\n",
            "t = 11, avg_loss = 0.0189\n",
            "t = 12, avg_loss = 0.0437\n",
            "t = 13, avg_loss = 0.0214\n",
            "t = 14, avg_loss = 0.0356\n",
            "t = 15, avg_loss = 0.0485\n",
            "Checking accuracy on test set\n",
            "Got 201 / 240 correct (83.75)\n",
            "acc = 0.837500\n",
            "Starting epoch 34 / 100\n",
            "t = 1, avg_loss = 0.0150\n",
            "t = 2, avg_loss = 0.0342\n",
            "t = 3, avg_loss = 0.0335\n",
            "t = 4, avg_loss = 0.0251\n",
            "t = 5, avg_loss = 0.0169\n",
            "t = 6, avg_loss = 0.0347\n",
            "t = 7, avg_loss = 0.0250\n",
            "t = 8, avg_loss = 0.0379\n",
            "t = 9, avg_loss = 0.0456\n",
            "t = 10, avg_loss = 0.1154\n",
            "t = 11, avg_loss = 0.0225\n",
            "t = 12, avg_loss = 0.0193\n",
            "t = 13, avg_loss = 0.0236\n",
            "t = 14, avg_loss = 0.0424\n",
            "t = 15, avg_loss = 0.1290\n",
            "Checking accuracy on test set\n",
            "Got 196 / 240 correct (81.67)\n",
            "acc = 0.816667\n",
            "Starting epoch 35 / 100\n",
            "t = 1, avg_loss = 0.0219\n",
            "t = 2, avg_loss = 0.0528\n",
            "t = 3, avg_loss = 0.0381\n",
            "t = 4, avg_loss = 0.0703\n",
            "t = 5, avg_loss = 0.0106\n",
            "t = 6, avg_loss = 0.0413\n",
            "t = 7, avg_loss = 0.0249\n",
            "t = 8, avg_loss = 0.0309\n",
            "t = 9, avg_loss = 0.0552\n",
            "t = 10, avg_loss = 0.0420\n",
            "t = 11, avg_loss = 0.1120\n",
            "t = 12, avg_loss = 0.0368\n",
            "t = 13, avg_loss = 0.0464\n",
            "t = 14, avg_loss = 0.0264\n",
            "t = 15, avg_loss = 0.0335\n",
            "Checking accuracy on test set\n",
            "Got 203 / 240 correct (84.58)\n",
            "acc = 0.845833\n",
            "Starting epoch 36 / 100\n",
            "t = 1, avg_loss = 0.0179\n",
            "t = 2, avg_loss = 0.0522\n",
            "t = 3, avg_loss = 0.0251\n",
            "t = 4, avg_loss = 0.0937\n",
            "t = 5, avg_loss = 0.0246\n",
            "t = 6, avg_loss = 0.1653\n",
            "t = 7, avg_loss = 0.0724\n",
            "t = 8, avg_loss = 0.0246\n",
            "t = 9, avg_loss = 0.0318\n",
            "t = 10, avg_loss = 0.0297\n",
            "t = 11, avg_loss = 0.0178\n",
            "t = 12, avg_loss = 0.0265\n",
            "t = 13, avg_loss = 0.0827\n",
            "t = 14, avg_loss = 0.0213\n",
            "t = 15, avg_loss = 0.0108\n",
            "Checking accuracy on test set\n",
            "Got 192 / 240 correct (80.00)\n",
            "acc = 0.800000\n",
            "Starting epoch 37 / 100\n",
            "t = 1, avg_loss = 0.0495\n",
            "t = 2, avg_loss = 0.0355\n",
            "t = 3, avg_loss = 0.0103\n",
            "t = 4, avg_loss = 0.0424\n",
            "t = 5, avg_loss = 0.0422\n",
            "t = 6, avg_loss = 0.0123\n",
            "t = 7, avg_loss = 0.0193\n",
            "t = 8, avg_loss = 0.0157\n",
            "t = 9, avg_loss = 0.0267\n",
            "t = 10, avg_loss = 0.0368\n",
            "t = 11, avg_loss = 0.0141\n",
            "t = 12, avg_loss = 0.0378\n",
            "t = 13, avg_loss = 0.0107\n",
            "t = 14, avg_loss = 0.0244\n",
            "t = 15, avg_loss = 0.0215\n",
            "Checking accuracy on test set\n",
            "Got 199 / 240 correct (82.92)\n",
            "acc = 0.829167\n",
            "Starting epoch 38 / 100\n",
            "t = 1, avg_loss = 0.0470\n",
            "t = 2, avg_loss = 0.0179\n",
            "t = 3, avg_loss = 0.0074\n",
            "t = 4, avg_loss = 0.0315\n",
            "t = 5, avg_loss = 0.0259\n",
            "t = 6, avg_loss = 0.0492\n",
            "t = 7, avg_loss = 0.0530\n",
            "t = 8, avg_loss = 0.0405\n",
            "t = 9, avg_loss = 0.0200\n",
            "t = 10, avg_loss = 0.0123\n",
            "t = 11, avg_loss = 0.0109\n",
            "t = 12, avg_loss = 0.0263\n",
            "t = 13, avg_loss = 0.0182\n",
            "t = 14, avg_loss = 0.0251\n",
            "t = 15, avg_loss = 0.0132\n",
            "Checking accuracy on test set\n",
            "Got 200 / 240 correct (83.33)\n",
            "acc = 0.833333\n",
            "Starting epoch 39 / 100\n",
            "t = 1, avg_loss = 0.0201\n",
            "t = 2, avg_loss = 0.0216\n",
            "t = 3, avg_loss = 0.0235\n",
            "t = 4, avg_loss = 0.0069\n",
            "t = 5, avg_loss = 0.0160\n",
            "t = 6, avg_loss = 0.0119\n",
            "t = 7, avg_loss = 0.0222\n",
            "t = 8, avg_loss = 0.0105\n",
            "t = 9, avg_loss = 0.0082\n",
            "t = 10, avg_loss = 0.0160\n",
            "t = 11, avg_loss = 0.0076\n",
            "t = 12, avg_loss = 0.0167\n",
            "t = 13, avg_loss = 0.0237\n",
            "t = 14, avg_loss = 0.0116\n",
            "t = 15, avg_loss = 0.0098\n",
            "Checking accuracy on test set\n",
            "Got 201 / 240 correct (83.75)\n",
            "acc = 0.837500\n",
            "Starting epoch 40 / 100\n",
            "t = 1, avg_loss = 0.0157\n",
            "t = 2, avg_loss = 0.0086\n",
            "t = 3, avg_loss = 0.0267\n",
            "t = 4, avg_loss = 0.0082\n",
            "t = 5, avg_loss = 0.0076\n",
            "t = 6, avg_loss = 0.0233\n",
            "t = 7, avg_loss = 0.0156\n",
            "t = 8, avg_loss = 0.0152\n",
            "t = 9, avg_loss = 0.0688\n",
            "t = 10, avg_loss = 0.0194\n",
            "t = 11, avg_loss = 0.0285\n",
            "t = 12, avg_loss = 0.0081\n",
            "t = 13, avg_loss = 0.0091\n",
            "t = 14, avg_loss = 0.0075\n",
            "t = 15, avg_loss = 0.0613\n",
            "Checking accuracy on test set\n",
            "Got 198 / 240 correct (82.50)\n",
            "acc = 0.825000\n",
            "Starting epoch 41 / 100\n",
            "t = 1, avg_loss = 0.0546\n",
            "t = 2, avg_loss = 0.0086\n",
            "t = 3, avg_loss = 0.0084\n",
            "t = 4, avg_loss = 0.0208\n",
            "t = 5, avg_loss = 0.0356\n",
            "t = 6, avg_loss = 0.0289\n",
            "t = 7, avg_loss = 0.0075\n",
            "t = 8, avg_loss = 0.0347\n",
            "t = 9, avg_loss = 0.0212\n",
            "t = 10, avg_loss = 0.1918\n",
            "t = 11, avg_loss = 0.0340\n",
            "t = 12, avg_loss = 0.0283\n",
            "t = 13, avg_loss = 0.0444\n",
            "t = 14, avg_loss = 0.0685\n",
            "t = 15, avg_loss = 0.0686\n",
            "Checking accuracy on test set\n",
            "Got 200 / 240 correct (83.33)\n",
            "acc = 0.833333\n",
            "Starting epoch 42 / 100\n",
            "t = 1, avg_loss = 0.0094\n",
            "t = 2, avg_loss = 0.0499\n",
            "t = 3, avg_loss = 0.0253\n",
            "t = 4, avg_loss = 0.0267\n",
            "t = 5, avg_loss = 0.0812\n",
            "t = 6, avg_loss = 0.0411\n",
            "t = 7, avg_loss = 0.0363\n",
            "t = 8, avg_loss = 0.0247\n",
            "t = 9, avg_loss = 0.0851\n",
            "t = 10, avg_loss = 0.0313\n",
            "t = 11, avg_loss = 0.0109\n",
            "t = 12, avg_loss = 0.0386\n",
            "t = 13, avg_loss = 0.0236\n",
            "t = 14, avg_loss = 0.0135\n",
            "t = 15, avg_loss = 0.0393\n",
            "Checking accuracy on test set\n",
            "Got 201 / 240 correct (83.75)\n",
            "acc = 0.837500\n",
            "Starting epoch 43 / 100\n",
            "t = 1, avg_loss = 0.0767\n",
            "t = 2, avg_loss = 0.0040\n",
            "t = 3, avg_loss = 0.0267\n",
            "t = 4, avg_loss = 0.0191\n",
            "t = 5, avg_loss = 0.0195\n",
            "t = 6, avg_loss = 0.0244\n",
            "t = 7, avg_loss = 0.0188\n",
            "t = 8, avg_loss = 0.0317\n",
            "t = 9, avg_loss = 0.0140\n",
            "t = 10, avg_loss = 0.0163\n",
            "t = 11, avg_loss = 0.0195\n",
            "t = 12, avg_loss = 0.1014\n",
            "t = 13, avg_loss = 0.0255\n",
            "t = 14, avg_loss = 0.0484\n",
            "t = 15, avg_loss = 0.0363\n",
            "Checking accuracy on test set\n",
            "Got 199 / 240 correct (82.92)\n",
            "acc = 0.829167\n",
            "Starting epoch 44 / 100\n",
            "t = 1, avg_loss = 0.0131\n",
            "t = 2, avg_loss = 0.0125\n",
            "t = 3, avg_loss = 0.0241\n",
            "t = 4, avg_loss = 0.0061\n",
            "t = 5, avg_loss = 0.0103\n",
            "t = 6, avg_loss = 0.0127\n",
            "t = 7, avg_loss = 0.0296\n",
            "t = 8, avg_loss = 0.0279\n",
            "t = 9, avg_loss = 0.0224\n",
            "t = 10, avg_loss = 0.0087\n",
            "t = 11, avg_loss = 0.0229\n",
            "t = 12, avg_loss = 0.0056\n",
            "t = 13, avg_loss = 0.0142\n",
            "t = 14, avg_loss = 0.0092\n",
            "t = 15, avg_loss = 0.0271\n",
            "Checking accuracy on test set\n",
            "Got 204 / 240 correct (85.00)\n",
            "acc = 0.850000\n",
            "Starting epoch 45 / 100\n",
            "t = 1, avg_loss = 0.0088\n",
            "t = 2, avg_loss = 0.0154\n",
            "t = 3, avg_loss = 0.0046\n",
            "t = 4, avg_loss = 0.0120\n",
            "t = 5, avg_loss = 0.0082\n",
            "t = 6, avg_loss = 0.0255\n",
            "t = 7, avg_loss = 0.0127\n",
            "t = 8, avg_loss = 0.0179\n",
            "t = 9, avg_loss = 0.0327\n",
            "t = 10, avg_loss = 0.0116\n",
            "t = 11, avg_loss = 0.0034\n",
            "t = 12, avg_loss = 0.0611\n",
            "t = 13, avg_loss = 0.0221\n",
            "t = 14, avg_loss = 0.0083\n",
            "t = 15, avg_loss = 0.0108\n",
            "Checking accuracy on test set\n",
            "Got 204 / 240 correct (85.00)\n",
            "acc = 0.850000\n",
            "Starting epoch 46 / 100\n",
            "t = 1, avg_loss = 0.0092\n",
            "t = 2, avg_loss = 0.0092\n",
            "t = 3, avg_loss = 0.0128\n",
            "t = 4, avg_loss = 0.0128\n",
            "t = 5, avg_loss = 0.0127\n",
            "t = 6, avg_loss = 0.0045\n",
            "t = 7, avg_loss = 0.0073\n",
            "t = 8, avg_loss = 0.0131\n",
            "t = 9, avg_loss = 0.0081\n",
            "t = 10, avg_loss = 0.0131\n",
            "t = 11, avg_loss = 0.0128\n",
            "t = 12, avg_loss = 0.0042\n",
            "t = 13, avg_loss = 0.0260\n",
            "t = 14, avg_loss = 0.0055\n",
            "t = 15, avg_loss = 0.0067\n",
            "Checking accuracy on test set\n",
            "Got 199 / 240 correct (82.92)\n",
            "acc = 0.829167\n",
            "Starting epoch 47 / 100\n",
            "t = 1, avg_loss = 0.0030\n",
            "t = 2, avg_loss = 0.0119\n",
            "t = 3, avg_loss = 0.0049\n",
            "t = 4, avg_loss = 0.0075\n",
            "t = 5, avg_loss = 0.0240\n",
            "t = 6, avg_loss = 0.0149\n",
            "t = 7, avg_loss = 0.0094\n",
            "t = 8, avg_loss = 0.0042\n",
            "t = 9, avg_loss = 0.0070\n",
            "t = 10, avg_loss = 0.0160\n",
            "t = 11, avg_loss = 0.0043\n",
            "t = 12, avg_loss = 0.0207\n",
            "t = 13, avg_loss = 0.0125\n",
            "t = 14, avg_loss = 0.0036\n",
            "t = 15, avg_loss = 0.0050\n",
            "Checking accuracy on test set\n",
            "Got 199 / 240 correct (82.92)\n",
            "acc = 0.829167\n",
            "Starting epoch 48 / 100\n",
            "t = 1, avg_loss = 0.0069\n",
            "t = 2, avg_loss = 0.0020\n",
            "t = 3, avg_loss = 0.0160\n",
            "t = 4, avg_loss = 0.0078\n",
            "t = 5, avg_loss = 0.0096\n",
            "t = 6, avg_loss = 0.0152\n",
            "t = 7, avg_loss = 0.0157\n",
            "t = 8, avg_loss = 0.0114\n",
            "t = 9, avg_loss = 0.0052\n",
            "t = 10, avg_loss = 0.0116\n",
            "t = 11, avg_loss = 0.0263\n",
            "t = 12, avg_loss = 0.0038\n",
            "t = 13, avg_loss = 0.0153\n",
            "t = 14, avg_loss = 0.0088\n",
            "t = 15, avg_loss = 0.0049\n",
            "Checking accuracy on test set\n",
            "Got 197 / 240 correct (82.08)\n",
            "acc = 0.820833\n",
            "Starting epoch 49 / 100\n",
            "t = 1, avg_loss = 0.0152\n",
            "t = 2, avg_loss = 0.0057\n",
            "t = 3, avg_loss = 0.0065\n",
            "t = 4, avg_loss = 0.0266\n",
            "t = 5, avg_loss = 0.0043\n",
            "t = 6, avg_loss = 0.0282\n",
            "t = 7, avg_loss = 0.0180\n",
            "t = 8, avg_loss = 0.0044\n",
            "t = 9, avg_loss = 0.0141\n",
            "t = 10, avg_loss = 0.0102\n",
            "t = 11, avg_loss = 0.0098\n",
            "t = 12, avg_loss = 0.0148\n",
            "t = 13, avg_loss = 0.0087\n",
            "t = 14, avg_loss = 0.0185\n",
            "t = 15, avg_loss = 0.0127\n",
            "Checking accuracy on test set\n",
            "Got 194 / 240 correct (80.83)\n",
            "acc = 0.808333\n",
            "Starting epoch 50 / 100\n",
            "t = 1, avg_loss = 0.0048\n",
            "t = 2, avg_loss = 0.0127\n",
            "t = 3, avg_loss = 0.0094\n",
            "t = 4, avg_loss = 0.0858\n",
            "t = 5, avg_loss = 0.0048\n",
            "t = 6, avg_loss = 0.0072\n",
            "t = 7, avg_loss = 0.0410\n",
            "t = 8, avg_loss = 0.0080\n",
            "t = 9, avg_loss = 0.0021\n",
            "t = 10, avg_loss = 0.0133\n",
            "t = 11, avg_loss = 0.0102\n",
            "t = 12, avg_loss = 0.0027\n",
            "t = 13, avg_loss = 0.0146\n",
            "t = 14, avg_loss = 0.0108\n",
            "t = 15, avg_loss = 0.0275\n",
            "Checking accuracy on test set\n",
            "Got 203 / 240 correct (84.58)\n",
            "acc = 0.845833\n",
            "Starting epoch 51 / 100\n",
            "t = 1, avg_loss = 0.0050\n",
            "t = 2, avg_loss = 0.0075\n",
            "t = 3, avg_loss = 0.0077\n",
            "t = 4, avg_loss = 0.0142\n",
            "t = 5, avg_loss = 0.0059\n",
            "t = 6, avg_loss = 0.0050\n",
            "t = 7, avg_loss = 0.0132\n",
            "t = 8, avg_loss = 0.0099\n",
            "t = 9, avg_loss = 0.0086\n",
            "t = 10, avg_loss = 0.0037\n",
            "t = 11, avg_loss = 0.0051\n",
            "t = 12, avg_loss = 0.0039\n",
            "t = 13, avg_loss = 0.0027\n",
            "t = 14, avg_loss = 0.0295\n",
            "t = 15, avg_loss = 0.0100\n",
            "Checking accuracy on test set\n",
            "Got 200 / 240 correct (83.33)\n",
            "acc = 0.833333\n",
            "Starting epoch 52 / 100\n",
            "t = 1, avg_loss = 0.0121\n",
            "t = 2, avg_loss = 0.0047\n",
            "t = 3, avg_loss = 0.0056\n",
            "t = 4, avg_loss = 0.0056\n",
            "t = 5, avg_loss = 0.0058\n",
            "t = 6, avg_loss = 0.0100\n",
            "t = 7, avg_loss = 0.0055\n",
            "t = 8, avg_loss = 0.0040\n",
            "t = 9, avg_loss = 0.0019\n",
            "t = 10, avg_loss = 0.0031\n",
            "t = 11, avg_loss = 0.0048\n",
            "t = 12, avg_loss = 0.0048\n",
            "t = 13, avg_loss = 0.0064\n",
            "t = 14, avg_loss = 0.0136\n",
            "t = 15, avg_loss = 0.0099\n",
            "Checking accuracy on test set\n",
            "Got 198 / 240 correct (82.50)\n",
            "acc = 0.825000\n",
            "Starting epoch 53 / 100\n",
            "t = 1, avg_loss = 0.0162\n",
            "t = 2, avg_loss = 0.0007\n",
            "t = 3, avg_loss = 0.0027\n",
            "t = 4, avg_loss = 0.0036\n",
            "t = 5, avg_loss = 0.0049\n",
            "t = 6, avg_loss = 0.0250\n",
            "t = 7, avg_loss = 0.0018\n",
            "t = 8, avg_loss = 0.0179\n",
            "t = 9, avg_loss = 0.0100\n",
            "t = 10, avg_loss = 0.0024\n",
            "t = 11, avg_loss = 0.0054\n",
            "t = 12, avg_loss = 0.0182\n",
            "t = 13, avg_loss = 0.0094\n",
            "t = 14, avg_loss = 0.0110\n",
            "t = 15, avg_loss = 0.0218\n",
            "Checking accuracy on test set\n",
            "Got 205 / 240 correct (85.42)\n",
            "acc = 0.854167\n",
            "Starting epoch 54 / 100\n",
            "t = 1, avg_loss = 0.0099\n",
            "t = 2, avg_loss = 0.0022\n",
            "t = 3, avg_loss = 0.0038\n",
            "t = 4, avg_loss = 0.0032\n",
            "t = 5, avg_loss = 0.0166\n",
            "t = 6, avg_loss = 0.0058\n",
            "t = 7, avg_loss = 0.0117\n",
            "t = 8, avg_loss = 0.0052\n",
            "t = 9, avg_loss = 0.0090\n",
            "t = 10, avg_loss = 0.0103\n",
            "t = 11, avg_loss = 0.0125\n",
            "t = 12, avg_loss = 0.0137\n",
            "t = 13, avg_loss = 0.0048\n",
            "t = 14, avg_loss = 0.0104\n",
            "t = 15, avg_loss = 0.0235\n",
            "Checking accuracy on test set\n",
            "Got 198 / 240 correct (82.50)\n",
            "acc = 0.825000\n",
            "Starting epoch 55 / 100\n",
            "t = 1, avg_loss = 0.0052\n",
            "t = 2, avg_loss = 0.0064\n",
            "t = 3, avg_loss = 0.0054\n",
            "t = 4, avg_loss = 0.0038\n",
            "t = 5, avg_loss = 0.0054\n",
            "t = 6, avg_loss = 0.0627\n",
            "t = 7, avg_loss = 0.0035\n",
            "t = 8, avg_loss = 0.0050\n",
            "t = 9, avg_loss = 0.0041\n",
            "t = 10, avg_loss = 0.0066\n",
            "t = 11, avg_loss = 0.0244\n",
            "t = 12, avg_loss = 0.0077\n",
            "t = 13, avg_loss = 0.0096\n",
            "t = 14, avg_loss = 0.0046\n",
            "t = 15, avg_loss = 0.0030\n",
            "Checking accuracy on test set\n",
            "Got 195 / 240 correct (81.25)\n",
            "acc = 0.812500\n",
            "Starting epoch 56 / 100\n",
            "t = 1, avg_loss = 0.0047\n",
            "t = 2, avg_loss = 0.0058\n",
            "t = 3, avg_loss = 0.0080\n",
            "t = 4, avg_loss = 0.0082\n",
            "t = 5, avg_loss = 0.0098\n",
            "t = 6, avg_loss = 0.0081\n",
            "t = 7, avg_loss = 0.0113\n",
            "t = 8, avg_loss = 0.0034\n",
            "t = 9, avg_loss = 0.0020\n",
            "t = 10, avg_loss = 0.0170\n",
            "t = 11, avg_loss = 0.0058\n",
            "t = 12, avg_loss = 0.0024\n",
            "t = 13, avg_loss = 0.0063\n",
            "t = 14, avg_loss = 0.0014\n",
            "t = 15, avg_loss = 0.0037\n",
            "Checking accuracy on test set\n",
            "Got 204 / 240 correct (85.00)\n",
            "acc = 0.850000\n",
            "Starting epoch 57 / 100\n",
            "t = 1, avg_loss = 0.0075\n",
            "t = 2, avg_loss = 0.0043\n",
            "t = 3, avg_loss = 0.0048\n",
            "t = 4, avg_loss = 0.0083\n",
            "t = 5, avg_loss = 0.0415\n",
            "t = 6, avg_loss = 0.0136\n",
            "t = 7, avg_loss = 0.0035\n",
            "t = 8, avg_loss = 0.0024\n",
            "t = 9, avg_loss = 0.0158\n",
            "t = 10, avg_loss = 0.0176\n",
            "t = 11, avg_loss = 0.0073\n",
            "t = 12, avg_loss = 0.0361\n",
            "t = 13, avg_loss = 0.0367\n",
            "t = 14, avg_loss = 0.0094\n",
            "t = 15, avg_loss = 0.0075\n",
            "Checking accuracy on test set\n",
            "Got 193 / 240 correct (80.42)\n",
            "acc = 0.804167\n",
            "Starting epoch 58 / 100\n",
            "t = 1, avg_loss = 0.0059\n",
            "t = 2, avg_loss = 0.0062\n",
            "t = 3, avg_loss = 0.0092\n",
            "t = 4, avg_loss = 0.0173\n",
            "t = 5, avg_loss = 0.0112\n",
            "t = 6, avg_loss = 0.0238\n",
            "t = 7, avg_loss = 0.0084\n",
            "t = 8, avg_loss = 0.0156\n",
            "t = 9, avg_loss = 0.0075\n",
            "t = 10, avg_loss = 0.0045\n",
            "t = 11, avg_loss = 0.0060\n",
            "t = 12, avg_loss = 0.0232\n",
            "t = 13, avg_loss = 0.0228\n",
            "t = 14, avg_loss = 0.0159\n",
            "t = 15, avg_loss = 0.0057\n",
            "Checking accuracy on test set\n",
            "Got 201 / 240 correct (83.75)\n",
            "acc = 0.837500\n",
            "Starting epoch 59 / 100\n",
            "t = 1, avg_loss = 0.0040\n",
            "t = 2, avg_loss = 0.0058\n",
            "t = 3, avg_loss = 0.0039\n",
            "t = 4, avg_loss = 0.0075\n",
            "t = 5, avg_loss = 0.0065\n",
            "t = 6, avg_loss = 0.0250\n",
            "t = 7, avg_loss = 0.0032\n",
            "t = 8, avg_loss = 0.0137\n",
            "t = 9, avg_loss = 0.0283\n",
            "t = 10, avg_loss = 0.0104\n",
            "t = 11, avg_loss = 0.0025\n",
            "t = 12, avg_loss = 0.0041\n",
            "t = 13, avg_loss = 0.0019\n",
            "t = 14, avg_loss = 0.0076\n",
            "t = 15, avg_loss = 0.0054\n",
            "Checking accuracy on test set\n",
            "Got 195 / 240 correct (81.25)\n",
            "acc = 0.812500\n",
            "Starting epoch 60 / 100\n",
            "t = 1, avg_loss = 0.0042\n",
            "t = 2, avg_loss = 0.0043\n",
            "t = 3, avg_loss = 0.0291\n",
            "t = 4, avg_loss = 0.0058\n",
            "t = 5, avg_loss = 0.0057\n",
            "t = 6, avg_loss = 0.0124\n",
            "t = 7, avg_loss = 0.0028\n",
            "t = 8, avg_loss = 0.0019\n",
            "t = 9, avg_loss = 0.0027\n",
            "t = 10, avg_loss = 0.0085\n",
            "t = 11, avg_loss = 0.0040\n",
            "t = 12, avg_loss = 0.0046\n",
            "t = 13, avg_loss = 0.0061\n",
            "t = 14, avg_loss = 0.0301\n",
            "t = 15, avg_loss = 0.0072\n",
            "Checking accuracy on test set\n",
            "Got 197 / 240 correct (82.08)\n",
            "acc = 0.820833\n",
            "Starting epoch 61 / 100\n",
            "t = 1, avg_loss = 0.0022\n",
            "t = 2, avg_loss = 0.0043\n",
            "t = 3, avg_loss = 0.0014\n",
            "t = 4, avg_loss = 0.0028\n",
            "t = 5, avg_loss = 0.0068\n",
            "t = 6, avg_loss = 0.0022\n",
            "t = 7, avg_loss = 0.0049\n",
            "t = 8, avg_loss = 0.0048\n",
            "t = 9, avg_loss = 0.0043\n",
            "t = 10, avg_loss = 0.0016\n",
            "t = 11, avg_loss = 0.0131\n",
            "t = 12, avg_loss = 0.0016\n",
            "t = 13, avg_loss = 0.0034\n",
            "t = 14, avg_loss = 0.0029\n",
            "t = 15, avg_loss = 0.0021\n",
            "Checking accuracy on test set\n",
            "Got 200 / 240 correct (83.33)\n",
            "acc = 0.833333\n",
            "Starting epoch 62 / 100\n",
            "t = 1, avg_loss = 0.0059\n",
            "t = 2, avg_loss = 0.0031\n",
            "t = 3, avg_loss = 0.0033\n",
            "t = 4, avg_loss = 0.0027\n",
            "t = 5, avg_loss = 0.0018\n",
            "t = 6, avg_loss = 0.0024\n",
            "t = 7, avg_loss = 0.0024\n",
            "t = 8, avg_loss = 0.0012\n",
            "t = 9, avg_loss = 0.0037\n",
            "t = 10, avg_loss = 0.0079\n",
            "t = 11, avg_loss = 0.0028\n",
            "t = 12, avg_loss = 0.0035\n",
            "t = 13, avg_loss = 0.0013\n",
            "t = 14, avg_loss = 0.0032\n",
            "t = 15, avg_loss = 0.0049\n",
            "Checking accuracy on test set\n",
            "Got 196 / 240 correct (81.67)\n",
            "acc = 0.816667\n",
            "Starting epoch 63 / 100\n",
            "t = 1, avg_loss = 0.0028\n",
            "t = 2, avg_loss = 0.0024\n",
            "t = 3, avg_loss = 0.0030\n",
            "t = 4, avg_loss = 0.0060\n",
            "t = 5, avg_loss = 0.0026\n",
            "t = 6, avg_loss = 0.0020\n",
            "t = 7, avg_loss = 0.0052\n",
            "t = 8, avg_loss = 0.0025\n",
            "t = 9, avg_loss = 0.0071\n",
            "t = 10, avg_loss = 0.0163\n",
            "t = 11, avg_loss = 0.0059\n",
            "t = 12, avg_loss = 0.0049\n",
            "t = 13, avg_loss = 0.0020\n",
            "t = 14, avg_loss = 0.0027\n",
            "t = 15, avg_loss = 0.0010\n",
            "Checking accuracy on test set\n",
            "Got 198 / 240 correct (82.50)\n",
            "acc = 0.825000\n",
            "Starting epoch 64 / 100\n",
            "t = 1, avg_loss = 0.0016\n",
            "t = 2, avg_loss = 0.0035\n",
            "t = 3, avg_loss = 0.0069\n",
            "t = 4, avg_loss = 0.0011\n",
            "t = 5, avg_loss = 0.0016\n",
            "t = 6, avg_loss = 0.0015\n",
            "t = 7, avg_loss = 0.0012\n",
            "t = 8, avg_loss = 0.0189\n",
            "t = 9, avg_loss = 0.0020\n",
            "t = 10, avg_loss = 0.0026\n",
            "t = 11, avg_loss = 0.0017\n",
            "t = 12, avg_loss = 0.0023\n",
            "t = 13, avg_loss = 0.0031\n",
            "t = 14, avg_loss = 0.0034\n",
            "t = 15, avg_loss = 0.0127\n",
            "Checking accuracy on test set\n",
            "Got 198 / 240 correct (82.50)\n",
            "acc = 0.825000\n",
            "Starting epoch 65 / 100\n",
            "t = 1, avg_loss = 0.0042\n",
            "t = 2, avg_loss = 0.0036\n",
            "t = 3, avg_loss = 0.0031\n",
            "t = 4, avg_loss = 0.0075\n",
            "t = 5, avg_loss = 0.0041\n",
            "t = 6, avg_loss = 0.0065\n",
            "t = 7, avg_loss = 0.0030\n",
            "t = 8, avg_loss = 0.0074\n",
            "t = 9, avg_loss = 0.0056\n",
            "t = 10, avg_loss = 0.0041\n",
            "t = 11, avg_loss = 0.0018\n",
            "t = 12, avg_loss = 0.0017\n",
            "t = 13, avg_loss = 0.0026\n",
            "t = 14, avg_loss = 0.0193\n",
            "t = 15, avg_loss = 0.0045\n",
            "Checking accuracy on test set\n",
            "Got 202 / 240 correct (84.17)\n",
            "acc = 0.841667\n",
            "Starting epoch 66 / 100\n",
            "t = 1, avg_loss = 0.0116\n",
            "t = 2, avg_loss = 0.0027\n",
            "t = 3, avg_loss = 0.0026\n",
            "t = 4, avg_loss = 0.0023\n",
            "t = 5, avg_loss = 0.0013\n",
            "t = 6, avg_loss = 0.0111\n",
            "t = 7, avg_loss = 0.0015\n",
            "t = 8, avg_loss = 0.0008\n",
            "t = 9, avg_loss = 0.0032\n",
            "t = 10, avg_loss = 0.0064\n",
            "t = 11, avg_loss = 0.0164\n",
            "t = 12, avg_loss = 0.0019\n",
            "t = 13, avg_loss = 0.0046\n",
            "t = 14, avg_loss = 0.0008\n",
            "t = 15, avg_loss = 0.0072\n",
            "Checking accuracy on test set\n",
            "Got 197 / 240 correct (82.08)\n",
            "acc = 0.820833\n",
            "Starting epoch 67 / 100\n",
            "t = 1, avg_loss = 0.0030\n",
            "t = 2, avg_loss = 0.0032\n",
            "t = 3, avg_loss = 0.0015\n",
            "t = 4, avg_loss = 0.0072\n",
            "t = 5, avg_loss = 0.0023\n",
            "t = 6, avg_loss = 0.0030\n",
            "t = 7, avg_loss = 0.0021\n",
            "t = 8, avg_loss = 0.0019\n",
            "t = 9, avg_loss = 0.0017\n",
            "t = 10, avg_loss = 0.0025\n",
            "t = 11, avg_loss = 0.0035\n",
            "t = 12, avg_loss = 0.0092\n",
            "t = 13, avg_loss = 0.0022\n",
            "t = 14, avg_loss = 0.0022\n",
            "t = 15, avg_loss = 0.0018\n",
            "Checking accuracy on test set\n",
            "Got 197 / 240 correct (82.08)\n",
            "acc = 0.820833\n",
            "Starting epoch 68 / 100\n",
            "t = 1, avg_loss = 0.0007\n",
            "t = 2, avg_loss = 0.0017\n",
            "t = 3, avg_loss = 0.0035\n",
            "t = 4, avg_loss = 0.0006\n",
            "t = 5, avg_loss = 0.0007\n",
            "t = 6, avg_loss = 0.0042\n",
            "t = 7, avg_loss = 0.0017\n",
            "t = 8, avg_loss = 0.0024\n",
            "t = 9, avg_loss = 0.0100\n",
            "t = 10, avg_loss = 0.0043\n",
            "t = 11, avg_loss = 0.0015\n",
            "t = 12, avg_loss = 0.0027\n",
            "t = 13, avg_loss = 0.0017\n",
            "t = 14, avg_loss = 0.0021\n",
            "t = 15, avg_loss = 0.0020\n",
            "Checking accuracy on test set\n",
            "Got 202 / 240 correct (84.17)\n",
            "acc = 0.841667\n",
            "Starting epoch 69 / 100\n",
            "t = 1, avg_loss = 0.0015\n",
            "t = 2, avg_loss = 0.0026\n",
            "t = 3, avg_loss = 0.0035\n",
            "t = 4, avg_loss = 0.0042\n",
            "t = 5, avg_loss = 0.0013\n",
            "t = 6, avg_loss = 0.0043\n",
            "t = 7, avg_loss = 0.0017\n",
            "t = 8, avg_loss = 0.0038\n",
            "t = 9, avg_loss = 0.0014\n",
            "t = 10, avg_loss = 0.0061\n",
            "t = 11, avg_loss = 0.0017\n",
            "t = 12, avg_loss = 0.0091\n",
            "t = 13, avg_loss = 0.0005\n",
            "t = 14, avg_loss = 0.0030\n",
            "t = 15, avg_loss = 0.0007\n",
            "Checking accuracy on test set\n",
            "Got 198 / 240 correct (82.50)\n",
            "acc = 0.825000\n",
            "Starting epoch 70 / 100\n",
            "t = 1, avg_loss = 0.0043\n",
            "t = 2, avg_loss = 0.0115\n",
            "t = 3, avg_loss = 0.0008\n",
            "t = 4, avg_loss = 0.0010\n",
            "t = 5, avg_loss = 0.0049\n",
            "t = 6, avg_loss = 0.0022\n",
            "t = 7, avg_loss = 0.0044\n",
            "t = 8, avg_loss = 0.0017\n",
            "t = 9, avg_loss = 0.0021\n",
            "t = 10, avg_loss = 0.0052\n",
            "t = 11, avg_loss = 0.0017\n",
            "t = 12, avg_loss = 0.0039\n",
            "t = 13, avg_loss = 0.0085\n",
            "t = 14, avg_loss = 0.0026\n",
            "t = 15, avg_loss = 0.0016\n",
            "Checking accuracy on test set\n",
            "Got 202 / 240 correct (84.17)\n",
            "acc = 0.841667\n",
            "Starting epoch 71 / 100\n",
            "t = 1, avg_loss = 0.0055\n",
            "t = 2, avg_loss = 0.0035\n",
            "t = 3, avg_loss = 0.0030\n",
            "t = 4, avg_loss = 0.0008\n",
            "t = 5, avg_loss = 0.0017\n",
            "t = 6, avg_loss = 0.0034\n",
            "t = 7, avg_loss = 0.0007\n",
            "t = 8, avg_loss = 0.0014\n",
            "t = 9, avg_loss = 0.0014\n",
            "t = 10, avg_loss = 0.0019\n",
            "t = 11, avg_loss = 0.0009\n",
            "t = 12, avg_loss = 0.0009\n",
            "t = 13, avg_loss = 0.0015\n",
            "t = 14, avg_loss = 0.0010\n",
            "t = 15, avg_loss = 0.0019\n",
            "Checking accuracy on test set\n",
            "Got 198 / 240 correct (82.50)\n",
            "acc = 0.825000\n",
            "Starting epoch 72 / 100\n",
            "t = 1, avg_loss = 0.0047\n",
            "t = 2, avg_loss = 0.0020\n",
            "t = 3, avg_loss = 0.0121\n",
            "t = 4, avg_loss = 0.0430\n",
            "t = 5, avg_loss = 0.0007\n",
            "t = 6, avg_loss = 0.0006\n",
            "t = 7, avg_loss = 0.0047\n",
            "t = 8, avg_loss = 0.0060\n",
            "t = 9, avg_loss = 0.0027\n",
            "t = 10, avg_loss = 0.0069\n",
            "t = 11, avg_loss = 0.0772\n",
            "t = 12, avg_loss = 0.0137\n",
            "t = 13, avg_loss = 0.0114\n",
            "t = 14, avg_loss = 0.0169\n",
            "t = 15, avg_loss = 0.0105\n",
            "Checking accuracy on test set\n",
            "Got 200 / 240 correct (83.33)\n",
            "acc = 0.833333\n",
            "Starting epoch 73 / 100\n",
            "t = 1, avg_loss = 0.0037\n",
            "t = 2, avg_loss = 0.0011\n",
            "t = 3, avg_loss = 0.0009\n",
            "t = 4, avg_loss = 0.0059\n",
            "t = 5, avg_loss = 0.0053\n",
            "t = 6, avg_loss = 0.0123\n",
            "t = 7, avg_loss = 0.0203\n",
            "t = 8, avg_loss = 0.0143\n",
            "t = 9, avg_loss = 0.0123\n",
            "t = 10, avg_loss = 0.0137\n",
            "t = 11, avg_loss = 0.0035\n",
            "t = 12, avg_loss = 0.0209\n",
            "t = 13, avg_loss = 0.0052\n",
            "t = 14, avg_loss = 0.0052\n",
            "t = 15, avg_loss = 0.0028\n",
            "Checking accuracy on test set\n",
            "Got 196 / 240 correct (81.67)\n",
            "acc = 0.816667\n",
            "Starting epoch 74 / 100\n",
            "t = 1, avg_loss = 0.0101\n",
            "t = 2, avg_loss = 0.0179\n",
            "t = 3, avg_loss = 0.0092\n",
            "t = 4, avg_loss = 0.0046\n",
            "t = 5, avg_loss = 0.0037\n",
            "t = 6, avg_loss = 0.0065\n",
            "t = 7, avg_loss = 0.0047\n",
            "t = 8, avg_loss = 0.0011\n",
            "t = 9, avg_loss = 0.0019\n",
            "t = 10, avg_loss = 0.0013\n",
            "t = 11, avg_loss = 0.0106\n",
            "t = 12, avg_loss = 0.0011\n",
            "t = 13, avg_loss = 0.0056\n",
            "t = 14, avg_loss = 0.0021\n",
            "t = 15, avg_loss = 0.0051\n",
            "Checking accuracy on test set\n",
            "Got 199 / 240 correct (82.92)\n",
            "acc = 0.829167\n",
            "Starting epoch 75 / 100\n",
            "t = 1, avg_loss = 0.0030\n",
            "t = 2, avg_loss = 0.0028\n",
            "t = 3, avg_loss = 0.0015\n",
            "t = 4, avg_loss = 0.0038\n",
            "t = 5, avg_loss = 0.0037\n",
            "t = 6, avg_loss = 0.0028\n",
            "t = 7, avg_loss = 0.0058\n",
            "t = 8, avg_loss = 0.0029\n",
            "t = 9, avg_loss = 0.0031\n",
            "t = 10, avg_loss = 0.0018\n",
            "t = 11, avg_loss = 0.0026\n",
            "t = 12, avg_loss = 0.0044\n",
            "t = 13, avg_loss = 0.0030\n",
            "t = 14, avg_loss = 0.0584\n",
            "t = 15, avg_loss = 0.0069\n",
            "Checking accuracy on test set\n",
            "Got 200 / 240 correct (83.33)\n",
            "acc = 0.833333\n",
            "Starting epoch 76 / 100\n",
            "t = 1, avg_loss = 0.0057\n",
            "t = 2, avg_loss = 0.0009\n",
            "t = 3, avg_loss = 0.0032\n",
            "t = 4, avg_loss = 0.0010\n",
            "t = 5, avg_loss = 0.0080\n",
            "t = 6, avg_loss = 0.0194\n",
            "t = 7, avg_loss = 0.0056\n",
            "t = 8, avg_loss = 0.0041\n",
            "t = 9, avg_loss = 0.0027\n",
            "t = 10, avg_loss = 0.0065\n",
            "t = 11, avg_loss = 0.0052\n",
            "t = 12, avg_loss = 0.0047\n",
            "t = 13, avg_loss = 0.0021\n",
            "t = 14, avg_loss = 0.0045\n",
            "t = 15, avg_loss = 0.0179\n",
            "Checking accuracy on test set\n",
            "Got 200 / 240 correct (83.33)\n",
            "acc = 0.833333\n",
            "Starting epoch 77 / 100\n",
            "t = 1, avg_loss = 0.0104\n",
            "t = 2, avg_loss = 0.0017\n",
            "t = 3, avg_loss = 0.0010\n",
            "t = 4, avg_loss = 0.0015\n",
            "t = 5, avg_loss = 0.0054\n",
            "t = 6, avg_loss = 0.0114\n",
            "t = 7, avg_loss = 0.0149\n",
            "t = 8, avg_loss = 0.0033\n",
            "t = 9, avg_loss = 0.0014\n",
            "t = 10, avg_loss = 0.0025\n",
            "t = 11, avg_loss = 0.0010\n",
            "t = 12, avg_loss = 0.0138\n",
            "t = 13, avg_loss = 0.0034\n",
            "t = 14, avg_loss = 0.0074\n",
            "t = 15, avg_loss = 0.0075\n",
            "Checking accuracy on test set\n",
            "Got 199 / 240 correct (82.92)\n",
            "acc = 0.829167\n",
            "Starting epoch 78 / 100\n",
            "t = 1, avg_loss = 0.0038\n",
            "t = 2, avg_loss = 0.0081\n",
            "t = 3, avg_loss = 0.0128\n",
            "t = 4, avg_loss = 0.0384\n",
            "t = 5, avg_loss = 0.0019\n",
            "t = 6, avg_loss = 0.0018\n",
            "t = 7, avg_loss = 0.0012\n",
            "t = 8, avg_loss = 0.0086\n",
            "t = 9, avg_loss = 0.0031\n",
            "t = 10, avg_loss = 0.0149\n",
            "t = 11, avg_loss = 0.0599\n",
            "t = 12, avg_loss = 0.0086\n",
            "t = 13, avg_loss = 0.0021\n",
            "t = 14, avg_loss = 0.0032\n",
            "t = 15, avg_loss = 0.0078\n",
            "Checking accuracy on test set\n",
            "Got 201 / 240 correct (83.75)\n",
            "acc = 0.837500\n",
            "Starting epoch 79 / 100\n",
            "t = 1, avg_loss = 0.0040\n",
            "t = 2, avg_loss = 0.0028\n",
            "t = 3, avg_loss = 0.0029\n",
            "t = 4, avg_loss = 0.0179\n",
            "t = 5, avg_loss = 0.0020\n",
            "t = 6, avg_loss = 0.0337\n",
            "t = 7, avg_loss = 0.0142\n",
            "t = 8, avg_loss = 0.0029\n",
            "t = 9, avg_loss = 0.0050\n",
            "t = 10, avg_loss = 0.0047\n",
            "t = 11, avg_loss = 0.0129\n",
            "t = 12, avg_loss = 0.0072\n",
            "t = 13, avg_loss = 0.0073\n",
            "t = 14, avg_loss = 0.0038\n",
            "t = 15, avg_loss = 0.0194\n",
            "Checking accuracy on test set\n",
            "Got 202 / 240 correct (84.17)\n",
            "acc = 0.841667\n",
            "Starting epoch 80 / 100\n",
            "t = 1, avg_loss = 0.0043\n",
            "t = 2, avg_loss = 0.0047\n",
            "t = 3, avg_loss = 0.0076\n",
            "t = 4, avg_loss = 0.0029\n",
            "t = 5, avg_loss = 0.0067\n",
            "t = 6, avg_loss = 0.0164\n",
            "t = 7, avg_loss = 0.0056\n",
            "t = 8, avg_loss = 0.0031\n",
            "t = 9, avg_loss = 0.0085\n",
            "t = 10, avg_loss = 0.0120\n",
            "t = 11, avg_loss = 0.0071\n",
            "t = 12, avg_loss = 0.0167\n",
            "t = 13, avg_loss = 0.0032\n",
            "t = 14, avg_loss = 0.0061\n",
            "t = 15, avg_loss = 0.0039\n",
            "Checking accuracy on test set\n",
            "Got 202 / 240 correct (84.17)\n",
            "acc = 0.841667\n",
            "Starting epoch 81 / 100\n",
            "t = 1, avg_loss = 0.0042\n",
            "t = 2, avg_loss = 0.0104\n",
            "t = 3, avg_loss = 0.0036\n",
            "t = 4, avg_loss = 0.0125\n",
            "t = 5, avg_loss = 0.0166\n",
            "t = 6, avg_loss = 0.0050\n",
            "t = 7, avg_loss = 0.0079\n",
            "t = 8, avg_loss = 0.0016\n",
            "t = 9, avg_loss = 0.0015\n",
            "t = 10, avg_loss = 0.0061\n",
            "t = 11, avg_loss = 0.0024\n",
            "t = 12, avg_loss = 0.0037\n",
            "t = 13, avg_loss = 0.0036\n",
            "t = 14, avg_loss = 0.0202\n",
            "t = 15, avg_loss = 0.0105\n",
            "Checking accuracy on test set\n",
            "Got 200 / 240 correct (83.33)\n",
            "acc = 0.833333\n",
            "Starting epoch 82 / 100\n",
            "t = 1, avg_loss = 0.0047\n",
            "t = 2, avg_loss = 0.0030\n",
            "t = 3, avg_loss = 0.0375\n",
            "t = 4, avg_loss = 0.0045\n",
            "t = 5, avg_loss = 0.0020\n",
            "t = 6, avg_loss = 0.0063\n",
            "t = 7, avg_loss = 0.0083\n",
            "t = 8, avg_loss = 0.0041\n",
            "t = 9, avg_loss = 0.0218\n",
            "t = 10, avg_loss = 0.0070\n",
            "t = 11, avg_loss = 0.0033\n",
            "t = 12, avg_loss = 0.0036\n",
            "t = 13, avg_loss = 0.0034\n",
            "t = 14, avg_loss = 0.0014\n",
            "t = 15, avg_loss = 0.0030\n",
            "Checking accuracy on test set\n",
            "Got 198 / 240 correct (82.50)\n",
            "acc = 0.825000\n",
            "Starting epoch 83 / 100\n",
            "t = 1, avg_loss = 0.0013\n",
            "t = 2, avg_loss = 0.0033\n",
            "t = 3, avg_loss = 0.0017\n",
            "t = 4, avg_loss = 0.0047\n",
            "t = 5, avg_loss = 0.0117\n",
            "t = 6, avg_loss = 0.0621\n",
            "t = 7, avg_loss = 0.0052\n",
            "t = 8, avg_loss = 0.0078\n",
            "t = 9, avg_loss = 0.0030\n",
            "t = 10, avg_loss = 0.0052\n",
            "t = 11, avg_loss = 0.0022\n",
            "t = 12, avg_loss = 0.0098\n",
            "t = 13, avg_loss = 0.0020\n",
            "t = 14, avg_loss = 0.0061\n",
            "t = 15, avg_loss = 0.0142\n",
            "Checking accuracy on test set\n",
            "Got 198 / 240 correct (82.50)\n",
            "acc = 0.825000\n",
            "Starting epoch 84 / 100\n",
            "t = 1, avg_loss = 0.0027\n",
            "t = 2, avg_loss = 0.0018\n",
            "t = 3, avg_loss = 0.0021\n",
            "t = 4, avg_loss = 0.0022\n",
            "t = 5, avg_loss = 0.0038\n",
            "t = 6, avg_loss = 0.0219\n",
            "t = 7, avg_loss = 0.0009\n",
            "t = 8, avg_loss = 0.0011\n",
            "t = 9, avg_loss = 0.0074\n",
            "t = 10, avg_loss = 0.0015\n",
            "t = 11, avg_loss = 0.0074\n",
            "t = 12, avg_loss = 0.0047\n",
            "t = 13, avg_loss = 0.0012\n",
            "t = 14, avg_loss = 0.0192\n",
            "t = 15, avg_loss = 0.0047\n",
            "Checking accuracy on test set\n",
            "Got 201 / 240 correct (83.75)\n",
            "acc = 0.837500\n",
            "Starting epoch 85 / 100\n",
            "t = 1, avg_loss = 0.0019\n",
            "t = 2, avg_loss = 0.0113\n",
            "t = 3, avg_loss = 0.0042\n",
            "t = 4, avg_loss = 0.0030\n",
            "t = 5, avg_loss = 0.0114\n",
            "t = 6, avg_loss = 0.0024\n",
            "t = 7, avg_loss = 0.0029\n",
            "t = 8, avg_loss = 0.0098\n",
            "t = 9, avg_loss = 0.0140\n",
            "t = 10, avg_loss = 0.0014\n",
            "t = 11, avg_loss = 0.0125\n",
            "t = 12, avg_loss = 0.0050\n",
            "t = 13, avg_loss = 0.0045\n",
            "t = 14, avg_loss = 0.0077\n",
            "t = 15, avg_loss = 0.0046\n",
            "Checking accuracy on test set\n",
            "Got 200 / 240 correct (83.33)\n",
            "acc = 0.833333\n",
            "Starting epoch 86 / 100\n",
            "t = 1, avg_loss = 0.0082\n",
            "t = 2, avg_loss = 0.0019\n",
            "t = 3, avg_loss = 0.0010\n",
            "t = 4, avg_loss = 0.0045\n",
            "t = 5, avg_loss = 0.0174\n",
            "t = 6, avg_loss = 0.0017\n",
            "t = 7, avg_loss = 0.0014\n",
            "t = 8, avg_loss = 0.0017\n",
            "t = 9, avg_loss = 0.0021\n",
            "t = 10, avg_loss = 0.0047\n",
            "t = 11, avg_loss = 0.0019\n",
            "t = 12, avg_loss = 0.0049\n",
            "t = 13, avg_loss = 0.0155\n",
            "t = 14, avg_loss = 0.0230\n",
            "t = 15, avg_loss = 0.0100\n",
            "Checking accuracy on test set\n",
            "Got 201 / 240 correct (83.75)\n",
            "acc = 0.837500\n",
            "Starting epoch 87 / 100\n",
            "t = 1, avg_loss = 0.0007\n",
            "t = 2, avg_loss = 0.0056\n",
            "t = 3, avg_loss = 0.0043\n",
            "t = 4, avg_loss = 0.0015\n",
            "t = 5, avg_loss = 0.0018\n",
            "t = 6, avg_loss = 0.0119\n",
            "t = 7, avg_loss = 0.0032\n",
            "t = 8, avg_loss = 0.0038\n",
            "t = 9, avg_loss = 0.0090\n",
            "t = 10, avg_loss = 0.0449\n",
            "t = 11, avg_loss = 0.0096\n",
            "t = 12, avg_loss = 0.0076\n",
            "t = 13, avg_loss = 0.0170\n",
            "t = 14, avg_loss = 0.0028\n",
            "t = 15, avg_loss = 0.0248\n",
            "Checking accuracy on test set\n",
            "Got 202 / 240 correct (84.17)\n",
            "acc = 0.841667\n",
            "Starting epoch 88 / 100\n",
            "t = 1, avg_loss = 0.0061\n",
            "t = 2, avg_loss = 0.0011\n",
            "t = 3, avg_loss = 0.0017\n",
            "t = 4, avg_loss = 0.0104\n",
            "t = 5, avg_loss = 0.0080\n",
            "t = 6, avg_loss = 0.0067\n",
            "t = 7, avg_loss = 0.0029\n",
            "t = 8, avg_loss = 0.0075\n",
            "t = 9, avg_loss = 0.0326\n",
            "t = 10, avg_loss = 0.0214\n",
            "t = 11, avg_loss = 0.0098\n",
            "t = 12, avg_loss = 0.0224\n",
            "t = 13, avg_loss = 0.0133\n",
            "t = 14, avg_loss = 0.0366\n",
            "t = 15, avg_loss = 0.0488\n",
            "Checking accuracy on test set\n",
            "Got 203 / 240 correct (84.58)\n",
            "acc = 0.845833\n",
            "Starting epoch 89 / 100\n",
            "t = 1, avg_loss = 0.0167\n",
            "t = 2, avg_loss = 0.0204\n",
            "t = 3, avg_loss = 0.0088\n",
            "t = 4, avg_loss = 0.0016\n",
            "t = 5, avg_loss = 0.0111\n",
            "t = 6, avg_loss = 0.0367\n",
            "t = 7, avg_loss = 0.0178\n",
            "t = 8, avg_loss = 0.0380\n",
            "t = 9, avg_loss = 0.0049\n",
            "t = 10, avg_loss = 0.0424\n",
            "t = 11, avg_loss = 0.0149\n",
            "t = 12, avg_loss = 0.0138\n",
            "t = 13, avg_loss = 0.0131\n",
            "t = 14, avg_loss = 0.0457\n",
            "t = 15, avg_loss = 0.0080\n",
            "Checking accuracy on test set\n",
            "Got 195 / 240 correct (81.25)\n",
            "acc = 0.812500\n",
            "Starting epoch 90 / 100\n",
            "t = 1, avg_loss = 0.0239\n",
            "t = 2, avg_loss = 0.0082\n",
            "t = 3, avg_loss = 0.0319\n",
            "t = 4, avg_loss = 0.0517\n",
            "t = 5, avg_loss = 0.0260\n",
            "t = 6, avg_loss = 0.0267\n",
            "t = 7, avg_loss = 0.0290\n",
            "t = 8, avg_loss = 0.0179\n",
            "t = 9, avg_loss = 0.0370\n",
            "t = 10, avg_loss = 0.0322\n",
            "t = 11, avg_loss = 0.0108\n",
            "t = 12, avg_loss = 0.0232\n",
            "t = 13, avg_loss = 0.0132\n",
            "t = 14, avg_loss = 0.0271\n",
            "t = 15, avg_loss = 0.0079\n",
            "Checking accuracy on test set\n",
            "Got 195 / 240 correct (81.25)\n",
            "acc = 0.812500\n",
            "Starting epoch 91 / 100\n",
            "t = 1, avg_loss = 0.0185\n",
            "t = 2, avg_loss = 0.0017\n",
            "t = 3, avg_loss = 0.0119\n",
            "t = 4, avg_loss = 0.0072\n",
            "t = 5, avg_loss = 0.0154\n",
            "t = 6, avg_loss = 0.1450\n",
            "t = 7, avg_loss = 0.0104\n",
            "t = 8, avg_loss = 0.0090\n",
            "t = 9, avg_loss = 0.0128\n",
            "t = 10, avg_loss = 0.0105\n",
            "t = 11, avg_loss = 0.0461\n",
            "t = 12, avg_loss = 0.0152\n",
            "t = 13, avg_loss = 0.0188\n",
            "t = 14, avg_loss = 0.0253\n",
            "t = 15, avg_loss = 0.0832\n",
            "Checking accuracy on test set\n",
            "Got 198 / 240 correct (82.50)\n",
            "acc = 0.825000\n",
            "Starting epoch 92 / 100\n",
            "t = 1, avg_loss = 0.0158\n",
            "t = 2, avg_loss = 0.0519\n",
            "t = 3, avg_loss = 0.0153\n",
            "t = 4, avg_loss = 0.0062\n",
            "t = 5, avg_loss = 0.0281\n",
            "t = 6, avg_loss = 0.0292\n",
            "t = 7, avg_loss = 0.0559\n",
            "t = 8, avg_loss = 0.0219\n",
            "t = 9, avg_loss = 0.0047\n",
            "t = 10, avg_loss = 0.0497\n",
            "t = 11, avg_loss = 0.0415\n",
            "t = 12, avg_loss = 0.0153\n",
            "t = 13, avg_loss = 0.0083\n",
            "t = 14, avg_loss = 0.0116\n",
            "t = 15, avg_loss = 0.0397\n",
            "Checking accuracy on test set\n",
            "Got 199 / 240 correct (82.92)\n",
            "acc = 0.829167\n",
            "Starting epoch 93 / 100\n",
            "t = 1, avg_loss = 0.0203\n",
            "t = 2, avg_loss = 0.0315\n",
            "t = 3, avg_loss = 0.0055\n",
            "t = 4, avg_loss = 0.0152\n",
            "t = 5, avg_loss = 0.0835\n",
            "t = 6, avg_loss = 0.0358\n",
            "t = 7, avg_loss = 0.0171\n",
            "t = 8, avg_loss = 0.0569\n",
            "t = 9, avg_loss = 0.0046\n",
            "t = 10, avg_loss = 0.0230\n",
            "t = 11, avg_loss = 0.0504\n",
            "t = 12, avg_loss = 0.0268\n",
            "t = 13, avg_loss = 0.0077\n",
            "t = 14, avg_loss = 0.0110\n",
            "t = 15, avg_loss = 0.0202\n",
            "Checking accuracy on test set\n",
            "Got 192 / 240 correct (80.00)\n",
            "acc = 0.800000\n",
            "Starting epoch 94 / 100\n",
            "t = 1, avg_loss = 0.0417\n",
            "t = 2, avg_loss = 0.0174\n",
            "t = 3, avg_loss = 0.0551\n",
            "t = 4, avg_loss = 0.0882\n",
            "t = 5, avg_loss = 0.0626\n",
            "t = 6, avg_loss = 0.0056\n",
            "t = 7, avg_loss = 0.0013\n",
            "t = 8, avg_loss = 0.0201\n",
            "t = 9, avg_loss = 0.0290\n",
            "t = 10, avg_loss = 0.0115\n",
            "t = 11, avg_loss = 0.0080\n",
            "t = 12, avg_loss = 0.0104\n",
            "t = 13, avg_loss = 0.0040\n",
            "t = 14, avg_loss = 0.0109\n",
            "t = 15, avg_loss = 0.0336\n",
            "Checking accuracy on test set\n",
            "Got 196 / 240 correct (81.67)\n",
            "acc = 0.816667\n",
            "Starting epoch 95 / 100\n",
            "t = 1, avg_loss = 0.0102\n",
            "t = 2, avg_loss = 0.0157\n",
            "t = 3, avg_loss = 0.0095\n",
            "t = 4, avg_loss = 0.0146\n",
            "t = 5, avg_loss = 0.0136\n",
            "t = 6, avg_loss = 0.0136\n",
            "t = 7, avg_loss = 0.0190\n",
            "t = 8, avg_loss = 0.0056\n",
            "t = 9, avg_loss = 0.0100\n",
            "t = 10, avg_loss = 0.0371\n",
            "t = 11, avg_loss = 0.0102\n",
            "t = 12, avg_loss = 0.0711\n",
            "t = 13, avg_loss = 0.0033\n",
            "t = 14, avg_loss = 0.0027\n",
            "t = 15, avg_loss = 0.0290\n",
            "Checking accuracy on test set\n",
            "Got 195 / 240 correct (81.25)\n",
            "acc = 0.812500\n",
            "Starting epoch 96 / 100\n",
            "t = 1, avg_loss = 0.0224\n",
            "t = 2, avg_loss = 0.0126\n",
            "t = 3, avg_loss = 0.0107\n",
            "t = 4, avg_loss = 0.0517\n",
            "t = 5, avg_loss = 0.0173\n",
            "t = 6, avg_loss = 0.0661\n",
            "t = 7, avg_loss = 0.0056\n",
            "t = 8, avg_loss = 0.0437\n",
            "t = 9, avg_loss = 0.0204\n",
            "t = 10, avg_loss = 0.0146\n",
            "t = 11, avg_loss = 0.0052\n",
            "t = 12, avg_loss = 0.0446\n",
            "t = 13, avg_loss = 0.0047\n",
            "t = 14, avg_loss = 0.0279\n",
            "t = 15, avg_loss = 0.1108\n",
            "Checking accuracy on test set\n",
            "Got 196 / 240 correct (81.67)\n",
            "acc = 0.816667\n",
            "Starting epoch 97 / 100\n",
            "t = 1, avg_loss = 0.0278\n",
            "t = 2, avg_loss = 0.0333\n",
            "t = 3, avg_loss = 0.0056\n",
            "t = 4, avg_loss = 0.0144\n",
            "t = 5, avg_loss = 0.0039\n",
            "t = 6, avg_loss = 0.0319\n",
            "t = 7, avg_loss = 0.0282\n",
            "t = 8, avg_loss = 0.0310\n",
            "t = 9, avg_loss = 0.0341\n",
            "t = 10, avg_loss = 0.0098\n",
            "t = 11, avg_loss = 0.0110\n",
            "t = 12, avg_loss = 0.0676\n",
            "t = 13, avg_loss = 0.0132\n",
            "t = 14, avg_loss = 0.0428\n",
            "t = 15, avg_loss = 0.0087\n",
            "Checking accuracy on test set\n",
            "Got 200 / 240 correct (83.33)\n",
            "acc = 0.833333\n",
            "Starting epoch 98 / 100\n",
            "t = 1, avg_loss = 0.0171\n",
            "t = 2, avg_loss = 0.0297\n",
            "t = 3, avg_loss = 0.0090\n",
            "t = 4, avg_loss = 0.0168\n",
            "t = 5, avg_loss = 0.0059\n",
            "t = 6, avg_loss = 0.0044\n",
            "t = 7, avg_loss = 0.0188\n",
            "t = 8, avg_loss = 0.0313\n",
            "t = 9, avg_loss = 0.0100\n",
            "t = 10, avg_loss = 0.0029\n",
            "t = 11, avg_loss = 0.0144\n",
            "t = 12, avg_loss = 0.0124\n",
            "t = 13, avg_loss = 0.0363\n",
            "t = 14, avg_loss = 0.0031\n",
            "t = 15, avg_loss = 0.0166\n",
            "Checking accuracy on test set\n",
            "Got 197 / 240 correct (82.08)\n",
            "acc = 0.820833\n",
            "Starting epoch 99 / 100\n",
            "t = 1, avg_loss = 0.0070\n",
            "t = 2, avg_loss = 0.0162\n",
            "t = 3, avg_loss = 0.0037\n",
            "t = 4, avg_loss = 0.0092\n",
            "t = 5, avg_loss = 0.0419\n",
            "t = 6, avg_loss = 0.0341\n",
            "t = 7, avg_loss = 0.0068\n",
            "t = 8, avg_loss = 0.0132\n",
            "t = 9, avg_loss = 0.0174\n",
            "t = 10, avg_loss = 0.0480\n",
            "t = 11, avg_loss = 0.0039\n",
            "t = 12, avg_loss = 0.0147\n",
            "t = 13, avg_loss = 0.0931\n",
            "t = 14, avg_loss = 0.0088\n",
            "t = 15, avg_loss = 0.0108\n",
            "Checking accuracy on test set\n",
            "Got 201 / 240 correct (83.75)\n",
            "acc = 0.837500\n",
            "Starting epoch 100 / 100\n",
            "t = 1, avg_loss = 0.0053\n",
            "t = 2, avg_loss = 0.0137\n",
            "t = 3, avg_loss = 0.0018\n",
            "t = 4, avg_loss = 0.0030\n",
            "t = 5, avg_loss = 0.0426\n",
            "t = 6, avg_loss = 0.0540\n",
            "t = 7, avg_loss = 0.0122\n",
            "t = 8, avg_loss = 0.0010\n",
            "t = 9, avg_loss = 0.0552\n",
            "t = 10, avg_loss = 0.0091\n",
            "t = 11, avg_loss = 0.0034\n",
            "t = 12, avg_loss = 0.0264\n",
            "t = 13, avg_loss = 0.1658\n",
            "t = 14, avg_loss = 0.0279\n",
            "t = 15, avg_loss = 0.0014\n",
            "Checking accuracy on test set\n",
            "Got 196 / 240 correct (81.67)\n",
            "acc = 0.816667\n",
            "Checking accuracy on test set\n",
            "Got 193 / 240 correct (80.42)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8041666666666667"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDn-2g-TLY3k",
        "colab_type": "code",
        "outputId": "998ab8b3-dfc9-4d17-d752-41df8da8efbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot([print_every*batch_size*(i+1) for i in range((len(avg_loss_list)))],avg_loss_list)\n",
        "print(\"Loss:\")\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD4CAYAAADsKpHdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRETEo4AgIiKAAoKIiHj+P6lXsJj/4LyKAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGer6hJv7-zR",
        "colab_type": "code",
        "outputId": "8a5c1e86-521a-4621-e1f5-600fa6e2ee36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plt.plot([i+1 for i in range((len(acc_list)))],acc_list)\n",
        "print(\"Accurancy:\")\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accurancy:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAVTPez/vp+WwAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBTReWHxz4Ml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}