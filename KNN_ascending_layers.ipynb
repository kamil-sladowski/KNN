{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN_ascending_layers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamilo116/KNN/blob/master/KNN_ascending_layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7ReM7FU-xs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import sys\n",
        "from random import shuffle\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms as transforms\n",
        "import timeit\n",
        "\n",
        "np.random.seed(4) \n",
        "torch.manual_seed(4) \n",
        "torch.cuda.manual_seed(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYIMZ8QyYewD",
        "colab_type": "code",
        "outputId": "a19df4ff-2b5c-4ca1-9e15-dde3e66ca4d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "! git clone https://github.com/wang-chen/kervolution.git \n",
        "\n",
        "sys.path.append(\"kervolution/\")\n",
        "from kervolution import Kerv2d\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'kervolution' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvbKg4VJXKY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LIMIT_IMAGES_NUM = 1000\n",
        "train_test_split_size = 0.2\n",
        "image_resize = (100, 100)\n",
        "batch_size = 64\n",
        "num_workers = 0\n",
        "\n",
        "out_1 = 16\n",
        "out_2 = 32\n",
        "out_3 = 64\n",
        "out_4 = 100\n",
        "out_5 = 128\n",
        "\n",
        "\n",
        "k_size_1 = 3\n",
        "padding_1 = 1\n",
        "in_channels = 3\n",
        "\n",
        "kernel_size = 3\n",
        "num_epochs = 80\n",
        "\n",
        "learning_rate = 0.0001\n",
        "weight_decay = 0.05\n",
        "\n",
        "MALIGNANT_DATASET = '/content/drive/My Drive/Colab_data/malignant/malignant/'\n",
        "BENIGN_DATASET = '/content/drive/My Drive/Colab_data/benign/benign/'\n",
        "DATA_FOLDER = '/content/drive/My Drive/Colab_data/'\n",
        "model_backup_path = os.path.join(DATA_FOLDER, 'backup_model2') \n",
        "TRAIN_DATA_PER_CATEGORY = 101"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbMvvuct1lUT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMOHez_kHZD6",
        "colab_type": "code",
        "outputId": "82aeeab1-3041-4afb-b08c-0fd476414a9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b8P1NdXfVdX",
        "colab_type": "code",
        "outputId": "c19604ed-f441-4618-cf98-57256b6692c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "benign_train_list = sorted(os.listdir(BENIGN_DATASET))[:LIMIT_IMAGES_NUM]\n",
        "malignant_train_list = sorted(os.listdir(MALIGNANT_DATASET))[:LIMIT_IMAGES_NUM]\n",
        "\n",
        "shuffle(benign_train_list)\n",
        "shuffle(malignant_train_list)\n",
        "\n",
        "test_benign_file_list = os.listdir(BENIGN_DATASET + 'test_set')[:TRAIN_DATA_PER_CATEGORY]\n",
        "test_malignant_file_list = os.listdir(MALIGNANT_DATASET + 'test_set')[:TRAIN_DATA_PER_CATEGORY]\n",
        "shuffle(test_benign_file_list)\n",
        "shuffle(test_malignant_file_list)\n",
        "print(f\"Number of training benign {len(benign_train_list)} images\")\n",
        "print(f\"Number of training malignant {len(malignant_train_list)} images\")\n",
        "print(f\"Number of test benign {len(test_benign_file_list)} images\")\n",
        "print(f\"Number of test malignant {len(test_malignant_file_list)} images\")\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize(image_resize),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    #transforms.RandomRotation(45),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "data_transforms_test = transforms.Compose([\n",
        "    transforms.Resize(image_resize),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training benign 1000 images\n",
            "Number of training malignant 1000 images\n",
            "Number of test benign 101 images\n",
            "Number of test malignant 101 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvAAOqmVfVll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IsicDataset(Dataset):\n",
        "    def __init__(self, data_folder, labeled_data, \n",
        "                 transform=transforms.Compose([transforms.ToTensor()]), datatype='train'):\n",
        "        self.labeled_data = labeled_data\n",
        "        self.transform = transform\n",
        "        self.data_folder = data_folder\n",
        "        self.datatype = datatype\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labeled_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        label = self.labeled_data[index]\n",
        "        test_set = ''\n",
        "        if self.datatype == 'test':\n",
        "          test_set = 'test_set' \n",
        "        if label == 0:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"benign\", \"benign\", test_set, index ))\n",
        "        else:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"malignant\", \"malignant\", test_set, index ))\n",
        "        image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "    @property\n",
        "    def labels(self):\n",
        "      return self.labeled_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e8nFBR6Yug5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "def prepare_dataset(benign_file_list, malignant_file_list, transform, datatype='train'):\n",
        "  benign_dict = {filename: 0 for filename in benign_file_list}\n",
        "  malignant_dict = {filename: 1 for filename in malignant_file_list}\n",
        "  img_class_dict = {**benign_dict , **malignant_dict}\n",
        "  labeled_data = pd.Series(img_class_dict)\n",
        "\n",
        "  dataset = IsicDataset(DATA_FOLDER, labeled_data, transform=transform, datatype=datatype)\n",
        "  print(dataset.labels)\n",
        "  return dataset\n",
        "\n",
        "def train(model, train_loader ,loss_fn, optimizer, num_epochs=1, starting_from_epoch=1):\n",
        "    total_loss =0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
        "        model.train()\n",
        "\n",
        "        for t, (x, y) in enumerate(train_loader):\n",
        "            x_var = Variable(x.type(gpu_dtype))\n",
        "            y_var = Variable(y.type(gpu_dtype).long())\n",
        "            scores = model(x_var)\n",
        "            loss = loss_fn(scores, y_var)\n",
        "            total_loss += loss.data\n",
        "            \n",
        "            if (t + 1) % print_every == 0:\n",
        "                avg_loss = total_loss/print_every\n",
        "                print('t = %d, avg_loss = %.4f' % (t + 1, avg_loss) )\n",
        "                avg_loss_list.append(avg_loss)\n",
        "                total_loss = 0\n",
        "                \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        acc = check_accuracy(model_gpu, valid_loader)\n",
        "        print('acc = %f' %(acc))\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model_gpu.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            'acc_list': acc_list,\n",
        "            }, model_backup_path)\n",
        "            \n",
        "def check_accuracy(model, loader, datatype='train'):\n",
        "    print(f'Checking accuracy on {datatype} set')   \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval() \n",
        "    for x, y in loader:\n",
        "        x_var = Variable(x.type(gpu_dtype))\n",
        "\n",
        "        scores = model(x_var)\n",
        "        _, preds = scores.data.cpu().max(1)\n",
        "        num_correct += (preds == y).sum()\n",
        "        num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    if datatype is 'train':\n",
        "      acc_list.append(acc)\n",
        "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "    return acc\n",
        "    \n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.size()\n",
        "        return x.view(N, -1)  \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSuYqjLAYrWA",
        "colab_type": "code",
        "outputId": "d94ba75b-0213-4527-a7c9-89b26add1252",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "train_dataset = prepare_dataset(benign_train_list, malignant_train_list, data_transforms)\n",
        "\n",
        "X_train, X_valid = train_test_split(train_dataset.labels, test_size=train_test_split_size)\n",
        "\n",
        "print(\"number of training data: \",len(X_train))\n",
        "print(\"number of valid  data: \",len(X_valid))\n",
        "\n",
        "train_sampler = SubsetRandomSampler(list(X_train.index))\n",
        "valid_sampler = SubsetRandomSampler(list(X_valid.index))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ISIC_0000630.jpeg    0\n",
            "ISIC_0001366.jpeg    0\n",
            "ISIC_0000315.jpeg    0\n",
            "ISIC_0000735.jpeg    0\n",
            "ISIC_0001325.jpeg    0\n",
            "                    ..\n",
            "ISIC_0011700.jpeg    1\n",
            "ISIC_0014290.jpeg    1\n",
            "ISIC_0010746.jpeg    1\n",
            "ISIC_0000040.jpeg    1\n",
            "ISIC_0010923.jpeg    1\n",
            "Length: 2000, dtype: int64\n",
            "number of training data:  1600\n",
            "number of valid  data:  400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vjEOfNZUB7W",
        "colab_type": "code",
        "outputId": "febe534d-5388-4dcc-bc2c-ef9a5c23dbbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "test_dataset = prepare_dataset(test_benign_file_list, test_malignant_file_list, data_transforms_test, datatype='test')\n",
        "test_part, _ = train_test_split(test_dataset.labels, test_size=1)\n",
        "test_sampler = SubsetRandomSampler(list(test_part.index))\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=50, sampler=test_sampler, num_workers=num_workers)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ISIC_0000348.jpeg    0\n",
            "ISIC_0000461.jpeg    0\n",
            "ISIC_0000023.jpeg    0\n",
            "ISIC_0000265.jpeg    0\n",
            "ISIC_0001415.jpeg    0\n",
            "                    ..\n",
            "ISIC_0010322.jpeg    1\n",
            "ISIC_0010401.jpeg    1\n",
            "ISIC_0012067.jpeg    1\n",
            "ISIC_0026847.jpg     1\n",
            "ISIC_0015109.jpeg    1\n",
            "Length: 202, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-gYHw0Jlbwt",
        "colab_type": "code",
        "outputId": "8d216f6d-2292-43a3-8e59-b0680f0b33b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "print_every = 5\n",
        "gpu_dtype = torch.cuda.FloatTensor\n",
        "\n",
        "\n",
        "'''\n",
        "Kerv2d\n",
        "kervolution with following options:\n",
        "kernel_type: [linear, polynomial, gaussian, etc.]\n",
        "default is convolution:\n",
        "          kernel_type --> linear,\n",
        "balance, power, gamma is valid only when the kernel_type is specified\n",
        "if learnable_kernel = True,  they just be the initial value of learable parameters\n",
        "if learnable_kernel = False, they are the value of kernel_type's parameter\n",
        "the parameter [power] cannot be learned due to integer limitation\n",
        "dilation (int or tuple, optional): Spacing between kernel\n",
        "elements. Default: 1\n",
        "groups (int, optional): Number of blocked connections from input\n",
        "channels to output channels. Default: 1\n",
        "bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n",
        "kernel_type (str), Default: 'linear'\n",
        "learnable_kernel (bool): Learnable kernel parameters.  Default: False \n",
        "balance: 0, 1\n",
        "power: 3, 4, 5\n",
        "gamma:\n",
        "'''\n",
        "\n",
        "model_base = nn.Sequential( \n",
        "                #nn.Conv2d(in_channels , out_1, padding= padding_1, kernel_size=k_size_1, stride=1),\n",
        "                nn.Kerv2d(in_channels , out_1, padding=padding_1, bias=True, \n",
        "                          kernel_type='gaussian', kernel_size=3, learnable_kernel=True,\n",
        "                          kernel_regularizer=True, stride=1, gamma=0.75\n",
        "                          ), \n",
        "                #nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_1),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_1 , out_2, padding= padding_1, kernel_size=3, stride=1), \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_2),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_2 , out_3, padding= padding_1, kernel_size=3, stride=1),  \n",
        "                \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_3),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                # nn.Conv2d(out_3 , out_4, padding= padding_1, kernel_size=3, stride=1),  \n",
        "                # nn.ReLU(inplace=True),\n",
        "                # nn.BatchNorm2d(out_4),\n",
        "                # nn.MaxPool2d(2, stride=2),\n",
        "                # nn.Conv2d(out_4 , out_5, padding= padding_1, kernel_size=3, stride=1),  \n",
        "                # nn.ReLU(inplace=True),\n",
        "                # nn.BatchNorm2d(out_5),\n",
        "                # nn.MaxPool2d(2, stride=2),\n",
        "                nn.Dropout(0.5),\n",
        "                Flatten(),\n",
        "                nn.Linear(9216,64),\n",
        "                nn.Dropout(0.05),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Linear(64,2)\n",
        "            )\n",
        "model_gpu = model_base.type(gpu_dtype)\n",
        "print(model_gpu)\n",
        "loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Kerv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (4): ReLU(inplace=True)\n",
            "  (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (7): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (8): ReLU(inplace=True)\n",
            "  (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (11): Dropout(p=0.5, inplace=False)\n",
            "  (12): Flatten()\n",
            "  (13): Linear(in_features=9216, out_features=64, bias=True)\n",
            "  (14): Dropout(p=0.05, inplace=False)\n",
            "  (15): ReLU(inplace=True)\n",
            "  (16): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQyrlcCSRAby",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmioXyejRDF3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgmexhBRZAK6",
        "colab_type": "code",
        "outputId": "74aeef6c-7eb9-4512-b537-029a804621e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 1 / 80\n",
            "t = 5, avg_loss = 0.6499\n",
            "t = 10, avg_loss = 0.5909\n",
            "t = 15, avg_loss = 0.6304\n",
            "t = 20, avg_loss = 0.5507\n",
            "t = 25, avg_loss = 0.5016\n",
            "Checking accuracy on train set\n",
            "Got 203 / 400 correct (50.75)\n",
            "acc = 0.507500\n",
            "Starting epoch 2 / 80\n",
            "t = 5, avg_loss = 0.5044\n",
            "t = 10, avg_loss = 0.4990\n",
            "t = 15, avg_loss = 0.5071\n",
            "t = 20, avg_loss = 0.4525\n",
            "t = 25, avg_loss = 0.4837\n",
            "Checking accuracy on train set\n",
            "Got 267 / 400 correct (66.75)\n",
            "acc = 0.667500\n",
            "Starting epoch 3 / 80\n",
            "t = 5, avg_loss = 0.4517\n",
            "t = 10, avg_loss = 0.4316\n",
            "t = 15, avg_loss = 0.4610\n",
            "t = 20, avg_loss = 0.4632\n",
            "t = 25, avg_loss = 0.4472\n",
            "Checking accuracy on train set\n",
            "Got 290 / 400 correct (72.50)\n",
            "acc = 0.725000\n",
            "Starting epoch 4 / 80\n",
            "t = 5, avg_loss = 0.4409\n",
            "t = 10, avg_loss = 0.4372\n",
            "t = 15, avg_loss = 0.3975\n",
            "t = 20, avg_loss = 0.4238\n",
            "t = 25, avg_loss = 0.4642\n",
            "Checking accuracy on train set\n",
            "Got 308 / 400 correct (77.00)\n",
            "acc = 0.770000\n",
            "Starting epoch 5 / 80\n",
            "t = 5, avg_loss = 0.4010\n",
            "t = 10, avg_loss = 0.3830\n",
            "t = 15, avg_loss = 0.4154\n",
            "t = 20, avg_loss = 0.4274\n",
            "t = 25, avg_loss = 0.4196\n",
            "Checking accuracy on train set\n",
            "Got 298 / 400 correct (74.50)\n",
            "acc = 0.745000\n",
            "Starting epoch 6 / 80\n",
            "t = 5, avg_loss = 0.4185\n",
            "t = 10, avg_loss = 0.3739\n",
            "t = 15, avg_loss = 0.3631\n",
            "t = 20, avg_loss = 0.3863\n",
            "t = 25, avg_loss = 0.3992\n",
            "Checking accuracy on train set\n",
            "Got 323 / 400 correct (80.75)\n",
            "acc = 0.807500\n",
            "Starting epoch 7 / 80\n",
            "t = 5, avg_loss = 0.3195\n",
            "t = 10, avg_loss = 0.3841\n",
            "t = 15, avg_loss = 0.3833\n",
            "t = 20, avg_loss = 0.3762\n",
            "t = 25, avg_loss = 0.4025\n",
            "Checking accuracy on train set\n",
            "Got 308 / 400 correct (77.00)\n",
            "acc = 0.770000\n",
            "Starting epoch 8 / 80\n",
            "t = 5, avg_loss = 0.3723\n",
            "t = 10, avg_loss = 0.3467\n",
            "t = 15, avg_loss = 0.3935\n",
            "t = 20, avg_loss = 0.3904\n",
            "t = 25, avg_loss = 0.3897\n",
            "Checking accuracy on train set\n",
            "Got 313 / 400 correct (78.25)\n",
            "acc = 0.782500\n",
            "Starting epoch 9 / 80\n",
            "t = 5, avg_loss = 0.3291\n",
            "t = 10, avg_loss = 0.3944\n",
            "t = 15, avg_loss = 0.3628\n",
            "t = 20, avg_loss = 0.3812\n",
            "t = 25, avg_loss = 0.3563\n",
            "Checking accuracy on train set\n",
            "Got 330 / 400 correct (82.50)\n",
            "acc = 0.825000\n",
            "Starting epoch 10 / 80\n",
            "t = 5, avg_loss = 0.3348\n",
            "t = 10, avg_loss = 0.3544\n",
            "t = 15, avg_loss = 0.3873\n",
            "t = 20, avg_loss = 0.3187\n",
            "t = 25, avg_loss = 0.3456\n",
            "Checking accuracy on train set\n",
            "Got 309 / 400 correct (77.25)\n",
            "acc = 0.772500\n",
            "Starting epoch 11 / 80\n",
            "t = 5, avg_loss = 0.3481\n",
            "t = 10, avg_loss = 0.3232\n",
            "t = 15, avg_loss = 0.3134\n",
            "t = 20, avg_loss = 0.3561\n",
            "t = 25, avg_loss = 0.3588\n",
            "Checking accuracy on train set\n",
            "Got 317 / 400 correct (79.25)\n",
            "acc = 0.792500\n",
            "Starting epoch 12 / 80\n",
            "t = 5, avg_loss = 0.2942\n",
            "t = 10, avg_loss = 0.3568\n",
            "t = 15, avg_loss = 0.3258\n",
            "t = 20, avg_loss = 0.3387\n",
            "t = 25, avg_loss = 0.3680\n",
            "Checking accuracy on train set\n",
            "Got 331 / 400 correct (82.75)\n",
            "acc = 0.827500\n",
            "Starting epoch 13 / 80\n",
            "t = 5, avg_loss = 0.3065\n",
            "t = 10, avg_loss = 0.3017\n",
            "t = 15, avg_loss = 0.3196\n",
            "t = 20, avg_loss = 0.3293\n",
            "t = 25, avg_loss = 0.3298\n",
            "Checking accuracy on train set\n",
            "Got 328 / 400 correct (82.00)\n",
            "acc = 0.820000\n",
            "Starting epoch 14 / 80\n",
            "t = 5, avg_loss = 0.3095\n",
            "t = 10, avg_loss = 0.3303\n",
            "t = 15, avg_loss = 0.3065\n",
            "t = 20, avg_loss = 0.3093\n",
            "t = 25, avg_loss = 0.2996\n",
            "Checking accuracy on train set\n",
            "Got 308 / 400 correct (77.00)\n",
            "acc = 0.770000\n",
            "Starting epoch 15 / 80\n",
            "t = 5, avg_loss = 0.3825\n",
            "t = 10, avg_loss = 0.3242\n",
            "t = 15, avg_loss = 0.3070\n",
            "t = 20, avg_loss = 0.2937\n",
            "t = 25, avg_loss = 0.2736\n",
            "Checking accuracy on train set\n",
            "Got 325 / 400 correct (81.25)\n",
            "acc = 0.812500\n",
            "Starting epoch 16 / 80\n",
            "t = 5, avg_loss = 0.2783\n",
            "t = 10, avg_loss = 0.2743\n",
            "t = 15, avg_loss = 0.3703\n",
            "t = 20, avg_loss = 0.3277\n",
            "t = 25, avg_loss = 0.3075\n",
            "Checking accuracy on train set\n",
            "Got 311 / 400 correct (77.75)\n",
            "acc = 0.777500\n",
            "Starting epoch 17 / 80\n",
            "t = 5, avg_loss = 0.2919\n",
            "t = 10, avg_loss = 0.3174\n",
            "t = 15, avg_loss = 0.2530\n",
            "t = 20, avg_loss = 0.3211\n",
            "t = 25, avg_loss = 0.3356\n",
            "Checking accuracy on train set\n",
            "Got 327 / 400 correct (81.75)\n",
            "acc = 0.817500\n",
            "Starting epoch 18 / 80\n",
            "t = 5, avg_loss = 0.2723\n",
            "t = 10, avg_loss = 0.2741\n",
            "t = 15, avg_loss = 0.3229\n",
            "t = 20, avg_loss = 0.3155\n",
            "t = 25, avg_loss = 0.3786\n",
            "Checking accuracy on train set\n",
            "Got 301 / 400 correct (75.25)\n",
            "acc = 0.752500\n",
            "Starting epoch 19 / 80\n",
            "t = 5, avg_loss = 0.3406\n",
            "t = 10, avg_loss = 0.2953\n",
            "t = 15, avg_loss = 0.3114\n",
            "t = 20, avg_loss = 0.3068\n",
            "t = 25, avg_loss = 0.2774\n",
            "Checking accuracy on train set\n",
            "Got 310 / 400 correct (77.50)\n",
            "acc = 0.775000\n",
            "Starting epoch 20 / 80\n",
            "t = 5, avg_loss = 0.2626\n",
            "t = 10, avg_loss = 0.2870\n",
            "t = 15, avg_loss = 0.3178\n",
            "t = 20, avg_loss = 0.3095\n",
            "t = 25, avg_loss = 0.3011\n",
            "Checking accuracy on train set\n",
            "Got 328 / 400 correct (82.00)\n",
            "acc = 0.820000\n",
            "Starting epoch 21 / 80\n",
            "t = 5, avg_loss = 0.2725\n",
            "t = 10, avg_loss = 0.2860\n",
            "t = 15, avg_loss = 0.3138\n",
            "t = 20, avg_loss = 0.3231\n",
            "t = 25, avg_loss = 0.2603\n",
            "Checking accuracy on train set\n",
            "Got 318 / 400 correct (79.50)\n",
            "acc = 0.795000\n",
            "Starting epoch 22 / 80\n",
            "t = 5, avg_loss = 0.2611\n",
            "t = 10, avg_loss = 0.2710\n",
            "t = 15, avg_loss = 0.2829\n",
            "t = 20, avg_loss = 0.3296\n",
            "t = 25, avg_loss = 0.2408\n",
            "Checking accuracy on train set\n",
            "Got 323 / 400 correct (80.75)\n",
            "acc = 0.807500\n",
            "Starting epoch 23 / 80\n",
            "t = 5, avg_loss = 0.2412\n",
            "t = 10, avg_loss = 0.3139\n",
            "t = 15, avg_loss = 0.2760\n",
            "t = 20, avg_loss = 0.2636\n",
            "t = 25, avg_loss = 0.3093\n",
            "Checking accuracy on train set\n",
            "Got 311 / 400 correct (77.75)\n",
            "acc = 0.777500\n",
            "Starting epoch 24 / 80\n",
            "t = 5, avg_loss = 0.2589\n",
            "t = 10, avg_loss = 0.2691\n",
            "t = 15, avg_loss = 0.3060\n",
            "t = 20, avg_loss = 0.2936\n",
            "t = 25, avg_loss = 0.2730\n",
            "Checking accuracy on train set\n",
            "Got 322 / 400 correct (80.50)\n",
            "acc = 0.805000\n",
            "Starting epoch 25 / 80\n",
            "t = 5, avg_loss = 0.2857\n",
            "t = 10, avg_loss = 0.2618\n",
            "t = 15, avg_loss = 0.2425\n",
            "t = 20, avg_loss = 0.2456\n",
            "t = 25, avg_loss = 0.2920\n",
            "Checking accuracy on train set\n",
            "Got 332 / 400 correct (83.00)\n",
            "acc = 0.830000\n",
            "Starting epoch 26 / 80\n",
            "t = 5, avg_loss = 0.2501\n",
            "t = 10, avg_loss = 0.2757\n",
            "t = 15, avg_loss = 0.2326\n",
            "t = 20, avg_loss = 0.3183\n",
            "t = 25, avg_loss = 0.2350\n",
            "Checking accuracy on train set\n",
            "Got 328 / 400 correct (82.00)\n",
            "acc = 0.820000\n",
            "Starting epoch 27 / 80\n",
            "t = 5, avg_loss = 0.2245\n",
            "t = 10, avg_loss = 0.2502\n",
            "t = 15, avg_loss = 0.3029\n",
            "t = 20, avg_loss = 0.2590\n",
            "t = 25, avg_loss = 0.2635\n",
            "Checking accuracy on train set\n",
            "Got 329 / 400 correct (82.25)\n",
            "acc = 0.822500\n",
            "Starting epoch 28 / 80\n",
            "t = 5, avg_loss = 0.2402\n",
            "t = 10, avg_loss = 0.2866\n",
            "t = 15, avg_loss = 0.2774\n",
            "t = 20, avg_loss = 0.2687\n",
            "t = 25, avg_loss = 0.2538\n",
            "Checking accuracy on train set\n",
            "Got 326 / 400 correct (81.50)\n",
            "acc = 0.815000\n",
            "Starting epoch 29 / 80\n",
            "t = 5, avg_loss = 0.2698\n",
            "t = 10, avg_loss = 0.2108\n",
            "t = 15, avg_loss = 0.2958\n",
            "t = 20, avg_loss = 0.2470\n",
            "t = 25, avg_loss = 0.2704\n",
            "Checking accuracy on train set\n",
            "Got 321 / 400 correct (80.25)\n",
            "acc = 0.802500\n",
            "Starting epoch 30 / 80\n",
            "t = 5, avg_loss = 0.2277\n",
            "t = 10, avg_loss = 0.2946\n",
            "t = 15, avg_loss = 0.2854\n",
            "t = 20, avg_loss = 0.2699\n",
            "t = 25, avg_loss = 0.2487\n",
            "Checking accuracy on train set\n",
            "Got 328 / 400 correct (82.00)\n",
            "acc = 0.820000\n",
            "Starting epoch 31 / 80\n",
            "t = 5, avg_loss = 0.2602\n",
            "t = 10, avg_loss = 0.2354\n",
            "t = 15, avg_loss = 0.2560\n",
            "t = 20, avg_loss = 0.2276\n",
            "t = 25, avg_loss = 0.2713\n",
            "Checking accuracy on train set\n",
            "Got 330 / 400 correct (82.50)\n",
            "acc = 0.825000\n",
            "Starting epoch 32 / 80\n",
            "t = 5, avg_loss = 0.2491\n",
            "t = 10, avg_loss = 0.2545\n",
            "t = 15, avg_loss = 0.2210\n",
            "t = 20, avg_loss = 0.2502\n",
            "t = 25, avg_loss = 0.2416\n",
            "Checking accuracy on train set\n",
            "Got 321 / 400 correct (80.25)\n",
            "acc = 0.802500\n",
            "Starting epoch 33 / 80\n",
            "t = 5, avg_loss = 0.2553\n",
            "t = 10, avg_loss = 0.2493\n",
            "t = 15, avg_loss = 0.2618\n",
            "t = 20, avg_loss = 0.2498\n",
            "t = 25, avg_loss = 0.2842\n",
            "Checking accuracy on train set\n",
            "Got 331 / 400 correct (82.75)\n",
            "acc = 0.827500\n",
            "Starting epoch 34 / 80\n",
            "t = 5, avg_loss = 0.2449\n",
            "t = 10, avg_loss = 0.2170\n",
            "t = 15, avg_loss = 0.2712\n",
            "t = 20, avg_loss = 0.2210\n",
            "t = 25, avg_loss = 0.2503\n",
            "Checking accuracy on train set\n",
            "Got 319 / 400 correct (79.75)\n",
            "acc = 0.797500\n",
            "Starting epoch 35 / 80\n",
            "t = 5, avg_loss = 0.1947\n",
            "t = 10, avg_loss = 0.2646\n",
            "t = 15, avg_loss = 0.2426\n",
            "t = 20, avg_loss = 0.2361\n",
            "t = 25, avg_loss = 0.2595\n",
            "Checking accuracy on train set\n",
            "Got 325 / 400 correct (81.25)\n",
            "acc = 0.812500\n",
            "Starting epoch 36 / 80\n",
            "t = 5, avg_loss = 0.2352\n",
            "t = 10, avg_loss = 0.2485\n",
            "t = 15, avg_loss = 0.2669\n",
            "t = 20, avg_loss = 0.2401\n",
            "t = 25, avg_loss = 0.2203\n",
            "Checking accuracy on train set\n",
            "Got 319 / 400 correct (79.75)\n",
            "acc = 0.797500\n",
            "Starting epoch 37 / 80\n",
            "t = 5, avg_loss = 0.2260\n",
            "t = 10, avg_loss = 0.2977\n",
            "t = 15, avg_loss = 0.2203\n",
            "t = 20, avg_loss = 0.2186\n",
            "t = 25, avg_loss = 0.2334\n",
            "Checking accuracy on train set\n",
            "Got 321 / 400 correct (80.25)\n",
            "acc = 0.802500\n",
            "Starting epoch 38 / 80\n",
            "t = 5, avg_loss = 0.2629\n",
            "t = 10, avg_loss = 0.2108\n",
            "t = 15, avg_loss = 0.2177\n",
            "t = 20, avg_loss = 0.2014\n",
            "t = 25, avg_loss = 0.2783\n",
            "Checking accuracy on train set\n",
            "Got 328 / 400 correct (82.00)\n",
            "acc = 0.820000\n",
            "Starting epoch 39 / 80\n",
            "t = 5, avg_loss = 0.2106\n",
            "t = 10, avg_loss = 0.2437\n",
            "t = 15, avg_loss = 0.2080\n",
            "t = 20, avg_loss = 0.2775\n",
            "t = 25, avg_loss = 0.2671\n",
            "Checking accuracy on train set\n",
            "Got 322 / 400 correct (80.50)\n",
            "acc = 0.805000\n",
            "Starting epoch 40 / 80\n",
            "t = 5, avg_loss = 0.2139\n",
            "t = 10, avg_loss = 0.2615\n",
            "t = 15, avg_loss = 0.2295\n",
            "t = 20, avg_loss = 0.2591\n",
            "t = 25, avg_loss = 0.1940\n",
            "Checking accuracy on train set\n",
            "Got 334 / 400 correct (83.50)\n",
            "acc = 0.835000\n",
            "Starting epoch 41 / 80\n",
            "t = 5, avg_loss = 0.2391\n",
            "t = 10, avg_loss = 0.2362\n",
            "t = 15, avg_loss = 0.2295\n",
            "t = 20, avg_loss = 0.1955\n",
            "t = 25, avg_loss = 0.2071\n",
            "Checking accuracy on train set\n",
            "Got 323 / 400 correct (80.75)\n",
            "acc = 0.807500\n",
            "Starting epoch 42 / 80\n",
            "t = 5, avg_loss = 0.2100\n",
            "t = 10, avg_loss = 0.2058\n",
            "t = 15, avg_loss = 0.2717\n",
            "t = 20, avg_loss = 0.2311\n",
            "t = 25, avg_loss = 0.2715\n",
            "Checking accuracy on train set\n",
            "Got 315 / 400 correct (78.75)\n",
            "acc = 0.787500\n",
            "Starting epoch 43 / 80\n",
            "t = 5, avg_loss = 0.2610\n",
            "t = 10, avg_loss = 0.2235\n",
            "t = 15, avg_loss = 0.2060\n",
            "t = 20, avg_loss = 0.1891\n",
            "t = 25, avg_loss = 0.2271\n",
            "Checking accuracy on train set\n",
            "Got 322 / 400 correct (80.50)\n",
            "acc = 0.805000\n",
            "Starting epoch 44 / 80\n",
            "t = 5, avg_loss = 0.2002\n",
            "t = 10, avg_loss = 0.2233\n",
            "t = 15, avg_loss = 0.2240\n",
            "t = 20, avg_loss = 0.1881\n",
            "t = 25, avg_loss = 0.2389\n",
            "Checking accuracy on train set\n",
            "Got 313 / 400 correct (78.25)\n",
            "acc = 0.782500\n",
            "Starting epoch 45 / 80\n",
            "t = 5, avg_loss = 0.2012\n",
            "t = 10, avg_loss = 0.1889\n",
            "t = 15, avg_loss = 0.2333\n",
            "t = 20, avg_loss = 0.2244\n",
            "t = 25, avg_loss = 0.2229\n",
            "Checking accuracy on train set\n",
            "Got 321 / 400 correct (80.25)\n",
            "acc = 0.802500\n",
            "Starting epoch 46 / 80\n",
            "t = 5, avg_loss = 0.1936\n",
            "t = 10, avg_loss = 0.2288\n",
            "t = 15, avg_loss = 0.1837\n",
            "t = 20, avg_loss = 0.2090\n",
            "t = 25, avg_loss = 0.2387\n",
            "Checking accuracy on train set\n",
            "Got 334 / 400 correct (83.50)\n",
            "acc = 0.835000\n",
            "Starting epoch 47 / 80\n",
            "t = 5, avg_loss = 0.1895\n",
            "t = 10, avg_loss = 0.2053\n",
            "t = 15, avg_loss = 0.2136\n",
            "t = 20, avg_loss = 0.2108\n",
            "t = 25, avg_loss = 0.2082\n",
            "Checking accuracy on train set\n",
            "Got 333 / 400 correct (83.25)\n",
            "acc = 0.832500\n",
            "Starting epoch 48 / 80\n",
            "t = 5, avg_loss = 0.2002\n",
            "t = 10, avg_loss = 0.2414\n",
            "t = 15, avg_loss = 0.2257\n",
            "t = 20, avg_loss = 0.1829\n",
            "t = 25, avg_loss = 0.2098\n",
            "Checking accuracy on train set\n",
            "Got 326 / 400 correct (81.50)\n",
            "acc = 0.815000\n",
            "Starting epoch 49 / 80\n",
            "t = 5, avg_loss = 0.2310\n",
            "t = 10, avg_loss = 0.1881\n",
            "t = 15, avg_loss = 0.1995\n",
            "t = 20, avg_loss = 0.2090\n",
            "t = 25, avg_loss = 0.2230\n",
            "Checking accuracy on train set\n",
            "Got 331 / 400 correct (82.75)\n",
            "acc = 0.827500\n",
            "Starting epoch 50 / 80\n",
            "t = 5, avg_loss = 0.1803\n",
            "t = 10, avg_loss = 0.2041\n",
            "t = 15, avg_loss = 0.1963\n",
            "t = 20, avg_loss = 0.2357\n",
            "t = 25, avg_loss = 0.2128\n",
            "Checking accuracy on train set\n",
            "Got 323 / 400 correct (80.75)\n",
            "acc = 0.807500\n",
            "Starting epoch 51 / 80\n",
            "t = 5, avg_loss = 0.1917\n",
            "t = 10, avg_loss = 0.2141\n",
            "t = 15, avg_loss = 0.1997\n",
            "t = 20, avg_loss = 0.2133\n",
            "t = 25, avg_loss = 0.2227\n",
            "Checking accuracy on train set\n",
            "Got 336 / 400 correct (84.00)\n",
            "acc = 0.840000\n",
            "Starting epoch 52 / 80\n",
            "t = 5, avg_loss = 0.1962\n",
            "t = 10, avg_loss = 0.1891\n",
            "t = 15, avg_loss = 0.1899\n",
            "t = 20, avg_loss = 0.2407\n",
            "t = 25, avg_loss = 0.1990\n",
            "Checking accuracy on train set\n",
            "Got 315 / 400 correct (78.75)\n",
            "acc = 0.787500\n",
            "Starting epoch 53 / 80\n",
            "t = 5, avg_loss = 0.1806\n",
            "t = 10, avg_loss = 0.2001\n",
            "t = 15, avg_loss = 0.1915\n",
            "t = 20, avg_loss = 0.1902\n",
            "t = 25, avg_loss = 0.2460\n",
            "Checking accuracy on train set\n",
            "Got 320 / 400 correct (80.00)\n",
            "acc = 0.800000\n",
            "Starting epoch 54 / 80\n",
            "t = 5, avg_loss = 0.1949\n",
            "t = 10, avg_loss = 0.2151\n",
            "t = 15, avg_loss = 0.2237\n",
            "t = 20, avg_loss = 0.1916\n",
            "t = 25, avg_loss = 0.2161\n",
            "Checking accuracy on train set\n",
            "Got 325 / 400 correct (81.25)\n",
            "acc = 0.812500\n",
            "Starting epoch 55 / 80\n",
            "t = 5, avg_loss = 0.1758\n",
            "t = 10, avg_loss = 0.2302\n",
            "t = 15, avg_loss = 0.1856\n",
            "t = 20, avg_loss = 0.1778\n",
            "t = 25, avg_loss = 0.2133\n",
            "Checking accuracy on train set\n",
            "Got 330 / 400 correct (82.50)\n",
            "acc = 0.825000\n",
            "Starting epoch 56 / 80\n",
            "t = 5, avg_loss = 0.1660\n",
            "t = 10, avg_loss = 0.1811\n",
            "t = 15, avg_loss = 0.1968\n",
            "t = 20, avg_loss = 0.1801\n",
            "t = 25, avg_loss = 0.1774\n",
            "Checking accuracy on train set\n",
            "Got 328 / 400 correct (82.00)\n",
            "acc = 0.820000\n",
            "Starting epoch 57 / 80\n",
            "t = 5, avg_loss = 0.1904\n",
            "t = 10, avg_loss = 0.1795\n",
            "t = 15, avg_loss = 0.1834\n",
            "t = 20, avg_loss = 0.1780\n",
            "t = 25, avg_loss = 0.2175\n",
            "Checking accuracy on train set\n",
            "Got 326 / 400 correct (81.50)\n",
            "acc = 0.815000\n",
            "Starting epoch 58 / 80\n",
            "t = 5, avg_loss = 0.2074\n",
            "t = 10, avg_loss = 0.1954\n",
            "t = 15, avg_loss = 0.1676\n",
            "t = 20, avg_loss = 0.2013\n",
            "t = 25, avg_loss = 0.1975\n",
            "Checking accuracy on train set\n",
            "Got 331 / 400 correct (82.75)\n",
            "acc = 0.827500\n",
            "Starting epoch 59 / 80\n",
            "t = 5, avg_loss = 0.1894\n",
            "t = 10, avg_loss = 0.1689\n",
            "t = 15, avg_loss = 0.1974\n",
            "t = 20, avg_loss = 0.1745\n",
            "t = 25, avg_loss = 0.1947\n",
            "Checking accuracy on train set\n",
            "Got 332 / 400 correct (83.00)\n",
            "acc = 0.830000\n",
            "Starting epoch 60 / 80\n",
            "t = 5, avg_loss = 0.1403\n",
            "t = 10, avg_loss = 0.1891\n",
            "t = 15, avg_loss = 0.2042\n",
            "t = 20, avg_loss = 0.2353\n",
            "t = 25, avg_loss = 0.2004\n",
            "Checking accuracy on train set\n",
            "Got 330 / 400 correct (82.50)\n",
            "acc = 0.825000\n",
            "Starting epoch 61 / 80\n",
            "t = 5, avg_loss = 0.1798\n",
            "t = 10, avg_loss = 0.2051\n",
            "t = 15, avg_loss = 0.1924\n",
            "t = 20, avg_loss = 0.1756\n",
            "t = 25, avg_loss = 0.1950\n",
            "Checking accuracy on train set\n",
            "Got 328 / 400 correct (82.00)\n",
            "acc = 0.820000\n",
            "Starting epoch 62 / 80\n",
            "t = 5, avg_loss = 0.1804\n",
            "t = 10, avg_loss = 0.1578\n",
            "t = 15, avg_loss = 0.1887\n",
            "t = 20, avg_loss = 0.2208\n",
            "t = 25, avg_loss = 0.1794\n",
            "Checking accuracy on train set\n",
            "Got 324 / 400 correct (81.00)\n",
            "acc = 0.810000\n",
            "Starting epoch 63 / 80\n",
            "t = 5, avg_loss = 0.1614\n",
            "t = 10, avg_loss = 0.1905\n",
            "t = 15, avg_loss = 0.1614\n",
            "t = 20, avg_loss = 0.1456\n",
            "t = 25, avg_loss = 0.1953\n",
            "Checking accuracy on train set\n",
            "Got 333 / 400 correct (83.25)\n",
            "acc = 0.832500\n",
            "Starting epoch 64 / 80\n",
            "t = 5, avg_loss = 0.1502\n",
            "t = 10, avg_loss = 0.2124\n",
            "t = 15, avg_loss = 0.1869\n",
            "t = 20, avg_loss = 0.1890\n",
            "t = 25, avg_loss = 0.1756\n",
            "Checking accuracy on train set\n",
            "Got 325 / 400 correct (81.25)\n",
            "acc = 0.812500\n",
            "Starting epoch 65 / 80\n",
            "t = 5, avg_loss = 0.1526\n",
            "t = 10, avg_loss = 0.2196\n",
            "t = 15, avg_loss = 0.2282\n",
            "t = 20, avg_loss = 0.1511\n",
            "t = 25, avg_loss = 0.2055\n",
            "Checking accuracy on train set\n",
            "Got 337 / 400 correct (84.25)\n",
            "acc = 0.842500\n",
            "Starting epoch 66 / 80\n",
            "t = 5, avg_loss = 0.1670\n",
            "t = 10, avg_loss = 0.1689\n",
            "t = 15, avg_loss = 0.2021\n",
            "t = 20, avg_loss = 0.1840\n",
            "t = 25, avg_loss = 0.1796\n",
            "Checking accuracy on train set\n",
            "Got 329 / 400 correct (82.25)\n",
            "acc = 0.822500\n",
            "Starting epoch 67 / 80\n",
            "t = 5, avg_loss = 0.1561\n",
            "t = 10, avg_loss = 0.1808\n",
            "t = 15, avg_loss = 0.1916\n",
            "t = 20, avg_loss = 0.1772\n",
            "t = 25, avg_loss = 0.1812\n",
            "Checking accuracy on train set\n",
            "Got 328 / 400 correct (82.00)\n",
            "acc = 0.820000\n",
            "Starting epoch 68 / 80\n",
            "t = 5, avg_loss = 0.1677\n",
            "t = 10, avg_loss = 0.1524\n",
            "t = 15, avg_loss = 0.1804\n",
            "t = 20, avg_loss = 0.1882\n",
            "t = 25, avg_loss = 0.2102\n",
            "Checking accuracy on train set\n",
            "Got 338 / 400 correct (84.50)\n",
            "acc = 0.845000\n",
            "Starting epoch 69 / 80\n",
            "t = 5, avg_loss = 0.1749\n",
            "t = 10, avg_loss = 0.2059\n",
            "t = 15, avg_loss = 0.1804\n",
            "t = 20, avg_loss = 0.1648\n",
            "t = 25, avg_loss = 0.1952\n",
            "Checking accuracy on train set\n",
            "Got 321 / 400 correct (80.25)\n",
            "acc = 0.802500\n",
            "Starting epoch 70 / 80\n",
            "t = 5, avg_loss = 0.1784\n",
            "t = 10, avg_loss = 0.1888\n",
            "t = 15, avg_loss = 0.2187\n",
            "t = 20, avg_loss = 0.1797\n",
            "t = 25, avg_loss = 0.1582\n",
            "Checking accuracy on train set\n",
            "Got 340 / 400 correct (85.00)\n",
            "acc = 0.850000\n",
            "Starting epoch 71 / 80\n",
            "t = 5, avg_loss = 0.1782\n",
            "t = 10, avg_loss = 0.1644\n",
            "t = 15, avg_loss = 0.1883\n",
            "t = 25, avg_loss = 0.1618\n",
            "Checking accuracy on train set\n",
            "Got 337 / 400 correct (84.25)\n",
            "acc = 0.842500\n",
            "Starting epoch 72 / 80\n",
            "t = 5, avg_loss = 0.1786\n",
            "t = 10, avg_loss = 0.2124\n",
            "t = 15, avg_loss = 0.1914\n",
            "t = 20, avg_loss = 0.1930\n",
            "t = 25, avg_loss = 0.2058\n",
            "Checking accuracy on train set\n",
            "Got 313 / 400 correct (78.25)\n",
            "acc = 0.782500\n",
            "Starting epoch 73 / 80\n",
            "t = 5, avg_loss = 0.1658\n",
            "t = 10, avg_loss = 0.1982\n",
            "t = 15, avg_loss = 0.1707\n",
            "t = 20, avg_loss = 0.1687\n",
            "t = 25, avg_loss = 0.1697\n",
            "Checking accuracy on train set\n",
            "Got 334 / 400 correct (83.50)\n",
            "acc = 0.835000\n",
            "Starting epoch 74 / 80\n",
            "t = 5, avg_loss = 0.1753\n",
            "t = 10, avg_loss = 0.1786\n",
            "t = 15, avg_loss = 0.1762\n",
            "t = 20, avg_loss = 0.1510\n",
            "t = 25, avg_loss = 0.1754\n",
            "Checking accuracy on train set\n",
            "Got 331 / 400 correct (82.75)\n",
            "acc = 0.827500\n",
            "Starting epoch 75 / 80\n",
            "t = 5, avg_loss = 0.1540\n",
            "t = 10, avg_loss = 0.1611\n",
            "t = 15, avg_loss = 0.2048\n",
            "t = 20, avg_loss = 0.1783\n",
            "t = 25, avg_loss = 0.1576\n",
            "Checking accuracy on train set\n",
            "Got 322 / 400 correct (80.50)\n",
            "acc = 0.805000\n",
            "Starting epoch 76 / 80\n",
            "t = 5, avg_loss = 0.1591\n",
            "t = 10, avg_loss = 0.1668\n",
            "t = 15, avg_loss = 0.1835\n",
            "t = 20, avg_loss = 0.2112\n",
            "t = 25, avg_loss = 0.1806\n",
            "Checking accuracy on train set\n",
            "Got 327 / 400 correct (81.75)\n",
            "acc = 0.817500\n",
            "Starting epoch 77 / 80\n",
            "t = 5, avg_loss = 0.1549\n",
            "t = 10, avg_loss = 0.1676\n",
            "t = 15, avg_loss = 0.1720\n",
            "t = 20, avg_loss = 0.1741\n",
            "t = 25, avg_loss = 0.1754\n",
            "Checking accuracy on train set\n",
            "Got 327 / 400 correct (81.75)\n",
            "acc = 0.817500\n",
            "Starting epoch 78 / 80\n",
            "t = 5, avg_loss = 0.1802\n",
            "t = 10, avg_loss = 0.1500\n",
            "t = 15, avg_loss = 0.1465\n",
            "t = 20, avg_loss = 0.1633\n",
            "t = 25, avg_loss = 0.1713\n",
            "Checking accuracy on train set\n",
            "Got 331 / 400 correct (82.75)\n",
            "acc = 0.827500\n",
            "Starting epoch 79 / 80\n",
            "t = 5, avg_loss = 0.1693\n",
            "t = 10, avg_loss = 0.1955\n",
            "t = 15, avg_loss = 0.1592\n",
            "t = 20, avg_loss = 0.1515\n",
            "t = 25, avg_loss = 0.1902\n",
            "Checking accuracy on train set\n",
            "Got 323 / 400 correct (80.75)\n",
            "acc = 0.807500\n",
            "Starting epoch 80 / 80\n",
            "t = 5, avg_loss = 0.1957\n",
            "t = 10, avg_loss = 0.1809\n",
            "t = 15, avg_loss = 0.1693\n",
            "t = 20, avg_loss = 0.1715\n",
            "t = 25, avg_loss = 0.1685\n",
            "Checking accuracy on train set\n",
            "Got 319 / 400 correct (79.75)\n",
            "acc = 0.797500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "US4sjopDuPdh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "766b3b0c-a169-4d76-bdf9-f1e690c8febb"
      },
      "source": [
        "check_accuracy(model_gpu, test_loader, datatype='test')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking accuracy on test set\n",
            "Got 162 / 201 correct (80.60)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8059701492537313"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvoCj5uscUsz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_accurancy(acc_list):\n",
        "  plt.plot([i+1 for i in range((len(acc_list)))],acc_list)\n",
        "  print(\"Accurancy:\")\n",
        "  plt.show()\n",
        "\n",
        "def plot_loss_function(avg_loss_list):\n",
        "  plt.plot([print_every*batch_size*(i+1) for i in range((len(avg_loss_list)))],avg_loss_list)\n",
        "  print(\"Loss:\")\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-Co5KBw-Yy4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plot_accurancy(acc_list)\n",
        "#plot_loss_function(avg_loss_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzuX5gLEeJfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def retry_from_backup():\n",
        "  model_gpu = model_base.type(gpu_dtype)\n",
        "  print(model_gpu)\n",
        "  loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) \n",
        "\n",
        "  checkpoint = torch.load(model_backup_path)\n",
        "  model_gpu.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  epoch = checkpoint['epoch']\n",
        "  loss = checkpoint['loss']\n",
        "  acc_list = checkpoint['acc_list']\n",
        "  #avg_loss_list = checkpoint['avg_loss_list']\n",
        "  print(\"starting from epoch: \" + str(epoch))\n",
        "  print(\"starting from loss: \" + str(loss))\n",
        "  print(acc_list)\n",
        "  \n",
        "  \n",
        "  train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=20, starting_from_epoch=epoch)\n",
        "  check_accuracy(model_gpu, valid_loader)\n",
        "\n",
        "  plot_accurancy(acc_list)\n",
        "  plot_loss_function(avg_loss_list)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--rQZKqOalaJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aee2e055-98e2-4283-b003-7fd363e9227b"
      },
      "source": [
        "retry_from_backup()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Kerv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (4): ReLU(inplace=True)\n",
            "  (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (7): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (8): ReLU(inplace=True)\n",
            "  (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (11): Dropout(p=0.5, inplace=False)\n",
            "  (12): Flatten()\n",
            "  (13): Linear(in_features=9216, out_features=64, bias=True)\n",
            "  (14): Dropout(p=0.05, inplace=False)\n",
            "  (15): ReLU(inplace=True)\n",
            "  (16): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n",
            "starting from epoch: 79\n",
            "starting from loss: tensor(0.1134, device='cuda:0', requires_grad=True)\n",
            "[0.5075, 0.6675, 0.725, 0.77, 0.745, 0.8075, 0.77, 0.7825, 0.825, 0.7725, 0.7925, 0.8275, 0.82, 0.77, 0.8125, 0.7775, 0.8175, 0.7525, 0.775, 0.82, 0.795, 0.8075, 0.7775, 0.805, 0.83, 0.82, 0.8225, 0.815, 0.8025, 0.82, 0.825, 0.8025, 0.8275, 0.7975, 0.8125, 0.7975, 0.8025, 0.82, 0.805, 0.835, 0.8075, 0.7875, 0.805, 0.7825, 0.8025, 0.835, 0.8325, 0.815, 0.8275, 0.8075, 0.84, 0.7875, 0.8, 0.8125, 0.825, 0.82, 0.815, 0.8275, 0.83, 0.825, 0.82, 0.81, 0.8325, 0.8125, 0.8425, 0.8225, 0.82, 0.845, 0.8025, 0.85, 0.8425, 0.7825, 0.835, 0.8275, 0.805, 0.8175, 0.8175, 0.8275, 0.8075, 0.7975]\n",
            "Starting epoch 1 / 20\n",
            "t = 5, avg_loss = 0.1658\n",
            "t = 10, avg_loss = 0.1599\n",
            "t = 15, avg_loss = 0.1670\n",
            "t = 20, avg_loss = 0.1189\n",
            "t = 25, avg_loss = 0.2089\n",
            "Checking accuracy on train set\n",
            "Got 319 / 400 correct (79.75)\n",
            "acc = 0.797500\n",
            "Starting epoch 2 / 20\n",
            "t = 5, avg_loss = 0.1484\n",
            "t = 10, avg_loss = 0.1465\n",
            "t = 15, avg_loss = 0.1598\n",
            "t = 20, avg_loss = 0.1543\n",
            "t = 25, avg_loss = 0.1537\n",
            "Checking accuracy on train set\n",
            "Got 318 / 400 correct (79.50)\n",
            "acc = 0.795000\n",
            "Starting epoch 3 / 20\n",
            "t = 5, avg_loss = 0.1438\n",
            "t = 10, avg_loss = 0.1568\n",
            "t = 15, avg_loss = 0.1420\n",
            "t = 20, avg_loss = 0.1630\n",
            "t = 25, avg_loss = 0.1672\n",
            "Checking accuracy on train set\n",
            "Got 330 / 400 correct (82.50)\n",
            "acc = 0.825000\n",
            "Starting epoch 4 / 20\n",
            "t = 5, avg_loss = 0.1494\n",
            "t = 10, avg_loss = 0.1602\n",
            "t = 15, avg_loss = 0.1623\n",
            "t = 20, avg_loss = 0.1611\n",
            "t = 25, avg_loss = 0.1915\n",
            "Checking accuracy on train set\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-bc0ed074296d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mretry_from_backup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-3c10dff3369b>\u001b[0m in \u001b[0;36mretry_from_backup\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarting_from_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m   \u001b[0mcheck_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-49ca391291dc>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, loss_fn, optimizer, num_epochs, starting_from_epoch)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'acc = %f'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         torch.save({\n",
            "\u001b[0;32m<ipython-input-7-49ca391291dc>\u001b[0m in \u001b[0;36mcheck_accuracy\u001b[0;34m(model, loader, datatype)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mx_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-c34cad82a6d6>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m           \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"malignant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"malignant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   1856\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1858\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreducing_gap\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresample\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mNEAREST\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjJMcsW6PVLP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqAon2NL_qG2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "outputId": "36382b6f-c231-4926-efd7-b22f5527dc60"
      },
      "source": [
        "plot_accurancy(acc_list)\n",
        "plot_loss_function(avg_loss_list)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accurancy:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhLioSYJy-zW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "5404ff78-2194-4f46-c80b-8bc4c6b75aae"
      },
      "source": [
        "check_accuracy(model_gpu, test_loader, datatype='test')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking accuracy on test set\n",
            "Got 171 / 201 correct (85.07)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8507462686567164"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEiSqj1sGQue",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "57b46982-2a91-420c-f091-120afb2953a8"
      },
      "source": [
        "print(acc_list)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.5075, 0.6675, 0.725, 0.77, 0.745, 0.8075, 0.77, 0.7825, 0.825, 0.7725, 0.7925, 0.8275, 0.82, 0.77, 0.8125, 0.7775, 0.8175, 0.7525, 0.775, 0.82, 0.795, 0.8075, 0.7775, 0.805, 0.83, 0.82, 0.8225, 0.815, 0.8025, 0.82, 0.825, 0.8025, 0.8275, 0.7975, 0.8125, 0.7975, 0.8025, 0.82, 0.805, 0.835, 0.8075, 0.7875, 0.805, 0.7825, 0.8025, 0.835, 0.8325, 0.815, 0.8275, 0.8075, 0.84, 0.7875, 0.8, 0.8125, 0.825, 0.82, 0.815, 0.8275, 0.83, 0.825, 0.82, 0.81, 0.8325, 0.8125, 0.8425, 0.8225, 0.82, 0.845, 0.8025, 0.85, 0.8425, 0.7825, 0.835, 0.8275, 0.805, 0.8175, 0.8175, 0.8275, 0.8075, 0.7975, 0.7975, 0.795, 0.825]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05ssUmnTTbMK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oMMj0Y9xAaa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}