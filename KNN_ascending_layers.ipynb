{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN_ascending_layers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMucDhR2o/Jbu6+XZjQHViy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamilo116/KNN/blob/master/KNN_ascending_layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7ReM7FU-xs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import sys\n",
        "from random import shuffle\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "import timeit\n",
        "\n",
        "np.random.seed(4) \n",
        "torch.manual_seed(4) \n",
        "torch.cuda.manual_seed(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMOHez_kHZD6",
        "colab_type": "code",
        "outputId": "3909b62e-c247-429e-9155-be9a9d92bc56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYIMZ8QyYewD",
        "colab_type": "code",
        "outputId": "ef22d945-a927-46fe-b9fb-5b617931d352",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "! git clone https://github.com/wang-chen/kervolution.git \n",
        "\n",
        "sys.path.append(\"kervolution/\")\n",
        "from kervolution import Kerv2d\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'kervolution' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b8P1NdXfVdX",
        "colab_type": "code",
        "outputId": "e4e2d0e1-694b-4571-8910-a5bf366694ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "MALIGNANT_DATASET = '/content/drive/My Drive/Colab_data/malignant/malignant/'\n",
        "BENIGN_DATASET = '/content/drive/My Drive/Colab_data/benign/benign/'\n",
        "DATA_FOLDER = '/content/drive/My Drive/Colab_data/'\n",
        "LIMIT_IMAGES_NUM = 600\n",
        "\n",
        "benign_file_list = sorted(os.listdir(BENIGN_DATASET))[:LIMIT_IMAGES_NUM]\n",
        "malignant_file_list = sorted(os.listdir(MALIGNANT_DATASET))[:LIMIT_IMAGES_NUM]\n",
        "shuffle(benign_file_list)\n",
        "shuffle(malignant_file_list)\n",
        "\n",
        "print(f\"Number of benign {len(benign_file_list)} images\")\n",
        "print(f\"Number of malignant {len(malignant_file_list)} images\")\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize((100, 100)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of benign 600 images\n",
            "Number of malignant 600 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGDQfal74BLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "benign_dict = {filename: 0 for filename in benign_file_list}\n",
        "malignant_dict = {filename: 1 for filename in malignant_file_list}\n",
        "img_class_dict = {**benign_dict , **malignant_dict}\n",
        "labeled_data = pd.Series(img_class_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvAAOqmVfVll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IsicDataset(Dataset):\n",
        "    def __init__(self, data_folder, labeled_data, \n",
        "                 transform=transforms.Compose([transforms.ToTensor()])):\n",
        "        self.labeled_data = labeled_data\n",
        "        self.transform = transform\n",
        "        self.data_folder = data_folder\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labeled_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        label = self.labeled_data[index]\n",
        "        if label == 0:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"benign\", \"benign\", index ))\n",
        "        else:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"malignant\", \"malignant\", index ))\n",
        "        image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "    @property\n",
        "    def labels(self):\n",
        "      return self.labeled_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSuYqjLAYrWA",
        "colab_type": "code",
        "outputId": "2c35d438-d3aa-459e-b0ef-e2de479241a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        }
      },
      "source": [
        " \n",
        "dataset = IsicDataset(DATA_FOLDER, labeled_data, transform=data_transforms)\n",
        "print(dataset.labels)\n",
        "\n",
        "X_train, X_test = train_test_split(dataset.labels, test_size=0.2)\n",
        "print(\"number of training data: \",len(X_train))\n",
        "print(\"number of testing  data: \",len(X_test))\n",
        "\n",
        "train_sampler = SubsetRandomSampler(list(X_train.index))\n",
        "valid_sampler = SubsetRandomSampler(list(X_test.index))\n",
        "batch_size = 64\n",
        "num_workers = 0\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ISIC_0000829.jpeg    0\n",
            "ISIC_0000062.jpeg    0\n",
            "ISIC_0000343.jpeg    0\n",
            "ISIC_0000740.jpeg    0\n",
            "ISIC_0000060.jpeg    0\n",
            "                    ..\n",
            "ISIC_0010210.jpeg    1\n",
            "ISIC_0010407.jpeg    1\n",
            "ISIC_0000412.jpeg    1\n",
            "ISIC_0001157.jpeg    1\n",
            "ISIC_0010181.jpeg    1\n",
            "Length: 1200, dtype: int64\n",
            "number of training data:  960\n",
            "number of testing  data:  240\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e8nFBR6Yug5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "def train(model, train_loader ,loss_fn, optimizer, num_epochs = 1):\n",
        "    total_loss =0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
        "        model.train()\n",
        "\n",
        "        for t, (x, y) in enumerate(train_loader):\n",
        "            x_var = Variable(x.type(gpu_dtype))\n",
        "            y_var = Variable(y.type(gpu_dtype).long())\n",
        "            scores = model(x_var)\n",
        "            loss = loss_fn(scores, y_var)\n",
        "            total_loss += loss.data\n",
        "            \n",
        "            if (t + 1) % print_every == 0:\n",
        "                avg_loss = total_loss/print_every\n",
        "                print('t = %d, avg_loss = %.4f' % (t + 1, avg_loss) )\n",
        "                avg_loss_list.append(avg_loss)\n",
        "                total_loss = 0\n",
        "                \n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        acc = check_accuracy(fixed_model_gpu, valid_loader)\n",
        "        print('acc = %f' %(acc))\n",
        "            \n",
        "def check_accuracy(model, loader):\n",
        "    print('Checking accuracy on test set')   \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval() \n",
        "    for x, y in loader:\n",
        "        x_var = Variable(x.type(gpu_dtype))\n",
        "\n",
        "        scores = model(x_var)\n",
        "        _, preds = scores.data.cpu().max(1)\n",
        "        num_correct += (preds == y).sum()\n",
        "        num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    acc_list.append(acc)\n",
        "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "    return acc\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggvpMu36Yw2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.size()\n",
        "        return x.view(N, -1)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgmexhBRZAK6",
        "colab_type": "code",
        "outputId": "7160d8f9-9d59-44eb-abb1-7168bbf4f1e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "\n",
        "print_every = 1\n",
        "gpu_dtype = torch.cuda.FloatTensor\n",
        "\n",
        "out_1 = 32\n",
        "out_2 = 64\n",
        "out_3 = 128\n",
        "#out_4 = 256\n",
        "\n",
        "\n",
        "k_size_1 = 3\n",
        "padding_1 = 1\n",
        "in_channels = 3\n",
        "\n",
        "num_epochs = 50\n",
        "\n",
        "'''\n",
        "Kerv2d\n",
        "kervolution with following options:\n",
        "kernel_type: [linear, polynomial, gaussian, etc.]\n",
        "default is convolution:\n",
        "          kernel_type --> linear,\n",
        "balance, power, gamma is valid only when the kernel_type is specified\n",
        "if learnable_kernel = True,  they just be the initial value of learable parameters\n",
        "if learnable_kernel = False, they are the value of kernel_type's parameter\n",
        "the parameter [power] cannot be learned due to integer limitation\n",
        "dilation (int or tuple, optional): Spacing between kernel\n",
        "elements. Default: 1\n",
        "groups (int, optional): Number of blocked connections from input\n",
        "channels to output channels. Default: 1\n",
        "bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n",
        "kernel_type (str), Default: 'linear'\n",
        "learnable_kernel (bool): Learnable kernel parameters.  Default: False \n",
        "balance: 0, 1\n",
        "power: 3, 4, 5\n",
        "gamma:\n",
        "'''\n",
        "\n",
        "\n",
        "fixed_model_base = nn.Sequential( \n",
        "                nn.Kerv2d(in_channels , out_1, padding=padding_1, dilation=1, groups=1, bias=True, \n",
        "                          kernel_type='polynomial', kernel_size=k_size_1, learnable_kernel=True,\n",
        "                          kernel_regularizer=True, stride=1, balance=0, power=3, gamma=1), \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_1),\n",
        "                nn.Conv2d(out_1 , out_2, padding= padding_1, kernel_size=k_size_1, stride=1), \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_2),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_2 , out_3, padding= padding_1, kernel_size=k_size_1, stride=1),  \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_3),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Dropout(0.5),\n",
        "                Flatten(),\n",
        "                nn.Linear(80000,64),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Linear(64,2)\n",
        "            )\n",
        "fixed_model_gpu = fixed_model_base.type(gpu_dtype)\n",
        "print(fixed_model_gpu)\n",
        "loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(fixed_model_gpu.parameters(), lr = 0.00012, weight_decay=0) \n",
        "\n",
        "train(fixed_model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs)\n",
        "check_accuracy(fixed_model_gpu, valid_loader)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Kerv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (4): ReLU(inplace=True)\n",
            "  (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (8): ReLU(inplace=True)\n",
            "  (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (11): Dropout(p=0.5, inplace=False)\n",
            "  (12): Flatten()\n",
            "  (13): Linear(in_features=80000, out_features=64, bias=True)\n",
            "  (14): ReLU(inplace=True)\n",
            "  (15): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n",
            "Starting epoch 1 / 50\n",
            "t = 1, avg_loss = 0.6979\n",
            "t = 2, avg_loss = 1.0131\n",
            "t = 3, avg_loss = 1.2478\n",
            "t = 4, avg_loss = 1.2466\n",
            "t = 5, avg_loss = 0.8428\n",
            "t = 6, avg_loss = 0.7805\n",
            "t = 7, avg_loss = 0.5116\n",
            "t = 8, avg_loss = 0.7127\n",
            "t = 9, avg_loss = 0.7174\n",
            "t = 10, avg_loss = 0.5728\n",
            "t = 11, avg_loss = 0.4730\n",
            "t = 12, avg_loss = 0.5330\n",
            "t = 13, avg_loss = 0.5365\n",
            "t = 14, avg_loss = 0.4274\n",
            "t = 15, avg_loss = 0.4657\n",
            "Checking accuracy on test set\n",
            "Got 118 / 240 correct (49.17)\n",
            "acc = 0.491667\n",
            "Starting epoch 2 / 50\n",
            "t = 1, avg_loss = 0.5399\n",
            "t = 2, avg_loss = 0.4083\n",
            "t = 3, avg_loss = 0.5307\n",
            "t = 4, avg_loss = 0.4282\n",
            "t = 5, avg_loss = 0.5351\n",
            "t = 6, avg_loss = 0.4449\n",
            "t = 7, avg_loss = 0.3733\n",
            "t = 8, avg_loss = 0.3706\n",
            "t = 9, avg_loss = 0.4145\n",
            "t = 10, avg_loss = 0.3181\n",
            "t = 11, avg_loss = 0.4884\n",
            "t = 12, avg_loss = 0.5124\n",
            "t = 13, avg_loss = 0.4037\n",
            "t = 14, avg_loss = 0.4247\n",
            "t = 15, avg_loss = 0.4001\n",
            "Checking accuracy on test set\n",
            "Got 123 / 240 correct (51.25)\n",
            "acc = 0.512500\n",
            "Starting epoch 3 / 50\n",
            "t = 1, avg_loss = 0.3246\n",
            "t = 2, avg_loss = 0.4253\n",
            "t = 3, avg_loss = 0.3405\n",
            "t = 4, avg_loss = 0.4722\n",
            "t = 5, avg_loss = 0.2965\n",
            "t = 6, avg_loss = 0.4885\n",
            "t = 7, avg_loss = 0.5428\n",
            "t = 8, avg_loss = 0.3213\n",
            "t = 9, avg_loss = 0.3423\n",
            "t = 10, avg_loss = 0.4060\n",
            "t = 11, avg_loss = 0.3072\n",
            "t = 12, avg_loss = 0.2396\n",
            "t = 13, avg_loss = 0.3780\n",
            "t = 14, avg_loss = 0.4349\n",
            "t = 15, avg_loss = 0.3963\n",
            "Checking accuracy on test set\n",
            "Got 133 / 240 correct (55.42)\n",
            "acc = 0.554167\n",
            "Starting epoch 4 / 50\n",
            "t = 1, avg_loss = 0.3072\n",
            "t = 2, avg_loss = 0.2245\n",
            "t = 3, avg_loss = 0.2958\n",
            "t = 4, avg_loss = 0.3139\n",
            "t = 5, avg_loss = 0.2828\n",
            "t = 6, avg_loss = 0.2017\n",
            "t = 7, avg_loss = 0.2878\n",
            "t = 8, avg_loss = 0.4565\n",
            "t = 9, avg_loss = 0.4167\n",
            "t = 10, avg_loss = 0.3221\n",
            "t = 11, avg_loss = 0.3255\n",
            "t = 12, avg_loss = 0.3852\n",
            "t = 13, avg_loss = 0.3160\n",
            "t = 14, avg_loss = 0.2942\n",
            "t = 15, avg_loss = 0.3163\n",
            "Checking accuracy on test set\n",
            "Got 152 / 240 correct (63.33)\n",
            "acc = 0.633333\n",
            "Starting epoch 5 / 50\n",
            "t = 1, avg_loss = 0.3010\n",
            "t = 2, avg_loss = 0.2948\n",
            "t = 3, avg_loss = 0.2669\n",
            "t = 4, avg_loss = 0.2836\n",
            "t = 5, avg_loss = 0.2577\n",
            "t = 6, avg_loss = 0.2771\n",
            "t = 7, avg_loss = 0.3913\n",
            "t = 8, avg_loss = 0.2515\n",
            "t = 9, avg_loss = 0.2955\n",
            "t = 10, avg_loss = 0.2379\n",
            "t = 11, avg_loss = 0.2632\n",
            "t = 12, avg_loss = 0.2570\n",
            "t = 13, avg_loss = 0.4419\n",
            "t = 14, avg_loss = 0.3761\n",
            "t = 15, avg_loss = 0.2875\n",
            "Checking accuracy on test set\n",
            "Got 170 / 240 correct (70.83)\n",
            "acc = 0.708333\n",
            "Starting epoch 6 / 50\n",
            "t = 1, avg_loss = 0.2119\n",
            "t = 2, avg_loss = 0.2762\n",
            "t = 3, avg_loss = 0.2047\n",
            "t = 4, avg_loss = 0.2497\n",
            "t = 5, avg_loss = 0.2249\n",
            "t = 6, avg_loss = 0.3276\n",
            "t = 7, avg_loss = 0.2241\n",
            "t = 8, avg_loss = 0.2778\n",
            "t = 9, avg_loss = 0.3342\n",
            "t = 10, avg_loss = 0.2820\n",
            "t = 11, avg_loss = 0.2235\n",
            "t = 12, avg_loss = 0.2738\n",
            "t = 13, avg_loss = 0.2060\n",
            "t = 14, avg_loss = 0.4066\n",
            "t = 15, avg_loss = 0.2714\n",
            "Checking accuracy on test set\n",
            "Got 183 / 240 correct (76.25)\n",
            "acc = 0.762500\n",
            "Starting epoch 7 / 50\n",
            "t = 1, avg_loss = 0.2099\n",
            "t = 2, avg_loss = 0.2609\n",
            "t = 3, avg_loss = 0.2898\n",
            "t = 4, avg_loss = 0.3064\n",
            "t = 5, avg_loss = 0.3734\n",
            "t = 6, avg_loss = 0.2094\n",
            "t = 7, avg_loss = 0.2321\n",
            "t = 8, avg_loss = 0.3389\n",
            "t = 9, avg_loss = 0.2342\n",
            "t = 10, avg_loss = 0.4355\n",
            "t = 11, avg_loss = 0.2491\n",
            "t = 12, avg_loss = 0.1792\n",
            "t = 13, avg_loss = 0.2923\n",
            "t = 14, avg_loss = 0.2069\n",
            "t = 15, avg_loss = 0.1506\n",
            "Checking accuracy on test set\n",
            "Got 197 / 240 correct (82.08)\n",
            "acc = 0.820833\n",
            "Starting epoch 8 / 50\n",
            "t = 1, avg_loss = 0.1973\n",
            "t = 2, avg_loss = 0.1499\n",
            "t = 3, avg_loss = 0.2396\n",
            "t = 4, avg_loss = 0.2336\n",
            "t = 5, avg_loss = 0.2358\n",
            "t = 6, avg_loss = 0.2639\n",
            "t = 7, avg_loss = 0.1632\n",
            "t = 8, avg_loss = 0.2299\n",
            "t = 9, avg_loss = 0.2363\n",
            "t = 10, avg_loss = 0.3075\n",
            "t = 11, avg_loss = 0.1867\n",
            "t = 12, avg_loss = 0.2600\n",
            "t = 13, avg_loss = 0.1820\n",
            "t = 14, avg_loss = 0.2012\n",
            "t = 15, avg_loss = 0.2250\n",
            "Checking accuracy on test set\n",
            "Got 199 / 240 correct (82.92)\n",
            "acc = 0.829167\n",
            "Starting epoch 9 / 50\n",
            "t = 1, avg_loss = 0.1836\n",
            "t = 2, avg_loss = 0.2012\n",
            "t = 3, avg_loss = 0.2750\n",
            "t = 4, avg_loss = 0.1676\n",
            "t = 5, avg_loss = 0.1920\n",
            "t = 6, avg_loss = 0.2945\n",
            "t = 7, avg_loss = 0.2552\n",
            "t = 8, avg_loss = 0.3606\n",
            "t = 9, avg_loss = 0.2191\n",
            "t = 10, avg_loss = 0.2465\n",
            "t = 11, avg_loss = 0.2544\n",
            "t = 12, avg_loss = 0.2990\n",
            "t = 13, avg_loss = 0.2341\n",
            "t = 14, avg_loss = 0.1161\n",
            "t = 15, avg_loss = 0.2120\n",
            "Checking accuracy on test set\n",
            "Got 189 / 240 correct (78.75)\n",
            "acc = 0.787500\n",
            "Starting epoch 10 / 50\n",
            "t = 1, avg_loss = 0.1690\n",
            "t = 2, avg_loss = 0.1971\n",
            "t = 3, avg_loss = 0.1868\n",
            "t = 4, avg_loss = 0.3214\n",
            "t = 5, avg_loss = 0.1935\n",
            "t = 6, avg_loss = 0.1281\n",
            "t = 7, avg_loss = 0.1157\n",
            "t = 8, avg_loss = 0.2208\n",
            "t = 9, avg_loss = 0.2109\n",
            "t = 10, avg_loss = 0.2924\n",
            "t = 11, avg_loss = 0.1603\n",
            "t = 12, avg_loss = 0.2996\n",
            "t = 13, avg_loss = 0.2018\n",
            "t = 14, avg_loss = 0.0964\n",
            "t = 15, avg_loss = 0.2786\n",
            "Checking accuracy on test set\n",
            "Got 197 / 240 correct (82.08)\n",
            "acc = 0.820833\n",
            "Starting epoch 11 / 50\n",
            "t = 1, avg_loss = 0.2154\n",
            "t = 2, avg_loss = 0.2514\n",
            "t = 3, avg_loss = 0.2041\n",
            "t = 4, avg_loss = 0.2286\n",
            "t = 5, avg_loss = 0.1088\n",
            "t = 6, avg_loss = 0.1868\n",
            "t = 7, avg_loss = 0.1000\n",
            "t = 8, avg_loss = 0.2531\n",
            "t = 9, avg_loss = 0.2864\n",
            "t = 10, avg_loss = 0.1723\n",
            "t = 11, avg_loss = 0.1692\n",
            "t = 12, avg_loss = 0.0945\n",
            "t = 13, avg_loss = 0.2241\n",
            "t = 14, avg_loss = 0.1430\n",
            "t = 15, avg_loss = 0.1722\n",
            "Checking accuracy on test set\n",
            "Got 195 / 240 correct (81.25)\n",
            "acc = 0.812500\n",
            "Starting epoch 12 / 50\n",
            "t = 1, avg_loss = 0.2132\n",
            "t = 2, avg_loss = 0.2076\n",
            "t = 3, avg_loss = 0.1349\n",
            "t = 4, avg_loss = 0.1091\n",
            "t = 5, avg_loss = 0.2385\n",
            "t = 6, avg_loss = 0.1702\n",
            "t = 7, avg_loss = 0.1199\n",
            "t = 8, avg_loss = 0.1690\n",
            "t = 9, avg_loss = 0.1153\n",
            "t = 10, avg_loss = 0.1524\n",
            "t = 11, avg_loss = 0.1264\n",
            "t = 12, avg_loss = 0.2035\n",
            "t = 13, avg_loss = 0.1878\n",
            "t = 14, avg_loss = 0.2385\n",
            "t = 15, avg_loss = 0.1579\n",
            "Checking accuracy on test set\n",
            "Got 197 / 240 correct (82.08)\n",
            "acc = 0.820833\n",
            "Starting epoch 13 / 50\n",
            "t = 1, avg_loss = 0.2028\n",
            "t = 2, avg_loss = 0.1048\n",
            "t = 3, avg_loss = 0.2091\n",
            "t = 4, avg_loss = 0.1672\n",
            "t = 5, avg_loss = 0.1261\n",
            "t = 6, avg_loss = 0.1825\n",
            "t = 7, avg_loss = 0.1129\n",
            "t = 8, avg_loss = 0.1364\n",
            "t = 9, avg_loss = 0.1722\n",
            "t = 10, avg_loss = 0.1378\n",
            "t = 11, avg_loss = 0.1657\n",
            "t = 12, avg_loss = 0.1789\n",
            "t = 13, avg_loss = 0.1515\n",
            "t = 14, avg_loss = 0.1965\n",
            "t = 15, avg_loss = 0.1235\n",
            "Checking accuracy on test set\n",
            "Got 194 / 240 correct (80.83)\n",
            "acc = 0.808333\n",
            "Starting epoch 14 / 50\n",
            "t = 1, avg_loss = 0.1417\n",
            "t = 2, avg_loss = 0.0662\n",
            "t = 3, avg_loss = 0.1374\n",
            "t = 4, avg_loss = 0.2131\n",
            "t = 5, avg_loss = 0.1519\n",
            "t = 6, avg_loss = 0.2649\n",
            "t = 7, avg_loss = 0.1315\n",
            "t = 8, avg_loss = 0.1587\n",
            "t = 9, avg_loss = 0.0459\n",
            "t = 10, avg_loss = 0.0965\n",
            "t = 11, avg_loss = 0.1753\n",
            "t = 12, avg_loss = 0.1867\n",
            "t = 13, avg_loss = 0.1571\n",
            "t = 14, avg_loss = 0.1454\n",
            "t = 15, avg_loss = 0.0874\n",
            "Checking accuracy on test set\n",
            "Got 200 / 240 correct (83.33)\n",
            "acc = 0.833333\n",
            "Starting epoch 15 / 50\n",
            "t = 1, avg_loss = 0.1905\n",
            "t = 2, avg_loss = 0.0861\n",
            "t = 3, avg_loss = 0.1511\n",
            "t = 4, avg_loss = 0.2027\n",
            "t = 5, avg_loss = 0.1187\n",
            "t = 6, avg_loss = 0.0834\n",
            "t = 7, avg_loss = 0.1596\n",
            "t = 8, avg_loss = 0.0925\n",
            "t = 9, avg_loss = 0.0857\n",
            "t = 10, avg_loss = 0.0764\n",
            "t = 11, avg_loss = 0.1476\n",
            "t = 12, avg_loss = 0.0904\n",
            "t = 13, avg_loss = 0.2086\n",
            "t = 14, avg_loss = 0.1125\n",
            "t = 15, avg_loss = 0.1581\n",
            "Checking accuracy on test set\n",
            "Got 199 / 240 correct (82.92)\n",
            "acc = 0.829167\n",
            "Starting epoch 16 / 50\n",
            "t = 1, avg_loss = 0.0962\n",
            "t = 2, avg_loss = 0.1615\n",
            "t = 3, avg_loss = 0.1151\n",
            "t = 4, avg_loss = 0.0587\n",
            "t = 5, avg_loss = 0.1124\n",
            "t = 6, avg_loss = 0.1878\n",
            "t = 7, avg_loss = 0.0709\n",
            "t = 8, avg_loss = 0.0679\n",
            "t = 9, avg_loss = 0.1237\n",
            "t = 10, avg_loss = 0.1305\n",
            "t = 11, avg_loss = 0.0690\n",
            "t = 12, avg_loss = 0.1683\n",
            "t = 13, avg_loss = 0.1299\n",
            "t = 14, avg_loss = 0.1288\n",
            "t = 15, avg_loss = 0.0733\n",
            "Checking accuracy on test set\n",
            "Got 196 / 240 correct (81.67)\n",
            "acc = 0.816667\n",
            "Starting epoch 17 / 50\n",
            "t = 1, avg_loss = 0.1030\n",
            "t = 2, avg_loss = 0.0994\n",
            "t = 3, avg_loss = 0.0808\n",
            "t = 4, avg_loss = 0.1126\n",
            "t = 5, avg_loss = 0.0770\n",
            "t = 6, avg_loss = 0.1441\n",
            "t = 7, avg_loss = 0.1041\n",
            "t = 8, avg_loss = 0.1713\n",
            "t = 9, avg_loss = 0.1109\n",
            "t = 10, avg_loss = 0.2425\n",
            "t = 11, avg_loss = 0.0707\n",
            "t = 12, avg_loss = 0.1490\n",
            "t = 13, avg_loss = 0.0931\n",
            "t = 14, avg_loss = 0.0903\n",
            "t = 15, avg_loss = 0.1211\n",
            "Checking accuracy on test set\n",
            "Got 198 / 240 correct (82.50)\n",
            "acc = 0.825000\n",
            "Starting epoch 18 / 50\n",
            "t = 1, avg_loss = 0.1128\n",
            "t = 2, avg_loss = 0.0715\n",
            "t = 3, avg_loss = 0.1025\n",
            "t = 4, avg_loss = 0.1424\n",
            "t = 5, avg_loss = 0.1146\n",
            "t = 6, avg_loss = 0.1024\n",
            "t = 7, avg_loss = 0.1218\n",
            "t = 8, avg_loss = 0.0436\n",
            "t = 9, avg_loss = 0.0843\n",
            "t = 10, avg_loss = 0.0395\n",
            "t = 11, avg_loss = 0.1018\n",
            "t = 12, avg_loss = 0.1248\n",
            "t = 13, avg_loss = 0.0920\n",
            "t = 14, avg_loss = 0.0546\n",
            "t = 15, avg_loss = 0.1866\n",
            "Checking accuracy on test set\n",
            "Got 204 / 240 correct (85.00)\n",
            "acc = 0.850000\n",
            "Starting epoch 19 / 50\n",
            "t = 1, avg_loss = 0.0949\n",
            "t = 2, avg_loss = 0.0618\n",
            "t = 3, avg_loss = 0.0912\n",
            "t = 4, avg_loss = 0.1015\n",
            "t = 5, avg_loss = 0.0481\n",
            "t = 6, avg_loss = 0.0782\n",
            "t = 7, avg_loss = 0.0715\n",
            "t = 8, avg_loss = 0.1266\n",
            "t = 9, avg_loss = 0.0611\n",
            "t = 10, avg_loss = 0.1527\n",
            "t = 11, avg_loss = 0.0566\n",
            "t = 12, avg_loss = 0.1535\n",
            "t = 13, avg_loss = 0.1367\n",
            "t = 14, avg_loss = 0.0789\n",
            "t = 15, avg_loss = 0.1687\n",
            "Checking accuracy on test set\n",
            "Got 206 / 240 correct (85.83)\n",
            "acc = 0.858333\n",
            "Starting epoch 20 / 50\n",
            "t = 1, avg_loss = 0.0430\n",
            "t = 2, avg_loss = 0.1147\n",
            "t = 3, avg_loss = 0.1462\n",
            "t = 4, avg_loss = 0.0974\n",
            "t = 5, avg_loss = 0.0689\n",
            "t = 6, avg_loss = 0.1092\n",
            "t = 7, avg_loss = 0.0793\n",
            "t = 8, avg_loss = 0.0839\n",
            "t = 9, avg_loss = 0.0776\n",
            "t = 10, avg_loss = 0.0918\n",
            "t = 11, avg_loss = 0.0539\n",
            "t = 12, avg_loss = 0.1119\n",
            "t = 13, avg_loss = 0.1582\n",
            "t = 14, avg_loss = 0.0858\n",
            "t = 15, avg_loss = 0.0780\n",
            "Checking accuracy on test set\n",
            "Got 196 / 240 correct (81.67)\n",
            "acc = 0.816667\n",
            "Starting epoch 21 / 50\n",
            "t = 1, avg_loss = 0.1048\n",
            "t = 2, avg_loss = 0.0626\n",
            "t = 3, avg_loss = 0.0695\n",
            "t = 4, avg_loss = 0.1933\n",
            "t = 5, avg_loss = 0.0713\n",
            "t = 6, avg_loss = 0.1464\n",
            "t = 7, avg_loss = 0.1357\n",
            "t = 8, avg_loss = 0.0859\n",
            "t = 9, avg_loss = 0.0675\n",
            "t = 10, avg_loss = 0.0775\n",
            "t = 11, avg_loss = 0.0418\n",
            "t = 12, avg_loss = 0.0631\n",
            "t = 13, avg_loss = 0.0554\n",
            "t = 14, avg_loss = 0.0626\n",
            "t = 15, avg_loss = 0.1133\n",
            "Checking accuracy on test set\n",
            "Got 195 / 240 correct (81.25)\n",
            "acc = 0.812500\n",
            "Starting epoch 22 / 50\n",
            "t = 1, avg_loss = 0.1203\n",
            "t = 2, avg_loss = 0.1077\n",
            "t = 3, avg_loss = 0.0886\n",
            "t = 4, avg_loss = 0.0776\n",
            "t = 5, avg_loss = 0.0905\n",
            "t = 6, avg_loss = 0.0814\n",
            "t = 7, avg_loss = 0.1109\n",
            "t = 8, avg_loss = 0.1126\n",
            "t = 9, avg_loss = 0.0440\n",
            "t = 10, avg_loss = 0.1249\n",
            "t = 11, avg_loss = 0.0589\n",
            "t = 12, avg_loss = 0.0602\n",
            "t = 13, avg_loss = 0.0932\n",
            "t = 14, avg_loss = 0.1179\n",
            "t = 15, avg_loss = 0.0525\n",
            "Checking accuracy on test set\n",
            "Got 193 / 240 correct (80.42)\n",
            "acc = 0.804167\n",
            "Starting epoch 23 / 50\n",
            "t = 1, avg_loss = 0.0403\n",
            "t = 2, avg_loss = 0.0641\n",
            "t = 3, avg_loss = 0.0641\n",
            "t = 4, avg_loss = 0.0322\n",
            "t = 5, avg_loss = 0.0953\n",
            "t = 6, avg_loss = 0.0381\n",
            "t = 7, avg_loss = 0.0545\n",
            "t = 8, avg_loss = 0.1333\n",
            "t = 9, avg_loss = 0.0921\n",
            "t = 10, avg_loss = 0.0880\n",
            "t = 11, avg_loss = 0.0604\n",
            "t = 12, avg_loss = 0.1290\n",
            "t = 13, avg_loss = 0.0907\n",
            "t = 14, avg_loss = 0.1076\n",
            "t = 15, avg_loss = 0.1174\n",
            "Checking accuracy on test set\n",
            "Got 202 / 240 correct (84.17)\n",
            "acc = 0.841667\n",
            "Starting epoch 24 / 50\n",
            "t = 1, avg_loss = 0.0520\n",
            "t = 2, avg_loss = 0.0748\n",
            "t = 3, avg_loss = 0.1916\n",
            "t = 4, avg_loss = 0.1221\n",
            "t = 5, avg_loss = 0.0546\n",
            "t = 6, avg_loss = 0.0506\n",
            "t = 7, avg_loss = 0.0349\n",
            "t = 8, avg_loss = 0.0459\n",
            "t = 9, avg_loss = 0.0855\n",
            "t = 10, avg_loss = 0.0747\n",
            "t = 11, avg_loss = 0.0601\n",
            "t = 12, avg_loss = 0.0818\n",
            "t = 13, avg_loss = 0.0858\n",
            "t = 14, avg_loss = 0.0979\n",
            "t = 15, avg_loss = 0.0902\n",
            "Checking accuracy on test set\n",
            "Got 197 / 240 correct (82.08)\n",
            "acc = 0.820833\n",
            "Starting epoch 25 / 50\n",
            "t = 1, avg_loss = 0.0452\n",
            "t = 2, avg_loss = 0.0324\n",
            "t = 3, avg_loss = 0.0468\n",
            "t = 4, avg_loss = 0.0232\n",
            "t = 5, avg_loss = 0.1005\n",
            "t = 6, avg_loss = 0.0641\n",
            "t = 7, avg_loss = 0.0932\n",
            "t = 8, avg_loss = 0.0771\n",
            "t = 9, avg_loss = 0.0771\n",
            "t = 10, avg_loss = 0.0392\n",
            "t = 11, avg_loss = 0.0880\n",
            "t = 12, avg_loss = 0.0514\n",
            "t = 13, avg_loss = 0.0999\n",
            "t = 14, avg_loss = 0.0881\n",
            "t = 15, avg_loss = 0.1360\n",
            "Checking accuracy on test set\n",
            "Got 199 / 240 correct (82.92)\n",
            "acc = 0.829167\n",
            "Starting epoch 26 / 50\n",
            "t = 1, avg_loss = 0.0650\n",
            "t = 2, avg_loss = 0.1126\n",
            "t = 3, avg_loss = 0.0635\n",
            "t = 4, avg_loss = 0.0810\n",
            "t = 5, avg_loss = 0.0344\n",
            "t = 6, avg_loss = 0.0370\n",
            "t = 7, avg_loss = 0.0335\n",
            "t = 8, avg_loss = 0.0486\n",
            "t = 9, avg_loss = 0.1041\n",
            "t = 10, avg_loss = 0.0261\n",
            "t = 11, avg_loss = 0.0836\n",
            "t = 12, avg_loss = 0.0234\n",
            "t = 13, avg_loss = 0.0413\n",
            "t = 14, avg_loss = 0.0673\n",
            "t = 15, avg_loss = 0.0543\n",
            "Checking accuracy on test set\n",
            "Got 199 / 240 correct (82.92)\n",
            "acc = 0.829167\n",
            "Starting epoch 27 / 50\n",
            "t = 1, avg_loss = 0.0612\n",
            "t = 2, avg_loss = 0.0687\n",
            "t = 3, avg_loss = 0.0405\n",
            "t = 4, avg_loss = 0.0292\n",
            "t = 5, avg_loss = 0.0759\n",
            "t = 6, avg_loss = 0.0503\n",
            "t = 7, avg_loss = 0.0641\n",
            "t = 8, avg_loss = 0.0735\n",
            "t = 9, avg_loss = 0.0574\n",
            "t = 10, avg_loss = 0.0333\n",
            "t = 11, avg_loss = 0.0197\n",
            "t = 12, avg_loss = 0.0224\n",
            "t = 13, avg_loss = 0.0272\n",
            "t = 14, avg_loss = 0.0537\n",
            "t = 15, avg_loss = 0.0483\n",
            "Checking accuracy on test set\n",
            "Got 198 / 240 correct (82.50)\n",
            "acc = 0.825000\n",
            "Starting epoch 28 / 50\n",
            "t = 1, avg_loss = 0.0493\n",
            "t = 2, avg_loss = 0.0347\n",
            "t = 3, avg_loss = 0.0191\n",
            "t = 4, avg_loss = 0.0597\n",
            "t = 5, avg_loss = 0.0301\n",
            "t = 6, avg_loss = 0.0502\n",
            "t = 7, avg_loss = 0.0497\n",
            "t = 8, avg_loss = 0.0267\n",
            "t = 9, avg_loss = 0.0457\n",
            "t = 10, avg_loss = 0.0277\n",
            "t = 11, avg_loss = 0.0366\n",
            "t = 12, avg_loss = 0.0359\n",
            "t = 13, avg_loss = 0.0413\n",
            "t = 14, avg_loss = 0.0619\n",
            "t = 15, avg_loss = 0.0223\n",
            "Checking accuracy on test set\n",
            "Got 205 / 240 correct (85.42)\n",
            "acc = 0.854167\n",
            "Starting epoch 29 / 50\n",
            "t = 1, avg_loss = 0.0567\n",
            "t = 2, avg_loss = 0.0390\n",
            "t = 3, avg_loss = 0.0395\n",
            "t = 4, avg_loss = 0.0325\n",
            "t = 5, avg_loss = 0.0211\n",
            "t = 6, avg_loss = 0.0458\n",
            "t = 7, avg_loss = 0.0111\n",
            "t = 8, avg_loss = 0.0377\n",
            "t = 9, avg_loss = 0.0654\n",
            "t = 10, avg_loss = 0.0136\n",
            "t = 11, avg_loss = 0.0137\n",
            "t = 12, avg_loss = 0.0641\n",
            "t = 13, avg_loss = 0.0488\n",
            "t = 14, avg_loss = 0.0392\n",
            "t = 15, avg_loss = 0.0367\n",
            "Checking accuracy on test set\n",
            "Got 204 / 240 correct (85.00)\n",
            "acc = 0.850000\n",
            "Starting epoch 30 / 50\n",
            "t = 1, avg_loss = 0.0291\n",
            "t = 2, avg_loss = 0.0498\n",
            "t = 3, avg_loss = 0.0259\n",
            "t = 4, avg_loss = 0.0135\n",
            "t = 5, avg_loss = 0.0135\n",
            "t = 6, avg_loss = 0.0470\n",
            "t = 7, avg_loss = 0.0440\n",
            "t = 8, avg_loss = 0.0467\n",
            "t = 9, avg_loss = 0.0233\n",
            "t = 10, avg_loss = 0.0113\n",
            "t = 11, avg_loss = 0.0263\n",
            "t = 12, avg_loss = 0.0240\n",
            "t = 13, avg_loss = 0.0337\n",
            "t = 14, avg_loss = 0.0394\n",
            "t = 15, avg_loss = 0.1336\n",
            "Checking accuracy on test set\n",
            "Got 201 / 240 correct (83.75)\n",
            "acc = 0.837500\n",
            "Starting epoch 31 / 50\n",
            "t = 1, avg_loss = 0.0070\n",
            "t = 2, avg_loss = 0.0427\n",
            "t = 3, avg_loss = 0.0310\n",
            "t = 4, avg_loss = 0.0389\n",
            "t = 5, avg_loss = 0.0320\n",
            "t = 6, avg_loss = 0.0204\n",
            "t = 7, avg_loss = 0.0349\n",
            "t = 8, avg_loss = 0.0195\n",
            "t = 9, avg_loss = 0.0349\n",
            "t = 10, avg_loss = 0.0122\n",
            "t = 11, avg_loss = 0.0295\n",
            "t = 12, avg_loss = 0.0183\n",
            "t = 13, avg_loss = 0.0294\n",
            "t = 14, avg_loss = 0.0917\n",
            "t = 15, avg_loss = 0.0345\n",
            "Checking accuracy on test set\n",
            "Got 198 / 240 correct (82.50)\n",
            "acc = 0.825000\n",
            "Starting epoch 32 / 50\n",
            "t = 1, avg_loss = 0.0318\n",
            "t = 2, avg_loss = 0.0217\n",
            "t = 3, avg_loss = 0.0203\n",
            "t = 4, avg_loss = 0.0320\n",
            "t = 5, avg_loss = 0.0424\n",
            "t = 6, avg_loss = 0.0853\n",
            "t = 7, avg_loss = 0.0436\n",
            "t = 8, avg_loss = 0.0688\n",
            "t = 9, avg_loss = 0.0159\n",
            "t = 10, avg_loss = 0.0486\n",
            "t = 11, avg_loss = 0.0174\n",
            "t = 12, avg_loss = 0.0114\n",
            "t = 13, avg_loss = 0.0325\n",
            "t = 14, avg_loss = 0.0379\n",
            "t = 15, avg_loss = 0.0558\n",
            "Checking accuracy on test set\n",
            "Got 201 / 240 correct (83.75)\n",
            "acc = 0.837500\n",
            "Starting epoch 33 / 50\n",
            "t = 1, avg_loss = 0.0718\n",
            "t = 2, avg_loss = 0.0359\n",
            "t = 3, avg_loss = 0.0165\n",
            "t = 4, avg_loss = 0.0221\n",
            "t = 5, avg_loss = 0.0181\n",
            "t = 6, avg_loss = 0.0191\n",
            "t = 7, avg_loss = 0.0277\n",
            "t = 8, avg_loss = 0.0359\n",
            "t = 9, avg_loss = 0.0593\n",
            "t = 10, avg_loss = 0.0175\n",
            "t = 11, avg_loss = 0.0243\n",
            "t = 12, avg_loss = 0.0196\n",
            "t = 13, avg_loss = 0.0351\n",
            "t = 14, avg_loss = 0.0933\n",
            "t = 15, avg_loss = 0.0112\n",
            "Checking accuracy on test set\n",
            "Got 204 / 240 correct (85.00)\n",
            "acc = 0.850000\n",
            "Starting epoch 34 / 50\n",
            "t = 1, avg_loss = 0.0638\n",
            "t = 2, avg_loss = 0.0203\n",
            "t = 3, avg_loss = 0.0178\n",
            "t = 4, avg_loss = 0.0294\n",
            "t = 5, avg_loss = 0.0235\n",
            "t = 6, avg_loss = 0.0063\n",
            "t = 7, avg_loss = 0.0218\n",
            "t = 8, avg_loss = 0.0359\n",
            "t = 9, avg_loss = 0.0592\n",
            "t = 10, avg_loss = 0.0288\n",
            "t = 11, avg_loss = 0.0426\n",
            "t = 12, avg_loss = 0.0138\n",
            "t = 13, avg_loss = 0.0228\n",
            "t = 14, avg_loss = 0.0604\n",
            "t = 15, avg_loss = 0.0221\n",
            "Checking accuracy on test set\n",
            "Got 201 / 240 correct (83.75)\n",
            "acc = 0.837500\n",
            "Starting epoch 35 / 50\n",
            "t = 1, avg_loss = 0.0401\n",
            "t = 2, avg_loss = 0.0208\n",
            "t = 3, avg_loss = 0.0232\n",
            "t = 4, avg_loss = 0.0168\n",
            "t = 5, avg_loss = 0.0612\n",
            "t = 6, avg_loss = 0.0516\n",
            "t = 7, avg_loss = 0.0509\n",
            "t = 8, avg_loss = 0.0453\n",
            "t = 9, avg_loss = 0.0750\n",
            "t = 10, avg_loss = 0.0088\n",
            "t = 11, avg_loss = 0.0283\n",
            "t = 12, avg_loss = 0.0586\n",
            "t = 13, avg_loss = 0.0450\n",
            "t = 14, avg_loss = 0.0070\n",
            "t = 15, avg_loss = 0.0225\n",
            "Checking accuracy on test set\n",
            "Got 204 / 240 correct (85.00)\n",
            "acc = 0.850000\n",
            "Starting epoch 36 / 50\n",
            "t = 1, avg_loss = 0.0326\n",
            "t = 2, avg_loss = 0.0528\n",
            "t = 3, avg_loss = 0.0108\n",
            "t = 4, avg_loss = 0.0207\n",
            "t = 5, avg_loss = 0.0208\n",
            "t = 6, avg_loss = 0.0212\n",
            "t = 7, avg_loss = 0.0101\n",
            "t = 8, avg_loss = 0.0403\n",
            "t = 9, avg_loss = 0.0357\n",
            "t = 10, avg_loss = 0.0100\n",
            "t = 11, avg_loss = 0.0244\n",
            "t = 12, avg_loss = 0.0340\n",
            "t = 13, avg_loss = 0.0219\n",
            "t = 14, avg_loss = 0.0292\n",
            "t = 15, avg_loss = 0.0137\n",
            "Checking accuracy on test set\n",
            "Got 200 / 240 correct (83.33)\n",
            "acc = 0.833333\n",
            "Starting epoch 37 / 50\n",
            "t = 1, avg_loss = 0.0136\n",
            "t = 2, avg_loss = 0.0176\n",
            "t = 3, avg_loss = 0.0426\n",
            "t = 4, avg_loss = 0.0159\n",
            "t = 5, avg_loss = 0.0619\n",
            "t = 6, avg_loss = 0.0409\n",
            "t = 7, avg_loss = 0.0194\n",
            "t = 8, avg_loss = 0.0074\n",
            "t = 9, avg_loss = 0.0312\n",
            "t = 10, avg_loss = 0.0224\n",
            "t = 11, avg_loss = 0.0422\n",
            "t = 12, avg_loss = 0.0196\n",
            "t = 13, avg_loss = 0.0181\n",
            "t = 14, avg_loss = 0.0497\n",
            "t = 15, avg_loss = 0.0267\n",
            "Checking accuracy on test set\n",
            "Got 198 / 240 correct (82.50)\n",
            "acc = 0.825000\n",
            "Starting epoch 38 / 50\n",
            "t = 1, avg_loss = 0.0146\n",
            "t = 2, avg_loss = 0.0258\n",
            "t = 3, avg_loss = 0.0105\n",
            "t = 4, avg_loss = 0.0133\n",
            "t = 5, avg_loss = 0.0104\n",
            "t = 6, avg_loss = 0.0064\n",
            "t = 7, avg_loss = 0.0270\n",
            "t = 8, avg_loss = 0.0158\n",
            "t = 9, avg_loss = 0.0078\n",
            "t = 10, avg_loss = 0.0219\n",
            "t = 11, avg_loss = 0.0231\n",
            "t = 12, avg_loss = 0.0348\n",
            "t = 13, avg_loss = 0.0213\n",
            "t = 14, avg_loss = 0.0572\n",
            "t = 15, avg_loss = 0.0122\n",
            "Checking accuracy on test set\n",
            "Got 201 / 240 correct (83.75)\n",
            "acc = 0.837500\n",
            "Starting epoch 39 / 50\n",
            "t = 1, avg_loss = 0.0268\n",
            "t = 2, avg_loss = 0.0100\n",
            "t = 3, avg_loss = 0.0291\n",
            "t = 4, avg_loss = 0.0292\n",
            "t = 5, avg_loss = 0.0060\n",
            "t = 6, avg_loss = 0.0097\n",
            "t = 7, avg_loss = 0.0159\n",
            "t = 8, avg_loss = 0.0177\n",
            "t = 9, avg_loss = 0.0039\n",
            "t = 10, avg_loss = 0.0114\n",
            "t = 11, avg_loss = 0.0415\n",
            "t = 12, avg_loss = 0.0158\n",
            "t = 13, avg_loss = 0.0123\n",
            "t = 14, avg_loss = 0.0098\n",
            "t = 15, avg_loss = 0.0181\n",
            "Checking accuracy on test set\n",
            "Got 205 / 240 correct (85.42)\n",
            "acc = 0.854167\n",
            "Starting epoch 40 / 50\n",
            "t = 1, avg_loss = 0.0241\n",
            "t = 2, avg_loss = 0.0284\n",
            "t = 3, avg_loss = 0.0264\n",
            "t = 4, avg_loss = 0.0087\n",
            "t = 5, avg_loss = 0.0274\n",
            "t = 6, avg_loss = 0.0355\n",
            "t = 7, avg_loss = 0.0091\n",
            "t = 8, avg_loss = 0.0098\n",
            "t = 9, avg_loss = 0.0053\n",
            "t = 10, avg_loss = 0.0059\n",
            "t = 11, avg_loss = 0.0336\n",
            "t = 12, avg_loss = 0.0332\n",
            "t = 13, avg_loss = 0.0573\n",
            "t = 14, avg_loss = 0.0340\n",
            "t = 15, avg_loss = 0.0215\n",
            "Checking accuracy on test set\n",
            "Got 202 / 240 correct (84.17)\n",
            "acc = 0.841667\n",
            "Starting epoch 41 / 50\n",
            "t = 1, avg_loss = 0.0061\n",
            "t = 2, avg_loss = 0.0213\n",
            "t = 3, avg_loss = 0.0124\n",
            "t = 4, avg_loss = 0.0455\n",
            "t = 5, avg_loss = 0.0553\n",
            "t = 6, avg_loss = 0.0273\n",
            "t = 7, avg_loss = 0.0146\n",
            "t = 8, avg_loss = 0.0222\n",
            "t = 9, avg_loss = 0.0089\n",
            "t = 10, avg_loss = 0.0207\n",
            "t = 11, avg_loss = 0.0122\n",
            "t = 12, avg_loss = 0.0074\n",
            "t = 13, avg_loss = 0.0116\n",
            "t = 14, avg_loss = 0.0241\n",
            "t = 15, avg_loss = 0.0165\n",
            "Checking accuracy on test set\n",
            "Got 196 / 240 correct (81.67)\n",
            "acc = 0.816667\n",
            "Starting epoch 42 / 50\n",
            "t = 1, avg_loss = 0.0584\n",
            "t = 2, avg_loss = 0.0253\n",
            "t = 3, avg_loss = 0.0614\n",
            "t = 4, avg_loss = 0.0099\n",
            "t = 5, avg_loss = 0.0158\n",
            "t = 6, avg_loss = 0.0122\n",
            "t = 7, avg_loss = 0.0357\n",
            "t = 8, avg_loss = 0.0137\n",
            "t = 9, avg_loss = 0.0080\n",
            "t = 10, avg_loss = 0.0042\n",
            "t = 11, avg_loss = 0.0154\n",
            "t = 12, avg_loss = 0.0486\n",
            "t = 13, avg_loss = 0.0164\n",
            "t = 14, avg_loss = 0.0081\n",
            "t = 15, avg_loss = 0.0245\n",
            "Checking accuracy on test set\n",
            "Got 195 / 240 correct (81.25)\n",
            "acc = 0.812500\n",
            "Starting epoch 43 / 50\n",
            "t = 1, avg_loss = 0.0135\n",
            "t = 2, avg_loss = 0.0284\n",
            "t = 3, avg_loss = 0.0092\n",
            "t = 4, avg_loss = 0.0150\n",
            "t = 5, avg_loss = 0.0160\n",
            "t = 6, avg_loss = 0.0075\n",
            "t = 7, avg_loss = 0.0482\n",
            "t = 8, avg_loss = 0.0353\n",
            "t = 9, avg_loss = 0.0094\n",
            "t = 10, avg_loss = 0.0092\n",
            "t = 11, avg_loss = 0.0284\n",
            "t = 12, avg_loss = 0.0121\n",
            "t = 13, avg_loss = 0.0084\n",
            "t = 14, avg_loss = 0.0169\n",
            "t = 15, avg_loss = 0.0044\n",
            "Checking accuracy on test set\n",
            "Got 205 / 240 correct (85.42)\n",
            "acc = 0.854167\n",
            "Starting epoch 44 / 50\n",
            "t = 1, avg_loss = 0.0062\n",
            "t = 2, avg_loss = 0.0048\n",
            "t = 3, avg_loss = 0.0067\n",
            "t = 4, avg_loss = 0.0157\n",
            "t = 5, avg_loss = 0.0159\n",
            "t = 6, avg_loss = 0.0107\n",
            "t = 7, avg_loss = 0.0086\n",
            "t = 8, avg_loss = 0.0268\n",
            "t = 9, avg_loss = 0.0086\n",
            "t = 10, avg_loss = 0.0106\n",
            "t = 11, avg_loss = 0.0130\n",
            "t = 12, avg_loss = 0.0231\n",
            "t = 13, avg_loss = 0.0061\n",
            "t = 14, avg_loss = 0.0111\n",
            "t = 15, avg_loss = 0.0414\n",
            "Checking accuracy on test set\n",
            "Got 197 / 240 correct (82.08)\n",
            "acc = 0.820833\n",
            "Starting epoch 45 / 50\n",
            "t = 1, avg_loss = 0.0066\n",
            "t = 2, avg_loss = 0.0112\n",
            "t = 3, avg_loss = 0.0194\n",
            "t = 4, avg_loss = 0.0045\n",
            "t = 5, avg_loss = 0.0191\n",
            "t = 6, avg_loss = 0.0337\n",
            "t = 7, avg_loss = 0.0144\n",
            "t = 8, avg_loss = 0.0057\n",
            "t = 9, avg_loss = 0.0069\n",
            "t = 10, avg_loss = 0.0095\n",
            "t = 11, avg_loss = 0.0148\n",
            "t = 12, avg_loss = 0.0073\n",
            "t = 13, avg_loss = 0.0059\n",
            "t = 14, avg_loss = 0.0092\n",
            "t = 15, avg_loss = 0.0234\n",
            "Checking accuracy on test set\n",
            "Got 198 / 240 correct (82.50)\n",
            "acc = 0.825000\n",
            "Starting epoch 46 / 50\n",
            "t = 1, avg_loss = 0.0114\n",
            "t = 2, avg_loss = 0.0085\n",
            "t = 3, avg_loss = 0.0078\n",
            "t = 4, avg_loss = 0.0050\n",
            "t = 5, avg_loss = 0.0060\n",
            "t = 6, avg_loss = 0.0050\n",
            "t = 7, avg_loss = 0.0081\n",
            "t = 8, avg_loss = 0.0188\n",
            "t = 9, avg_loss = 0.0047\n",
            "t = 10, avg_loss = 0.0102\n",
            "t = 11, avg_loss = 0.0135\n",
            "t = 12, avg_loss = 0.0094\n",
            "t = 13, avg_loss = 0.0039\n",
            "t = 14, avg_loss = 0.0038\n",
            "t = 15, avg_loss = 0.0129\n",
            "Checking accuracy on test set\n",
            "Got 197 / 240 correct (82.08)\n",
            "acc = 0.820833\n",
            "Starting epoch 47 / 50\n",
            "t = 1, avg_loss = 0.0204\n",
            "t = 2, avg_loss = 0.0084\n",
            "t = 3, avg_loss = 0.0048\n",
            "t = 4, avg_loss = 0.0117\n",
            "t = 5, avg_loss = 0.0080\n",
            "t = 6, avg_loss = 0.0110\n",
            "t = 7, avg_loss = 0.0142\n",
            "t = 8, avg_loss = 0.0201\n",
            "t = 9, avg_loss = 0.0076\n",
            "t = 10, avg_loss = 0.0049\n",
            "t = 11, avg_loss = 0.0084\n",
            "t = 12, avg_loss = 0.0133\n",
            "t = 13, avg_loss = 0.0074\n",
            "t = 14, avg_loss = 0.0051\n",
            "t = 15, avg_loss = 0.0028\n",
            "Checking accuracy on test set\n",
            "Got 200 / 240 correct (83.33)\n",
            "acc = 0.833333\n",
            "Starting epoch 48 / 50\n",
            "t = 1, avg_loss = 0.0049\n",
            "t = 2, avg_loss = 0.0040\n",
            "t = 3, avg_loss = 0.0040\n",
            "t = 4, avg_loss = 0.0140\n",
            "t = 5, avg_loss = 0.0124\n",
            "t = 6, avg_loss = 0.0044\n",
            "t = 7, avg_loss = 0.0094\n",
            "t = 8, avg_loss = 0.0058\n",
            "t = 9, avg_loss = 0.0088\n",
            "t = 10, avg_loss = 0.0092\n",
            "t = 11, avg_loss = 0.0083\n",
            "t = 12, avg_loss = 0.0040\n",
            "t = 13, avg_loss = 0.0068\n",
            "t = 14, avg_loss = 0.0100\n",
            "t = 15, avg_loss = 0.0201\n",
            "Checking accuracy on test set\n",
            "Got 202 / 240 correct (84.17)\n",
            "acc = 0.841667\n",
            "Starting epoch 49 / 50\n",
            "t = 1, avg_loss = 0.0034\n",
            "t = 2, avg_loss = 0.0045\n",
            "t = 3, avg_loss = 0.0055\n",
            "t = 4, avg_loss = 0.0024\n",
            "t = 5, avg_loss = 0.0070\n",
            "t = 6, avg_loss = 0.0029\n",
            "t = 7, avg_loss = 0.0089\n",
            "t = 8, avg_loss = 0.0041\n",
            "t = 9, avg_loss = 0.0093\n",
            "t = 10, avg_loss = 0.0089\n",
            "t = 11, avg_loss = 0.0059\n",
            "t = 12, avg_loss = 0.0143\n",
            "t = 13, avg_loss = 0.0075\n",
            "t = 14, avg_loss = 0.0029\n",
            "t = 15, avg_loss = 0.0071\n",
            "Checking accuracy on test set\n",
            "Got 201 / 240 correct (83.75)\n",
            "acc = 0.837500\n",
            "Starting epoch 50 / 50\n",
            "t = 1, avg_loss = 0.0015\n",
            "t = 2, avg_loss = 0.0080\n",
            "t = 3, avg_loss = 0.0062\n",
            "t = 4, avg_loss = 0.0108\n",
            "t = 5, avg_loss = 0.0055\n",
            "t = 6, avg_loss = 0.0042\n",
            "t = 7, avg_loss = 0.0052\n",
            "t = 8, avg_loss = 0.0050\n",
            "t = 9, avg_loss = 0.0077\n",
            "t = 10, avg_loss = 0.0089\n",
            "t = 11, avg_loss = 0.0178\n",
            "t = 12, avg_loss = 0.0065\n",
            "t = 13, avg_loss = 0.0031\n",
            "t = 14, avg_loss = 0.0077\n",
            "t = 15, avg_loss = 0.0030\n",
            "Checking accuracy on test set\n",
            "Got 202 / 240 correct (84.17)\n",
            "acc = 0.841667\n",
            "Checking accuracy on test set\n",
            "Got 201 / 240 correct (83.75)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8375"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDn-2g-TLY3k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "941a41b6-78ae-4ddf-bc01-8cac9f6e567e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot([print_every*batch_size*(i+1) for i in range((len(avg_loss_list)))],avg_loss_list)\n",
        "print(\"Loss:\")\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD4CAYAAAAKA1qZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGer6hJv7-zR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "0e278cad-3c0d-43d9-9de7-d51553e8a5ff"
      },
      "source": [
        "plt.plot([i+1 for i in range((len(acc_list)))],acc_list)\n",
        "print(\"Accurancy:\")\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accurancy:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBTReWHxz4Ml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}