{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN_ascending_layers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamilo116/KNN/blob/master/KNN_ascending_layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7ReM7FU-xs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import sys\n",
        "from random import shuffle\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms as transforms\n",
        "import timeit\n",
        "\n",
        "np.random.seed(4) \n",
        "torch.manual_seed(4) \n",
        "torch.cuda.manual_seed(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYIMZ8QyYewD",
        "colab_type": "code",
        "outputId": "9029a140-5670-4740-b3ec-f99368adca5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "! git clone https://github.com/wang-chen/kervolution.git \n",
        "\n",
        "sys.path.append(\"kervolution/\")\n",
        "from kervolution import Kerv2d\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'kervolution'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects:  16% (1/6)\u001b[K\rremote: Counting objects:  33% (2/6)\u001b[K\rremote: Counting objects:  50% (3/6)\u001b[K\rremote: Counting objects:  66% (4/6)\u001b[K\rremote: Counting objects:  83% (5/6)\u001b[K\rremote: Counting objects: 100% (6/6)\u001b[K\rremote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects:  16% (1/6)\u001b[K\rremote: Compressing objects:  33% (2/6)\u001b[K\rremote: Compressing objects:  50% (3/6)\u001b[K\rremote: Compressing objects:  66% (4/6)\u001b[K\rremote: Compressing objects:  83% (5/6)\u001b[K\rremote: Compressing objects: 100% (6/6)\u001b[K\rremote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "Unpacking objects:   1% (1/53)   \rUnpacking objects:   3% (2/53)   \rUnpacking objects:   5% (3/53)   \rremote: Total 53 (delta 2), reused 0 (delta 0), pack-reused 47\u001b[K\n",
            "Unpacking objects:   7% (4/53)   \rUnpacking objects:   9% (5/53)   \rUnpacking objects:  11% (6/53)   \rUnpacking objects:  13% (7/53)   \rUnpacking objects:  15% (8/53)   \rUnpacking objects:  16% (9/53)   \rUnpacking objects:  18% (10/53)   \rUnpacking objects:  20% (11/53)   \rUnpacking objects:  22% (12/53)   \rUnpacking objects:  24% (13/53)   \rUnpacking objects:  26% (14/53)   \rUnpacking objects:  28% (15/53)   \rUnpacking objects:  30% (16/53)   \rUnpacking objects:  32% (17/53)   \rUnpacking objects:  33% (18/53)   \rUnpacking objects:  35% (19/53)   \rUnpacking objects:  37% (20/53)   \rUnpacking objects:  39% (21/53)   \rUnpacking objects:  41% (22/53)   \rUnpacking objects:  43% (23/53)   \rUnpacking objects:  45% (24/53)   \rUnpacking objects:  47% (25/53)   \rUnpacking objects:  49% (26/53)   \rUnpacking objects:  50% (27/53)   \rUnpacking objects:  52% (28/53)   \rUnpacking objects:  54% (29/53)   \rUnpacking objects:  56% (30/53)   \rUnpacking objects:  58% (31/53)   \rUnpacking objects:  60% (32/53)   \rUnpacking objects:  62% (33/53)   \rUnpacking objects:  64% (34/53)   \rUnpacking objects:  66% (35/53)   \rUnpacking objects:  67% (36/53)   \rUnpacking objects:  69% (37/53)   \rUnpacking objects:  71% (38/53)   \rUnpacking objects:  73% (39/53)   \rUnpacking objects:  75% (40/53)   \rUnpacking objects:  77% (41/53)   \rUnpacking objects:  79% (42/53)   \rUnpacking objects:  81% (43/53)   \rUnpacking objects:  83% (44/53)   \rUnpacking objects:  84% (45/53)   \rUnpacking objects:  86% (46/53)   \rUnpacking objects:  88% (47/53)   \rUnpacking objects:  90% (48/53)   \rUnpacking objects:  92% (49/53)   \rUnpacking objects:  94% (50/53)   \rUnpacking objects:  96% (51/53)   \rUnpacking objects:  98% (52/53)   \rUnpacking objects: 100% (53/53)   \rUnpacking objects: 100% (53/53), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvbKg4VJXKY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LIMIT_IMAGES_NUM = 1000\n",
        "train_test_split_size = 0.2\n",
        "image_resize = (100, 100)\n",
        "batch_size = 64\n",
        "num_workers = 0\n",
        "\n",
        "out_1 = 16\n",
        "out_2 = 32\n",
        "out_3 = 64\n",
        "out_4 = 128\n",
        "\n",
        "\n",
        "k_size_1 = 3\n",
        "padding_1 = 1\n",
        "in_channels = 3\n",
        "\n",
        "kernel_size = 3\n",
        "num_epochs = 100\n",
        "\n",
        "learning_rate = 0.0001\n",
        "weight_decay = 0.1\n",
        "\n",
        "MALIGNANT_DATASET = '/content/drive/My Drive/Colab_data/malignant/malignant/'\n",
        "BENIGN_DATASET = '/content/drive/My Drive/Colab_data/benign/benign/'\n",
        "DATA_FOLDER = '/content/drive/My Drive/Colab_data/'\n",
        "model_backup_path = os.path.join(DATA_FOLDER, 'backup_model2') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMOHez_kHZD6",
        "colab_type": "code",
        "outputId": "e2cac737-42b7-4952-ba31-2ebc0f74754e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b8P1NdXfVdX",
        "colab_type": "code",
        "outputId": "a2f437c4-3341-4d89-e6be-4e62521e7d4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "benign_file_list = sorted(os.listdir(BENIGN_DATASET))\n",
        "malignant_file_list = sorted(os.listdir(MALIGNANT_DATASET))\n",
        "shuffle(benign_file_list)\n",
        "shuffle(malignant_file_list)\n",
        "benign_file_list = benign_file_list[:LIMIT_IMAGES_NUM]\n",
        "malignant_file_list = malignant_file_list[:LIMIT_IMAGES_NUM]\n",
        "\n",
        "print(f\"Number of benign {len(benign_file_list)} images\")\n",
        "print(f\"Number of malignant {len(malignant_file_list)} images\")\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize(image_resize),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of benign 1000 images\n",
            "Number of malignant 1000 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGDQfal74BLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "benign_dict = {filename: 0 for filename in benign_file_list}\n",
        "malignant_dict = {filename: 1 for filename in malignant_file_list}\n",
        "img_class_dict = {**benign_dict , **malignant_dict}\n",
        "labeled_data = pd.Series(img_class_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvAAOqmVfVll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IsicDataset(Dataset):\n",
        "    def __init__(self, data_folder, labeled_data, \n",
        "                 transform=transforms.Compose([transforms.ToTensor()])):\n",
        "        self.labeled_data = labeled_data\n",
        "        self.transform = transform\n",
        "        self.data_folder = data_folder\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labeled_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        label = self.labeled_data[index]\n",
        "        if label == 0:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"benign\", \"benign\", index ))\n",
        "        else:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"malignant\", \"malignant\", index ))\n",
        "        image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "    @property\n",
        "    def labels(self):\n",
        "      return self.labeled_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSuYqjLAYrWA",
        "colab_type": "code",
        "outputId": "f4488670-e83e-415b-fb8f-ab48bf697be1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "dataset = IsicDataset(DATA_FOLDER, labeled_data, transform=data_transforms)\n",
        "print(dataset.labels)\n",
        "\n",
        "X_train, X_test = train_test_split(dataset.labels, test_size=train_test_split_size)\n",
        "print(\"number of training data: \",len(X_train))\n",
        "print(\"number of testing  data: \",len(X_test))\n",
        "\n",
        "train_sampler = SubsetRandomSampler(list(X_train.index))\n",
        "valid_sampler = SubsetRandomSampler(list(X_test.index))\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ISIC_0000496.jpeg    0\n",
            "ISIC_0002859.jpeg    0\n",
            "ISIC_0002733.jpeg    0\n",
            "ISIC_0000418.jpeg    0\n",
            "ISIC_0000889.jpeg    0\n",
            "                    ..\n",
            "ISIC_0025105.jpg     1\n",
            "ISIC_0014922.jpeg    1\n",
            "ISIC_0014044.jpeg    1\n",
            "ISIC_0010478.jpeg    1\n",
            "ISIC_0011209.jpeg    1\n",
            "Length: 2000, dtype: int64\n",
            "number of training data:  1600\n",
            "number of testing  data:  400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e8nFBR6Yug5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "def train(model, train_loader ,loss_fn, optimizer, num_epochs=1, starting_from_epoch=1):\n",
        "    total_loss =0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
        "        model.train()\n",
        "\n",
        "        for t, (x, y) in enumerate(train_loader):\n",
        "            x_var = Variable(x.type(gpu_dtype))\n",
        "            y_var = Variable(y.type(gpu_dtype).long())\n",
        "            scores = model(x_var)\n",
        "            loss = loss_fn(scores, y_var)\n",
        "            total_loss += loss.data\n",
        "            \n",
        "            if (t + 1) % print_every == 0:\n",
        "                avg_loss = total_loss/print_every\n",
        "                print('t = %d, avg_loss = %.4f' % (t + 1, avg_loss) )\n",
        "                avg_loss_list.append(avg_loss)\n",
        "                total_loss = 0\n",
        "                \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        acc = check_accuracy(model_gpu, valid_loader)\n",
        "        print('acc = %f' %(acc))\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model_gpu.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            'acc_list': acc_list,\n",
        "            }, model_backup_path)\n",
        "            \n",
        "def check_accuracy(model, loader):\n",
        "    print('Checking accuracy on test set')   \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval() \n",
        "    for x, y in loader:\n",
        "        x_var = Variable(x.type(gpu_dtype))\n",
        "\n",
        "        scores = model(x_var)\n",
        "        _, preds = scores.data.cpu().max(1)\n",
        "        num_correct += (preds == y).sum()\n",
        "        num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    acc_list.append(acc)\n",
        "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "    return acc\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.size()\n",
        "        return x.view(N, -1)      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-gYHw0Jlbwt",
        "colab_type": "code",
        "outputId": "8bad16ef-f0bd-468d-d216-c8411d069a7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "source": [
        "print_every = 2\n",
        "gpu_dtype = torch.cuda.FloatTensor\n",
        "\n",
        "\n",
        "'''\n",
        "Kerv2d\n",
        "kervolution with following options:\n",
        "kernel_type: [linear, polynomial, gaussian, etc.]\n",
        "default is convolution:\n",
        "          kernel_type --> linear,\n",
        "balance, power, gamma is valid only when the kernel_type is specified\n",
        "if learnable_kernel = True,  they just be the initial value of learable parameters\n",
        "if learnable_kernel = False, they are the value of kernel_type's parameter\n",
        "the parameter [power] cannot be learned due to integer limitation\n",
        "dilation (int or tuple, optional): Spacing between kernel\n",
        "elements. Default: 1\n",
        "groups (int, optional): Number of blocked connections from input\n",
        "channels to output channels. Default: 1\n",
        "bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n",
        "kernel_type (str), Default: 'linear'\n",
        "learnable_kernel (bool): Learnable kernel parameters.  Default: False \n",
        "balance: 0, 1\n",
        "power: 3, 4, 5\n",
        "gamma:\n",
        "'''\n",
        "\n",
        "\n",
        "model_base = nn.Sequential( \n",
        "                #nn.Conv2d(in_channels , out_1, padding= padding_1, kernel_size=k_size_1, stride=1),\n",
        "                nn.Kerv2d(in_channels , out_1, padding=padding_1, dilation=1, groups=1, bias=True, \n",
        "                          kernel_type='polynomial', kernel_size=k_size_1, learnable_kernel=True,\n",
        "                          kernel_regularizer=True, stride=1, balance=1, power=3, gamma=1\n",
        "                          ), \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_1),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_1 , out_2, padding= padding_1, kernel_size=k_size_1, stride=1), \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_2),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_2 , out_3, padding= padding_1, kernel_size=k_size_1, stride=1),  \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_3),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_3 , out_4, padding= padding_1, kernel_size=k_size_1, stride=1),  \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_4),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Dropout(0.5),\n",
        "                Flatten(),\n",
        "                nn.Linear(4608,64),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Linear(64,2)\n",
        "            )\n",
        "model_gpu = model_base.type(gpu_dtype)\n",
        "print(model_gpu)\n",
        "loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Kerv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (4): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (5): ReLU(inplace=True)\n",
            "  (6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (8): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (9): ReLU(inplace=True)\n",
            "  (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (12): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (13): ReLU(inplace=True)\n",
            "  (14): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (16): Dropout(p=0.5, inplace=False)\n",
            "  (17): Flatten()\n",
            "  (18): Linear(in_features=4608, out_features=64, bias=True)\n",
            "  (19): ReLU(inplace=True)\n",
            "  (20): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgmexhBRZAK6",
        "colab_type": "code",
        "outputId": "4ef257f2-5f9c-4ef3-d1a2-7cc32964f5ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs)\n",
        "check_accuracy(model_gpu, valid_loader)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 1 / 100\n",
            "t = 2, avg_loss = 0.7521\n",
            "t = 4, avg_loss = 0.6399\n",
            "t = 6, avg_loss = 0.6282\n",
            "t = 8, avg_loss = 0.5953\n",
            "t = 10, avg_loss = 0.5545\n",
            "t = 12, avg_loss = 0.5602\n",
            "t = 14, avg_loss = 0.4190\n",
            "t = 16, avg_loss = 0.5549\n",
            "t = 18, avg_loss = 0.4666\n",
            "t = 20, avg_loss = 0.5273\n",
            "t = 22, avg_loss = 0.4341\n",
            "t = 24, avg_loss = 0.3704\n",
            "Checking accuracy on test set\n",
            "Got 229 / 400 correct (57.25)\n",
            "acc = 0.572500\n",
            "Starting epoch 2 / 100\n",
            "t = 2, avg_loss = 0.6422\n",
            "t = 4, avg_loss = 0.3632\n",
            "t = 6, avg_loss = 0.4017\n",
            "t = 8, avg_loss = 0.4816\n",
            "t = 10, avg_loss = 0.4235\n",
            "t = 12, avg_loss = 0.3986\n",
            "t = 14, avg_loss = 0.3586\n",
            "t = 16, avg_loss = 0.4973\n",
            "t = 18, avg_loss = 0.4525\n",
            "t = 20, avg_loss = 0.4143\n",
            "t = 22, avg_loss = 0.3035\n",
            "t = 24, avg_loss = 0.4076\n",
            "Checking accuracy on test set\n",
            "Got 315 / 400 correct (78.75)\n",
            "acc = 0.787500\n",
            "Starting epoch 3 / 100\n",
            "t = 2, avg_loss = 0.6248\n",
            "t = 4, avg_loss = 0.3556\n",
            "t = 6, avg_loss = 0.4207\n",
            "t = 8, avg_loss = 0.4169\n",
            "t = 10, avg_loss = 0.4495\n",
            "t = 12, avg_loss = 0.3757\n",
            "t = 14, avg_loss = 0.3593\n",
            "t = 16, avg_loss = 0.3044\n",
            "t = 18, avg_loss = 0.3273\n",
            "t = 20, avg_loss = 0.3125\n",
            "t = 22, avg_loss = 0.3132\n",
            "t = 24, avg_loss = 0.4719\n",
            "Checking accuracy on test set\n",
            "Got 326 / 400 correct (81.50)\n",
            "acc = 0.815000\n",
            "Starting epoch 4 / 100\n",
            "t = 2, avg_loss = 0.5303\n",
            "t = 4, avg_loss = 0.4216\n",
            "t = 6, avg_loss = 0.4342\n",
            "t = 8, avg_loss = 0.3327\n",
            "t = 10, avg_loss = 0.3933\n",
            "t = 12, avg_loss = 0.3440\n",
            "t = 14, avg_loss = 0.3441\n",
            "t = 16, avg_loss = 0.2846\n",
            "t = 18, avg_loss = 0.3049\n",
            "t = 20, avg_loss = 0.3840\n",
            "t = 22, avg_loss = 0.3051\n",
            "t = 24, avg_loss = 0.2895\n",
            "Checking accuracy on test set\n",
            "Got 313 / 400 correct (78.25)\n",
            "acc = 0.782500\n",
            "Starting epoch 5 / 100\n",
            "t = 2, avg_loss = 0.3897\n",
            "t = 4, avg_loss = 0.2954\n",
            "t = 6, avg_loss = 0.3578\n",
            "t = 8, avg_loss = 0.3253\n",
            "t = 10, avg_loss = 0.3184\n",
            "t = 12, avg_loss = 0.3601\n",
            "t = 14, avg_loss = 0.3539\n",
            "t = 16, avg_loss = 0.3403\n",
            "t = 18, avg_loss = 0.3760\n",
            "t = 20, avg_loss = 0.3637\n",
            "t = 22, avg_loss = 0.3413\n",
            "t = 24, avg_loss = 0.3693\n",
            "Checking accuracy on test set\n",
            "Got 329 / 400 correct (82.25)\n",
            "acc = 0.822500\n",
            "Starting epoch 6 / 100\n",
            "t = 2, avg_loss = 0.5153\n",
            "t = 4, avg_loss = 0.3374\n",
            "t = 6, avg_loss = 0.2724\n",
            "t = 8, avg_loss = 0.3219\n",
            "t = 10, avg_loss = 0.2819\n",
            "t = 12, avg_loss = 0.2740\n",
            "t = 14, avg_loss = 0.2451\n",
            "t = 16, avg_loss = 0.3188\n",
            "t = 18, avg_loss = 0.3422\n",
            "t = 20, avg_loss = 0.3762\n",
            "t = 22, avg_loss = 0.2937\n",
            "t = 24, avg_loss = 0.2586\n",
            "Checking accuracy on test set\n",
            "Got 334 / 400 correct (83.50)\n",
            "acc = 0.835000\n",
            "Starting epoch 7 / 100\n",
            "t = 2, avg_loss = 0.4083\n",
            "t = 4, avg_loss = 0.2642\n",
            "t = 6, avg_loss = 0.3071\n",
            "t = 8, avg_loss = 0.3257\n",
            "t = 10, avg_loss = 0.2760\n",
            "t = 12, avg_loss = 0.3176\n",
            "t = 14, avg_loss = 0.3583\n",
            "t = 16, avg_loss = 0.2101\n",
            "t = 18, avg_loss = 0.2590\n",
            "t = 20, avg_loss = 0.2604\n",
            "t = 22, avg_loss = 0.3322\n",
            "t = 24, avg_loss = 0.3590\n",
            "Checking accuracy on test set\n",
            "Got 339 / 400 correct (84.75)\n",
            "acc = 0.847500\n",
            "Starting epoch 8 / 100\n",
            "t = 2, avg_loss = 0.4341\n",
            "t = 4, avg_loss = 0.2825\n",
            "t = 6, avg_loss = 0.3604\n",
            "t = 8, avg_loss = 0.3152\n",
            "t = 10, avg_loss = 0.2984\n",
            "t = 12, avg_loss = 0.3700\n",
            "t = 14, avg_loss = 0.2822\n",
            "t = 16, avg_loss = 0.2189\n",
            "t = 18, avg_loss = 0.2414\n",
            "t = 20, avg_loss = 0.3618\n",
            "t = 22, avg_loss = 0.2381\n",
            "t = 24, avg_loss = 0.3314\n",
            "Checking accuracy on test set\n",
            "Got 338 / 400 correct (84.50)\n",
            "acc = 0.845000\n",
            "Starting epoch 9 / 100\n",
            "t = 2, avg_loss = 0.5228\n",
            "t = 4, avg_loss = 0.2636\n",
            "t = 6, avg_loss = 0.3024\n",
            "t = 8, avg_loss = 0.2643\n",
            "t = 10, avg_loss = 0.2366\n",
            "t = 12, avg_loss = 0.3064\n",
            "t = 14, avg_loss = 0.2587\n",
            "t = 16, avg_loss = 0.2954\n",
            "t = 18, avg_loss = 0.3309\n",
            "t = 20, avg_loss = 0.3356\n",
            "t = 22, avg_loss = 0.2351\n",
            "t = 24, avg_loss = 0.3416\n",
            "Checking accuracy on test set\n",
            "Got 341 / 400 correct (85.25)\n",
            "acc = 0.852500\n",
            "Starting epoch 10 / 100\n",
            "t = 2, avg_loss = 0.4032\n",
            "t = 4, avg_loss = 0.3546\n",
            "t = 6, avg_loss = 0.3106\n",
            "t = 8, avg_loss = 0.3186\n",
            "t = 10, avg_loss = 0.3024\n",
            "t = 12, avg_loss = 0.2344\n",
            "t = 14, avg_loss = 0.2609\n",
            "t = 16, avg_loss = 0.2033\n",
            "t = 18, avg_loss = 0.2580\n",
            "t = 20, avg_loss = 0.1870\n",
            "t = 22, avg_loss = 0.2927\n",
            "t = 24, avg_loss = 0.2785\n",
            "Checking accuracy on test set\n",
            "Got 332 / 400 correct (83.00)\n",
            "acc = 0.830000\n",
            "Starting epoch 11 / 100\n",
            "t = 2, avg_loss = 0.4694\n",
            "t = 4, avg_loss = 0.2436\n",
            "t = 6, avg_loss = 0.2721\n",
            "t = 8, avg_loss = 0.3268\n",
            "t = 10, avg_loss = 0.2158\n",
            "t = 12, avg_loss = 0.2844\n",
            "t = 14, avg_loss = 0.2445\n",
            "t = 16, avg_loss = 0.2862\n",
            "t = 18, avg_loss = 0.3093\n",
            "t = 20, avg_loss = 0.3186\n",
            "t = 22, avg_loss = 0.2488\n",
            "t = 24, avg_loss = 0.2571\n",
            "Checking accuracy on test set\n",
            "Got 337 / 400 correct (84.25)\n",
            "acc = 0.842500\n",
            "Starting epoch 12 / 100\n",
            "t = 2, avg_loss = 0.3933\n",
            "t = 4, avg_loss = 0.2684\n",
            "t = 6, avg_loss = 0.2832\n",
            "t = 8, avg_loss = 0.3303\n",
            "t = 10, avg_loss = 0.2196\n",
            "t = 12, avg_loss = 0.3080\n",
            "t = 14, avg_loss = 0.2699\n",
            "t = 16, avg_loss = 0.2587\n",
            "t = 18, avg_loss = 0.2779\n",
            "t = 20, avg_loss = 0.2214\n",
            "t = 22, avg_loss = 0.2382\n",
            "t = 24, avg_loss = 0.2340\n",
            "Checking accuracy on test set\n",
            "Got 341 / 400 correct (85.25)\n",
            "acc = 0.852500\n",
            "Starting epoch 13 / 100\n",
            "t = 2, avg_loss = 0.4080\n",
            "t = 4, avg_loss = 0.2297\n",
            "t = 6, avg_loss = 0.2134\n",
            "t = 8, avg_loss = 0.1990\n",
            "t = 10, avg_loss = 0.2310\n",
            "t = 12, avg_loss = 0.2855\n",
            "t = 14, avg_loss = 0.2450\n",
            "t = 16, avg_loss = 0.2315\n",
            "t = 18, avg_loss = 0.2714\n",
            "t = 20, avg_loss = 0.2348\n",
            "t = 22, avg_loss = 0.3075\n",
            "t = 24, avg_loss = 0.2632\n",
            "Checking accuracy on test set\n",
            "Got 339 / 400 correct (84.75)\n",
            "acc = 0.847500\n",
            "Starting epoch 14 / 100\n",
            "t = 2, avg_loss = 0.3503\n",
            "t = 4, avg_loss = 0.2475\n",
            "t = 6, avg_loss = 0.2603\n",
            "t = 8, avg_loss = 0.2069\n",
            "t = 10, avg_loss = 0.2064\n",
            "t = 12, avg_loss = 0.2582\n",
            "t = 14, avg_loss = 0.2284\n",
            "t = 16, avg_loss = 0.2572\n",
            "t = 18, avg_loss = 0.2255\n",
            "t = 20, avg_loss = 0.2137\n",
            "t = 22, avg_loss = 0.1970\n",
            "t = 24, avg_loss = 0.2271\n",
            "Checking accuracy on test set\n",
            "Got 343 / 400 correct (85.75)\n",
            "acc = 0.857500\n",
            "Starting epoch 15 / 100\n",
            "t = 2, avg_loss = 0.4073\n",
            "t = 4, avg_loss = 0.2332\n",
            "t = 6, avg_loss = 0.2185\n",
            "t = 8, avg_loss = 0.2709\n",
            "t = 10, avg_loss = 0.2304\n",
            "t = 12, avg_loss = 0.1922\n",
            "t = 14, avg_loss = 0.2233\n",
            "t = 16, avg_loss = 0.2578\n",
            "t = 18, avg_loss = 0.2150\n",
            "t = 20, avg_loss = 0.2589\n",
            "t = 22, avg_loss = 0.2333\n",
            "t = 24, avg_loss = 0.2680\n",
            "Checking accuracy on test set\n",
            "Got 342 / 400 correct (85.50)\n",
            "acc = 0.855000\n",
            "Starting epoch 16 / 100\n",
            "t = 2, avg_loss = 0.3512\n",
            "t = 4, avg_loss = 0.2651\n",
            "t = 6, avg_loss = 0.2890\n",
            "t = 8, avg_loss = 0.2359\n",
            "t = 10, avg_loss = 0.1823\n",
            "t = 12, avg_loss = 0.2790\n",
            "t = 14, avg_loss = 0.2414\n",
            "t = 16, avg_loss = 0.2710\n",
            "t = 18, avg_loss = 0.2376\n",
            "t = 20, avg_loss = 0.1753\n",
            "t = 22, avg_loss = 0.1774\n",
            "t = 24, avg_loss = 0.2994\n",
            "Checking accuracy on test set\n",
            "Got 337 / 400 correct (84.25)\n",
            "acc = 0.842500\n",
            "Starting epoch 17 / 100\n",
            "t = 2, avg_loss = 0.3540\n",
            "t = 4, avg_loss = 0.2497\n",
            "t = 6, avg_loss = 0.2531\n",
            "t = 8, avg_loss = 0.1849\n",
            "t = 10, avg_loss = 0.2399\n",
            "t = 12, avg_loss = 0.2705\n",
            "t = 14, avg_loss = 0.2691\n",
            "t = 16, avg_loss = 0.1853\n",
            "t = 18, avg_loss = 0.2076\n",
            "t = 20, avg_loss = 0.2057\n",
            "t = 22, avg_loss = 0.2453\n",
            "t = 24, avg_loss = 0.2325\n",
            "Checking accuracy on test set\n",
            "Got 345 / 400 correct (86.25)\n",
            "acc = 0.862500\n",
            "Starting epoch 18 / 100\n",
            "t = 2, avg_loss = 0.4144\n",
            "t = 4, avg_loss = 0.2306\n",
            "t = 6, avg_loss = 0.1673\n",
            "t = 8, avg_loss = 0.2081\n",
            "t = 10, avg_loss = 0.1986\n",
            "t = 12, avg_loss = 0.1568\n",
            "t = 14, avg_loss = 0.2703\n",
            "t = 16, avg_loss = 0.2310\n",
            "t = 18, avg_loss = 0.2286\n",
            "t = 20, avg_loss = 0.1910\n",
            "t = 22, avg_loss = 0.2582\n",
            "t = 24, avg_loss = 0.1911\n",
            "Checking accuracy on test set\n",
            "Got 346 / 400 correct (86.50)\n",
            "acc = 0.865000\n",
            "Starting epoch 19 / 100\n",
            "t = 2, avg_loss = 0.2799\n",
            "t = 4, avg_loss = 0.1565\n",
            "t = 6, avg_loss = 0.2203\n",
            "t = 8, avg_loss = 0.2321\n",
            "t = 10, avg_loss = 0.1266\n",
            "t = 12, avg_loss = 0.2267\n",
            "t = 14, avg_loss = 0.2010\n",
            "t = 16, avg_loss = 0.3129\n",
            "t = 18, avg_loss = 0.2588\n",
            "t = 20, avg_loss = 0.2160\n",
            "t = 22, avg_loss = 0.2079\n",
            "t = 24, avg_loss = 0.2180\n",
            "Checking accuracy on test set\n",
            "Got 344 / 400 correct (86.00)\n",
            "acc = 0.860000\n",
            "Starting epoch 20 / 100\n",
            "t = 2, avg_loss = 0.2771\n",
            "t = 4, avg_loss = 0.1604\n",
            "t = 6, avg_loss = 0.2147\n",
            "t = 8, avg_loss = 0.2142\n",
            "t = 10, avg_loss = 0.1987\n",
            "t = 12, avg_loss = 0.2111\n",
            "t = 14, avg_loss = 0.2184\n",
            "t = 16, avg_loss = 0.2030\n",
            "t = 18, avg_loss = 0.1810\n",
            "t = 20, avg_loss = 0.2342\n",
            "t = 22, avg_loss = 0.2081\n",
            "t = 24, avg_loss = 0.2380\n",
            "Checking accuracy on test set\n",
            "Got 346 / 400 correct (86.50)\n",
            "acc = 0.865000\n",
            "Starting epoch 21 / 100\n",
            "t = 2, avg_loss = 0.3263\n",
            "t = 4, avg_loss = 0.1804\n",
            "t = 6, avg_loss = 0.1600\n",
            "t = 8, avg_loss = 0.2107\n",
            "t = 10, avg_loss = 0.1642\n",
            "t = 12, avg_loss = 0.1849\n",
            "t = 14, avg_loss = 0.1964\n",
            "t = 16, avg_loss = 0.2202\n",
            "t = 18, avg_loss = 0.2353\n",
            "t = 20, avg_loss = 0.2071\n",
            "t = 22, avg_loss = 0.2340\n",
            "t = 24, avg_loss = 0.2226\n",
            "Checking accuracy on test set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 22 / 100\n",
            "t = 2, avg_loss = 0.2457\n",
            "t = 4, avg_loss = 0.1531\n",
            "t = 6, avg_loss = 0.1980\n",
            "t = 8, avg_loss = 0.2251\n",
            "t = 10, avg_loss = 0.1895\n",
            "t = 12, avg_loss = 0.1886\n",
            "t = 14, avg_loss = 0.1628\n",
            "t = 16, avg_loss = 0.2321\n",
            "t = 18, avg_loss = 0.3080\n",
            "t = 20, avg_loss = 0.2162\n",
            "t = 22, avg_loss = 0.2841\n",
            "t = 24, avg_loss = 0.2659\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 23 / 100\n",
            "t = 2, avg_loss = 0.2665\n",
            "t = 4, avg_loss = 0.1814\n",
            "t = 6, avg_loss = 0.2332\n",
            "t = 8, avg_loss = 0.2108\n",
            "t = 10, avg_loss = 0.2349\n",
            "t = 12, avg_loss = 0.2158\n",
            "t = 14, avg_loss = 0.2913\n",
            "t = 16, avg_loss = 0.1831\n",
            "t = 18, avg_loss = 0.1596\n",
            "t = 20, avg_loss = 0.2124\n",
            "t = 22, avg_loss = 0.1748\n",
            "t = 24, avg_loss = 0.1582\n",
            "Checking accuracy on test set\n",
            "Got 341 / 400 correct (85.25)\n",
            "acc = 0.852500\n",
            "Starting epoch 24 / 100\n",
            "t = 2, avg_loss = 0.2423\n",
            "t = 4, avg_loss = 0.2506\n",
            "t = 6, avg_loss = 0.1402\n",
            "t = 8, avg_loss = 0.1848\n",
            "t = 10, avg_loss = 0.2067\n",
            "t = 12, avg_loss = 0.1521\n",
            "t = 14, avg_loss = 0.1879\n",
            "t = 16, avg_loss = 0.1903\n",
            "t = 18, avg_loss = 0.3222\n",
            "t = 20, avg_loss = 0.1543\n",
            "t = 22, avg_loss = 0.1586\n",
            "t = 24, avg_loss = 0.1599\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 25 / 100\n",
            "t = 2, avg_loss = 0.3072\n",
            "t = 4, avg_loss = 0.2157\n",
            "t = 6, avg_loss = 0.1417\n",
            "t = 8, avg_loss = 0.1888\n",
            "t = 10, avg_loss = 0.1198\n",
            "t = 12, avg_loss = 0.1790\n",
            "t = 14, avg_loss = 0.1208\n",
            "t = 16, avg_loss = 0.2169\n",
            "t = 18, avg_loss = 0.1439\n",
            "t = 20, avg_loss = 0.1554\n",
            "t = 22, avg_loss = 0.1586\n",
            "t = 24, avg_loss = 0.1645\n",
            "Checking accuracy on test set\n",
            "Got 351 / 400 correct (87.75)\n",
            "acc = 0.877500\n",
            "Starting epoch 26 / 100\n",
            "t = 2, avg_loss = 0.2186\n",
            "t = 4, avg_loss = 0.1271\n",
            "t = 6, avg_loss = 0.2019\n",
            "t = 8, avg_loss = 0.2041\n",
            "t = 10, avg_loss = 0.1449\n",
            "t = 12, avg_loss = 0.1638\n",
            "t = 14, avg_loss = 0.1133\n",
            "t = 16, avg_loss = 0.1833\n",
            "t = 18, avg_loss = 0.2266\n",
            "t = 20, avg_loss = 0.2612\n",
            "t = 22, avg_loss = 0.1477\n",
            "t = 24, avg_loss = 0.1443\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 27 / 100\n",
            "t = 2, avg_loss = 0.3000\n",
            "t = 4, avg_loss = 0.1659\n",
            "t = 6, avg_loss = 0.2016\n",
            "t = 8, avg_loss = 0.1193\n",
            "t = 10, avg_loss = 0.2164\n",
            "t = 12, avg_loss = 0.1491\n",
            "t = 14, avg_loss = 0.1550\n",
            "t = 16, avg_loss = 0.1696\n",
            "t = 18, avg_loss = 0.2009\n",
            "t = 20, avg_loss = 0.2596\n",
            "t = 22, avg_loss = 0.1119\n",
            "t = 24, avg_loss = 0.1708\n",
            "Checking accuracy on test set\n",
            "Got 343 / 400 correct (85.75)\n",
            "acc = 0.857500\n",
            "Starting epoch 28 / 100\n",
            "t = 2, avg_loss = 0.1995\n",
            "t = 4, avg_loss = 0.1237\n",
            "t = 6, avg_loss = 0.1864\n",
            "t = 8, avg_loss = 0.1818\n",
            "t = 10, avg_loss = 0.2017\n",
            "t = 12, avg_loss = 0.1574\n",
            "t = 14, avg_loss = 0.1815\n",
            "t = 16, avg_loss = 0.1784\n",
            "t = 18, avg_loss = 0.1685\n",
            "t = 20, avg_loss = 0.1715\n",
            "t = 22, avg_loss = 0.1812\n",
            "t = 24, avg_loss = 0.1397\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 29 / 100\n",
            "t = 2, avg_loss = 0.2648\n",
            "t = 4, avg_loss = 0.2040\n",
            "t = 6, avg_loss = 0.1242\n",
            "t = 8, avg_loss = 0.1841\n",
            "t = 10, avg_loss = 0.1225\n",
            "t = 12, avg_loss = 0.1797\n",
            "t = 14, avg_loss = 0.1667\n",
            "t = 16, avg_loss = 0.1478\n",
            "t = 18, avg_loss = 0.1747\n",
            "t = 20, avg_loss = 0.1891\n",
            "t = 22, avg_loss = 0.1382\n",
            "t = 24, avg_loss = 0.1890\n",
            "Checking accuracy on test set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 30 / 100\n",
            "t = 2, avg_loss = 0.3188\n",
            "t = 4, avg_loss = 0.2031\n",
            "t = 6, avg_loss = 0.1644\n",
            "t = 8, avg_loss = 0.1742\n",
            "t = 10, avg_loss = 0.1664\n",
            "t = 12, avg_loss = 0.1502\n",
            "t = 14, avg_loss = 0.1697\n",
            "t = 16, avg_loss = 0.2143\n",
            "t = 18, avg_loss = 0.1836\n",
            "t = 20, avg_loss = 0.1288\n",
            "t = 22, avg_loss = 0.1832\n",
            "t = 24, avg_loss = 0.1176\n",
            "Checking accuracy on test set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 31 / 100\n",
            "t = 2, avg_loss = 0.2728\n",
            "t = 4, avg_loss = 0.1692\n",
            "t = 6, avg_loss = 0.1850\n",
            "t = 8, avg_loss = 0.1365\n",
            "t = 10, avg_loss = 0.1501\n",
            "t = 12, avg_loss = 0.0960\n",
            "t = 14, avg_loss = 0.1928\n",
            "t = 16, avg_loss = 0.1966\n",
            "t = 18, avg_loss = 0.1421\n",
            "t = 20, avg_loss = 0.1592\n",
            "t = 22, avg_loss = 0.1423\n",
            "t = 24, avg_loss = 0.1832\n",
            "Checking accuracy on test set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 32 / 100\n",
            "t = 2, avg_loss = 0.1608\n",
            "t = 4, avg_loss = 0.1201\n",
            "t = 6, avg_loss = 0.1562\n",
            "t = 8, avg_loss = 0.1954\n",
            "t = 10, avg_loss = 0.1449\n",
            "t = 12, avg_loss = 0.1753\n",
            "t = 14, avg_loss = 0.1896\n",
            "t = 16, avg_loss = 0.2701\n",
            "t = 18, avg_loss = 0.1726\n",
            "t = 20, avg_loss = 0.1753\n",
            "t = 22, avg_loss = 0.1580\n",
            "t = 24, avg_loss = 0.1340\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 33 / 100\n",
            "t = 2, avg_loss = 0.2152\n",
            "t = 4, avg_loss = 0.1535\n",
            "t = 6, avg_loss = 0.1520\n",
            "t = 8, avg_loss = 0.1397\n",
            "t = 10, avg_loss = 0.1803\n",
            "t = 12, avg_loss = 0.1357\n",
            "t = 14, avg_loss = 0.2575\n",
            "t = 16, avg_loss = 0.1091\n",
            "t = 18, avg_loss = 0.1903\n",
            "t = 20, avg_loss = 0.1352\n",
            "t = 22, avg_loss = 0.1657\n",
            "t = 24, avg_loss = 0.1370\n",
            "Checking accuracy on test set\n",
            "Got 343 / 400 correct (85.75)\n",
            "acc = 0.857500\n",
            "Starting epoch 34 / 100\n",
            "t = 2, avg_loss = 0.1732\n",
            "t = 4, avg_loss = 0.1500\n",
            "t = 6, avg_loss = 0.1756\n",
            "t = 8, avg_loss = 0.1975\n",
            "t = 10, avg_loss = 0.1593\n",
            "t = 12, avg_loss = 0.0797\n",
            "t = 14, avg_loss = 0.1422\n",
            "t = 16, avg_loss = 0.2125\n",
            "t = 18, avg_loss = 0.2032\n",
            "t = 20, avg_loss = 0.1072\n",
            "t = 22, avg_loss = 0.1608\n",
            "t = 24, avg_loss = 0.1253\n",
            "Checking accuracy on test set\n",
            "Got 344 / 400 correct (86.00)\n",
            "acc = 0.860000\n",
            "Starting epoch 35 / 100\n",
            "t = 2, avg_loss = 0.2826\n",
            "t = 4, avg_loss = 0.1728\n",
            "t = 6, avg_loss = 0.1565\n",
            "t = 8, avg_loss = 0.1144\n",
            "t = 10, avg_loss = 0.2006\n",
            "t = 12, avg_loss = 0.1263\n",
            "t = 14, avg_loss = 0.1641\n",
            "t = 16, avg_loss = 0.1953\n",
            "t = 18, avg_loss = 0.1067\n",
            "t = 20, avg_loss = 0.1750\n",
            "t = 22, avg_loss = 0.2197\n",
            "t = 24, avg_loss = 0.1348\n",
            "Checking accuracy on test set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 36 / 100\n",
            "t = 2, avg_loss = 0.2272\n",
            "t = 4, avg_loss = 0.1295\n",
            "t = 6, avg_loss = 0.1187\n",
            "t = 8, avg_loss = 0.0887\n",
            "t = 10, avg_loss = 0.1406\n",
            "t = 12, avg_loss = 0.1437\n",
            "t = 14, avg_loss = 0.2054\n",
            "t = 16, avg_loss = 0.1816\n",
            "t = 18, avg_loss = 0.1260\n",
            "t = 20, avg_loss = 0.1414\n",
            "t = 22, avg_loss = 0.1063\n",
            "t = 24, avg_loss = 0.1134\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 37 / 100\n",
            "t = 2, avg_loss = 0.2585\n",
            "t = 4, avg_loss = 0.0974\n",
            "t = 6, avg_loss = 0.1466\n",
            "t = 8, avg_loss = 0.1019\n",
            "t = 10, avg_loss = 0.1238\n",
            "t = 12, avg_loss = 0.2393\n",
            "t = 14, avg_loss = 0.1427\n",
            "t = 16, avg_loss = 0.1566\n",
            "t = 18, avg_loss = 0.1387\n",
            "t = 20, avg_loss = 0.1099\n",
            "t = 22, avg_loss = 0.2023\n",
            "t = 24, avg_loss = 0.1344\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 38 / 100\n",
            "t = 2, avg_loss = 0.1432\n",
            "t = 4, avg_loss = 0.1441\n",
            "t = 6, avg_loss = 0.1482\n",
            "t = 8, avg_loss = 0.1171\n",
            "t = 10, avg_loss = 0.1215\n",
            "t = 12, avg_loss = 0.1918\n",
            "t = 14, avg_loss = 0.1504\n",
            "t = 16, avg_loss = 0.1057\n",
            "t = 18, avg_loss = 0.1539\n",
            "t = 20, avg_loss = 0.1593\n",
            "t = 22, avg_loss = 0.1125\n",
            "t = 24, avg_loss = 0.1438\n",
            "Checking accuracy on test set\n",
            "Got 346 / 400 correct (86.50)\n",
            "acc = 0.865000\n",
            "Starting epoch 39 / 100\n",
            "t = 2, avg_loss = 0.2040\n",
            "t = 4, avg_loss = 0.0904\n",
            "t = 6, avg_loss = 0.1820\n",
            "t = 8, avg_loss = 0.1114\n",
            "t = 10, avg_loss = 0.1600\n",
            "t = 12, avg_loss = 0.1681\n",
            "t = 14, avg_loss = 0.1383\n",
            "t = 16, avg_loss = 0.1224\n",
            "t = 18, avg_loss = 0.1583\n",
            "t = 20, avg_loss = 0.1702\n",
            "t = 22, avg_loss = 0.1483\n",
            "t = 24, avg_loss = 0.1460\n",
            "Checking accuracy on test set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 40 / 100\n",
            "t = 2, avg_loss = 0.2507\n",
            "t = 4, avg_loss = 0.0841\n",
            "t = 6, avg_loss = 0.1644\n",
            "t = 8, avg_loss = 0.1290\n",
            "t = 10, avg_loss = 0.1273\n",
            "t = 12, avg_loss = 0.1614\n",
            "t = 14, avg_loss = 0.1354\n",
            "t = 16, avg_loss = 0.1491\n",
            "t = 18, avg_loss = 0.1088\n",
            "t = 20, avg_loss = 0.1432\n",
            "t = 22, avg_loss = 0.1491\n",
            "t = 24, avg_loss = 0.1148\n",
            "Checking accuracy on test set\n",
            "Got 351 / 400 correct (87.75)\n",
            "acc = 0.877500\n",
            "Starting epoch 41 / 100\n",
            "t = 2, avg_loss = 0.1068\n",
            "t = 4, avg_loss = 0.1061\n",
            "t = 6, avg_loss = 0.1294\n",
            "t = 8, avg_loss = 0.1101\n",
            "t = 10, avg_loss = 0.1973\n",
            "t = 12, avg_loss = 0.1122\n",
            "t = 14, avg_loss = 0.0735\n",
            "t = 16, avg_loss = 0.1953\n",
            "t = 18, avg_loss = 0.2082\n",
            "t = 20, avg_loss = 0.1433\n",
            "t = 22, avg_loss = 0.1291\n",
            "t = 24, avg_loss = 0.1354\n",
            "Checking accuracy on test set\n",
            "Got 336 / 400 correct (84.00)\n",
            "acc = 0.840000\n",
            "Starting epoch 42 / 100\n",
            "t = 2, avg_loss = 0.2372\n",
            "t = 4, avg_loss = 0.1468\n",
            "t = 6, avg_loss = 0.1217\n",
            "t = 8, avg_loss = 0.0874\n",
            "t = 10, avg_loss = 0.1088\n",
            "t = 12, avg_loss = 0.1392\n",
            "t = 14, avg_loss = 0.0897\n",
            "t = 16, avg_loss = 0.1364\n",
            "t = 18, avg_loss = 0.1128\n",
            "t = 20, avg_loss = 0.1025\n",
            "t = 22, avg_loss = 0.1397\n",
            "t = 24, avg_loss = 0.0875\n",
            "Checking accuracy on test set\n",
            "Got 351 / 400 correct (87.75)\n",
            "acc = 0.877500\n",
            "Starting epoch 43 / 100\n",
            "t = 2, avg_loss = 0.1840\n",
            "t = 4, avg_loss = 0.1458\n",
            "t = 6, avg_loss = 0.1739\n",
            "t = 8, avg_loss = 0.1077\n",
            "t = 10, avg_loss = 0.1564\n",
            "t = 12, avg_loss = 0.1212\n",
            "t = 14, avg_loss = 0.1070\n",
            "t = 16, avg_loss = 0.1146\n",
            "t = 18, avg_loss = 0.1291\n",
            "t = 20, avg_loss = 0.2192\n",
            "t = 22, avg_loss = 0.1028\n",
            "t = 24, avg_loss = 0.1422\n",
            "Checking accuracy on test set\n",
            "Got 343 / 400 correct (85.75)\n",
            "acc = 0.857500\n",
            "Starting epoch 44 / 100\n",
            "t = 2, avg_loss = 0.1812\n",
            "t = 4, avg_loss = 0.1136\n",
            "t = 6, avg_loss = 0.1284\n",
            "t = 8, avg_loss = 0.1196\n",
            "t = 10, avg_loss = 0.1734\n",
            "t = 12, avg_loss = 0.1356\n",
            "t = 14, avg_loss = 0.1559\n",
            "t = 16, avg_loss = 0.1448\n",
            "t = 18, avg_loss = 0.1898\n",
            "t = 20, avg_loss = 0.2110\n",
            "t = 22, avg_loss = 0.1460\n",
            "t = 24, avg_loss = 0.1212\n",
            "Checking accuracy on test set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 45 / 100\n",
            "t = 2, avg_loss = 0.1422\n",
            "t = 4, avg_loss = 0.1080\n",
            "t = 6, avg_loss = 0.0702\n",
            "t = 8, avg_loss = 0.1037\n",
            "t = 10, avg_loss = 0.1372\n",
            "t = 12, avg_loss = 0.0917\n",
            "t = 14, avg_loss = 0.1146\n",
            "t = 16, avg_loss = 0.1310\n",
            "t = 18, avg_loss = 0.0884\n",
            "t = 20, avg_loss = 0.1381\n",
            "t = 22, avg_loss = 0.1415\n",
            "t = 24, avg_loss = 0.1256\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 46 / 100\n",
            "t = 2, avg_loss = 0.2165\n",
            "t = 4, avg_loss = 0.1354\n",
            "t = 6, avg_loss = 0.1649\n",
            "t = 8, avg_loss = 0.1299\n",
            "t = 10, avg_loss = 0.0876\n",
            "t = 12, avg_loss = 0.1236\n",
            "t = 14, avg_loss = 0.0814\n",
            "t = 16, avg_loss = 0.0951\n",
            "t = 18, avg_loss = 0.0818\n",
            "t = 20, avg_loss = 0.1454\n",
            "t = 22, avg_loss = 0.1546\n",
            "t = 24, avg_loss = 0.1670\n",
            "Checking accuracy on test set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 47 / 100\n",
            "t = 2, avg_loss = 0.1274\n",
            "t = 4, avg_loss = 0.0966\n",
            "t = 6, avg_loss = 0.1084\n",
            "t = 8, avg_loss = 0.0935\n",
            "t = 10, avg_loss = 0.1204\n",
            "t = 12, avg_loss = 0.0982\n",
            "t = 14, avg_loss = 0.1472\n",
            "t = 16, avg_loss = 0.1120\n",
            "t = 18, avg_loss = 0.0928\n",
            "t = 20, avg_loss = 0.1246\n",
            "t = 22, avg_loss = 0.2103\n",
            "t = 24, avg_loss = 0.1575\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 48 / 100\n",
            "t = 2, avg_loss = 0.1389\n",
            "t = 4, avg_loss = 0.1381\n",
            "t = 6, avg_loss = 0.0836\n",
            "t = 8, avg_loss = 0.2298\n",
            "t = 10, avg_loss = 0.1180\n",
            "t = 12, avg_loss = 0.1144\n",
            "t = 14, avg_loss = 0.1451\n",
            "t = 16, avg_loss = 0.0974\n",
            "t = 18, avg_loss = 0.0800\n",
            "t = 20, avg_loss = 0.1424\n",
            "t = 22, avg_loss = 0.0838\n",
            "t = 24, avg_loss = 0.1099\n",
            "Checking accuracy on test set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 49 / 100\n",
            "t = 2, avg_loss = 0.1649\n",
            "t = 4, avg_loss = 0.0634\n",
            "t = 6, avg_loss = 0.1424\n",
            "t = 8, avg_loss = 0.1741\n",
            "t = 10, avg_loss = 0.1224\n",
            "t = 12, avg_loss = 0.1020\n",
            "t = 14, avg_loss = 0.1305\n",
            "t = 16, avg_loss = 0.1273\n",
            "t = 18, avg_loss = 0.0850\n",
            "t = 20, avg_loss = 0.1060\n",
            "t = 22, avg_loss = 0.0929\n",
            "t = 24, avg_loss = 0.0877\n",
            "Checking accuracy on test set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 50 / 100\n",
            "t = 2, avg_loss = 0.1823\n",
            "t = 4, avg_loss = 0.1141\n",
            "t = 6, avg_loss = 0.0939\n",
            "t = 8, avg_loss = 0.0998\n",
            "t = 10, avg_loss = 0.1164\n",
            "t = 12, avg_loss = 0.1380\n",
            "t = 14, avg_loss = 0.1387\n",
            "t = 16, avg_loss = 0.1001\n",
            "t = 18, avg_loss = 0.1356\n",
            "t = 20, avg_loss = 0.0690\n",
            "t = 22, avg_loss = 0.1721\n",
            "t = 24, avg_loss = 0.1365\n",
            "Checking accuracy on test set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 51 / 100\n",
            "t = 2, avg_loss = 0.1177\n",
            "t = 4, avg_loss = 0.1440\n",
            "t = 6, avg_loss = 0.0971\n",
            "t = 8, avg_loss = 0.1763\n",
            "t = 10, avg_loss = 0.0774\n",
            "t = 12, avg_loss = 0.1306\n",
            "t = 14, avg_loss = 0.0800\n",
            "t = 16, avg_loss = 0.1374\n",
            "t = 18, avg_loss = 0.0667\n",
            "t = 20, avg_loss = 0.1162\n",
            "t = 22, avg_loss = 0.0765\n",
            "t = 24, avg_loss = 0.1496\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 52 / 100\n",
            "t = 2, avg_loss = 0.1345\n",
            "t = 4, avg_loss = 0.1212\n",
            "t = 6, avg_loss = 0.1168\n",
            "t = 8, avg_loss = 0.0687\n",
            "t = 10, avg_loss = 0.1246\n",
            "t = 12, avg_loss = 0.0832\n",
            "t = 14, avg_loss = 0.0971\n",
            "t = 16, avg_loss = 0.1016\n",
            "t = 18, avg_loss = 0.0930\n",
            "t = 20, avg_loss = 0.1240\n",
            "t = 22, avg_loss = 0.0622\n",
            "t = 24, avg_loss = 0.1516\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 53 / 100\n",
            "t = 2, avg_loss = 0.1549\n",
            "t = 4, avg_loss = 0.1399\n",
            "t = 6, avg_loss = 0.1357\n",
            "t = 8, avg_loss = 0.0852\n",
            "t = 10, avg_loss = 0.0659\n",
            "t = 12, avg_loss = 0.0935\n",
            "t = 14, avg_loss = 0.0817\n",
            "t = 16, avg_loss = 0.0904\n",
            "t = 18, avg_loss = 0.0972\n",
            "t = 20, avg_loss = 0.1172\n",
            "t = 22, avg_loss = 0.0937\n",
            "t = 24, avg_loss = 0.1184\n",
            "Checking accuracy on test set\n",
            "Got 340 / 400 correct (85.00)\n",
            "acc = 0.850000\n",
            "Starting epoch 54 / 100\n",
            "t = 2, avg_loss = 0.1866\n",
            "t = 4, avg_loss = 0.0992\n",
            "t = 6, avg_loss = 0.0789\n",
            "t = 8, avg_loss = 0.1280\n",
            "t = 10, avg_loss = 0.0761\n",
            "t = 12, avg_loss = 0.1358\n",
            "t = 14, avg_loss = 0.1143\n",
            "t = 16, avg_loss = 0.1355\n",
            "t = 18, avg_loss = 0.0973\n",
            "t = 20, avg_loss = 0.1910\n",
            "t = 22, avg_loss = 0.0991\n",
            "t = 24, avg_loss = 0.0946\n",
            "Checking accuracy on test set\n",
            "Got 344 / 400 correct (86.00)\n",
            "acc = 0.860000\n",
            "Starting epoch 55 / 100\n",
            "t = 2, avg_loss = 0.1399\n",
            "t = 4, avg_loss = 0.0776\n",
            "t = 6, avg_loss = 0.1485\n",
            "t = 8, avg_loss = 0.1417\n",
            "t = 10, avg_loss = 0.0958\n",
            "t = 12, avg_loss = 0.1729\n",
            "t = 14, avg_loss = 0.0822\n",
            "t = 16, avg_loss = 0.0945\n",
            "t = 18, avg_loss = 0.1122\n",
            "t = 20, avg_loss = 0.0981\n",
            "t = 22, avg_loss = 0.1058\n",
            "t = 24, avg_loss = 0.1415\n",
            "Checking accuracy on test set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 56 / 100\n",
            "t = 2, avg_loss = 0.1200\n",
            "t = 4, avg_loss = 0.0721\n",
            "t = 6, avg_loss = 0.0974\n",
            "t = 8, avg_loss = 0.0892\n",
            "t = 10, avg_loss = 0.0986\n",
            "t = 12, avg_loss = 0.1065\n",
            "t = 14, avg_loss = 0.1121\n",
            "t = 16, avg_loss = 0.1003\n",
            "t = 18, avg_loss = 0.1134\n",
            "t = 20, avg_loss = 0.1206\n",
            "t = 22, avg_loss = 0.0851\n",
            "t = 24, avg_loss = 0.1199\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 57 / 100\n",
            "t = 2, avg_loss = 0.1371\n",
            "t = 4, avg_loss = 0.0951\n",
            "t = 6, avg_loss = 0.0950\n",
            "t = 8, avg_loss = 0.0912\n",
            "t = 10, avg_loss = 0.0546\n",
            "t = 12, avg_loss = 0.0839\n",
            "t = 14, avg_loss = 0.0930\n",
            "t = 16, avg_loss = 0.1084\n",
            "t = 18, avg_loss = 0.0716\n",
            "t = 20, avg_loss = 0.0936\n",
            "t = 22, avg_loss = 0.0931\n",
            "t = 24, avg_loss = 0.1226\n",
            "Checking accuracy on test set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 58 / 100\n",
            "t = 2, avg_loss = 0.1454\n",
            "t = 4, avg_loss = 0.0918\n",
            "t = 6, avg_loss = 0.1289\n",
            "t = 8, avg_loss = 0.0871\n",
            "t = 10, avg_loss = 0.0738\n",
            "t = 12, avg_loss = 0.1227\n",
            "t = 14, avg_loss = 0.1411\n",
            "t = 16, avg_loss = 0.0940\n",
            "t = 18, avg_loss = 0.0778\n",
            "t = 20, avg_loss = 0.0477\n",
            "t = 22, avg_loss = 0.1368\n",
            "t = 24, avg_loss = 0.1226\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 59 / 100\n",
            "t = 2, avg_loss = 0.1121\n",
            "t = 4, avg_loss = 0.0857\n",
            "t = 6, avg_loss = 0.0600\n",
            "t = 8, avg_loss = 0.0936\n",
            "t = 10, avg_loss = 0.1305\n",
            "t = 12, avg_loss = 0.0665\n",
            "t = 14, avg_loss = 0.0887\n",
            "t = 16, avg_loss = 0.0799\n",
            "t = 18, avg_loss = 0.0775\n",
            "t = 20, avg_loss = 0.0783\n",
            "t = 22, avg_loss = 0.0949\n",
            "t = 24, avg_loss = 0.0997\n",
            "Checking accuracy on test set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 60 / 100\n",
            "t = 2, avg_loss = 0.1478\n",
            "t = 4, avg_loss = 0.0348\n",
            "t = 6, avg_loss = 0.0569\n",
            "t = 8, avg_loss = 0.1384\n",
            "t = 10, avg_loss = 0.0543\n",
            "t = 12, avg_loss = 0.0596\n",
            "t = 14, avg_loss = 0.1040\n",
            "t = 16, avg_loss = 0.0847\n",
            "t = 18, avg_loss = 0.0974\n",
            "t = 20, avg_loss = 0.0980\n",
            "t = 22, avg_loss = 0.1042\n",
            "t = 24, avg_loss = 0.0364\n",
            "Checking accuracy on test set\n",
            "Got 346 / 400 correct (86.50)\n",
            "acc = 0.865000\n",
            "Starting epoch 61 / 100\n",
            "t = 2, avg_loss = 0.1154\n",
            "t = 4, avg_loss = 0.1368\n",
            "t = 6, avg_loss = 0.1099\n",
            "t = 8, avg_loss = 0.1586\n",
            "t = 10, avg_loss = 0.0852\n",
            "t = 12, avg_loss = 0.0894\n",
            "t = 14, avg_loss = 0.0849\n",
            "t = 16, avg_loss = 0.1115\n",
            "t = 18, avg_loss = 0.0657\n",
            "t = 20, avg_loss = 0.1187\n",
            "t = 22, avg_loss = 0.0771\n",
            "t = 24, avg_loss = 0.1287\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 62 / 100\n",
            "t = 2, avg_loss = 0.1641\n",
            "t = 4, avg_loss = 0.0666\n",
            "t = 6, avg_loss = 0.1484\n",
            "t = 8, avg_loss = 0.0821\n",
            "t = 10, avg_loss = 0.0809\n",
            "t = 12, avg_loss = 0.0563\n",
            "t = 14, avg_loss = 0.0793\n",
            "t = 16, avg_loss = 0.1076\n",
            "t = 18, avg_loss = 0.1536\n",
            "t = 20, avg_loss = 0.0868\n",
            "t = 22, avg_loss = 0.0867\n",
            "t = 24, avg_loss = 0.1572\n",
            "Checking accuracy on test set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 63 / 100\n",
            "t = 2, avg_loss = 0.1852\n",
            "t = 4, avg_loss = 0.0940\n",
            "t = 6, avg_loss = 0.0915\n",
            "t = 8, avg_loss = 0.1126\n",
            "t = 10, avg_loss = 0.1109\n",
            "t = 12, avg_loss = 0.1308\n",
            "t = 14, avg_loss = 0.1141\n",
            "t = 16, avg_loss = 0.0889\n",
            "t = 18, avg_loss = 0.0727\n",
            "t = 20, avg_loss = 0.0927\n",
            "t = 22, avg_loss = 0.1630\n",
            "t = 24, avg_loss = 0.1473\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 64 / 100\n",
            "t = 2, avg_loss = 0.1864\n",
            "t = 4, avg_loss = 0.0698\n",
            "t = 6, avg_loss = 0.0588\n",
            "t = 8, avg_loss = 0.0750\n",
            "t = 10, avg_loss = 0.1664\n",
            "t = 12, avg_loss = 0.1576\n",
            "t = 14, avg_loss = 0.1258\n",
            "t = 16, avg_loss = 0.1012\n",
            "t = 18, avg_loss = 0.0861\n",
            "t = 20, avg_loss = 0.0848\n",
            "t = 22, avg_loss = 0.1476\n",
            "t = 24, avg_loss = 0.1149\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 65 / 100\n",
            "t = 2, avg_loss = 0.1557\n",
            "t = 4, avg_loss = 0.0689\n",
            "t = 6, avg_loss = 0.1291\n",
            "t = 8, avg_loss = 0.0983\n",
            "t = 10, avg_loss = 0.0758\n",
            "t = 12, avg_loss = 0.0731\n",
            "t = 14, avg_loss = 0.0814\n",
            "t = 16, avg_loss = 0.1240\n",
            "t = 18, avg_loss = 0.1052\n",
            "t = 20, avg_loss = 0.1165\n",
            "t = 22, avg_loss = 0.0845\n",
            "t = 24, avg_loss = 0.1074\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 66 / 100\n",
            "t = 2, avg_loss = 0.1236\n",
            "t = 4, avg_loss = 0.0911\n",
            "t = 6, avg_loss = 0.0695\n",
            "t = 8, avg_loss = 0.0445\n",
            "t = 10, avg_loss = 0.0437\n",
            "t = 12, avg_loss = 0.0522\n",
            "t = 14, avg_loss = 0.1133\n",
            "t = 16, avg_loss = 0.0606\n",
            "t = 18, avg_loss = 0.0736\n",
            "t = 20, avg_loss = 0.0719\n",
            "t = 22, avg_loss = 0.1077\n",
            "t = 24, avg_loss = 0.0575\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 67 / 100\n",
            "t = 2, avg_loss = 0.1301\n",
            "t = 4, avg_loss = 0.0646\n",
            "t = 6, avg_loss = 0.0572\n",
            "t = 8, avg_loss = 0.1260\n",
            "t = 10, avg_loss = 0.1050\n",
            "t = 12, avg_loss = 0.0914\n",
            "t = 14, avg_loss = 0.0677\n",
            "t = 16, avg_loss = 0.1000\n",
            "t = 18, avg_loss = 0.0886\n",
            "t = 20, avg_loss = 0.1103\n",
            "t = 22, avg_loss = 0.0571\n",
            "t = 24, avg_loss = 0.0913\n",
            "Checking accuracy on test set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 68 / 100\n",
            "t = 2, avg_loss = 0.0889\n",
            "t = 4, avg_loss = 0.0783\n",
            "t = 6, avg_loss = 0.0699\n",
            "t = 8, avg_loss = 0.0609\n",
            "t = 10, avg_loss = 0.0583\n",
            "t = 12, avg_loss = 0.0828\n",
            "t = 14, avg_loss = 0.0650\n",
            "t = 16, avg_loss = 0.0895\n",
            "t = 18, avg_loss = 0.1181\n",
            "t = 20, avg_loss = 0.0331\n",
            "t = 22, avg_loss = 0.0802\n",
            "t = 24, avg_loss = 0.0885\n",
            "Checking accuracy on test set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 69 / 100\n",
            "t = 2, avg_loss = 0.1468\n",
            "t = 4, avg_loss = 0.0730\n",
            "t = 6, avg_loss = 0.0658\n",
            "t = 8, avg_loss = 0.0769\n",
            "t = 10, avg_loss = 0.0742\n",
            "t = 12, avg_loss = 0.1032\n",
            "t = 14, avg_loss = 0.0960\n",
            "t = 16, avg_loss = 0.0650\n",
            "t = 18, avg_loss = 0.1002\n",
            "t = 20, avg_loss = 0.1415\n",
            "t = 22, avg_loss = 0.0536\n",
            "t = 24, avg_loss = 0.0868\n",
            "Checking accuracy on test set\n",
            "Got 344 / 400 correct (86.00)\n",
            "acc = 0.860000\n",
            "Starting epoch 70 / 100\n",
            "t = 2, avg_loss = 0.1431\n",
            "t = 4, avg_loss = 0.0802\n",
            "t = 6, avg_loss = 0.0748\n",
            "t = 8, avg_loss = 0.0840\n",
            "t = 10, avg_loss = 0.0598\n",
            "t = 12, avg_loss = 0.0844\n",
            "t = 14, avg_loss = 0.0630\n",
            "t = 16, avg_loss = 0.1288\n",
            "t = 18, avg_loss = 0.0657\n",
            "t = 20, avg_loss = 0.1246\n",
            "t = 22, avg_loss = 0.0635\n",
            "t = 24, avg_loss = 0.0676\n",
            "Checking accuracy on test set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 71 / 100\n",
            "t = 2, avg_loss = 0.0955\n",
            "t = 4, avg_loss = 0.0931\n",
            "t = 6, avg_loss = 0.0456\n",
            "t = 8, avg_loss = 0.0399\n",
            "t = 10, avg_loss = 0.0503\n",
            "t = 12, avg_loss = 0.0840\n",
            "t = 14, avg_loss = 0.0959\n",
            "t = 16, avg_loss = 0.0464\n",
            "t = 18, avg_loss = 0.1009\n",
            "t = 20, avg_loss = 0.0771\n",
            "t = 22, avg_loss = 0.0477\n",
            "t = 24, avg_loss = 0.0741\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 72 / 100\n",
            "t = 2, avg_loss = 0.1162\n",
            "t = 4, avg_loss = 0.0563\n",
            "t = 6, avg_loss = 0.0430\n",
            "t = 8, avg_loss = 0.0584\n",
            "t = 10, avg_loss = 0.0588\n",
            "t = 12, avg_loss = 0.0782\n",
            "t = 14, avg_loss = 0.0631\n",
            "t = 16, avg_loss = 0.1166\n",
            "t = 18, avg_loss = 0.1466\n",
            "t = 20, avg_loss = 0.0610\n",
            "t = 22, avg_loss = 0.1206\n",
            "t = 24, avg_loss = 0.0717\n",
            "Checking accuracy on test set\n",
            "Got 346 / 400 correct (86.50)\n",
            "acc = 0.865000\n",
            "Starting epoch 73 / 100\n",
            "t = 2, avg_loss = 0.1190\n",
            "t = 4, avg_loss = 0.0684\n",
            "t = 6, avg_loss = 0.0622\n",
            "t = 8, avg_loss = 0.0853\n",
            "t = 10, avg_loss = 0.0787\n",
            "t = 12, avg_loss = 0.0355\n",
            "t = 14, avg_loss = 0.0741\n",
            "t = 16, avg_loss = 0.0530\n",
            "t = 18, avg_loss = 0.0405\n",
            "t = 20, avg_loss = 0.0686\n",
            "t = 22, avg_loss = 0.0755\n",
            "t = 24, avg_loss = 0.0639\n",
            "Checking accuracy on test set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 74 / 100\n",
            "t = 2, avg_loss = 0.1090\n",
            "t = 4, avg_loss = 0.0404\n",
            "t = 6, avg_loss = 0.0281\n",
            "t = 8, avg_loss = 0.0969\n",
            "t = 10, avg_loss = 0.1080\n",
            "t = 12, avg_loss = 0.0563\n",
            "t = 14, avg_loss = 0.0774\n",
            "t = 16, avg_loss = 0.0942\n",
            "t = 18, avg_loss = 0.0464\n",
            "t = 20, avg_loss = 0.0700\n",
            "t = 22, avg_loss = 0.0929\n",
            "t = 24, avg_loss = 0.0730\n",
            "Checking accuracy on test set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 75 / 100\n",
            "t = 2, avg_loss = 0.1418\n",
            "t = 4, avg_loss = 0.0720\n",
            "t = 6, avg_loss = 0.0744\n",
            "t = 8, avg_loss = 0.0649\n",
            "t = 10, avg_loss = 0.0709\n",
            "t = 12, avg_loss = 0.0531\n",
            "t = 14, avg_loss = 0.1041\n",
            "t = 16, avg_loss = 0.0569\n",
            "t = 18, avg_loss = 0.0901\n",
            "t = 20, avg_loss = 0.1145\n",
            "t = 22, avg_loss = 0.0850\n",
            "t = 24, avg_loss = 0.0969\n",
            "Checking accuracy on test set\n",
            "Got 346 / 400 correct (86.50)\n",
            "acc = 0.865000\n",
            "Starting epoch 76 / 100\n",
            "t = 2, avg_loss = 0.1790\n",
            "t = 4, avg_loss = 0.0572\n",
            "t = 6, avg_loss = 0.0828\n",
            "t = 8, avg_loss = 0.1097\n",
            "t = 10, avg_loss = 0.0536\n",
            "t = 12, avg_loss = 0.0851\n",
            "t = 14, avg_loss = 0.0659\n",
            "t = 16, avg_loss = 0.0828\n",
            "t = 18, avg_loss = 0.1270\n",
            "t = 20, avg_loss = 0.0721\n",
            "t = 22, avg_loss = 0.0844\n",
            "t = 24, avg_loss = 0.0945\n",
            "Checking accuracy on test set\n",
            "Got 345 / 400 correct (86.25)\n",
            "acc = 0.862500\n",
            "Starting epoch 77 / 100\n",
            "t = 2, avg_loss = 0.0855\n",
            "t = 4, avg_loss = 0.0719\n",
            "t = 6, avg_loss = 0.0882\n",
            "t = 8, avg_loss = 0.0423\n",
            "t = 10, avg_loss = 0.0742\n",
            "t = 12, avg_loss = 0.0775\n",
            "t = 14, avg_loss = 0.0816\n",
            "t = 16, avg_loss = 0.0692\n",
            "t = 18, avg_loss = 0.0546\n",
            "t = 20, avg_loss = 0.1018\n",
            "t = 22, avg_loss = 0.0683\n",
            "t = 24, avg_loss = 0.0535\n",
            "Checking accuracy on test set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 78 / 100\n",
            "t = 2, avg_loss = 0.1213\n",
            "t = 4, avg_loss = 0.0798\n",
            "t = 6, avg_loss = 0.0515\n",
            "t = 8, avg_loss = 0.0499\n",
            "t = 10, avg_loss = 0.1092\n",
            "t = 12, avg_loss = 0.0540\n",
            "t = 14, avg_loss = 0.0504\n",
            "t = 16, avg_loss = 0.0941\n",
            "t = 18, avg_loss = 0.0359\n",
            "t = 20, avg_loss = 0.1227\n",
            "t = 22, avg_loss = 0.0508\n",
            "t = 24, avg_loss = 0.0505\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 79 / 100\n",
            "t = 2, avg_loss = 0.0728\n",
            "t = 4, avg_loss = 0.0870\n",
            "t = 6, avg_loss = 0.1531\n",
            "t = 8, avg_loss = 0.0942\n",
            "t = 10, avg_loss = 0.0504\n",
            "t = 12, avg_loss = 0.0878\n",
            "t = 14, avg_loss = 0.0543\n",
            "t = 16, avg_loss = 0.0851\n",
            "t = 18, avg_loss = 0.1174\n",
            "t = 20, avg_loss = 0.0995\n",
            "t = 22, avg_loss = 0.0751\n",
            "t = 24, avg_loss = 0.0953\n",
            "Checking accuracy on test set\n",
            "Got 346 / 400 correct (86.50)\n",
            "acc = 0.865000\n",
            "Starting epoch 80 / 100\n",
            "t = 2, avg_loss = 0.1716\n",
            "t = 4, avg_loss = 0.0671\n",
            "t = 6, avg_loss = 0.0350\n",
            "t = 8, avg_loss = 0.0734\n",
            "t = 10, avg_loss = 0.0950\n",
            "t = 12, avg_loss = 0.0937\n",
            "t = 14, avg_loss = 0.0914\n",
            "t = 16, avg_loss = 0.0568\n",
            "t = 18, avg_loss = 0.0715\n",
            "t = 20, avg_loss = 0.0877\n",
            "t = 22, avg_loss = 0.1080\n",
            "t = 24, avg_loss = 0.0611\n",
            "Checking accuracy on test set\n",
            "Got 346 / 400 correct (86.50)\n",
            "acc = 0.865000\n",
            "Starting epoch 81 / 100\n",
            "t = 2, avg_loss = 0.1355\n",
            "t = 4, avg_loss = 0.0709\n",
            "t = 6, avg_loss = 0.0694\n",
            "t = 8, avg_loss = 0.0994\n",
            "t = 10, avg_loss = 0.0708\n",
            "t = 12, avg_loss = 0.0575\n",
            "t = 14, avg_loss = 0.0859\n",
            "t = 16, avg_loss = 0.0660\n",
            "t = 18, avg_loss = 0.0872\n",
            "t = 20, avg_loss = 0.0445\n",
            "t = 22, avg_loss = 0.1000\n",
            "t = 24, avg_loss = 0.0972\n",
            "Checking accuracy on test set\n",
            "Got 344 / 400 correct (86.00)\n",
            "acc = 0.860000\n",
            "Starting epoch 82 / 100\n",
            "t = 2, avg_loss = 0.1329\n",
            "t = 4, avg_loss = 0.0612\n",
            "t = 6, avg_loss = 0.0768\n",
            "t = 8, avg_loss = 0.0684\n",
            "t = 10, avg_loss = 0.0760\n",
            "t = 12, avg_loss = 0.0811\n",
            "t = 14, avg_loss = 0.1093\n",
            "t = 16, avg_loss = 0.0866\n",
            "t = 18, avg_loss = 0.0380\n",
            "t = 20, avg_loss = 0.0798\n",
            "t = 22, avg_loss = 0.0803\n",
            "t = 24, avg_loss = 0.1190\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 83 / 100\n",
            "t = 2, avg_loss = 0.1007\n",
            "t = 4, avg_loss = 0.1011\n",
            "t = 6, avg_loss = 0.0562\n",
            "t = 8, avg_loss = 0.1021\n",
            "t = 10, avg_loss = 0.0769\n",
            "t = 12, avg_loss = 0.0775\n",
            "t = 14, avg_loss = 0.0992\n",
            "t = 16, avg_loss = 0.0583\n",
            "t = 18, avg_loss = 0.0557\n",
            "t = 20, avg_loss = 0.0799\n",
            "t = 22, avg_loss = 0.0521\n",
            "t = 24, avg_loss = 0.0913\n",
            "Checking accuracy on test set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 84 / 100\n",
            "t = 2, avg_loss = 0.1664\n",
            "t = 4, avg_loss = 0.0978\n",
            "t = 6, avg_loss = 0.0759\n",
            "t = 8, avg_loss = 0.1219\n",
            "t = 10, avg_loss = 0.0945\n",
            "t = 12, avg_loss = 0.0584\n",
            "t = 14, avg_loss = 0.0927\n",
            "t = 16, avg_loss = 0.1316\n",
            "t = 18, avg_loss = 0.0691\n",
            "t = 20, avg_loss = 0.0517\n",
            "t = 22, avg_loss = 0.0997\n",
            "t = 24, avg_loss = 0.1035\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 85 / 100\n",
            "t = 2, avg_loss = 0.1597\n",
            "t = 4, avg_loss = 0.0375\n",
            "t = 6, avg_loss = 0.0910\n",
            "t = 8, avg_loss = 0.0555\n",
            "t = 10, avg_loss = 0.0758\n",
            "t = 12, avg_loss = 0.0587\n",
            "t = 14, avg_loss = 0.0676\n",
            "t = 16, avg_loss = 0.0997\n",
            "t = 18, avg_loss = 0.0650\n",
            "t = 20, avg_loss = 0.0704\n",
            "t = 22, avg_loss = 0.0772\n",
            "t = 24, avg_loss = 0.0438\n",
            "Checking accuracy on test set\n",
            "Got 351 / 400 correct (87.75)\n",
            "acc = 0.877500\n",
            "Starting epoch 86 / 100\n",
            "t = 2, avg_loss = 0.0851\n",
            "t = 4, avg_loss = 0.0439\n",
            "t = 6, avg_loss = 0.0743\n",
            "t = 8, avg_loss = 0.0677\n",
            "t = 10, avg_loss = 0.0867\n",
            "t = 12, avg_loss = 0.0854\n",
            "t = 14, avg_loss = 0.0435\n",
            "t = 16, avg_loss = 0.0823\n",
            "t = 18, avg_loss = 0.0955\n",
            "t = 20, avg_loss = 0.0636\n",
            "t = 22, avg_loss = 0.0513\n",
            "t = 24, avg_loss = 0.0824\n",
            "Checking accuracy on test set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 87 / 100\n",
            "t = 2, avg_loss = 0.1067\n",
            "t = 4, avg_loss = 0.0488\n",
            "t = 6, avg_loss = 0.0768\n",
            "t = 8, avg_loss = 0.0973\n",
            "t = 10, avg_loss = 0.0708\n",
            "t = 12, avg_loss = 0.0697\n",
            "t = 14, avg_loss = 0.0607\n",
            "t = 16, avg_loss = 0.0741\n",
            "t = 18, avg_loss = 0.0868\n",
            "t = 20, avg_loss = 0.0604\n",
            "t = 22, avg_loss = 0.0963\n",
            "t = 24, avg_loss = 0.0632\n",
            "Checking accuracy on test set\n",
            "Got 360 / 400 correct (90.00)\n",
            "acc = 0.900000\n",
            "Starting epoch 88 / 100\n",
            "t = 2, avg_loss = 0.1120\n",
            "t = 4, avg_loss = 0.0659\n",
            "t = 6, avg_loss = 0.0839\n",
            "t = 8, avg_loss = 0.0468\n",
            "t = 10, avg_loss = 0.0764\n",
            "t = 12, avg_loss = 0.0537\n",
            "t = 14, avg_loss = 0.0610\n",
            "t = 16, avg_loss = 0.0477\n",
            "t = 18, avg_loss = 0.0787\n",
            "t = 20, avg_loss = 0.0594\n",
            "t = 22, avg_loss = 0.0353\n",
            "t = 24, avg_loss = 0.0736\n",
            "Checking accuracy on test set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 89 / 100\n",
            "t = 2, avg_loss = 0.0850\n",
            "t = 4, avg_loss = 0.0427\n",
            "t = 6, avg_loss = 0.0541\n",
            "t = 8, avg_loss = 0.0685\n",
            "t = 10, avg_loss = 0.0997\n",
            "t = 12, avg_loss = 0.0875\n",
            "t = 14, avg_loss = 0.0408\n",
            "t = 16, avg_loss = 0.0631\n",
            "t = 18, avg_loss = 0.0628\n",
            "t = 20, avg_loss = 0.0364\n",
            "t = 22, avg_loss = 0.0550\n",
            "t = 24, avg_loss = 0.0537\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 90 / 100\n",
            "t = 2, avg_loss = 0.1101\n",
            "t = 4, avg_loss = 0.0715\n",
            "t = 6, avg_loss = 0.0756\n",
            "t = 8, avg_loss = 0.0528\n",
            "t = 10, avg_loss = 0.0896\n",
            "t = 12, avg_loss = 0.0600\n",
            "t = 14, avg_loss = 0.0363\n",
            "t = 16, avg_loss = 0.0593\n",
            "t = 18, avg_loss = 0.0352\n",
            "t = 20, avg_loss = 0.0480\n",
            "t = 22, avg_loss = 0.0862\n",
            "t = 24, avg_loss = 0.0464\n",
            "Checking accuracy on test set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 91 / 100\n",
            "t = 2, avg_loss = 0.0602\n",
            "t = 4, avg_loss = 0.0478\n",
            "t = 6, avg_loss = 0.0337\n",
            "t = 8, avg_loss = 0.0861\n",
            "t = 10, avg_loss = 0.0422\n",
            "t = 12, avg_loss = 0.0576\n",
            "t = 14, avg_loss = 0.0540\n",
            "t = 16, avg_loss = 0.0623\n",
            "t = 18, avg_loss = 0.0270\n",
            "t = 20, avg_loss = 0.0310\n",
            "t = 22, avg_loss = 0.0529\n",
            "t = 24, avg_loss = 0.1066\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 92 / 100\n",
            "t = 2, avg_loss = 0.0830\n",
            "t = 4, avg_loss = 0.0584\n",
            "t = 6, avg_loss = 0.0690\n",
            "t = 8, avg_loss = 0.0484\n",
            "t = 10, avg_loss = 0.0524\n",
            "t = 12, avg_loss = 0.0708\n",
            "t = 14, avg_loss = 0.0625\n",
            "t = 16, avg_loss = 0.0551\n",
            "t = 18, avg_loss = 0.0583\n",
            "t = 20, avg_loss = 0.0981\n",
            "t = 22, avg_loss = 0.0803\n",
            "t = 24, avg_loss = 0.0518\n",
            "Checking accuracy on test set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 93 / 100\n",
            "t = 2, avg_loss = 0.1184\n",
            "t = 4, avg_loss = 0.0578\n",
            "t = 6, avg_loss = 0.0944\n",
            "t = 8, avg_loss = 0.0779\n",
            "t = 10, avg_loss = 0.0655\n",
            "t = 12, avg_loss = 0.0697\n",
            "t = 14, avg_loss = 0.0754\n",
            "t = 16, avg_loss = 0.0638\n",
            "t = 18, avg_loss = 0.0642\n",
            "t = 20, avg_loss = 0.0783\n",
            "t = 22, avg_loss = 0.0513\n",
            "t = 24, avg_loss = 0.0355\n",
            "Checking accuracy on test set\n",
            "Got 345 / 400 correct (86.25)\n",
            "acc = 0.862500\n",
            "Starting epoch 94 / 100\n",
            "t = 2, avg_loss = 0.1038\n",
            "t = 4, avg_loss = 0.0843\n",
            "t = 6, avg_loss = 0.0338\n",
            "t = 8, avg_loss = 0.0704\n",
            "t = 10, avg_loss = 0.0505\n",
            "t = 12, avg_loss = 0.0564\n",
            "t = 14, avg_loss = 0.0448\n",
            "t = 16, avg_loss = 0.0521\n",
            "t = 18, avg_loss = 0.0506\n",
            "t = 20, avg_loss = 0.0210\n",
            "t = 22, avg_loss = 0.0668\n",
            "t = 24, avg_loss = 0.0664\n",
            "Checking accuracy on test set\n",
            "Got 358 / 400 correct (89.50)\n",
            "acc = 0.895000\n",
            "Starting epoch 95 / 100\n",
            "t = 2, avg_loss = 0.0663\n",
            "t = 4, avg_loss = 0.0672\n",
            "t = 6, avg_loss = 0.0680\n",
            "t = 8, avg_loss = 0.0247\n",
            "t = 10, avg_loss = 0.0470\n",
            "t = 12, avg_loss = 0.0331\n",
            "t = 14, avg_loss = 0.0435\n",
            "t = 16, avg_loss = 0.0308\n",
            "t = 18, avg_loss = 0.0737\n",
            "t = 20, avg_loss = 0.0571\n",
            "t = 22, avg_loss = 0.0617\n",
            "t = 24, avg_loss = 0.0273\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 96 / 100\n",
            "t = 2, avg_loss = 0.1167\n",
            "t = 4, avg_loss = 0.0578\n",
            "t = 6, avg_loss = 0.1165\n",
            "t = 8, avg_loss = 0.0397\n",
            "t = 10, avg_loss = 0.0640\n",
            "t = 12, avg_loss = 0.0495\n",
            "t = 14, avg_loss = 0.0596\n",
            "t = 16, avg_loss = 0.0588\n",
            "t = 18, avg_loss = 0.1064\n",
            "t = 20, avg_loss = 0.0646\n",
            "t = 22, avg_loss = 0.0711\n",
            "t = 24, avg_loss = 0.0465\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 97 / 100\n",
            "t = 2, avg_loss = 0.1125\n",
            "t = 4, avg_loss = 0.0849\n",
            "t = 6, avg_loss = 0.0720\n",
            "t = 8, avg_loss = 0.0585\n",
            "t = 10, avg_loss = 0.0489\n",
            "t = 12, avg_loss = 0.0796\n",
            "t = 14, avg_loss = 0.1372\n",
            "t = 16, avg_loss = 0.1076\n",
            "t = 18, avg_loss = 0.1009\n",
            "t = 20, avg_loss = 0.0774\n",
            "t = 22, avg_loss = 0.0768\n",
            "t = 24, avg_loss = 0.0428\n",
            "Checking accuracy on test set\n",
            "Got 359 / 400 correct (89.75)\n",
            "acc = 0.897500\n",
            "Starting epoch 98 / 100\n",
            "t = 2, avg_loss = 0.0739\n",
            "t = 4, avg_loss = 0.0738\n",
            "t = 6, avg_loss = 0.0443\n",
            "t = 8, avg_loss = 0.0614\n",
            "t = 10, avg_loss = 0.0761\n",
            "t = 12, avg_loss = 0.0403\n",
            "t = 14, avg_loss = 0.0358\n",
            "t = 16, avg_loss = 0.0665\n",
            "t = 18, avg_loss = 0.0534\n",
            "t = 20, avg_loss = 0.0404\n",
            "t = 22, avg_loss = 0.0856\n",
            "t = 24, avg_loss = 0.0345\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 99 / 100\n",
            "t = 2, avg_loss = 0.1230\n",
            "t = 4, avg_loss = 0.0645\n",
            "t = 6, avg_loss = 0.0662\n",
            "t = 8, avg_loss = 0.0290\n",
            "t = 10, avg_loss = 0.0626\n",
            "t = 12, avg_loss = 0.0363\n",
            "t = 14, avg_loss = 0.0283\n",
            "t = 16, avg_loss = 0.0472\n",
            "t = 18, avg_loss = 0.0477\n",
            "t = 20, avg_loss = 0.0327\n",
            "t = 22, avg_loss = 0.0413\n",
            "t = 24, avg_loss = 0.0441\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 100 / 100\n",
            "t = 2, avg_loss = 0.0303\n",
            "t = 4, avg_loss = 0.0365\n",
            "t = 6, avg_loss = 0.0434\n",
            "t = 8, avg_loss = 0.0938\n",
            "t = 10, avg_loss = 0.0377\n",
            "t = 12, avg_loss = 0.0690\n",
            "t = 14, avg_loss = 0.0393\n",
            "t = 16, avg_loss = 0.0199\n",
            "t = 18, avg_loss = 0.0886\n",
            "t = 20, avg_loss = 0.0628\n",
            "t = 22, avg_loss = 0.0599\n",
            "t = 24, avg_loss = 0.0431\n",
            "Checking accuracy on test set\n",
            "Got 343 / 400 correct (85.75)\n",
            "acc = 0.857500\n",
            "Checking accuracy on test set\n",
            "Got 335 / 400 correct (83.75)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8375"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "US4sjopDuPdh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "f1f6fbba-b7ea-4f8a-ba65-f5ffc508bd7d"
      },
      "source": [
        "check_accuracy(model_gpu, valid_loader)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking accuracy on test set\n",
            "Got 346 / 400 correct (86.50)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.865"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvoCj5uscUsz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_accurancy(acc_list):\n",
        "  plt.plot([i+1 for i in range((len(acc_list)))],acc_list)\n",
        "  print(\"Accurancy:\")\n",
        "  plt.show()\n",
        "\n",
        "def plot_loss_function(avg_loss_list):\n",
        "  plt.plot([print_every*batch_size*(i+1) for i in range((len(avg_loss_list)))],avg_loss_list)\n",
        "  print(\"Loss:\")\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-Co5KBw-Yy4",
        "colab_type": "code",
        "outputId": "110e565a-f8fe-4b91-f3d2-07936be006d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        }
      },
      "source": [
        "plot_accurancy(acc_list)\n",
        "plot_loss_function(avg_loss_list)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accurancy:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzuX5gLEeJfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def retry_from_backup():\n",
        "  model_gpu = model_base.type(gpu_dtype)\n",
        "  print(model_gpu)\n",
        "  loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) \n",
        "\n",
        "\n",
        "\n",
        "  checkpoint = torch.load(model_backup_path)\n",
        "  model_gpu.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  epoch = checkpoint['epoch']\n",
        "  loss = checkpoint['loss']\n",
        "  acc_list = checkpoint['acc_list']\n",
        "  #avg_loss_list = checkpoint['avg_loss_list']\n",
        "  print(\"starting from epoch: \" + str(epoch))\n",
        "  print(\"starting from loss: \" + str(loss))\n",
        "  print(acc_list)\n",
        "  \n",
        "  \n",
        "  train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=27, starting_from_epoch=epoch)\n",
        "  check_accuracy(model_gpu, valid_loader)\n",
        "\n",
        "  plot_accurancy(acc_list)\n",
        "  plot_loss_function(avg_loss_list)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfT0jtaruhtg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--rQZKqOalaJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#retry_from_backup()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}