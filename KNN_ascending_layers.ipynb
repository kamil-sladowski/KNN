{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN_ascending_layers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPGbPp79x0ZihaKI0mhwkbT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamilo116/KNN/blob/master/KNN_ascending_layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7ReM7FU-xs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import sys\n",
        "from random import shuffle\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "np.random.seed(4) \n",
        "torch.manual_seed(4) \n",
        "torch.cuda.manual_seed(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYIMZ8QyYewD",
        "colab_type": "code",
        "outputId": "20c009e6-26c5-4140-b2c0-0eb94e78cfd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! git clone https://github.com/wang-chen/kervolution.git \n",
        "\n",
        "sys.path.append(\"kervolution/\")\n",
        "from kervolution import Kerv2d\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'kervolution' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMOHez_kHZD6",
        "colab_type": "code",
        "outputId": "28ae394e-2239-4d00-cc23-5245bf028d05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvbKg4VJXKY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LIMIT_IMAGES_NUM = 1000\n",
        "train_test_split_size = 0.2\n",
        "image_resize = (100, 100)\n",
        "batch_size = 64\n",
        "num_workers = 0\n",
        "\n",
        "out_1 = 16\n",
        "out_2 = 32\n",
        "out_3 = 64\n",
        "out_4 = 100\n",
        "\n",
        "\n",
        "k_size_1 = 3\n",
        "padding_1 = 1\n",
        "in_channels = 3\n",
        "\n",
        "kernel_size = 3\n",
        "num_epochs = 80\n",
        "\n",
        "learning_rate = 0.0001\n",
        "weight_decay = 0.05\n",
        "\n",
        "MALIGNANT_DATASET = '/content/drive/My Drive/Colab_data/malignant/malignant/'\n",
        "BENIGN_DATASET = '/content/drive/My Drive/Colab_data/benign/benign/'\n",
        "DATA_FOLDER = '/content/drive/My Drive/Colab_data/'\n",
        "model_backup_path = os.path.join(DATA_FOLDER, 'backup_model') \n",
        "TRAIN_DATA_PER_CATEGORY = 101"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b8P1NdXfVdX",
        "colab_type": "code",
        "outputId": "ee79d6ec-614e-4695-809b-419056f129a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "benign_train_list = sorted(os.listdir(BENIGN_DATASET))[:LIMIT_IMAGES_NUM]\n",
        "malignant_train_list = sorted(os.listdir(MALIGNANT_DATASET))[:LIMIT_IMAGES_NUM]\n",
        "\n",
        "shuffle(benign_train_list)\n",
        "shuffle(malignant_train_list)\n",
        "\n",
        "test_benign_file_list = os.listdir(BENIGN_DATASET + 'test_set')[:TRAIN_DATA_PER_CATEGORY]\n",
        "test_malignant_file_list = os.listdir(MALIGNANT_DATASET + 'test_set')[:TRAIN_DATA_PER_CATEGORY]\n",
        "\n",
        "print(f\"Number of training benign {len(benign_train_list)} images\")\n",
        "print(f\"Number of training malignant {len(malignant_train_list)} images\")\n",
        "print(f\"Number of test benign {len(test_benign_file_list)} images\")\n",
        "print(f\"Number of test malignant {len(test_malignant_file_list)} images\")\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize(image_resize),\n",
        "    # transforms.RandomSizedCrop(224),\n",
        "    #transform.Affine(rotation_range=45,translation_range =0.1),\n",
        "    #transforms.RandomRotation(45),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "data_transforms_test = transforms.Compose([\n",
        "    transforms.Resize(image_resize),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training benign 1000 images\n",
            "Number of training malignant 1000 images\n",
            "Number of test benign 101 images\n",
            "Number of test malignant 101 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvAAOqmVfVll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IsicDataset(Dataset):\n",
        "    def __init__(self, data_folder, labeled_data, \n",
        "                 transform=transforms.Compose([transforms.ToTensor()]), datatype='train'):\n",
        "        self.labeled_data = labeled_data\n",
        "        self.transform = transform\n",
        "        self.data_folder = data_folder\n",
        "        self.datatype = datatype\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labeled_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        label = self.labeled_data[index]\n",
        "        test_set = ''\n",
        "        if self.datatype == 'test':\n",
        "          test_set = 'test_set' \n",
        "        if label == 0:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"benign\", \"benign\", test_set, index ))\n",
        "        else:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"malignant\", \"malignant\", test_set, index ))\n",
        "        image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "    @property\n",
        "    def labels(self):\n",
        "      return self.labeled_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e8nFBR6Yug5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "def prepare_dataset(benign_file_list, malignant_file_list, transform, datatype='train'):\n",
        "  benign_dict = {filename: 0 for filename in benign_file_list}\n",
        "  malignant_dict = {filename: 1 for filename in malignant_file_list}\n",
        "  img_class_dict = {**benign_dict , **malignant_dict}\n",
        "  labeled_data = pd.Series(img_class_dict)\n",
        "\n",
        "  dataset = IsicDataset(DATA_FOLDER, labeled_data, transform=transform, datatype=datatype)\n",
        "  print(dataset.labels)\n",
        "  return dataset\n",
        "\n",
        "def train(model, train_loader ,loss_fn, optimizer, num_epochs=1, starting_from_epoch=1):\n",
        "    total_loss =0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Starting epoch %d / %d' % (epoch + starting_from_epoch, num_epochs + starting_from_epoch - 1))\n",
        "        model.train()\n",
        "\n",
        "        for t, (x, y) in enumerate(train_loader):\n",
        "            x_var = Variable(x.type(gpu_dtype))\n",
        "            y_var = Variable(y.type(gpu_dtype).long())\n",
        "            scores = model(x_var)\n",
        "            loss = loss_fn(scores, y_var)\n",
        "            total_loss += loss.data\n",
        "            \n",
        "            if (t + 1) % print_every == 0:\n",
        "                avg_loss = total_loss/print_every\n",
        "                print('t = %d, avg_loss = %.4f' % (t + 1, avg_loss) )\n",
        "                avg_loss_list.append(avg_loss)\n",
        "                total_loss = 0\n",
        "                \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        acc = check_accuracy(model_gpu, valid_loader)\n",
        "        print('acc = %f' %(acc))\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model_gpu.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            'acc_list': acc_list,\n",
        "            }, model_backup_path)\n",
        "            \n",
        "def check_accuracy(model, loader, datatype='train'):\n",
        "    print(f'Checking accuracy on {datatype} set')   \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval() \n",
        "    for x, y in loader:\n",
        "        x_var = Variable(x.type(gpu_dtype))\n",
        "\n",
        "        scores = model(x_var)\n",
        "        _, preds = scores.data.cpu().max(1)\n",
        "        num_correct += (preds == y).sum()\n",
        "        num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    if datatype is 'train':\n",
        "      acc_list.append(acc)\n",
        "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "    return acc\n",
        "    \n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.size()\n",
        "        return x.view(N, -1)  \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSuYqjLAYrWA",
        "colab_type": "code",
        "outputId": "5d03913e-e995-4435-d1d7-099d342f71ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "train_dataset = prepare_dataset(benign_train_list, malignant_train_list, data_transforms, datatype='train')\n",
        "\n",
        "X_train, X_valid = train_test_split(train_dataset.labels, test_size=train_test_split_size)\n",
        "\n",
        "print(\"number of training data: \",len(X_train))\n",
        "print(\"number of valid  data: \",len(X_valid))\n",
        "\n",
        "\n",
        "train_sampler = SubsetRandomSampler(list(X_train.index))\n",
        "valid_sampler = SubsetRandomSampler(list(X_valid.index))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ISIC_0000678.jpeg    0\n",
            "ISIC_0002734.jpeg    0\n",
            "ISIC_0000372.jpeg    0\n",
            "ISIC_0000017.jpeg    0\n",
            "ISIC_0000079.jpeg    0\n",
            "                    ..\n",
            "ISIC_0010145.jpeg    1\n",
            "ISIC_0015180.jpeg    1\n",
            "ISIC_0014072.jpeg    1\n",
            "ISIC_0014187.jpeg    1\n",
            "ISIC_0000446.jpeg    1\n",
            "Length: 2000, dtype: int64\n",
            "number of training data:  1600\n",
            "number of valid  data:  400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XSwl3mRsU36",
        "colab_type": "code",
        "outputId": "7f60e412-872f-4e11-a48b-8aa460bd59f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "test_dataset = prepare_dataset(test_benign_file_list, test_malignant_file_list, data_transforms_test, datatype='test')\n",
        "test_part, _ = train_test_split(test_dataset.labels, test_size=1)\n",
        "test_sampler = SubsetRandomSampler(list(test_part.index))\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=50, sampler=test_sampler, num_workers=num_workers)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ISIC_0000081.jpeg    0\n",
            "ISIC_0000033.jpeg    0\n",
            "ISIC_0000023.jpeg    0\n",
            "ISIC_0000137.jpeg    0\n",
            "ISIC_0000073.jpeg    0\n",
            "                    ..\n",
            "ISIC_0025783.jpg     1\n",
            "ISIC_0026604.jpg     1\n",
            "ISIC_0026754.jpg     1\n",
            "ISIC_0026847.jpg     1\n",
            "ISIC_0027060.jpg     1\n",
            "Length: 202, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-gYHw0Jlbwt",
        "colab_type": "code",
        "outputId": "3e308c4b-40bb-401c-c561-d17a98078b93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "print_every = 1\n",
        "gpu_dtype = torch.cuda.FloatTensor\n",
        "\n",
        "\n",
        "'''\n",
        "Kerv2d\n",
        "kervolution with following options:\n",
        "kernel_type: [linear, polynomial, gaussian, etc.]\n",
        "default is convolution:\n",
        "          kernel_type --> linear,\n",
        "balance, power, gamma is valid only when the kernel_type is specified\n",
        "if learnable_kernel = True,  they just be the initial value of learable parameters\n",
        "if learnable_kernel = False, they are the value of kernel_type's parameter\n",
        "the parameter [power] cannot be learned due to integer limitation\n",
        "dilation (int or tuple, optional): Spacing between kernel\n",
        "elements. Default: 1\n",
        "groups (int, optional): Number of blocked connections from input\n",
        "channels to output channels. Default: 1\n",
        "bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n",
        "kernel_type (str), Default: 'linear'\n",
        "learnable_kernel (bool): Learnable kernel parameters.  Default: False \n",
        "balance: [0:1]\n",
        "power: 2, 3, 4, 5\n",
        "gamma: [0:1]\n",
        "'''\n",
        "\n",
        "\n",
        "model_base = nn.Sequential( \n",
        "                #nn.Conv2d(in_channels , out_1, padding= padding_1, kernel_size=k_size_1, stride=1),\n",
        "                nn.Kerv2d(in_channels , out_1, padding=padding_1, bias=True, \n",
        "                          kernel_type='polynomial', kernel_size=3, learnable_kernel=True,\n",
        "                          kernel_regularizer=True, stride=1, balance=1, power=2, gamma=1\n",
        "                          ), \n",
        "                #nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_1),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_1 , out_2, padding= padding_1, kernel_size=k_size_1, stride=1), \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_2),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                #nn.Conv2d(out_2 , out_3, padding= padding_1, kernel_size=k_size_1, stride=1),  \n",
        "                nn.Kerv2d(out_2 , out_3, padding=padding_1, bias=True, \n",
        "                          kernel_type='polynomial', kernel_size=4, learnable_kernel=True,\n",
        "                          kernel_regularizer=True, stride=1, balance=1, power=3, gamma=1\n",
        "                          ), \n",
        "                #nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_3),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_3 , out_4, padding= padding_1, kernel_size=9, stride=1),  \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_4),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Dropout(0.5),\n",
        "                Flatten(),\n",
        "                nn.Linear(900,64),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Linear(64,2)\n",
        "            )\n",
        "model_gpu = model_base.type(gpu_dtype)\n",
        "print(model_gpu)\n",
        "loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Kerv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (4): ReLU(inplace=True)\n",
            "  (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (7): Kerv2d(32, 64, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
            "  (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (10): Conv2d(64, 100, kernel_size=(9, 9), stride=(1, 1), padding=(1, 1))\n",
            "  (11): ReLU(inplace=True)\n",
            "  (12): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (14): Dropout(p=0.5, inplace=False)\n",
            "  (15): Flatten()\n",
            "  (16): Linear(in_features=900, out_features=64, bias=True)\n",
            "  (17): ReLU(inplace=True)\n",
            "  (18): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgmexhBRZAK6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "86a99a0f-adc1-4bc7-8d63-a0f76223f687"
      },
      "source": [
        "train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 1 / 80\n",
            "t = 1, avg_loss = 0.7059\n",
            "t = 2, avg_loss = 0.6538\n",
            "t = 3, avg_loss = 0.5905\n",
            "t = 4, avg_loss = 0.6724\n",
            "t = 5, avg_loss = 0.6246\n",
            "t = 6, avg_loss = 0.6183\n",
            "t = 7, avg_loss = 0.5047\n",
            "t = 8, avg_loss = 0.5572\n",
            "t = 9, avg_loss = 0.6049\n",
            "t = 10, avg_loss = 0.5407\n",
            "t = 11, avg_loss = 0.5930\n",
            "t = 12, avg_loss = 0.5838\n",
            "t = 13, avg_loss = 0.5796\n",
            "t = 14, avg_loss = 0.4936\n",
            "t = 15, avg_loss = 0.5295\n",
            "t = 16, avg_loss = 0.5546\n",
            "t = 17, avg_loss = 0.6065\n",
            "t = 18, avg_loss = 0.5239\n",
            "t = 19, avg_loss = 0.4834\n",
            "t = 20, avg_loss = 0.5740\n",
            "t = 21, avg_loss = 0.5760\n",
            "t = 22, avg_loss = 0.4930\n",
            "t = 23, avg_loss = 0.5663\n",
            "t = 24, avg_loss = 0.4882\n",
            "t = 25, avg_loss = 0.5263\n",
            "Checking accuracy on train set\n",
            "Got 237 / 400 correct (59.25)\n",
            "acc = 0.592500\n",
            "Starting epoch 2 / 80\n",
            "t = 1, avg_loss = 0.4650\n",
            "t = 2, avg_loss = 0.4119\n",
            "t = 3, avg_loss = 0.5498\n",
            "t = 4, avg_loss = 0.5510\n",
            "t = 5, avg_loss = 0.5005\n",
            "t = 6, avg_loss = 0.4879\n",
            "t = 7, avg_loss = 0.5004\n",
            "t = 8, avg_loss = 0.4224\n",
            "t = 9, avg_loss = 0.5095\n",
            "t = 10, avg_loss = 0.4817\n",
            "t = 11, avg_loss = 0.4744\n",
            "t = 12, avg_loss = 0.5229\n",
            "t = 13, avg_loss = 0.5235\n",
            "t = 14, avg_loss = 0.4335\n",
            "t = 15, avg_loss = 0.5682\n",
            "t = 16, avg_loss = 0.4295\n",
            "t = 17, avg_loss = 0.5099\n",
            "t = 18, avg_loss = 0.5334\n",
            "t = 19, avg_loss = 0.4725\n",
            "t = 20, avg_loss = 0.4132\n",
            "t = 21, avg_loss = 0.4047\n",
            "t = 22, avg_loss = 0.3643\n",
            "t = 23, avg_loss = 0.3264\n",
            "t = 24, avg_loss = 0.4476\n",
            "t = 25, avg_loss = 0.3538\n",
            "Checking accuracy on train set\n",
            "Got 312 / 400 correct (78.00)\n",
            "acc = 0.780000\n",
            "Starting epoch 3 / 80\n",
            "t = 1, avg_loss = 0.4852\n",
            "t = 2, avg_loss = 0.4930\n",
            "t = 3, avg_loss = 0.4579\n",
            "t = 4, avg_loss = 0.3249\n",
            "t = 5, avg_loss = 0.3382\n",
            "t = 6, avg_loss = 0.4584\n",
            "t = 7, avg_loss = 0.3053\n",
            "t = 8, avg_loss = 0.3951\n",
            "t = 9, avg_loss = 0.3394\n",
            "t = 10, avg_loss = 0.4105\n",
            "t = 11, avg_loss = 0.4170\n",
            "t = 12, avg_loss = 0.5634\n",
            "t = 13, avg_loss = 0.2757\n",
            "t = 14, avg_loss = 0.4253\n",
            "t = 15, avg_loss = 0.3466\n",
            "t = 16, avg_loss = 0.3964\n",
            "t = 17, avg_loss = 0.4385\n",
            "t = 18, avg_loss = 0.3680\n",
            "t = 19, avg_loss = 0.4255\n",
            "t = 20, avg_loss = 0.3670\n",
            "t = 21, avg_loss = 0.4504\n",
            "t = 22, avg_loss = 0.3588\n",
            "t = 23, avg_loss = 0.3981\n",
            "t = 24, avg_loss = 0.3262\n",
            "t = 25, avg_loss = 0.3629\n",
            "Checking accuracy on train set\n",
            "Got 336 / 400 correct (84.00)\n",
            "acc = 0.840000\n",
            "Starting epoch 4 / 80\n",
            "t = 1, avg_loss = 0.3616\n",
            "t = 2, avg_loss = 0.4004\n",
            "t = 3, avg_loss = 0.3851\n",
            "t = 4, avg_loss = 0.4679\n",
            "t = 5, avg_loss = 0.3080\n",
            "t = 6, avg_loss = 0.3332\n",
            "t = 7, avg_loss = 0.3125\n",
            "t = 8, avg_loss = 0.3848\n",
            "t = 9, avg_loss = 0.3934\n",
            "t = 10, avg_loss = 0.4820\n",
            "t = 11, avg_loss = 0.4129\n",
            "t = 12, avg_loss = 0.3307\n",
            "t = 13, avg_loss = 0.3892\n",
            "t = 14, avg_loss = 0.4469\n",
            "t = 15, avg_loss = 0.3851\n",
            "t = 16, avg_loss = 0.4245\n",
            "t = 17, avg_loss = 0.3709\n",
            "t = 18, avg_loss = 0.3016\n",
            "t = 19, avg_loss = 0.4505\n",
            "t = 20, avg_loss = 0.4074\n",
            "t = 21, avg_loss = 0.3751\n",
            "t = 22, avg_loss = 0.4515\n",
            "t = 23, avg_loss = 0.3769\n",
            "t = 24, avg_loss = 0.4035\n",
            "t = 25, avg_loss = 0.3780\n",
            "Checking accuracy on train set\n",
            "Got 344 / 400 correct (86.00)\n",
            "acc = 0.860000\n",
            "Starting epoch 5 / 80\n",
            "t = 1, avg_loss = 0.4268\n",
            "t = 2, avg_loss = 0.3355\n",
            "t = 3, avg_loss = 0.3919\n",
            "t = 4, avg_loss = 0.2331\n",
            "t = 5, avg_loss = 0.3561\n",
            "t = 6, avg_loss = 0.4701\n",
            "t = 7, avg_loss = 0.4012\n",
            "t = 8, avg_loss = 0.3395\n",
            "t = 9, avg_loss = 0.3484\n",
            "t = 10, avg_loss = 0.2342\n",
            "t = 11, avg_loss = 0.3087\n",
            "t = 12, avg_loss = 0.3933\n",
            "t = 13, avg_loss = 0.3759\n",
            "t = 14, avg_loss = 0.3465\n",
            "t = 15, avg_loss = 0.3265\n",
            "t = 16, avg_loss = 0.2754\n",
            "t = 17, avg_loss = 0.4011\n",
            "t = 18, avg_loss = 0.4101\n",
            "t = 19, avg_loss = 0.3978\n",
            "t = 20, avg_loss = 0.3607\n",
            "t = 21, avg_loss = 0.3431\n",
            "t = 22, avg_loss = 0.3248\n",
            "t = 23, avg_loss = 0.4367\n",
            "t = 24, avg_loss = 0.3711\n",
            "t = 25, avg_loss = 0.3362\n",
            "Checking accuracy on train set\n",
            "Got 332 / 400 correct (83.00)\n",
            "acc = 0.830000\n",
            "Starting epoch 6 / 80\n",
            "t = 1, avg_loss = 0.3125\n",
            "t = 2, avg_loss = 0.3106\n",
            "t = 3, avg_loss = 0.3051\n",
            "t = 4, avg_loss = 0.4299\n",
            "t = 5, avg_loss = 0.3538\n",
            "t = 6, avg_loss = 0.3130\n",
            "t = 7, avg_loss = 0.3891\n",
            "t = 8, avg_loss = 0.2907\n",
            "t = 9, avg_loss = 0.2571\n",
            "t = 10, avg_loss = 0.3972\n",
            "t = 11, avg_loss = 0.3570\n",
            "t = 12, avg_loss = 0.3027\n",
            "t = 13, avg_loss = 0.4236\n",
            "t = 14, avg_loss = 0.2980\n",
            "t = 15, avg_loss = 0.3172\n",
            "t = 16, avg_loss = 0.2795\n",
            "t = 17, avg_loss = 0.3535\n",
            "t = 18, avg_loss = 0.3903\n",
            "t = 19, avg_loss = 0.2693\n",
            "t = 20, avg_loss = 0.2937\n",
            "t = 21, avg_loss = 0.2430\n",
            "t = 22, avg_loss = 0.2912\n",
            "t = 23, avg_loss = 0.3164\n",
            "t = 24, avg_loss = 0.4496\n",
            "t = 25, avg_loss = 0.4291\n",
            "Checking accuracy on train set\n",
            "Got 339 / 400 correct (84.75)\n",
            "acc = 0.847500\n",
            "Starting epoch 7 / 80\n",
            "t = 1, avg_loss = 0.2995\n",
            "t = 2, avg_loss = 0.3032\n",
            "t = 3, avg_loss = 0.2050\n",
            "t = 4, avg_loss = 0.3723\n",
            "t = 5, avg_loss = 0.3735\n",
            "t = 6, avg_loss = 0.3662\n",
            "t = 7, avg_loss = 0.2818\n",
            "t = 8, avg_loss = 0.3533\n",
            "t = 9, avg_loss = 0.4411\n",
            "t = 10, avg_loss = 0.2942\n",
            "t = 11, avg_loss = 0.3777\n",
            "t = 12, avg_loss = 0.2942\n",
            "t = 13, avg_loss = 0.4124\n",
            "t = 14, avg_loss = 0.4289\n",
            "t = 15, avg_loss = 0.2520\n",
            "t = 16, avg_loss = 0.2836\n",
            "t = 17, avg_loss = 0.3235\n",
            "t = 18, avg_loss = 0.3035\n",
            "t = 19, avg_loss = 0.2614\n",
            "t = 20, avg_loss = 0.2233\n",
            "t = 21, avg_loss = 0.2891\n",
            "t = 22, avg_loss = 0.2504\n",
            "t = 23, avg_loss = 0.3437\n",
            "t = 24, avg_loss = 0.3523\n",
            "t = 25, avg_loss = 0.2277\n",
            "Checking accuracy on train set\n",
            "Got 338 / 400 correct (84.50)\n",
            "acc = 0.845000\n",
            "Starting epoch 8 / 80\n",
            "t = 1, avg_loss = 0.2420\n",
            "t = 2, avg_loss = 0.2847\n",
            "t = 3, avg_loss = 0.3329\n",
            "t = 4, avg_loss = 0.3069\n",
            "t = 5, avg_loss = 0.4393\n",
            "t = 6, avg_loss = 0.2949\n",
            "t = 7, avg_loss = 0.2796\n",
            "t = 8, avg_loss = 0.2984\n",
            "t = 9, avg_loss = 0.2924\n",
            "t = 10, avg_loss = 0.3177\n",
            "t = 11, avg_loss = 0.2590\n",
            "t = 12, avg_loss = 0.3289\n",
            "t = 13, avg_loss = 0.2318\n",
            "t = 14, avg_loss = 0.3887\n",
            "t = 15, avg_loss = 0.3345\n",
            "t = 16, avg_loss = 0.3783\n",
            "t = 17, avg_loss = 0.3015\n",
            "t = 18, avg_loss = 0.3731\n",
            "t = 19, avg_loss = 0.3054\n",
            "t = 20, avg_loss = 0.2953\n",
            "t = 21, avg_loss = 0.2633\n",
            "t = 22, avg_loss = 0.2763\n",
            "t = 23, avg_loss = 0.2451\n",
            "t = 24, avg_loss = 0.2689\n",
            "t = 25, avg_loss = 0.3202\n",
            "Checking accuracy on train set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 9 / 80\n",
            "t = 1, avg_loss = 0.2132\n",
            "t = 2, avg_loss = 0.2538\n",
            "t = 3, avg_loss = 0.3243\n",
            "t = 4, avg_loss = 0.4209\n",
            "t = 5, avg_loss = 0.2278\n",
            "t = 6, avg_loss = 0.3368\n",
            "t = 7, avg_loss = 0.2635\n",
            "t = 8, avg_loss = 0.2933\n",
            "t = 9, avg_loss = 0.3117\n",
            "t = 10, avg_loss = 0.2173\n",
            "t = 11, avg_loss = 0.2403\n",
            "t = 12, avg_loss = 0.3330\n",
            "t = 13, avg_loss = 0.2999\n",
            "t = 14, avg_loss = 0.3880\n",
            "t = 15, avg_loss = 0.3000\n",
            "t = 16, avg_loss = 0.2856\n",
            "t = 17, avg_loss = 0.3200\n",
            "t = 18, avg_loss = 0.2629\n",
            "t = 19, avg_loss = 0.3518\n",
            "t = 20, avg_loss = 0.4357\n",
            "t = 21, avg_loss = 0.2935\n",
            "t = 22, avg_loss = 0.3534\n",
            "t = 23, avg_loss = 0.3533\n",
            "t = 24, avg_loss = 0.2575\n",
            "t = 25, avg_loss = 0.2764\n",
            "Checking accuracy on train set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 10 / 80\n",
            "t = 1, avg_loss = 0.2252\n",
            "t = 2, avg_loss = 0.2003\n",
            "t = 3, avg_loss = 0.2988\n",
            "t = 4, avg_loss = 0.2202\n",
            "t = 5, avg_loss = 0.2210\n",
            "t = 6, avg_loss = 0.2821\n",
            "t = 7, avg_loss = 0.3070\n",
            "t = 8, avg_loss = 0.3939\n",
            "t = 9, avg_loss = 0.3008\n",
            "t = 10, avg_loss = 0.2581\n",
            "t = 11, avg_loss = 0.2862\n",
            "t = 12, avg_loss = 0.2352\n",
            "t = 13, avg_loss = 0.2713\n",
            "t = 14, avg_loss = 0.3109\n",
            "t = 15, avg_loss = 0.3431\n",
            "t = 16, avg_loss = 0.2529\n",
            "t = 17, avg_loss = 0.2716\n",
            "t = 18, avg_loss = 0.3732\n",
            "t = 19, avg_loss = 0.2354\n",
            "t = 20, avg_loss = 0.2598\n",
            "t = 21, avg_loss = 0.3035\n",
            "t = 22, avg_loss = 0.4280\n",
            "t = 23, avg_loss = 0.2659\n",
            "t = 24, avg_loss = 0.2125\n",
            "t = 25, avg_loss = 0.3244\n",
            "Checking accuracy on train set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 11 / 80\n",
            "t = 1, avg_loss = 0.3410\n",
            "t = 2, avg_loss = 0.2568\n",
            "t = 3, avg_loss = 0.3796\n",
            "t = 4, avg_loss = 0.2218\n",
            "t = 5, avg_loss = 0.2697\n",
            "t = 6, avg_loss = 0.3654\n",
            "t = 7, avg_loss = 0.2741\n",
            "t = 8, avg_loss = 0.3012\n",
            "t = 9, avg_loss = 0.2594\n",
            "t = 10, avg_loss = 0.2714\n",
            "t = 11, avg_loss = 0.3457\n",
            "t = 12, avg_loss = 0.3520\n",
            "t = 13, avg_loss = 0.1432\n",
            "t = 14, avg_loss = 0.2349\n",
            "t = 15, avg_loss = 0.3326\n",
            "t = 16, avg_loss = 0.2831\n",
            "t = 17, avg_loss = 0.2573\n",
            "t = 18, avg_loss = 0.3313\n",
            "t = 19, avg_loss = 0.3563\n",
            "t = 20, avg_loss = 0.1747\n",
            "t = 21, avg_loss = 0.3460\n",
            "t = 22, avg_loss = 0.2666\n",
            "t = 23, avg_loss = 0.1699\n",
            "t = 24, avg_loss = 0.2552\n",
            "t = 25, avg_loss = 0.1668\n",
            "Checking accuracy on train set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 12 / 80\n",
            "t = 1, avg_loss = 0.3210\n",
            "t = 2, avg_loss = 0.1805\n",
            "t = 3, avg_loss = 0.3415\n",
            "t = 4, avg_loss = 0.2384\n",
            "t = 5, avg_loss = 0.3014\n",
            "t = 6, avg_loss = 0.2144\n",
            "t = 7, avg_loss = 0.2005\n",
            "t = 8, avg_loss = 0.2202\n",
            "t = 9, avg_loss = 0.2884\n",
            "t = 10, avg_loss = 0.1704\n",
            "t = 11, avg_loss = 0.2622\n",
            "t = 12, avg_loss = 0.2331\n",
            "t = 13, avg_loss = 0.3184\n",
            "t = 14, avg_loss = 0.2987\n",
            "t = 15, avg_loss = 0.2685\n",
            "t = 16, avg_loss = 0.2184\n",
            "t = 17, avg_loss = 0.2831\n",
            "t = 18, avg_loss = 0.3661\n",
            "t = 19, avg_loss = 0.2691\n",
            "t = 20, avg_loss = 0.3632\n",
            "t = 21, avg_loss = 0.4165\n",
            "t = 22, avg_loss = 0.3361\n",
            "t = 23, avg_loss = 0.2594\n",
            "t = 24, avg_loss = 0.2619\n",
            "t = 25, avg_loss = 0.3877\n",
            "Checking accuracy on train set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 13 / 80\n",
            "t = 1, avg_loss = 0.2491\n",
            "t = 2, avg_loss = 0.2477\n",
            "t = 3, avg_loss = 0.1602\n",
            "t = 4, avg_loss = 0.2367\n",
            "t = 5, avg_loss = 0.2369\n",
            "t = 6, avg_loss = 0.2236\n",
            "t = 7, avg_loss = 0.2255\n",
            "t = 8, avg_loss = 0.2126\n",
            "t = 9, avg_loss = 0.2880\n",
            "t = 10, avg_loss = 0.1706\n",
            "t = 11, avg_loss = 0.2704\n",
            "t = 12, avg_loss = 0.2609\n",
            "t = 13, avg_loss = 0.3395\n",
            "t = 14, avg_loss = 0.1708\n",
            "t = 15, avg_loss = 0.2957\n",
            "t = 16, avg_loss = 0.2928\n",
            "t = 17, avg_loss = 0.2949\n",
            "t = 18, avg_loss = 0.2127\n",
            "t = 19, avg_loss = 0.2827\n",
            "t = 20, avg_loss = 0.2623\n",
            "t = 21, avg_loss = 0.3322\n",
            "t = 22, avg_loss = 0.1405\n",
            "t = 23, avg_loss = 0.2502\n",
            "t = 24, avg_loss = 0.4061\n",
            "t = 25, avg_loss = 0.2867\n",
            "Checking accuracy on train set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 14 / 80\n",
            "t = 1, avg_loss = 0.3072\n",
            "t = 2, avg_loss = 0.2743\n",
            "t = 3, avg_loss = 0.1983\n",
            "t = 4, avg_loss = 0.2672\n",
            "t = 5, avg_loss = 0.2800\n",
            "t = 6, avg_loss = 0.1293\n",
            "t = 7, avg_loss = 0.1763\n",
            "t = 8, avg_loss = 0.2261\n",
            "t = 9, avg_loss = 0.2756\n",
            "t = 10, avg_loss = 0.1797\n",
            "t = 11, avg_loss = 0.2341\n",
            "t = 12, avg_loss = 0.2572\n",
            "t = 13, avg_loss = 0.2338\n",
            "t = 14, avg_loss = 0.2503\n",
            "t = 15, avg_loss = 0.1931\n",
            "t = 16, avg_loss = 0.3360\n",
            "t = 17, avg_loss = 0.3879\n",
            "t = 18, avg_loss = 0.2432\n",
            "t = 19, avg_loss = 0.3325\n",
            "t = 20, avg_loss = 0.2799\n",
            "t = 21, avg_loss = 0.2662\n",
            "t = 22, avg_loss = 0.3458\n",
            "t = 23, avg_loss = 0.2088\n",
            "t = 24, avg_loss = 0.2167\n",
            "t = 25, avg_loss = 0.1922\n",
            "Checking accuracy on train set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 15 / 80\n",
            "t = 1, avg_loss = 0.1486\n",
            "t = 2, avg_loss = 0.1805\n",
            "t = 3, avg_loss = 0.1104\n",
            "t = 4, avg_loss = 0.3476\n",
            "t = 5, avg_loss = 0.2282\n",
            "t = 6, avg_loss = 0.2946\n",
            "t = 7, avg_loss = 0.3580\n",
            "t = 8, avg_loss = 0.2481\n",
            "t = 9, avg_loss = 0.3898\n",
            "t = 10, avg_loss = 0.2054\n",
            "t = 11, avg_loss = 0.2153\n",
            "t = 12, avg_loss = 0.2261\n",
            "t = 13, avg_loss = 0.1954\n",
            "t = 14, avg_loss = 0.2155\n",
            "t = 15, avg_loss = 0.2323\n",
            "t = 16, avg_loss = 0.2722\n",
            "t = 17, avg_loss = 0.2527\n",
            "t = 18, avg_loss = 0.2074\n",
            "t = 19, avg_loss = 0.2973\n",
            "t = 20, avg_loss = 0.2041\n",
            "t = 21, avg_loss = 0.1856\n",
            "t = 22, avg_loss = 0.2870\n",
            "t = 23, avg_loss = 0.2211\n",
            "t = 24, avg_loss = 0.3237\n",
            "t = 25, avg_loss = 0.2601\n",
            "Checking accuracy on train set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 16 / 80\n",
            "t = 1, avg_loss = 0.1303\n",
            "t = 2, avg_loss = 0.1800\n",
            "t = 3, avg_loss = 0.1843\n",
            "t = 4, avg_loss = 0.2842\n",
            "t = 5, avg_loss = 0.2315\n",
            "t = 6, avg_loss = 0.2517\n",
            "t = 7, avg_loss = 0.1115\n",
            "t = 8, avg_loss = 0.2909\n",
            "t = 9, avg_loss = 0.2498\n",
            "t = 10, avg_loss = 0.1999\n",
            "t = 11, avg_loss = 0.3803\n",
            "t = 12, avg_loss = 0.2808\n",
            "t = 13, avg_loss = 0.2010\n",
            "t = 14, avg_loss = 0.1647\n",
            "t = 15, avg_loss = 0.2827\n",
            "t = 16, avg_loss = 0.2063\n",
            "t = 17, avg_loss = 0.1811\n",
            "t = 18, avg_loss = 0.2875\n",
            "t = 19, avg_loss = 0.2077\n",
            "t = 20, avg_loss = 0.1454\n",
            "t = 21, avg_loss = 0.2024\n",
            "t = 22, avg_loss = 0.2346\n",
            "t = 23, avg_loss = 0.2545\n",
            "t = 24, avg_loss = 0.3221\n",
            "t = 25, avg_loss = 0.1767\n",
            "Checking accuracy on train set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 17 / 80\n",
            "t = 1, avg_loss = 0.1979\n",
            "t = 2, avg_loss = 0.2621\n",
            "t = 3, avg_loss = 0.2138\n",
            "t = 4, avg_loss = 0.2053\n",
            "t = 5, avg_loss = 0.2121\n",
            "t = 6, avg_loss = 0.1542\n",
            "t = 7, avg_loss = 0.1763\n",
            "t = 8, avg_loss = 0.3376\n",
            "t = 9, avg_loss = 0.1797\n",
            "t = 10, avg_loss = 0.1713\n",
            "t = 11, avg_loss = 0.1837\n",
            "t = 12, avg_loss = 0.1224\n",
            "t = 13, avg_loss = 0.2024\n",
            "t = 14, avg_loss = 0.3202\n",
            "t = 15, avg_loss = 0.2367\n",
            "t = 16, avg_loss = 0.1220\n",
            "t = 17, avg_loss = 0.2655\n",
            "t = 18, avg_loss = 0.2361\n",
            "t = 19, avg_loss = 0.1325\n",
            "t = 20, avg_loss = 0.3528\n",
            "t = 21, avg_loss = 0.2212\n",
            "t = 22, avg_loss = 0.2903\n",
            "t = 23, avg_loss = 0.1789\n",
            "t = 24, avg_loss = 0.3512\n",
            "t = 25, avg_loss = 0.2897\n",
            "Checking accuracy on train set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 18 / 80\n",
            "t = 1, avg_loss = 0.2138\n",
            "t = 2, avg_loss = 0.1933\n",
            "t = 3, avg_loss = 0.2417\n",
            "t = 4, avg_loss = 0.1647\n",
            "t = 5, avg_loss = 0.2441\n",
            "t = 6, avg_loss = 0.2727\n",
            "t = 7, avg_loss = 0.1482\n",
            "t = 8, avg_loss = 0.2396\n",
            "t = 9, avg_loss = 0.2252\n",
            "t = 10, avg_loss = 0.2515\n",
            "t = 11, avg_loss = 0.2037\n",
            "t = 12, avg_loss = 0.2200\n",
            "t = 13, avg_loss = 0.1915\n",
            "t = 14, avg_loss = 0.1548\n",
            "t = 15, avg_loss = 0.1907\n",
            "t = 16, avg_loss = 0.2454\n",
            "t = 17, avg_loss = 0.2298\n",
            "t = 18, avg_loss = 0.2618\n",
            "t = 19, avg_loss = 0.3435\n",
            "t = 20, avg_loss = 0.1424\n",
            "t = 21, avg_loss = 0.3593\n",
            "t = 22, avg_loss = 0.1980\n",
            "t = 23, avg_loss = 0.3117\n",
            "t = 24, avg_loss = 0.3716\n",
            "t = 25, avg_loss = 0.3083\n",
            "Checking accuracy on train set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 19 / 80\n",
            "t = 1, avg_loss = 0.2483\n",
            "t = 2, avg_loss = 0.2528\n",
            "t = 3, avg_loss = 0.2922\n",
            "t = 4, avg_loss = 0.1181\n",
            "t = 5, avg_loss = 0.2212\n",
            "t = 6, avg_loss = 0.2788\n",
            "t = 7, avg_loss = 0.1868\n",
            "t = 8, avg_loss = 0.2185\n",
            "t = 9, avg_loss = 0.1561\n",
            "t = 10, avg_loss = 0.2413\n",
            "t = 11, avg_loss = 0.3044\n",
            "t = 12, avg_loss = 0.2266\n",
            "t = 13, avg_loss = 0.2271\n",
            "t = 14, avg_loss = 0.2082\n",
            "t = 15, avg_loss = 0.2640\n",
            "t = 16, avg_loss = 0.2384\n",
            "t = 17, avg_loss = 0.2069\n",
            "t = 18, avg_loss = 0.2425\n",
            "t = 19, avg_loss = 0.2098\n",
            "t = 20, avg_loss = 0.1494\n",
            "t = 21, avg_loss = 0.2409\n",
            "t = 22, avg_loss = 0.2555\n",
            "t = 23, avg_loss = 0.1701\n",
            "t = 24, avg_loss = 0.2061\n",
            "t = 25, avg_loss = 0.2537\n",
            "Checking accuracy on train set\n",
            "Got 346 / 400 correct (86.50)\n",
            "acc = 0.865000\n",
            "Starting epoch 20 / 80\n",
            "t = 1, avg_loss = 0.1704\n",
            "t = 2, avg_loss = 0.1795\n",
            "t = 3, avg_loss = 0.2191\n",
            "t = 4, avg_loss = 0.2686\n",
            "t = 5, avg_loss = 0.4217\n",
            "t = 6, avg_loss = 0.1557\n",
            "t = 7, avg_loss = 0.1633\n",
            "t = 8, avg_loss = 0.3860\n",
            "t = 9, avg_loss = 0.1619\n",
            "t = 10, avg_loss = 0.0973\n",
            "t = 11, avg_loss = 0.2506\n",
            "t = 12, avg_loss = 0.2634\n",
            "t = 13, avg_loss = 0.3126\n",
            "t = 14, avg_loss = 0.2948\n",
            "t = 15, avg_loss = 0.1944\n",
            "t = 16, avg_loss = 0.1822\n",
            "t = 17, avg_loss = 0.2150\n",
            "t = 18, avg_loss = 0.1453\n",
            "t = 19, avg_loss = 0.3994\n",
            "t = 20, avg_loss = 0.3514\n",
            "t = 21, avg_loss = 0.2359\n",
            "t = 22, avg_loss = 0.2486\n",
            "t = 23, avg_loss = 0.2282\n",
            "t = 24, avg_loss = 0.1864\n",
            "t = 25, avg_loss = 0.1295\n",
            "Checking accuracy on train set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 21 / 80\n",
            "t = 1, avg_loss = 0.2227\n",
            "t = 2, avg_loss = 0.2230\n",
            "t = 3, avg_loss = 0.2081\n",
            "t = 4, avg_loss = 0.2184\n",
            "t = 5, avg_loss = 0.3099\n",
            "t = 6, avg_loss = 0.1984\n",
            "t = 7, avg_loss = 0.1876\n",
            "t = 8, avg_loss = 0.1834\n",
            "t = 9, avg_loss = 0.1842\n",
            "t = 10, avg_loss = 0.1661\n",
            "t = 11, avg_loss = 0.2074\n",
            "t = 12, avg_loss = 0.2113\n",
            "t = 13, avg_loss = 0.2575\n",
            "t = 14, avg_loss = 0.1835\n",
            "t = 15, avg_loss = 0.2853\n",
            "t = 16, avg_loss = 0.2291\n",
            "t = 17, avg_loss = 0.1655\n",
            "t = 18, avg_loss = 0.1589\n",
            "t = 19, avg_loss = 0.2170\n",
            "t = 20, avg_loss = 0.2197\n",
            "t = 21, avg_loss = 0.3091\n",
            "t = 22, avg_loss = 0.1365\n",
            "t = 23, avg_loss = 0.1840\n",
            "t = 24, avg_loss = 0.2227\n",
            "t = 25, avg_loss = 0.2135\n",
            "Checking accuracy on train set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 22 / 80\n",
            "t = 1, avg_loss = 0.1921\n",
            "t = 2, avg_loss = 0.2012\n",
            "t = 3, avg_loss = 0.2529\n",
            "t = 4, avg_loss = 0.2518\n",
            "t = 5, avg_loss = 0.3572\n",
            "t = 6, avg_loss = 0.1698\n",
            "t = 7, avg_loss = 0.1374\n",
            "t = 8, avg_loss = 0.2714\n",
            "t = 9, avg_loss = 0.2282\n",
            "t = 10, avg_loss = 0.1611\n",
            "t = 11, avg_loss = 0.1500\n",
            "t = 12, avg_loss = 0.2227\n",
            "t = 13, avg_loss = 0.1915\n",
            "t = 14, avg_loss = 0.2041\n",
            "t = 15, avg_loss = 0.1708\n",
            "t = 16, avg_loss = 0.1753\n",
            "t = 17, avg_loss = 0.1567\n",
            "t = 18, avg_loss = 0.2648\n",
            "t = 19, avg_loss = 0.2078\n",
            "t = 20, avg_loss = 0.2587\n",
            "t = 21, avg_loss = 0.1464\n",
            "t = 22, avg_loss = 0.1970\n",
            "t = 23, avg_loss = 0.2775\n",
            "t = 24, avg_loss = 0.2377\n",
            "t = 25, avg_loss = 0.1740\n",
            "Checking accuracy on train set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 23 / 80\n",
            "t = 1, avg_loss = 0.2517\n",
            "t = 2, avg_loss = 0.1792\n",
            "t = 3, avg_loss = 0.2509\n",
            "t = 4, avg_loss = 0.1232\n",
            "t = 5, avg_loss = 0.1525\n",
            "t = 6, avg_loss = 0.1964\n",
            "t = 7, avg_loss = 0.2646\n",
            "t = 8, avg_loss = 0.1153\n",
            "t = 9, avg_loss = 0.2633\n",
            "t = 10, avg_loss = 0.3088\n",
            "t = 11, avg_loss = 0.1910\n",
            "t = 12, avg_loss = 0.2019\n",
            "t = 13, avg_loss = 0.1193\n",
            "t = 14, avg_loss = 0.2519\n",
            "t = 15, avg_loss = 0.3608\n",
            "t = 16, avg_loss = 0.3159\n",
            "t = 17, avg_loss = 0.1729\n",
            "t = 18, avg_loss = 0.1737\n",
            "t = 19, avg_loss = 0.1883\n",
            "t = 20, avg_loss = 0.1619\n",
            "t = 21, avg_loss = 0.1859\n",
            "t = 22, avg_loss = 0.1843\n",
            "t = 23, avg_loss = 0.2411\n",
            "t = 24, avg_loss = 0.1352\n",
            "t = 25, avg_loss = 0.1975\n",
            "Checking accuracy on train set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 24 / 80\n",
            "t = 1, avg_loss = 0.1415\n",
            "t = 2, avg_loss = 0.1214\n",
            "t = 3, avg_loss = 0.2600\n",
            "t = 4, avg_loss = 0.2132\n",
            "t = 5, avg_loss = 0.4568\n",
            "t = 6, avg_loss = 0.1211\n",
            "t = 7, avg_loss = 0.1521\n",
            "t = 8, avg_loss = 0.1558\n",
            "t = 9, avg_loss = 0.1730\n",
            "t = 10, avg_loss = 0.1442\n",
            "t = 11, avg_loss = 0.2742\n",
            "t = 12, avg_loss = 0.1506\n",
            "t = 13, avg_loss = 0.2104\n",
            "t = 14, avg_loss = 0.1864\n",
            "t = 15, avg_loss = 0.1343\n",
            "t = 16, avg_loss = 0.2161\n",
            "t = 17, avg_loss = 0.1741\n",
            "t = 18, avg_loss = 0.1945\n",
            "t = 19, avg_loss = 0.2859\n",
            "t = 20, avg_loss = 0.2236\n",
            "t = 21, avg_loss = 0.0864\n",
            "t = 22, avg_loss = 0.2101\n",
            "t = 23, avg_loss = 0.1962\n",
            "t = 24, avg_loss = 0.2333\n",
            "t = 25, avg_loss = 0.3268\n",
            "Checking accuracy on train set\n",
            "Got 359 / 400 correct (89.75)\n",
            "acc = 0.897500\n",
            "Starting epoch 25 / 80\n",
            "t = 1, avg_loss = 0.1259\n",
            "t = 2, avg_loss = 0.1642\n",
            "t = 3, avg_loss = 0.2204\n",
            "t = 4, avg_loss = 0.1247\n",
            "t = 5, avg_loss = 0.1653\n",
            "t = 6, avg_loss = 0.1469\n",
            "t = 7, avg_loss = 0.1689\n",
            "t = 8, avg_loss = 0.2062\n",
            "t = 9, avg_loss = 0.2272\n",
            "t = 10, avg_loss = 0.2179\n",
            "t = 11, avg_loss = 0.1465\n",
            "t = 12, avg_loss = 0.1761\n",
            "t = 13, avg_loss = 0.1535\n",
            "t = 14, avg_loss = 0.2645\n",
            "t = 15, avg_loss = 0.1451\n",
            "t = 16, avg_loss = 0.1657\n",
            "t = 17, avg_loss = 0.1753\n",
            "t = 18, avg_loss = 0.1301\n",
            "t = 19, avg_loss = 0.3032\n",
            "t = 20, avg_loss = 0.1601\n",
            "t = 21, avg_loss = 0.1421\n",
            "t = 22, avg_loss = 0.1703\n",
            "t = 23, avg_loss = 0.1519\n",
            "t = 24, avg_loss = 0.2147\n",
            "t = 25, avg_loss = 0.2447\n",
            "Checking accuracy on train set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 26 / 80\n",
            "t = 1, avg_loss = 0.1736\n",
            "t = 2, avg_loss = 0.2321\n",
            "t = 3, avg_loss = 0.2648\n",
            "t = 4, avg_loss = 0.1774\n",
            "t = 5, avg_loss = 0.1896\n",
            "t = 6, avg_loss = 0.1737\n",
            "t = 7, avg_loss = 0.1410\n",
            "t = 8, avg_loss = 0.2036\n",
            "t = 9, avg_loss = 0.1175\n",
            "t = 10, avg_loss = 0.2436\n",
            "t = 11, avg_loss = 0.1923\n",
            "t = 12, avg_loss = 0.2750\n",
            "t = 13, avg_loss = 0.1430\n",
            "t = 14, avg_loss = 0.2158\n",
            "t = 15, avg_loss = 0.2230\n",
            "t = 16, avg_loss = 0.1411\n",
            "t = 17, avg_loss = 0.1947\n",
            "t = 18, avg_loss = 0.1965\n",
            "t = 19, avg_loss = 0.1846\n",
            "t = 20, avg_loss = 0.1771\n",
            "t = 21, avg_loss = 0.1675\n",
            "t = 22, avg_loss = 0.1888\n",
            "t = 23, avg_loss = 0.1785\n",
            "t = 24, avg_loss = 0.1977\n",
            "t = 25, avg_loss = 0.3122\n",
            "Checking accuracy on train set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 27 / 80\n",
            "t = 1, avg_loss = 0.1226\n",
            "t = 2, avg_loss = 0.1546\n",
            "t = 3, avg_loss = 0.2388\n",
            "t = 4, avg_loss = 0.1229\n",
            "t = 5, avg_loss = 0.2224\n",
            "t = 6, avg_loss = 0.2537\n",
            "t = 7, avg_loss = 0.2606\n",
            "t = 8, avg_loss = 0.2745\n",
            "t = 9, avg_loss = 0.1782\n",
            "t = 10, avg_loss = 0.3186\n",
            "t = 11, avg_loss = 0.1944\n",
            "t = 12, avg_loss = 0.1299\n",
            "t = 13, avg_loss = 0.1500\n",
            "t = 14, avg_loss = 0.1667\n",
            "t = 15, avg_loss = 0.2084\n",
            "t = 16, avg_loss = 0.1894\n",
            "t = 17, avg_loss = 0.2201\n",
            "t = 18, avg_loss = 0.1575\n",
            "t = 19, avg_loss = 0.2129\n",
            "t = 20, avg_loss = 0.3177\n",
            "t = 21, avg_loss = 0.1021\n",
            "t = 22, avg_loss = 0.1525\n",
            "t = 23, avg_loss = 0.1254\n",
            "t = 24, avg_loss = 0.1927\n",
            "t = 25, avg_loss = 0.1601\n",
            "Checking accuracy on train set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 28 / 80\n",
            "t = 1, avg_loss = 0.0874\n",
            "t = 2, avg_loss = 0.1594\n",
            "t = 3, avg_loss = 0.0928\n",
            "t = 4, avg_loss = 0.1421\n",
            "t = 5, avg_loss = 0.1269\n",
            "t = 6, avg_loss = 0.1709\n",
            "t = 7, avg_loss = 0.1310\n",
            "t = 8, avg_loss = 0.2545\n",
            "t = 9, avg_loss = 0.1216\n",
            "t = 10, avg_loss = 0.1890\n",
            "t = 11, avg_loss = 0.1813\n",
            "t = 12, avg_loss = 0.2021\n",
            "t = 13, avg_loss = 0.1285\n",
            "t = 14, avg_loss = 0.3129\n",
            "t = 15, avg_loss = 0.0838\n",
            "t = 16, avg_loss = 0.1978\n",
            "t = 17, avg_loss = 0.1527\n",
            "t = 18, avg_loss = 0.1717\n",
            "t = 19, avg_loss = 0.1288\n",
            "t = 20, avg_loss = 0.2676\n",
            "t = 21, avg_loss = 0.1405\n",
            "t = 22, avg_loss = 0.1082\n",
            "t = 23, avg_loss = 0.2362\n",
            "t = 24, avg_loss = 0.1562\n",
            "t = 25, avg_loss = 0.2929\n",
            "Checking accuracy on train set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 29 / 80\n",
            "t = 1, avg_loss = 0.1455\n",
            "t = 2, avg_loss = 0.1221\n",
            "t = 3, avg_loss = 0.1227\n",
            "t = 4, avg_loss = 0.1916\n",
            "t = 5, avg_loss = 0.1400\n",
            "t = 6, avg_loss = 0.1057\n",
            "t = 7, avg_loss = 0.2091\n",
            "t = 8, avg_loss = 0.2059\n",
            "t = 9, avg_loss = 0.1758\n",
            "t = 10, avg_loss = 0.2792\n",
            "t = 11, avg_loss = 0.1922\n",
            "t = 12, avg_loss = 0.1216\n",
            "t = 13, avg_loss = 0.1665\n",
            "t = 14, avg_loss = 0.1949\n",
            "t = 15, avg_loss = 0.1471\n",
            "t = 16, avg_loss = 0.1069\n",
            "t = 17, avg_loss = 0.1681\n",
            "t = 18, avg_loss = 0.1951\n",
            "t = 19, avg_loss = 0.1297\n",
            "t = 20, avg_loss = 0.1589\n",
            "t = 21, avg_loss = 0.2192\n",
            "t = 22, avg_loss = 0.1834\n",
            "t = 23, avg_loss = 0.1850\n",
            "t = 24, avg_loss = 0.1568\n",
            "t = 25, avg_loss = 0.1436\n",
            "Checking accuracy on train set\n",
            "Got 359 / 400 correct (89.75)\n",
            "acc = 0.897500\n",
            "Starting epoch 30 / 80\n",
            "t = 1, avg_loss = 0.1522\n",
            "t = 2, avg_loss = 0.1831\n",
            "t = 3, avg_loss = 0.1161\n",
            "t = 4, avg_loss = 0.2504\n",
            "t = 5, avg_loss = 0.2225\n",
            "t = 6, avg_loss = 0.0748\n",
            "t = 7, avg_loss = 0.1443\n",
            "t = 8, avg_loss = 0.0597\n",
            "t = 9, avg_loss = 0.1751\n",
            "t = 10, avg_loss = 0.1783\n",
            "t = 11, avg_loss = 0.2135\n",
            "t = 12, avg_loss = 0.1055\n",
            "t = 13, avg_loss = 0.1389\n",
            "t = 14, avg_loss = 0.1104\n",
            "t = 15, avg_loss = 0.1541\n",
            "t = 16, avg_loss = 0.1584\n",
            "t = 17, avg_loss = 0.1629\n",
            "t = 18, avg_loss = 0.1338\n",
            "t = 19, avg_loss = 0.1679\n",
            "t = 20, avg_loss = 0.1181\n",
            "t = 21, avg_loss = 0.1716\n",
            "t = 22, avg_loss = 0.1302\n",
            "t = 23, avg_loss = 0.1445\n",
            "t = 24, avg_loss = 0.1568\n",
            "t = 25, avg_loss = 0.1807\n",
            "Checking accuracy on train set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 31 / 80\n",
            "t = 1, avg_loss = 0.0973\n",
            "t = 2, avg_loss = 0.1313\n",
            "t = 3, avg_loss = 0.1219\n",
            "t = 4, avg_loss = 0.1717\n",
            "t = 5, avg_loss = 0.0967\n",
            "t = 6, avg_loss = 0.1400\n",
            "t = 7, avg_loss = 0.1682\n",
            "t = 8, avg_loss = 0.1243\n",
            "t = 9, avg_loss = 0.1989\n",
            "t = 10, avg_loss = 0.1009\n",
            "t = 11, avg_loss = 0.0937\n",
            "t = 12, avg_loss = 0.2103\n",
            "t = 13, avg_loss = 0.1824\n",
            "t = 14, avg_loss = 0.1833\n",
            "t = 15, avg_loss = 0.1917\n",
            "t = 16, avg_loss = 0.1040\n",
            "t = 17, avg_loss = 0.1244\n",
            "t = 18, avg_loss = 0.1712\n",
            "t = 19, avg_loss = 0.1189\n",
            "t = 20, avg_loss = 0.1236\n",
            "t = 21, avg_loss = 0.1432\n",
            "t = 22, avg_loss = 0.0837\n",
            "t = 23, avg_loss = 0.0997\n",
            "t = 24, avg_loss = 0.1307\n",
            "t = 25, avg_loss = 0.1657\n",
            "Checking accuracy on train set\n",
            "Got 358 / 400 correct (89.50)\n",
            "acc = 0.895000\n",
            "Starting epoch 32 / 80\n",
            "t = 1, avg_loss = 0.1906\n",
            "t = 2, avg_loss = 0.0879\n",
            "t = 3, avg_loss = 0.1522\n",
            "t = 4, avg_loss = 0.1100\n",
            "t = 5, avg_loss = 0.2098\n",
            "t = 6, avg_loss = 0.1039\n",
            "t = 7, avg_loss = 0.2746\n",
            "t = 8, avg_loss = 0.1859\n",
            "t = 9, avg_loss = 0.1151\n",
            "t = 10, avg_loss = 0.1184\n",
            "t = 11, avg_loss = 0.1360\n",
            "t = 12, avg_loss = 0.1435\n",
            "t = 13, avg_loss = 0.0893\n",
            "t = 14, avg_loss = 0.2322\n",
            "t = 15, avg_loss = 0.1933\n",
            "t = 16, avg_loss = 0.2300\n",
            "t = 17, avg_loss = 0.1913\n",
            "t = 18, avg_loss = 0.1068\n",
            "t = 19, avg_loss = 0.0992\n",
            "t = 20, avg_loss = 0.2342\n",
            "t = 21, avg_loss = 0.2075\n",
            "t = 22, avg_loss = 0.1511\n",
            "t = 23, avg_loss = 0.1340\n",
            "t = 24, avg_loss = 0.1608\n",
            "t = 25, avg_loss = 0.1715\n",
            "Checking accuracy on train set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 33 / 80\n",
            "t = 1, avg_loss = 0.1217\n",
            "t = 2, avg_loss = 0.0804\n",
            "t = 3, avg_loss = 0.1703\n",
            "t = 4, avg_loss = 0.0985\n",
            "t = 5, avg_loss = 0.1349\n",
            "t = 6, avg_loss = 0.0890\n",
            "t = 7, avg_loss = 0.1105\n",
            "t = 8, avg_loss = 0.1849\n",
            "t = 9, avg_loss = 0.2087\n",
            "t = 10, avg_loss = 0.1072\n",
            "t = 11, avg_loss = 0.1941\n",
            "t = 12, avg_loss = 0.1102\n",
            "t = 13, avg_loss = 0.1453\n",
            "t = 14, avg_loss = 0.1574\n",
            "t = 15, avg_loss = 0.1251\n",
            "t = 16, avg_loss = 0.1119\n",
            "t = 17, avg_loss = 0.0816\n",
            "t = 18, avg_loss = 0.1890\n",
            "t = 19, avg_loss = 0.2263\n",
            "t = 20, avg_loss = 0.1309\n",
            "t = 21, avg_loss = 0.1717\n",
            "t = 22, avg_loss = 0.2719\n",
            "t = 23, avg_loss = 0.1885\n",
            "t = 24, avg_loss = 0.1918\n",
            "t = 25, avg_loss = 0.0924\n",
            "Checking accuracy on train set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 34 / 80\n",
            "t = 1, avg_loss = 0.1523\n",
            "t = 2, avg_loss = 0.0943\n",
            "t = 3, avg_loss = 0.1273\n",
            "t = 4, avg_loss = 0.1203\n",
            "t = 5, avg_loss = 0.1984\n",
            "t = 6, avg_loss = 0.1390\n",
            "t = 7, avg_loss = 0.2466\n",
            "t = 8, avg_loss = 0.1721\n",
            "t = 9, avg_loss = 0.2044\n",
            "t = 10, avg_loss = 0.1791\n",
            "t = 11, avg_loss = 0.2006\n",
            "t = 12, avg_loss = 0.1235\n",
            "t = 13, avg_loss = 0.1112\n",
            "t = 14, avg_loss = 0.1267\n",
            "t = 15, avg_loss = 0.1580\n",
            "t = 16, avg_loss = 0.1240\n",
            "t = 17, avg_loss = 0.1551\n",
            "t = 18, avg_loss = 0.2235\n",
            "t = 19, avg_loss = 0.1403\n",
            "t = 20, avg_loss = 0.1435\n",
            "t = 21, avg_loss = 0.1988\n",
            "t = 22, avg_loss = 0.1221\n",
            "t = 23, avg_loss = 0.1181\n",
            "t = 24, avg_loss = 0.2272\n",
            "t = 25, avg_loss = 0.1134\n",
            "Checking accuracy on train set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 35 / 80\n",
            "t = 1, avg_loss = 0.1404\n",
            "t = 2, avg_loss = 0.1425\n",
            "t = 3, avg_loss = 0.1152\n",
            "t = 4, avg_loss = 0.1046\n",
            "t = 5, avg_loss = 0.0907\n",
            "t = 6, avg_loss = 0.1543\n",
            "t = 7, avg_loss = 0.1348\n",
            "t = 8, avg_loss = 0.1007\n",
            "t = 9, avg_loss = 0.2224\n",
            "t = 10, avg_loss = 0.1054\n",
            "t = 11, avg_loss = 0.1662\n",
            "t = 12, avg_loss = 0.1772\n",
            "t = 13, avg_loss = 0.0850\n",
            "t = 14, avg_loss = 0.1768\n",
            "t = 15, avg_loss = 0.1931\n",
            "t = 16, avg_loss = 0.1384\n",
            "t = 17, avg_loss = 0.1728\n",
            "t = 18, avg_loss = 0.1705\n",
            "t = 19, avg_loss = 0.1837\n",
            "t = 20, avg_loss = 0.1992\n",
            "t = 21, avg_loss = 0.2952\n",
            "t = 22, avg_loss = 0.1067\n",
            "t = 23, avg_loss = 0.1246\n",
            "t = 24, avg_loss = 0.0775\n",
            "t = 25, avg_loss = 0.1913\n",
            "Checking accuracy on train set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 36 / 80\n",
            "t = 1, avg_loss = 0.2025\n",
            "t = 2, avg_loss = 0.0674\n",
            "t = 3, avg_loss = 0.1446\n",
            "t = 4, avg_loss = 0.0825\n",
            "t = 5, avg_loss = 0.1379\n",
            "t = 6, avg_loss = 0.1924\n",
            "t = 7, avg_loss = 0.1111\n",
            "t = 8, avg_loss = 0.1646\n",
            "t = 9, avg_loss = 0.1869\n",
            "t = 10, avg_loss = 0.1240\n",
            "t = 11, avg_loss = 0.1349\n",
            "t = 12, avg_loss = 0.1519\n",
            "t = 13, avg_loss = 0.1433\n",
            "t = 14, avg_loss = 0.1534\n",
            "t = 15, avg_loss = 0.1146\n",
            "t = 16, avg_loss = 0.1722\n",
            "t = 17, avg_loss = 0.1488\n",
            "t = 18, avg_loss = 0.1909\n",
            "t = 19, avg_loss = 0.1026\n",
            "t = 20, avg_loss = 0.1845\n",
            "t = 21, avg_loss = 0.1185\n",
            "t = 22, avg_loss = 0.1656\n",
            "t = 23, avg_loss = 0.0986\n",
            "t = 24, avg_loss = 0.0693\n",
            "t = 25, avg_loss = 0.1444\n",
            "Checking accuracy on train set\n",
            "Got 360 / 400 correct (90.00)\n",
            "acc = 0.900000\n",
            "Starting epoch 37 / 80\n",
            "t = 1, avg_loss = 0.0790\n",
            "t = 2, avg_loss = 0.1671\n",
            "t = 3, avg_loss = 0.1046\n",
            "t = 4, avg_loss = 0.0986\n",
            "t = 5, avg_loss = 0.1107\n",
            "t = 6, avg_loss = 0.1388\n",
            "t = 7, avg_loss = 0.0547\n",
            "t = 8, avg_loss = 0.1333\n",
            "t = 9, avg_loss = 0.1240\n",
            "t = 10, avg_loss = 0.2019\n",
            "t = 11, avg_loss = 0.0996\n",
            "t = 12, avg_loss = 0.1303\n",
            "t = 13, avg_loss = 0.1366\n",
            "t = 14, avg_loss = 0.1324\n",
            "t = 15, avg_loss = 0.0917\n",
            "t = 16, avg_loss = 0.1174\n",
            "t = 17, avg_loss = 0.0742\n",
            "t = 18, avg_loss = 0.2352\n",
            "t = 19, avg_loss = 0.1153\n",
            "t = 20, avg_loss = 0.1506\n",
            "t = 21, avg_loss = 0.0852\n",
            "t = 22, avg_loss = 0.1982\n",
            "t = 23, avg_loss = 0.1294\n",
            "t = 24, avg_loss = 0.2278\n",
            "t = 25, avg_loss = 0.1419\n",
            "Checking accuracy on train set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 38 / 80\n",
            "t = 1, avg_loss = 0.0893\n",
            "t = 2, avg_loss = 0.0709\n",
            "t = 3, avg_loss = 0.0996\n",
            "t = 4, avg_loss = 0.2319\n",
            "t = 5, avg_loss = 0.1164\n",
            "t = 6, avg_loss = 0.0621\n",
            "t = 7, avg_loss = 0.1177\n",
            "t = 8, avg_loss = 0.1025\n",
            "t = 9, avg_loss = 0.1343\n",
            "t = 10, avg_loss = 0.1880\n",
            "t = 11, avg_loss = 0.1193\n",
            "t = 12, avg_loss = 0.0994\n",
            "t = 13, avg_loss = 0.1991\n",
            "t = 14, avg_loss = 0.0961\n",
            "t = 15, avg_loss = 0.0563\n",
            "t = 16, avg_loss = 0.1523\n",
            "t = 17, avg_loss = 0.2238\n",
            "t = 18, avg_loss = 0.1464\n",
            "t = 19, avg_loss = 0.1578\n",
            "t = 20, avg_loss = 0.1530\n",
            "t = 21, avg_loss = 0.0886\n",
            "t = 22, avg_loss = 0.1628\n",
            "t = 23, avg_loss = 0.3201\n",
            "t = 24, avg_loss = 0.1166\n",
            "t = 25, avg_loss = 0.2006\n",
            "Checking accuracy on train set\n",
            "Got 341 / 400 correct (85.25)\n",
            "acc = 0.852500\n",
            "Starting epoch 39 / 80\n",
            "t = 1, avg_loss = 0.1159\n",
            "t = 2, avg_loss = 0.1696\n",
            "t = 3, avg_loss = 0.1323\n",
            "t = 4, avg_loss = 0.1549\n",
            "t = 5, avg_loss = 0.1154\n",
            "t = 6, avg_loss = 0.1327\n",
            "t = 7, avg_loss = 0.1822\n",
            "t = 8, avg_loss = 0.3204\n",
            "t = 9, avg_loss = 0.1333\n",
            "t = 10, avg_loss = 0.1261\n",
            "t = 11, avg_loss = 0.0955\n",
            "t = 12, avg_loss = 0.2250\n",
            "t = 13, avg_loss = 0.1765\n",
            "t = 14, avg_loss = 0.1462\n",
            "t = 15, avg_loss = 0.1442\n",
            "t = 16, avg_loss = 0.1598\n",
            "t = 17, avg_loss = 0.2306\n",
            "t = 18, avg_loss = 0.1776\n",
            "t = 19, avg_loss = 0.1466\n",
            "t = 20, avg_loss = 0.1685\n",
            "t = 21, avg_loss = 0.0915\n",
            "t = 22, avg_loss = 0.1296\n",
            "t = 23, avg_loss = 0.1105\n",
            "t = 24, avg_loss = 0.1675\n",
            "t = 25, avg_loss = 0.3174\n",
            "Checking accuracy on train set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 40 / 80\n",
            "t = 1, avg_loss = 0.0947\n",
            "t = 2, avg_loss = 0.0869\n",
            "t = 3, avg_loss = 0.0882\n",
            "t = 4, avg_loss = 0.1245\n",
            "t = 5, avg_loss = 0.1220\n",
            "t = 6, avg_loss = 0.1552\n",
            "t = 7, avg_loss = 0.1807\n",
            "t = 8, avg_loss = 0.1520\n",
            "t = 9, avg_loss = 0.0858\n",
            "t = 10, avg_loss = 0.1183\n",
            "t = 11, avg_loss = 0.1468\n",
            "t = 12, avg_loss = 0.1160\n",
            "t = 13, avg_loss = 0.0991\n",
            "t = 14, avg_loss = 0.2509\n",
            "t = 15, avg_loss = 0.1561\n",
            "t = 16, avg_loss = 0.1564\n",
            "t = 17, avg_loss = 0.0646\n",
            "t = 18, avg_loss = 0.2274\n",
            "t = 19, avg_loss = 0.0932\n",
            "t = 20, avg_loss = 0.1368\n",
            "t = 21, avg_loss = 0.1059\n",
            "t = 22, avg_loss = 0.1021\n",
            "t = 23, avg_loss = 0.0801\n",
            "t = 24, avg_loss = 0.1227\n",
            "t = 25, avg_loss = 0.1001\n",
            "Checking accuracy on train set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 41 / 80\n",
            "t = 1, avg_loss = 0.0898\n",
            "t = 2, avg_loss = 0.1019\n",
            "t = 3, avg_loss = 0.1464\n",
            "t = 4, avg_loss = 0.0854\n",
            "t = 5, avg_loss = 0.0632\n",
            "t = 6, avg_loss = 0.1542\n",
            "t = 7, avg_loss = 0.0779\n",
            "t = 8, avg_loss = 0.0877\n",
            "t = 9, avg_loss = 0.0861\n",
            "t = 10, avg_loss = 0.1501\n",
            "t = 11, avg_loss = 0.1726\n",
            "t = 12, avg_loss = 0.1031\n",
            "t = 13, avg_loss = 0.1497\n",
            "t = 14, avg_loss = 0.1486\n",
            "t = 15, avg_loss = 0.2426\n",
            "t = 16, avg_loss = 0.1301\n",
            "t = 17, avg_loss = 0.2400\n",
            "t = 18, avg_loss = 0.2073\n",
            "t = 19, avg_loss = 0.1650\n",
            "t = 20, avg_loss = 0.0783\n",
            "t = 21, avg_loss = 0.1941\n",
            "t = 22, avg_loss = 0.1244\n",
            "t = 23, avg_loss = 0.1477\n",
            "t = 24, avg_loss = 0.1439\n",
            "t = 25, avg_loss = 0.1821\n",
            "Checking accuracy on train set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 42 / 80\n",
            "t = 1, avg_loss = 0.0936\n",
            "t = 2, avg_loss = 0.1207\n",
            "t = 3, avg_loss = 0.0718\n",
            "t = 4, avg_loss = 0.1131\n",
            "t = 5, avg_loss = 0.0579\n",
            "t = 6, avg_loss = 0.1468\n",
            "t = 7, avg_loss = 0.1499\n",
            "t = 8, avg_loss = 0.1581\n",
            "t = 9, avg_loss = 0.1301\n",
            "t = 10, avg_loss = 0.0859\n",
            "t = 11, avg_loss = 0.1747\n",
            "t = 12, avg_loss = 0.0514\n",
            "t = 13, avg_loss = 0.1182\n",
            "t = 14, avg_loss = 0.1220\n",
            "t = 15, avg_loss = 0.1840\n",
            "t = 16, avg_loss = 0.1015\n",
            "t = 17, avg_loss = 0.1483\n",
            "t = 18, avg_loss = 0.1364\n",
            "t = 19, avg_loss = 0.0886\n",
            "t = 20, avg_loss = 0.1843\n",
            "t = 21, avg_loss = 0.0644\n",
            "t = 22, avg_loss = 0.0803\n",
            "t = 23, avg_loss = 0.1392\n",
            "t = 24, avg_loss = 0.0962\n",
            "t = 25, avg_loss = 0.0910\n",
            "Checking accuracy on train set\n",
            "Got 358 / 400 correct (89.50)\n",
            "acc = 0.895000\n",
            "Starting epoch 43 / 80\n",
            "t = 1, avg_loss = 0.0914\n",
            "t = 2, avg_loss = 0.1162\n",
            "t = 3, avg_loss = 0.0648\n",
            "t = 4, avg_loss = 0.1953\n",
            "t = 5, avg_loss = 0.1446\n",
            "t = 6, avg_loss = 0.1045\n",
            "t = 7, avg_loss = 0.1067\n",
            "t = 8, avg_loss = 0.0848\n",
            "t = 9, avg_loss = 0.0844\n",
            "t = 10, avg_loss = 0.1955\n",
            "t = 11, avg_loss = 0.1579\n",
            "t = 12, avg_loss = 0.0920\n",
            "t = 13, avg_loss = 0.0987\n",
            "t = 14, avg_loss = 0.0859\n",
            "t = 15, avg_loss = 0.1082\n",
            "t = 16, avg_loss = 0.0864\n",
            "t = 17, avg_loss = 0.2195\n",
            "t = 18, avg_loss = 0.1237\n",
            "t = 19, avg_loss = 0.0965\n",
            "t = 20, avg_loss = 0.2028\n",
            "t = 21, avg_loss = 0.2196\n",
            "t = 22, avg_loss = 0.0741\n",
            "t = 23, avg_loss = 0.2317\n",
            "t = 24, avg_loss = 0.0553\n",
            "t = 25, avg_loss = 0.1048\n",
            "Checking accuracy on train set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 44 / 80\n",
            "t = 1, avg_loss = 0.1268\n",
            "t = 2, avg_loss = 0.1106\n",
            "t = 3, avg_loss = 0.0893\n",
            "t = 4, avg_loss = 0.0892\n",
            "t = 5, avg_loss = 0.1213\n",
            "t = 6, avg_loss = 0.0937\n",
            "t = 7, avg_loss = 0.0718\n",
            "t = 8, avg_loss = 0.1081\n",
            "t = 9, avg_loss = 0.1988\n",
            "t = 10, avg_loss = 0.1086\n",
            "t = 11, avg_loss = 0.1184\n",
            "t = 12, avg_loss = 0.1015\n",
            "t = 13, avg_loss = 0.0577\n",
            "t = 14, avg_loss = 0.0729\n",
            "t = 15, avg_loss = 0.1273\n",
            "t = 16, avg_loss = 0.1998\n",
            "t = 17, avg_loss = 0.2348\n",
            "t = 18, avg_loss = 0.0923\n",
            "t = 19, avg_loss = 0.1870\n",
            "t = 20, avg_loss = 0.1079\n",
            "t = 21, avg_loss = 0.2612\n",
            "t = 22, avg_loss = 0.0362\n",
            "t = 23, avg_loss = 0.1823\n",
            "t = 24, avg_loss = 0.1294\n",
            "t = 25, avg_loss = 0.0843\n",
            "Checking accuracy on train set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 45 / 80\n",
            "t = 1, avg_loss = 0.0844\n",
            "t = 2, avg_loss = 0.0528\n",
            "t = 3, avg_loss = 0.0568\n",
            "t = 4, avg_loss = 0.0898\n",
            "t = 5, avg_loss = 0.0809\n",
            "t = 6, avg_loss = 0.1346\n",
            "t = 7, avg_loss = 0.0960\n",
            "t = 8, avg_loss = 0.1717\n",
            "t = 9, avg_loss = 0.0605\n",
            "t = 10, avg_loss = 0.1602\n",
            "t = 11, avg_loss = 0.1570\n",
            "t = 12, avg_loss = 0.1084\n",
            "t = 13, avg_loss = 0.1320\n",
            "t = 14, avg_loss = 0.1256\n",
            "t = 15, avg_loss = 0.1174\n",
            "t = 16, avg_loss = 0.1128\n",
            "t = 17, avg_loss = 0.1429\n",
            "t = 18, avg_loss = 0.2369\n",
            "t = 19, avg_loss = 0.1722\n",
            "t = 20, avg_loss = 0.0747\n",
            "t = 21, avg_loss = 0.1758\n",
            "t = 22, avg_loss = 0.1507\n",
            "t = 23, avg_loss = 0.0829\n",
            "t = 24, avg_loss = 0.1847\n",
            "t = 25, avg_loss = 0.0742\n",
            "Checking accuracy on train set\n",
            "Got 343 / 400 correct (85.75)\n",
            "acc = 0.857500\n",
            "Starting epoch 46 / 80\n",
            "t = 1, avg_loss = 0.1458\n",
            "t = 2, avg_loss = 0.1882\n",
            "t = 3, avg_loss = 0.1219\n",
            "t = 4, avg_loss = 0.0907\n",
            "t = 5, avg_loss = 0.1354\n",
            "t = 6, avg_loss = 0.0773\n",
            "t = 7, avg_loss = 0.1288\n",
            "t = 8, avg_loss = 0.0998\n",
            "t = 9, avg_loss = 0.1468\n",
            "t = 10, avg_loss = 0.1497\n",
            "t = 11, avg_loss = 0.1724\n",
            "t = 12, avg_loss = 0.0397\n",
            "t = 13, avg_loss = 0.0998\n",
            "t = 14, avg_loss = 0.1476\n",
            "t = 15, avg_loss = 0.1429\n",
            "t = 16, avg_loss = 0.0822\n",
            "t = 17, avg_loss = 0.0866\n",
            "t = 18, avg_loss = 0.1339\n",
            "t = 19, avg_loss = 0.1284\n",
            "t = 20, avg_loss = 0.1135\n",
            "t = 21, avg_loss = 0.1140\n",
            "t = 22, avg_loss = 0.0726\n",
            "t = 23, avg_loss = 0.0855\n",
            "t = 24, avg_loss = 0.1149\n",
            "t = 25, avg_loss = 0.1538\n",
            "Checking accuracy on train set\n",
            "Got 362 / 400 correct (90.50)\n",
            "acc = 0.905000\n",
            "Starting epoch 47 / 80\n",
            "t = 1, avg_loss = 0.1140\n",
            "t = 2, avg_loss = 0.0857\n",
            "t = 3, avg_loss = 0.1158\n",
            "t = 4, avg_loss = 0.1012\n",
            "t = 5, avg_loss = 0.0539\n",
            "t = 6, avg_loss = 0.1079\n",
            "t = 7, avg_loss = 0.1268\n",
            "t = 8, avg_loss = 0.1013\n",
            "t = 9, avg_loss = 0.0679\n",
            "t = 10, avg_loss = 0.1189\n",
            "t = 11, avg_loss = 0.1046\n",
            "t = 12, avg_loss = 0.0765\n",
            "t = 13, avg_loss = 0.1584\n",
            "t = 14, avg_loss = 0.0717\n",
            "t = 15, avg_loss = 0.1610\n",
            "t = 16, avg_loss = 0.0566\n",
            "t = 17, avg_loss = 0.0471\n",
            "t = 18, avg_loss = 0.0605\n",
            "t = 19, avg_loss = 0.1326\n",
            "t = 20, avg_loss = 0.0843\n",
            "t = 21, avg_loss = 0.0957\n",
            "t = 22, avg_loss = 0.1271\n",
            "t = 23, avg_loss = 0.1180\n",
            "t = 24, avg_loss = 0.1184\n",
            "t = 25, avg_loss = 0.0734\n",
            "Checking accuracy on train set\n",
            "Got 345 / 400 correct (86.25)\n",
            "acc = 0.862500\n",
            "Starting epoch 48 / 80\n",
            "t = 1, avg_loss = 0.0991\n",
            "t = 2, avg_loss = 0.0570\n",
            "t = 3, avg_loss = 0.1135\n",
            "t = 4, avg_loss = 0.0470\n",
            "t = 5, avg_loss = 0.1600\n",
            "t = 6, avg_loss = 0.1462\n",
            "t = 7, avg_loss = 0.0696\n",
            "t = 8, avg_loss = 0.0870\n",
            "t = 9, avg_loss = 0.0955\n",
            "t = 10, avg_loss = 0.1361\n",
            "t = 11, avg_loss = 0.1521\n",
            "t = 12, avg_loss = 0.0920\n",
            "t = 13, avg_loss = 0.1331\n",
            "t = 14, avg_loss = 0.0917\n",
            "t = 15, avg_loss = 0.1459\n",
            "t = 16, avg_loss = 0.0657\n",
            "t = 17, avg_loss = 0.2066\n",
            "t = 18, avg_loss = 0.1107\n",
            "t = 19, avg_loss = 0.1234\n",
            "t = 20, avg_loss = 0.1121\n",
            "t = 21, avg_loss = 0.0853\n",
            "t = 22, avg_loss = 0.0539\n",
            "t = 23, avg_loss = 0.0686\n",
            "t = 24, avg_loss = 0.1401\n",
            "t = 25, avg_loss = 0.0605\n",
            "Checking accuracy on train set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 49 / 80\n",
            "t = 1, avg_loss = 0.1175\n",
            "t = 2, avg_loss = 0.0777\n",
            "t = 3, avg_loss = 0.1304\n",
            "t = 4, avg_loss = 0.0639\n",
            "t = 5, avg_loss = 0.1056\n",
            "t = 6, avg_loss = 0.0594\n",
            "t = 7, avg_loss = 0.0803\n",
            "t = 8, avg_loss = 0.0290\n",
            "t = 9, avg_loss = 0.1064\n",
            "t = 10, avg_loss = 0.0543\n",
            "t = 11, avg_loss = 0.0594\n",
            "t = 12, avg_loss = 0.0336\n",
            "t = 13, avg_loss = 0.1023\n",
            "t = 14, avg_loss = 0.0638\n",
            "t = 15, avg_loss = 0.0676\n",
            "t = 16, avg_loss = 0.0897\n",
            "t = 17, avg_loss = 0.1295\n",
            "t = 18, avg_loss = 0.1282\n",
            "t = 19, avg_loss = 0.0734\n",
            "t = 20, avg_loss = 0.0888\n",
            "t = 21, avg_loss = 0.2097\n",
            "t = 22, avg_loss = 0.0818\n",
            "t = 23, avg_loss = 0.0908\n",
            "t = 24, avg_loss = 0.1456\n",
            "t = 25, avg_loss = 0.0838\n",
            "Checking accuracy on train set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 50 / 80\n",
            "t = 1, avg_loss = 0.1007\n",
            "t = 2, avg_loss = 0.1133\n",
            "t = 3, avg_loss = 0.1047\n",
            "t = 4, avg_loss = 0.1791\n",
            "t = 5, avg_loss = 0.1393\n",
            "t = 6, avg_loss = 0.1327\n",
            "t = 7, avg_loss = 0.1152\n",
            "t = 8, avg_loss = 0.1156\n",
            "t = 9, avg_loss = 0.0845\n",
            "t = 10, avg_loss = 0.1008\n",
            "t = 11, avg_loss = 0.1976\n",
            "t = 12, avg_loss = 0.1928\n",
            "t = 13, avg_loss = 0.1060\n",
            "t = 14, avg_loss = 0.1604\n",
            "t = 15, avg_loss = 0.1078\n",
            "t = 16, avg_loss = 0.1379\n",
            "t = 17, avg_loss = 0.0713\n",
            "t = 18, avg_loss = 0.2484\n",
            "t = 19, avg_loss = 0.1640\n",
            "t = 20, avg_loss = 0.1194\n",
            "t = 21, avg_loss = 0.0792\n",
            "t = 22, avg_loss = 0.1383\n",
            "t = 23, avg_loss = 0.1170\n",
            "t = 24, avg_loss = 0.1142\n",
            "t = 25, avg_loss = 0.1300\n",
            "Checking accuracy on train set\n",
            "Got 358 / 400 correct (89.50)\n",
            "acc = 0.895000\n",
            "Starting epoch 51 / 80\n",
            "t = 1, avg_loss = 0.1237\n",
            "t = 2, avg_loss = 0.1611\n",
            "t = 3, avg_loss = 0.0821\n",
            "t = 4, avg_loss = 0.0794\n",
            "t = 5, avg_loss = 0.0892\n",
            "t = 6, avg_loss = 0.0852\n",
            "t = 7, avg_loss = 0.0704\n",
            "t = 8, avg_loss = 0.1054\n",
            "t = 9, avg_loss = 0.1220\n",
            "t = 10, avg_loss = 0.0604\n",
            "t = 11, avg_loss = 0.0877\n",
            "t = 12, avg_loss = 0.0964\n",
            "t = 13, avg_loss = 0.0688\n",
            "t = 14, avg_loss = 0.1054\n",
            "t = 15, avg_loss = 0.1046\n",
            "t = 16, avg_loss = 0.1997\n",
            "t = 17, avg_loss = 0.1699\n",
            "t = 18, avg_loss = 0.2213\n",
            "t = 19, avg_loss = 0.0796\n",
            "t = 20, avg_loss = 0.0688\n",
            "t = 21, avg_loss = 0.1144\n",
            "t = 22, avg_loss = 0.0409\n",
            "t = 23, avg_loss = 0.0655\n",
            "t = 24, avg_loss = 0.0882\n",
            "t = 25, avg_loss = 0.1188\n",
            "Checking accuracy on train set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 52 / 80\n",
            "t = 1, avg_loss = 0.0667\n",
            "t = 2, avg_loss = 0.0904\n",
            "t = 3, avg_loss = 0.1964\n",
            "t = 4, avg_loss = 0.1602\n",
            "t = 5, avg_loss = 0.1033\n",
            "t = 6, avg_loss = 0.0884\n",
            "t = 7, avg_loss = 0.1124\n",
            "t = 8, avg_loss = 0.0809\n",
            "t = 9, avg_loss = 0.0548\n",
            "t = 10, avg_loss = 0.0587\n",
            "t = 11, avg_loss = 0.0945\n",
            "t = 12, avg_loss = 0.0598\n",
            "t = 13, avg_loss = 0.0959\n",
            "t = 14, avg_loss = 0.0857\n",
            "t = 15, avg_loss = 0.0555\n",
            "t = 16, avg_loss = 0.0854\n",
            "t = 17, avg_loss = 0.0826\n",
            "t = 18, avg_loss = 0.0670\n",
            "t = 19, avg_loss = 0.1247\n",
            "t = 20, avg_loss = 0.0800\n",
            "t = 21, avg_loss = 0.1454\n",
            "t = 22, avg_loss = 0.0578\n",
            "t = 23, avg_loss = 0.0701\n",
            "t = 24, avg_loss = 0.0672\n",
            "t = 25, avg_loss = 0.1418\n",
            "Checking accuracy on train set\n",
            "Got 351 / 400 correct (87.75)\n",
            "acc = 0.877500\n",
            "Starting epoch 53 / 80\n",
            "t = 1, avg_loss = 0.0892\n",
            "t = 2, avg_loss = 0.0601\n",
            "t = 3, avg_loss = 0.1191\n",
            "t = 4, avg_loss = 0.1808\n",
            "t = 5, avg_loss = 0.1417\n",
            "t = 6, avg_loss = 0.0288\n",
            "t = 7, avg_loss = 0.0424\n",
            "t = 8, avg_loss = 0.1231\n",
            "t = 9, avg_loss = 0.1175\n",
            "t = 10, avg_loss = 0.1055\n",
            "t = 11, avg_loss = 0.1501\n",
            "t = 12, avg_loss = 0.0313\n",
            "t = 13, avg_loss = 0.1103\n",
            "t = 14, avg_loss = 0.0667\n",
            "t = 15, avg_loss = 0.0571\n",
            "t = 16, avg_loss = 0.0894\n",
            "t = 17, avg_loss = 0.1040\n",
            "t = 18, avg_loss = 0.1147\n",
            "t = 19, avg_loss = 0.1007\n",
            "t = 20, avg_loss = 0.1481\n",
            "t = 21, avg_loss = 0.0626\n",
            "t = 22, avg_loss = 0.0839\n",
            "t = 23, avg_loss = 0.0714\n",
            "t = 24, avg_loss = 0.0634\n",
            "t = 25, avg_loss = 0.1025\n",
            "Checking accuracy on train set\n",
            "Got 343 / 400 correct (85.75)\n",
            "acc = 0.857500\n",
            "Starting epoch 54 / 80\n",
            "t = 1, avg_loss = 0.1008\n",
            "t = 2, avg_loss = 0.0798\n",
            "t = 3, avg_loss = 0.1301\n",
            "t = 4, avg_loss = 0.1064\n",
            "t = 5, avg_loss = 0.0479\n",
            "t = 6, avg_loss = 0.0188\n",
            "t = 7, avg_loss = 0.0998\n",
            "t = 8, avg_loss = 0.1705\n",
            "t = 9, avg_loss = 0.1018\n",
            "t = 10, avg_loss = 0.1590\n",
            "t = 11, avg_loss = 0.1000\n",
            "t = 12, avg_loss = 0.0414\n",
            "t = 13, avg_loss = 0.0509\n",
            "t = 14, avg_loss = 0.1749\n",
            "t = 15, avg_loss = 0.1486\n",
            "t = 16, avg_loss = 0.1208\n",
            "t = 17, avg_loss = 0.0868\n",
            "t = 18, avg_loss = 0.0932\n",
            "t = 19, avg_loss = 0.1002\n",
            "t = 20, avg_loss = 0.1051\n",
            "t = 21, avg_loss = 0.2012\n",
            "t = 22, avg_loss = 0.1129\n",
            "t = 23, avg_loss = 0.0815\n",
            "t = 24, avg_loss = 0.1200\n",
            "t = 25, avg_loss = 0.0905\n",
            "Checking accuracy on train set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 55 / 80\n",
            "t = 1, avg_loss = 0.0968\n",
            "t = 2, avg_loss = 0.0632\n",
            "t = 3, avg_loss = 0.0326\n",
            "t = 4, avg_loss = 0.1195\n",
            "t = 5, avg_loss = 0.0762\n",
            "t = 6, avg_loss = 0.1155\n",
            "t = 7, avg_loss = 0.0990\n",
            "t = 8, avg_loss = 0.0677\n",
            "t = 9, avg_loss = 0.1270\n",
            "t = 10, avg_loss = 0.0922\n",
            "t = 11, avg_loss = 0.0735\n",
            "t = 12, avg_loss = 0.0822\n",
            "t = 13, avg_loss = 0.0776\n",
            "t = 14, avg_loss = 0.0657\n",
            "t = 15, avg_loss = 0.0946\n",
            "t = 16, avg_loss = 0.0762\n",
            "t = 17, avg_loss = 0.0626\n",
            "t = 18, avg_loss = 0.1064\n",
            "t = 19, avg_loss = 0.1860\n",
            "t = 20, avg_loss = 0.1991\n",
            "t = 21, avg_loss = 0.1758\n",
            "t = 22, avg_loss = 0.1145\n",
            "t = 23, avg_loss = 0.0551\n",
            "t = 24, avg_loss = 0.0562\n",
            "t = 25, avg_loss = 0.1238\n",
            "Checking accuracy on train set\n",
            "Got 358 / 400 correct (89.50)\n",
            "acc = 0.895000\n",
            "Starting epoch 56 / 80\n",
            "t = 1, avg_loss = 0.0828\n",
            "t = 2, avg_loss = 0.0401\n",
            "t = 3, avg_loss = 0.1329\n",
            "t = 4, avg_loss = 0.0916\n",
            "t = 5, avg_loss = 0.1860\n",
            "t = 6, avg_loss = 0.0337\n",
            "t = 7, avg_loss = 0.0347\n",
            "t = 8, avg_loss = 0.0466\n",
            "t = 9, avg_loss = 0.0946\n",
            "t = 10, avg_loss = 0.0842\n",
            "t = 11, avg_loss = 0.0751\n",
            "t = 12, avg_loss = 0.0902\n",
            "t = 13, avg_loss = 0.2081\n",
            "t = 14, avg_loss = 0.0902\n",
            "t = 15, avg_loss = 0.1430\n",
            "t = 16, avg_loss = 0.0908\n",
            "t = 17, avg_loss = 0.1560\n",
            "t = 18, avg_loss = 0.0864\n",
            "t = 19, avg_loss = 0.1667\n",
            "t = 20, avg_loss = 0.1263\n",
            "t = 21, avg_loss = 0.1628\n",
            "t = 22, avg_loss = 0.1059\n",
            "t = 23, avg_loss = 0.1434\n",
            "t = 24, avg_loss = 0.0574\n",
            "t = 25, avg_loss = 0.1171\n",
            "Checking accuracy on train set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 57 / 80\n",
            "t = 1, avg_loss = 0.1468\n",
            "t = 2, avg_loss = 0.1149\n",
            "t = 3, avg_loss = 0.0741\n",
            "t = 4, avg_loss = 0.0694\n",
            "t = 5, avg_loss = 0.1035\n",
            "t = 6, avg_loss = 0.0317\n",
            "t = 7, avg_loss = 0.1304\n",
            "t = 8, avg_loss = 0.0648\n",
            "t = 9, avg_loss = 0.1452\n",
            "t = 10, avg_loss = 0.0740\n",
            "t = 11, avg_loss = 0.2257\n",
            "t = 12, avg_loss = 0.0887\n",
            "t = 13, avg_loss = 0.0607\n",
            "t = 14, avg_loss = 0.1066\n",
            "t = 15, avg_loss = 0.0925\n",
            "t = 16, avg_loss = 0.0802\n",
            "t = 17, avg_loss = 0.0614\n",
            "t = 18, avg_loss = 0.0769\n",
            "t = 19, avg_loss = 0.1571\n",
            "t = 20, avg_loss = 0.0702\n",
            "t = 21, avg_loss = 0.1583\n",
            "t = 22, avg_loss = 0.2441\n",
            "t = 23, avg_loss = 0.1082\n",
            "t = 24, avg_loss = 0.0612\n",
            "t = 25, avg_loss = 0.0919\n",
            "Checking accuracy on train set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 58 / 80\n",
            "t = 1, avg_loss = 0.1793\n",
            "t = 2, avg_loss = 0.1276\n",
            "t = 3, avg_loss = 0.1137\n",
            "t = 4, avg_loss = 0.1102\n",
            "t = 5, avg_loss = 0.1070\n",
            "t = 6, avg_loss = 0.1106\n",
            "t = 7, avg_loss = 0.1294\n",
            "t = 8, avg_loss = 0.0851\n",
            "t = 9, avg_loss = 0.0797\n",
            "t = 10, avg_loss = 0.0702\n",
            "t = 11, avg_loss = 0.1788\n",
            "t = 12, avg_loss = 0.1255\n",
            "t = 13, avg_loss = 0.0918\n",
            "t = 14, avg_loss = 0.0613\n",
            "t = 15, avg_loss = 0.0967\n",
            "t = 16, avg_loss = 0.1292\n",
            "t = 17, avg_loss = 0.0621\n",
            "t = 18, avg_loss = 0.1381\n",
            "t = 19, avg_loss = 0.2022\n",
            "t = 20, avg_loss = 0.1109\n",
            "t = 21, avg_loss = 0.0969\n",
            "t = 22, avg_loss = 0.0671\n",
            "t = 23, avg_loss = 0.0677\n",
            "t = 24, avg_loss = 0.1163\n",
            "t = 25, avg_loss = 0.0962\n",
            "Checking accuracy on train set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 59 / 80\n",
            "t = 1, avg_loss = 0.1623\n",
            "t = 2, avg_loss = 0.0652\n",
            "t = 3, avg_loss = 0.1192\n",
            "t = 4, avg_loss = 0.0468\n",
            "t = 5, avg_loss = 0.0692\n",
            "t = 6, avg_loss = 0.1247\n",
            "t = 7, avg_loss = 0.0962\n",
            "t = 8, avg_loss = 0.1175\n",
            "t = 9, avg_loss = 0.1381\n",
            "t = 10, avg_loss = 0.0622\n",
            "t = 11, avg_loss = 0.0407\n",
            "t = 12, avg_loss = 0.0982\n",
            "t = 13, avg_loss = 0.0811\n",
            "t = 14, avg_loss = 0.0715\n",
            "t = 15, avg_loss = 0.1559\n",
            "t = 16, avg_loss = 0.0607\n",
            "t = 17, avg_loss = 0.0598\n",
            "t = 18, avg_loss = 0.0744\n",
            "t = 19, avg_loss = 0.0611\n",
            "t = 20, avg_loss = 0.1027\n",
            "t = 21, avg_loss = 0.0999\n",
            "t = 22, avg_loss = 0.1223\n",
            "t = 23, avg_loss = 0.1455\n",
            "t = 24, avg_loss = 0.0517\n",
            "t = 25, avg_loss = 0.1868\n",
            "Checking accuracy on train set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 60 / 80\n",
            "t = 1, avg_loss = 0.0523\n",
            "t = 2, avg_loss = 0.0404\n",
            "t = 3, avg_loss = 0.0964\n",
            "t = 4, avg_loss = 0.0906\n",
            "t = 5, avg_loss = 0.0580\n",
            "t = 6, avg_loss = 0.1585\n",
            "t = 7, avg_loss = 0.0412\n",
            "t = 8, avg_loss = 0.0558\n",
            "t = 9, avg_loss = 0.0538\n",
            "t = 10, avg_loss = 0.1708\n",
            "t = 11, avg_loss = 0.0656\n",
            "t = 12, avg_loss = 0.0854\n",
            "t = 13, avg_loss = 0.0548\n",
            "t = 14, avg_loss = 0.0712\n",
            "t = 15, avg_loss = 0.0563\n",
            "t = 16, avg_loss = 0.0548\n",
            "t = 17, avg_loss = 0.1226\n",
            "t = 18, avg_loss = 0.0530\n",
            "t = 19, avg_loss = 0.0500\n",
            "t = 20, avg_loss = 0.0567\n",
            "t = 21, avg_loss = 0.0831\n",
            "t = 22, avg_loss = 0.1027\n",
            "t = 23, avg_loss = 0.0554\n",
            "t = 24, avg_loss = 0.1758\n",
            "t = 25, avg_loss = 0.0397\n",
            "Checking accuracy on train set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 61 / 80\n",
            "t = 1, avg_loss = 0.0934\n",
            "t = 2, avg_loss = 0.0501\n",
            "t = 3, avg_loss = 0.0766\n",
            "t = 4, avg_loss = 0.1556\n",
            "t = 5, avg_loss = 0.0478\n",
            "t = 6, avg_loss = 0.0609\n",
            "t = 7, avg_loss = 0.0588\n",
            "t = 8, avg_loss = 0.1783\n",
            "t = 9, avg_loss = 0.0617\n",
            "t = 10, avg_loss = 0.1794\n",
            "t = 11, avg_loss = 0.0895\n",
            "t = 12, avg_loss = 0.0505\n",
            "t = 13, avg_loss = 0.0983\n",
            "t = 14, avg_loss = 0.0946\n",
            "t = 15, avg_loss = 0.1058\n",
            "t = 16, avg_loss = 0.0991\n",
            "t = 17, avg_loss = 0.3200\n",
            "t = 18, avg_loss = 0.1197\n",
            "t = 19, avg_loss = 0.1245\n",
            "t = 20, avg_loss = 0.0524\n",
            "t = 21, avg_loss = 0.0940\n",
            "t = 22, avg_loss = 0.0689\n",
            "t = 23, avg_loss = 0.1095\n",
            "t = 24, avg_loss = 0.2649\n",
            "t = 25, avg_loss = 0.0916\n",
            "Checking accuracy on train set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 62 / 80\n",
            "t = 1, avg_loss = 0.0821\n",
            "t = 2, avg_loss = 0.0580\n",
            "t = 3, avg_loss = 0.1617\n",
            "t = 4, avg_loss = 0.0754\n",
            "t = 5, avg_loss = 0.0542\n",
            "t = 6, avg_loss = 0.0794\n",
            "t = 7, avg_loss = 0.0474\n",
            "t = 8, avg_loss = 0.1918\n",
            "t = 9, avg_loss = 0.0405\n",
            "t = 10, avg_loss = 0.0679\n",
            "t = 11, avg_loss = 0.0762\n",
            "t = 12, avg_loss = 0.0366\n",
            "t = 13, avg_loss = 0.1436\n",
            "t = 14, avg_loss = 0.0581\n",
            "t = 15, avg_loss = 0.0854\n",
            "t = 16, avg_loss = 0.0742\n",
            "t = 17, avg_loss = 0.1040\n",
            "t = 18, avg_loss = 0.1685\n",
            "t = 19, avg_loss = 0.1196\n",
            "t = 20, avg_loss = 0.0343\n",
            "t = 21, avg_loss = 0.1199\n",
            "t = 22, avg_loss = 0.1087\n",
            "t = 23, avg_loss = 0.1944\n",
            "t = 24, avg_loss = 0.1132\n",
            "t = 25, avg_loss = 0.0733\n",
            "Checking accuracy on train set\n",
            "Got 358 / 400 correct (89.50)\n",
            "acc = 0.895000\n",
            "Starting epoch 63 / 80\n",
            "t = 1, avg_loss = 0.0955\n",
            "t = 2, avg_loss = 0.0594\n",
            "t = 3, avg_loss = 0.0450\n",
            "t = 4, avg_loss = 0.0429\n",
            "t = 5, avg_loss = 0.0562\n",
            "t = 6, avg_loss = 0.0482\n",
            "t = 7, avg_loss = 0.0659\n",
            "t = 8, avg_loss = 0.1319\n",
            "t = 9, avg_loss = 0.0839\n",
            "t = 10, avg_loss = 0.1735\n",
            "t = 11, avg_loss = 0.1102\n",
            "t = 12, avg_loss = 0.0867\n",
            "t = 13, avg_loss = 0.1087\n",
            "t = 14, avg_loss = 0.0853\n",
            "t = 15, avg_loss = 0.0493\n",
            "t = 16, avg_loss = 0.0911\n",
            "t = 17, avg_loss = 0.1140\n",
            "t = 18, avg_loss = 0.0821\n",
            "t = 19, avg_loss = 0.0777\n",
            "t = 20, avg_loss = 0.0495\n",
            "t = 21, avg_loss = 0.2265\n",
            "t = 22, avg_loss = 0.0873\n",
            "t = 23, avg_loss = 0.0650\n",
            "t = 24, avg_loss = 0.1217\n",
            "t = 25, avg_loss = 0.1092\n",
            "Checking accuracy on train set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 64 / 80\n",
            "t = 1, avg_loss = 0.1050\n",
            "t = 2, avg_loss = 0.0285\n",
            "t = 3, avg_loss = 0.1580\n",
            "t = 4, avg_loss = 0.0785\n",
            "t = 5, avg_loss = 0.0613\n",
            "t = 6, avg_loss = 0.0545\n",
            "t = 7, avg_loss = 0.1714\n",
            "t = 8, avg_loss = 0.0868\n",
            "t = 9, avg_loss = 0.0523\n",
            "t = 10, avg_loss = 0.0292\n",
            "t = 11, avg_loss = 0.0925\n",
            "t = 12, avg_loss = 0.0391\n",
            "t = 13, avg_loss = 0.1078\n",
            "t = 14, avg_loss = 0.0923\n",
            "t = 15, avg_loss = 0.0878\n",
            "t = 16, avg_loss = 0.0503\n",
            "t = 17, avg_loss = 0.1184\n",
            "t = 18, avg_loss = 0.0885\n",
            "t = 19, avg_loss = 0.1378\n",
            "t = 20, avg_loss = 0.0742\n",
            "t = 21, avg_loss = 0.0335\n",
            "t = 22, avg_loss = 0.0380\n",
            "t = 23, avg_loss = 0.0761\n",
            "t = 24, avg_loss = 0.0499\n",
            "t = 25, avg_loss = 0.0818\n",
            "Checking accuracy on train set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 65 / 80\n",
            "t = 1, avg_loss = 0.0663\n",
            "t = 2, avg_loss = 0.0425\n",
            "t = 3, avg_loss = 0.0751\n",
            "t = 4, avg_loss = 0.0401\n",
            "t = 5, avg_loss = 0.0568\n",
            "t = 6, avg_loss = 0.1570\n",
            "t = 7, avg_loss = 0.0569\n",
            "t = 8, avg_loss = 0.0343\n",
            "t = 9, avg_loss = 0.0424\n",
            "t = 10, avg_loss = 0.0643\n",
            "t = 11, avg_loss = 0.1276\n",
            "t = 12, avg_loss = 0.0752\n",
            "t = 13, avg_loss = 0.0429\n",
            "t = 14, avg_loss = 0.0865\n",
            "t = 15, avg_loss = 0.0358\n",
            "t = 16, avg_loss = 0.1409\n",
            "t = 17, avg_loss = 0.0889\n",
            "t = 18, avg_loss = 0.0508\n",
            "t = 19, avg_loss = 0.0310\n",
            "t = 20, avg_loss = 0.1043\n",
            "t = 21, avg_loss = 0.0531\n",
            "t = 22, avg_loss = 0.0383\n",
            "t = 23, avg_loss = 0.0922\n",
            "t = 24, avg_loss = 0.0449\n",
            "t = 25, avg_loss = 0.0517\n",
            "Checking accuracy on train set\n",
            "Got 358 / 400 correct (89.50)\n",
            "acc = 0.895000\n",
            "Starting epoch 66 / 80\n",
            "t = 1, avg_loss = 0.0506\n",
            "t = 2, avg_loss = 0.0801\n",
            "t = 3, avg_loss = 0.0588\n",
            "t = 4, avg_loss = 0.0453\n",
            "t = 5, avg_loss = 0.0636\n",
            "t = 6, avg_loss = 0.0795\n",
            "t = 7, avg_loss = 0.0460\n",
            "t = 8, avg_loss = 0.0425\n",
            "t = 9, avg_loss = 0.1780\n",
            "t = 10, avg_loss = 0.0463\n",
            "t = 11, avg_loss = 0.0518\n",
            "t = 12, avg_loss = 0.1360\n",
            "t = 13, avg_loss = 0.0854\n",
            "t = 14, avg_loss = 0.0577\n",
            "t = 15, avg_loss = 0.0748\n",
            "t = 16, avg_loss = 0.0856\n",
            "t = 17, avg_loss = 0.0493\n",
            "t = 18, avg_loss = 0.0370\n",
            "t = 19, avg_loss = 0.0473\n",
            "t = 20, avg_loss = 0.1342\n",
            "t = 21, avg_loss = 0.0395\n",
            "t = 22, avg_loss = 0.1060\n",
            "t = 23, avg_loss = 0.0722\n",
            "t = 24, avg_loss = 0.0570\n",
            "t = 25, avg_loss = 0.0388\n",
            "Checking accuracy on train set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 67 / 80\n",
            "t = 1, avg_loss = 0.0435\n",
            "t = 2, avg_loss = 0.0576\n",
            "t = 3, avg_loss = 0.1433\n",
            "t = 4, avg_loss = 0.0280\n",
            "t = 5, avg_loss = 0.0340\n",
            "t = 6, avg_loss = 0.1001\n",
            "t = 7, avg_loss = 0.0510\n",
            "t = 8, avg_loss = 0.0652\n",
            "t = 9, avg_loss = 0.0686\n",
            "t = 10, avg_loss = 0.0618\n",
            "t = 11, avg_loss = 0.0534\n",
            "t = 12, avg_loss = 0.0340\n",
            "t = 13, avg_loss = 0.0222\n",
            "t = 14, avg_loss = 0.0756\n",
            "t = 15, avg_loss = 0.0513\n",
            "t = 16, avg_loss = 0.0555\n",
            "t = 17, avg_loss = 0.1058\n",
            "t = 18, avg_loss = 0.0976\n",
            "t = 19, avg_loss = 0.1515\n",
            "t = 20, avg_loss = 0.0339\n",
            "t = 21, avg_loss = 0.0383\n",
            "t = 22, avg_loss = 0.0468\n",
            "t = 23, avg_loss = 0.0546\n",
            "t = 24, avg_loss = 0.0661\n",
            "t = 25, avg_loss = 0.0574\n",
            "Checking accuracy on train set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 68 / 80\n",
            "t = 1, avg_loss = 0.0386\n",
            "t = 2, avg_loss = 0.0604\n",
            "t = 3, avg_loss = 0.0623\n",
            "t = 4, avg_loss = 0.0288\n",
            "t = 5, avg_loss = 0.0647\n",
            "t = 6, avg_loss = 0.0468\n",
            "t = 7, avg_loss = 0.0579\n",
            "t = 8, avg_loss = 0.0723\n",
            "t = 9, avg_loss = 0.0284\n",
            "t = 10, avg_loss = 0.0627\n",
            "t = 11, avg_loss = 0.1628\n",
            "t = 12, avg_loss = 0.0776\n",
            "t = 13, avg_loss = 0.0582\n",
            "t = 14, avg_loss = 0.0337\n",
            "t = 15, avg_loss = 0.0880\n",
            "t = 16, avg_loss = 0.0639\n",
            "t = 17, avg_loss = 0.0612\n",
            "t = 18, avg_loss = 0.0557\n",
            "t = 19, avg_loss = 0.0717\n",
            "t = 20, avg_loss = 0.0710\n",
            "t = 21, avg_loss = 0.0642\n",
            "t = 22, avg_loss = 0.0897\n",
            "t = 23, avg_loss = 0.0417\n",
            "t = 24, avg_loss = 0.0645\n",
            "t = 25, avg_loss = 0.0352\n",
            "Checking accuracy on train set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 69 / 80\n",
            "t = 1, avg_loss = 0.1424\n",
            "t = 2, avg_loss = 0.0539\n",
            "t = 3, avg_loss = 0.0301\n",
            "t = 4, avg_loss = 0.1058\n",
            "t = 5, avg_loss = 0.0747\n",
            "t = 6, avg_loss = 0.0611\n",
            "t = 7, avg_loss = 0.0620\n",
            "t = 8, avg_loss = 0.0774\n",
            "t = 9, avg_loss = 0.0740\n",
            "t = 10, avg_loss = 0.0425\n",
            "t = 11, avg_loss = 0.1566\n",
            "t = 12, avg_loss = 0.0430\n",
            "t = 13, avg_loss = 0.0781\n",
            "t = 14, avg_loss = 0.0612\n",
            "t = 15, avg_loss = 0.0367\n",
            "t = 16, avg_loss = 0.1346\n",
            "t = 17, avg_loss = 0.0486\n",
            "t = 18, avg_loss = 0.0562\n",
            "t = 19, avg_loss = 0.0492\n",
            "t = 20, avg_loss = 0.0717\n",
            "t = 21, avg_loss = 0.0998\n",
            "t = 22, avg_loss = 0.0430\n",
            "t = 23, avg_loss = 0.0375\n",
            "t = 24, avg_loss = 0.0703\n",
            "t = 25, avg_loss = 0.0239\n",
            "Checking accuracy on train set\n",
            "Got 340 / 400 correct (85.00)\n",
            "acc = 0.850000\n",
            "Starting epoch 70 / 80\n",
            "t = 1, avg_loss = 0.1840\n",
            "t = 2, avg_loss = 0.0810\n",
            "t = 3, avg_loss = 0.0570\n",
            "t = 4, avg_loss = 0.0264\n",
            "t = 5, avg_loss = 0.0276\n",
            "t = 6, avg_loss = 0.0850\n",
            "t = 7, avg_loss = 0.0924\n",
            "t = 8, avg_loss = 0.0696\n",
            "t = 9, avg_loss = 0.1181\n",
            "t = 10, avg_loss = 0.0592\n",
            "t = 11, avg_loss = 0.1309\n",
            "t = 12, avg_loss = 0.0553\n",
            "t = 13, avg_loss = 0.0956\n",
            "t = 14, avg_loss = 0.0618\n",
            "t = 15, avg_loss = 0.0385\n",
            "t = 16, avg_loss = 0.0421\n",
            "t = 17, avg_loss = 0.0400\n",
            "t = 18, avg_loss = 0.0574\n",
            "t = 19, avg_loss = 0.0429\n",
            "t = 20, avg_loss = 0.0876\n",
            "t = 21, avg_loss = 0.0622\n",
            "t = 22, avg_loss = 0.0791\n",
            "t = 23, avg_loss = 0.1318\n",
            "t = 24, avg_loss = 0.0678\n",
            "t = 25, avg_loss = 0.0612\n",
            "Checking accuracy on train set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 71 / 80\n",
            "t = 1, avg_loss = 0.0672\n",
            "t = 2, avg_loss = 0.0638\n",
            "t = 3, avg_loss = 0.0403\n",
            "t = 4, avg_loss = 0.0624\n",
            "t = 5, avg_loss = 0.0767\n",
            "t = 6, avg_loss = 0.0322\n",
            "t = 7, avg_loss = 0.0405\n",
            "t = 8, avg_loss = 0.1315\n",
            "t = 9, avg_loss = 0.0818\n",
            "t = 10, avg_loss = 0.0692\n",
            "t = 11, avg_loss = 0.0427\n",
            "t = 12, avg_loss = 0.0429\n",
            "t = 13, avg_loss = 0.0975\n",
            "t = 14, avg_loss = 0.1230\n",
            "t = 15, avg_loss = 0.0378\n",
            "t = 16, avg_loss = 0.0599\n",
            "t = 17, avg_loss = 0.0617\n",
            "t = 18, avg_loss = 0.0661\n",
            "t = 19, avg_loss = 0.0794\n",
            "t = 20, avg_loss = 0.1582\n",
            "t = 21, avg_loss = 0.0289\n",
            "t = 22, avg_loss = 0.0886\n",
            "t = 23, avg_loss = 0.0871\n",
            "t = 24, avg_loss = 0.0781\n",
            "t = 25, avg_loss = 0.0738\n",
            "Checking accuracy on train set\n",
            "Got 358 / 400 correct (89.50)\n",
            "acc = 0.895000\n",
            "Starting epoch 72 / 80\n",
            "t = 1, avg_loss = 0.1027\n",
            "t = 2, avg_loss = 0.1585\n",
            "t = 3, avg_loss = 0.0882\n",
            "t = 4, avg_loss = 0.0293\n",
            "t = 5, avg_loss = 0.0365\n",
            "t = 6, avg_loss = 0.1019\n",
            "t = 7, avg_loss = 0.1502\n",
            "t = 8, avg_loss = 0.1154\n",
            "t = 9, avg_loss = 0.0645\n",
            "t = 10, avg_loss = 0.1114\n",
            "t = 11, avg_loss = 0.0254\n",
            "t = 12, avg_loss = 0.1062\n",
            "t = 13, avg_loss = 0.0566\n",
            "t = 14, avg_loss = 0.1232\n",
            "t = 15, avg_loss = 0.0839\n",
            "t = 16, avg_loss = 0.0835\n",
            "t = 17, avg_loss = 0.1205\n",
            "t = 18, avg_loss = 0.0924\n",
            "t = 19, avg_loss = 0.0726\n",
            "t = 20, avg_loss = 0.0762\n",
            "t = 21, avg_loss = 0.0693\n",
            "t = 22, avg_loss = 0.0472\n",
            "t = 23, avg_loss = 0.1307\n",
            "t = 24, avg_loss = 0.1341\n",
            "t = 25, avg_loss = 0.0266\n",
            "Checking accuracy on train set\n",
            "Got 363 / 400 correct (90.75)\n",
            "acc = 0.907500\n",
            "Starting epoch 73 / 80\n",
            "t = 1, avg_loss = 0.1041\n",
            "t = 2, avg_loss = 0.0242\n",
            "t = 3, avg_loss = 0.0425\n",
            "t = 4, avg_loss = 0.0631\n",
            "t = 5, avg_loss = 0.1725\n",
            "t = 6, avg_loss = 0.0311\n",
            "t = 7, avg_loss = 0.0296\n",
            "t = 8, avg_loss = 0.0465\n",
            "t = 9, avg_loss = 0.0462\n",
            "t = 10, avg_loss = 0.0726\n",
            "t = 11, avg_loss = 0.0512\n",
            "t = 12, avg_loss = 0.1149\n",
            "t = 13, avg_loss = 0.0564\n",
            "t = 14, avg_loss = 0.0443\n",
            "t = 15, avg_loss = 0.1088\n",
            "t = 16, avg_loss = 0.1203\n",
            "t = 17, avg_loss = 0.0422\n",
            "t = 18, avg_loss = 0.0866\n",
            "t = 19, avg_loss = 0.1021\n",
            "t = 20, avg_loss = 0.0781\n",
            "t = 21, avg_loss = 0.0681\n",
            "t = 22, avg_loss = 0.0674\n",
            "t = 23, avg_loss = 0.1092\n",
            "t = 24, avg_loss = 0.0619\n",
            "t = 25, avg_loss = 0.0937\n",
            "Checking accuracy on train set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 74 / 80\n",
            "t = 1, avg_loss = 0.0525\n",
            "t = 2, avg_loss = 0.0252\n",
            "t = 3, avg_loss = 0.0946\n",
            "t = 4, avg_loss = 0.0742\n",
            "t = 5, avg_loss = 0.0623\n",
            "t = 6, avg_loss = 0.0480\n",
            "t = 7, avg_loss = 0.0610\n",
            "t = 8, avg_loss = 0.1211\n",
            "t = 9, avg_loss = 0.0941\n",
            "t = 10, avg_loss = 0.0577\n",
            "t = 11, avg_loss = 0.0519\n",
            "t = 12, avg_loss = 0.0943\n",
            "t = 13, avg_loss = 0.0585\n",
            "t = 14, avg_loss = 0.0506\n",
            "t = 15, avg_loss = 0.0463\n",
            "t = 16, avg_loss = 0.0632\n",
            "t = 17, avg_loss = 0.1269\n",
            "t = 18, avg_loss = 0.0735\n",
            "t = 19, avg_loss = 0.0321\n",
            "t = 20, avg_loss = 0.0297\n",
            "t = 21, avg_loss = 0.0606\n",
            "t = 22, avg_loss = 0.1172\n",
            "t = 23, avg_loss = 0.0606\n",
            "t = 24, avg_loss = 0.0701\n",
            "t = 25, avg_loss = 0.0598\n",
            "Checking accuracy on train set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 75 / 80\n",
            "t = 1, avg_loss = 0.0604\n",
            "t = 2, avg_loss = 0.0366\n",
            "t = 3, avg_loss = 0.0562\n",
            "t = 4, avg_loss = 0.0537\n",
            "t = 5, avg_loss = 0.0413\n",
            "t = 6, avg_loss = 0.1032\n",
            "t = 7, avg_loss = 0.0628\n",
            "t = 8, avg_loss = 0.0376\n",
            "t = 9, avg_loss = 0.0502\n",
            "t = 10, avg_loss = 0.0493\n",
            "t = 11, avg_loss = 0.0754\n",
            "t = 12, avg_loss = 0.0497\n",
            "t = 13, avg_loss = 0.0669\n",
            "t = 14, avg_loss = 0.1046\n",
            "t = 15, avg_loss = 0.0545\n",
            "t = 16, avg_loss = 0.0654\n",
            "t = 17, avg_loss = 0.0467\n",
            "t = 18, avg_loss = 0.0714\n",
            "t = 19, avg_loss = 0.0455\n",
            "t = 20, avg_loss = 0.0591\n",
            "t = 21, avg_loss = 0.0652\n",
            "t = 22, avg_loss = 0.0242\n",
            "t = 23, avg_loss = 0.0737\n",
            "t = 24, avg_loss = 0.0381\n",
            "t = 25, avg_loss = 0.1149\n",
            "Checking accuracy on train set\n",
            "Got 358 / 400 correct (89.50)\n",
            "acc = 0.895000\n",
            "Starting epoch 76 / 80\n",
            "t = 1, avg_loss = 0.0993\n",
            "t = 2, avg_loss = 0.0438\n",
            "t = 3, avg_loss = 0.0352\n",
            "t = 4, avg_loss = 0.0600\n",
            "t = 5, avg_loss = 0.1041\n",
            "t = 6, avg_loss = 0.1044\n",
            "t = 7, avg_loss = 0.0692\n",
            "t = 8, avg_loss = 0.0792\n",
            "t = 9, avg_loss = 0.0447\n",
            "t = 10, avg_loss = 0.0299\n",
            "t = 11, avg_loss = 0.0446\n",
            "t = 12, avg_loss = 0.0708\n",
            "t = 13, avg_loss = 0.0328\n",
            "t = 14, avg_loss = 0.0230\n",
            "t = 15, avg_loss = 0.0252\n",
            "t = 16, avg_loss = 0.0542\n",
            "t = 17, avg_loss = 0.0822\n",
            "t = 18, avg_loss = 0.1007\n",
            "t = 19, avg_loss = 0.0853\n",
            "t = 20, avg_loss = 0.0631\n",
            "t = 21, avg_loss = 0.1058\n",
            "t = 22, avg_loss = 0.0770\n",
            "t = 23, avg_loss = 0.0820\n",
            "t = 24, avg_loss = 0.0421\n",
            "t = 25, avg_loss = 0.0835\n",
            "Checking accuracy on train set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 77 / 80\n",
            "t = 1, avg_loss = 0.0392\n",
            "t = 2, avg_loss = 0.0429\n",
            "t = 3, avg_loss = 0.1058\n",
            "t = 4, avg_loss = 0.0377\n",
            "t = 5, avg_loss = 0.0482\n",
            "t = 6, avg_loss = 0.1125\n",
            "t = 7, avg_loss = 0.0719\n",
            "t = 8, avg_loss = 0.0393\n",
            "t = 9, avg_loss = 0.1193\n",
            "t = 10, avg_loss = 0.0419\n",
            "t = 11, avg_loss = 0.0623\n",
            "t = 12, avg_loss = 0.0926\n",
            "t = 13, avg_loss = 0.0478\n",
            "t = 14, avg_loss = 0.0392\n",
            "t = 15, avg_loss = 0.0692\n",
            "t = 16, avg_loss = 0.0645\n",
            "t = 17, avg_loss = 0.1020\n",
            "t = 18, avg_loss = 0.0404\n",
            "t = 19, avg_loss = 0.0478\n",
            "t = 20, avg_loss = 0.0648\n",
            "t = 21, avg_loss = 0.1252\n",
            "t = 22, avg_loss = 0.0380\n",
            "t = 23, avg_loss = 0.0489\n",
            "t = 24, avg_loss = 0.1756\n",
            "t = 25, avg_loss = 0.1031\n",
            "Checking accuracy on train set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 78 / 80\n",
            "t = 1, avg_loss = 0.0665\n",
            "t = 2, avg_loss = 0.1396\n",
            "t = 3, avg_loss = 0.1134\n",
            "t = 4, avg_loss = 0.0554\n",
            "t = 5, avg_loss = 0.0759\n",
            "t = 6, avg_loss = 0.0294\n",
            "t = 7, avg_loss = 0.0454\n",
            "t = 8, avg_loss = 0.0768\n",
            "t = 9, avg_loss = 0.0539\n",
            "t = 10, avg_loss = 0.0456\n",
            "t = 11, avg_loss = 0.1359\n",
            "t = 12, avg_loss = 0.0904\n",
            "t = 13, avg_loss = 0.0578\n",
            "t = 14, avg_loss = 0.0662\n",
            "t = 15, avg_loss = 0.0542\n",
            "t = 16, avg_loss = 0.0605\n",
            "t = 17, avg_loss = 0.0745\n",
            "t = 18, avg_loss = 0.0943\n",
            "t = 19, avg_loss = 0.0506\n",
            "t = 20, avg_loss = 0.0896\n",
            "t = 21, avg_loss = 0.0315\n",
            "t = 22, avg_loss = 0.0977\n",
            "t = 23, avg_loss = 0.0614\n",
            "t = 24, avg_loss = 0.0845\n",
            "t = 25, avg_loss = 0.1365\n",
            "Checking accuracy on train set\n",
            "Got 351 / 400 correct (87.75)\n",
            "acc = 0.877500\n",
            "Starting epoch 79 / 80\n",
            "t = 1, avg_loss = 0.0214\n",
            "t = 2, avg_loss = 0.0635\n",
            "t = 3, avg_loss = 0.0967\n",
            "t = 4, avg_loss = 0.0991\n",
            "t = 5, avg_loss = 0.0530\n",
            "t = 6, avg_loss = 0.0847\n",
            "t = 7, avg_loss = 0.0202\n",
            "t = 8, avg_loss = 0.0269\n",
            "t = 9, avg_loss = 0.0869\n",
            "t = 10, avg_loss = 0.0587\n",
            "t = 11, avg_loss = 0.1078\n",
            "t = 12, avg_loss = 0.0437\n",
            "t = 13, avg_loss = 0.0945\n",
            "t = 14, avg_loss = 0.0602\n",
            "t = 15, avg_loss = 0.0391\n",
            "t = 16, avg_loss = 0.0433\n",
            "t = 17, avg_loss = 0.0492\n",
            "t = 18, avg_loss = 0.0777\n",
            "t = 19, avg_loss = 0.0231\n",
            "t = 20, avg_loss = 0.1286\n",
            "t = 21, avg_loss = 0.0886\n",
            "t = 22, avg_loss = 0.0545\n",
            "t = 23, avg_loss = 0.0499\n",
            "t = 24, avg_loss = 0.0469\n",
            "t = 25, avg_loss = 0.0595\n",
            "Checking accuracy on train set\n",
            "Got 334 / 400 correct (83.50)\n",
            "acc = 0.835000\n",
            "Starting epoch 80 / 80\n",
            "t = 1, avg_loss = 0.0573\n",
            "t = 2, avg_loss = 0.0817\n",
            "t = 3, avg_loss = 0.1352\n",
            "t = 4, avg_loss = 0.0552\n",
            "t = 5, avg_loss = 0.0603\n",
            "t = 6, avg_loss = 0.0476\n",
            "t = 7, avg_loss = 0.0424\n",
            "t = 8, avg_loss = 0.0911\n",
            "t = 9, avg_loss = 0.0613\n",
            "t = 10, avg_loss = 0.0293\n",
            "t = 11, avg_loss = 0.1427\n",
            "t = 12, avg_loss = 0.0880\n",
            "t = 13, avg_loss = 0.0187\n",
            "t = 14, avg_loss = 0.0931\n",
            "t = 15, avg_loss = 0.0560\n",
            "t = 16, avg_loss = 0.0807\n",
            "t = 17, avg_loss = 0.0547\n",
            "t = 18, avg_loss = 0.1164\n",
            "t = 19, avg_loss = 0.0507\n",
            "t = 20, avg_loss = 0.0388\n",
            "t = 21, avg_loss = 0.0832\n",
            "t = 22, avg_loss = 0.0418\n",
            "t = 23, avg_loss = 0.1263\n",
            "t = 24, avg_loss = 0.0745\n",
            "t = 25, avg_loss = 0.0558\n",
            "Checking accuracy on train set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwQoVQhf5tgM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "4cbd660f-062f-4e4a-a2dd-e371fe897580"
      },
      "source": [
        "check_accuracy(model_gpu, test_loader, datatype='test')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking accuracy on test set\n",
            "Got 185 / 201 correct (92.04)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9203980099502488"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vu4XPvuqb7T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvoCj5uscUsz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_accurancy(acc_list):\n",
        "  plt.plot([i+1 for i in range((len(acc_list)))],acc_list)\n",
        "  print(\"Accurancy:\")\n",
        "  plt.show()\n",
        "\n",
        "def plot_loss_function(avg_loss_list):\n",
        "  plt.plot([print_every*batch_size*(i+1) for i in range((len(avg_loss_list)))],avg_loss_list)\n",
        "  print(\"Loss:\")\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfNGj_aLPv3d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "243a29f8-19c9-401f-cf69-a772264043ec"
      },
      "source": [
        "plot_accurancy(acc_list)\n",
        "plot_loss_function(avg_loss_list)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accurancy:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzuX5gLEeJfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def retry_from_backup():\n",
        "  model_gpu = model_base.type(gpu_dtype)\n",
        "  print(model_gpu)\n",
        "  loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) \n",
        "\n",
        "\n",
        "  checkpoint = torch.load(model_backup_path)\n",
        "  model_gpu.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  epoch = checkpoint['epoch']\n",
        "  loss = checkpoint['loss']\n",
        "  acc_list = checkpoint['acc_list']\n",
        "  print(\"starting from epoch: \" + str(epoch))\n",
        "  print(\"starting from loss: \" + str(loss))\n",
        "  print(acc_list)\n",
        "  \n",
        "  \n",
        "  train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=20, starting_from_epoch=epoch)\n",
        "  check_accuracy(model_gpu, valid_loader)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4H8kjAjB36R0",
        "colab_type": "code",
        "outputId": "df4210d1-e451-4a49-b4a4-0c77b82d7bed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "retry_from_backup()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Kerv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (4): ReLU(inplace=True)\n",
            "  (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (7): Kerv2d(32, 64, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
            "  (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (10): Conv2d(64, 100, kernel_size=(9, 9), stride=(1, 1), padding=(1, 1))\n",
            "  (11): ReLU(inplace=True)\n",
            "  (12): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (14): Dropout(p=0.5, inplace=False)\n",
            "  (15): Flatten()\n",
            "  (16): Linear(in_features=900, out_features=64, bias=True)\n",
            "  (17): ReLU(inplace=True)\n",
            "  (18): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n",
            "starting from epoch: 79\n",
            "starting from loss: tensor(0.0558, device='cuda:0', requires_grad=True)\n",
            "[0.5925, 0.78, 0.84, 0.86, 0.83, 0.8475, 0.845, 0.8725, 0.88, 0.8825, 0.8875, 0.885, 0.885, 0.88, 0.875, 0.89, 0.89, 0.8825, 0.865, 0.8875, 0.8925, 0.88, 0.88, 0.8975, 0.885, 0.885, 0.885, 0.89, 0.8975, 0.8925, 0.895, 0.8675, 0.87, 0.885, 0.875, 0.9, 0.875, 0.8525, 0.89, 0.87, 0.875, 0.895, 0.89, 0.8675, 0.8575, 0.905, 0.8625, 0.87, 0.88, 0.895, 0.8875, 0.8775, 0.8575, 0.89, 0.895, 0.89, 0.8875, 0.89, 0.8875, 0.8825, 0.8725, 0.895, 0.87, 0.8675, 0.895, 0.89, 0.8925, 0.8725, 0.85, 0.8875, 0.895, 0.9075, 0.8875, 0.885, 0.895, 0.8875, 0.8875, 0.8775, 0.835, 0.88]\n",
            "Starting epoch 79 / 98\n",
            "t = 1, avg_loss = 0.0836\n",
            "t = 2, avg_loss = 0.0360\n",
            "t = 3, avg_loss = 0.0961\n",
            "t = 4, avg_loss = 0.0609\n",
            "t = 5, avg_loss = 0.0892\n",
            "t = 6, avg_loss = 0.0385\n",
            "t = 7, avg_loss = 0.0525\n",
            "t = 8, avg_loss = 0.1140\n",
            "t = 9, avg_loss = 0.0255\n",
            "t = 10, avg_loss = 0.0601\n",
            "t = 11, avg_loss = 0.1979\n",
            "t = 12, avg_loss = 0.0362\n",
            "t = 13, avg_loss = 0.0765\n",
            "t = 14, avg_loss = 0.0527\n",
            "t = 15, avg_loss = 0.0751\n",
            "t = 16, avg_loss = 0.0986\n",
            "t = 17, avg_loss = 0.1118\n",
            "t = 18, avg_loss = 0.0509\n",
            "t = 19, avg_loss = 0.0610\n",
            "t = 20, avg_loss = 0.1415\n",
            "t = 21, avg_loss = 0.0670\n",
            "t = 22, avg_loss = 0.0510\n",
            "t = 23, avg_loss = 0.0886\n",
            "t = 24, avg_loss = 0.0395\n",
            "t = 25, avg_loss = 0.0889\n",
            "Checking accuracy on train set\n",
            "Got 342 / 400 correct (85.50)\n",
            "acc = 0.855000\n",
            "Starting epoch 80 / 98\n",
            "t = 1, avg_loss = 0.0780\n",
            "t = 2, avg_loss = 0.0650\n",
            "t = 3, avg_loss = 0.1139\n",
            "t = 4, avg_loss = 0.0721\n",
            "t = 5, avg_loss = 0.0900\n",
            "t = 6, avg_loss = 0.1278\n",
            "t = 7, avg_loss = 0.0687\n",
            "t = 8, avg_loss = 0.0618\n",
            "t = 9, avg_loss = 0.0299\n",
            "t = 10, avg_loss = 0.0942\n",
            "t = 11, avg_loss = 0.0510\n",
            "t = 12, avg_loss = 0.0774\n",
            "t = 13, avg_loss = 0.0579\n",
            "t = 14, avg_loss = 0.0833\n",
            "t = 15, avg_loss = 0.0462\n",
            "t = 16, avg_loss = 0.0549\n",
            "t = 17, avg_loss = 0.0836\n",
            "t = 18, avg_loss = 0.0421\n",
            "t = 19, avg_loss = 0.1705\n",
            "t = 20, avg_loss = 0.0901\n",
            "t = 21, avg_loss = 0.0381\n",
            "t = 22, avg_loss = 0.0482\n",
            "t = 23, avg_loss = 0.0489\n",
            "t = 24, avg_loss = 0.0659\n",
            "t = 25, avg_loss = 0.1204\n",
            "Checking accuracy on train set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 81 / 98\n",
            "t = 1, avg_loss = 0.0980\n",
            "t = 2, avg_loss = 0.0907\n",
            "t = 3, avg_loss = 0.0389\n",
            "t = 4, avg_loss = 0.0516\n",
            "t = 5, avg_loss = 0.0461\n",
            "t = 6, avg_loss = 0.0364\n",
            "t = 7, avg_loss = 0.1600\n",
            "t = 8, avg_loss = 0.0539\n",
            "t = 9, avg_loss = 0.1091\n",
            "t = 10, avg_loss = 0.0595\n",
            "t = 11, avg_loss = 0.1127\n",
            "t = 12, avg_loss = 0.0690\n",
            "t = 13, avg_loss = 0.0759\n",
            "t = 14, avg_loss = 0.1699\n",
            "t = 15, avg_loss = 0.2186\n",
            "t = 16, avg_loss = 0.0847\n",
            "t = 17, avg_loss = 0.0844\n",
            "t = 18, avg_loss = 0.1014\n",
            "t = 19, avg_loss = 0.0625\n",
            "t = 20, avg_loss = 0.0470\n",
            "t = 21, avg_loss = 0.0792\n",
            "t = 22, avg_loss = 0.1362\n",
            "t = 23, avg_loss = 0.1208\n",
            "t = 24, avg_loss = 0.1268\n",
            "t = 25, avg_loss = 0.1127\n",
            "Checking accuracy on train set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 82 / 98\n",
            "t = 1, avg_loss = 0.0604\n",
            "t = 2, avg_loss = 0.0920\n",
            "t = 3, avg_loss = 0.0671\n",
            "t = 4, avg_loss = 0.0514\n",
            "t = 5, avg_loss = 0.0487\n",
            "t = 6, avg_loss = 0.0458\n",
            "t = 7, avg_loss = 0.1184\n",
            "t = 8, avg_loss = 0.0624\n",
            "t = 9, avg_loss = 0.1046\n",
            "t = 10, avg_loss = 0.0820\n",
            "t = 11, avg_loss = 0.0468\n",
            "t = 12, avg_loss = 0.0479\n",
            "t = 13, avg_loss = 0.0423\n",
            "t = 14, avg_loss = 0.1188\n",
            "t = 15, avg_loss = 0.0994\n",
            "t = 16, avg_loss = 0.0826\n",
            "t = 17, avg_loss = 0.0854\n",
            "t = 18, avg_loss = 0.0749\n",
            "t = 19, avg_loss = 0.0753\n",
            "t = 20, avg_loss = 0.0767\n",
            "t = 21, avg_loss = 0.0465\n",
            "t = 22, avg_loss = 0.0711\n",
            "t = 23, avg_loss = 0.0198\n",
            "t = 24, avg_loss = 0.0595\n",
            "t = 25, avg_loss = 0.0696\n",
            "Checking accuracy on train set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 83 / 98\n",
            "t = 1, avg_loss = 0.0721\n",
            "t = 2, avg_loss = 0.0478\n",
            "t = 3, avg_loss = 0.0531\n",
            "t = 4, avg_loss = 0.0493\n",
            "t = 5, avg_loss = 0.1501\n",
            "t = 6, avg_loss = 0.0490\n",
            "t = 7, avg_loss = 0.0324\n",
            "t = 8, avg_loss = 0.0834\n",
            "t = 9, avg_loss = 0.0309\n",
            "t = 10, avg_loss = 0.0507\n",
            "t = 11, avg_loss = 0.0739\n",
            "t = 12, avg_loss = 0.0705\n",
            "t = 13, avg_loss = 0.0833\n",
            "t = 14, avg_loss = 0.0583\n",
            "t = 15, avg_loss = 0.0242\n",
            "t = 16, avg_loss = 0.1394\n",
            "t = 17, avg_loss = 0.0483\n",
            "t = 18, avg_loss = 0.0461\n",
            "t = 19, avg_loss = 0.0522\n",
            "t = 20, avg_loss = 0.0891\n",
            "t = 21, avg_loss = 0.0607\n",
            "t = 22, avg_loss = 0.0765\n",
            "t = 23, avg_loss = 0.0455\n",
            "t = 24, avg_loss = 0.0705\n",
            "t = 25, avg_loss = 0.1305\n",
            "Checking accuracy on train set\n",
            "Got 359 / 400 correct (89.75)\n",
            "acc = 0.897500\n",
            "Starting epoch 84 / 98\n",
            "t = 1, avg_loss = 0.0323\n",
            "t = 2, avg_loss = 0.0695\n",
            "t = 3, avg_loss = 0.0451\n",
            "t = 4, avg_loss = 0.0809\n",
            "t = 5, avg_loss = 0.0611\n",
            "t = 6, avg_loss = 0.0585\n",
            "t = 7, avg_loss = 0.1107\n",
            "t = 8, avg_loss = 0.0493\n",
            "t = 9, avg_loss = 0.0999\n",
            "t = 10, avg_loss = 0.0973\n",
            "t = 11, avg_loss = 0.0336\n",
            "t = 12, avg_loss = 0.0469\n",
            "t = 13, avg_loss = 0.0256\n",
            "t = 14, avg_loss = 0.0581\n",
            "t = 15, avg_loss = 0.0384\n",
            "t = 16, avg_loss = 0.1137\n",
            "t = 17, avg_loss = 0.0476\n",
            "t = 18, avg_loss = 0.0444\n",
            "t = 19, avg_loss = 0.0523\n",
            "t = 20, avg_loss = 0.0247\n",
            "t = 21, avg_loss = 0.0489\n",
            "t = 22, avg_loss = 0.0575\n",
            "t = 23, avg_loss = 0.1293\n",
            "t = 24, avg_loss = 0.0848\n",
            "t = 25, avg_loss = 0.1186\n",
            "Checking accuracy on train set\n",
            "Got 362 / 400 correct (90.50)\n",
            "acc = 0.905000\n",
            "Starting epoch 85 / 98\n",
            "t = 1, avg_loss = 0.0742\n",
            "t = 2, avg_loss = 0.0503\n",
            "t = 3, avg_loss = 0.0495\n",
            "t = 4, avg_loss = 0.0347\n",
            "t = 5, avg_loss = 0.0319\n",
            "t = 6, avg_loss = 0.0568\n",
            "t = 7, avg_loss = 0.0858\n",
            "t = 8, avg_loss = 0.1324\n",
            "t = 9, avg_loss = 0.0219\n",
            "t = 10, avg_loss = 0.0582\n",
            "t = 11, avg_loss = 0.0730\n",
            "t = 12, avg_loss = 0.0542\n",
            "t = 13, avg_loss = 0.0972\n",
            "t = 14, avg_loss = 0.1167\n",
            "t = 15, avg_loss = 0.0405\n",
            "t = 16, avg_loss = 0.0508\n",
            "t = 17, avg_loss = 0.0531\n",
            "t = 18, avg_loss = 0.1983\n",
            "t = 19, avg_loss = 0.0258\n",
            "t = 20, avg_loss = 0.1117\n",
            "t = 21, avg_loss = 0.0470\n",
            "t = 22, avg_loss = 0.0887\n",
            "t = 23, avg_loss = 0.0638\n",
            "t = 24, avg_loss = 0.0715\n",
            "t = 25, avg_loss = 0.0864\n",
            "Checking accuracy on train set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 86 / 98\n",
            "t = 1, avg_loss = 0.0683\n",
            "t = 2, avg_loss = 0.0622\n",
            "t = 3, avg_loss = 0.0295\n",
            "t = 4, avg_loss = 0.1524\n",
            "t = 5, avg_loss = 0.0477\n",
            "t = 6, avg_loss = 0.0851\n",
            "t = 7, avg_loss = 0.0590\n",
            "t = 8, avg_loss = 0.0733\n",
            "t = 9, avg_loss = 0.0455\n",
            "t = 10, avg_loss = 0.0650\n",
            "t = 11, avg_loss = 0.1168\n",
            "t = 12, avg_loss = 0.0946\n",
            "t = 13, avg_loss = 0.1007\n",
            "t = 14, avg_loss = 0.0393\n",
            "t = 15, avg_loss = 0.1411\n",
            "t = 16, avg_loss = 0.0668\n",
            "t = 17, avg_loss = 0.0356\n",
            "t = 18, avg_loss = 0.0219\n",
            "t = 19, avg_loss = 0.0506\n",
            "t = 20, avg_loss = 0.0465\n",
            "t = 21, avg_loss = 0.0651\n",
            "t = 22, avg_loss = 0.0864\n",
            "t = 23, avg_loss = 0.0468\n",
            "t = 24, avg_loss = 0.0456\n",
            "t = 25, avg_loss = 0.0329\n",
            "Checking accuracy on train set\n",
            "Got 341 / 400 correct (85.25)\n",
            "acc = 0.852500\n",
            "Starting epoch 87 / 98\n",
            "t = 1, avg_loss = 0.0521\n",
            "t = 2, avg_loss = 0.0608\n",
            "t = 3, avg_loss = 0.0288\n",
            "t = 4, avg_loss = 0.0770\n",
            "t = 5, avg_loss = 0.0391\n",
            "t = 6, avg_loss = 0.0753\n",
            "t = 7, avg_loss = 0.0341\n",
            "t = 8, avg_loss = 0.0217\n",
            "t = 9, avg_loss = 0.0404\n",
            "t = 10, avg_loss = 0.0688\n",
            "t = 11, avg_loss = 0.0713\n",
            "t = 12, avg_loss = 0.1068\n",
            "t = 13, avg_loss = 0.0473\n",
            "t = 14, avg_loss = 0.0443\n",
            "t = 15, avg_loss = 0.0205\n",
            "t = 16, avg_loss = 0.1065\n",
            "t = 17, avg_loss = 0.0806\n",
            "t = 18, avg_loss = 0.0416\n",
            "t = 19, avg_loss = 0.0794\n",
            "t = 20, avg_loss = 0.0251\n",
            "t = 21, avg_loss = 0.0823\n",
            "t = 22, avg_loss = 0.0775\n",
            "t = 23, avg_loss = 0.0612\n",
            "t = 24, avg_loss = 0.0448\n",
            "t = 25, avg_loss = 0.0504\n",
            "Checking accuracy on train set\n",
            "Got 359 / 400 correct (89.75)\n",
            "acc = 0.897500\n",
            "Starting epoch 88 / 98\n",
            "t = 1, avg_loss = 0.1067\n",
            "t = 2, avg_loss = 0.0690\n",
            "t = 3, avg_loss = 0.0397\n",
            "t = 4, avg_loss = 0.0644\n",
            "t = 5, avg_loss = 0.0511\n",
            "t = 6, avg_loss = 0.0306\n",
            "t = 7, avg_loss = 0.0470\n",
            "t = 8, avg_loss = 0.0565\n",
            "t = 9, avg_loss = 0.0252\n",
            "t = 10, avg_loss = 0.0697\n",
            "t = 11, avg_loss = 0.1107\n",
            "t = 12, avg_loss = 0.0205\n",
            "t = 13, avg_loss = 0.0416\n",
            "t = 14, avg_loss = 0.0568\n",
            "t = 15, avg_loss = 0.0940\n",
            "t = 16, avg_loss = 0.0658\n",
            "t = 17, avg_loss = 0.0304\n",
            "t = 18, avg_loss = 0.0898\n",
            "t = 19, avg_loss = 0.0537\n",
            "t = 20, avg_loss = 0.0292\n",
            "t = 21, avg_loss = 0.1529\n",
            "t = 22, avg_loss = 0.0815\n",
            "t = 23, avg_loss = 0.0726\n",
            "t = 24, avg_loss = 0.0896\n",
            "t = 25, avg_loss = 0.0873\n",
            "Checking accuracy on train set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 89 / 98\n",
            "t = 1, avg_loss = 0.0586\n",
            "t = 2, avg_loss = 0.1213\n",
            "t = 3, avg_loss = 0.0300\n",
            "t = 4, avg_loss = 0.0792\n",
            "t = 5, avg_loss = 0.0591\n",
            "t = 6, avg_loss = 0.0427\n",
            "t = 7, avg_loss = 0.0424\n",
            "t = 8, avg_loss = 0.0714\n",
            "t = 9, avg_loss = 0.0920\n",
            "t = 10, avg_loss = 0.0386\n",
            "t = 11, avg_loss = 0.0960\n",
            "t = 12, avg_loss = 0.0811\n",
            "t = 13, avg_loss = 0.0179\n",
            "t = 14, avg_loss = 0.0421\n",
            "t = 15, avg_loss = 0.0224\n",
            "t = 16, avg_loss = 0.0383\n",
            "t = 17, avg_loss = 0.0367\n",
            "t = 18, avg_loss = 0.0571\n",
            "t = 19, avg_loss = 0.0366\n",
            "t = 20, avg_loss = 0.0657\n",
            "t = 21, avg_loss = 0.0583\n",
            "t = 22, avg_loss = 0.0424\n",
            "t = 23, avg_loss = 0.0137\n",
            "t = 24, avg_loss = 0.0415\n",
            "t = 25, avg_loss = 0.0586\n",
            "Checking accuracy on train set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 90 / 98\n",
            "t = 1, avg_loss = 0.0232\n",
            "t = 2, avg_loss = 0.0324\n",
            "t = 3, avg_loss = 0.0177\n",
            "t = 4, avg_loss = 0.1883\n",
            "t = 5, avg_loss = 0.0407\n",
            "t = 6, avg_loss = 0.0212\n",
            "t = 7, avg_loss = 0.0228\n",
            "t = 8, avg_loss = 0.0375\n",
            "t = 9, avg_loss = 0.0301\n",
            "t = 10, avg_loss = 0.0512\n",
            "t = 11, avg_loss = 0.0393\n",
            "t = 12, avg_loss = 0.0218\n",
            "t = 13, avg_loss = 0.0659\n",
            "t = 14, avg_loss = 0.0588\n",
            "t = 15, avg_loss = 0.0455\n",
            "t = 16, avg_loss = 0.0731\n",
            "t = 17, avg_loss = 0.0355\n",
            "t = 18, avg_loss = 0.0635\n",
            "t = 19, avg_loss = 0.0423\n",
            "t = 20, avg_loss = 0.0824\n",
            "t = 21, avg_loss = 0.0743\n",
            "t = 22, avg_loss = 0.0592\n",
            "t = 23, avg_loss = 0.0491\n",
            "t = 24, avg_loss = 0.0573\n",
            "t = 25, avg_loss = 0.0200\n",
            "Checking accuracy on train set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 91 / 98\n",
            "t = 1, avg_loss = 0.0240\n",
            "t = 2, avg_loss = 0.0461\n",
            "t = 3, avg_loss = 0.0397\n",
            "t = 4, avg_loss = 0.0641\n",
            "t = 5, avg_loss = 0.0300\n",
            "t = 6, avg_loss = 0.0251\n",
            "t = 7, avg_loss = 0.0244\n",
            "t = 8, avg_loss = 0.0699\n",
            "t = 9, avg_loss = 0.0139\n",
            "t = 10, avg_loss = 0.0404\n",
            "t = 11, avg_loss = 0.0466\n",
            "t = 12, avg_loss = 0.0275\n",
            "t = 13, avg_loss = 0.0148\n",
            "t = 14, avg_loss = 0.0162\n",
            "t = 15, avg_loss = 0.1215\n",
            "t = 16, avg_loss = 0.0696\n",
            "t = 17, avg_loss = 0.0459\n",
            "t = 18, avg_loss = 0.0811\n",
            "t = 19, avg_loss = 0.0474\n",
            "t = 20, avg_loss = 0.0359\n",
            "t = 21, avg_loss = 0.0670\n",
            "t = 22, avg_loss = 0.0206\n",
            "t = 23, avg_loss = 0.0843\n",
            "t = 24, avg_loss = 0.0599\n",
            "t = 25, avg_loss = 0.0316\n",
            "Checking accuracy on train set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 92 / 98\n",
            "t = 1, avg_loss = 0.0621\n",
            "t = 2, avg_loss = 0.0640\n",
            "t = 3, avg_loss = 0.0905\n",
            "t = 4, avg_loss = 0.0208\n",
            "t = 5, avg_loss = 0.0585\n",
            "t = 6, avg_loss = 0.0200\n",
            "t = 7, avg_loss = 0.0743\n",
            "t = 8, avg_loss = 0.0813\n",
            "t = 9, avg_loss = 0.0526\n",
            "t = 10, avg_loss = 0.0178\n",
            "t = 11, avg_loss = 0.0243\n",
            "t = 12, avg_loss = 0.0399\n",
            "t = 13, avg_loss = 0.0251\n",
            "t = 14, avg_loss = 0.0215\n",
            "t = 15, avg_loss = 0.0545\n",
            "t = 16, avg_loss = 0.0496\n",
            "t = 17, avg_loss = 0.0296\n",
            "t = 18, avg_loss = 0.0375\n",
            "t = 19, avg_loss = 0.0789\n",
            "t = 20, avg_loss = 0.0351\n",
            "t = 21, avg_loss = 0.1657\n",
            "t = 22, avg_loss = 0.0326\n",
            "t = 23, avg_loss = 0.0400\n",
            "t = 24, avg_loss = 0.1631\n",
            "t = 25, avg_loss = 0.0701\n",
            "Checking accuracy on train set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 93 / 98\n",
            "t = 1, avg_loss = 0.0448\n",
            "t = 2, avg_loss = 0.0213\n",
            "t = 3, avg_loss = 0.0320\n",
            "t = 4, avg_loss = 0.0182\n",
            "t = 5, avg_loss = 0.0451\n",
            "t = 6, avg_loss = 0.0501\n",
            "t = 7, avg_loss = 0.0450\n",
            "t = 8, avg_loss = 0.0831\n",
            "t = 9, avg_loss = 0.0263\n",
            "t = 10, avg_loss = 0.0650\n",
            "t = 11, avg_loss = 0.0451\n",
            "t = 12, avg_loss = 0.0295\n",
            "t = 13, avg_loss = 0.0631\n",
            "t = 14, avg_loss = 0.0560\n",
            "t = 15, avg_loss = 0.0313\n",
            "t = 16, avg_loss = 0.0304\n",
            "t = 17, avg_loss = 0.0342\n",
            "t = 18, avg_loss = 0.0376\n",
            "t = 19, avg_loss = 0.0310\n",
            "t = 20, avg_loss = 0.0185\n",
            "t = 21, avg_loss = 0.0516\n",
            "t = 22, avg_loss = 0.0454\n",
            "t = 23, avg_loss = 0.0388\n",
            "t = 24, avg_loss = 0.0624\n",
            "t = 25, avg_loss = 0.0192\n",
            "Checking accuracy on train set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 94 / 98\n",
            "t = 1, avg_loss = 0.0542\n",
            "t = 2, avg_loss = 0.0217\n",
            "t = 3, avg_loss = 0.0388\n",
            "t = 4, avg_loss = 0.0727\n",
            "t = 5, avg_loss = 0.0406\n",
            "t = 6, avg_loss = 0.0347\n",
            "t = 7, avg_loss = 0.0589\n",
            "t = 8, avg_loss = 0.0707\n",
            "t = 9, avg_loss = 0.0406\n",
            "t = 10, avg_loss = 0.0519\n",
            "t = 11, avg_loss = 0.0397\n",
            "t = 12, avg_loss = 0.0658\n",
            "t = 13, avg_loss = 0.0256\n",
            "t = 14, avg_loss = 0.0736\n",
            "t = 15, avg_loss = 0.0517\n",
            "t = 16, avg_loss = 0.0264\n",
            "t = 17, avg_loss = 0.0357\n",
            "t = 18, avg_loss = 0.0588\n",
            "t = 19, avg_loss = 0.0174\n",
            "t = 20, avg_loss = 0.0387\n",
            "t = 21, avg_loss = 0.0379\n",
            "t = 22, avg_loss = 0.0529\n",
            "t = 23, avg_loss = 0.0918\n",
            "t = 24, avg_loss = 0.0277\n",
            "t = 25, avg_loss = 0.0325\n",
            "Checking accuracy on train set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 95 / 98\n",
            "t = 1, avg_loss = 0.0150\n",
            "t = 2, avg_loss = 0.0352\n",
            "t = 3, avg_loss = 0.0314\n",
            "t = 4, avg_loss = 0.0588\n",
            "t = 5, avg_loss = 0.0294\n",
            "t = 6, avg_loss = 0.0213\n",
            "t = 7, avg_loss = 0.0123\n",
            "t = 8, avg_loss = 0.0167\n",
            "t = 9, avg_loss = 0.1118\n",
            "t = 10, avg_loss = 0.0287\n",
            "t = 11, avg_loss = 0.1845\n",
            "t = 12, avg_loss = 0.0279\n",
            "t = 13, avg_loss = 0.0609\n",
            "t = 14, avg_loss = 0.0167\n",
            "t = 15, avg_loss = 0.1076\n",
            "t = 16, avg_loss = 0.0295\n",
            "t = 17, avg_loss = 0.0884\n",
            "t = 18, avg_loss = 0.0533\n",
            "t = 19, avg_loss = 0.0248\n",
            "t = 20, avg_loss = 0.0286\n",
            "t = 21, avg_loss = 0.0445\n",
            "t = 22, avg_loss = 0.0281\n",
            "t = 23, avg_loss = 0.0410\n",
            "t = 24, avg_loss = 0.0979\n",
            "t = 25, avg_loss = 0.0988\n",
            "Checking accuracy on train set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 96 / 98\n",
            "t = 1, avg_loss = 0.0144\n",
            "t = 2, avg_loss = 0.0287\n",
            "t = 3, avg_loss = 0.0477\n",
            "t = 4, avg_loss = 0.0400\n",
            "t = 5, avg_loss = 0.0498\n",
            "t = 6, avg_loss = 0.0638\n",
            "t = 7, avg_loss = 0.0339\n",
            "t = 8, avg_loss = 0.0667\n",
            "t = 9, avg_loss = 0.0372\n",
            "t = 10, avg_loss = 0.0510\n",
            "t = 11, avg_loss = 0.0160\n",
            "t = 12, avg_loss = 0.0749\n",
            "t = 13, avg_loss = 0.0595\n",
            "t = 14, avg_loss = 0.0465\n",
            "t = 15, avg_loss = 0.0600\n",
            "t = 16, avg_loss = 0.0582\n",
            "t = 17, avg_loss = 0.0351\n",
            "t = 18, avg_loss = 0.0178\n",
            "t = 19, avg_loss = 0.0377\n",
            "t = 20, avg_loss = 0.0374\n",
            "t = 21, avg_loss = 0.0372\n",
            "t = 22, avg_loss = 0.0834\n",
            "t = 23, avg_loss = 0.0259\n",
            "t = 24, avg_loss = 0.0819\n",
            "t = 25, avg_loss = 0.0245\n",
            "Checking accuracy on train set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 97 / 98\n",
            "t = 1, avg_loss = 0.0700\n",
            "t = 2, avg_loss = 0.0279\n",
            "t = 3, avg_loss = 0.0616\n",
            "t = 4, avg_loss = 0.0244\n",
            "t = 5, avg_loss = 0.0373\n",
            "t = 6, avg_loss = 0.0705\n",
            "t = 7, avg_loss = 0.0606\n",
            "t = 8, avg_loss = 0.0481\n",
            "t = 9, avg_loss = 0.2091\n",
            "t = 10, avg_loss = 0.0438\n",
            "t = 11, avg_loss = 0.0870\n",
            "t = 12, avg_loss = 0.0101\n",
            "t = 13, avg_loss = 0.0567\n",
            "t = 14, avg_loss = 0.1074\n",
            "t = 15, avg_loss = 0.0514\n",
            "t = 16, avg_loss = 0.0141\n",
            "t = 17, avg_loss = 0.0338\n",
            "t = 18, avg_loss = 0.0316\n",
            "t = 19, avg_loss = 0.0283\n",
            "t = 20, avg_loss = 0.0563\n",
            "t = 21, avg_loss = 0.0806\n",
            "t = 22, avg_loss = 0.0822\n",
            "t = 23, avg_loss = 0.0318\n",
            "t = 24, avg_loss = 0.0181\n",
            "t = 25, avg_loss = 0.0292\n",
            "Checking accuracy on train set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 98 / 98\n",
            "t = 1, avg_loss = 0.0458\n",
            "t = 2, avg_loss = 0.0327\n",
            "t = 3, avg_loss = 0.1299\n",
            "t = 4, avg_loss = 0.0412\n",
            "t = 5, avg_loss = 0.0366\n",
            "t = 6, avg_loss = 0.0151\n",
            "t = 7, avg_loss = 0.0516\n",
            "t = 8, avg_loss = 0.0411\n",
            "t = 9, avg_loss = 0.0738\n",
            "t = 10, avg_loss = 0.0827\n",
            "t = 11, avg_loss = 0.1339\n",
            "t = 12, avg_loss = 0.0241\n",
            "t = 13, avg_loss = 0.0653\n",
            "t = 14, avg_loss = 0.0239\n",
            "t = 15, avg_loss = 0.0568\n",
            "t = 16, avg_loss = 0.1043\n",
            "t = 17, avg_loss = 0.0316\n",
            "t = 18, avg_loss = 0.0446\n",
            "t = 19, avg_loss = 0.0463\n",
            "t = 20, avg_loss = 0.0285\n",
            "t = 21, avg_loss = 0.0342\n",
            "t = 22, avg_loss = 0.0609\n",
            "t = 23, avg_loss = 0.0417\n",
            "t = 24, avg_loss = 0.0551\n",
            "t = 25, avg_loss = 0.0565\n",
            "Checking accuracy on train set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Checking accuracy on train set\n",
            "Got 348 / 400 correct (87.00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Av6C3V5z2m2x",
        "colab_type": "code",
        "outputId": "bb9a07d0-d638-45de-a39c-0dc7c2c63ccc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "check_accuracy(model_gpu, test_loader, datatype='test')\n",
        "plot_accurancy(acc_list)\n",
        "plot_loss_function(avg_loss_list)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking accuracy on test set\n",
            "Got 185 / 201 correct (92.04)\n",
            "Accurancy:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOlG4B_zDO2J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3Ytd376QjCU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}