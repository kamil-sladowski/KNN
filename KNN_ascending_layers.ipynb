{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN_ascending_layers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOGK1nchfvPGMqeHhEyTtUQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamilo116/KNN/blob/master/KNN_ascending_layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7ReM7FU-xs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import sys\n",
        "from random import shuffle\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms as transforms\n",
        "import timeit\n",
        "\n",
        "np.random.seed(4) \n",
        "torch.manual_seed(4) \n",
        "torch.cuda.manual_seed(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdDATVpSio04",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install -q tf-nightly-2.0-preview\n",
        "#%load_ext tensorboard #Load extension\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "logs_base_dir = \"runs\"\n",
        "os.makedirs(logs_base_dir, exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYIMZ8QyYewD",
        "colab_type": "code",
        "outputId": "114583db-d3db-4e98-f65c-5ae6948ba7a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "! git clone https://github.com/wang-chen/kervolution.git \n",
        "\n",
        "sys.path.append(\"kervolution/\")\n",
        "from kervolution import Kerv2d\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'kervolution' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvbKg4VJXKY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LIMIT_IMAGES_NUM = 1000\n",
        "train_test_split_size = 0.2\n",
        "image_resize = (100, 100)\n",
        "batch_size = 64\n",
        "num_workers = 0\n",
        "\n",
        "in_channels = 3\n",
        "out_channels_1 = 16\n",
        "out_channels_2 = 32\n",
        "out_channels_3 = 64\n",
        "out_channels_4 = 128\n",
        "\n",
        "kernel_size = 3\n",
        "padding_1 = 1\n",
        "num_epochs = 80\n",
        "\n",
        "learning_rate = 0.0002\n",
        "weight_decay = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMOHez_kHZD6",
        "colab_type": "code",
        "outputId": "2756ce55-78e4-40f7-a2cc-9f717f55e899",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b8P1NdXfVdX",
        "colab_type": "code",
        "outputId": "2728af49-3ab1-4ff4-9d4c-5373efbf2fc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "MALIGNANT_DATASET = '/content/drive/My Drive/Colab_data/malignant/malignant/'\n",
        "BENIGN_DATASET = '/content/drive/My Drive/Colab_data/benign/benign/'\n",
        "DATA_FOLDER = '/content/drive/My Drive/Colab_data/'\n",
        "\n",
        "\n",
        "benign_file_list = sorted(os.listdir(BENIGN_DATASET))\n",
        "malignant_file_list = sorted(os.listdir(MALIGNANT_DATASET))\n",
        "shuffle(benign_file_list)\n",
        "shuffle(malignant_file_list)\n",
        "benign_file_list = benign_file_list[:LIMIT_IMAGES_NUM]\n",
        "malignant_file_list = malignant_file_list[:LIMIT_IMAGES_NUM]\n",
        "\n",
        "print(f\"Number of benign {len(benign_file_list)} images\")\n",
        "print(f\"Number of malignant {len(malignant_file_list)} images\")\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize(image_resize),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of benign 1000 images\n",
            "Number of malignant 1000 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGDQfal74BLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "benign_dict = {filename: 0 for filename in benign_file_list}\n",
        "malignant_dict = {filename: 1 for filename in malignant_file_list}\n",
        "img_class_dict = {**benign_dict , **malignant_dict}\n",
        "labeled_data = pd.Series(img_class_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvAAOqmVfVll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IsicDataset(Dataset):\n",
        "    def __init__(self, data_folder, labeled_data, \n",
        "                 transform=transforms.Compose([transforms.ToTensor()])):\n",
        "        self.labeled_data = labeled_data\n",
        "        self.transform = transform\n",
        "        self.data_folder = data_folder\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labeled_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        label = self.labeled_data[index]\n",
        "        if label == 0:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"benign\", \"benign\", index ))\n",
        "        else:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"malignant\", \"malignant\", index ))\n",
        "        image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "    @property\n",
        "    def labels(self):\n",
        "      return self.labeled_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSuYqjLAYrWA",
        "colab_type": "code",
        "outputId": "00347d88-d2bc-4e65-c4cf-26ce5118add5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        }
      },
      "source": [
        " \n",
        "dataset = IsicDataset(DATA_FOLDER, labeled_data, transform=data_transforms)\n",
        "print(dataset.labels)\n",
        "\n",
        "X_train, X_test = train_test_split(dataset.labels, test_size=train_test_split_size)\n",
        "print(\"number of training data: \",len(X_train))\n",
        "print(\"number of testing  data: \",len(X_test))\n",
        "\n",
        "train_sampler = SubsetRandomSampler(list(X_train.index))\n",
        "valid_sampler = SubsetRandomSampler(list(X_test.index))\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ISIC_0000347.jpeg    0\n",
            "ISIC_0000323.jpeg    0\n",
            "ISIC_0001768.jpeg    0\n",
            "ISIC_0001473.jpeg    0\n",
            "ISIC_0000016.jpeg    0\n",
            "                    ..\n",
            "ISIC_0000314.jpeg    1\n",
            "ISIC_0010024.jpeg    1\n",
            "ISIC_0010432.jpeg    1\n",
            "ISIC_0014291.jpeg    1\n",
            "ISIC_0011802.jpeg    1\n",
            "Length: 2000, dtype: int64\n",
            "number of training data:  1600\n",
            "number of testing  data:  400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eK-sW83ndrkP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tb = SummaryWriter()\n",
        "images, labels = next(iter(train_loader))\n",
        "grid = torchvision.utils.make_grid(images)\n",
        "tb.add_image('images', grid)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e8nFBR6Yug5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "def train(model, train_loader ,loss_fn, optimizer, num_epochs = 1):\n",
        "    total_loss =0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
        "        model.train()\n",
        "\n",
        "        for t, (x, y) in enumerate(train_loader):\n",
        "            x_var = Variable(x.type(gpu_dtype))\n",
        "            y_var = Variable(y.type(gpu_dtype).long())\n",
        "            scores = model(x_var)\n",
        "            loss = loss_fn(scores, y_var)\n",
        "            total_loss += loss.data\n",
        "            \n",
        "            if (t + 1) % print_every == 0:\n",
        "                avg_loss = total_loss/print_every\n",
        "                print('t = %d, avg_loss = %.4f' % (t + 1, avg_loss) )\n",
        "                avg_loss_list.append(avg_loss)\n",
        "                total_loss = 0\n",
        "                \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        tb.add_scalar('Loss', total_loss, epoch)\n",
        "        #tb.add_scalar('Number of correct', total_correct, epoch)\n",
        "        #tb.add_histogram('', total_, epoch)\n",
        "        \n",
        "        acc = check_accuracy(model_gpu, valid_loader)\n",
        "        print('acc = %f' %(acc))\n",
        "        tb.add_scalar('Accurancy', acc, epoch)\n",
        "            \n",
        "def check_accuracy(model, loader):\n",
        "    print('Checking accuracy on test set')   \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval() \n",
        "    for x, y in loader:\n",
        "        x_var = Variable(x.type(gpu_dtype))\n",
        "\n",
        "        scores = model(x_var)\n",
        "        _, preds = scores.data.cpu().max(1)\n",
        "        num_correct += (preds == y).sum()\n",
        "        num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    acc_list.append(acc)\n",
        "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "    return acc\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggvpMu36Yw2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.size()\n",
        "        return x.view(N, -1)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgmexhBRZAK6",
        "colab_type": "code",
        "outputId": "80e5f269-3a04-46e4-b545-41ff04303120",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "gpu_dtype = torch.cuda.FloatTensor\n",
        "\n",
        "print_every = 1\n",
        "\n",
        "\n",
        "'''\n",
        "Kerv2d\n",
        "kervolution with following options:\n",
        "kernel_type: [linear, polynomial, gaussian, etc.]\n",
        "default is convolution:\n",
        "          kernel_type --> linear,\n",
        "balance, power, gamma is valid only when the kernel_type is specified\n",
        "if learnable_kernel = True,  they just be the initial value of learable parameters\n",
        "if learnable_kernel = False, they are the value of kernel_type's parameter\n",
        "the parameter [power] cannot be learned due to integer limitation\n",
        "dilation (int or tuple, optional): Spacing between kernel\n",
        "elements. Default: 1\n",
        "groups (int, optional): Number of blocked connections from input\n",
        "channels to output channels. Default: 1\n",
        "bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n",
        "kernel_type (str), Default: 'linear'\n",
        "learnable_kernel (bool): Learnable kernel parameters.  Default: False \n",
        "balance: 0, 1\n",
        "power: 3, 4, 5\n",
        "gamma:\n",
        "'''\n",
        "\n",
        "\n",
        "model_base = nn.Sequential( \n",
        "                nn.Kerv2d(in_channels , out_channels_1, padding=padding_1, dilation=1, groups=1, bias=True, \n",
        "                          kernel_type='gaussian', kernel_size=kernel_size, learnable_kernel=True,\n",
        "                          kernel_regularizer=True, stride=1, balance=1, power=5, gamma=1\n",
        "                          ), \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_channels_1),\n",
        "                nn.Conv2d(out_channels_1 , out_channels_2, padding= padding_1, kernel_size=kernel_size, stride=1), \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_channels_2),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_2 , out_channels_3, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_channels_3),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_3 , out_channels_4, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_channels_4),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Dropout(0.5),\n",
        "                Flatten(),\n",
        "                nn.Linear(18432,64),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Linear(64,2)\n",
        "            )\n",
        "model_gpu = model_base.type(gpu_dtype)\n",
        "print(model_gpu)\n",
        "loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) \n",
        "\n",
        "\n",
        "train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs)\n",
        "check_accuracy(model_gpu, valid_loader)\n",
        "\n",
        "#tb.add_graph(model_gpu, images)\n",
        "tb.close()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Kerv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (4): ReLU(inplace=True)\n",
            "  (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (7): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (8): ReLU(inplace=True)\n",
            "  (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (11): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (12): ReLU(inplace=True)\n",
            "  (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (15): Dropout(p=0.5, inplace=False)\n",
            "  (16): Flatten()\n",
            "  (17): Linear(in_features=18432, out_features=64, bias=True)\n",
            "  (18): ReLU(inplace=True)\n",
            "  (19): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n",
            "Starting epoch 1 / 80\n",
            "t = 1, avg_loss = 0.7790\n",
            "t = 2, avg_loss = 0.6887\n",
            "t = 3, avg_loss = 0.6588\n",
            "t = 4, avg_loss = 0.6057\n",
            "t = 5, avg_loss = 0.6462\n",
            "t = 6, avg_loss = 0.5855\n",
            "t = 7, avg_loss = 0.5073\n",
            "t = 8, avg_loss = 0.5765\n",
            "t = 9, avg_loss = 0.6527\n",
            "t = 10, avg_loss = 0.6152\n",
            "t = 11, avg_loss = 0.5723\n",
            "t = 12, avg_loss = 0.5999\n",
            "t = 13, avg_loss = 0.5963\n",
            "t = 14, avg_loss = 0.4389\n",
            "t = 15, avg_loss = 0.4396\n",
            "t = 16, avg_loss = 0.4426\n",
            "t = 17, avg_loss = 0.5665\n",
            "t = 18, avg_loss = 0.6060\n",
            "t = 19, avg_loss = 0.5061\n",
            "t = 20, avg_loss = 0.5241\n",
            "t = 21, avg_loss = 0.5765\n",
            "t = 22, avg_loss = 0.4231\n",
            "t = 23, avg_loss = 0.4753\n",
            "t = 24, avg_loss = 0.5372\n",
            "t = 25, avg_loss = 0.5009\n",
            "Checking accuracy on test set\n",
            "Got 204 / 400 correct (51.00)\n",
            "acc = 0.510000\n",
            "Starting epoch 2 / 80\n",
            "t = 1, avg_loss = 0.4888\n",
            "t = 2, avg_loss = 0.4180\n",
            "t = 3, avg_loss = 0.4888\n",
            "t = 4, avg_loss = 0.4361\n",
            "t = 5, avg_loss = 0.4214\n",
            "t = 6, avg_loss = 0.6098\n",
            "t = 7, avg_loss = 0.3647\n",
            "t = 8, avg_loss = 0.3446\n",
            "t = 9, avg_loss = 0.3617\n",
            "t = 10, avg_loss = 0.3555\n",
            "t = 11, avg_loss = 0.3899\n",
            "t = 12, avg_loss = 0.4005\n",
            "t = 13, avg_loss = 0.4576\n",
            "t = 14, avg_loss = 0.4454\n",
            "t = 15, avg_loss = 0.4852\n",
            "t = 16, avg_loss = 0.4935\n",
            "t = 17, avg_loss = 0.3862\n",
            "t = 18, avg_loss = 0.6403\n",
            "t = 19, avg_loss = 0.5442\n",
            "t = 20, avg_loss = 0.3826\n",
            "t = 21, avg_loss = 0.5526\n",
            "t = 22, avg_loss = 0.3757\n",
            "t = 23, avg_loss = 0.3662\n",
            "t = 24, avg_loss = 0.4133\n",
            "t = 25, avg_loss = 0.3823\n",
            "Checking accuracy on test set\n",
            "Got 252 / 400 correct (63.00)\n",
            "acc = 0.630000\n",
            "Starting epoch 3 / 80\n",
            "t = 1, avg_loss = 0.2772\n",
            "t = 2, avg_loss = 0.3413\n",
            "t = 3, avg_loss = 0.3211\n",
            "t = 4, avg_loss = 0.3760\n",
            "t = 5, avg_loss = 0.5497\n",
            "t = 6, avg_loss = 0.4459\n",
            "t = 7, avg_loss = 0.3499\n",
            "t = 8, avg_loss = 0.4070\n",
            "t = 9, avg_loss = 0.4699\n",
            "t = 10, avg_loss = 0.4538\n",
            "t = 11, avg_loss = 0.4932\n",
            "t = 12, avg_loss = 0.5646\n",
            "t = 13, avg_loss = 0.3801\n",
            "t = 14, avg_loss = 0.4941\n",
            "t = 15, avg_loss = 0.3538\n",
            "t = 16, avg_loss = 0.3321\n",
            "t = 17, avg_loss = 0.3864\n",
            "t = 18, avg_loss = 0.5679\n",
            "t = 19, avg_loss = 0.4253\n",
            "t = 20, avg_loss = 0.4668\n",
            "t = 21, avg_loss = 0.3439\n",
            "t = 22, avg_loss = 0.3266\n",
            "t = 23, avg_loss = 0.2527\n",
            "t = 24, avg_loss = 0.3469\n",
            "t = 25, avg_loss = 0.4008\n",
            "Checking accuracy on test set\n",
            "Got 303 / 400 correct (75.75)\n",
            "acc = 0.757500\n",
            "Starting epoch 4 / 80\n",
            "t = 1, avg_loss = 0.3085\n",
            "t = 2, avg_loss = 0.4247\n",
            "t = 3, avg_loss = 0.2877\n",
            "t = 4, avg_loss = 0.4158\n",
            "t = 5, avg_loss = 0.4146\n",
            "t = 6, avg_loss = 0.2812\n",
            "t = 7, avg_loss = 0.3695\n",
            "t = 8, avg_loss = 0.3999\n",
            "t = 9, avg_loss = 0.4009\n",
            "t = 10, avg_loss = 0.3229\n",
            "t = 11, avg_loss = 0.3533\n",
            "t = 12, avg_loss = 0.3723\n",
            "t = 13, avg_loss = 0.3903\n",
            "t = 14, avg_loss = 0.2622\n",
            "t = 15, avg_loss = 0.3278\n",
            "t = 16, avg_loss = 0.3200\n",
            "t = 17, avg_loss = 0.4117\n",
            "t = 18, avg_loss = 0.3991\n",
            "t = 19, avg_loss = 0.4011\n",
            "t = 20, avg_loss = 0.3524\n",
            "t = 21, avg_loss = 0.4363\n",
            "t = 22, avg_loss = 0.3642\n",
            "t = 23, avg_loss = 0.3523\n",
            "t = 24, avg_loss = 0.4088\n",
            "t = 25, avg_loss = 0.2423\n",
            "Checking accuracy on test set\n",
            "Got 318 / 400 correct (79.50)\n",
            "acc = 0.795000\n",
            "Starting epoch 5 / 80\n",
            "t = 1, avg_loss = 0.2050\n",
            "t = 2, avg_loss = 0.4072\n",
            "t = 3, avg_loss = 0.3308\n",
            "t = 4, avg_loss = 0.3400\n",
            "t = 5, avg_loss = 0.2603\n",
            "t = 6, avg_loss = 0.3435\n",
            "t = 7, avg_loss = 0.2638\n",
            "t = 8, avg_loss = 0.5097\n",
            "t = 9, avg_loss = 0.4065\n",
            "t = 10, avg_loss = 0.2478\n",
            "t = 11, avg_loss = 0.3282\n",
            "t = 12, avg_loss = 0.3332\n",
            "t = 13, avg_loss = 0.2663\n",
            "t = 14, avg_loss = 0.4195\n",
            "t = 15, avg_loss = 0.3991\n",
            "t = 16, avg_loss = 0.3773\n",
            "t = 17, avg_loss = 0.3887\n",
            "t = 18, avg_loss = 0.3043\n",
            "t = 19, avg_loss = 0.3037\n",
            "t = 20, avg_loss = 0.3624\n",
            "t = 21, avg_loss = 0.4388\n",
            "t = 22, avg_loss = 0.3930\n",
            "t = 23, avg_loss = 0.3138\n",
            "t = 24, avg_loss = 0.2514\n",
            "t = 25, avg_loss = 0.3660\n",
            "Checking accuracy on test set\n",
            "Got 328 / 400 correct (82.00)\n",
            "acc = 0.820000\n",
            "Starting epoch 6 / 80\n",
            "t = 1, avg_loss = 0.2565\n",
            "t = 2, avg_loss = 0.3220\n",
            "t = 3, avg_loss = 0.4579\n",
            "t = 4, avg_loss = 0.3721\n",
            "t = 5, avg_loss = 0.4648\n",
            "t = 6, avg_loss = 0.4028\n",
            "t = 7, avg_loss = 0.3018\n",
            "t = 8, avg_loss = 0.3392\n",
            "t = 9, avg_loss = 0.2952\n",
            "t = 10, avg_loss = 0.3158\n",
            "t = 11, avg_loss = 0.2267\n",
            "t = 12, avg_loss = 0.3515\n",
            "t = 13, avg_loss = 0.4242\n",
            "t = 14, avg_loss = 0.3093\n",
            "t = 15, avg_loss = 0.3119\n",
            "t = 16, avg_loss = 0.3237\n",
            "t = 17, avg_loss = 0.2960\n",
            "t = 18, avg_loss = 0.5097\n",
            "t = 19, avg_loss = 0.3593\n",
            "t = 20, avg_loss = 0.3837\n",
            "t = 21, avg_loss = 0.2777\n",
            "t = 22, avg_loss = 0.2697\n",
            "t = 23, avg_loss = 0.3538\n",
            "t = 24, avg_loss = 0.3542\n",
            "t = 25, avg_loss = 0.2704\n",
            "Checking accuracy on test set\n",
            "Got 327 / 400 correct (81.75)\n",
            "acc = 0.817500\n",
            "Starting epoch 7 / 80\n",
            "t = 1, avg_loss = 0.2856\n",
            "t = 2, avg_loss = 0.3687\n",
            "t = 3, avg_loss = 0.3600\n",
            "t = 4, avg_loss = 0.2459\n",
            "t = 5, avg_loss = 0.2863\n",
            "t = 6, avg_loss = 0.2415\n",
            "t = 7, avg_loss = 0.3496\n",
            "t = 8, avg_loss = 0.2703\n",
            "t = 9, avg_loss = 0.3000\n",
            "t = 10, avg_loss = 0.3726\n",
            "t = 11, avg_loss = 0.3965\n",
            "t = 12, avg_loss = 0.2733\n",
            "t = 13, avg_loss = 0.3405\n",
            "t = 14, avg_loss = 0.2842\n",
            "t = 15, avg_loss = 0.2606\n",
            "t = 16, avg_loss = 0.3601\n",
            "t = 17, avg_loss = 0.2434\n",
            "t = 18, avg_loss = 0.3263\n",
            "t = 19, avg_loss = 0.3014\n",
            "t = 20, avg_loss = 0.2719\n",
            "t = 21, avg_loss = 0.4793\n",
            "t = 22, avg_loss = 0.3593\n",
            "t = 23, avg_loss = 0.5447\n",
            "t = 24, avg_loss = 0.3340\n",
            "t = 25, avg_loss = 0.3104\n",
            "Checking accuracy on test set\n",
            "Got 327 / 400 correct (81.75)\n",
            "acc = 0.817500\n",
            "Starting epoch 8 / 80\n",
            "t = 1, avg_loss = 0.2475\n",
            "t = 2, avg_loss = 0.2473\n",
            "t = 3, avg_loss = 0.2608\n",
            "t = 4, avg_loss = 0.3291\n",
            "t = 5, avg_loss = 0.2821\n",
            "t = 6, avg_loss = 0.3305\n",
            "t = 7, avg_loss = 0.2555\n",
            "t = 8, avg_loss = 0.2298\n",
            "t = 9, avg_loss = 0.2859\n",
            "t = 10, avg_loss = 0.2953\n",
            "t = 11, avg_loss = 0.3050\n",
            "t = 12, avg_loss = 0.2218\n",
            "t = 13, avg_loss = 0.2751\n",
            "t = 14, avg_loss = 0.4102\n",
            "t = 15, avg_loss = 0.4794\n",
            "t = 16, avg_loss = 0.3176\n",
            "t = 17, avg_loss = 0.2914\n",
            "t = 18, avg_loss = 0.2950\n",
            "t = 19, avg_loss = 0.3189\n",
            "t = 20, avg_loss = 0.3430\n",
            "t = 21, avg_loss = 0.3076\n",
            "t = 22, avg_loss = 0.3481\n",
            "t = 23, avg_loss = 0.4718\n",
            "t = 24, avg_loss = 0.2906\n",
            "t = 25, avg_loss = 0.2039\n",
            "Checking accuracy on test set\n",
            "Got 307 / 400 correct (76.75)\n",
            "acc = 0.767500\n",
            "Starting epoch 9 / 80\n",
            "t = 1, avg_loss = 0.3630\n",
            "t = 2, avg_loss = 0.3290\n",
            "t = 3, avg_loss = 0.4513\n",
            "t = 4, avg_loss = 0.2580\n",
            "t = 5, avg_loss = 0.4195\n",
            "t = 6, avg_loss = 0.3634\n",
            "t = 7, avg_loss = 0.4253\n",
            "t = 8, avg_loss = 0.3359\n",
            "t = 9, avg_loss = 0.3486\n",
            "t = 10, avg_loss = 0.2539\n",
            "t = 11, avg_loss = 0.2322\n",
            "t = 12, avg_loss = 0.2600\n",
            "t = 13, avg_loss = 0.3450\n",
            "t = 14, avg_loss = 0.2876\n",
            "t = 15, avg_loss = 0.4355\n",
            "t = 16, avg_loss = 0.3833\n",
            "t = 17, avg_loss = 0.3014\n",
            "t = 18, avg_loss = 0.1902\n",
            "t = 19, avg_loss = 0.2603\n",
            "t = 20, avg_loss = 0.5012\n",
            "t = 21, avg_loss = 0.2656\n",
            "t = 22, avg_loss = 0.3996\n",
            "t = 23, avg_loss = 0.3077\n",
            "t = 24, avg_loss = 0.2377\n",
            "t = 25, avg_loss = 0.2633\n",
            "Checking accuracy on test set\n",
            "Got 309 / 400 correct (77.25)\n",
            "acc = 0.772500\n",
            "Starting epoch 10 / 80\n",
            "t = 1, avg_loss = 0.2437\n",
            "t = 2, avg_loss = 0.4543\n",
            "t = 3, avg_loss = 0.3819\n",
            "t = 4, avg_loss = 0.4401\n",
            "t = 5, avg_loss = 0.2777\n",
            "t = 6, avg_loss = 0.2310\n",
            "t = 7, avg_loss = 0.2145\n",
            "t = 8, avg_loss = 0.3831\n",
            "t = 9, avg_loss = 0.2033\n",
            "t = 10, avg_loss = 0.1937\n",
            "t = 11, avg_loss = 0.2628\n",
            "t = 12, avg_loss = 0.3537\n",
            "t = 13, avg_loss = 0.2863\n",
            "t = 14, avg_loss = 0.2976\n",
            "t = 15, avg_loss = 0.3104\n",
            "t = 16, avg_loss = 0.2322\n",
            "t = 17, avg_loss = 0.3590\n",
            "t = 18, avg_loss = 0.2905\n",
            "t = 19, avg_loss = 0.1761\n",
            "t = 20, avg_loss = 0.2591\n",
            "t = 21, avg_loss = 0.3447\n",
            "t = 22, avg_loss = 0.2331\n",
            "t = 23, avg_loss = 0.2920\n",
            "t = 24, avg_loss = 0.2902\n",
            "t = 25, avg_loss = 0.3019\n",
            "Checking accuracy on test set\n",
            "Got 333 / 400 correct (83.25)\n",
            "acc = 0.832500\n",
            "Starting epoch 11 / 80\n",
            "t = 1, avg_loss = 0.3201\n",
            "t = 2, avg_loss = 0.2470\n",
            "t = 3, avg_loss = 0.2316\n",
            "t = 4, avg_loss = 0.3178\n",
            "t = 5, avg_loss = 0.3006\n",
            "t = 6, avg_loss = 0.2715\n",
            "t = 7, avg_loss = 0.1767\n",
            "t = 8, avg_loss = 0.2268\n",
            "t = 9, avg_loss = 0.2725\n",
            "t = 10, avg_loss = 0.3066\n",
            "t = 11, avg_loss = 0.3313\n",
            "t = 12, avg_loss = 0.2747\n",
            "t = 13, avg_loss = 0.3221\n",
            "t = 14, avg_loss = 0.2785\n",
            "t = 15, avg_loss = 0.3006\n",
            "t = 16, avg_loss = 0.2234\n",
            "t = 17, avg_loss = 0.2140\n",
            "t = 18, avg_loss = 0.2937\n",
            "t = 19, avg_loss = 0.2323\n",
            "t = 20, avg_loss = 0.2143\n",
            "t = 21, avg_loss = 0.2866\n",
            "t = 22, avg_loss = 0.2197\n",
            "t = 23, avg_loss = 0.2432\n",
            "t = 24, avg_loss = 0.2537\n",
            "t = 25, avg_loss = 0.2499\n",
            "Checking accuracy on test set\n",
            "Got 319 / 400 correct (79.75)\n",
            "acc = 0.797500\n",
            "Starting epoch 12 / 80\n",
            "t = 1, avg_loss = 0.2841\n",
            "t = 2, avg_loss = 0.2153\n",
            "t = 3, avg_loss = 0.1999\n",
            "t = 4, avg_loss = 0.2755\n",
            "t = 5, avg_loss = 0.2721\n",
            "t = 6, avg_loss = 0.2133\n",
            "t = 7, avg_loss = 0.2041\n",
            "t = 8, avg_loss = 0.2123\n",
            "t = 9, avg_loss = 0.1601\n",
            "t = 10, avg_loss = 0.3067\n",
            "t = 11, avg_loss = 0.3334\n",
            "t = 12, avg_loss = 0.3201\n",
            "t = 13, avg_loss = 0.2397\n",
            "t = 14, avg_loss = 0.3656\n",
            "t = 15, avg_loss = 0.2439\n",
            "t = 16, avg_loss = 0.3048\n",
            "t = 17, avg_loss = 0.2586\n",
            "t = 18, avg_loss = 0.3050\n",
            "t = 19, avg_loss = 0.2436\n",
            "t = 20, avg_loss = 0.2774\n",
            "t = 21, avg_loss = 0.3150\n",
            "t = 22, avg_loss = 0.2180\n",
            "t = 23, avg_loss = 0.4136\n",
            "t = 24, avg_loss = 0.3539\n",
            "t = 25, avg_loss = 0.2523\n",
            "Checking accuracy on test set\n",
            "Got 312 / 400 correct (78.00)\n",
            "acc = 0.780000\n",
            "Starting epoch 13 / 80\n",
            "t = 1, avg_loss = 0.1852\n",
            "t = 2, avg_loss = 0.2268\n",
            "t = 3, avg_loss = 0.2181\n",
            "t = 4, avg_loss = 0.1790\n",
            "t = 5, avg_loss = 0.3045\n",
            "t = 6, avg_loss = 0.3650\n",
            "t = 7, avg_loss = 0.2193\n",
            "t = 8, avg_loss = 0.2557\n",
            "t = 9, avg_loss = 0.2152\n",
            "t = 10, avg_loss = 0.2299\n",
            "t = 11, avg_loss = 0.3104\n",
            "t = 12, avg_loss = 0.2235\n",
            "t = 13, avg_loss = 0.3387\n",
            "t = 14, avg_loss = 0.3312\n",
            "t = 15, avg_loss = 0.1963\n",
            "t = 16, avg_loss = 0.3134\n",
            "t = 17, avg_loss = 0.2231\n",
            "t = 18, avg_loss = 0.1435\n",
            "t = 19, avg_loss = 0.2226\n",
            "t = 20, avg_loss = 0.2325\n",
            "t = 21, avg_loss = 0.2645\n",
            "t = 22, avg_loss = 0.3154\n",
            "t = 23, avg_loss = 0.2426\n",
            "t = 24, avg_loss = 0.2692\n",
            "t = 25, avg_loss = 0.4043\n",
            "Checking accuracy on test set\n",
            "Got 323 / 400 correct (80.75)\n",
            "acc = 0.807500\n",
            "Starting epoch 14 / 80\n",
            "t = 1, avg_loss = 0.2760\n",
            "t = 2, avg_loss = 0.1620\n",
            "t = 3, avg_loss = 0.2504\n",
            "t = 4, avg_loss = 0.2235\n",
            "t = 5, avg_loss = 0.2493\n",
            "t = 6, avg_loss = 0.2030\n",
            "t = 7, avg_loss = 0.2035\n",
            "t = 8, avg_loss = 0.2006\n",
            "t = 9, avg_loss = 0.2705\n",
            "t = 10, avg_loss = 0.3277\n",
            "t = 11, avg_loss = 0.2196\n",
            "t = 12, avg_loss = 0.1872\n",
            "t = 13, avg_loss = 0.2366\n",
            "t = 14, avg_loss = 0.2207\n",
            "t = 15, avg_loss = 0.3104\n",
            "t = 16, avg_loss = 0.2560\n",
            "t = 17, avg_loss = 0.3249\n",
            "t = 18, avg_loss = 0.1584\n",
            "t = 19, avg_loss = 0.1775\n",
            "t = 20, avg_loss = 0.1737\n",
            "t = 21, avg_loss = 0.3682\n",
            "t = 22, avg_loss = 0.3593\n",
            "t = 23, avg_loss = 0.3061\n",
            "t = 24, avg_loss = 0.2373\n",
            "t = 25, avg_loss = 0.1978\n",
            "Checking accuracy on test set\n",
            "Got 323 / 400 correct (80.75)\n",
            "acc = 0.807500\n",
            "Starting epoch 15 / 80\n",
            "t = 1, avg_loss = 0.3175\n",
            "t = 2, avg_loss = 0.2938\n",
            "t = 3, avg_loss = 0.2537\n",
            "t = 4, avg_loss = 0.3511\n",
            "t = 5, avg_loss = 0.2385\n",
            "t = 6, avg_loss = 0.2485\n",
            "t = 7, avg_loss = 0.2955\n",
            "t = 8, avg_loss = 0.1621\n",
            "t = 9, avg_loss = 0.1851\n",
            "t = 10, avg_loss = 0.2090\n",
            "t = 11, avg_loss = 0.2331\n",
            "t = 12, avg_loss = 0.2579\n",
            "t = 13, avg_loss = 0.1819\n",
            "t = 14, avg_loss = 0.2132\n",
            "t = 15, avg_loss = 0.2169\n",
            "t = 16, avg_loss = 0.2364\n",
            "t = 17, avg_loss = 0.2091\n",
            "t = 18, avg_loss = 0.1756\n",
            "t = 19, avg_loss = 0.1917\n",
            "t = 20, avg_loss = 0.3122\n",
            "t = 21, avg_loss = 0.3615\n",
            "t = 22, avg_loss = 0.3305\n",
            "t = 23, avg_loss = 0.1794\n",
            "t = 24, avg_loss = 0.1703\n",
            "t = 25, avg_loss = 0.1751\n",
            "Checking accuracy on test set\n",
            "Got 318 / 400 correct (79.50)\n",
            "acc = 0.795000\n",
            "Starting epoch 16 / 80\n",
            "t = 1, avg_loss = 0.1986\n",
            "t = 2, avg_loss = 0.1594\n",
            "t = 3, avg_loss = 0.2179\n",
            "t = 4, avg_loss = 0.1441\n",
            "t = 5, avg_loss = 0.2182\n",
            "t = 6, avg_loss = 0.1658\n",
            "t = 7, avg_loss = 0.1837\n",
            "t = 8, avg_loss = 0.2209\n",
            "t = 9, avg_loss = 0.1506\n",
            "t = 10, avg_loss = 0.3025\n",
            "t = 11, avg_loss = 0.1868\n",
            "t = 12, avg_loss = 0.1710\n",
            "t = 13, avg_loss = 0.1418\n",
            "t = 14, avg_loss = 0.3169\n",
            "t = 15, avg_loss = 0.3003\n",
            "t = 16, avg_loss = 0.1999\n",
            "t = 17, avg_loss = 0.1503\n",
            "t = 18, avg_loss = 0.2803\n",
            "t = 19, avg_loss = 0.2522\n",
            "t = 20, avg_loss = 0.2242\n",
            "t = 21, avg_loss = 0.3622\n",
            "t = 22, avg_loss = 0.2694\n",
            "t = 23, avg_loss = 0.2411\n",
            "t = 24, avg_loss = 0.1994\n",
            "t = 25, avg_loss = 0.2303\n",
            "Checking accuracy on test set\n",
            "Got 298 / 400 correct (74.50)\n",
            "acc = 0.745000\n",
            "Starting epoch 17 / 80\n",
            "t = 1, avg_loss = 0.3487\n",
            "t = 2, avg_loss = 0.3032\n",
            "t = 3, avg_loss = 0.1505\n",
            "t = 4, avg_loss = 0.2508\n",
            "t = 5, avg_loss = 0.1757\n",
            "t = 6, avg_loss = 0.1716\n",
            "t = 7, avg_loss = 0.1970\n",
            "t = 8, avg_loss = 0.3083\n",
            "t = 9, avg_loss = 0.1585\n",
            "t = 10, avg_loss = 0.2112\n",
            "t = 11, avg_loss = 0.2353\n",
            "t = 12, avg_loss = 0.3338\n",
            "t = 13, avg_loss = 0.1759\n",
            "t = 14, avg_loss = 0.1954\n",
            "t = 15, avg_loss = 0.2192\n",
            "t = 16, avg_loss = 0.1652\n",
            "t = 17, avg_loss = 0.2007\n",
            "t = 18, avg_loss = 0.2455\n",
            "t = 19, avg_loss = 0.1361\n",
            "t = 20, avg_loss = 0.2392\n",
            "t = 21, avg_loss = 0.2634\n",
            "t = 22, avg_loss = 0.1941\n",
            "t = 23, avg_loss = 0.2031\n",
            "t = 24, avg_loss = 0.3202\n",
            "t = 25, avg_loss = 0.3623\n",
            "Checking accuracy on test set\n",
            "Got 313 / 400 correct (78.25)\n",
            "acc = 0.782500\n",
            "Starting epoch 18 / 80\n",
            "t = 1, avg_loss = 0.2994\n",
            "t = 2, avg_loss = 0.1500\n",
            "t = 3, avg_loss = 0.1537\n",
            "t = 4, avg_loss = 0.1967\n",
            "t = 5, avg_loss = 0.2368\n",
            "t = 6, avg_loss = 0.1681\n",
            "t = 7, avg_loss = 0.2464\n",
            "t = 8, avg_loss = 0.2188\n",
            "t = 9, avg_loss = 0.1584\n",
            "t = 10, avg_loss = 0.1657\n",
            "t = 11, avg_loss = 0.2007\n",
            "t = 12, avg_loss = 0.2384\n",
            "t = 13, avg_loss = 0.1546\n",
            "t = 14, avg_loss = 0.3059\n",
            "t = 15, avg_loss = 0.1508\n",
            "t = 16, avg_loss = 0.1951\n",
            "t = 17, avg_loss = 0.2259\n",
            "t = 18, avg_loss = 0.3072\n",
            "t = 19, avg_loss = 0.2045\n",
            "t = 20, avg_loss = 0.2930\n",
            "t = 21, avg_loss = 0.1734\n",
            "t = 22, avg_loss = 0.1727\n",
            "t = 23, avg_loss = 0.2900\n",
            "t = 24, avg_loss = 0.2890\n",
            "t = 25, avg_loss = 0.2003\n",
            "Checking accuracy on test set\n",
            "Got 326 / 400 correct (81.50)\n",
            "acc = 0.815000\n",
            "Starting epoch 19 / 80\n",
            "t = 1, avg_loss = 0.2182\n",
            "t = 2, avg_loss = 0.1478\n",
            "t = 3, avg_loss = 0.2639\n",
            "t = 4, avg_loss = 0.1926\n",
            "t = 5, avg_loss = 0.2153\n",
            "t = 6, avg_loss = 0.1893\n",
            "t = 7, avg_loss = 0.2416\n",
            "t = 8, avg_loss = 0.2232\n",
            "t = 9, avg_loss = 0.1802\n",
            "t = 10, avg_loss = 0.2353\n",
            "t = 11, avg_loss = 0.1500\n",
            "t = 12, avg_loss = 0.0913\n",
            "t = 13, avg_loss = 0.1695\n",
            "t = 14, avg_loss = 0.2232\n",
            "t = 15, avg_loss = 0.2096\n",
            "t = 16, avg_loss = 0.2245\n",
            "t = 17, avg_loss = 0.2248\n",
            "t = 18, avg_loss = 0.1397\n",
            "t = 19, avg_loss = 0.2116\n",
            "t = 20, avg_loss = 0.3335\n",
            "t = 21, avg_loss = 0.2776\n",
            "t = 22, avg_loss = 0.2241\n",
            "t = 23, avg_loss = 0.2001\n",
            "t = 24, avg_loss = 0.1058\n",
            "t = 25, avg_loss = 0.2787\n",
            "Checking accuracy on test set\n",
            "Got 325 / 400 correct (81.25)\n",
            "acc = 0.812500\n",
            "Starting epoch 20 / 80\n",
            "t = 1, avg_loss = 0.1226\n",
            "t = 2, avg_loss = 0.1393\n",
            "t = 3, avg_loss = 0.1546\n",
            "t = 4, avg_loss = 0.1586\n",
            "t = 5, avg_loss = 0.1978\n",
            "t = 6, avg_loss = 0.1612\n",
            "t = 7, avg_loss = 0.1947\n",
            "t = 8, avg_loss = 0.2400\n",
            "t = 9, avg_loss = 0.1493\n",
            "t = 10, avg_loss = 0.3148\n",
            "t = 11, avg_loss = 0.2844\n",
            "t = 12, avg_loss = 0.2173\n",
            "t = 13, avg_loss = 0.1836\n",
            "t = 14, avg_loss = 0.1263\n",
            "t = 15, avg_loss = 0.1379\n",
            "t = 16, avg_loss = 0.2317\n",
            "t = 17, avg_loss = 0.2772\n",
            "t = 18, avg_loss = 0.2392\n",
            "t = 19, avg_loss = 0.1539\n",
            "t = 20, avg_loss = 0.1202\n",
            "t = 21, avg_loss = 0.1681\n",
            "t = 22, avg_loss = 0.1884\n",
            "t = 23, avg_loss = 0.1176\n",
            "t = 24, avg_loss = 0.1546\n",
            "t = 25, avg_loss = 0.2042\n",
            "Checking accuracy on test set\n",
            "Got 337 / 400 correct (84.25)\n",
            "acc = 0.842500\n",
            "Starting epoch 21 / 80\n",
            "t = 1, avg_loss = 0.1536\n",
            "t = 2, avg_loss = 0.1918\n",
            "t = 3, avg_loss = 0.1365\n",
            "t = 4, avg_loss = 0.2056\n",
            "t = 5, avg_loss = 0.2081\n",
            "t = 6, avg_loss = 0.1716\n",
            "t = 7, avg_loss = 0.2461\n",
            "t = 8, avg_loss = 0.1261\n",
            "t = 9, avg_loss = 0.1935\n",
            "t = 10, avg_loss = 0.2656\n",
            "t = 11, avg_loss = 0.1120\n",
            "t = 12, avg_loss = 0.2215\n",
            "t = 13, avg_loss = 0.1120\n",
            "t = 14, avg_loss = 0.1925\n",
            "t = 15, avg_loss = 0.1892\n",
            "t = 16, avg_loss = 0.1926\n",
            "t = 17, avg_loss = 0.2154\n",
            "t = 18, avg_loss = 0.1593\n",
            "t = 19, avg_loss = 0.2682\n",
            "t = 20, avg_loss = 0.2008\n",
            "t = 21, avg_loss = 0.1316\n",
            "t = 22, avg_loss = 0.2203\n",
            "t = 23, avg_loss = 0.2592\n",
            "t = 24, avg_loss = 0.3384\n",
            "t = 25, avg_loss = 0.2094\n",
            "Checking accuracy on test set\n",
            "Got 297 / 400 correct (74.25)\n",
            "acc = 0.742500\n",
            "Starting epoch 22 / 80\n",
            "t = 1, avg_loss = 0.2411\n",
            "t = 2, avg_loss = 0.2660\n",
            "t = 3, avg_loss = 0.1110\n",
            "t = 4, avg_loss = 0.1464\n",
            "t = 5, avg_loss = 0.0939\n",
            "t = 6, avg_loss = 0.2025\n",
            "t = 7, avg_loss = 0.1758\n",
            "t = 8, avg_loss = 0.1183\n",
            "t = 9, avg_loss = 0.1489\n",
            "t = 10, avg_loss = 0.1160\n",
            "t = 11, avg_loss = 0.1789\n",
            "t = 12, avg_loss = 0.1462\n",
            "t = 13, avg_loss = 0.1646\n",
            "t = 14, avg_loss = 0.2345\n",
            "t = 15, avg_loss = 0.2501\n",
            "t = 16, avg_loss = 0.1354\n",
            "t = 17, avg_loss = 0.1289\n",
            "t = 18, avg_loss = 0.1159\n",
            "t = 19, avg_loss = 0.1321\n",
            "t = 20, avg_loss = 0.1551\n",
            "t = 21, avg_loss = 0.2670\n",
            "t = 22, avg_loss = 0.2118\n",
            "t = 23, avg_loss = 0.2208\n",
            "t = 24, avg_loss = 0.2020\n",
            "t = 25, avg_loss = 0.1504\n",
            "Checking accuracy on test set\n",
            "Got 322 / 400 correct (80.50)\n",
            "acc = 0.805000\n",
            "Starting epoch 23 / 80\n",
            "t = 1, avg_loss = 0.1269\n",
            "t = 2, avg_loss = 0.1404\n",
            "t = 3, avg_loss = 0.1935\n",
            "t = 4, avg_loss = 0.0901\n",
            "t = 5, avg_loss = 0.1680\n",
            "t = 6, avg_loss = 0.2929\n",
            "t = 7, avg_loss = 0.2369\n",
            "t = 8, avg_loss = 0.2260\n",
            "t = 9, avg_loss = 0.2141\n",
            "t = 10, avg_loss = 0.2094\n",
            "t = 11, avg_loss = 0.1788\n",
            "t = 12, avg_loss = 0.2256\n",
            "t = 13, avg_loss = 0.2610\n",
            "t = 14, avg_loss = 0.1655\n",
            "t = 15, avg_loss = 0.1804\n",
            "t = 16, avg_loss = 0.1223\n",
            "t = 17, avg_loss = 0.1171\n",
            "t = 18, avg_loss = 0.2590\n",
            "t = 19, avg_loss = 0.1445\n",
            "t = 20, avg_loss = 0.1080\n",
            "t = 21, avg_loss = 0.1315\n",
            "t = 22, avg_loss = 0.1918\n",
            "t = 23, avg_loss = 0.1429\n",
            "t = 24, avg_loss = 0.1087\n",
            "t = 25, avg_loss = 0.1310\n",
            "Checking accuracy on test set\n",
            "Got 329 / 400 correct (82.25)\n",
            "acc = 0.822500\n",
            "Starting epoch 24 / 80\n",
            "t = 1, avg_loss = 0.1373\n",
            "t = 2, avg_loss = 0.1694\n",
            "t = 3, avg_loss = 0.1944\n",
            "t = 4, avg_loss = 0.1112\n",
            "t = 5, avg_loss = 0.2176\n",
            "t = 6, avg_loss = 0.1986\n",
            "t = 7, avg_loss = 0.1505\n",
            "t = 8, avg_loss = 0.1202\n",
            "t = 9, avg_loss = 0.2304\n",
            "t = 10, avg_loss = 0.1982\n",
            "t = 11, avg_loss = 0.1064\n",
            "t = 12, avg_loss = 0.1097\n",
            "t = 13, avg_loss = 0.2414\n",
            "t = 14, avg_loss = 0.1523\n",
            "t = 15, avg_loss = 0.1195\n",
            "t = 16, avg_loss = 0.1068\n",
            "t = 17, avg_loss = 0.2201\n",
            "t = 18, avg_loss = 0.1671\n",
            "t = 19, avg_loss = 0.1010\n",
            "t = 20, avg_loss = 0.1972\n",
            "t = 21, avg_loss = 0.1809\n",
            "t = 22, avg_loss = 0.2581\n",
            "t = 23, avg_loss = 0.1028\n",
            "t = 24, avg_loss = 0.2202\n",
            "t = 25, avg_loss = 0.1041\n",
            "Checking accuracy on test set\n",
            "Got 331 / 400 correct (82.75)\n",
            "acc = 0.827500\n",
            "Starting epoch 25 / 80\n",
            "t = 1, avg_loss = 0.2133\n",
            "t = 2, avg_loss = 0.1586\n",
            "t = 3, avg_loss = 0.1722\n",
            "t = 4, avg_loss = 0.0850\n",
            "t = 5, avg_loss = 0.2106\n",
            "t = 6, avg_loss = 0.1085\n",
            "t = 7, avg_loss = 0.1887\n",
            "t = 8, avg_loss = 0.1728\n",
            "t = 9, avg_loss = 0.1968\n",
            "t = 10, avg_loss = 0.0929\n",
            "t = 11, avg_loss = 0.1269\n",
            "t = 12, avg_loss = 0.1681\n",
            "t = 13, avg_loss = 0.1551\n",
            "t = 14, avg_loss = 0.1789\n",
            "t = 15, avg_loss = 0.1783\n",
            "t = 16, avg_loss = 0.1106\n",
            "t = 17, avg_loss = 0.1552\n",
            "t = 18, avg_loss = 0.1683\n",
            "t = 19, avg_loss = 0.0848\n",
            "t = 20, avg_loss = 0.1903\n",
            "t = 21, avg_loss = 0.1794\n",
            "t = 22, avg_loss = 0.1883\n",
            "t = 23, avg_loss = 0.1137\n",
            "t = 24, avg_loss = 0.1663\n",
            "t = 25, avg_loss = 0.2276\n",
            "Checking accuracy on test set\n",
            "Got 313 / 400 correct (78.25)\n",
            "acc = 0.782500\n",
            "Starting epoch 26 / 80\n",
            "t = 1, avg_loss = 0.1162\n",
            "t = 2, avg_loss = 0.2214\n",
            "t = 3, avg_loss = 0.1231\n",
            "t = 4, avg_loss = 0.1588\n",
            "t = 5, avg_loss = 0.1622\n",
            "t = 6, avg_loss = 0.1785\n",
            "t = 7, avg_loss = 0.1677\n",
            "t = 8, avg_loss = 0.1087\n",
            "t = 9, avg_loss = 0.1126\n",
            "t = 10, avg_loss = 0.1361\n",
            "t = 11, avg_loss = 0.1361\n",
            "t = 12, avg_loss = 0.1794\n",
            "t = 13, avg_loss = 0.1795\n",
            "t = 14, avg_loss = 0.1701\n",
            "t = 15, avg_loss = 0.1163\n",
            "t = 16, avg_loss = 0.1387\n",
            "t = 17, avg_loss = 0.2572\n",
            "t = 18, avg_loss = 0.1516\n",
            "t = 19, avg_loss = 0.1489\n",
            "t = 20, avg_loss = 0.1489\n",
            "t = 21, avg_loss = 0.1043\n",
            "t = 22, avg_loss = 0.2025\n",
            "t = 23, avg_loss = 0.2491\n",
            "t = 24, avg_loss = 0.1148\n",
            "t = 25, avg_loss = 0.1830\n",
            "Checking accuracy on test set\n",
            "Got 318 / 400 correct (79.50)\n",
            "acc = 0.795000\n",
            "Starting epoch 27 / 80\n",
            "t = 1, avg_loss = 0.1238\n",
            "t = 2, avg_loss = 0.1400\n",
            "t = 3, avg_loss = 0.0977\n",
            "t = 4, avg_loss = 0.1484\n",
            "t = 5, avg_loss = 0.1704\n",
            "t = 6, avg_loss = 0.1985\n",
            "t = 7, avg_loss = 0.1498\n",
            "t = 8, avg_loss = 0.0740\n",
            "t = 9, avg_loss = 0.0729\n",
            "t = 10, avg_loss = 0.1148\n",
            "t = 11, avg_loss = 0.2073\n",
            "t = 12, avg_loss = 0.0839\n",
            "t = 13, avg_loss = 0.1634\n",
            "t = 14, avg_loss = 0.1583\n",
            "t = 15, avg_loss = 0.2265\n",
            "t = 16, avg_loss = 0.2660\n",
            "t = 17, avg_loss = 0.1074\n",
            "t = 18, avg_loss = 0.1216\n",
            "t = 19, avg_loss = 0.1546\n",
            "t = 20, avg_loss = 0.1115\n",
            "t = 21, avg_loss = 0.1469\n",
            "t = 22, avg_loss = 0.1623\n",
            "t = 23, avg_loss = 0.0915\n",
            "t = 24, avg_loss = 0.0674\n",
            "t = 25, avg_loss = 0.2463\n",
            "Checking accuracy on test set\n",
            "Got 322 / 400 correct (80.50)\n",
            "acc = 0.805000\n",
            "Starting epoch 28 / 80\n",
            "t = 1, avg_loss = 0.1204\n",
            "t = 2, avg_loss = 0.1684\n",
            "t = 3, avg_loss = 0.1695\n",
            "t = 4, avg_loss = 0.0951\n",
            "t = 5, avg_loss = 0.1069\n",
            "t = 6, avg_loss = 0.1252\n",
            "t = 7, avg_loss = 0.1524\n",
            "t = 8, avg_loss = 0.1385\n",
            "t = 9, avg_loss = 0.1291\n",
            "t = 10, avg_loss = 0.1631\n",
            "t = 11, avg_loss = 0.1044\n",
            "t = 12, avg_loss = 0.1125\n",
            "t = 13, avg_loss = 0.2157\n",
            "t = 14, avg_loss = 0.1072\n",
            "t = 15, avg_loss = 0.1535\n",
            "t = 16, avg_loss = 0.1141\n",
            "t = 17, avg_loss = 0.1036\n",
            "t = 18, avg_loss = 0.2308\n",
            "t = 19, avg_loss = 0.1206\n",
            "t = 20, avg_loss = 0.1830\n",
            "t = 21, avg_loss = 0.0799\n",
            "t = 22, avg_loss = 0.2343\n",
            "t = 23, avg_loss = 0.2579\n",
            "t = 24, avg_loss = 0.1217\n",
            "t = 25, avg_loss = 0.1013\n",
            "Checking accuracy on test set\n",
            "Got 330 / 400 correct (82.50)\n",
            "acc = 0.825000\n",
            "Starting epoch 29 / 80\n",
            "t = 1, avg_loss = 0.0777\n",
            "t = 2, avg_loss = 0.1173\n",
            "t = 3, avg_loss = 0.0981\n",
            "t = 4, avg_loss = 0.0933\n",
            "t = 5, avg_loss = 0.1264\n",
            "t = 6, avg_loss = 0.1154\n",
            "t = 7, avg_loss = 0.1713\n",
            "t = 8, avg_loss = 0.1340\n",
            "t = 9, avg_loss = 0.1101\n",
            "t = 10, avg_loss = 0.0727\n",
            "t = 11, avg_loss = 0.0763\n",
            "t = 12, avg_loss = 0.1580\n",
            "t = 13, avg_loss = 0.1613\n",
            "t = 14, avg_loss = 0.2016\n",
            "t = 15, avg_loss = 0.1133\n",
            "t = 16, avg_loss = 0.1489\n",
            "t = 17, avg_loss = 0.1060\n",
            "t = 18, avg_loss = 0.1820\n",
            "t = 19, avg_loss = 0.1133\n",
            "t = 20, avg_loss = 0.1481\n",
            "t = 21, avg_loss = 0.0732\n",
            "t = 22, avg_loss = 0.0699\n",
            "t = 23, avg_loss = 0.1622\n",
            "t = 24, avg_loss = 0.1641\n",
            "t = 25, avg_loss = 0.0678\n",
            "Checking accuracy on test set\n",
            "Got 335 / 400 correct (83.75)\n",
            "acc = 0.837500\n",
            "Starting epoch 30 / 80\n",
            "t = 1, avg_loss = 0.0847\n",
            "t = 2, avg_loss = 0.1364\n",
            "t = 3, avg_loss = 0.1038\n",
            "t = 4, avg_loss = 0.0994\n",
            "t = 5, avg_loss = 0.0847\n",
            "t = 6, avg_loss = 0.1128\n",
            "t = 7, avg_loss = 0.1272\n",
            "t = 8, avg_loss = 0.1399\n",
            "t = 9, avg_loss = 0.1403\n",
            "t = 10, avg_loss = 0.0651\n",
            "t = 11, avg_loss = 0.1070\n",
            "t = 12, avg_loss = 0.1033\n",
            "t = 13, avg_loss = 0.1123\n",
            "t = 14, avg_loss = 0.1034\n",
            "t = 15, avg_loss = 0.0865\n",
            "t = 16, avg_loss = 0.2020\n",
            "t = 17, avg_loss = 0.1493\n",
            "t = 18, avg_loss = 0.0995\n",
            "t = 19, avg_loss = 0.1296\n",
            "t = 20, avg_loss = 0.0863\n",
            "t = 21, avg_loss = 0.1195\n",
            "t = 22, avg_loss = 0.0890\n",
            "t = 23, avg_loss = 0.1588\n",
            "t = 24, avg_loss = 0.0779\n",
            "t = 25, avg_loss = 0.1110\n",
            "Checking accuracy on test set\n",
            "Got 326 / 400 correct (81.50)\n",
            "acc = 0.815000\n",
            "Starting epoch 31 / 80\n",
            "t = 1, avg_loss = 0.1192\n",
            "t = 2, avg_loss = 0.0698\n",
            "t = 3, avg_loss = 0.0820\n",
            "t = 4, avg_loss = 0.0975\n",
            "t = 5, avg_loss = 0.1371\n",
            "t = 6, avg_loss = 0.1158\n",
            "t = 7, avg_loss = 0.0804\n",
            "t = 8, avg_loss = 0.1025\n",
            "t = 9, avg_loss = 0.0972\n",
            "t = 10, avg_loss = 0.0714\n",
            "t = 11, avg_loss = 0.1080\n",
            "t = 12, avg_loss = 0.1113\n",
            "t = 13, avg_loss = 0.1147\n",
            "t = 14, avg_loss = 0.1604\n",
            "t = 15, avg_loss = 0.1799\n",
            "t = 16, avg_loss = 0.2426\n",
            "t = 17, avg_loss = 0.1214\n",
            "t = 18, avg_loss = 0.1358\n",
            "t = 19, avg_loss = 0.1685\n",
            "t = 20, avg_loss = 0.1225\n",
            "t = 21, avg_loss = 0.0776\n",
            "t = 22, avg_loss = 0.1257\n",
            "t = 23, avg_loss = 0.2117\n",
            "t = 24, avg_loss = 0.1447\n",
            "t = 25, avg_loss = 0.1744\n",
            "Checking accuracy on test set\n",
            "Got 318 / 400 correct (79.50)\n",
            "acc = 0.795000\n",
            "Starting epoch 32 / 80\n",
            "t = 1, avg_loss = 0.1361\n",
            "t = 2, avg_loss = 0.2274\n",
            "t = 3, avg_loss = 0.1355\n",
            "t = 4, avg_loss = 0.1632\n",
            "t = 5, avg_loss = 0.0499\n",
            "t = 6, avg_loss = 0.0971\n",
            "t = 7, avg_loss = 0.0953\n",
            "t = 8, avg_loss = 0.0946\n",
            "t = 9, avg_loss = 0.0998\n",
            "t = 10, avg_loss = 0.0918\n",
            "t = 11, avg_loss = 0.0898\n",
            "t = 12, avg_loss = 0.0878\n",
            "t = 13, avg_loss = 0.0923\n",
            "t = 14, avg_loss = 0.1754\n",
            "t = 15, avg_loss = 0.1680\n",
            "t = 16, avg_loss = 0.1112\n",
            "t = 17, avg_loss = 0.1145\n",
            "t = 18, avg_loss = 0.1633\n",
            "t = 19, avg_loss = 0.1762\n",
            "t = 20, avg_loss = 0.1315\n",
            "t = 21, avg_loss = 0.2154\n",
            "t = 22, avg_loss = 0.1081\n",
            "t = 23, avg_loss = 0.1760\n",
            "t = 24, avg_loss = 0.0952\n",
            "t = 25, avg_loss = 0.1650\n",
            "Checking accuracy on test set\n",
            "Got 321 / 400 correct (80.25)\n",
            "acc = 0.802500\n",
            "Starting epoch 33 / 80\n",
            "t = 1, avg_loss = 0.1143\n",
            "t = 2, avg_loss = 0.1411\n",
            "t = 3, avg_loss = 0.1348\n",
            "t = 4, avg_loss = 0.1336\n",
            "t = 5, avg_loss = 0.1174\n",
            "t = 6, avg_loss = 0.1733\n",
            "t = 7, avg_loss = 0.1003\n",
            "t = 8, avg_loss = 0.0853\n",
            "t = 9, avg_loss = 0.0970\n",
            "t = 10, avg_loss = 0.1340\n",
            "t = 11, avg_loss = 0.2196\n",
            "t = 12, avg_loss = 0.1132\n",
            "t = 13, avg_loss = 0.1143\n",
            "t = 14, avg_loss = 0.1351\n",
            "t = 15, avg_loss = 0.1798\n",
            "t = 16, avg_loss = 0.1218\n",
            "t = 17, avg_loss = 0.1284\n",
            "t = 18, avg_loss = 0.0756\n",
            "t = 19, avg_loss = 0.1337\n",
            "t = 20, avg_loss = 0.1491\n",
            "t = 21, avg_loss = 0.0691\n",
            "t = 22, avg_loss = 0.1167\n",
            "t = 23, avg_loss = 0.1153\n",
            "t = 24, avg_loss = 0.1516\n",
            "t = 25, avg_loss = 0.1324\n",
            "Checking accuracy on test set\n",
            "Got 316 / 400 correct (79.00)\n",
            "acc = 0.790000\n",
            "Starting epoch 34 / 80\n",
            "t = 1, avg_loss = 0.0902\n",
            "t = 2, avg_loss = 0.1840\n",
            "t = 3, avg_loss = 0.1140\n",
            "t = 4, avg_loss = 0.0826\n",
            "t = 5, avg_loss = 0.0838\n",
            "t = 6, avg_loss = 0.1015\n",
            "t = 7, avg_loss = 0.1194\n",
            "t = 8, avg_loss = 0.0650\n",
            "t = 9, avg_loss = 0.1076\n",
            "t = 10, avg_loss = 0.1095\n",
            "t = 11, avg_loss = 0.0955\n",
            "t = 12, avg_loss = 0.1131\n",
            "t = 13, avg_loss = 0.1341\n",
            "t = 14, avg_loss = 0.1739\n",
            "t = 15, avg_loss = 0.1443\n",
            "t = 16, avg_loss = 0.0811\n",
            "t = 17, avg_loss = 0.1170\n",
            "t = 18, avg_loss = 0.0673\n",
            "t = 19, avg_loss = 0.0998\n",
            "t = 20, avg_loss = 0.1096\n",
            "t = 21, avg_loss = 0.1699\n",
            "t = 22, avg_loss = 0.0312\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-f8bfd2e8c010>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0mcheck_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-460fe8ab2743>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, loss_fn, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mx_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0my_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-50a9cd504daf>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m           \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"malignant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"malignant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \"\"\"\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   1871\u001b[0m                 )\n\u001b[1;32m   1872\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1873\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1875\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDn-2g-TLY3k",
        "colab_type": "code",
        "outputId": "288d3600-4b93-4b5f-ee77-96fd077fc955",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot([print_every*batch_size*(i+1) for i in range((len(avg_loss_list)))],avg_loss_list)\n",
        "print(\"Loss:\")\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYEFnGIbJEVjQGYZhcoT/B/ZpMnakRYD2AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGer6hJv7-zR",
        "colab_type": "code",
        "outputId": "7c556cbb-f5eb-4493-c760-97caf1ac7316",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "plt.plot([i+1 for i in range((len(acc_list)))],acc_list)\n",
        "print(\"Accurancy:\")\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accurancy:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXiU5dX48e/JCklYEpIQIECAgAiI\nIJss7orUqtDWWmytS7XUVvRt9W2r/VlrsX21vl1sLVptyytVK64FVBRccEFAEhRZwpaEJQlLdiAk\nZJvz+2MmMIQsk2SS2c7nunKReeZ5Zk6G5Mw993Pu84iqYowxJniF+ToAY4wxncsSvTHGBDlL9MYY\nE+Qs0RtjTJCzRG+MMUEuwtcBNJaYmKhpaWm+DsMYYwLKxo0bi1U1qan7/C7Rp6WlkZmZ6eswjDEm\noIjIvubus6kbY4wJch4lehGZJSI7RSRbRO5r4v5BIrJaRL4Qkc0icpVre5qIVInIJtfX37z9Axhj\njGlZq1M3IhIOLASuAPKBDBFZrqpZbrs9ALysqk+JyChgBZDmui9HVcd5N2xjjDGe8mREPxnIVtVc\nVa0BlgCzG+2jQE/X972AA94L0RhjTEd4kugHAHlut/Nd29w9BNwoIvk4R/N3ud03xDWl85GIXNDU\nE4jIPBHJFJHMoqIiz6M3xhjTKm+djL0BeFZVU4GrgOdEJAw4CAxS1fHAPcC/RaRn44NV9RlVnaiq\nE5OSmqwOMsYY006eJPoCYKDb7VTXNne3AS8DqOo6oBuQqKrVqlri2r4RyAFGdDRoY4wxnvMk0WcA\nw0VkiIhEAXOB5Y322Q9cBiAiZ+NM9EUikuQ6mYuIDAWGA7neCt6YYHakspaXMvZjrcRNR7VadaOq\ndSIyH1gJhAOLVHWbiCwAMlV1OXAv8HcR+QnOE7O3qKqKyIXAAhGpBRzAHapa2mk/jTFB5JG3t7Mk\nI4+xqb05u98ZM57GeMyjlbGqugLnSVb3bQ+6fZ8FTG/iuNeA1zoYozEhJ7uwgpcznTUQuwsrLNGb\nDrGVscb4oT+s2kn3yHDCxJn0jfe8l3WYtTnFvg6jS1miN8bPbMor5+2th/j+hUMZmBBDjiV6r6ip\nc/Dgsq3c/q9Mbns2k5yi0HldLdEb40dUld+9vYM+sVHcfsFQ0pPibETvBQePVPGtZ9bxr3X7uGnq\nYKIjw/jxkk3U1Dl8HVqXsERvWpRXWsnz6/dZ5UcX+WR3MetyS5h/aTpx0RGkJ8exp/g4dfWhkZA6\nw9qcYq55Yg27Dh3jye+cx4LZY3j062PZUnCEP723y9fhdQlL9KZFf/sohweWbiVjb5mvQwl6Dofy\n2ModpMZ359tTBgEwLDmOmnoHeWVVPo4u8KgqT3+Uw43/+Ixe3SNZNn86V53TD4BZY1K4YfJA/vZR\nTkjM11uiNy36NNv5R/DMxzk+jiT4vbXlIFsLjnLPFSOIjggHID05DrATsm1VUV3Hj174nEfe3sGs\nMSksmz+D9OQep+3zy6tHMaRPLPe89CXllTU+irRrWKI3zcorrWRvSSUDenfnve2FZBce83VIQau2\n3sEfVu3krL49mD3uVCspf0v0x07U8ubmAzz+3i6q6+p9HU6TsguPMfuva1i57RC/uGokC799HnHR\nZ1aSx0RF8PjccRRXVPOL/2wJ6ulJv7vClPEfDaP5P1x/Ljcv2sDfP97D764b6+OogtNLGXnsLank\nnzdPJDxMTm7v2S2S5B7RPk30hcdO8F5WIauyDrE2u4Qa1/mCIYmxp70p+YM3Nx/gZ69uJiYqnOdv\nn8K0YYkt7j82tTf3zBzBY+/s5NWN+Xxz4sAW9w9UluhNs9ZkF9O3ZzRThiTwzYmpvJyRz70zR5Dc\ns5uvQwsqlTV1/Pn93UwcHM+lI5PPuD89OY7sLi4FzC2qYFXWYVZtO8QXeeWowqCEGG6aOpgrRvXl\nxy9tYtmmA36V6F/bmM+9r3zJ+EG9efI759GvV3ePjvvBhcP4aGcRDy3fxqS0BNISYzs50q5nUzem\nSQ6HsjanhOnpiYgIt88YSq3DwbNr9/o6tKDzf5/upehYNT//ykhE5Iz705PjyCms6JKphefW7eXy\nP37EpX/4iEff3kFtvXLP5SNY+eML+einF/PA1aOYMrQP157bn493FVF63D/mtjfnl3P/f7YwbVgf\nXpo31eMkDxAeJvzpW+MIDxN+/NImaoOwwskSfRc4UlXLiVr/nM9sTtbBo5Qer2FGuvOjb1piLLNG\np/D8+n1UVNf5OLrgUV5Zw98+yuGykclMSktocp/05Dgqqus4fLS6U2P555o9/HLZNnp1j+TX147m\n0/su5Y27ZnDXZcM5K6XHaW9Cs8cNoM6hvLXZ99cYKq6o5gfPbSQpLpq/fvs8oiLantb69+7O/3z9\nHDbllfPE+7s7IUrfsqmbTra3+DhX/eUTqmrrGRgfw7CkWIYlxTEsOc75b1IsCbFRTY7kfKlhfn56\n+qk5znkXDuXtrYd4KSOP22YM8VVoQeWpD3OoqK7jp7POanaf9KRTJ2RTenXOtNl/vsjn4TezmDU6\nhYXfOe+08wRNObtfD0b0jWPppgN8d2pap8Tkidp6Bz964XNKj9fw2g+nkRAb1e7Hunpsf1bvKOKv\nq7O5YERSs2+8gcgSfSdSVe5/fQvhItx1STq5xcfJKTrO2pwSqt1W5PWOiWRYUhz9e3enlb8vwkT4\n/gVDGdW/c5tcrckuZkTfOPq6zcePHxTP5LQEFq3Zw01TBxMZbh8IO+LgkSqeXbuXr40bwMiU5v8/\nT1XeHGPG8JZPLrbH6h2F/PSVzUwd2ofH545rNckDiAizxw3gf1fuJK+0koEJMV6PyxO/fWs7G/aU\n8vi3xjFmQK8OP96vZ48mY28pP16yibd/fAE9u0V6IUrfs0TfiV7JzGddbgm//doYvjNl8MntDodS\nUF5FTlEFOUXHnf8WVrAlv7zVxzxQfgKHKn+eO77T4j5RW8+GPaUnF+24m3fhUG7/VyYrthz0qxNx\n/kJVOXjkBMk9oolo5Y3wz+/txqHKT65o+Vo8ST2i6dEtolNOyG7cV8YPX9jIWSk9eOamCXSLDPf4\n2Nnj+vO/K3eybFMB8y8d7vXYWvNKZh7Prt3LbTOGMGe8d34X46KdJZff/Ns6Hly6lcc78e+sK1mi\n7ySFx07wm7eymJyWwA2TTk+YYWHCwIQYBibEcHHzn9ib9PNXN7Niy0Gq6+pPLqrxts/3lVFd5zg5\nP+/u0pHJDEuK5emPcrn23P5+N+Xka8+t38eDy7YRGS4M7hN7aqrONV03NCmWnt0iT7YhvmlqWquj\nYRFxVt54ucRy1+FjfO/ZDFJ6duPZWyfTo42j19T4GCalxbN00wHuvCS9S38Xvswr5/8t3cq0YX24\n/ysjvfrY5w2K578uG84f393F1GF9+NakMwc8gcYSfSf59fIsTtQ6eOQb5xDmwUdhT80ak8JLmXms\nzSnhkrPOLMXzhjXZxUSECVOG9jnjvrAwYd6FQ/n5a1v4NLukU6YSAtWJ2nr++kE25wzoxYzhieQU\nVpBdWMH72wupc5yqmEnuEU14mNA9Mpz5l6Z79NjpSXGs3lnktVjzyyq56Z8biIoI47nbppDUI7pd\njzN73AAeWLqVbQeOemXqxBPFFdXc8bzz5OsTN4xv9ZNTe9x5SToZe0v55dJtjOjbg/GD4r3+HF3J\nEn0neDfrMG9tOch/zxzBMNeJNG+Zlt6HuOgIVm491GmJ/tPsYsYP6t3kakKAOeMH8PtVu3j64xxL\n9G5ezsyj8Fg1j88dd9pCndp6B/tLK8kpPDVVl1tUwZ2XpJMY51mCTU+O45WN+RyprKVXTMfmjUsq\nqrnpnxs4XlPHyz+Y2qH59a+e04+Hlm9j2aaCLkn0jU++9vHw9Wur8DDhL3PHc+3CNdzx/EbeuGsG\nyT0Cd/2InU3zsmMnavnl0q2MTOnBvAuHef3xoyPCuXRkMquyDlPv8H5ddXllDZsLjpxWbdNUDLdM\nS+OT3cVkHTjq9RgCUXVdPU99mMOktHimNvokFBkexrCkOGaOTuGHFw/j9988l9d/NJ0bzx/czKOd\n6eQJ2aKOtaGoqK7j1mczKCiv4p83T+rwlaviY6O4+Kwkln95oFN+HxtrOPn6u2+M7fQ3lvjYKJ6+\ncSJHqmr50fOfB3RLYxvRe9lj7+zk8LET/O27E9pVz+uJWWNSWP7lATL2lnJ+E9MrHbEupwRVmpyf\nd3fjlMEsXJ3N3z/J5U/fGue151dVHn9vN1sLjrS6b2JcND+ddZbHo+LO9OrGfA4eOcFj143tlLlq\n9543Ewa3r+yvuq6eO57byLYDR3n6xglMHuKd8sHZ4wbw3vZCPsstYVorvzcd0RknX1szqn9PHrvu\nXO5+8QsefjOLh+eM6ZLn9TYb0XtR5t5Snlu/j1unDWHcwN6d9jwXjUgiOiKMd7Ye8vpjr8kuJi46\ngnNbib9XTCRzJw3ijS8PcKDcey103956iD+/v5t9pZUcPnaixa+lmwq4+i9r+Hy/b1so19Q5eHJ1\nDuMH9W71DbK9UuNjiIoIa/cJ2XqHcu/LX7Imu5hHv34Ol4/q67XYLj+7L7FR4SzdVOC1x2ys4eTr\n1KHeP/nammvP7c8PLhzKc+v38XJGXpc+t7d4NKIXkVnAn4Fw4B+q+mij+wcBi4Hern3uc11QHBG5\nH7gNqAfuVtWV3gvff1TX1fPz1zYzoHd37p3ZcrlcR8VGR3DhiCRWbjvEr64Z5dUR5KfZxZw/NMGj\nGvnvzUhj8bq9LFqzhweuHtXh5z5RW89v39rOyJQevHX3Ba3Wc287cIQfPv8533p6HQ9ePYobzx/s\nkyqg/3yRT0F5Fb/52phOe/7wMGFoYiw5RcfbdfxbWw7y5uaD3PeVkV5v3NU9Kpwrx6Tw9pZDLJg9\npk0lmq2pq3eweN0+/rhqp2vla+ecfG3Nz2aNJOvgUR5YupXhfeMC7uRsq6+YiIQDC4GvAKOAG0Sk\n8V/1A8DLqjoemAs86Tp2lOv2aGAW8KTr8YLOwtU55BQd5zdfG0NsMycxvWnW6BQOHjnB5vzWpzg8\n1dCWuKX5eXep8TFcPbYfL27Yz5Gq2g4//9Mf5VJQXsVD1472aNHO6P69eGP+DC4YnsQvl23j3pe/\npKqma1tN1NY7+OvqbMam9uLiEUmd+lwdKbH8ZFcRvWMimXfBUC9H5TRn3ACOVdexekeh1x5zS/4R\n5jz5KQ+/mcXkIQm89IPzO+3ka2saTs727RXNHc9vpPDYCY+Oq3coK7YcZP6/P/doOrKzePLWOBnI\nVtVcVa0BlgCzG+2jQMNZnV5AQwOM2cASVa1W1T1Atuvxgsquw8d46sNs5ozr32mVMI1ddnYyEWHC\nO9u8N33T0PagLdMP8y4cyvGaev792f4OPXdBeRVPfZTNV8/p16bzDr1iIvnHTRO554oR/GdTAV97\n8lP2lbRv1NseyzYdIK+0irsvHd7pnyaGJcWRV1bZrr5J63JLOH9IH6+W+rqbNqwPiXHRXpm+qaiu\n49dvbGP2wjUcPlrNwm+fx6JbJpEa75vVtw3cT87e+ULLJ2er6+pZsmE/l//xI370wue8vfUQX39q\nLS9n+mbqx5NEPwBwjy7ftc3dQ8CNIpIPrADuasOxAa3eofz8tc3ERUfwSy9MX3iqd0wUU4f14Z2t\nh7zW1bChLXHDiT9PjO7fixnpifzfp3s6dCGKR1ZsRxXuv6rt869hYcLdlw3n/26ZxMEjJ7j6iTW8\nv/1wu2PxVF29g4WrsxnVryeXnd35b/DpyXGoQm4bp2/ySivJL6ti6jDvnrh3FxEexjXn9mP1jiKO\nVLb/092qbYe44o8f8ezavXxnymDev/civjq2n98szGs4OZuxt4yH38w64/6K6jqe+TiHC363mvte\n30JcdARPfuc81t9/GZPS4vnZq5u5//XNXd7k0FuTXTcAz6pqKnAV8JyIePzYIjJPRDJFJLOoyHuL\nQrrC8+v38cX+ch68ZlSXf6y8cnQKe4qPs9sLKyYbtyVui3kXDqXwWDVLNrRvtPJZbglvbj7IHRcN\n69Co7eKzknnzrhkMSojhtsWZ/HHVzk4t+Xtz80H2FB/n7ss6fzQP7iWWbfv/brgm6rROTPTgnL6p\nqXfw9taDbT72QHkV8/6VybznNtKreySv/XAaD88Z45e9Zpo6OVtcUc3vV+5k2iPv8z8rdjC8bxzP\n3zaF5a7r1Cb1iOZf35vCjy4exosb8rj+6XXkl1V2WcyeJOMCwP3sTaprm7vbgJcBVHUd0A1I9PBY\nVPUZVZ2oqhOTkjp3ntObCsqreOydHVw4Iok5Puj7MnNUX0RgpReqbxq3JW6LC4YnMj29Dw+/mcWH\nO9s2R1vvUB56I4v+vbpxx0UdX3cwMCGG1344jW9OSOUvH2Rz67MZnXI90HqH8sQHuxmZ0oOZXqxg\nacmQxFjCpO2XFVyXU0JiXNs+qbXH2NReDEmMbdP0Tb1DWbRmD1f88SM+3l3E/V8ZyRt3zeA8Pz/Z\n+dMrz2JGeiIPLN3Kf7/yJdMf/YCFH2YzPT2RZXdO54Xbz2fG8NMHTeFhws9mjeSZ705gT9Fxrnli\nDZ/s7pqBrSeJPgMYLiJDRCQK58nV5Y322Q9cBiAiZ+NM9EWu/eaKSLSIDAGGAxu8Fbyv/endXdSr\n8ts5nVdt0ZLknt2YMCjeK/P0TbUl9pSI8NSNExjRtwc/fP5zvmhDueOSjP1sP3iUX3z1bLpHeec8\nfbfIcB67biyPfP0c1uUU88iKHV55XHcrthwkp+g4d106vNPmvRvrFhnOwIQYctqQ6FWdn9SmDuvT\n6b+jzo6W/flsTykHj7Reclt2vIZbn81gwZtZTBqSwLs/uYgfXDQsILqiRoSH8cQNzpOzyzYVMGfc\nAN675yKeunFCq6XJM0ensGz+dJJ6RHPTog0sXJ2No5MXm7X6iqpqHTAfWAlsx1lds01EFojIta7d\n7gW+LyJfAi8Ct6jTNpwj/SzgHeBOVQ2sK3A0o6SimuVfHuCbEwb6rEUrOBdPbTtwlLzSjn0MbKot\ncVv07BbJ4u9NJrlnNLc+m+HRhcSPVNby+5U7mTwkga+e069dz9scEeGGyYO4emx/VmYdos6LVw1y\nuEbzw5Pj+MqYFK89rifSk9pWeZNbfJzCY9VnrNbtLHPGDUAVlm9q+YIkW/KPcPUTa1ifU8L/fO0c\n/u+WST79O2qP+Ngo3pg/g3X3X8bvrhvbpnYnQ5PiWHrndK4Z6+wAOu+5jV6pXGuOR2+dqrpCVUeo\n6jBV/a1r24Oqutz1fZaqTlfVc1V1nKqucjv2t67jzlLVtzvnx+h6SzLyqKlzcPM0z5exd4YrRzsT\nzcoOjOob2hK3ZzTvLqlHNM99bwqR4WF8958bWl1I9af3dnGkqtbrawHcXTk6hfLKWjbsKfXaY67c\ndohdhyuYf2l6l43mG6Qnx7Gn+LjHb1xrc0qAzp+fb5CWGMu5A3uztIVE/3JGHt/421pUlVfumMq3\npwzym5OtbdU7JqrdK7NjoiL489xx/OqaUXy4s5DZf13DjkOd01LE/z8j+aHaegfPrdvHjPRE0pN7\n+DSWgQkxjOrXs0OrZFtqS9xWg/rEsPjWyVScqOO7//yMsmauKbrr8DGeW7+PuZMHMbp/5/UsuWhE\nEt0iw7xWhupwKH9+fzdDE2O5emx/rzxmWwxLjqOm3kFemWerkdfnlNCvVzcG9+m60fKccf3ZfvAo\nuw6f/qnuRG0997++mZ+9tpkpQxJ48+4LWp3mCHYiwq3Th/DivPM5XlPPXf/+olOmcSzRt8OqbYc5\ndPQEN09L83UogHP6ZuP+MgqPeraIo7GW2hK3x6j+PfnHzRPJK6vi1mczON7oGrOqyoI3soiNCue/\nZ7axIX8bdY8K5+IRyazcdsgrf0DvbT/MjkPHmH9pukeLurzNvedNaxwOZV1u18zPu7t6bH/Cw4Sl\nX5w6KZtfVsn1T6/jxQ153HnJMJ69dXKHLvsXbCalJfDWXTP467fP65RPiZbo22Hx2r0MTOjOpSO7\nZnFUa2aNSUEVVmW1r3a8tbbE7TFlaB/+esN4NueXc8fzG09bXLIq6zBrsov5yRUjuuSPfdaYFA4f\nrWaTB1fwaomq8pcPdjO4TwzXntv1o3loW6LfVXiM0uM1p7VM7gpJPaKZkZ7Isk0HcDiUT3YXcc0T\na9hTdJxnvjuBn1450idvkv4uuWc3zkrpnBkCS/RttO3AETbsLeWm89P85pd1eHIcQxNj2zVP70lb\n4vaaOTqFR78+lk92F3PvK1/icCgnauv5zVtZDE+Oa1Ob3o64ZGQykeHS4TLU1TsL2VpwlDsvSfdJ\nvxVwnvRO7hHtUaJfm+2cn+/MhVLNmTO+PwXlVfz3K19y06INJPfoxvK7ZjBzdNeevDZO1qa4jRav\n3Uv3yHCu93JjqI4QEa4ck8LfP86lvLKG3jGej5I9bUvcXtdPGkjJ8Rp+984OEmIiSe7ZjbzSKp6/\nbUqXldH16h7JtGGJvLPtEPd9ZWS7pjFUlb+8n01qfHe+1kUtcpuTnhzn0aKpdbklDO4Tw4De3bsg\nqtPNHJVC98itvP5FAbPH9eeRr59DTJSlG1+xEX0blB2vYdmmA8wZP6DDV/nxtlmjU6hzKO9vb9uC\nJU/bEnfEHRcN5fYZQ1i8bh9/WLWTmaP6dvmVqWaNSWFfSSU7DrXvwh1f5JWzKa+ceRcO9Xmdd3py\nHDmFFS22vqh3KOtzS7qsrLKx2OgIfjNnDI9dN5bHvzXOkryPWaJvgyUZeVT7QUllU8am9qJfr25t\nri5Z04a2xO0lIvziqrP5xnmpdI8M54Gvdl1PoAaXn+1cRdze6qTFa/fSIzqCb5yX6uXI2i49OY6K\n6joOH61udp+sA0c5dqLOJ9M2Db4xIZXrJw4M2NLJYGKJ3kN19Q6eX7+PqUP7MDKlY5df6wwiwpWj\nU/h4V9EZVS7NySutZF8b2hJ3RFiY8PtvjmXD/7ucQV1Y6tcgqUc0kwYntOs8RuHRE6zYcpDrJqZ2\nSQvq1qQntX5CtqG/ja9G9Ma/WKL30HvbD1NQXuU3JZVNmTUmheo6Bx/t8qx/RnvaEneEiPg0UV45\nJoUdh46xt7ht3R9f+Gw/dQ7l5qlpnRNYG52qvGl+GmpdbgnpyXEkt3Olswkulug99OzavQzo3Z3L\nu6AdbXtNSkugT2yUx6PW9rQlDmRXjnY2H2vLqL6mzsG/N+zn4hFJpCXGdlZobZLUI5oe3SKaPSFb\nW+9gw55SG82bkyzRe2DHoaOszy3lxvMH+6yszhPhYcIVo/rywfbCZnvDOxzKxn1lPPL2dj7YUdiu\ntsSBKjU+hnMG9GrTeYy3tx6k6Fi1X32SE5EWrza1Of8IlTX1Xdb2wPg/3084BoDFa/cRHRHG3En+\nU1LZnCvHpLAkI4+1OSUnr3ZVXVfP2pwSVm07zLtZhymuqCYiTJg6rA/zL0n3ccRda9aYFP535U4O\nHTlBSq/WpzWeXbuXIYmxXDjcv9pnpyfFsXpn01N061zz895a6WwCnyX6VhyprOU/X+QzZ9wA4gNg\nyfa0YX3oER3B0i8KOFpVy6qsw3y4o5DjNfXERoVz8chkZo7qy8VnJdOru3+ViHaFK0c7E/2qrEPc\n1Mqc+5d55Xyxv5xfXTOqy5uXtSY9OY5XNuZzpLL2jFLfdbklnN2vp7UYMCdZom/FS5n7OVHr8KuP\n7i2Jjgjn0rOTWbbpAMs2HSAxLpprxw1g5ui+TBvWh+iIoLw2u8fSk+NIT47jna2tJ/rFa/cSGxXO\ndRN8X1LZ2KmrTR1jwuCEk9ur6+rJ3FvGd6b4Xwmw8R1L9C2odyj/WrePyWkJjOrvfyWVzbn7suEM\nSYzlguFJjB/Y2+9Go742a3QKT32UQ+nxmmZHvcUV1by5+SA3TB5IDz+8nJ17zxv3RP/F/nKq6xw2\nP29O479nFv3ABzsKyS+r4pbpab4OpU2GJcXx48tHMGFwvCX5Jswak0K9Q3mvhQuIv/jZfmrqHdzk\np5/kUuNjiIoIO+OE7NqcEsIEJg9NaOZIE4os0bdg8dq99OvVrcuuCWq6xuj+PRnQuzurmqm+qa13\n8Pxn+7hgeGKbrhrUlcLDhKGJseQUnb4mYH1OCecM6OWXF9U2vmOJvhm7Dx9jTXax35dUmrY7uYp4\ndzEVTawifmfrIQ4freZWP/8k17jEsqqmni/yypjaxW2Jjf+zDNaMxev2EhUgJZWm7WaNSaGmzsGH\nO89sArd47V4G94nh4hH+uzgOnIk+r6ySE7XONROZ+0qprVef9rcx/skSfRNO1Nbz+ucFXDO2P33a\neT1I498mDI4nMS7qjCZnWwuOkLmvjO+eP9jvz2+kJ8ehCrmu6Zu1OSVEhAmT0uJ9HJnxN5bom5Bf\nVkllTT0XdHErXdN1nKuIU1i9o/DkiBicC6S6R4bzTT+63kBzTpVYOqdv1uWUMG5gb2sJbM7gUaIX\nkVkislNEskXkvibu/5OIbHJ97RKRcrf76t3uW+7N4DtLw4WXByZ0/QUbTNeZNSaF4zX1J5u7lVRU\ns/zLA3z9vAEBsZgsrU8sYeIssTx2opYtBUesrNI0qdW3fhEJBxYCVwD5QIaILFfVrIZ9VPUnbvvf\nBYx3e4gqVR3nvZA7X74r0afGd307XdN1pg7tQ49uEbyz9RCXnd2XJRl51NQ5uMVPSyob6xYZzsCE\nGHIKK8jYW0q9QznfEr1pgicj+slAtqrmqmoNsASY3cL+NwAveiM4X8kvqyQqPIwkm58PalERYVx+\ndl/e3X6YE7X1vLB+H9PT+zC8b+dcoLkzpCc5K2/WZpcQFRHGeYNsft6cyZNEPwDIc7ud79p2BhEZ\nDAwBPnDb3E1EMkVkvYjMaea4ea59MouKPOul3pnyy6oYEN/d70/GmY67cnQK5ZW1/Pat7Rw4csJv\nes57Kj05jj3Fx1mTXcyEQfF0iwztFhemad4+GTsXeFVV3XvkDlbVicC3gcdFZFjjg1T1GVWdqKoT\nk5J83yUwv6yK1Hibnw8FF41IoltkGM+t30dqfHcuOzuwFscNS46jpt7BjkPHbH7eNMuTRF8AuJcg\npLq2NWUujaZtVLXA9W8u8CHsjdQAABEeSURBVCGnz9/7pYKySkv0IaJ7VPjJevnvnj+Y8AD7FOd+\n0RirnzfN8STRZwDDRWSIiEThTOZnVM+IyEggHljnti1eRKJd3ycC04Gsxsf6k8qaOoorauxEbAi5\nYcogRvSN41sBuDiuIdHHRIUzNrW3j6Mx/qrVqhtVrROR+cBKIBxYpKrbRGQBkKmqDUl/LrBEVdXt\n8LOBp0XEgfNN5VH3ah1/VHCy4sZG9KHiohFJXDTiIl+H0S49u0XSr1c3RvTtQVSELYsxTfNoZYWq\nrgBWNNr2YKPbDzVx3FrgnA7E1+WstNIEmie/c55dZMS0yJbQNZJfVgnAQBvRmwAx3koqTSvss14j\n+WVVREWEkWg19MaYIGGJvpH8sipSe1sNvTEmeFiibyS/rJIBNm1jjAkilugbcS6WshOxxpjgYYne\nTWVNHSXHa6y00hgTVCzRu8m3GnpjTBCyRO/mZGllgk3dGGOChyV6NzaiN8YEI0v0bvLLqoiOsD70\nxpjgYoneTUNppYjV0BtjgoclejdWWmmMCUaW6N3YBUeMMcHIEr3L8eo6Sq2G3hgThCzRuxSUW3ti\nY0xwskTvkldq7YmNMcHJEr2LXXDEGBOsLNG75JdVEh0RRmKcXanHGBNcLNG7NFTcWA29MSbYWKJ3\nsRp6Y0ywskTvkl9WaaWVxpig5FGiF5FZIrJTRLJF5L4m7v+TiGxyfe0SkXK3+24Wkd2ur5u9Gby3\nVFTXUVZZayN6Y0xQimhtBxEJBxYCVwD5QIaILFfVrIZ9VPUnbvvfBYx3fZ8A/AqYCCiw0XVsmVd/\nig4qsK6Vxpgg5smIfjKQraq5qloDLAFmt7D/DcCLru+vBN5V1VJXcn8XmNWRgDuD9aE3xgQzTxL9\nACDP7Xa+a9sZRGQwMAT4oC3Hisg8EckUkcyioiJP4vaqhsVSNqI3xgQjb5+MnQu8qqr1bTlIVZ9R\n1YmqOjEpKcnLIbUuv6yKbpFh9Im1GnpjTPDxJNEXAAPdbqe6tjVlLqembdp6rM80lFZaDb0xJhh5\nkugzgOEiMkREonAm8+WNdxKRkUA8sM5t80pgpojEi0g8MNO1za/kl1tppTEmeLWa6FW1DpiPM0Fv\nB15W1W0iskBErnXbdS6wRFXV7dhS4GGcbxYZwALXNr9ifeiNMcGs1fJKAFVdAaxotO3BRrcfaubY\nRcCidsbX6Y6dqKXcauiNMUEs5FfGnupDbyN6Y0xwCvlEn1/qTPQDbURvjAlSlujLrIbeGBPcQj7R\n55VV0T0ynASroTfGBKmQT/QNXSutht4YE6ws0VtppTEmyFmitwuOGGOCXEgn+qMnajlSVWsjemNM\nUAvpRH+qD72N6I0xwSukE32+K9EPTLARvTEmeIV4om+oobcRvTEmeIV4oq8iJiqc+JhIX4dijDGd\nJqQTfV6p1dAbY4JfSCd6K600xoSCEE/0dsERY0zwC9lEf6SqlqMn6izRG2OCXsgmequhN8aEipBN\n9A2lldaH3hgT7EI40duVpYwxoSGkE31sVDi9rYbeGBPkQjbR55VVkhofYzX0xpig51GiF5FZIrJT\nRLJF5L5m9rleRLJEZJuI/Ntte72IbHJ9LfdW4B1lfeiNMaEiorUdRCQcWAhcAeQDGSKyXFWz3PYZ\nDtwPTFfVMhFJdnuIKlUd5+W4Oyy/rJLJafG+DsMYYzqdJyP6yUC2quaqag2wBJjdaJ/vAwtVtQxA\nVQu9G6Z3Hamq5diJOiutNMaEBE8S/QAgz+12vmubuxHACBH5VETWi8gst/u6iUima/ucpp5AROa5\n9sksKipq0w/QHidLK609sTEmBLQ6ddOGxxkOXAykAh+LyDmqWg4MVtUCERkKfCAiW1Q1x/1gVX0G\neAZg4sSJ6qWYmpVvi6WMMSHEkxF9ATDQ7Xaqa5u7fGC5qtaq6h5gF87Ej6oWuP7NBT4Exncw5g6z\nGnpjTCjxJNFnAMNFZIiIRAFzgcbVM0txjuYRkUScUzm5IhIvItFu26cDWfhYflklcdER9OpuNfTG\nmODX6tSNqtaJyHxgJRAOLFLVbSKyAMhU1eWu+2aKSBZQD/xUVUtEZBrwtIg4cL6pPOpereMrDaWV\nVkNvjAkFHs3Rq+oKYEWjbQ+6fa/APa4v933WAud0PEzvarjgiDHGhIKQWxmrqhTYBUeMMSEk5BL9\n0ao6jlVbH3pjTOgIuUSf56qhtxG9MSZUhFyit9JKY0yoCcFEbxccMcaElhBM9FXERUfQs7u3FgUb\nY4x/C7lEn1dayaAE60NvjAkdIZfo97kSvTHGhIqQSvQOhzpH9H0s0RtjQkdIJfqiimqq6xwMtBG9\nMSaEhFSi31/qrLixqRtjTCgJrURfYoneGBN6QivRl1YSJjCgty2WMsaEjpBK9HmllfTr1Z2oiJD6\nsY0xIS6kMp6VVhpjQlFIJfr9luiNMSEoZBJ9VU09RceqrYbeGBNyQibRN7Qnthp6Y0yoCZlEb6WV\nxphQFTqJ3hZLGWNClEeJXkRmichOEckWkfua2ed6EckSkW0i8m+37TeLyG7X183eCryt9pdWEhcd\nQXxMpK9CMMYYn2i1KbuIhAMLgSuAfCBDRJarapbbPsOB+4HpqlomIsmu7QnAr4CJgAIbXceWef9H\nadl+a09sjAlRnozoJwPZqpqrqjXAEmB2o32+DyxsSOCqWujafiXwrqqWuu57F5jlndDbxkorjTGh\nypNEPwDIc7ud79rmbgQwQkQ+FZH1IjKrDcciIvNEJFNEMouKijyP3kPWntgYE8q8dTI2AhgOXAzc\nAPxdRHp7erCqPqOqE1V1YlJSkpdCOsXaExtjQpknib4AGOh2O9W1zV0+sFxVa1V1D7ALZ+L35NhO\nZxU3xphQ5kmizwCGi8gQEYkC5gLLG+2zFOdoHhFJxDmVkwusBGaKSLyIxAMzXdu6lNXQG2NCWatV\nN6paJyLzcSbocGCRqm4TkQVApqou51RCzwLqgZ+qagmAiDyM880CYIGqlnbGD9KS/aWViLUnNsaE\nqFYTPYCqrgBWNNr2oNv3Ctzj+mp87CJgUcfC7Ji80kr6W3tiY0yIConMZ+2JjTGhLCQSvdXQG2NC\nWdAnemtPbIwJdUGf6K09sTEm1AV9orfSSmNMqAv+RG+LpYwxIS4kEr21JzbGhLKQSPQDrT2xMSaE\nhUSiH2zTNsaYEBbUid7aExtjTJAnemtPbIwxQZ7oreLGGGOCPdFbDb0xxgR5orf2xMYYE/yJ3toT\nG2NCXVBnQGcNvY3mjTGhLegT/eCEWF+HYYwxPhW0id7aExtjjFPQJnprT2yMMU5Bm+ittNIYY5yC\nN9HbYiljjAE8TPQiMktEdopItojc18T9t4hIkYhscn3d7nZfvdv25d4MviXWntgYY5wiWttBRMKB\nhcAVQD6QISLLVTWr0a4vqer8Jh6iSlXHdTzUtrH2xMYY4+TJiH4ykK2quapaAywBZnduWB23v7SS\nQVZDb4wxHiX6AUCe2+1817bGviEim0XkVREZ6La9m4hkish6EZnT1BOIyDzXPplFRUWeR9+MhvbE\ng/tYDb0xxnjrZOwbQJqqjgXeBRa73TdYVScC3wYeF5FhjQ9W1WdUdaKqTkxKSupwMNae2BhjTvEk\n0RcA7iP0VNe2k1S1RFWrXTf/AUxwu6/A9W8u8CEwvgPxesQqbowx5hRPEn0GMFxEhohIFDAXOK16\nRkT6ud28Ftju2h4vItGu7xOB6UDjk7heZzX0xhhzSqtVN6paJyLzgZVAOLBIVbeJyAIgU1WXA3eL\nyLVAHVAK3OI6/GzgaRFx4HxTebSJah2v22ftiY0x5qRWEz2Aqq4AVjTa9qDb9/cD9zdx3FrgnA7G\n2GZ51p7YGGNOCspMaO2JjTHmlKBN9DY/b4wxTkGX6BvaE1sNvTHGOAVdorf2xMYYc7qgS/RWWmmM\nMacLukS/zxZLGWPMaYIu0edZe2JjjDlN0CV6a09sjDGnC8pEb+2JjTHmlKBK9Nae2BhjzhRUid7a\nExtjzJmCKtFbe2JjjDlTUCX6fVZDb4wxZwiqRL/f2hMbY8wZgirRW3tiY4w5U1BlRGtPbIwxZwq6\nRG/z88YYc7qgSfTWntgYY5oWNIm+sqaOa8/tz9jUXr4OxRhj/IpH14wNBH3iovnLDeN9HYYxxvid\noBnRG2OMaZpHiV5EZonIThHJFpH7mrj/FhEpEpFNrq/b3e67WUR2u75u9mbwxhhjWtfq1I2IhAML\ngSuAfCBDRJaralajXV9S1fmNjk0AfgVMBBTY6Dq2zCvRG2OMaZUnI/rJQLaq5qpqDbAEmO3h418J\nvKuqpa7k/i4wq32hGmOMaQ9PEv0AIM/tdr5rW2PfEJHNIvKqiAxsy7EiMk9EMkUks6ioyMPQjTHG\neMJbJ2PfANJUdSzOUfvithysqs+o6kRVnZiUlOSlkIwxxoBnib4AGOh2O9W17SRVLVHVatfNfwAT\nPD3WGGNM5/Ik0WcAw0VkiIhEAXOB5e47iEg/t5vXAttd368EZopIvIjEAzNd24wxxnSRVqtuVLVO\nRObjTNDhwCJV3SYiC4BMVV0O3C0i1wJ1QClwi+vYUhF5GOebBcACVS1t6fk2btxYLCL7mrgrESj2\n8OfyR4EcfyDHDoEdfyDHDoEdf6DFPri5O0RVuzKQdhORTFWd6Os42iuQ4w/k2CGw4w/k2CGw4w/k\n2BuzlbHGGBPkLNEbY0yQC6RE/4yvA+igQI4/kGOHwI4/kGOHwI4/kGM/TcDM0RtjjGmfQBrRG2OM\naQdL9MYYE+QCItG31ibZn4nIXhHZ4mrfnOnreFojIotEpFBEtrptSxCRd12tpt91LX7zS83E/5CI\nFLi10b7KlzE2R0QGishqEckSkW0i8l+u7X7/+rcQe6C89t1EZIOIfOmK/9eu7UNE5DNX7nnJtWg0\n4Pj9HL2rTfIu3NokAzc00SbZL4nIXmCiqgbEwgsRuRCoAP6lqmNc2x4DSlX1Udcbbbyq/tyXcTan\nmfgfAipU9fe+jK01rhXm/VT1cxHpAWwE5uBcgOjXr38LsV9PYLz2AsSqaoWIRAJrgP8C7gFeV9Ul\nIvI34EtVfcqXsbZHIIzoO9Im2bSRqn6Mc3Wzu9mcalS3GOcfsF9qJv6AoKoHVfVz1/fHcLYSGUAA\nvP4txB4Q1KnCdTPS9aXApcCrru1++dp7IhASvadtkv2VAqtEZKOIzPN1MO3UV1UPur4/BPT1ZTDt\nNN/VRnuRP059NCYiacB44DMC7PVvFDsEyGsvIuEisgkoxNmFNwcoV9U61y6BlntOCoREH+hmqOp5\nwFeAO11TCwFLnXN9/j3fd6angGHAOOAg8AffhtMyEYkDXgN+rKpH3e/z99e/idgD5rVX1XpVHYez\ny+5kYKSPQ/KaQEj0Ad3qWFULXP8WAv/B+QsUaA43dCh1/Vvo43jaRFUPu/6IHcDf8eP/A9f88GvA\nC6r6umtzQLz+TcUeSK99A1UtB1YDU4HeItLQ/DGgco+7QEj0rbZJ9lciEus6MYWIxOJs07y15aP8\n0nKg4cLuNwPLfBhLmzVqo/01/PT/wHVC8J/AdlX9o9tdfv/6Nxd7AL32SSLS2/V9d5zFH9txJvzr\nXLv55WvvCb+vugFwlWQ9zqk2yb/1cUgeEZGhOEfx4GwJ/W9/j11EXgQuxtmi9TDOi7svBV4GBgH7\ngOtbazftK83EfzHOqQMF9gI/cJvz9hsiMgP4BNgCOFybf4FzrtuvX/8WYr+BwHjtx+I82RqOcwD8\nsqoucP0NLwESgC+AG90ushQwAiLRG2OMab9AmLoxxhjTAZbojTEmyFmiN8aYIGeJ3hhjgpwlemOM\nCXKW6I0xJshZojfGmCD3/wG3W3LWgGpnPAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBTReWHxz4Ml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}