{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN_ascending_layers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamilo116/KNN/blob/master/KNN_ascending_layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7ReM7FU-xs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import sys\n",
        "from random import shuffle\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms as transforms\n",
        "import timeit\n",
        "\n",
        "np.random.seed(4) \n",
        "torch.manual_seed(4) \n",
        "torch.cuda.manual_seed(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYIMZ8QyYewD",
        "colab_type": "code",
        "outputId": "83d1692f-9b23-423b-9e1b-0bab921ac157",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "! git clone https://github.com/wang-chen/kervolution.git \n",
        "\n",
        "sys.path.append(\"kervolution/\")\n",
        "from kervolution import Kerv2d\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'kervolution'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 53 (delta 2), reused 0 (delta 0), pack-reused 47\u001b[K\n",
            "Unpacking objects: 100% (53/53), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvbKg4VJXKY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LIMIT_IMAGES_NUM = 1000\n",
        "train_test_split_size = 0.2\n",
        "image_resize = (100, 100)\n",
        "batch_size = 64\n",
        "num_workers = 0\n",
        "\n",
        "out_1 = 16\n",
        "out_2 = 32\n",
        "out_3 = 64\n",
        "out_4 = 128\n",
        "\n",
        "\n",
        "k_size_1 = 3\n",
        "padding_1 = 1\n",
        "in_channels = 3\n",
        "\n",
        "kernel_size = 3\n",
        "num_epochs = 80\n",
        "\n",
        "learning_rate = 0.0001\n",
        "weight_decay = 0.05\n",
        "\n",
        "MALIGNANT_DATASET = '/content/drive/My Drive/Colab_data/malignant/malignant/'\n",
        "BENIGN_DATASET = '/content/drive/My Drive/Colab_data/benign/benign/'\n",
        "DATA_FOLDER = '/content/drive/My Drive/Colab_data/'\n",
        "model_backup_path = os.path.join(DATA_FOLDER, 'backup_model2') \n",
        "TRAIN_DATA_PER_CATEGORY = 101"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMOHez_kHZD6",
        "colab_type": "code",
        "outputId": "e358fbe9-5f87-479b-9888-7ac35982e83b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b8P1NdXfVdX",
        "colab_type": "code",
        "outputId": "0e5d99e1-f765-4f79-823b-366223da884d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "benign_train_list = sorted(os.listdir(BENIGN_DATASET))[:LIMIT_IMAGES_NUM]\n",
        "malignant_train_list = sorted(os.listdir(MALIGNANT_DATASET))[:LIMIT_IMAGES_NUM]\n",
        "\n",
        "shuffle(benign_train_list)\n",
        "shuffle(malignant_train_list)\n",
        "\n",
        "test_benign_file_list = os.listdir(BENIGN_DATASET + 'test_set')[:TRAIN_DATA_PER_CATEGORY]\n",
        "test_malignant_file_list = os.listdir(MALIGNANT_DATASET + 'test_set')[:TRAIN_DATA_PER_CATEGORY]\n",
        "\n",
        "print(f\"Number of training benign {len(benign_train_list)} images\")\n",
        "print(f\"Number of training malignant {len(malignant_train_list)} images\")\n",
        "print(f\"Number of test benign {len(test_benign_file_list)} images\")\n",
        "print(f\"Number of test malignant {len(test_malignant_file_list)} images\")\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize(image_resize),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "data_transforms_test = transforms.Compose([\n",
        "    transforms.Resize(image_resize),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training benign 1000 images\n",
            "Number of training malignant 1000 images\n",
            "Number of test benign 101 images\n",
            "Number of test malignant 101 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvAAOqmVfVll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IsicDataset(Dataset):\n",
        "    def __init__(self, data_folder, labeled_data, \n",
        "                 transform=transforms.Compose([transforms.ToTensor()]), datatype='train'):\n",
        "        self.labeled_data = labeled_data\n",
        "        self.transform = transform\n",
        "        self.data_folder = data_folder\n",
        "        self.datatype = datatype\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labeled_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        label = self.labeled_data[index]\n",
        "        if self.datatype == 'train':\n",
        "          if label == 0:\n",
        "            image = Image.open(os.path.join(self.data_folder, \"benign\", \"benign\", index ))\n",
        "          else:\n",
        "            image = Image.open(os.path.join(self.data_folder, \"malignant\", \"malignant\", index ))\n",
        "        else:\n",
        "          if label == 0:\n",
        "            image = Image.open(os.path.join(self.data_folder, \"benign\", \"benign\", 'test_set', index ))\n",
        "          else:\n",
        "            image = Image.open(os.path.join(self.data_folder, \"malignant\", \"malignant\", 'test_set', index ))\n",
        "        image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "    @property\n",
        "    def labels(self):\n",
        "      return self.labeled_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e8nFBR6Yug5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "def prepare_dataset(benign_file_list, malignant_file_list, transform, datatype='train'):\n",
        "  benign_dict = {filename: 0 for filename in benign_file_list}\n",
        "  malignant_dict = {filename: 1 for filename in malignant_file_list}\n",
        "  img_class_dict = {**benign_dict , **malignant_dict}\n",
        "  labeled_data = pd.Series(img_class_dict)\n",
        "\n",
        "  dataset = IsicDataset(DATA_FOLDER, labeled_data, transform=transform, datatype=datatype)\n",
        "  print(dataset.labels)\n",
        "  return dataset\n",
        "\n",
        "def train(model, train_loader ,loss_fn, optimizer, num_epochs=1, starting_from_epoch=1):\n",
        "    total_loss =0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
        "        model.train()\n",
        "\n",
        "        for t, (x, y) in enumerate(train_loader):\n",
        "            x_var = Variable(x.type(gpu_dtype))\n",
        "            y_var = Variable(y.type(gpu_dtype).long())\n",
        "            scores = model(x_var)\n",
        "            loss = loss_fn(scores, y_var)\n",
        "            total_loss += loss.data\n",
        "            \n",
        "            if (t + 1) % print_every == 0:\n",
        "                avg_loss = total_loss/print_every\n",
        "                print('t = %d, avg_loss = %.4f' % (t + 1, avg_loss) )\n",
        "                avg_loss_list.append(avg_loss)\n",
        "                total_loss = 0\n",
        "                \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        acc = check_accuracy(model_gpu, valid_loader)\n",
        "        print('acc = %f' %(acc))\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model_gpu.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            'acc_list': acc_list,\n",
        "            }, model_backup_path)\n",
        "            \n",
        "def check_accuracy(model, loader, datatype='train'):\n",
        "    print(f'Checking accuracy on {datatype} set')   \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval() \n",
        "    for x, y in loader:\n",
        "        x_var = Variable(x.type(gpu_dtype))\n",
        "\n",
        "        scores = model(x_var)\n",
        "        _, preds = scores.data.cpu().max(1)\n",
        "        num_correct += (preds == y).sum()\n",
        "        num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    if datatype is 'train':\n",
        "      acc_list.append(acc)\n",
        "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "    return acc\n",
        "    \n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.size()\n",
        "        return x.view(N, -1)  \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSuYqjLAYrWA",
        "colab_type": "code",
        "outputId": "11674cdc-9699-4db8-a39e-65bd7d050d20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "train_dataset = prepare_dataset(benign_train_list, malignant_train_list, data_transforms)\n",
        "\n",
        "X_train, X_valid = train_test_split(train_dataset.labels, test_size=train_test_split_size)\n",
        "\n",
        "print(\"number of training data: \",len(X_train))\n",
        "print(\"number of valid  data: \",len(X_valid))\n",
        "\n",
        "train_sampler = SubsetRandomSampler(list(X_train.index))\n",
        "valid_sampler = SubsetRandomSampler(list(X_valid.index))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ISIC_0000330.jpeg    0\n",
            "ISIC_0000339.jpeg    0\n",
            "ISIC_0001453.jpeg    0\n",
            "ISIC_0000698.jpeg    0\n",
            "ISIC_0001145.jpeg    0\n",
            "                    ..\n",
            "ISIC_0000390.jpeg    1\n",
            "ISIC_0011870.jpeg    1\n",
            "ISIC_0011534.jpeg    1\n",
            "ISIC_0012758.jpeg    1\n",
            "ISIC_0000172.jpeg    1\n",
            "Length: 2000, dtype: int64\n",
            "number of training data:  1600\n",
            "number of valid  data:  400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vjEOfNZUB7W",
        "colab_type": "code",
        "outputId": "13e72dbb-8481-498a-e85f-89d15a52c55d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "test_dataset = prepare_dataset(test_benign_file_list, test_malignant_file_list, data_transforms_test, datatype='test')\n",
        "test_part, _ = train_test_split(test_dataset.labels, test_size=1)\n",
        "test_sampler = SubsetRandomSampler(list(test_part.index))\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=200, sampler=test_sampler, num_workers=num_workers)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ISIC_0000081.jpeg    0\n",
            "ISIC_0000033.jpeg    0\n",
            "ISIC_0000023.jpeg    0\n",
            "ISIC_0000137.jpeg    0\n",
            "ISIC_0000073.jpeg    0\n",
            "                    ..\n",
            "ISIC_0025783.jpg     1\n",
            "ISIC_0026604.jpg     1\n",
            "ISIC_0026754.jpg     1\n",
            "ISIC_0026847.jpg     1\n",
            "ISIC_0027060.jpg     1\n",
            "Length: 202, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-gYHw0Jlbwt",
        "colab_type": "code",
        "outputId": "782f06dd-609e-475d-94ee-cbcd2567101e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "print_every = 5\n",
        "gpu_dtype = torch.cuda.FloatTensor\n",
        "\n",
        "\n",
        "'''\n",
        "Kerv2d\n",
        "kervolution with following options:\n",
        "kernel_type: [linear, polynomial, gaussian, etc.]\n",
        "default is convolution:\n",
        "          kernel_type --> linear,\n",
        "balance, power, gamma is valid only when the kernel_type is specified\n",
        "if learnable_kernel = True,  they just be the initial value of learable parameters\n",
        "if learnable_kernel = False, they are the value of kernel_type's parameter\n",
        "the parameter [power] cannot be learned due to integer limitation\n",
        "dilation (int or tuple, optional): Spacing between kernel\n",
        "elements. Default: 1\n",
        "groups (int, optional): Number of blocked connections from input\n",
        "channels to output channels. Default: 1\n",
        "bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n",
        "kernel_type (str), Default: 'linear'\n",
        "learnable_kernel (bool): Learnable kernel parameters.  Default: False \n",
        "balance: 0, 1\n",
        "power: 3, 4, 5\n",
        "gamma:\n",
        "'''\n",
        "\n",
        "\n",
        "model_base = nn.Sequential( \n",
        "                #nn.Conv2d(in_channels , out_1, padding= padding_1, kernel_size=k_size_1, stride=1),\n",
        "                nn.Kerv2d(in_channels , out_1, padding=padding_1, dilation=1, groups=1, bias=True, \n",
        "                          kernel_type='polynomial', kernel_size=k_size_1, learnable_kernel=True,\n",
        "                          kernel_regularizer=True, stride=1, balance=1, power=3, gamma=1\n",
        "                          ), \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_1),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_1 , out_2, padding= padding_1, kernel_size=k_size_1, stride=1), \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_2),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_2 , out_3, padding= padding_1, kernel_size=k_size_1, stride=1),  \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_3),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_3 , out_4, padding= padding_1, kernel_size=k_size_1, stride=1),  \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_4),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Dropout(0.5),\n",
        "                Flatten(),\n",
        "                nn.Linear(4608,64),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Linear(64,2)\n",
        "            )\n",
        "model_gpu = model_base.type(gpu_dtype)\n",
        "print(model_gpu)\n",
        "loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Kerv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (4): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (5): ReLU(inplace=True)\n",
            "  (6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (8): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (9): ReLU(inplace=True)\n",
            "  (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (12): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (13): ReLU(inplace=True)\n",
            "  (14): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (16): Dropout(p=0.5, inplace=False)\n",
            "  (17): Flatten()\n",
            "  (18): Linear(in_features=4608, out_features=64, bias=True)\n",
            "  (19): ReLU(inplace=True)\n",
            "  (20): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgmexhBRZAK6",
        "colab_type": "code",
        "outputId": "4d9b1894-ee0d-4fd8-b488-485fc8efc2f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 1 / 80\n",
            "t = 2, avg_loss = 0.7561\n",
            "t = 4, avg_loss = 0.6100\n",
            "t = 6, avg_loss = 0.5856\n",
            "t = 8, avg_loss = 0.5818\n",
            "t = 10, avg_loss = 0.6288\n",
            "t = 12, avg_loss = 0.4127\n",
            "t = 14, avg_loss = 0.5417\n",
            "t = 16, avg_loss = 0.5396\n",
            "t = 18, avg_loss = 0.4144\n",
            "t = 20, avg_loss = 0.3993\n",
            "t = 22, avg_loss = 0.4429\n",
            "t = 24, avg_loss = 0.5213\n",
            "Checking accuracy on train set\n",
            "Got 243 / 400 correct (60.75)\n",
            "acc = 0.607500\n",
            "Starting epoch 2 / 80\n",
            "t = 2, avg_loss = 0.5825\n",
            "t = 4, avg_loss = 0.4029\n",
            "t = 6, avg_loss = 0.4296\n",
            "t = 8, avg_loss = 0.4373\n",
            "t = 10, avg_loss = 0.4814\n",
            "t = 12, avg_loss = 0.3955\n",
            "t = 14, avg_loss = 0.3852\n",
            "t = 16, avg_loss = 0.3688\n",
            "t = 18, avg_loss = 0.4053\n",
            "t = 20, avg_loss = 0.3771\n",
            "t = 22, avg_loss = 0.3516\n",
            "t = 24, avg_loss = 0.3838\n",
            "Checking accuracy on train set\n",
            "Got 327 / 400 correct (81.75)\n",
            "acc = 0.817500\n",
            "Starting epoch 3 / 80\n",
            "t = 2, avg_loss = 0.5068\n",
            "t = 4, avg_loss = 0.4613\n",
            "t = 6, avg_loss = 0.3576\n",
            "t = 8, avg_loss = 0.3784\n",
            "t = 10, avg_loss = 0.3837\n",
            "t = 12, avg_loss = 0.3540\n",
            "t = 14, avg_loss = 0.3627\n",
            "t = 16, avg_loss = 0.4305\n",
            "t = 18, avg_loss = 0.3327\n",
            "t = 20, avg_loss = 0.3999\n",
            "t = 22, avg_loss = 0.3661\n",
            "t = 24, avg_loss = 0.3097\n",
            "Checking accuracy on train set\n",
            "Got 338 / 400 correct (84.50)\n",
            "acc = 0.845000\n",
            "Starting epoch 4 / 80\n",
            "t = 2, avg_loss = 0.4169\n",
            "t = 4, avg_loss = 0.2860\n",
            "t = 6, avg_loss = 0.2850\n",
            "t = 8, avg_loss = 0.3320\n",
            "t = 10, avg_loss = 0.4059\n",
            "t = 12, avg_loss = 0.3129\n",
            "t = 14, avg_loss = 0.3834\n",
            "t = 16, avg_loss = 0.2952\n",
            "t = 18, avg_loss = 0.3040\n",
            "t = 20, avg_loss = 0.3572\n",
            "t = 22, avg_loss = 0.2795\n",
            "t = 24, avg_loss = 0.4816\n",
            "Checking accuracy on train set\n",
            "Got 338 / 400 correct (84.50)\n",
            "acc = 0.845000\n",
            "Starting epoch 5 / 80\n",
            "t = 2, avg_loss = 0.4363\n",
            "t = 4, avg_loss = 0.2926\n",
            "t = 6, avg_loss = 0.3173\n",
            "t = 8, avg_loss = 0.2655\n",
            "t = 10, avg_loss = 0.3814\n",
            "t = 12, avg_loss = 0.4044\n",
            "t = 14, avg_loss = 0.3258\n",
            "t = 16, avg_loss = 0.3456\n",
            "t = 18, avg_loss = 0.3868\n",
            "t = 20, avg_loss = 0.2994\n",
            "t = 22, avg_loss = 0.3887\n",
            "t = 24, avg_loss = 0.3531\n",
            "Checking accuracy on train set\n",
            "Got 340 / 400 correct (85.00)\n",
            "acc = 0.850000\n",
            "Starting epoch 6 / 80\n",
            "t = 2, avg_loss = 0.4725\n",
            "t = 4, avg_loss = 0.2561\n",
            "t = 6, avg_loss = 0.2741\n",
            "t = 8, avg_loss = 0.2732\n",
            "t = 10, avg_loss = 0.2876\n",
            "t = 12, avg_loss = 0.3136\n",
            "t = 14, avg_loss = 0.2866\n",
            "t = 16, avg_loss = 0.3158\n",
            "t = 18, avg_loss = 0.2982\n",
            "t = 20, avg_loss = 0.3370\n",
            "t = 22, avg_loss = 0.3490\n",
            "t = 24, avg_loss = 0.2123\n",
            "Checking accuracy on train set\n",
            "Got 339 / 400 correct (84.75)\n",
            "acc = 0.847500\n",
            "Starting epoch 7 / 80\n",
            "t = 2, avg_loss = 0.4057\n",
            "t = 4, avg_loss = 0.3204\n",
            "t = 6, avg_loss = 0.3453\n",
            "t = 8, avg_loss = 0.2462\n",
            "t = 10, avg_loss = 0.2554\n",
            "t = 12, avg_loss = 0.2751\n",
            "t = 14, avg_loss = 0.3481\n",
            "t = 16, avg_loss = 0.2620\n",
            "t = 18, avg_loss = 0.3121\n",
            "t = 20, avg_loss = 0.2648\n",
            "t = 22, avg_loss = 0.2334\n",
            "t = 24, avg_loss = 0.3432\n",
            "Checking accuracy on train set\n",
            "Got 344 / 400 correct (86.00)\n",
            "acc = 0.860000\n",
            "Starting epoch 8 / 80\n",
            "t = 2, avg_loss = 0.4031\n",
            "t = 4, avg_loss = 0.2354\n",
            "t = 6, avg_loss = 0.3140\n",
            "t = 8, avg_loss = 0.3255\n",
            "t = 10, avg_loss = 0.2751\n",
            "t = 12, avg_loss = 0.3442\n",
            "t = 14, avg_loss = 0.2945\n",
            "t = 16, avg_loss = 0.2453\n",
            "t = 18, avg_loss = 0.4936\n",
            "t = 20, avg_loss = 0.2642\n",
            "t = 22, avg_loss = 0.2406\n",
            "t = 24, avg_loss = 0.2871\n",
            "Checking accuracy on train set\n",
            "Got 341 / 400 correct (85.25)\n",
            "acc = 0.852500\n",
            "Starting epoch 9 / 80\n",
            "t = 2, avg_loss = 0.5443\n",
            "t = 4, avg_loss = 0.2797\n",
            "t = 6, avg_loss = 0.1993\n",
            "t = 8, avg_loss = 0.3314\n",
            "t = 10, avg_loss = 0.3144\n",
            "t = 12, avg_loss = 0.2308\n",
            "t = 14, avg_loss = 0.2837\n",
            "t = 16, avg_loss = 0.1650\n",
            "t = 18, avg_loss = 0.2882\n",
            "t = 20, avg_loss = 0.2660\n",
            "t = 22, avg_loss = 0.2209\n",
            "t = 24, avg_loss = 0.2380\n",
            "Checking accuracy on train set\n",
            "Got 337 / 400 correct (84.25)\n",
            "acc = 0.842500\n",
            "Starting epoch 10 / 80\n",
            "t = 2, avg_loss = 0.3117\n",
            "t = 4, avg_loss = 0.2107\n",
            "t = 6, avg_loss = 0.3146\n",
            "t = 8, avg_loss = 0.3581\n",
            "t = 10, avg_loss = 0.2792\n",
            "t = 12, avg_loss = 0.2471\n",
            "t = 14, avg_loss = 0.2859\n",
            "t = 16, avg_loss = 0.2181\n",
            "t = 18, avg_loss = 0.2611\n",
            "t = 20, avg_loss = 0.2391\n",
            "t = 22, avg_loss = 0.2241\n",
            "t = 24, avg_loss = 0.3301\n",
            "Checking accuracy on train set\n",
            "Got 340 / 400 correct (85.00)\n",
            "acc = 0.850000\n",
            "Starting epoch 11 / 80\n",
            "t = 2, avg_loss = 0.4480\n",
            "t = 4, avg_loss = 0.2673\n",
            "t = 6, avg_loss = 0.2647\n",
            "t = 8, avg_loss = 0.1829\n",
            "t = 10, avg_loss = 0.2721\n",
            "t = 12, avg_loss = 0.1948\n",
            "t = 14, avg_loss = 0.2912\n",
            "t = 16, avg_loss = 0.1569\n",
            "t = 18, avg_loss = 0.3237\n",
            "t = 20, avg_loss = 0.2534\n",
            "t = 22, avg_loss = 0.1909\n",
            "t = 24, avg_loss = 0.2433\n",
            "Checking accuracy on train set\n",
            "Got 344 / 400 correct (86.00)\n",
            "acc = 0.860000\n",
            "Starting epoch 12 / 80\n",
            "t = 2, avg_loss = 0.3490\n",
            "t = 4, avg_loss = 0.2181\n",
            "t = 6, avg_loss = 0.2361\n",
            "t = 8, avg_loss = 0.2289\n",
            "t = 10, avg_loss = 0.1909\n",
            "t = 12, avg_loss = 0.2022\n",
            "t = 14, avg_loss = 0.1713\n",
            "t = 16, avg_loss = 0.2694\n",
            "t = 18, avg_loss = 0.2721\n",
            "t = 20, avg_loss = 0.2009\n",
            "t = 22, avg_loss = 0.3211\n",
            "t = 24, avg_loss = 0.2461\n",
            "Checking accuracy on train set\n",
            "Got 343 / 400 correct (85.75)\n",
            "acc = 0.857500\n",
            "Starting epoch 13 / 80\n",
            "t = 2, avg_loss = 0.3562\n",
            "t = 4, avg_loss = 0.1615\n",
            "t = 6, avg_loss = 0.1264\n",
            "t = 8, avg_loss = 0.2075\n",
            "t = 10, avg_loss = 0.1955\n",
            "t = 12, avg_loss = 0.1999\n",
            "t = 14, avg_loss = 0.1852\n",
            "t = 16, avg_loss = 0.2952\n",
            "t = 18, avg_loss = 0.2344\n",
            "t = 20, avg_loss = 0.3376\n",
            "t = 22, avg_loss = 0.2337\n",
            "t = 24, avg_loss = 0.2030\n",
            "Checking accuracy on train set\n",
            "Got 342 / 400 correct (85.50)\n",
            "acc = 0.855000\n",
            "Starting epoch 14 / 80\n",
            "t = 2, avg_loss = 0.4159\n",
            "t = 4, avg_loss = 0.2043\n",
            "t = 6, avg_loss = 0.2206\n",
            "t = 8, avg_loss = 0.2197\n",
            "t = 10, avg_loss = 0.2227\n",
            "t = 12, avg_loss = 0.1635\n",
            "t = 14, avg_loss = 0.1528\n",
            "t = 16, avg_loss = 0.2348\n",
            "t = 18, avg_loss = 0.1847\n",
            "t = 20, avg_loss = 0.1961\n",
            "t = 22, avg_loss = 0.2519\n",
            "t = 24, avg_loss = 0.2207\n",
            "Checking accuracy on train set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 15 / 80\n",
            "t = 2, avg_loss = 0.3225\n",
            "t = 4, avg_loss = 0.2117\n",
            "t = 6, avg_loss = 0.2317\n",
            "t = 8, avg_loss = 0.1667\n",
            "t = 10, avg_loss = 0.2251\n",
            "t = 12, avg_loss = 0.2482\n",
            "t = 14, avg_loss = 0.1974\n",
            "t = 16, avg_loss = 0.1554\n",
            "t = 18, avg_loss = 0.3034\n",
            "t = 20, avg_loss = 0.1980\n",
            "t = 22, avg_loss = 0.2100\n",
            "t = 24, avg_loss = 0.2431\n",
            "Checking accuracy on train set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 16 / 80\n",
            "t = 2, avg_loss = 0.3231\n",
            "t = 4, avg_loss = 0.1580\n",
            "t = 6, avg_loss = 0.2145\n",
            "t = 8, avg_loss = 0.2955\n",
            "t = 10, avg_loss = 0.1635\n",
            "t = 12, avg_loss = 0.2136\n",
            "t = 14, avg_loss = 0.1971\n",
            "t = 16, avg_loss = 0.1459\n",
            "t = 18, avg_loss = 0.1732\n",
            "t = 20, avg_loss = 0.2221\n",
            "t = 22, avg_loss = 0.2150\n",
            "t = 24, avg_loss = 0.2230\n",
            "Checking accuracy on train set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 17 / 80\n",
            "t = 2, avg_loss = 0.2888\n",
            "t = 4, avg_loss = 0.1309\n",
            "t = 6, avg_loss = 0.2466\n",
            "t = 8, avg_loss = 0.1770\n",
            "t = 10, avg_loss = 0.2173\n",
            "t = 12, avg_loss = 0.1460\n",
            "t = 14, avg_loss = 0.2237\n",
            "t = 16, avg_loss = 0.2035\n",
            "t = 18, avg_loss = 0.2042\n",
            "t = 20, avg_loss = 0.2337\n",
            "t = 22, avg_loss = 0.2103\n",
            "t = 24, avg_loss = 0.2156\n",
            "Checking accuracy on train set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 18 / 80\n",
            "t = 2, avg_loss = 0.2365\n",
            "t = 4, avg_loss = 0.2266\n",
            "t = 6, avg_loss = 0.2333\n",
            "t = 8, avg_loss = 0.1859\n",
            "t = 10, avg_loss = 0.2573\n",
            "t = 12, avg_loss = 0.1822\n",
            "t = 14, avg_loss = 0.2279\n",
            "t = 16, avg_loss = 0.2288\n",
            "t = 18, avg_loss = 0.1657\n",
            "t = 20, avg_loss = 0.1710\n",
            "t = 22, avg_loss = 0.1946\n",
            "t = 24, avg_loss = 0.1703\n",
            "Checking accuracy on train set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 19 / 80\n",
            "t = 2, avg_loss = 0.2657\n",
            "t = 4, avg_loss = 0.2228\n",
            "t = 6, avg_loss = 0.1847\n",
            "t = 8, avg_loss = 0.1867\n",
            "t = 10, avg_loss = 0.2232\n",
            "t = 12, avg_loss = 0.1974\n",
            "t = 14, avg_loss = 0.2153\n",
            "t = 16, avg_loss = 0.1971\n",
            "t = 18, avg_loss = 0.2165\n",
            "t = 20, avg_loss = 0.2435\n",
            "t = 22, avg_loss = 0.2101\n",
            "t = 24, avg_loss = 0.1749\n",
            "Checking accuracy on train set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 20 / 80\n",
            "t = 2, avg_loss = 0.2455\n",
            "t = 4, avg_loss = 0.1753\n",
            "t = 6, avg_loss = 0.1814\n",
            "t = 8, avg_loss = 0.3317\n",
            "t = 10, avg_loss = 0.2470\n",
            "t = 12, avg_loss = 0.2655\n",
            "t = 14, avg_loss = 0.2076\n",
            "t = 16, avg_loss = 0.1892\n",
            "t = 18, avg_loss = 0.2459\n",
            "t = 20, avg_loss = 0.2494\n",
            "t = 22, avg_loss = 0.1801\n",
            "t = 24, avg_loss = 0.1411\n",
            "Checking accuracy on train set\n",
            "Got 339 / 400 correct (84.75)\n",
            "acc = 0.847500\n",
            "Starting epoch 21 / 80\n",
            "t = 2, avg_loss = 0.2728\n",
            "t = 4, avg_loss = 0.1406\n",
            "t = 6, avg_loss = 0.2090\n",
            "t = 8, avg_loss = 0.2391\n",
            "t = 10, avg_loss = 0.1585\n",
            "t = 12, avg_loss = 0.1397\n",
            "t = 14, avg_loss = 0.1870\n",
            "t = 16, avg_loss = 0.1910\n",
            "t = 18, avg_loss = 0.1563\n",
            "t = 20, avg_loss = 0.1728\n",
            "t = 22, avg_loss = 0.1943\n",
            "t = 24, avg_loss = 0.2377\n",
            "Checking accuracy on train set\n",
            "Got 342 / 400 correct (85.50)\n",
            "acc = 0.855000\n",
            "Starting epoch 22 / 80\n",
            "t = 2, avg_loss = 0.2354\n",
            "t = 4, avg_loss = 0.1405\n",
            "t = 6, avg_loss = 0.1839\n",
            "t = 8, avg_loss = 0.1399\n",
            "t = 10, avg_loss = 0.2416\n",
            "t = 12, avg_loss = 0.2241\n",
            "t = 14, avg_loss = 0.1636\n",
            "t = 16, avg_loss = 0.1406\n",
            "t = 18, avg_loss = 0.1752\n",
            "t = 20, avg_loss = 0.2273\n",
            "t = 22, avg_loss = 0.1836\n",
            "t = 24, avg_loss = 0.1924\n",
            "Checking accuracy on train set\n",
            "Got 342 / 400 correct (85.50)\n",
            "acc = 0.855000\n",
            "Starting epoch 23 / 80\n",
            "t = 2, avg_loss = 0.3009\n",
            "t = 4, avg_loss = 0.1292\n",
            "t = 6, avg_loss = 0.2386\n",
            "t = 8, avg_loss = 0.1791\n",
            "t = 10, avg_loss = 0.1437\n",
            "t = 12, avg_loss = 0.1961\n",
            "t = 14, avg_loss = 0.1714\n",
            "t = 16, avg_loss = 0.1456\n",
            "t = 18, avg_loss = 0.1587\n",
            "t = 20, avg_loss = 0.2841\n",
            "t = 22, avg_loss = 0.2305\n",
            "t = 24, avg_loss = 0.0826\n",
            "Checking accuracy on train set\n",
            "Got 346 / 400 correct (86.50)\n",
            "acc = 0.865000\n",
            "Starting epoch 24 / 80\n",
            "t = 2, avg_loss = 0.2049\n",
            "t = 4, avg_loss = 0.1368\n",
            "t = 6, avg_loss = 0.0730\n",
            "t = 8, avg_loss = 0.2207\n",
            "t = 10, avg_loss = 0.1497\n",
            "t = 12, avg_loss = 0.1590\n",
            "t = 14, avg_loss = 0.1283\n",
            "t = 16, avg_loss = 0.1925\n",
            "t = 18, avg_loss = 0.1429\n",
            "t = 20, avg_loss = 0.1848\n",
            "t = 22, avg_loss = 0.1221\n",
            "t = 24, avg_loss = 0.1816\n",
            "Checking accuracy on train set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 25 / 80\n",
            "t = 2, avg_loss = 0.2296\n",
            "t = 4, avg_loss = 0.1714\n",
            "t = 6, avg_loss = 0.1465\n",
            "t = 8, avg_loss = 0.1962\n",
            "t = 10, avg_loss = 0.1863\n",
            "t = 12, avg_loss = 0.2059\n",
            "t = 14, avg_loss = 0.1731\n",
            "t = 16, avg_loss = 0.1783\n",
            "t = 18, avg_loss = 0.1169\n",
            "t = 20, avg_loss = 0.0860\n",
            "t = 22, avg_loss = 0.1473\n",
            "t = 24, avg_loss = 0.1755\n",
            "Checking accuracy on train set\n",
            "Got 351 / 400 correct (87.75)\n",
            "acc = 0.877500\n",
            "Starting epoch 26 / 80\n",
            "t = 2, avg_loss = 0.1907\n",
            "t = 4, avg_loss = 0.1378\n",
            "t = 6, avg_loss = 0.1813\n",
            "t = 8, avg_loss = 0.1305\n",
            "t = 10, avg_loss = 0.1485\n",
            "t = 12, avg_loss = 0.1481\n",
            "t = 14, avg_loss = 0.1995\n",
            "t = 16, avg_loss = 0.1465\n",
            "t = 18, avg_loss = 0.1370\n",
            "t = 20, avg_loss = 0.1842\n",
            "t = 22, avg_loss = 0.1408\n",
            "t = 24, avg_loss = 0.1368\n",
            "Checking accuracy on train set\n",
            "Got 343 / 400 correct (85.75)\n",
            "acc = 0.857500\n",
            "Starting epoch 27 / 80\n",
            "t = 2, avg_loss = 0.3751\n",
            "t = 4, avg_loss = 0.1367\n",
            "t = 6, avg_loss = 0.1625\n",
            "t = 8, avg_loss = 0.1274\n",
            "t = 10, avg_loss = 0.1632\n",
            "t = 12, avg_loss = 0.1600\n",
            "t = 14, avg_loss = 0.2026\n",
            "t = 16, avg_loss = 0.0926\n",
            "t = 18, avg_loss = 0.1245\n",
            "t = 20, avg_loss = 0.1878\n",
            "t = 22, avg_loss = 0.1560\n",
            "t = 24, avg_loss = 0.1415\n",
            "Checking accuracy on train set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 28 / 80\n",
            "t = 2, avg_loss = 0.1718\n",
            "t = 4, avg_loss = 0.1260\n",
            "t = 6, avg_loss = 0.1282\n",
            "t = 8, avg_loss = 0.2104\n",
            "t = 10, avg_loss = 0.0802\n",
            "t = 12, avg_loss = 0.2018\n",
            "t = 14, avg_loss = 0.1239\n",
            "t = 16, avg_loss = 0.1494\n",
            "t = 18, avg_loss = 0.1843\n",
            "t = 20, avg_loss = 0.1537\n",
            "t = 22, avg_loss = 0.1429\n",
            "t = 24, avg_loss = 0.1336\n",
            "Checking accuracy on train set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 29 / 80\n",
            "t = 2, avg_loss = 0.1734\n",
            "t = 4, avg_loss = 0.1365\n",
            "t = 6, avg_loss = 0.1736\n",
            "t = 8, avg_loss = 0.1333\n",
            "t = 10, avg_loss = 0.1594\n",
            "t = 12, avg_loss = 0.1569\n",
            "t = 14, avg_loss = 0.1098\n",
            "t = 16, avg_loss = 0.1077\n",
            "t = 18, avg_loss = 0.1752\n",
            "t = 20, avg_loss = 0.1235\n",
            "t = 22, avg_loss = 0.1276\n",
            "t = 24, avg_loss = 0.2351\n",
            "Checking accuracy on train set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 30 / 80\n",
            "t = 2, avg_loss = 0.1628\n",
            "t = 4, avg_loss = 0.0903\n",
            "t = 6, avg_loss = 0.1331\n",
            "t = 8, avg_loss = 0.1213\n",
            "t = 10, avg_loss = 0.1159\n",
            "t = 12, avg_loss = 0.1231\n",
            "t = 14, avg_loss = 0.1866\n",
            "t = 16, avg_loss = 0.2076\n",
            "t = 18, avg_loss = 0.1342\n",
            "t = 20, avg_loss = 0.1100\n",
            "t = 22, avg_loss = 0.1167\n",
            "t = 24, avg_loss = 0.1652\n",
            "Checking accuracy on train set\n",
            "Got 345 / 400 correct (86.25)\n",
            "acc = 0.862500\n",
            "Starting epoch 31 / 80\n",
            "t = 2, avg_loss = 0.1675\n",
            "t = 4, avg_loss = 0.1356\n",
            "t = 6, avg_loss = 0.1320\n",
            "t = 8, avg_loss = 0.1498\n",
            "t = 10, avg_loss = 0.1956\n",
            "t = 12, avg_loss = 0.1567\n",
            "t = 14, avg_loss = 0.1698\n",
            "t = 16, avg_loss = 0.0835\n",
            "t = 18, avg_loss = 0.0766\n",
            "t = 20, avg_loss = 0.1717\n",
            "t = 22, avg_loss = 0.1356\n",
            "t = 24, avg_loss = 0.1640\n",
            "Checking accuracy on train set\n",
            "Got 346 / 400 correct (86.50)\n",
            "acc = 0.865000\n",
            "Starting epoch 32 / 80\n",
            "t = 2, avg_loss = 0.1875\n",
            "t = 4, avg_loss = 0.1417\n",
            "t = 6, avg_loss = 0.0954\n",
            "t = 8, avg_loss = 0.1270\n",
            "t = 10, avg_loss = 0.1071\n",
            "t = 12, avg_loss = 0.1765\n",
            "t = 14, avg_loss = 0.1148\n",
            "t = 16, avg_loss = 0.1488\n",
            "t = 18, avg_loss = 0.1005\n",
            "t = 20, avg_loss = 0.1866\n",
            "t = 22, avg_loss = 0.1260\n",
            "t = 24, avg_loss = 0.1014\n",
            "Checking accuracy on train set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 33 / 80\n",
            "t = 2, avg_loss = 0.2714\n",
            "t = 4, avg_loss = 0.1401\n",
            "t = 6, avg_loss = 0.1085\n",
            "t = 8, avg_loss = 0.1561\n",
            "t = 10, avg_loss = 0.0998\n",
            "t = 12, avg_loss = 0.1414\n",
            "t = 14, avg_loss = 0.1934\n",
            "t = 16, avg_loss = 0.1222\n",
            "t = 18, avg_loss = 0.0792\n",
            "t = 20, avg_loss = 0.1134\n",
            "t = 22, avg_loss = 0.1016\n",
            "t = 24, avg_loss = 0.1701\n",
            "Checking accuracy on train set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 34 / 80\n",
            "t = 2, avg_loss = 0.1225\n",
            "t = 4, avg_loss = 0.1606\n",
            "t = 6, avg_loss = 0.1194\n",
            "t = 8, avg_loss = 0.1030\n",
            "t = 10, avg_loss = 0.1221\n",
            "t = 12, avg_loss = 0.0966\n",
            "t = 14, avg_loss = 0.1072\n",
            "t = 16, avg_loss = 0.1404\n",
            "t = 18, avg_loss = 0.1084\n",
            "t = 20, avg_loss = 0.1366\n",
            "t = 22, avg_loss = 0.0680\n",
            "t = 24, avg_loss = 0.1549\n",
            "Checking accuracy on train set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 35 / 80\n",
            "t = 2, avg_loss = 0.1788\n",
            "t = 4, avg_loss = 0.0920\n",
            "t = 6, avg_loss = 0.1300\n",
            "t = 8, avg_loss = 0.0966\n",
            "t = 10, avg_loss = 0.1321\n",
            "t = 12, avg_loss = 0.1497\n",
            "t = 14, avg_loss = 0.0743\n",
            "t = 16, avg_loss = 0.1320\n",
            "t = 18, avg_loss = 0.1371\n",
            "t = 20, avg_loss = 0.1164\n",
            "t = 22, avg_loss = 0.1490\n",
            "t = 24, avg_loss = 0.0709\n",
            "Checking accuracy on train set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 36 / 80\n",
            "t = 2, avg_loss = 0.1887\n",
            "t = 4, avg_loss = 0.0859\n",
            "t = 6, avg_loss = 0.1125\n",
            "t = 8, avg_loss = 0.0948\n",
            "t = 10, avg_loss = 0.1492\n",
            "t = 12, avg_loss = 0.1754\n",
            "t = 14, avg_loss = 0.1022\n",
            "t = 16, avg_loss = 0.0952\n",
            "t = 18, avg_loss = 0.0984\n",
            "t = 20, avg_loss = 0.1187\n",
            "t = 22, avg_loss = 0.1182\n",
            "t = 24, avg_loss = 0.1009\n",
            "Checking accuracy on train set\n",
            "Got 344 / 400 correct (86.00)\n",
            "acc = 0.860000\n",
            "Starting epoch 37 / 80\n",
            "t = 2, avg_loss = 0.2392\n",
            "t = 4, avg_loss = 0.0526\n",
            "t = 6, avg_loss = 0.1252\n",
            "t = 8, avg_loss = 0.1445\n",
            "t = 10, avg_loss = 0.0683\n",
            "t = 12, avg_loss = 0.0863\n",
            "t = 14, avg_loss = 0.1267\n",
            "t = 16, avg_loss = 0.1674\n",
            "t = 18, avg_loss = 0.0818\n",
            "t = 20, avg_loss = 0.1197\n",
            "t = 22, avg_loss = 0.1502\n",
            "t = 24, avg_loss = 0.1152\n",
            "Checking accuracy on train set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 38 / 80\n",
            "t = 2, avg_loss = 0.1339\n",
            "t = 4, avg_loss = 0.1035\n",
            "t = 6, avg_loss = 0.0749\n",
            "t = 8, avg_loss = 0.1193\n",
            "t = 10, avg_loss = 0.1146\n",
            "t = 12, avg_loss = 0.1176\n",
            "t = 14, avg_loss = 0.1363\n",
            "t = 16, avg_loss = 0.1278\n",
            "t = 18, avg_loss = 0.0719\n",
            "t = 20, avg_loss = 0.1462\n",
            "t = 22, avg_loss = 0.1694\n",
            "t = 24, avg_loss = 0.0989\n",
            "Checking accuracy on train set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 39 / 80\n",
            "t = 2, avg_loss = 0.1513\n",
            "t = 4, avg_loss = 0.1263\n",
            "t = 6, avg_loss = 0.0908\n",
            "t = 8, avg_loss = 0.1230\n",
            "t = 10, avg_loss = 0.1346\n",
            "t = 12, avg_loss = 0.1282\n",
            "t = 14, avg_loss = 0.1169\n",
            "t = 16, avg_loss = 0.1708\n",
            "t = 18, avg_loss = 0.0952\n",
            "t = 20, avg_loss = 0.1334\n",
            "t = 22, avg_loss = 0.1175\n",
            "t = 24, avg_loss = 0.0981\n",
            "Checking accuracy on train set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 40 / 80\n",
            "t = 2, avg_loss = 0.2241\n",
            "t = 4, avg_loss = 0.0853\n",
            "t = 6, avg_loss = 0.0961\n",
            "t = 8, avg_loss = 0.1564\n",
            "t = 10, avg_loss = 0.1127\n",
            "t = 12, avg_loss = 0.1243\n",
            "t = 14, avg_loss = 0.1367\n",
            "t = 16, avg_loss = 0.1309\n",
            "t = 18, avg_loss = 0.1166\n",
            "t = 20, avg_loss = 0.0977\n",
            "t = 22, avg_loss = 0.0974\n",
            "t = 24, avg_loss = 0.1591\n",
            "Checking accuracy on train set\n",
            "Got 351 / 400 correct (87.75)\n",
            "acc = 0.877500\n",
            "Starting epoch 41 / 80\n",
            "t = 2, avg_loss = 0.1439\n",
            "t = 4, avg_loss = 0.1485\n",
            "t = 6, avg_loss = 0.1472\n",
            "t = 8, avg_loss = 0.0665\n",
            "t = 10, avg_loss = 0.0933\n",
            "t = 12, avg_loss = 0.0683\n",
            "t = 14, avg_loss = 0.1073\n",
            "t = 16, avg_loss = 0.1040\n",
            "t = 18, avg_loss = 0.1279\n",
            "t = 20, avg_loss = 0.1065\n",
            "t = 22, avg_loss = 0.1485\n",
            "t = 24, avg_loss = 0.0898\n",
            "Checking accuracy on train set\n",
            "Got 342 / 400 correct (85.50)\n",
            "acc = 0.855000\n",
            "Starting epoch 42 / 80\n",
            "t = 2, avg_loss = 0.1481\n",
            "t = 4, avg_loss = 0.0941\n",
            "t = 6, avg_loss = 0.1229\n",
            "t = 8, avg_loss = 0.0916\n",
            "t = 10, avg_loss = 0.1193\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-1e6140a9dd13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-49ca391291dc>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, loss_fn, optimizer, num_epochs, starting_from_epoch)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mx_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0my_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-f5436cf91a2f>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     23\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"malignant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"malignant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test_set'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   1856\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1858\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreducing_gap\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresample\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mNEAREST\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "US4sjopDuPdh",
        "colab_type": "code",
        "outputId": "feb16940-c194-4835-bb18-d18f81a549d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "check_accuracy(model_gpu, test_loader, datatype='test')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking accuracy on test set\n",
            "Got 180 / 201 correct (89.55)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8955223880597015"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMs_8t003ElH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDVWY9Ey3TOl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvoCj5uscUsz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_accurancy(acc_list):\n",
        "  plt.plot([i+1 for i in range((len(acc_list)))],acc_list)\n",
        "  print(\"Accurancy:\")\n",
        "  plt.show()\n",
        "\n",
        "def plot_loss_function(avg_loss_list):\n",
        "  plt.plot([print_every*batch_size*(i+1) for i in range((len(avg_loss_list)))],avg_loss_list)\n",
        "  print(\"Loss:\")\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-Co5KBw-Yy4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_accurancy(acc_list)\n",
        "plot_loss_function(avg_loss_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzuX5gLEeJfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def retry_from_backup():\n",
        "  model_gpu = model_base.type(gpu_dtype)\n",
        "  print(model_gpu)\n",
        "  loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) \n",
        "\n",
        "  checkpoint = torch.load(model_backup_path)\n",
        "  model_gpu.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  epoch = checkpoint['epoch']\n",
        "  loss = checkpoint['loss']\n",
        "  acc_list = checkpoint['acc_list']\n",
        "  #avg_loss_list = checkpoint['avg_loss_list']\n",
        "  print(\"starting from epoch: \" + str(epoch))\n",
        "  print(\"starting from loss: \" + str(loss))\n",
        "  print(acc_list)\n",
        "  \n",
        "  \n",
        "  train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=58, starting_from_epoch=epoch)\n",
        "  check_accuracy(model_gpu, valid_loader)\n",
        "\n",
        "  plot_accurancy(acc_list)\n",
        "  plot_loss_function(avg_loss_list)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--rQZKqOalaJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "015260ff-0657-4de3-f7cf-d8bf49b47168"
      },
      "source": [
        "retry_from_backup()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Kerv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (4): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (5): ReLU(inplace=True)\n",
            "  (6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (8): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (9): ReLU(inplace=True)\n",
            "  (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (12): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (13): ReLU(inplace=True)\n",
            "  (14): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (16): Dropout(p=0.5, inplace=False)\n",
            "  (17): Flatten()\n",
            "  (18): Linear(in_features=4608, out_features=64, bias=True)\n",
            "  (19): ReLU(inplace=True)\n",
            "  (20): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n",
            "starting from epoch: 40\n",
            "starting from loss: tensor(0.1123, device='cuda:0', requires_grad=True)\n",
            "[0.6075, 0.8175, 0.845, 0.845, 0.85, 0.8475, 0.86, 0.8525, 0.8425, 0.85, 0.86, 0.8575, 0.855, 0.87, 0.87, 0.8725, 0.8675, 0.87, 0.8675, 0.8475, 0.855, 0.855, 0.865, 0.87, 0.8775, 0.8575, 0.88, 0.8725, 0.89, 0.8625, 0.865, 0.875, 0.8725, 0.87, 0.875, 0.86, 0.875, 0.8675, 0.8725, 0.8775, 0.855]\n",
            "Starting epoch 1 / 58\n",
            "t = 5, avg_loss = 0.1743\n",
            "t = 10, avg_loss = 0.1733\n",
            "t = 15, avg_loss = 0.1272\n",
            "t = 20, avg_loss = 0.1452\n",
            "t = 25, avg_loss = 0.1350\n",
            "Checking accuracy on train set\n",
            "Got 373 / 400 correct (93.25)\n",
            "acc = 0.932500\n",
            "Starting epoch 2 / 58\n",
            "t = 5, avg_loss = 0.1684\n",
            "t = 10, avg_loss = 0.1023\n",
            "t = 15, avg_loss = 0.1042\n",
            "t = 20, avg_loss = 0.1073\n",
            "t = 25, avg_loss = 0.1515\n",
            "Checking accuracy on train set\n",
            "Got 366 / 400 correct (91.50)\n",
            "acc = 0.915000\n",
            "Starting epoch 3 / 58\n",
            "t = 5, avg_loss = 0.1378\n",
            "t = 10, avg_loss = 0.1164\n",
            "t = 15, avg_loss = 0.1279\n",
            "t = 20, avg_loss = 0.1134\n",
            "t = 25, avg_loss = 0.1131\n",
            "Checking accuracy on train set\n",
            "Got 373 / 400 correct (93.25)\n",
            "acc = 0.932500\n",
            "Starting epoch 4 / 58\n",
            "t = 5, avg_loss = 0.1135\n",
            "t = 10, avg_loss = 0.1409\n",
            "t = 15, avg_loss = 0.1655\n",
            "t = 20, avg_loss = 0.0986\n",
            "t = 25, avg_loss = 0.1675\n",
            "Checking accuracy on train set\n",
            "Got 368 / 400 correct (92.00)\n",
            "acc = 0.920000\n",
            "Starting epoch 5 / 58\n",
            "t = 5, avg_loss = 0.0977\n",
            "t = 10, avg_loss = 0.1220\n",
            "t = 15, avg_loss = 0.1470\n",
            "t = 20, avg_loss = 0.1130\n",
            "t = 25, avg_loss = 0.1117\n",
            "Checking accuracy on train set\n",
            "Got 368 / 400 correct (92.00)\n",
            "acc = 0.920000\n",
            "Starting epoch 6 / 58\n",
            "t = 5, avg_loss = 0.1006\n",
            "t = 10, avg_loss = 0.1364\n",
            "t = 15, avg_loss = 0.1028\n",
            "t = 20, avg_loss = 0.1179\n",
            "t = 25, avg_loss = 0.1339\n",
            "Checking accuracy on train set\n",
            "Got 364 / 400 correct (91.00)\n",
            "acc = 0.910000\n",
            "Starting epoch 7 / 58\n",
            "t = 5, avg_loss = 0.1023\n",
            "t = 10, avg_loss = 0.1149\n",
            "t = 15, avg_loss = 0.1296\n",
            "t = 20, avg_loss = 0.1208\n",
            "t = 25, avg_loss = 0.0887\n",
            "Checking accuracy on train set\n",
            "Got 368 / 400 correct (92.00)\n",
            "acc = 0.920000\n",
            "Starting epoch 8 / 58\n",
            "t = 5, avg_loss = 0.1089\n",
            "t = 10, avg_loss = 0.1062\n",
            "t = 15, avg_loss = 0.1148\n",
            "t = 20, avg_loss = 0.1090\n",
            "t = 25, avg_loss = 0.1132\n",
            "Checking accuracy on train set\n",
            "Got 364 / 400 correct (91.00)\n",
            "acc = 0.910000\n",
            "Starting epoch 9 / 58\n",
            "t = 5, avg_loss = 0.1033\n",
            "t = 10, avg_loss = 0.0992\n",
            "t = 15, avg_loss = 0.0885\n",
            "t = 20, avg_loss = 0.1203\n",
            "t = 25, avg_loss = 0.0863\n",
            "Checking accuracy on train set\n",
            "Got 366 / 400 correct (91.50)\n",
            "acc = 0.915000\n",
            "Starting epoch 10 / 58\n",
            "t = 5, avg_loss = 0.1003\n",
            "t = 10, avg_loss = 0.0938\n",
            "t = 15, avg_loss = 0.0980\n",
            "t = 20, avg_loss = 0.0873\n",
            "t = 25, avg_loss = 0.1147\n",
            "Checking accuracy on train set\n",
            "Got 362 / 400 correct (90.50)\n",
            "acc = 0.905000\n",
            "Starting epoch 11 / 58\n",
            "t = 5, avg_loss = 0.0716\n",
            "t = 10, avg_loss = 0.0829\n",
            "t = 15, avg_loss = 0.1337\n",
            "t = 20, avg_loss = 0.0845\n",
            "t = 25, avg_loss = 0.1197\n",
            "Checking accuracy on train set\n",
            "Got 364 / 400 correct (91.00)\n",
            "acc = 0.910000\n",
            "Starting epoch 12 / 58\n",
            "t = 5, avg_loss = 0.1005\n",
            "t = 10, avg_loss = 0.1093\n",
            "t = 15, avg_loss = 0.1279\n",
            "t = 20, avg_loss = 0.0970\n",
            "t = 25, avg_loss = 0.0869\n",
            "Checking accuracy on train set\n",
            "Got 362 / 400 correct (90.50)\n",
            "acc = 0.905000\n",
            "Starting epoch 13 / 58\n",
            "t = 5, avg_loss = 0.0877\n",
            "t = 10, avg_loss = 0.0915\n",
            "t = 15, avg_loss = 0.0931\n",
            "t = 20, avg_loss = 0.0723\n",
            "t = 25, avg_loss = 0.0953\n",
            "Checking accuracy on train set\n",
            "Got 372 / 400 correct (93.00)\n",
            "acc = 0.930000\n",
            "Starting epoch 14 / 58\n",
            "t = 5, avg_loss = 0.0791\n",
            "t = 10, avg_loss = 0.0713\n",
            "t = 15, avg_loss = 0.0945\n",
            "t = 20, avg_loss = 0.1102\n",
            "t = 25, avg_loss = 0.0865\n",
            "Checking accuracy on train set\n",
            "Got 364 / 400 correct (91.00)\n",
            "acc = 0.910000\n",
            "Starting epoch 15 / 58\n",
            "t = 5, avg_loss = 0.0879\n",
            "t = 10, avg_loss = 0.0602\n",
            "t = 15, avg_loss = 0.0956\n",
            "t = 20, avg_loss = 0.0695\n",
            "t = 25, avg_loss = 0.1095\n",
            "Checking accuracy on train set\n",
            "Got 363 / 400 correct (90.75)\n",
            "acc = 0.907500\n",
            "Starting epoch 16 / 58\n",
            "t = 5, avg_loss = 0.0899\n",
            "t = 10, avg_loss = 0.0822\n",
            "t = 15, avg_loss = 0.0889\n",
            "t = 20, avg_loss = 0.0887\n",
            "t = 25, avg_loss = 0.0656\n",
            "Checking accuracy on train set\n",
            "Got 366 / 400 correct (91.50)\n",
            "acc = 0.915000\n",
            "Starting epoch 17 / 58\n",
            "t = 5, avg_loss = 0.0691\n",
            "t = 10, avg_loss = 0.0794\n",
            "t = 15, avg_loss = 0.0998\n",
            "t = 20, avg_loss = 0.0799\n",
            "t = 25, avg_loss = 0.0709\n",
            "Checking accuracy on train set\n",
            "Got 366 / 400 correct (91.50)\n",
            "acc = 0.915000\n",
            "Starting epoch 18 / 58\n",
            "t = 5, avg_loss = 0.0686\n",
            "t = 10, avg_loss = 0.0702\n",
            "t = 15, avg_loss = 0.0800\n",
            "t = 20, avg_loss = 0.0686\n",
            "t = 25, avg_loss = 0.0814\n",
            "Checking accuracy on train set\n",
            "Got 366 / 400 correct (91.50)\n",
            "acc = 0.915000\n",
            "Starting epoch 19 / 58\n",
            "t = 5, avg_loss = 0.0722\n",
            "t = 10, avg_loss = 0.0595\n",
            "t = 15, avg_loss = 0.0662\n",
            "t = 20, avg_loss = 0.0583\n",
            "t = 25, avg_loss = 0.0627\n",
            "Checking accuracy on train set\n",
            "Got 363 / 400 correct (90.75)\n",
            "acc = 0.907500\n",
            "Starting epoch 20 / 58\n",
            "t = 5, avg_loss = 0.1042\n",
            "t = 10, avg_loss = 0.0738\n",
            "t = 15, avg_loss = 0.0651\n",
            "t = 20, avg_loss = 0.0655\n",
            "t = 25, avg_loss = 0.0858\n",
            "Checking accuracy on train set\n",
            "Got 366 / 400 correct (91.50)\n",
            "acc = 0.915000\n",
            "Starting epoch 21 / 58\n",
            "t = 5, avg_loss = 0.0615\n",
            "t = 10, avg_loss = 0.0539\n",
            "t = 15, avg_loss = 0.0679\n",
            "t = 20, avg_loss = 0.0718\n",
            "t = 25, avg_loss = 0.1054\n",
            "Checking accuracy on train set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 22 / 58\n",
            "t = 5, avg_loss = 0.0840\n",
            "t = 10, avg_loss = 0.0800\n",
            "t = 15, avg_loss = 0.0767\n",
            "t = 20, avg_loss = 0.0952\n",
            "t = 25, avg_loss = 0.0858\n",
            "Checking accuracy on train set\n",
            "Got 361 / 400 correct (90.25)\n",
            "acc = 0.902500\n",
            "Starting epoch 23 / 58\n",
            "t = 5, avg_loss = 0.0803\n",
            "t = 10, avg_loss = 0.0899\n",
            "t = 15, avg_loss = 0.0517\n",
            "t = 20, avg_loss = 0.0782\n",
            "t = 25, avg_loss = 0.0663\n",
            "Checking accuracy on train set\n",
            "Got 364 / 400 correct (91.00)\n",
            "acc = 0.910000\n",
            "Starting epoch 24 / 58\n",
            "t = 5, avg_loss = 0.0756\n",
            "t = 10, avg_loss = 0.0762\n",
            "t = 15, avg_loss = 0.0599\n",
            "t = 20, avg_loss = 0.0729\n",
            "t = 25, avg_loss = 0.0854\n",
            "Checking accuracy on train set\n",
            "Got 362 / 400 correct (90.50)\n",
            "acc = 0.905000\n",
            "Starting epoch 25 / 58\n",
            "t = 5, avg_loss = 0.0532\n",
            "t = 10, avg_loss = 0.0639\n",
            "t = 15, avg_loss = 0.0756\n",
            "t = 20, avg_loss = 0.0670\n",
            "t = 25, avg_loss = 0.0811\n",
            "Checking accuracy on train set\n",
            "Got 359 / 400 correct (89.75)\n",
            "acc = 0.897500\n",
            "Starting epoch 26 / 58\n",
            "t = 5, avg_loss = 0.0625\n",
            "t = 10, avg_loss = 0.0709\n",
            "t = 15, avg_loss = 0.0874\n",
            "t = 20, avg_loss = 0.0754\n",
            "t = 25, avg_loss = 0.0598\n",
            "Checking accuracy on train set\n",
            "Got 360 / 400 correct (90.00)\n",
            "acc = 0.900000\n",
            "Starting epoch 27 / 58\n",
            "t = 5, avg_loss = 0.0658\n",
            "t = 10, avg_loss = 0.0644\n",
            "t = 15, avg_loss = 0.0833\n",
            "t = 20, avg_loss = 0.0831\n",
            "t = 25, avg_loss = 0.0713\n",
            "Checking accuracy on train set\n",
            "Got 366 / 400 correct (91.50)\n",
            "acc = 0.915000\n",
            "Starting epoch 28 / 58\n",
            "t = 5, avg_loss = 0.0681\n",
            "t = 10, avg_loss = 0.0867\n",
            "t = 15, avg_loss = 0.0523\n",
            "t = 20, avg_loss = 0.0608\n",
            "t = 25, avg_loss = 0.0553\n",
            "Checking accuracy on train set\n",
            "Got 363 / 400 correct (90.75)\n",
            "acc = 0.907500\n",
            "Starting epoch 29 / 58\n",
            "t = 5, avg_loss = 0.0497\n",
            "t = 10, avg_loss = 0.0684\n",
            "t = 15, avg_loss = 0.0526\n",
            "t = 20, avg_loss = 0.0828\n",
            "t = 25, avg_loss = 0.0769\n",
            "Checking accuracy on train set\n",
            "Got 360 / 400 correct (90.00)\n",
            "acc = 0.900000\n",
            "Starting epoch 30 / 58\n",
            "t = 5, avg_loss = 0.0616\n",
            "t = 10, avg_loss = 0.0751\n",
            "t = 15, avg_loss = 0.0713\n",
            "t = 20, avg_loss = 0.0743\n",
            "t = 25, avg_loss = 0.0605\n",
            "Checking accuracy on train set\n",
            "Got 367 / 400 correct (91.75)\n",
            "acc = 0.917500\n",
            "Starting epoch 31 / 58\n",
            "t = 5, avg_loss = 0.0450\n",
            "t = 10, avg_loss = 0.0505\n",
            "t = 15, avg_loss = 0.0826\n",
            "t = 20, avg_loss = 0.0494\n",
            "t = 25, avg_loss = 0.0814\n",
            "Checking accuracy on train set\n",
            "Got 364 / 400 correct (91.00)\n",
            "acc = 0.910000\n",
            "Starting epoch 32 / 58\n",
            "t = 5, avg_loss = 0.0727\n",
            "t = 10, avg_loss = 0.0636\n",
            "t = 15, avg_loss = 0.0627\n",
            "t = 20, avg_loss = 0.0844\n",
            "t = 25, avg_loss = 0.0811\n",
            "Checking accuracy on train set\n",
            "Got 364 / 400 correct (91.00)\n",
            "acc = 0.910000\n",
            "Starting epoch 33 / 58\n",
            "t = 5, avg_loss = 0.0530\n",
            "t = 10, avg_loss = 0.0687\n",
            "t = 15, avg_loss = 0.0603\n",
            "t = 20, avg_loss = 0.0670\n",
            "t = 25, avg_loss = 0.0600\n",
            "Checking accuracy on train set\n",
            "Got 361 / 400 correct (90.25)\n",
            "acc = 0.902500\n",
            "Starting epoch 34 / 58\n",
            "t = 5, avg_loss = 0.0868\n",
            "t = 10, avg_loss = 0.0750\n",
            "t = 15, avg_loss = 0.0605\n",
            "t = 20, avg_loss = 0.0679\n",
            "t = 25, avg_loss = 0.0669\n",
            "Checking accuracy on train set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 35 / 58\n",
            "t = 5, avg_loss = 0.0958\n",
            "t = 10, avg_loss = 0.0772\n",
            "t = 15, avg_loss = 0.0641\n",
            "t = 20, avg_loss = 0.0779\n",
            "t = 25, avg_loss = 0.0743\n",
            "Checking accuracy on train set\n",
            "Got 364 / 400 correct (91.00)\n",
            "acc = 0.910000\n",
            "Starting epoch 36 / 58\n",
            "t = 5, avg_loss = 0.0579\n",
            "t = 10, avg_loss = 0.0908\n",
            "t = 15, avg_loss = 0.0652\n",
            "t = 20, avg_loss = 0.0643\n",
            "t = 25, avg_loss = 0.0813\n",
            "Checking accuracy on train set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 37 / 58\n",
            "t = 5, avg_loss = 0.0612\n",
            "t = 10, avg_loss = 0.0403\n",
            "t = 15, avg_loss = 0.0492\n",
            "t = 20, avg_loss = 0.0855\n",
            "t = 25, avg_loss = 0.0642\n",
            "Checking accuracy on train set\n",
            "Got 361 / 400 correct (90.25)\n",
            "acc = 0.902500\n",
            "Starting epoch 38 / 58\n",
            "t = 5, avg_loss = 0.0672\n",
            "t = 10, avg_loss = 0.0484\n",
            "t = 15, avg_loss = 0.0484\n",
            "t = 20, avg_loss = 0.0486\n",
            "t = 25, avg_loss = 0.0656\n",
            "Checking accuracy on train set\n",
            "Got 365 / 400 correct (91.25)\n",
            "acc = 0.912500\n",
            "Starting epoch 39 / 58\n",
            "t = 5, avg_loss = 0.0424\n",
            "t = 10, avg_loss = 0.0629\n",
            "t = 15, avg_loss = 0.0484\n",
            "t = 20, avg_loss = 0.0690\n",
            "t = 25, avg_loss = 0.0456\n",
            "Checking accuracy on train set\n",
            "Got 359 / 400 correct (89.75)\n",
            "acc = 0.897500\n",
            "Starting epoch 40 / 58\n",
            "t = 5, avg_loss = 0.0515\n",
            "t = 10, avg_loss = 0.0765\n",
            "t = 15, avg_loss = 0.0531\n",
            "t = 20, avg_loss = 0.0366\n",
            "t = 25, avg_loss = 0.0477\n",
            "Checking accuracy on train set\n",
            "Got 365 / 400 correct (91.25)\n",
            "acc = 0.912500\n",
            "Starting epoch 41 / 58\n",
            "t = 5, avg_loss = 0.0332\n",
            "t = 10, avg_loss = 0.0509\n",
            "t = 15, avg_loss = 0.0542\n",
            "t = 20, avg_loss = 0.0445\n",
            "t = 25, avg_loss = 0.0835\n",
            "Checking accuracy on train set\n",
            "Got 359 / 400 correct (89.75)\n",
            "acc = 0.897500\n",
            "Starting epoch 42 / 58\n",
            "t = 5, avg_loss = 0.0547\n",
            "t = 10, avg_loss = 0.0505\n",
            "t = 15, avg_loss = 0.0622\n",
            "t = 20, avg_loss = 0.0446\n",
            "t = 25, avg_loss = 0.0419\n",
            "Checking accuracy on train set\n",
            "Got 365 / 400 correct (91.25)\n",
            "acc = 0.912500\n",
            "Starting epoch 43 / 58\n",
            "t = 5, avg_loss = 0.0564\n",
            "t = 10, avg_loss = 0.0562\n",
            "t = 15, avg_loss = 0.0646\n",
            "t = 20, avg_loss = 0.0616\n",
            "t = 25, avg_loss = 0.0624\n",
            "Checking accuracy on train set\n",
            "Got 365 / 400 correct (91.25)\n",
            "acc = 0.912500\n",
            "Starting epoch 44 / 58\n",
            "t = 5, avg_loss = 0.0386\n",
            "t = 10, avg_loss = 0.0387\n",
            "t = 15, avg_loss = 0.0315\n",
            "t = 20, avg_loss = 0.0427\n",
            "t = 25, avg_loss = 0.0559\n",
            "Checking accuracy on train set\n",
            "Got 363 / 400 correct (90.75)\n",
            "acc = 0.907500\n",
            "Starting epoch 45 / 58\n",
            "t = 5, avg_loss = 0.0438\n",
            "t = 10, avg_loss = 0.0481\n",
            "t = 15, avg_loss = 0.0468\n",
            "t = 20, avg_loss = 0.0338\n",
            "t = 25, avg_loss = 0.0271\n",
            "Checking accuracy on train set\n",
            "Got 361 / 400 correct (90.25)\n",
            "acc = 0.902500\n",
            "Starting epoch 46 / 58\n",
            "t = 5, avg_loss = 0.0435\n",
            "t = 10, avg_loss = 0.0392\n",
            "t = 15, avg_loss = 0.0487\n",
            "t = 20, avg_loss = 0.0267\n",
            "t = 25, avg_loss = 0.0373\n",
            "Checking accuracy on train set\n",
            "Got 358 / 400 correct (89.50)\n",
            "acc = 0.895000\n",
            "Starting epoch 47 / 58\n",
            "t = 5, avg_loss = 0.0395\n",
            "t = 10, avg_loss = 0.0299\n",
            "t = 15, avg_loss = 0.0388\n",
            "t = 20, avg_loss = 0.0433\n",
            "t = 25, avg_loss = 0.0477\n",
            "Checking accuracy on train set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 48 / 58\n",
            "t = 5, avg_loss = 0.0456\n",
            "t = 10, avg_loss = 0.0348\n",
            "t = 15, avg_loss = 0.0341\n",
            "t = 20, avg_loss = 0.0356\n",
            "t = 25, avg_loss = 0.0428\n",
            "Checking accuracy on train set\n",
            "Got 361 / 400 correct (90.25)\n",
            "acc = 0.902500\n",
            "Starting epoch 49 / 58\n",
            "t = 5, avg_loss = 0.0266\n",
            "t = 10, avg_loss = 0.0269\n",
            "t = 15, avg_loss = 0.0523\n",
            "t = 20, avg_loss = 0.0389\n",
            "t = 25, avg_loss = 0.0351\n",
            "Checking accuracy on train set\n",
            "Got 359 / 400 correct (89.75)\n",
            "acc = 0.897500\n",
            "Starting epoch 50 / 58\n",
            "t = 5, avg_loss = 0.0426\n",
            "t = 10, avg_loss = 0.0460\n",
            "t = 15, avg_loss = 0.0384\n",
            "t = 20, avg_loss = 0.0454\n",
            "t = 25, avg_loss = 0.0309\n",
            "Checking accuracy on train set\n",
            "Got 362 / 400 correct (90.50)\n",
            "acc = 0.905000\n",
            "Starting epoch 51 / 58\n",
            "t = 5, avg_loss = 0.0378\n",
            "t = 10, avg_loss = 0.0227\n",
            "t = 15, avg_loss = 0.0475\n",
            "t = 20, avg_loss = 0.0707\n",
            "t = 25, avg_loss = 0.0717\n",
            "Checking accuracy on train set\n",
            "Got 360 / 400 correct (90.00)\n",
            "acc = 0.900000\n",
            "Starting epoch 52 / 58\n",
            "t = 5, avg_loss = 0.0494\n",
            "t = 10, avg_loss = 0.0698\n",
            "t = 15, avg_loss = 0.0510\n",
            "t = 20, avg_loss = 0.0819\n",
            "t = 25, avg_loss = 0.0604\n",
            "Checking accuracy on train set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 53 / 58\n",
            "t = 5, avg_loss = 0.0913\n",
            "t = 10, avg_loss = 0.0593\n",
            "t = 15, avg_loss = 0.0409\n",
            "t = 20, avg_loss = 0.0701\n",
            "t = 25, avg_loss = 0.0676\n",
            "Checking accuracy on train set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 54 / 58\n",
            "t = 5, avg_loss = 0.0639\n",
            "t = 10, avg_loss = 0.0544\n",
            "t = 15, avg_loss = 0.0550\n",
            "t = 20, avg_loss = 0.0332\n",
            "t = 25, avg_loss = 0.0613\n",
            "Checking accuracy on train set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 55 / 58\n",
            "t = 5, avg_loss = 0.0387\n",
            "t = 10, avg_loss = 0.0538\n",
            "t = 15, avg_loss = 0.0542\n",
            "t = 20, avg_loss = 0.0356\n",
            "t = 25, avg_loss = 0.0478\n",
            "Checking accuracy on train set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 56 / 58\n",
            "t = 5, avg_loss = 0.0477\n",
            "t = 10, avg_loss = 0.0538\n",
            "t = 15, avg_loss = 0.0478\n",
            "t = 20, avg_loss = 0.0526\n",
            "t = 25, avg_loss = 0.0387\n",
            "Checking accuracy on train set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 57 / 58\n",
            "t = 5, avg_loss = 0.0304\n",
            "t = 10, avg_loss = 0.0441\n",
            "t = 15, avg_loss = 0.0430\n",
            "t = 20, avg_loss = 0.0487\n",
            "t = 25, avg_loss = 0.0447\n",
            "Checking accuracy on train set\n",
            "Got 360 / 400 correct (90.00)\n",
            "acc = 0.900000\n",
            "Starting epoch 58 / 58\n",
            "t = 5, avg_loss = 0.0391\n",
            "t = 10, avg_loss = 0.0479\n",
            "t = 15, avg_loss = 0.0384\n",
            "t = 20, avg_loss = 0.0472\n",
            "t = 25, avg_loss = 0.0587\n",
            "Checking accuracy on train set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Checking accuracy on train set\n",
            "Got 356 / 400 correct (89.00)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-bc0ed074296d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mretry_from_backup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-53eeefbd7bb2>\u001b[0m in \u001b[0;36mretry_from_backup\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0mcheck_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m   \u001b[0mplot_accurancy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m   \u001b[0mplot_loss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_loss_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plot_accurancy' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqAon2NL_qG2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        },
        "outputId": "c34a8da9-5a41-4929-bbff-c74b70d3eb8c"
      },
      "source": [
        "plot_accurancy(acc_list)\n",
        "plot_loss_function(avg_loss_list)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accurancy:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaDJwxSI_66k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "08a50641-fcc5-42a9-aaf9-d6b880bfa32e"
      },
      "source": [
        "check_accuracy(model_gpu, test_loader, datatype='test')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking accuracy on test set\n",
            "Got 184 / 201 correct (91.54)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9154228855721394"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slmbrnE-v8f5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0h2h8bIt4qY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}