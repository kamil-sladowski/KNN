{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN_ascending_layers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNIcRfu1Nfj2EIz7KASld9d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamilo116/KNN/blob/master/KNN_ascending_layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7ReM7FU-xs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import sys\n",
        "from random import shuffle\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms as transforms\n",
        "import timeit\n",
        "\n",
        "np.random.seed(4) \n",
        "torch.manual_seed(4) \n",
        "torch.cuda.manual_seed(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYIMZ8QyYewD",
        "colab_type": "code",
        "outputId": "95230bc3-9517-4ad2-fcb5-092b7fd86435",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "! git clone https://github.com/wang-chen/kervolution.git \n",
        "\n",
        "sys.path.append(\"kervolution/\")\n",
        "from kervolution import Kerv2d\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'kervolution' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvbKg4VJXKY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LIMIT_IMAGES_NUM = 800\n",
        "train_test_split_size = 0.2\n",
        "image_resize = (100, 100)\n",
        "batch_size = 64\n",
        "num_workers = 0\n",
        "\n",
        "in_channels = 3\n",
        "out_channels_1 = 16\n",
        "out_channels_2 = 32\n",
        "out_channels_3 = 64\n",
        "out_channels_4 = 128\n",
        "\n",
        "kernel_size = 3\n",
        "padding_1 = 1\n",
        "num_epochs = 80\n",
        "\n",
        "learning_rate = 0.0001\n",
        "weight_decay = 0.1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMOHez_kHZD6",
        "colab_type": "code",
        "outputId": "f08b9443-a1eb-4e8a-a705-b4723daf828f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b8P1NdXfVdX",
        "colab_type": "code",
        "outputId": "6c5a1b49-c470-4070-d022-cf86dfde9d59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "MALIGNANT_DATASET = '/content/drive/My Drive/Colab_data/malignant/malignant/'\n",
        "BENIGN_DATASET = '/content/drive/My Drive/Colab_data/benign/benign/'\n",
        "DATA_FOLDER = '/content/drive/My Drive/Colab_data/'\n",
        "\n",
        "\n",
        "benign_file_list = sorted(os.listdir(BENIGN_DATASET))\n",
        "malignant_file_list = sorted(os.listdir(MALIGNANT_DATASET))\n",
        "shuffle(benign_file_list)\n",
        "shuffle(malignant_file_list)\n",
        "benign_file_list = benign_file_list[:LIMIT_IMAGES_NUM]\n",
        "malignant_file_list = malignant_file_list[:LIMIT_IMAGES_NUM]\n",
        "\n",
        "print(f\"Number of benign {len(benign_file_list)} images\")\n",
        "print(f\"Number of malignant {len(malignant_file_list)} images\")\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize(image_resize),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of benign 800 images\n",
            "Number of malignant 800 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGDQfal74BLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "benign_dict = {filename: 0 for filename in benign_file_list}\n",
        "malignant_dict = {filename: 1 for filename in malignant_file_list}\n",
        "img_class_dict = {**benign_dict , **malignant_dict}\n",
        "labeled_data = pd.Series(img_class_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvAAOqmVfVll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IsicDataset(Dataset):\n",
        "    def __init__(self, data_folder, labeled_data, \n",
        "                 transform=transforms.Compose([transforms.ToTensor()])):\n",
        "        self.labeled_data = labeled_data\n",
        "        self.transform = transform\n",
        "        self.data_folder = data_folder\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labeled_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        label = self.labeled_data[index]\n",
        "        if label == 0:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"benign\", \"benign\", index ))\n",
        "        else:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"malignant\", \"malignant\", index ))\n",
        "        image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "    @property\n",
        "    def labels(self):\n",
        "      return self.labeled_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSuYqjLAYrWA",
        "colab_type": "code",
        "outputId": "af0bbc56-0604-4e90-d828-92dfda413592",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        }
      },
      "source": [
        " \n",
        "dataset = IsicDataset(DATA_FOLDER, labeled_data, transform=data_transforms)\n",
        "print(dataset.labels)\n",
        "\n",
        "X_train, X_test = train_test_split(dataset.labels, test_size=train_test_split_size)\n",
        "print(\"number of training data: \",len(X_train))\n",
        "print(\"number of testing  data: \",len(X_test))\n",
        "\n",
        "train_sampler = SubsetRandomSampler(list(X_train.index))\n",
        "valid_sampler = SubsetRandomSampler(list(X_test.index))\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ISIC_0001421.jpeg    0\n",
            "ISIC_0000131.jpeg    0\n",
            "ISIC_0002884.jpeg    0\n",
            "ISIC_0000184.jpeg    0\n",
            "ISIC_0001310.jpeg    0\n",
            "                    ..\n",
            "ISIC_0011615.jpeg    1\n",
            "ISIC_0012990.jpeg    1\n",
            "ISIC_0011858.jpeg    1\n",
            "ISIC_0010242.jpeg    1\n",
            "ISIC_0015110.jpeg    1\n",
            "Length: 1600, dtype: int64\n",
            "number of training data:  1280\n",
            "number of testing  data:  320\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e8nFBR6Yug5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "def train(model, train_loader ,loss_fn, optimizer, num_epochs = 1):\n",
        "    total_loss =0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
        "        model.train()\n",
        "\n",
        "        for t, (x, y) in enumerate(train_loader):\n",
        "            x_var = Variable(x.type(gpu_dtype))\n",
        "            y_var = Variable(y.type(gpu_dtype).long())\n",
        "            scores = model(x_var)\n",
        "            loss = loss_fn(scores, y_var)\n",
        "            total_loss += loss.data\n",
        "            \n",
        "            if (t + 1) % print_every == 0:\n",
        "                avg_loss = total_loss/print_every\n",
        "                print('t = %d, avg_loss = %.4f' % (t + 1, avg_loss) )\n",
        "                avg_loss_list.append(avg_loss)\n",
        "                total_loss = 0\n",
        "                \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        acc = check_accuracy(model_gpu, valid_loader)\n",
        "        print('acc = %f' %(acc))\n",
        "            \n",
        "def check_accuracy(model, loader):\n",
        "    print('Checking accuracy on test set')   \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval() \n",
        "    for x, y in loader:\n",
        "        x_var = Variable(x.type(gpu_dtype))\n",
        "\n",
        "        scores = model(x_var)\n",
        "        _, preds = scores.data.cpu().max(1)\n",
        "        num_correct += (preds == y).sum()\n",
        "        num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    acc_list.append(acc)\n",
        "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "    return acc\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggvpMu36Yw2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.size()\n",
        "        return x.view(N, -1)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgmexhBRZAK6",
        "colab_type": "code",
        "outputId": "019b2cfe-73ee-423c-8ea0-b787fb462875",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "gpu_dtype = torch.cuda.FloatTensor\n",
        "\n",
        "print_every = 1\n",
        "\n",
        "\n",
        "'''\n",
        "Kerv2d\n",
        "kervolution with following options:\n",
        "kernel_type: [linear, polynomial, gaussian, etc.]\n",
        "default is convolution:\n",
        "          kernel_type --> linear,\n",
        "balance, power, gamma is valid only when the kernel_type is specified\n",
        "if learnable_kernel = True,  they just be the initial value of learable parameters\n",
        "if learnable_kernel = False, they are the value of kernel_type's parameter\n",
        "the parameter [power] cannot be learned due to integer limitation\n",
        "dilation (int or tuple, optional): Spacing between kernel\n",
        "elements. Default: 1\n",
        "groups (int, optional): Number of blocked connections from input\n",
        "channels to output channels. Default: 1\n",
        "bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n",
        "kernel_type (str), Default: 'linear'\n",
        "learnable_kernel (bool): Learnable kernel parameters.  Default: False \n",
        "balance: 0, 1\n",
        "power: 3, 4, 5\n",
        "gamma:\n",
        "'''\n",
        "\n",
        "\n",
        "model_base = nn.Sequential( \n",
        "                nn.Kerv2d(in_channels , out_channels_1, padding=padding_1, dilation=1, groups=1, bias=True, \n",
        "                          kernel_type='polynomial', kernel_size=kernel_size, learnable_kernel=True,\n",
        "                          kernel_regularizer=True, stride=1, balance=1, power=3, gamma=1\n",
        "                          ), \n",
        "                #nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_channels_1),\n",
        "                nn.Conv2d(out_channels_1 , out_channels_2, padding= padding_1, kernel_size=kernel_size, stride=1), \n",
        "                #nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_channels_2),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_2 , out_channels_3, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                #nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_channels_3),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_3 , out_channels_4, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                #nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_channels_4),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Dropout(0.5),\n",
        "                Flatten(),\n",
        "                nn.Linear(18432,64),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Linear(64,2)\n",
        "            )\n",
        "model_gpu = model_base.type(gpu_dtype)\n",
        "print(model_gpu)\n",
        "loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) \n",
        "\n",
        "\n",
        "train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs)\n",
        "check_accuracy(model_gpu, valid_loader)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Kerv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (4): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (7): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (10): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (11): Dropout(p=0.5, inplace=False)\n",
            "  (12): Flatten()\n",
            "  (13): Linear(in_features=18432, out_features=64, bias=True)\n",
            "  (14): ReLU(inplace=True)\n",
            "  (15): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n",
            "Starting epoch 1 / 80\n",
            "t = 1, avg_loss = 0.6939\n",
            "t = 2, avg_loss = 0.7727\n",
            "t = 3, avg_loss = 0.6340\n",
            "t = 4, avg_loss = 0.7314\n",
            "t = 5, avg_loss = 0.6996\n",
            "t = 6, avg_loss = 0.6100\n",
            "t = 7, avg_loss = 0.5828\n",
            "t = 8, avg_loss = 0.6801\n",
            "t = 9, avg_loss = 0.6006\n",
            "t = 10, avg_loss = 0.6055\n",
            "t = 11, avg_loss = 0.5887\n",
            "t = 12, avg_loss = 0.6640\n",
            "t = 13, avg_loss = 0.5067\n",
            "t = 14, avg_loss = 0.5904\n",
            "t = 15, avg_loss = 0.6370\n",
            "t = 16, avg_loss = 0.6032\n",
            "t = 17, avg_loss = 0.4922\n",
            "t = 18, avg_loss = 0.6740\n",
            "t = 19, avg_loss = 0.4092\n",
            "t = 20, avg_loss = 0.6781\n",
            "Checking accuracy on test set\n",
            "Got 163 / 320 correct (50.94)\n",
            "acc = 0.509375\n",
            "Starting epoch 2 / 80\n",
            "t = 1, avg_loss = 0.5197\n",
            "t = 2, avg_loss = 0.5481\n",
            "t = 3, avg_loss = 0.6113\n",
            "t = 4, avg_loss = 0.5153\n",
            "t = 5, avg_loss = 0.5151\n",
            "t = 6, avg_loss = 0.4787\n",
            "t = 7, avg_loss = 0.6286\n",
            "t = 8, avg_loss = 0.5579\n",
            "t = 9, avg_loss = 0.5033\n",
            "t = 10, avg_loss = 0.6817\n",
            "t = 11, avg_loss = 0.5175\n",
            "t = 12, avg_loss = 0.5413\n",
            "t = 13, avg_loss = 0.4915\n",
            "t = 14, avg_loss = 0.4979\n",
            "t = 15, avg_loss = 0.5283\n",
            "t = 16, avg_loss = 0.4745\n",
            "t = 17, avg_loss = 0.4988\n",
            "t = 18, avg_loss = 0.4554\n",
            "t = 19, avg_loss = 0.4188\n",
            "t = 20, avg_loss = 0.5271\n",
            "Checking accuracy on test set\n",
            "Got 241 / 320 correct (75.31)\n",
            "acc = 0.753125\n",
            "Starting epoch 3 / 80\n",
            "t = 1, avg_loss = 0.4392\n",
            "t = 2, avg_loss = 0.4623\n",
            "t = 3, avg_loss = 0.4699\n",
            "t = 4, avg_loss = 0.5111\n",
            "t = 5, avg_loss = 0.4445\n",
            "t = 6, avg_loss = 0.4942\n",
            "t = 7, avg_loss = 0.4565\n",
            "t = 8, avg_loss = 0.4789\n",
            "t = 9, avg_loss = 0.4515\n",
            "t = 10, avg_loss = 0.5251\n",
            "t = 11, avg_loss = 0.4640\n",
            "t = 12, avg_loss = 0.4387\n",
            "t = 13, avg_loss = 0.4646\n",
            "t = 14, avg_loss = 0.5262\n",
            "t = 15, avg_loss = 0.4712\n",
            "t = 16, avg_loss = 0.5101\n",
            "t = 17, avg_loss = 0.5179\n",
            "t = 18, avg_loss = 0.6670\n",
            "t = 19, avg_loss = 0.4831\n",
            "t = 20, avg_loss = 0.4021\n",
            "Checking accuracy on test set\n",
            "Got 252 / 320 correct (78.75)\n",
            "acc = 0.787500\n",
            "Starting epoch 4 / 80\n",
            "t = 1, avg_loss = 0.4817\n",
            "t = 2, avg_loss = 0.4128\n",
            "t = 3, avg_loss = 0.3820\n",
            "t = 4, avg_loss = 0.5628\n",
            "t = 5, avg_loss = 0.6377\n",
            "t = 6, avg_loss = 0.4317\n",
            "t = 7, avg_loss = 0.4277\n",
            "t = 8, avg_loss = 0.4841\n",
            "t = 9, avg_loss = 0.4979\n",
            "t = 10, avg_loss = 0.4360\n",
            "t = 11, avg_loss = 0.4818\n",
            "t = 12, avg_loss = 0.5716\n",
            "t = 13, avg_loss = 0.4149\n",
            "t = 14, avg_loss = 0.5162\n",
            "t = 15, avg_loss = 0.4460\n",
            "t = 16, avg_loss = 0.4949\n",
            "t = 17, avg_loss = 0.4658\n",
            "t = 18, avg_loss = 0.4011\n",
            "t = 19, avg_loss = 0.4493\n",
            "t = 20, avg_loss = 0.4068\n",
            "Checking accuracy on test set\n",
            "Got 251 / 320 correct (78.44)\n",
            "acc = 0.784375\n",
            "Starting epoch 5 / 80\n",
            "t = 1, avg_loss = 0.4159\n",
            "t = 2, avg_loss = 0.3059\n",
            "t = 3, avg_loss = 0.4203\n",
            "t = 4, avg_loss = 0.3758\n",
            "t = 5, avg_loss = 0.4916\n",
            "t = 6, avg_loss = 0.5276\n",
            "t = 7, avg_loss = 0.3948\n",
            "t = 8, avg_loss = 0.5223\n",
            "t = 9, avg_loss = 0.4012\n",
            "t = 10, avg_loss = 0.5065\n",
            "t = 11, avg_loss = 0.3619\n",
            "t = 12, avg_loss = 0.3957\n",
            "t = 13, avg_loss = 0.4422\n",
            "t = 14, avg_loss = 0.3924\n",
            "t = 15, avg_loss = 0.4061\n",
            "t = 16, avg_loss = 0.4293\n",
            "t = 17, avg_loss = 0.5724\n",
            "t = 18, avg_loss = 0.4875\n",
            "t = 19, avg_loss = 0.4433\n",
            "t = 20, avg_loss = 0.3551\n",
            "Checking accuracy on test set\n",
            "Got 252 / 320 correct (78.75)\n",
            "acc = 0.787500\n",
            "Starting epoch 6 / 80\n",
            "t = 1, avg_loss = 0.4750\n",
            "t = 2, avg_loss = 0.3552\n",
            "t = 3, avg_loss = 0.3864\n",
            "t = 4, avg_loss = 0.2832\n",
            "t = 5, avg_loss = 0.3224\n",
            "t = 6, avg_loss = 0.4163\n",
            "t = 7, avg_loss = 0.5344\n",
            "t = 8, avg_loss = 0.4183\n",
            "t = 9, avg_loss = 0.3970\n",
            "t = 10, avg_loss = 0.3170\n",
            "t = 11, avg_loss = 0.4390\n",
            "t = 12, avg_loss = 0.4465\n",
            "t = 13, avg_loss = 0.4180\n",
            "t = 14, avg_loss = 0.3884\n",
            "t = 15, avg_loss = 0.3375\n",
            "t = 16, avg_loss = 0.4750\n",
            "t = 17, avg_loss = 0.4253\n",
            "t = 18, avg_loss = 0.4554\n",
            "t = 19, avg_loss = 0.4082\n",
            "t = 20, avg_loss = 0.3640\n",
            "Checking accuracy on test set\n",
            "Got 262 / 320 correct (81.88)\n",
            "acc = 0.818750\n",
            "Starting epoch 7 / 80\n",
            "t = 1, avg_loss = 0.3321\n",
            "t = 2, avg_loss = 0.3927\n",
            "t = 3, avg_loss = 0.4601\n",
            "t = 4, avg_loss = 0.2796\n",
            "t = 5, avg_loss = 0.3902\n",
            "t = 6, avg_loss = 0.4595\n",
            "t = 7, avg_loss = 0.4944\n",
            "t = 8, avg_loss = 0.4235\n",
            "t = 9, avg_loss = 0.4445\n",
            "t = 10, avg_loss = 0.4107\n",
            "t = 11, avg_loss = 0.3734\n",
            "t = 12, avg_loss = 0.3593\n",
            "t = 13, avg_loss = 0.3821\n",
            "t = 14, avg_loss = 0.3639\n",
            "t = 15, avg_loss = 0.3684\n",
            "t = 16, avg_loss = 0.5220\n",
            "t = 17, avg_loss = 0.4644\n",
            "t = 18, avg_loss = 0.4861\n",
            "t = 19, avg_loss = 0.3700\n",
            "t = 20, avg_loss = 0.3252\n",
            "Checking accuracy on test set\n",
            "Got 256 / 320 correct (80.00)\n",
            "acc = 0.800000\n",
            "Starting epoch 8 / 80\n",
            "t = 1, avg_loss = 0.4731\n",
            "t = 2, avg_loss = 0.3570\n",
            "t = 3, avg_loss = 0.3849\n",
            "t = 4, avg_loss = 0.3680\n",
            "t = 5, avg_loss = 0.3539\n",
            "t = 6, avg_loss = 0.3952\n",
            "t = 7, avg_loss = 0.4033\n",
            "t = 8, avg_loss = 0.4513\n",
            "t = 9, avg_loss = 0.2962\n",
            "t = 10, avg_loss = 0.4405\n",
            "t = 11, avg_loss = 0.4380\n",
            "t = 12, avg_loss = 0.3620\n",
            "t = 13, avg_loss = 0.2887\n",
            "t = 14, avg_loss = 0.3386\n",
            "t = 15, avg_loss = 0.4251\n",
            "t = 16, avg_loss = 0.4415\n",
            "t = 17, avg_loss = 0.3404\n",
            "t = 18, avg_loss = 0.4129\n",
            "t = 19, avg_loss = 0.3527\n",
            "t = 20, avg_loss = 0.3526\n",
            "Checking accuracy on test set\n",
            "Got 250 / 320 correct (78.12)\n",
            "acc = 0.781250\n",
            "Starting epoch 9 / 80\n",
            "t = 1, avg_loss = 0.3750\n",
            "t = 2, avg_loss = 0.3753\n",
            "t = 3, avg_loss = 0.2996\n",
            "t = 4, avg_loss = 0.3020\n",
            "t = 5, avg_loss = 0.3315\n",
            "t = 6, avg_loss = 0.4044\n",
            "t = 7, avg_loss = 0.4513\n",
            "t = 8, avg_loss = 0.4000\n",
            "t = 9, avg_loss = 0.2958\n",
            "t = 10, avg_loss = 0.3260\n",
            "t = 11, avg_loss = 0.3844\n",
            "t = 12, avg_loss = 0.3647\n",
            "t = 13, avg_loss = 0.3842\n",
            "t = 14, avg_loss = 0.4569\n",
            "t = 15, avg_loss = 0.3478\n",
            "t = 16, avg_loss = 0.3166\n",
            "t = 17, avg_loss = 0.4524\n",
            "t = 18, avg_loss = 0.3916\n",
            "t = 19, avg_loss = 0.3874\n",
            "t = 20, avg_loss = 0.4718\n",
            "Checking accuracy on test set\n",
            "Got 261 / 320 correct (81.56)\n",
            "acc = 0.815625\n",
            "Starting epoch 10 / 80\n",
            "t = 1, avg_loss = 0.3010\n",
            "t = 2, avg_loss = 0.3043\n",
            "t = 3, avg_loss = 0.4129\n",
            "t = 4, avg_loss = 0.3174\n",
            "t = 5, avg_loss = 0.3781\n",
            "t = 6, avg_loss = 0.4911\n",
            "t = 7, avg_loss = 0.3151\n",
            "t = 8, avg_loss = 0.3644\n",
            "t = 9, avg_loss = 0.4376\n",
            "t = 10, avg_loss = 0.3242\n",
            "t = 11, avg_loss = 0.4283\n",
            "t = 12, avg_loss = 0.3556\n",
            "t = 13, avg_loss = 0.3944\n",
            "t = 14, avg_loss = 0.3724\n",
            "t = 15, avg_loss = 0.3521\n",
            "t = 16, avg_loss = 0.3710\n",
            "t = 17, avg_loss = 0.4867\n",
            "t = 18, avg_loss = 0.4094\n",
            "t = 19, avg_loss = 0.3585\n",
            "t = 20, avg_loss = 0.3812\n",
            "Checking accuracy on test set\n",
            "Got 268 / 320 correct (83.75)\n",
            "acc = 0.837500\n",
            "Starting epoch 11 / 80\n",
            "t = 1, avg_loss = 0.2955\n",
            "t = 2, avg_loss = 0.3677\n",
            "t = 3, avg_loss = 0.3563\n",
            "t = 4, avg_loss = 0.5340\n",
            "t = 5, avg_loss = 0.3189\n",
            "t = 6, avg_loss = 0.4469\n",
            "t = 7, avg_loss = 0.3365\n",
            "t = 8, avg_loss = 0.3667\n",
            "t = 9, avg_loss = 0.3855\n",
            "t = 10, avg_loss = 0.3600\n",
            "t = 11, avg_loss = 0.3022\n",
            "t = 12, avg_loss = 0.3003\n",
            "t = 13, avg_loss = 0.4113\n",
            "t = 14, avg_loss = 0.4342\n",
            "t = 15, avg_loss = 0.3607\n",
            "t = 16, avg_loss = 0.3194\n",
            "t = 17, avg_loss = 0.3914\n",
            "t = 18, avg_loss = 0.4424\n",
            "t = 19, avg_loss = 0.3326\n",
            "t = 20, avg_loss = 0.3266\n",
            "Checking accuracy on test set\n",
            "Got 259 / 320 correct (80.94)\n",
            "acc = 0.809375\n",
            "Starting epoch 12 / 80\n",
            "t = 1, avg_loss = 0.3568\n",
            "t = 2, avg_loss = 0.3540\n",
            "t = 3, avg_loss = 0.2954\n",
            "t = 4, avg_loss = 0.4249\n",
            "t = 5, avg_loss = 0.2947\n",
            "t = 6, avg_loss = 0.3361\n",
            "t = 7, avg_loss = 0.3686\n",
            "t = 8, avg_loss = 0.4180\n",
            "t = 9, avg_loss = 0.4013\n",
            "t = 10, avg_loss = 0.3696\n",
            "t = 11, avg_loss = 0.3376\n",
            "t = 12, avg_loss = 0.3251\n",
            "t = 13, avg_loss = 0.3233\n",
            "t = 14, avg_loss = 0.2818\n",
            "t = 15, avg_loss = 0.3592\n",
            "t = 16, avg_loss = 0.3433\n",
            "t = 17, avg_loss = 0.3424\n",
            "t = 18, avg_loss = 0.2993\n",
            "t = 19, avg_loss = 0.3533\n",
            "t = 20, avg_loss = 0.3955\n",
            "Checking accuracy on test set\n",
            "Got 266 / 320 correct (83.12)\n",
            "acc = 0.831250\n",
            "Starting epoch 13 / 80\n",
            "t = 1, avg_loss = 0.3332\n",
            "t = 2, avg_loss = 0.2827\n",
            "t = 3, avg_loss = 0.2838\n",
            "t = 4, avg_loss = 0.3066\n",
            "t = 5, avg_loss = 0.3666\n",
            "t = 6, avg_loss = 0.3716\n",
            "t = 7, avg_loss = 0.3511\n",
            "t = 8, avg_loss = 0.3466\n",
            "t = 9, avg_loss = 0.2168\n",
            "t = 10, avg_loss = 0.4540\n",
            "t = 11, avg_loss = 0.3741\n",
            "t = 12, avg_loss = 0.2899\n",
            "t = 13, avg_loss = 0.3821\n",
            "t = 14, avg_loss = 0.4333\n",
            "t = 15, avg_loss = 0.3737\n",
            "t = 16, avg_loss = 0.2589\n",
            "t = 17, avg_loss = 0.3834\n",
            "t = 18, avg_loss = 0.3066\n",
            "t = 19, avg_loss = 0.3125\n",
            "t = 20, avg_loss = 0.3528\n",
            "Checking accuracy on test set\n",
            "Got 263 / 320 correct (82.19)\n",
            "acc = 0.821875\n",
            "Starting epoch 14 / 80\n",
            "t = 1, avg_loss = 0.2658\n",
            "t = 2, avg_loss = 0.3404\n",
            "t = 3, avg_loss = 0.3113\n",
            "t = 4, avg_loss = 0.3487\n",
            "t = 5, avg_loss = 0.3309\n",
            "t = 6, avg_loss = 0.3698\n",
            "t = 7, avg_loss = 0.2903\n",
            "t = 8, avg_loss = 0.3529\n",
            "t = 9, avg_loss = 0.2971\n",
            "t = 10, avg_loss = 0.2870\n",
            "t = 11, avg_loss = 0.2960\n",
            "t = 12, avg_loss = 0.3198\n",
            "t = 13, avg_loss = 0.3685\n",
            "t = 14, avg_loss = 0.4979\n",
            "t = 15, avg_loss = 0.3233\n",
            "t = 16, avg_loss = 0.4164\n",
            "t = 17, avg_loss = 0.3434\n",
            "t = 18, avg_loss = 0.2503\n",
            "t = 19, avg_loss = 0.3196\n",
            "t = 20, avg_loss = 0.3218\n",
            "Checking accuracy on test set\n",
            "Got 268 / 320 correct (83.75)\n",
            "acc = 0.837500\n",
            "Starting epoch 15 / 80\n",
            "t = 1, avg_loss = 0.4615\n",
            "t = 2, avg_loss = 0.3236\n",
            "t = 3, avg_loss = 0.3046\n",
            "t = 4, avg_loss = 0.4094\n",
            "t = 5, avg_loss = 0.3097\n",
            "t = 6, avg_loss = 0.3469\n",
            "t = 7, avg_loss = 0.2337\n",
            "t = 8, avg_loss = 0.4590\n",
            "t = 9, avg_loss = 0.2634\n",
            "t = 10, avg_loss = 0.4403\n",
            "t = 11, avg_loss = 0.2461\n",
            "t = 12, avg_loss = 0.3558\n",
            "t = 13, avg_loss = 0.2807\n",
            "t = 14, avg_loss = 0.3218\n",
            "t = 15, avg_loss = 0.2699\n",
            "t = 16, avg_loss = 0.4337\n",
            "t = 17, avg_loss = 0.2604\n",
            "t = 18, avg_loss = 0.3837\n",
            "t = 19, avg_loss = 0.3170\n",
            "t = 20, avg_loss = 0.3602\n",
            "Checking accuracy on test set\n",
            "Got 274 / 320 correct (85.62)\n",
            "acc = 0.856250\n",
            "Starting epoch 16 / 80\n",
            "t = 1, avg_loss = 0.3997\n",
            "t = 2, avg_loss = 0.3290\n",
            "t = 3, avg_loss = 0.3781\n",
            "t = 4, avg_loss = 0.2837\n",
            "t = 5, avg_loss = 0.4277\n",
            "t = 6, avg_loss = 0.3264\n",
            "t = 7, avg_loss = 0.3830\n",
            "t = 8, avg_loss = 0.2592\n",
            "t = 9, avg_loss = 0.4304\n",
            "t = 10, avg_loss = 0.3138\n",
            "t = 11, avg_loss = 0.3831\n",
            "t = 12, avg_loss = 0.3406\n",
            "t = 13, avg_loss = 0.3144\n",
            "t = 14, avg_loss = 0.3678\n",
            "t = 15, avg_loss = 0.2913\n",
            "t = 16, avg_loss = 0.3149\n",
            "t = 17, avg_loss = 0.2528\n",
            "t = 18, avg_loss = 0.3007\n",
            "t = 19, avg_loss = 0.2746\n",
            "t = 20, avg_loss = 0.3373\n",
            "Checking accuracy on test set\n",
            "Got 272 / 320 correct (85.00)\n",
            "acc = 0.850000\n",
            "Starting epoch 17 / 80\n",
            "t = 1, avg_loss = 0.3058\n",
            "t = 2, avg_loss = 0.2464\n",
            "t = 3, avg_loss = 0.3293\n",
            "t = 4, avg_loss = 0.3630\n",
            "t = 5, avg_loss = 0.3066\n",
            "t = 6, avg_loss = 0.2811\n",
            "t = 7, avg_loss = 0.3237\n",
            "t = 8, avg_loss = 0.3259\n",
            "t = 9, avg_loss = 0.3027\n",
            "t = 10, avg_loss = 0.3111\n",
            "t = 11, avg_loss = 0.3826\n",
            "t = 12, avg_loss = 0.3914\n",
            "t = 13, avg_loss = 0.3344\n",
            "t = 14, avg_loss = 0.4041\n",
            "t = 15, avg_loss = 0.3533\n",
            "t = 16, avg_loss = 0.2530\n",
            "t = 17, avg_loss = 0.3577\n",
            "t = 18, avg_loss = 0.3948\n",
            "t = 19, avg_loss = 0.2789\n",
            "t = 20, avg_loss = 0.3040\n",
            "Checking accuracy on test set\n",
            "Got 264 / 320 correct (82.50)\n",
            "acc = 0.825000\n",
            "Starting epoch 18 / 80\n",
            "t = 1, avg_loss = 0.2855\n",
            "t = 2, avg_loss = 0.3060\n",
            "t = 3, avg_loss = 0.2783\n",
            "t = 4, avg_loss = 0.3168\n",
            "t = 5, avg_loss = 0.2629\n",
            "t = 6, avg_loss = 0.3947\n",
            "t = 7, avg_loss = 0.3397\n",
            "t = 8, avg_loss = 0.4587\n",
            "t = 9, avg_loss = 0.2994\n",
            "t = 10, avg_loss = 0.3283\n",
            "t = 11, avg_loss = 0.2664\n",
            "t = 12, avg_loss = 0.3109\n",
            "t = 13, avg_loss = 0.2759\n",
            "t = 14, avg_loss = 0.3293\n",
            "t = 15, avg_loss = 0.2857\n",
            "t = 16, avg_loss = 0.3559\n",
            "t = 17, avg_loss = 0.2364\n",
            "t = 18, avg_loss = 0.3078\n",
            "t = 19, avg_loss = 0.2783\n",
            "t = 20, avg_loss = 0.2955\n",
            "Checking accuracy on test set\n",
            "Got 263 / 320 correct (82.19)\n",
            "acc = 0.821875\n",
            "Starting epoch 19 / 80\n",
            "t = 1, avg_loss = 0.3507\n",
            "t = 2, avg_loss = 0.2471\n",
            "t = 3, avg_loss = 0.2702\n",
            "t = 4, avg_loss = 0.3552\n",
            "t = 5, avg_loss = 0.3128\n",
            "t = 6, avg_loss = 0.2662\n",
            "t = 7, avg_loss = 0.3614\n",
            "t = 8, avg_loss = 0.2735\n",
            "t = 9, avg_loss = 0.2657\n",
            "t = 10, avg_loss = 0.3388\n",
            "t = 11, avg_loss = 0.3874\n",
            "t = 12, avg_loss = 0.2831\n",
            "t = 13, avg_loss = 0.2524\n",
            "t = 14, avg_loss = 0.3547\n",
            "t = 15, avg_loss = 0.3059\n",
            "t = 16, avg_loss = 0.2330\n",
            "t = 17, avg_loss = 0.3061\n",
            "t = 18, avg_loss = 0.4656\n",
            "t = 19, avg_loss = 0.3403\n",
            "t = 20, avg_loss = 0.3715\n",
            "Checking accuracy on test set\n",
            "Got 271 / 320 correct (84.69)\n",
            "acc = 0.846875\n",
            "Starting epoch 20 / 80\n",
            "t = 1, avg_loss = 0.2984\n",
            "t = 2, avg_loss = 0.2740\n",
            "t = 3, avg_loss = 0.3537\n",
            "t = 4, avg_loss = 0.2543\n",
            "t = 5, avg_loss = 0.3394\n",
            "t = 6, avg_loss = 0.3199\n",
            "t = 7, avg_loss = 0.3029\n",
            "t = 8, avg_loss = 0.2459\n",
            "t = 9, avg_loss = 0.3059\n",
            "t = 10, avg_loss = 0.4196\n",
            "t = 11, avg_loss = 0.2726\n",
            "t = 12, avg_loss = 0.3313\n",
            "t = 13, avg_loss = 0.2838\n",
            "t = 14, avg_loss = 0.3299\n",
            "t = 15, avg_loss = 0.3112\n",
            "t = 16, avg_loss = 0.3362\n",
            "t = 17, avg_loss = 0.3618\n",
            "t = 18, avg_loss = 0.3976\n",
            "t = 19, avg_loss = 0.3929\n",
            "t = 20, avg_loss = 0.2628\n",
            "Checking accuracy on test set\n",
            "Got 260 / 320 correct (81.25)\n",
            "acc = 0.812500\n",
            "Starting epoch 21 / 80\n",
            "t = 1, avg_loss = 0.4132\n",
            "t = 2, avg_loss = 0.2573\n",
            "t = 3, avg_loss = 0.3293\n",
            "t = 4, avg_loss = 0.3244\n",
            "t = 5, avg_loss = 0.3097\n",
            "t = 6, avg_loss = 0.3242\n",
            "t = 7, avg_loss = 0.2760\n",
            "t = 8, avg_loss = 0.3476\n",
            "t = 9, avg_loss = 0.3976\n",
            "t = 10, avg_loss = 0.2465\n",
            "t = 11, avg_loss = 0.3171\n",
            "t = 12, avg_loss = 0.3001\n",
            "t = 13, avg_loss = 0.1920\n",
            "t = 14, avg_loss = 0.2925\n",
            "t = 15, avg_loss = 0.4649\n",
            "t = 16, avg_loss = 0.2616\n",
            "t = 17, avg_loss = 0.3541\n",
            "t = 18, avg_loss = 0.2984\n",
            "t = 19, avg_loss = 0.3066\n",
            "t = 20, avg_loss = 0.2813\n",
            "Checking accuracy on test set\n",
            "Got 270 / 320 correct (84.38)\n",
            "acc = 0.843750\n",
            "Starting epoch 22 / 80\n",
            "t = 1, avg_loss = 0.3865\n",
            "t = 2, avg_loss = 0.3784\n",
            "t = 3, avg_loss = 0.3733\n",
            "t = 4, avg_loss = 0.3219\n",
            "t = 5, avg_loss = 0.3255\n",
            "t = 6, avg_loss = 0.2486\n",
            "t = 7, avg_loss = 0.2477\n",
            "t = 8, avg_loss = 0.3185\n",
            "t = 9, avg_loss = 0.3140\n",
            "t = 10, avg_loss = 0.3410\n",
            "t = 11, avg_loss = 0.2476\n",
            "t = 12, avg_loss = 0.3006\n",
            "t = 13, avg_loss = 0.2647\n",
            "t = 14, avg_loss = 0.3756\n",
            "t = 15, avg_loss = 0.4237\n",
            "t = 16, avg_loss = 0.3737\n",
            "t = 17, avg_loss = 0.2897\n",
            "t = 18, avg_loss = 0.2513\n",
            "t = 19, avg_loss = 0.2055\n",
            "t = 20, avg_loss = 0.2360\n",
            "Checking accuracy on test set\n",
            "Got 271 / 320 correct (84.69)\n",
            "acc = 0.846875\n",
            "Starting epoch 23 / 80\n",
            "t = 1, avg_loss = 0.2654\n",
            "t = 2, avg_loss = 0.3471\n",
            "t = 3, avg_loss = 0.2483\n",
            "t = 4, avg_loss = 0.2771\n",
            "t = 5, avg_loss = 0.3424\n",
            "t = 6, avg_loss = 0.2642\n",
            "t = 7, avg_loss = 0.3115\n",
            "t = 8, avg_loss = 0.2841\n",
            "t = 9, avg_loss = 0.3643\n",
            "t = 10, avg_loss = 0.2935\n",
            "t = 11, avg_loss = 0.3002\n",
            "t = 12, avg_loss = 0.3070\n",
            "t = 13, avg_loss = 0.3382\n",
            "t = 14, avg_loss = 0.3725\n",
            "t = 15, avg_loss = 0.3232\n",
            "t = 16, avg_loss = 0.3368\n",
            "t = 17, avg_loss = 0.3192\n",
            "t = 18, avg_loss = 0.4202\n",
            "t = 19, avg_loss = 0.3364\n",
            "t = 20, avg_loss = 0.3231\n",
            "Checking accuracy on test set\n",
            "Got 268 / 320 correct (83.75)\n",
            "acc = 0.837500\n",
            "Starting epoch 24 / 80\n",
            "t = 1, avg_loss = 0.3737\n",
            "t = 2, avg_loss = 0.3714\n",
            "t = 3, avg_loss = 0.3437\n",
            "t = 4, avg_loss = 0.2342\n",
            "t = 5, avg_loss = 0.2698\n",
            "t = 6, avg_loss = 0.3723\n",
            "t = 7, avg_loss = 0.3794\n",
            "t = 8, avg_loss = 0.3131\n",
            "t = 9, avg_loss = 0.2449\n",
            "t = 10, avg_loss = 0.2659\n",
            "t = 11, avg_loss = 0.3385\n",
            "t = 12, avg_loss = 0.2478\n",
            "t = 13, avg_loss = 0.3430\n",
            "t = 14, avg_loss = 0.2143\n",
            "t = 15, avg_loss = 0.3110\n",
            "t = 16, avg_loss = 0.2627\n",
            "t = 17, avg_loss = 0.2812\n",
            "t = 18, avg_loss = 0.2283\n",
            "t = 19, avg_loss = 0.2506\n",
            "t = 20, avg_loss = 0.2402\n",
            "Checking accuracy on test set\n",
            "Got 264 / 320 correct (82.50)\n",
            "acc = 0.825000\n",
            "Starting epoch 25 / 80\n",
            "t = 1, avg_loss = 0.2936\n",
            "t = 2, avg_loss = 0.3154\n",
            "t = 3, avg_loss = 0.3353\n",
            "t = 4, avg_loss = 0.2517\n",
            "t = 5, avg_loss = 0.3476\n",
            "t = 6, avg_loss = 0.1975\n",
            "t = 7, avg_loss = 0.2215\n",
            "t = 8, avg_loss = 0.2058\n",
            "t = 9, avg_loss = 0.3837\n",
            "t = 10, avg_loss = 0.2861\n",
            "t = 11, avg_loss = 0.3681\n",
            "t = 12, avg_loss = 0.2295\n",
            "t = 13, avg_loss = 0.3234\n",
            "t = 14, avg_loss = 0.2531\n",
            "t = 15, avg_loss = 0.3529\n",
            "t = 16, avg_loss = 0.3849\n",
            "t = 17, avg_loss = 0.2801\n",
            "t = 18, avg_loss = 0.2060\n",
            "t = 19, avg_loss = 0.3189\n",
            "t = 20, avg_loss = 0.3096\n",
            "Checking accuracy on test set\n",
            "Got 277 / 320 correct (86.56)\n",
            "acc = 0.865625\n",
            "Starting epoch 26 / 80\n",
            "t = 1, avg_loss = 0.3224\n",
            "t = 2, avg_loss = 0.2645\n",
            "t = 3, avg_loss = 0.2874\n",
            "t = 4, avg_loss = 0.3045\n",
            "t = 5, avg_loss = 0.3005\n",
            "t = 6, avg_loss = 0.2475\n",
            "t = 7, avg_loss = 0.2999\n",
            "t = 8, avg_loss = 0.2440\n",
            "t = 9, avg_loss = 0.3422\n",
            "t = 10, avg_loss = 0.3100\n",
            "t = 11, avg_loss = 0.2875\n",
            "t = 12, avg_loss = 0.2673\n",
            "t = 13, avg_loss = 0.2107\n",
            "t = 14, avg_loss = 0.3102\n",
            "t = 15, avg_loss = 0.2295\n",
            "t = 16, avg_loss = 0.2817\n",
            "t = 17, avg_loss = 0.3790\n",
            "t = 18, avg_loss = 0.3161\n",
            "t = 19, avg_loss = 0.2113\n",
            "t = 20, avg_loss = 0.2627\n",
            "Checking accuracy on test set\n",
            "Got 271 / 320 correct (84.69)\n",
            "acc = 0.846875\n",
            "Starting epoch 27 / 80\n",
            "t = 1, avg_loss = 0.3628\n",
            "t = 2, avg_loss = 0.2254\n",
            "t = 3, avg_loss = 0.2171\n",
            "t = 4, avg_loss = 0.2619\n",
            "t = 5, avg_loss = 0.2617\n",
            "t = 6, avg_loss = 0.3077\n",
            "t = 7, avg_loss = 0.3987\n",
            "t = 8, avg_loss = 0.2885\n",
            "t = 9, avg_loss = 0.2577\n",
            "t = 10, avg_loss = 0.2230\n",
            "t = 11, avg_loss = 0.3465\n",
            "t = 12, avg_loss = 0.2623\n",
            "t = 13, avg_loss = 0.3546\n",
            "t = 14, avg_loss = 0.2763\n",
            "t = 15, avg_loss = 0.3593\n",
            "t = 16, avg_loss = 0.3663\n",
            "t = 17, avg_loss = 0.2855\n",
            "t = 18, avg_loss = 0.3304\n",
            "t = 19, avg_loss = 0.2585\n",
            "t = 20, avg_loss = 0.2570\n",
            "Checking accuracy on test set\n",
            "Got 269 / 320 correct (84.06)\n",
            "acc = 0.840625\n",
            "Starting epoch 28 / 80\n",
            "t = 1, avg_loss = 0.2632\n",
            "t = 2, avg_loss = 0.1886\n",
            "t = 3, avg_loss = 0.1833\n",
            "t = 4, avg_loss = 0.2894\n",
            "t = 5, avg_loss = 0.2292\n",
            "t = 6, avg_loss = 0.3222\n",
            "t = 7, avg_loss = 0.2091\n",
            "t = 8, avg_loss = 0.3424\n",
            "t = 9, avg_loss = 0.3355\n",
            "t = 10, avg_loss = 0.3871\n",
            "t = 11, avg_loss = 0.2785\n",
            "t = 12, avg_loss = 0.2734\n",
            "t = 13, avg_loss = 0.2505\n",
            "t = 14, avg_loss = 0.3346\n",
            "t = 15, avg_loss = 0.3279\n",
            "t = 16, avg_loss = 0.2942\n",
            "t = 17, avg_loss = 0.3019\n",
            "t = 18, avg_loss = 0.2925\n",
            "t = 19, avg_loss = 0.2697\n",
            "t = 20, avg_loss = 0.2789\n",
            "Checking accuracy on test set\n",
            "Got 275 / 320 correct (85.94)\n",
            "acc = 0.859375\n",
            "Starting epoch 29 / 80\n",
            "t = 1, avg_loss = 0.2800\n",
            "t = 2, avg_loss = 0.2055\n",
            "t = 3, avg_loss = 0.2823\n",
            "t = 4, avg_loss = 0.2492\n",
            "t = 5, avg_loss = 0.3182\n",
            "t = 6, avg_loss = 0.3080\n",
            "t = 7, avg_loss = 0.2242\n",
            "t = 8, avg_loss = 0.2701\n",
            "t = 9, avg_loss = 0.2366\n",
            "t = 10, avg_loss = 0.3544\n",
            "t = 11, avg_loss = 0.3051\n",
            "t = 12, avg_loss = 0.2395\n",
            "t = 13, avg_loss = 0.3553\n",
            "t = 14, avg_loss = 0.3269\n",
            "t = 15, avg_loss = 0.3191\n",
            "t = 16, avg_loss = 0.3055\n",
            "t = 17, avg_loss = 0.2768\n",
            "t = 18, avg_loss = 0.2302\n",
            "t = 19, avg_loss = 0.3044\n",
            "t = 20, avg_loss = 0.3139\n",
            "Checking accuracy on test set\n",
            "Got 271 / 320 correct (84.69)\n",
            "acc = 0.846875\n",
            "Starting epoch 30 / 80\n",
            "t = 1, avg_loss = 0.2971\n",
            "t = 2, avg_loss = 0.2747\n",
            "t = 3, avg_loss = 0.3163\n",
            "t = 4, avg_loss = 0.2521\n",
            "t = 5, avg_loss = 0.2751\n",
            "t = 6, avg_loss = 0.2383\n",
            "t = 7, avg_loss = 0.2269\n",
            "t = 8, avg_loss = 0.2878\n",
            "t = 9, avg_loss = 0.3118\n",
            "t = 10, avg_loss = 0.2695\n",
            "t = 11, avg_loss = 0.3671\n",
            "t = 12, avg_loss = 0.3567\n",
            "t = 13, avg_loss = 0.2532\n",
            "t = 14, avg_loss = 0.2925\n",
            "t = 15, avg_loss = 0.3429\n",
            "t = 16, avg_loss = 0.3330\n",
            "t = 17, avg_loss = 0.3830\n",
            "t = 18, avg_loss = 0.2953\n",
            "t = 19, avg_loss = 0.2890\n",
            "t = 20, avg_loss = 0.2637\n",
            "Checking accuracy on test set\n",
            "Got 269 / 320 correct (84.06)\n",
            "acc = 0.840625\n",
            "Starting epoch 31 / 80\n",
            "t = 1, avg_loss = 0.2631\n",
            "t = 2, avg_loss = 0.3019\n",
            "t = 3, avg_loss = 0.3371\n",
            "t = 4, avg_loss = 0.3423\n",
            "t = 5, avg_loss = 0.2692\n",
            "t = 6, avg_loss = 0.2766\n",
            "t = 7, avg_loss = 0.2322\n",
            "t = 8, avg_loss = 0.2595\n",
            "t = 9, avg_loss = 0.3896\n",
            "t = 10, avg_loss = 0.2650\n",
            "t = 11, avg_loss = 0.3059\n",
            "t = 12, avg_loss = 0.2639\n",
            "t = 13, avg_loss = 0.2849\n",
            "t = 14, avg_loss = 0.2900\n",
            "t = 15, avg_loss = 0.2486\n",
            "t = 16, avg_loss = 0.2625\n",
            "t = 17, avg_loss = 0.3186\n",
            "t = 18, avg_loss = 0.3107\n",
            "t = 19, avg_loss = 0.3441\n",
            "t = 20, avg_loss = 0.3198\n",
            "Checking accuracy on test set\n",
            "Got 267 / 320 correct (83.44)\n",
            "acc = 0.834375\n",
            "Starting epoch 32 / 80\n",
            "t = 1, avg_loss = 0.3349\n",
            "t = 2, avg_loss = 0.2284\n",
            "t = 3, avg_loss = 0.2249\n",
            "t = 4, avg_loss = 0.3308\n",
            "t = 5, avg_loss = 0.2627\n",
            "t = 6, avg_loss = 0.3479\n",
            "t = 7, avg_loss = 0.3386\n",
            "t = 8, avg_loss = 0.3212\n",
            "t = 9, avg_loss = 0.2309\n",
            "t = 10, avg_loss = 0.3162\n",
            "t = 11, avg_loss = 0.3365\n",
            "t = 12, avg_loss = 0.3035\n",
            "t = 13, avg_loss = 0.3084\n",
            "t = 14, avg_loss = 0.2304\n",
            "t = 15, avg_loss = 0.3459\n",
            "t = 16, avg_loss = 0.3473\n",
            "t = 17, avg_loss = 0.3003\n",
            "t = 18, avg_loss = 0.3007\n",
            "t = 19, avg_loss = 0.2970\n",
            "t = 20, avg_loss = 0.2590\n",
            "Checking accuracy on test set\n",
            "Got 267 / 320 correct (83.44)\n",
            "acc = 0.834375\n",
            "Starting epoch 33 / 80\n",
            "t = 1, avg_loss = 0.3169\n",
            "t = 2, avg_loss = 0.2868\n",
            "t = 3, avg_loss = 0.2336\n",
            "t = 4, avg_loss = 0.2495\n",
            "t = 5, avg_loss = 0.2460\n",
            "t = 6, avg_loss = 0.2854\n",
            "t = 7, avg_loss = 0.3364\n",
            "t = 8, avg_loss = 0.2449\n",
            "t = 9, avg_loss = 0.2807\n",
            "t = 10, avg_loss = 0.3079\n",
            "t = 11, avg_loss = 0.3792\n",
            "t = 12, avg_loss = 0.2914\n",
            "t = 13, avg_loss = 0.3357\n",
            "t = 14, avg_loss = 0.3641\n",
            "t = 15, avg_loss = 0.2935\n",
            "t = 16, avg_loss = 0.3068\n",
            "t = 17, avg_loss = 0.2514\n",
            "t = 18, avg_loss = 0.2739\n",
            "t = 19, avg_loss = 0.2037\n",
            "t = 20, avg_loss = 0.2538\n",
            "Checking accuracy on test set\n",
            "Got 260 / 320 correct (81.25)\n",
            "acc = 0.812500\n",
            "Starting epoch 34 / 80\n",
            "t = 1, avg_loss = 0.3533\n",
            "t = 2, avg_loss = 0.2158\n",
            "t = 3, avg_loss = 0.2506\n",
            "t = 4, avg_loss = 0.2045\n",
            "t = 5, avg_loss = 0.3133\n",
            "t = 6, avg_loss = 0.3302\n",
            "t = 7, avg_loss = 0.2390\n",
            "t = 8, avg_loss = 0.3100\n",
            "t = 9, avg_loss = 0.2372\n",
            "t = 10, avg_loss = 0.3439\n",
            "t = 11, avg_loss = 0.2959\n",
            "t = 12, avg_loss = 0.2999\n",
            "t = 13, avg_loss = 0.2649\n",
            "t = 14, avg_loss = 0.3190\n",
            "t = 15, avg_loss = 0.2780\n",
            "t = 16, avg_loss = 0.2242\n",
            "t = 17, avg_loss = 0.3064\n",
            "t = 18, avg_loss = 0.3089\n",
            "t = 19, avg_loss = 0.3008\n",
            "t = 20, avg_loss = 0.3148\n",
            "Checking accuracy on test set\n",
            "Got 256 / 320 correct (80.00)\n",
            "acc = 0.800000\n",
            "Starting epoch 35 / 80\n",
            "t = 1, avg_loss = 0.2896\n",
            "t = 2, avg_loss = 0.2319\n",
            "t = 3, avg_loss = 0.2327\n",
            "t = 4, avg_loss = 0.3521\n",
            "t = 5, avg_loss = 0.3038\n",
            "t = 6, avg_loss = 0.3381\n",
            "t = 7, avg_loss = 0.3703\n",
            "t = 8, avg_loss = 0.3000\n",
            "t = 9, avg_loss = 0.2860\n",
            "t = 10, avg_loss = 0.2556\n",
            "t = 11, avg_loss = 0.2858\n",
            "t = 12, avg_loss = 0.3297\n",
            "t = 13, avg_loss = 0.2649\n",
            "t = 14, avg_loss = 0.2502\n",
            "t = 15, avg_loss = 0.3621\n",
            "t = 16, avg_loss = 0.3030\n",
            "t = 17, avg_loss = 0.3175\n",
            "t = 18, avg_loss = 0.2198\n",
            "t = 19, avg_loss = 0.2576\n",
            "t = 20, avg_loss = 0.2803\n",
            "Checking accuracy on test set\n",
            "Got 271 / 320 correct (84.69)\n",
            "acc = 0.846875\n",
            "Starting epoch 36 / 80\n",
            "t = 1, avg_loss = 0.3136\n",
            "t = 2, avg_loss = 0.4550\n",
            "t = 3, avg_loss = 0.2847\n",
            "t = 4, avg_loss = 0.2755\n",
            "t = 5, avg_loss = 0.2648\n",
            "t = 6, avg_loss = 0.2284\n",
            "t = 7, avg_loss = 0.3075\n",
            "t = 8, avg_loss = 0.2014\n",
            "t = 9, avg_loss = 0.2105\n",
            "t = 10, avg_loss = 0.3176\n",
            "t = 11, avg_loss = 0.2571\n",
            "t = 12, avg_loss = 0.3150\n",
            "t = 13, avg_loss = 0.1915\n",
            "t = 14, avg_loss = 0.3127\n",
            "t = 15, avg_loss = 0.2847\n",
            "t = 16, avg_loss = 0.2713\n",
            "t = 17, avg_loss = 0.2678\n",
            "t = 18, avg_loss = 0.2176\n",
            "t = 19, avg_loss = 0.2825\n",
            "t = 20, avg_loss = 0.2335\n",
            "Checking accuracy on test set\n",
            "Got 275 / 320 correct (85.94)\n",
            "acc = 0.859375\n",
            "Starting epoch 37 / 80\n",
            "t = 1, avg_loss = 0.2453\n",
            "t = 2, avg_loss = 0.2895\n",
            "t = 3, avg_loss = 0.2258\n",
            "t = 4, avg_loss = 0.2792\n",
            "t = 5, avg_loss = 0.2838\n",
            "t = 6, avg_loss = 0.2359\n",
            "t = 7, avg_loss = 0.1604\n",
            "t = 8, avg_loss = 0.3281\n",
            "t = 9, avg_loss = 0.2209\n",
            "t = 10, avg_loss = 0.3265\n",
            "t = 11, avg_loss = 0.3504\n",
            "t = 12, avg_loss = 0.3447\n",
            "t = 13, avg_loss = 0.2243\n",
            "t = 14, avg_loss = 0.2076\n",
            "t = 15, avg_loss = 0.2656\n",
            "t = 16, avg_loss = 0.2452\n",
            "t = 17, avg_loss = 0.3789\n",
            "t = 18, avg_loss = 0.2656\n",
            "t = 19, avg_loss = 0.3691\n",
            "t = 20, avg_loss = 0.2905\n",
            "Checking accuracy on test set\n",
            "Got 274 / 320 correct (85.62)\n",
            "acc = 0.856250\n",
            "Starting epoch 38 / 80\n",
            "t = 1, avg_loss = 0.2432\n",
            "t = 2, avg_loss = 0.2272\n",
            "t = 3, avg_loss = 0.2591\n",
            "t = 4, avg_loss = 0.2656\n",
            "t = 5, avg_loss = 0.2616\n",
            "t = 6, avg_loss = 0.2059\n",
            "t = 7, avg_loss = 0.3217\n",
            "t = 8, avg_loss = 0.2585\n",
            "t = 9, avg_loss = 0.2537\n",
            "t = 10, avg_loss = 0.2797\n",
            "t = 11, avg_loss = 0.2832\n",
            "t = 12, avg_loss = 0.3765\n",
            "t = 13, avg_loss = 0.3693\n",
            "t = 14, avg_loss = 0.2240\n",
            "t = 15, avg_loss = 0.2939\n",
            "t = 16, avg_loss = 0.2290\n",
            "t = 17, avg_loss = 0.2170\n",
            "t = 18, avg_loss = 0.3267\n",
            "t = 19, avg_loss = 0.2934\n",
            "t = 20, avg_loss = 0.2587\n",
            "Checking accuracy on test set\n",
            "Got 275 / 320 correct (85.94)\n",
            "acc = 0.859375\n",
            "Starting epoch 39 / 80\n",
            "t = 1, avg_loss = 0.2120\n",
            "t = 2, avg_loss = 0.2085\n",
            "t = 3, avg_loss = 0.1689\n",
            "t = 4, avg_loss = 0.2707\n",
            "t = 5, avg_loss = 0.2861\n",
            "t = 6, avg_loss = 0.2703\n",
            "t = 7, avg_loss = 0.1877\n",
            "t = 8, avg_loss = 0.3320\n",
            "t = 9, avg_loss = 0.2531\n",
            "t = 10, avg_loss = 0.2113\n",
            "t = 11, avg_loss = 0.3416\n",
            "t = 12, avg_loss = 0.2493\n",
            "t = 13, avg_loss = 0.2537\n",
            "t = 14, avg_loss = 0.2940\n",
            "t = 15, avg_loss = 0.2547\n",
            "t = 16, avg_loss = 0.2794\n",
            "t = 17, avg_loss = 0.2793\n",
            "t = 18, avg_loss = 0.2083\n",
            "t = 19, avg_loss = 0.3631\n",
            "t = 20, avg_loss = 0.1854\n",
            "Checking accuracy on test set\n",
            "Got 276 / 320 correct (86.25)\n",
            "acc = 0.862500\n",
            "Starting epoch 40 / 80\n",
            "t = 1, avg_loss = 0.3179\n",
            "t = 2, avg_loss = 0.2074\n",
            "t = 3, avg_loss = 0.2339\n",
            "t = 4, avg_loss = 0.2863\n",
            "t = 5, avg_loss = 0.2375\n",
            "t = 6, avg_loss = 0.2477\n",
            "t = 7, avg_loss = 0.3698\n",
            "t = 8, avg_loss = 0.2238\n",
            "t = 9, avg_loss = 0.3470\n",
            "t = 10, avg_loss = 0.2561\n",
            "t = 11, avg_loss = 0.1877\n",
            "t = 12, avg_loss = 0.1772\n",
            "t = 13, avg_loss = 0.1606\n",
            "t = 14, avg_loss = 0.2393\n",
            "t = 15, avg_loss = 0.2537\n",
            "t = 16, avg_loss = 0.3272\n",
            "t = 17, avg_loss = 0.3379\n",
            "t = 18, avg_loss = 0.2978\n",
            "t = 19, avg_loss = 0.1951\n",
            "t = 20, avg_loss = 0.3279\n",
            "Checking accuracy on test set\n",
            "Got 275 / 320 correct (85.94)\n",
            "acc = 0.859375\n",
            "Starting epoch 41 / 80\n",
            "t = 1, avg_loss = 0.2920\n",
            "t = 2, avg_loss = 0.2330\n",
            "t = 3, avg_loss = 0.2555\n",
            "t = 4, avg_loss = 0.2970\n",
            "t = 5, avg_loss = 0.2263\n",
            "t = 6, avg_loss = 0.1932\n",
            "t = 7, avg_loss = 0.2552\n",
            "t = 8, avg_loss = 0.2846\n",
            "t = 9, avg_loss = 0.2769\n",
            "t = 10, avg_loss = 0.2953\n",
            "t = 11, avg_loss = 0.2431\n",
            "t = 12, avg_loss = 0.3439\n",
            "t = 13, avg_loss = 0.2589\n",
            "t = 14, avg_loss = 0.3189\n",
            "t = 15, avg_loss = 0.2769\n",
            "t = 16, avg_loss = 0.2439\n",
            "t = 17, avg_loss = 0.2863\n",
            "t = 18, avg_loss = 0.2283\n",
            "t = 19, avg_loss = 0.3033\n",
            "t = 20, avg_loss = 0.3017\n",
            "Checking accuracy on test set\n",
            "Got 265 / 320 correct (82.81)\n",
            "acc = 0.828125\n",
            "Starting epoch 42 / 80\n",
            "t = 1, avg_loss = 0.2375\n",
            "t = 2, avg_loss = 0.3138\n",
            "t = 3, avg_loss = 0.2571\n",
            "t = 4, avg_loss = 0.1740\n",
            "t = 5, avg_loss = 0.2375\n",
            "t = 6, avg_loss = 0.3414\n",
            "t = 7, avg_loss = 0.2856\n",
            "t = 8, avg_loss = 0.2689\n",
            "t = 9, avg_loss = 0.2194\n",
            "t = 10, avg_loss = 0.1998\n",
            "t = 11, avg_loss = 0.2934\n",
            "t = 12, avg_loss = 0.2584\n",
            "t = 13, avg_loss = 0.3210\n",
            "t = 14, avg_loss = 0.2759\n",
            "t = 15, avg_loss = 0.2493\n",
            "t = 16, avg_loss = 0.3168\n",
            "t = 17, avg_loss = 0.2563\n",
            "t = 18, avg_loss = 0.2111\n",
            "t = 19, avg_loss = 0.2293\n",
            "t = 20, avg_loss = 0.2651\n",
            "Checking accuracy on test set\n",
            "Got 266 / 320 correct (83.12)\n",
            "acc = 0.831250\n",
            "Starting epoch 43 / 80\n",
            "t = 1, avg_loss = 0.2405\n",
            "t = 2, avg_loss = 0.3223\n",
            "t = 3, avg_loss = 0.2135\n",
            "t = 4, avg_loss = 0.2451\n",
            "t = 5, avg_loss = 0.2427\n",
            "t = 6, avg_loss = 0.2132\n",
            "t = 7, avg_loss = 0.2470\n",
            "t = 8, avg_loss = 0.2229\n",
            "t = 9, avg_loss = 0.2734\n",
            "t = 10, avg_loss = 0.3051\n",
            "t = 11, avg_loss = 0.2330\n",
            "t = 12, avg_loss = 0.2677\n",
            "t = 13, avg_loss = 0.2399\n",
            "t = 14, avg_loss = 0.1947\n",
            "t = 15, avg_loss = 0.3131\n",
            "t = 16, avg_loss = 0.2174\n",
            "t = 17, avg_loss = 0.2323\n",
            "t = 18, avg_loss = 0.2888\n",
            "t = 19, avg_loss = 0.2132\n",
            "t = 20, avg_loss = 0.2616\n",
            "Checking accuracy on test set\n",
            "Got 270 / 320 correct (84.38)\n",
            "acc = 0.843750\n",
            "Starting epoch 44 / 80\n",
            "t = 1, avg_loss = 0.2124\n",
            "t = 2, avg_loss = 0.2454\n",
            "t = 3, avg_loss = 0.2596\n",
            "t = 4, avg_loss = 0.2128\n",
            "t = 5, avg_loss = 0.2161\n",
            "t = 6, avg_loss = 0.2116\n",
            "t = 7, avg_loss = 0.2665\n",
            "t = 8, avg_loss = 0.2220\n",
            "t = 9, avg_loss = 0.2248\n",
            "t = 10, avg_loss = 0.2373\n",
            "t = 11, avg_loss = 0.3803\n",
            "t = 12, avg_loss = 0.2596\n",
            "t = 13, avg_loss = 0.2055\n",
            "t = 14, avg_loss = 0.1969\n",
            "t = 15, avg_loss = 0.2917\n",
            "t = 16, avg_loss = 0.2013\n",
            "t = 17, avg_loss = 0.3794\n",
            "t = 18, avg_loss = 0.3508\n",
            "t = 19, avg_loss = 0.3235\n",
            "t = 20, avg_loss = 0.2949\n",
            "Checking accuracy on test set\n",
            "Got 270 / 320 correct (84.38)\n",
            "acc = 0.843750\n",
            "Starting epoch 45 / 80\n",
            "t = 1, avg_loss = 0.2039\n",
            "t = 2, avg_loss = 0.2896\n",
            "t = 3, avg_loss = 0.1943\n",
            "t = 4, avg_loss = 0.2446\n",
            "t = 5, avg_loss = 0.2220\n",
            "t = 6, avg_loss = 0.2046\n",
            "t = 7, avg_loss = 0.2307\n",
            "t = 8, avg_loss = 0.3473\n",
            "t = 9, avg_loss = 0.3561\n",
            "t = 10, avg_loss = 0.2351\n",
            "t = 11, avg_loss = 0.2225\n",
            "t = 12, avg_loss = 0.2529\n",
            "t = 13, avg_loss = 0.2359\n",
            "t = 14, avg_loss = 0.1847\n",
            "t = 15, avg_loss = 0.3043\n",
            "t = 16, avg_loss = 0.2285\n",
            "t = 17, avg_loss = 0.1971\n",
            "t = 18, avg_loss = 0.2301\n",
            "t = 19, avg_loss = 0.2293\n",
            "t = 20, avg_loss = 0.2505\n",
            "Checking accuracy on test set\n",
            "Got 273 / 320 correct (85.31)\n",
            "acc = 0.853125\n",
            "Starting epoch 46 / 80\n",
            "t = 1, avg_loss = 0.2061\n",
            "t = 2, avg_loss = 0.2259\n",
            "t = 3, avg_loss = 0.2765\n",
            "t = 4, avg_loss = 0.3247\n",
            "t = 5, avg_loss = 0.3300\n",
            "t = 6, avg_loss = 0.2195\n",
            "t = 7, avg_loss = 0.2030\n",
            "t = 8, avg_loss = 0.2039\n",
            "t = 9, avg_loss = 0.3134\n",
            "t = 10, avg_loss = 0.2274\n",
            "t = 11, avg_loss = 0.2200\n",
            "t = 12, avg_loss = 0.2843\n",
            "t = 13, avg_loss = 0.3068\n",
            "t = 14, avg_loss = 0.2662\n",
            "t = 15, avg_loss = 0.1717\n",
            "t = 16, avg_loss = 0.2108\n",
            "t = 17, avg_loss = 0.2436\n",
            "t = 18, avg_loss = 0.3710\n",
            "t = 19, avg_loss = 0.3266\n",
            "t = 20, avg_loss = 0.2335\n",
            "Checking accuracy on test set\n",
            "Got 273 / 320 correct (85.31)\n",
            "acc = 0.853125\n",
            "Starting epoch 47 / 80\n",
            "t = 1, avg_loss = 0.2416\n",
            "t = 2, avg_loss = 0.2610\n",
            "t = 3, avg_loss = 0.2417\n",
            "t = 4, avg_loss = 0.2678\n",
            "t = 5, avg_loss = 0.2103\n",
            "t = 6, avg_loss = 0.2318\n",
            "t = 7, avg_loss = 0.2536\n",
            "t = 8, avg_loss = 0.2174\n",
            "t = 9, avg_loss = 0.3374\n",
            "t = 10, avg_loss = 0.2729\n",
            "t = 11, avg_loss = 0.2643\n",
            "t = 12, avg_loss = 0.3312\n",
            "t = 13, avg_loss = 0.2496\n",
            "t = 14, avg_loss = 0.2109\n",
            "t = 15, avg_loss = 0.2535\n",
            "t = 16, avg_loss = 0.3292\n",
            "t = 17, avg_loss = 0.2848\n",
            "t = 18, avg_loss = 0.3046\n",
            "t = 19, avg_loss = 0.2363\n",
            "t = 20, avg_loss = 0.2525\n",
            "Checking accuracy on test set\n",
            "Got 267 / 320 correct (83.44)\n",
            "acc = 0.834375\n",
            "Starting epoch 48 / 80\n",
            "t = 1, avg_loss = 0.3018\n",
            "t = 2, avg_loss = 0.3812\n",
            "t = 3, avg_loss = 0.2150\n",
            "t = 4, avg_loss = 0.2362\n",
            "t = 5, avg_loss = 0.2624\n",
            "t = 6, avg_loss = 0.2742\n",
            "t = 7, avg_loss = 0.2465\n",
            "t = 8, avg_loss = 0.2872\n",
            "t = 9, avg_loss = 0.2179\n",
            "t = 10, avg_loss = 0.2541\n",
            "t = 11, avg_loss = 0.2621\n",
            "t = 12, avg_loss = 0.2702\n",
            "t = 13, avg_loss = 0.4390\n",
            "t = 14, avg_loss = 0.2369\n",
            "t = 15, avg_loss = 0.3090\n",
            "t = 16, avg_loss = 0.2199\n",
            "t = 17, avg_loss = 0.2777\n",
            "t = 18, avg_loss = 0.2472\n",
            "t = 19, avg_loss = 0.2665\n",
            "t = 20, avg_loss = 0.2081\n",
            "Checking accuracy on test set\n",
            "Got 272 / 320 correct (85.00)\n",
            "acc = 0.850000\n",
            "Starting epoch 49 / 80\n",
            "t = 1, avg_loss = 0.2441\n",
            "t = 2, avg_loss = 0.2608\n",
            "t = 3, avg_loss = 0.2103\n",
            "t = 4, avg_loss = 0.2725\n",
            "t = 5, avg_loss = 0.2219\n",
            "t = 6, avg_loss = 0.1594\n",
            "t = 7, avg_loss = 0.2209\n",
            "t = 8, avg_loss = 0.2570\n",
            "t = 9, avg_loss = 0.3477\n",
            "t = 10, avg_loss = 0.2970\n",
            "t = 11, avg_loss = 0.2152\n",
            "t = 12, avg_loss = 0.2084\n",
            "t = 13, avg_loss = 0.3437\n",
            "t = 14, avg_loss = 0.1579\n",
            "t = 15, avg_loss = 0.3920\n",
            "t = 16, avg_loss = 0.2974\n",
            "t = 17, avg_loss = 0.2507\n",
            "t = 18, avg_loss = 0.4065\n",
            "t = 19, avg_loss = 0.2459\n",
            "t = 20, avg_loss = 0.2680\n",
            "Checking accuracy on test set\n",
            "Got 272 / 320 correct (85.00)\n",
            "acc = 0.850000\n",
            "Starting epoch 50 / 80\n",
            "t = 1, avg_loss = 0.2582\n",
            "t = 2, avg_loss = 0.2782\n",
            "t = 3, avg_loss = 0.1978\n",
            "t = 4, avg_loss = 0.3125\n",
            "t = 5, avg_loss = 0.2179\n",
            "t = 6, avg_loss = 0.2658\n",
            "t = 7, avg_loss = 0.2054\n",
            "t = 8, avg_loss = 0.2552\n",
            "t = 9, avg_loss = 0.3660\n",
            "t = 10, avg_loss = 0.4008\n",
            "t = 11, avg_loss = 0.1452\n",
            "t = 12, avg_loss = 0.3464\n",
            "t = 13, avg_loss = 0.2578\n",
            "t = 14, avg_loss = 0.2492\n",
            "t = 15, avg_loss = 0.2138\n",
            "t = 16, avg_loss = 0.2862\n",
            "t = 17, avg_loss = 0.2811\n",
            "t = 18, avg_loss = 0.3234\n",
            "t = 19, avg_loss = 0.3033\n",
            "t = 20, avg_loss = 0.3368\n",
            "Checking accuracy on test set\n",
            "Got 265 / 320 correct (82.81)\n",
            "acc = 0.828125\n",
            "Starting epoch 51 / 80\n",
            "t = 1, avg_loss = 0.2407\n",
            "t = 2, avg_loss = 0.2629\n",
            "t = 3, avg_loss = 0.2178\n",
            "t = 4, avg_loss = 0.2757\n",
            "t = 5, avg_loss = 0.2307\n",
            "t = 6, avg_loss = 0.3092\n",
            "t = 7, avg_loss = 0.2324\n",
            "t = 8, avg_loss = 0.2668\n",
            "t = 9, avg_loss = 0.2969\n",
            "t = 10, avg_loss = 0.1805\n",
            "t = 11, avg_loss = 0.2235\n",
            "t = 12, avg_loss = 0.2618\n",
            "t = 13, avg_loss = 0.3159\n",
            "t = 14, avg_loss = 0.1957\n",
            "t = 15, avg_loss = 0.2445\n",
            "t = 16, avg_loss = 0.4010\n",
            "t = 17, avg_loss = 0.3514\n",
            "t = 18, avg_loss = 0.2155\n",
            "t = 19, avg_loss = 0.1778\n",
            "t = 20, avg_loss = 0.2144\n",
            "Checking accuracy on test set\n",
            "Got 271 / 320 correct (84.69)\n",
            "acc = 0.846875\n",
            "Starting epoch 52 / 80\n",
            "t = 1, avg_loss = 0.2584\n",
            "t = 2, avg_loss = 0.2018\n",
            "t = 3, avg_loss = 0.2281\n",
            "t = 4, avg_loss = 0.2141\n",
            "t = 5, avg_loss = 0.2277\n",
            "t = 6, avg_loss = 0.2691\n",
            "t = 7, avg_loss = 0.2562\n",
            "t = 8, avg_loss = 0.2612\n",
            "t = 9, avg_loss = 0.2661\n",
            "t = 10, avg_loss = 0.2150\n",
            "t = 11, avg_loss = 0.2251\n",
            "t = 12, avg_loss = 0.2546\n",
            "t = 13, avg_loss = 0.2566\n",
            "t = 14, avg_loss = 0.2485\n",
            "t = 15, avg_loss = 0.3419\n",
            "t = 16, avg_loss = 0.2675\n",
            "t = 17, avg_loss = 0.2858\n",
            "t = 18, avg_loss = 0.2553\n",
            "t = 19, avg_loss = 0.2052\n",
            "t = 20, avg_loss = 0.3104\n",
            "Checking accuracy on test set\n",
            "Got 270 / 320 correct (84.38)\n",
            "acc = 0.843750\n",
            "Starting epoch 53 / 80\n",
            "t = 1, avg_loss = 0.2474\n",
            "t = 2, avg_loss = 0.2499\n",
            "t = 3, avg_loss = 0.1853\n",
            "t = 4, avg_loss = 0.2083\n",
            "t = 5, avg_loss = 0.2155\n",
            "t = 6, avg_loss = 0.2586\n",
            "t = 7, avg_loss = 0.2479\n",
            "t = 8, avg_loss = 0.1891\n",
            "t = 9, avg_loss = 0.2703\n",
            "t = 10, avg_loss = 0.2747\n",
            "t = 11, avg_loss = 0.3200\n",
            "t = 12, avg_loss = 0.3124\n",
            "t = 13, avg_loss = 0.1956\n",
            "t = 14, avg_loss = 0.1546\n",
            "t = 15, avg_loss = 0.2434\n",
            "t = 16, avg_loss = 0.1871\n",
            "t = 17, avg_loss = 0.2408\n",
            "t = 18, avg_loss = 0.2459\n",
            "t = 19, avg_loss = 0.2676\n",
            "t = 20, avg_loss = 0.3020\n",
            "Checking accuracy on test set\n",
            "Got 267 / 320 correct (83.44)\n",
            "acc = 0.834375\n",
            "Starting epoch 54 / 80\n",
            "t = 1, avg_loss = 0.2442\n",
            "t = 2, avg_loss = 0.1892\n",
            "t = 3, avg_loss = 0.2714\n",
            "t = 4, avg_loss = 0.1159\n",
            "t = 5, avg_loss = 0.1948\n",
            "t = 6, avg_loss = 0.3025\n",
            "t = 7, avg_loss = 0.1960\n",
            "t = 8, avg_loss = 0.2780\n",
            "t = 9, avg_loss = 0.2348\n",
            "t = 10, avg_loss = 0.2648\n",
            "t = 11, avg_loss = 0.1527\n",
            "t = 12, avg_loss = 0.2186\n",
            "t = 13, avg_loss = 0.2785\n",
            "t = 14, avg_loss = 0.2205\n",
            "t = 15, avg_loss = 0.2374\n",
            "t = 16, avg_loss = 0.2200\n",
            "t = 17, avg_loss = 0.2696\n",
            "t = 18, avg_loss = 0.2939\n",
            "t = 19, avg_loss = 0.2615\n",
            "t = 20, avg_loss = 0.2654\n",
            "Checking accuracy on test set\n",
            "Got 269 / 320 correct (84.06)\n",
            "acc = 0.840625\n",
            "Starting epoch 55 / 80\n",
            "t = 1, avg_loss = 0.2756\n",
            "t = 2, avg_loss = 0.2354\n",
            "t = 3, avg_loss = 0.3326\n",
            "t = 4, avg_loss = 0.2736\n",
            "t = 5, avg_loss = 0.2998\n",
            "t = 6, avg_loss = 0.3578\n",
            "t = 7, avg_loss = 0.2660\n",
            "t = 8, avg_loss = 0.2299\n",
            "t = 9, avg_loss = 0.2202\n",
            "t = 10, avg_loss = 0.3236\n",
            "t = 11, avg_loss = 0.2628\n",
            "t = 12, avg_loss = 0.2362\n",
            "t = 13, avg_loss = 0.2267\n",
            "t = 14, avg_loss = 0.2362\n",
            "t = 15, avg_loss = 0.2458\n",
            "t = 16, avg_loss = 0.3244\n",
            "t = 17, avg_loss = 0.2130\n",
            "t = 18, avg_loss = 0.1804\n",
            "t = 19, avg_loss = 0.2001\n",
            "t = 20, avg_loss = 0.2168\n",
            "Checking accuracy on test set\n",
            "Got 279 / 320 correct (87.19)\n",
            "acc = 0.871875\n",
            "Starting epoch 56 / 80\n",
            "t = 1, avg_loss = 0.2409\n",
            "t = 2, avg_loss = 0.1658\n",
            "t = 3, avg_loss = 0.2607\n",
            "t = 4, avg_loss = 0.1966\n",
            "t = 5, avg_loss = 0.2802\n",
            "t = 6, avg_loss = 0.2347\n",
            "t = 7, avg_loss = 0.1500\n",
            "t = 8, avg_loss = 0.1961\n",
            "t = 9, avg_loss = 0.2519\n",
            "t = 10, avg_loss = 0.1960\n",
            "t = 11, avg_loss = 0.2318\n",
            "t = 12, avg_loss = 0.2896\n",
            "t = 13, avg_loss = 0.2324\n",
            "t = 14, avg_loss = 0.1440\n",
            "t = 15, avg_loss = 0.3019\n",
            "t = 16, avg_loss = 0.3115\n",
            "t = 17, avg_loss = 0.2369\n",
            "t = 18, avg_loss = 0.2950\n",
            "t = 19, avg_loss = 0.3691\n",
            "t = 20, avg_loss = 0.2060\n",
            "Checking accuracy on test set\n",
            "Got 272 / 320 correct (85.00)\n",
            "acc = 0.850000\n",
            "Starting epoch 57 / 80\n",
            "t = 1, avg_loss = 0.2282\n",
            "t = 2, avg_loss = 0.2657\n",
            "t = 3, avg_loss = 0.2173\n",
            "t = 4, avg_loss = 0.2511\n",
            "t = 5, avg_loss = 0.2056\n",
            "t = 6, avg_loss = 0.3000\n",
            "t = 7, avg_loss = 0.2465\n",
            "t = 8, avg_loss = 0.2426\n",
            "t = 9, avg_loss = 0.2863\n",
            "t = 10, avg_loss = 0.2641\n",
            "t = 11, avg_loss = 0.2027\n",
            "t = 12, avg_loss = 0.2621\n",
            "t = 13, avg_loss = 0.1914\n",
            "t = 14, avg_loss = 0.2279\n",
            "t = 15, avg_loss = 0.2417\n",
            "t = 16, avg_loss = 0.2184\n",
            "t = 17, avg_loss = 0.3073\n",
            "t = 18, avg_loss = 0.2813\n",
            "t = 19, avg_loss = 0.2544\n",
            "t = 20, avg_loss = 0.1530\n",
            "Checking accuracy on test set\n",
            "Got 270 / 320 correct (84.38)\n",
            "acc = 0.843750\n",
            "Starting epoch 58 / 80\n",
            "t = 1, avg_loss = 0.1800\n",
            "t = 2, avg_loss = 0.2413\n",
            "t = 3, avg_loss = 0.2586\n",
            "t = 4, avg_loss = 0.1858\n",
            "t = 5, avg_loss = 0.2624\n",
            "t = 6, avg_loss = 0.2197\n",
            "t = 7, avg_loss = 0.3873\n",
            "t = 8, avg_loss = 0.2145\n",
            "t = 9, avg_loss = 0.2490\n",
            "t = 10, avg_loss = 0.2090\n",
            "t = 11, avg_loss = 0.2449\n",
            "t = 12, avg_loss = 0.2100\n",
            "t = 13, avg_loss = 0.2584\n",
            "t = 14, avg_loss = 0.2080\n",
            "t = 15, avg_loss = 0.2640\n",
            "t = 16, avg_loss = 0.1713\n",
            "t = 17, avg_loss = 0.3118\n",
            "t = 18, avg_loss = 0.2130\n",
            "t = 19, avg_loss = 0.2528\n",
            "t = 20, avg_loss = 0.2554\n",
            "Checking accuracy on test set\n",
            "Got 282 / 320 correct (88.12)\n",
            "acc = 0.881250\n",
            "Starting epoch 59 / 80\n",
            "t = 1, avg_loss = 0.1918\n",
            "t = 2, avg_loss = 0.1501\n",
            "t = 3, avg_loss = 0.1997\n",
            "t = 4, avg_loss = 0.1446\n",
            "t = 5, avg_loss = 0.2233\n",
            "t = 6, avg_loss = 0.2299\n",
            "t = 7, avg_loss = 0.1765\n",
            "t = 8, avg_loss = 0.3416\n",
            "t = 9, avg_loss = 0.4010\n",
            "t = 10, avg_loss = 0.2363\n",
            "t = 11, avg_loss = 0.2217\n",
            "t = 12, avg_loss = 0.2287\n",
            "t = 13, avg_loss = 0.2167\n",
            "t = 14, avg_loss = 0.2837\n",
            "t = 15, avg_loss = 0.2390\n",
            "t = 16, avg_loss = 0.2690\n",
            "t = 17, avg_loss = 0.2296\n",
            "t = 18, avg_loss = 0.2985\n",
            "t = 19, avg_loss = 0.2776\n",
            "t = 20, avg_loss = 0.2515\n",
            "Checking accuracy on test set\n",
            "Got 265 / 320 correct (82.81)\n",
            "acc = 0.828125\n",
            "Starting epoch 60 / 80\n",
            "t = 1, avg_loss = 0.2239\n",
            "t = 2, avg_loss = 0.3086\n",
            "t = 3, avg_loss = 0.1778\n",
            "t = 4, avg_loss = 0.2460\n",
            "t = 5, avg_loss = 0.1971\n",
            "t = 6, avg_loss = 0.1938\n",
            "t = 7, avg_loss = 0.1488\n",
            "t = 8, avg_loss = 0.2335\n",
            "t = 9, avg_loss = 0.2828\n",
            "t = 10, avg_loss = 0.1963\n",
            "t = 11, avg_loss = 0.2131\n",
            "t = 12, avg_loss = 0.2438\n",
            "t = 13, avg_loss = 0.2398\n",
            "t = 14, avg_loss = 0.2176\n",
            "t = 15, avg_loss = 0.1971\n",
            "t = 16, avg_loss = 0.2529\n",
            "t = 17, avg_loss = 0.1786\n",
            "t = 18, avg_loss = 0.2238\n",
            "t = 19, avg_loss = 0.3637\n",
            "t = 20, avg_loss = 0.3721\n",
            "Checking accuracy on test set\n",
            "Got 276 / 320 correct (86.25)\n",
            "acc = 0.862500\n",
            "Starting epoch 61 / 80\n",
            "t = 1, avg_loss = 0.2079\n",
            "t = 2, avg_loss = 0.1971\n",
            "t = 3, avg_loss = 0.1815\n",
            "t = 4, avg_loss = 0.2693\n",
            "t = 5, avg_loss = 0.3404\n",
            "t = 6, avg_loss = 0.2039\n",
            "t = 7, avg_loss = 0.2680\n",
            "t = 8, avg_loss = 0.1657\n",
            "t = 9, avg_loss = 0.2398\n",
            "t = 10, avg_loss = 0.1940\n",
            "t = 11, avg_loss = 0.2160\n",
            "t = 12, avg_loss = 0.2654\n",
            "t = 13, avg_loss = 0.1887\n",
            "t = 14, avg_loss = 0.1904\n",
            "t = 15, avg_loss = 0.3012\n",
            "t = 16, avg_loss = 0.2947\n",
            "t = 17, avg_loss = 0.2464\n",
            "t = 18, avg_loss = 0.2517\n",
            "t = 19, avg_loss = 0.1678\n",
            "t = 20, avg_loss = 0.2619\n",
            "Checking accuracy on test set\n",
            "Got 273 / 320 correct (85.31)\n",
            "acc = 0.853125\n",
            "Starting epoch 62 / 80\n",
            "t = 1, avg_loss = 0.2009\n",
            "t = 2, avg_loss = 0.2703\n",
            "t = 3, avg_loss = 0.3182\n",
            "t = 4, avg_loss = 0.1366\n",
            "t = 5, avg_loss = 0.1558\n",
            "t = 6, avg_loss = 0.3160\n",
            "t = 7, avg_loss = 0.2246\n",
            "t = 8, avg_loss = 0.2634\n",
            "t = 9, avg_loss = 0.1535\n",
            "t = 10, avg_loss = 0.1640\n",
            "t = 11, avg_loss = 0.1864\n",
            "t = 12, avg_loss = 0.2832\n",
            "t = 13, avg_loss = 0.2233\n",
            "t = 14, avg_loss = 0.3416\n",
            "t = 15, avg_loss = 0.1990\n",
            "t = 16, avg_loss = 0.3176\n",
            "t = 17, avg_loss = 0.1666\n",
            "t = 18, avg_loss = 0.2120\n",
            "t = 19, avg_loss = 0.3679\n",
            "t = 20, avg_loss = 0.2200\n",
            "Checking accuracy on test set\n",
            "Got 281 / 320 correct (87.81)\n",
            "acc = 0.878125\n",
            "Starting epoch 63 / 80\n",
            "t = 1, avg_loss = 0.2153\n",
            "t = 2, avg_loss = 0.2710\n",
            "t = 3, avg_loss = 0.2343\n",
            "t = 4, avg_loss = 0.1977\n",
            "t = 5, avg_loss = 0.2174\n",
            "t = 6, avg_loss = 0.2342\n",
            "t = 7, avg_loss = 0.1578\n",
            "t = 8, avg_loss = 0.1609\n",
            "t = 9, avg_loss = 0.3546\n",
            "t = 10, avg_loss = 0.2461\n",
            "t = 11, avg_loss = 0.3029\n",
            "t = 12, avg_loss = 0.2486\n",
            "t = 13, avg_loss = 0.1708\n",
            "t = 14, avg_loss = 0.1997\n",
            "t = 15, avg_loss = 0.2087\n",
            "t = 16, avg_loss = 0.1885\n",
            "t = 17, avg_loss = 0.2754\n",
            "t = 18, avg_loss = 0.2582\n",
            "t = 19, avg_loss = 0.3282\n",
            "t = 20, avg_loss = 0.2033\n",
            "Checking accuracy on test set\n",
            "Got 260 / 320 correct (81.25)\n",
            "acc = 0.812500\n",
            "Starting epoch 64 / 80\n",
            "t = 1, avg_loss = 0.2370\n",
            "t = 2, avg_loss = 0.1522\n",
            "t = 3, avg_loss = 0.1627\n",
            "t = 4, avg_loss = 0.1792\n",
            "t = 5, avg_loss = 0.1308\n",
            "t = 6, avg_loss = 0.2349\n",
            "t = 7, avg_loss = 0.3039\n",
            "t = 8, avg_loss = 0.1972\n",
            "t = 9, avg_loss = 0.3039\n",
            "t = 10, avg_loss = 0.3119\n",
            "t = 11, avg_loss = 0.2959\n",
            "t = 12, avg_loss = 0.2890\n",
            "t = 13, avg_loss = 0.2399\n",
            "t = 14, avg_loss = 0.2227\n",
            "t = 15, avg_loss = 0.2134\n",
            "t = 16, avg_loss = 0.2343\n",
            "t = 17, avg_loss = 0.2147\n",
            "t = 18, avg_loss = 0.3353\n",
            "t = 19, avg_loss = 0.2780\n",
            "t = 20, avg_loss = 0.3187\n",
            "Checking accuracy on test set\n",
            "Got 264 / 320 correct (82.50)\n",
            "acc = 0.825000\n",
            "Starting epoch 65 / 80\n",
            "t = 1, avg_loss = 0.3185\n",
            "t = 2, avg_loss = 0.1895\n",
            "t = 3, avg_loss = 0.3002\n",
            "t = 4, avg_loss = 0.2716\n",
            "t = 5, avg_loss = 0.2359\n",
            "t = 6, avg_loss = 0.2755\n",
            "t = 7, avg_loss = 0.2093\n",
            "t = 8, avg_loss = 0.1971\n",
            "t = 9, avg_loss = 0.2682\n",
            "t = 10, avg_loss = 0.2006\n",
            "t = 11, avg_loss = 0.2405\n",
            "t = 12, avg_loss = 0.1776\n",
            "t = 13, avg_loss = 0.2161\n",
            "t = 14, avg_loss = 0.2349\n",
            "t = 15, avg_loss = 0.2006\n",
            "t = 16, avg_loss = 0.2831\n",
            "t = 17, avg_loss = 0.2386\n",
            "t = 18, avg_loss = 0.2710\n",
            "t = 19, avg_loss = 0.2295\n",
            "t = 20, avg_loss = 0.1947\n",
            "Checking accuracy on test set\n",
            "Got 272 / 320 correct (85.00)\n",
            "acc = 0.850000\n",
            "Starting epoch 66 / 80\n",
            "t = 1, avg_loss = 0.1559\n",
            "t = 2, avg_loss = 0.2102\n",
            "t = 3, avg_loss = 0.1533\n",
            "t = 4, avg_loss = 0.2161\n",
            "t = 5, avg_loss = 0.3081\n",
            "t = 6, avg_loss = 0.1584\n",
            "t = 7, avg_loss = 0.2803\n",
            "t = 8, avg_loss = 0.1696\n",
            "t = 9, avg_loss = 0.2704\n",
            "t = 10, avg_loss = 0.2788\n",
            "t = 11, avg_loss = 0.2669\n",
            "t = 12, avg_loss = 0.2378\n",
            "t = 13, avg_loss = 0.2624\n",
            "t = 14, avg_loss = 0.2480\n",
            "t = 15, avg_loss = 0.1958\n",
            "t = 16, avg_loss = 0.2833\n",
            "t = 17, avg_loss = 0.2567\n",
            "t = 18, avg_loss = 0.2550\n",
            "t = 19, avg_loss = 0.2480\n",
            "t = 20, avg_loss = 0.1835\n",
            "Checking accuracy on test set\n",
            "Got 264 / 320 correct (82.50)\n",
            "acc = 0.825000\n",
            "Starting epoch 67 / 80\n",
            "t = 1, avg_loss = 0.2776\n",
            "t = 2, avg_loss = 0.2461\n",
            "t = 3, avg_loss = 0.1454\n",
            "t = 4, avg_loss = 0.1682\n",
            "t = 5, avg_loss = 0.2318\n",
            "t = 6, avg_loss = 0.2581\n",
            "t = 7, avg_loss = 0.1860\n",
            "t = 8, avg_loss = 0.2385\n",
            "t = 9, avg_loss = 0.2861\n",
            "t = 10, avg_loss = 0.1976\n",
            "t = 11, avg_loss = 0.2301\n",
            "t = 12, avg_loss = 0.1693\n",
            "t = 13, avg_loss = 0.2837\n",
            "t = 14, avg_loss = 0.2124\n",
            "t = 15, avg_loss = 0.2506\n",
            "t = 16, avg_loss = 0.1990\n",
            "t = 17, avg_loss = 0.2308\n",
            "t = 18, avg_loss = 0.1922\n",
            "t = 19, avg_loss = 0.3249\n",
            "t = 20, avg_loss = 0.2246\n",
            "Checking accuracy on test set\n",
            "Got 272 / 320 correct (85.00)\n",
            "acc = 0.850000\n",
            "Starting epoch 68 / 80\n",
            "t = 1, avg_loss = 0.2756\n",
            "t = 2, avg_loss = 0.2539\n",
            "t = 3, avg_loss = 0.3060\n",
            "t = 4, avg_loss = 0.2024\n",
            "t = 5, avg_loss = 0.2420\n",
            "t = 6, avg_loss = 0.2979\n",
            "t = 7, avg_loss = 0.1706\n",
            "t = 8, avg_loss = 0.1880\n",
            "t = 9, avg_loss = 0.1825\n",
            "t = 10, avg_loss = 0.3057\n",
            "t = 11, avg_loss = 0.1730\n",
            "t = 12, avg_loss = 0.1997\n",
            "t = 13, avg_loss = 0.2748\n",
            "t = 14, avg_loss = 0.2991\n",
            "t = 15, avg_loss = 0.1792\n",
            "t = 16, avg_loss = 0.1927\n",
            "t = 17, avg_loss = 0.2754\n",
            "t = 18, avg_loss = 0.2025\n",
            "t = 19, avg_loss = 0.3549\n",
            "t = 20, avg_loss = 0.2935\n",
            "Checking accuracy on test set\n",
            "Got 277 / 320 correct (86.56)\n",
            "acc = 0.865625\n",
            "Starting epoch 69 / 80\n",
            "t = 1, avg_loss = 0.2241\n",
            "t = 2, avg_loss = 0.1817\n",
            "t = 3, avg_loss = 0.2154\n",
            "t = 4, avg_loss = 0.2219\n",
            "t = 5, avg_loss = 0.3643\n",
            "t = 6, avg_loss = 0.2656\n",
            "t = 7, avg_loss = 0.1777\n",
            "t = 8, avg_loss = 0.2746\n",
            "t = 9, avg_loss = 0.2759\n",
            "t = 10, avg_loss = 0.1984\n",
            "t = 11, avg_loss = 0.2187\n",
            "t = 12, avg_loss = 0.2337\n",
            "t = 13, avg_loss = 0.1933\n",
            "t = 14, avg_loss = 0.1814\n",
            "t = 15, avg_loss = 0.2700\n",
            "t = 16, avg_loss = 0.2812\n",
            "t = 17, avg_loss = 0.2307\n",
            "t = 18, avg_loss = 0.2641\n",
            "t = 19, avg_loss = 0.1754\n",
            "t = 20, avg_loss = 0.1681\n",
            "Checking accuracy on test set\n",
            "Got 274 / 320 correct (85.62)\n",
            "acc = 0.856250\n",
            "Starting epoch 70 / 80\n",
            "t = 1, avg_loss = 0.2524\n",
            "t = 2, avg_loss = 0.2301\n",
            "t = 3, avg_loss = 0.2107\n",
            "t = 4, avg_loss = 0.1554\n",
            "t = 5, avg_loss = 0.1945\n",
            "t = 6, avg_loss = 0.1759\n",
            "t = 7, avg_loss = 0.2838\n",
            "t = 8, avg_loss = 0.1986\n",
            "t = 9, avg_loss = 0.2304\n",
            "t = 10, avg_loss = 0.2433\n",
            "t = 11, avg_loss = 0.2034\n",
            "t = 12, avg_loss = 0.2289\n",
            "t = 13, avg_loss = 0.3360\n",
            "t = 14, avg_loss = 0.2332\n",
            "t = 15, avg_loss = 0.2463\n",
            "t = 16, avg_loss = 0.2500\n",
            "t = 17, avg_loss = 0.2096\n",
            "t = 18, avg_loss = 0.2512\n",
            "t = 19, avg_loss = 0.1750\n",
            "t = 20, avg_loss = 0.3029\n",
            "Checking accuracy on test set\n",
            "Got 276 / 320 correct (86.25)\n",
            "acc = 0.862500\n",
            "Starting epoch 71 / 80\n",
            "t = 1, avg_loss = 0.2215\n",
            "t = 2, avg_loss = 0.2094\n",
            "t = 3, avg_loss = 0.1988\n",
            "t = 4, avg_loss = 0.2018\n",
            "t = 5, avg_loss = 0.2458\n",
            "t = 6, avg_loss = 0.2457\n",
            "t = 7, avg_loss = 0.1718\n",
            "t = 8, avg_loss = 0.1978\n",
            "t = 9, avg_loss = 0.2708\n",
            "t = 10, avg_loss = 0.2519\n",
            "t = 11, avg_loss = 0.1597\n",
            "t = 12, avg_loss = 0.1946\n",
            "t = 13, avg_loss = 0.2699\n",
            "t = 14, avg_loss = 0.2344\n",
            "t = 15, avg_loss = 0.1939\n",
            "t = 16, avg_loss = 0.1885\n",
            "t = 17, avg_loss = 0.1955\n",
            "t = 18, avg_loss = 0.2109\n",
            "t = 19, avg_loss = 0.2173\n",
            "t = 20, avg_loss = 0.2644\n",
            "Checking accuracy on test set\n",
            "Got 278 / 320 correct (86.88)\n",
            "acc = 0.868750\n",
            "Starting epoch 72 / 80\n",
            "t = 1, avg_loss = 0.1760\n",
            "t = 2, avg_loss = 0.2198\n",
            "t = 3, avg_loss = 0.1583\n",
            "t = 4, avg_loss = 0.1714\n",
            "t = 5, avg_loss = 0.1950\n",
            "t = 6, avg_loss = 0.2171\n",
            "t = 7, avg_loss = 0.1893\n",
            "t = 8, avg_loss = 0.1832\n",
            "t = 9, avg_loss = 0.1572\n",
            "t = 10, avg_loss = 0.1789\n",
            "t = 11, avg_loss = 0.2489\n",
            "t = 12, avg_loss = 0.3110\n",
            "t = 13, avg_loss = 0.1914\n",
            "t = 14, avg_loss = 0.1948\n",
            "t = 15, avg_loss = 0.2652\n",
            "t = 16, avg_loss = 0.2090\n",
            "t = 17, avg_loss = 0.3320\n",
            "t = 18, avg_loss = 0.1864\n",
            "t = 19, avg_loss = 0.1775\n",
            "t = 20, avg_loss = 0.2300\n",
            "Checking accuracy on test set\n",
            "Got 272 / 320 correct (85.00)\n",
            "acc = 0.850000\n",
            "Starting epoch 73 / 80\n",
            "t = 1, avg_loss = 0.2138\n",
            "t = 2, avg_loss = 0.2260\n",
            "t = 3, avg_loss = 0.1255\n",
            "t = 4, avg_loss = 0.2806\n",
            "t = 5, avg_loss = 0.2105\n",
            "t = 6, avg_loss = 0.1950\n",
            "t = 7, avg_loss = 0.1752\n",
            "t = 8, avg_loss = 0.1565\n",
            "t = 9, avg_loss = 0.2003\n",
            "t = 10, avg_loss = 0.2708\n",
            "t = 11, avg_loss = 0.2071\n",
            "t = 12, avg_loss = 0.1767\n",
            "t = 13, avg_loss = 0.2350\n",
            "t = 14, avg_loss = 0.2232\n",
            "t = 15, avg_loss = 0.1673\n",
            "t = 16, avg_loss = 0.2612\n",
            "t = 17, avg_loss = 0.1836\n",
            "t = 18, avg_loss = 0.2277\n",
            "t = 19, avg_loss = 0.2215\n",
            "t = 20, avg_loss = 0.2447\n",
            "Checking accuracy on test set\n",
            "Got 273 / 320 correct (85.31)\n",
            "acc = 0.853125\n",
            "Starting epoch 74 / 80\n",
            "t = 1, avg_loss = 0.2232\n",
            "t = 2, avg_loss = 0.1516\n",
            "t = 3, avg_loss = 0.2779\n",
            "t = 4, avg_loss = 0.2123\n",
            "t = 5, avg_loss = 0.2912\n",
            "t = 6, avg_loss = 0.2536\n",
            "t = 7, avg_loss = 0.2097\n",
            "t = 8, avg_loss = 0.2884\n",
            "t = 9, avg_loss = 0.2251\n",
            "t = 10, avg_loss = 0.1838\n",
            "t = 11, avg_loss = 0.1740\n",
            "t = 12, avg_loss = 0.2382\n",
            "t = 13, avg_loss = 0.1803\n",
            "t = 14, avg_loss = 0.1556\n",
            "t = 15, avg_loss = 0.3475\n",
            "t = 16, avg_loss = 0.2556\n",
            "t = 17, avg_loss = 0.2456\n",
            "t = 18, avg_loss = 0.2669\n",
            "t = 19, avg_loss = 0.2255\n",
            "t = 20, avg_loss = 0.1807\n",
            "Checking accuracy on test set\n",
            "Got 269 / 320 correct (84.06)\n",
            "acc = 0.840625\n",
            "Starting epoch 75 / 80\n",
            "t = 1, avg_loss = 0.2543\n",
            "t = 2, avg_loss = 0.1912\n",
            "t = 3, avg_loss = 0.2156\n",
            "t = 4, avg_loss = 0.1945\n",
            "t = 5, avg_loss = 0.2021\n",
            "t = 6, avg_loss = 0.3047\n",
            "t = 7, avg_loss = 0.2416\n",
            "t = 8, avg_loss = 0.1991\n",
            "t = 9, avg_loss = 0.2360\n",
            "t = 10, avg_loss = 0.1865\n",
            "t = 11, avg_loss = 0.1632\n",
            "t = 12, avg_loss = 0.2720\n",
            "t = 13, avg_loss = 0.2350\n",
            "t = 14, avg_loss = 0.1768\n",
            "t = 15, avg_loss = 0.1685\n",
            "t = 16, avg_loss = 0.2462\n",
            "t = 17, avg_loss = 0.2060\n",
            "t = 18, avg_loss = 0.2745\n",
            "t = 19, avg_loss = 0.2367\n",
            "t = 20, avg_loss = 0.2645\n",
            "Checking accuracy on test set\n",
            "Got 278 / 320 correct (86.88)\n",
            "acc = 0.868750\n",
            "Starting epoch 76 / 80\n",
            "t = 1, avg_loss = 0.1841\n",
            "t = 2, avg_loss = 0.2105\n",
            "t = 3, avg_loss = 0.2295\n",
            "t = 4, avg_loss = 0.2160\n",
            "t = 5, avg_loss = 0.1684\n",
            "t = 6, avg_loss = 0.1825\n",
            "t = 7, avg_loss = 0.1688\n",
            "t = 8, avg_loss = 0.2639\n",
            "t = 9, avg_loss = 0.2394\n",
            "t = 10, avg_loss = 0.2257\n",
            "t = 11, avg_loss = 0.1808\n",
            "t = 12, avg_loss = 0.2468\n",
            "t = 13, avg_loss = 0.1607\n",
            "t = 14, avg_loss = 0.2509\n",
            "t = 15, avg_loss = 0.2281\n",
            "t = 16, avg_loss = 0.2197\n",
            "t = 17, avg_loss = 0.2195\n",
            "t = 18, avg_loss = 0.1742\n",
            "t = 19, avg_loss = 0.2479\n",
            "t = 20, avg_loss = 0.2137\n",
            "Checking accuracy on test set\n",
            "Got 273 / 320 correct (85.31)\n",
            "acc = 0.853125\n",
            "Starting epoch 77 / 80\n",
            "t = 1, avg_loss = 0.1752\n",
            "t = 2, avg_loss = 0.2485\n",
            "t = 3, avg_loss = 0.2019\n",
            "t = 4, avg_loss = 0.2227\n",
            "t = 5, avg_loss = 0.2225\n",
            "t = 6, avg_loss = 0.2656\n",
            "t = 7, avg_loss = 0.1864\n",
            "t = 8, avg_loss = 0.2088\n",
            "t = 9, avg_loss = 0.1850\n",
            "t = 10, avg_loss = 0.2057\n",
            "t = 11, avg_loss = 0.2447\n",
            "t = 12, avg_loss = 0.1588\n",
            "t = 13, avg_loss = 0.2551\n",
            "t = 14, avg_loss = 0.2165\n",
            "t = 15, avg_loss = 0.2363\n",
            "t = 16, avg_loss = 0.2341\n",
            "t = 17, avg_loss = 0.2358\n",
            "t = 18, avg_loss = 0.1591\n",
            "t = 19, avg_loss = 0.2012\n",
            "t = 20, avg_loss = 0.2636\n",
            "Checking accuracy on test set\n",
            "Got 274 / 320 correct (85.62)\n",
            "acc = 0.856250\n",
            "Starting epoch 78 / 80\n",
            "t = 1, avg_loss = 0.2013\n",
            "t = 2, avg_loss = 0.2391\n",
            "t = 3, avg_loss = 0.3000\n",
            "t = 4, avg_loss = 0.1619\n",
            "t = 5, avg_loss = 0.2094\n",
            "t = 6, avg_loss = 0.2230\n",
            "t = 7, avg_loss = 0.1920\n",
            "t = 8, avg_loss = 0.3527\n",
            "t = 9, avg_loss = 0.1693\n",
            "t = 10, avg_loss = 0.2085\n",
            "t = 11, avg_loss = 0.2186\n",
            "t = 12, avg_loss = 0.2002\n",
            "t = 13, avg_loss = 0.1670\n",
            "t = 14, avg_loss = 0.2018\n",
            "t = 15, avg_loss = 0.2865\n",
            "t = 16, avg_loss = 0.1743\n",
            "t = 17, avg_loss = 0.2445\n",
            "t = 18, avg_loss = 0.2204\n",
            "t = 19, avg_loss = 0.1884\n",
            "t = 20, avg_loss = 0.1661\n",
            "Checking accuracy on test set\n",
            "Got 275 / 320 correct (85.94)\n",
            "acc = 0.859375\n",
            "Starting epoch 79 / 80\n",
            "t = 1, avg_loss = 0.1660\n",
            "t = 2, avg_loss = 0.2256\n",
            "t = 3, avg_loss = 0.2344\n",
            "t = 4, avg_loss = 0.1934\n",
            "t = 5, avg_loss = 0.2192\n",
            "t = 6, avg_loss = 0.1310\n",
            "t = 7, avg_loss = 0.1754\n",
            "t = 8, avg_loss = 0.2770\n",
            "t = 9, avg_loss = 0.1915\n",
            "t = 10, avg_loss = 0.2619\n",
            "t = 11, avg_loss = 0.1806\n",
            "t = 12, avg_loss = 0.1322\n",
            "t = 13, avg_loss = 0.1612\n",
            "t = 14, avg_loss = 0.1397\n",
            "t = 15, avg_loss = 0.2501\n",
            "t = 16, avg_loss = 0.2038\n",
            "t = 17, avg_loss = 0.1752\n",
            "t = 18, avg_loss = 0.2439\n",
            "t = 19, avg_loss = 0.2509\n",
            "t = 20, avg_loss = 0.2023\n",
            "Checking accuracy on test set\n",
            "Got 273 / 320 correct (85.31)\n",
            "acc = 0.853125\n",
            "Starting epoch 80 / 80\n",
            "t = 1, avg_loss = 0.1521\n",
            "t = 2, avg_loss = 0.1772\n",
            "t = 3, avg_loss = 0.2136\n",
            "t = 4, avg_loss = 0.2798\n",
            "t = 5, avg_loss = 0.2170\n",
            "t = 6, avg_loss = 0.1589\n",
            "t = 7, avg_loss = 0.1809\n",
            "t = 8, avg_loss = 0.2412\n",
            "t = 9, avg_loss = 0.2407\n",
            "t = 10, avg_loss = 0.1951\n",
            "t = 11, avg_loss = 0.1940\n",
            "t = 12, avg_loss = 0.2062\n",
            "t = 13, avg_loss = 0.2208\n",
            "t = 14, avg_loss = 0.1603\n",
            "t = 15, avg_loss = 0.1883\n",
            "t = 16, avg_loss = 0.1740\n",
            "t = 17, avg_loss = 0.2531\n",
            "t = 18, avg_loss = 0.1947\n",
            "t = 19, avg_loss = 0.3111\n",
            "t = 20, avg_loss = 0.1368\n",
            "Checking accuracy on test set\n",
            "Got 273 / 320 correct (85.31)\n",
            "acc = 0.853125\n",
            "Checking accuracy on test set\n",
            "Got 271 / 320 correct (84.69)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.846875"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDn-2g-TLY3k",
        "colab_type": "code",
        "outputId": "c6802e1e-b3d3-4518-c347-d512e1370fde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot([print_every*batch_size*(i+1) for i in range((len(avg_loss_list)))],avg_loss_list)\n",
        "print(\"Loss:\")\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD7CAYAAAB68m/qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGer6hJv7-zR",
        "colab_type": "code",
        "outputId": "dda6e0c4-74eb-4d65-b3b4-f83083aebd1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "plt.plot([i+1 for i in range((len(acc_list)))],acc_list)\n",
        "print(\"Accurancy:\")\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accurancy:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSoU4DXqllApx/x9k0vb9f7EeKwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBTReWHxz4Ml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}