{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN_ascending_layers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMtWjWbt2vsD4yvaQgDWn5y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamilo116/KNN/blob/master/KNN_ascending_layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7ReM7FU-xs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import sys\n",
        "from random import shuffle\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms as transforms\n",
        "import timeit\n",
        "\n",
        "np.random.seed(4) \n",
        "torch.manual_seed(4) \n",
        "torch.cuda.manual_seed(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdDATVpSio04",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install -q tf-nightly-2.0-preview\n",
        "#%load_ext tensorboard #Load extension\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "logs_base_dir = \"runs\"\n",
        "os.makedirs(logs_base_dir, exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYIMZ8QyYewD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "a0b1507a-1a49-4b70-99d6-5bbd73c2f426"
      },
      "source": [
        "! git clone https://github.com/wang-chen/kervolution.git \n",
        "\n",
        "sys.path.append(\"kervolution/\")\n",
        "from kervolution import Kerv2d\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'kervolution'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 53 (delta 2), reused 0 (delta 0), pack-reused 47\u001b[K\n",
            "Unpacking objects: 100% (53/53), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvbKg4VJXKY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LIMIT_IMAGES_NUM = 1000\n",
        "train_test_split_size = 0.2\n",
        "image_resize = (100, 100)\n",
        "batch_size = 64\n",
        "num_workers = 0\n",
        "\n",
        "in_channels = 3\n",
        "out_channels_1 = 16\n",
        "out_channels_2 = 32\n",
        "out_channels_3 = 64\n",
        "out_channels_4 = 128\n",
        "\n",
        "kernel_size = 3\n",
        "padding_1 = 1\n",
        "num_epochs = 100\n",
        "\n",
        "learning_rate = 0.00012\n",
        "weight_decay = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMOHez_kHZD6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "b5faed79-29fa-4fdd-ad6a-87814635c409"
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b8P1NdXfVdX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "02984b3e-118a-4c88-c834-bc5067ce8d88"
      },
      "source": [
        "MALIGNANT_DATASET = '/content/drive/My Drive/Colab_data/malignant/malignant/'\n",
        "BENIGN_DATASET = '/content/drive/My Drive/Colab_data/benign/benign/'\n",
        "DATA_FOLDER = '/content/drive/My Drive/Colab_data/'\n",
        "\n",
        "\n",
        "benign_file_list = sorted(os.listdir(BENIGN_DATASET))\n",
        "malignant_file_list = sorted(os.listdir(MALIGNANT_DATASET))\n",
        "shuffle(benign_file_list)\n",
        "shuffle(malignant_file_list)\n",
        "benign_file_list = benign_file_list[:LIMIT_IMAGES_NUM]\n",
        "malignant_file_list = malignant_file_list[:LIMIT_IMAGES_NUM]\n",
        "\n",
        "print(f\"Number of benign {len(benign_file_list)} images\")\n",
        "print(f\"Number of malignant {len(malignant_file_list)} images\")\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize(image_resize),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of benign 1000 images\n",
            "Number of malignant 1000 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGDQfal74BLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "benign_dict = {filename: 0 for filename in benign_file_list}\n",
        "malignant_dict = {filename: 1 for filename in malignant_file_list}\n",
        "img_class_dict = {**benign_dict , **malignant_dict}\n",
        "labeled_data = pd.Series(img_class_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvAAOqmVfVll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IsicDataset(Dataset):\n",
        "    def __init__(self, data_folder, labeled_data, \n",
        "                 transform=transforms.Compose([transforms.ToTensor()])):\n",
        "        self.labeled_data = labeled_data\n",
        "        self.transform = transform\n",
        "        self.data_folder = data_folder\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labeled_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        label = self.labeled_data[index]\n",
        "        if label == 0:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"benign\", \"benign\", index ))\n",
        "        else:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"malignant\", \"malignant\", index ))\n",
        "        image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "    @property\n",
        "    def labels(self):\n",
        "      return self.labeled_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSuYqjLAYrWA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "f2b82c9b-7094-41e6-bca3-4617eebcbd03"
      },
      "source": [
        " \n",
        "dataset = IsicDataset(DATA_FOLDER, labeled_data, transform=data_transforms)\n",
        "print(dataset.labels)\n",
        "\n",
        "X_train, X_test = train_test_split(dataset.labels, test_size=train_test_split_size)\n",
        "print(\"number of training data: \",len(X_train))\n",
        "print(\"number of testing  data: \",len(X_test))\n",
        "\n",
        "train_sampler = SubsetRandomSampler(list(X_train.index))\n",
        "valid_sampler = SubsetRandomSampler(list(X_test.index))\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ISIC_0002800.jpeg    0\n",
            "ISIC_0000836.jpeg    0\n",
            "ISIC_0000384.jpeg    0\n",
            "ISIC_0000662.jpeg    0\n",
            "ISIC_0001139.jpeg    0\n",
            "                    ..\n",
            "ISIC_0011895.jpeg    1\n",
            "ISIC_0014249.jpeg    1\n",
            "ISIC_0014129.jpeg    1\n",
            "ISIC_0010534.jpeg    1\n",
            "ISIC_0010596.jpeg    1\n",
            "Length: 2000, dtype: int64\n",
            "number of training data:  1600\n",
            "number of testing  data:  400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eK-sW83ndrkP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tb = SummaryWriter()\n",
        "images, labels = next(iter(train_loader))\n",
        "grid = torchvision.utils.make_grid(images)\n",
        "tb.add_image('images', grid)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e8nFBR6Yug5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "def train(model, train_loader ,loss_fn, optimizer, num_epochs = 1):\n",
        "    total_loss =0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
        "        model.train()\n",
        "\n",
        "        for t, (x, y) in enumerate(train_loader):\n",
        "            x_var = Variable(x.type(gpu_dtype))\n",
        "            y_var = Variable(y.type(gpu_dtype).long())\n",
        "            scores = model(x_var)\n",
        "            loss = loss_fn(scores, y_var)\n",
        "            total_loss += loss.data\n",
        "            \n",
        "            if (t + 1) % print_every == 0:\n",
        "                avg_loss = total_loss/print_every\n",
        "                print('t = %d, avg_loss = %.4f' % (t + 1, avg_loss) )\n",
        "                avg_loss_list.append(avg_loss)\n",
        "                total_loss = 0\n",
        "                \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        tb.add_scalar('Loss', total_loss, epoch)\n",
        "        #tb.add_scalar('Number of correct', total_correct, epoch)\n",
        "        #tb.add_histogram('', total_, epoch)\n",
        "        \n",
        "        acc = check_accuracy(model_gpu, valid_loader)\n",
        "        print('acc = %f' %(acc))\n",
        "        tb.add_scalar('Accurancy', acc, epoch)\n",
        "            \n",
        "def check_accuracy(model, loader):\n",
        "    print('Checking accuracy on test set')   \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval() \n",
        "    for x, y in loader:\n",
        "        x_var = Variable(x.type(gpu_dtype))\n",
        "\n",
        "        scores = model(x_var)\n",
        "        _, preds = scores.data.cpu().max(1)\n",
        "        num_correct += (preds == y).sum()\n",
        "        num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    acc_list.append(acc)\n",
        "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "    return acc\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggvpMu36Yw2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.size()\n",
        "        return x.view(N, -1)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgmexhBRZAK6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a20aeefd-910c-4ea8-c4d7-69e2b0b2843f"
      },
      "source": [
        "gpu_dtype = torch.cuda.FloatTensor\n",
        "\n",
        "print_every = 1\n",
        "\n",
        "\n",
        "'''\n",
        "Kerv2d\n",
        "kervolution with following options:\n",
        "kernel_type: [linear, polynomial, gaussian, etc.]\n",
        "default is convolution:\n",
        "          kernel_type --> linear,\n",
        "balance, power, gamma is valid only when the kernel_type is specified\n",
        "if learnable_kernel = True,  they just be the initial value of learable parameters\n",
        "if learnable_kernel = False, they are the value of kernel_type's parameter\n",
        "the parameter [power] cannot be learned due to integer limitation\n",
        "dilation (int or tuple, optional): Spacing between kernel\n",
        "elements. Default: 1\n",
        "groups (int, optional): Number of blocked connections from input\n",
        "channels to output channels. Default: 1\n",
        "bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n",
        "kernel_type (str), Default: 'linear'\n",
        "learnable_kernel (bool): Learnable kernel parameters.  Default: False \n",
        "balance: 0, 1\n",
        "power: 3, 4, 5\n",
        "gamma:\n",
        "'''\n",
        "\n",
        "\n",
        "model_base = nn.Sequential( \n",
        "                nn.Kerv2d(in_channels , out_channels_1, padding=padding_1, dilation=1, groups=1, bias=True, \n",
        "                          kernel_type='polynomial', kernel_size=kernel_size, learnable_kernel=True,\n",
        "                          kernel_regularizer=True, stride=1, balance=1, power=3, gamma=1\n",
        "                          ), \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_channels_1),\n",
        "                nn.Conv2d(out_channels_1 , out_channels_2, padding= padding_1, kernel_size=kernel_size, stride=1), \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_channels_2),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_2 , out_channels_3, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_channels_3),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_channels_3 , out_channels_4, padding= padding_1, kernel_size=kernel_size, stride=1),  \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_channels_4),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Dropout(0.5),\n",
        "                Flatten(),\n",
        "                nn.Linear(18432,64),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Linear(64,2)\n",
        "            )\n",
        "model_gpu = model_base.type(gpu_dtype)\n",
        "print(model_gpu)\n",
        "loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) \n",
        "\n",
        "\n",
        "train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs)\n",
        "check_accuracy(model_gpu, valid_loader)\n",
        "\n",
        "#tb.add_graph(model_gpu, images)\n",
        "tb.close()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Kerv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (4): ReLU(inplace=True)\n",
            "  (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (7): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (8): ReLU(inplace=True)\n",
            "  (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (11): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (12): ReLU(inplace=True)\n",
            "  (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (15): Dropout(p=0.5, inplace=False)\n",
            "  (16): Flatten()\n",
            "  (17): Linear(in_features=18432, out_features=64, bias=True)\n",
            "  (18): ReLU(inplace=True)\n",
            "  (19): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n",
            "Starting epoch 1 / 100\n",
            "t = 1, avg_loss = 0.7726\n",
            "t = 2, avg_loss = 0.7346\n",
            "t = 3, avg_loss = 0.7687\n",
            "t = 4, avg_loss = 0.4630\n",
            "t = 5, avg_loss = 0.5264\n",
            "t = 6, avg_loss = 0.5500\n",
            "t = 7, avg_loss = 0.6482\n",
            "t = 8, avg_loss = 0.4975\n",
            "t = 9, avg_loss = 0.4840\n",
            "t = 10, avg_loss = 0.4430\n",
            "t = 11, avg_loss = 0.4298\n",
            "t = 12, avg_loss = 0.5304\n",
            "t = 13, avg_loss = 0.3982\n",
            "t = 14, avg_loss = 0.4608\n",
            "t = 15, avg_loss = 0.3675\n",
            "t = 16, avg_loss = 0.3477\n",
            "t = 17, avg_loss = 0.5237\n",
            "t = 18, avg_loss = 0.5404\n",
            "t = 19, avg_loss = 0.5284\n",
            "t = 20, avg_loss = 0.5428\n",
            "t = 21, avg_loss = 0.3251\n",
            "t = 22, avg_loss = 0.4139\n",
            "t = 23, avg_loss = 0.4415\n",
            "t = 24, avg_loss = 0.4790\n",
            "t = 25, avg_loss = 0.2995\n",
            "Checking accuracy on test set\n",
            "Got 212 / 400 correct (53.00)\n",
            "acc = 0.530000\n",
            "Starting epoch 2 / 100\n",
            "t = 1, avg_loss = 0.2902\n",
            "t = 2, avg_loss = 0.5903\n",
            "t = 3, avg_loss = 0.3608\n",
            "t = 4, avg_loss = 0.3558\n",
            "t = 5, avg_loss = 0.3812\n",
            "t = 6, avg_loss = 0.3090\n",
            "t = 7, avg_loss = 0.3801\n",
            "t = 8, avg_loss = 0.3933\n",
            "t = 9, avg_loss = 0.3681\n",
            "t = 10, avg_loss = 0.3111\n",
            "t = 11, avg_loss = 0.3742\n",
            "t = 12, avg_loss = 0.3636\n",
            "t = 13, avg_loss = 0.2888\n",
            "t = 14, avg_loss = 0.4231\n",
            "t = 15, avg_loss = 0.3421\n",
            "t = 16, avg_loss = 0.4131\n",
            "t = 17, avg_loss = 0.3741\n",
            "t = 18, avg_loss = 0.4470\n",
            "t = 19, avg_loss = 0.3765\n",
            "t = 20, avg_loss = 0.2555\n",
            "t = 21, avg_loss = 0.3745\n",
            "t = 22, avg_loss = 0.2880\n",
            "t = 23, avg_loss = 0.4145\n",
            "t = 24, avg_loss = 0.3313\n",
            "t = 25, avg_loss = 0.3562\n",
            "Checking accuracy on test set\n",
            "Got 334 / 400 correct (83.50)\n",
            "acc = 0.835000\n",
            "Starting epoch 3 / 100\n",
            "t = 1, avg_loss = 0.3050\n",
            "t = 2, avg_loss = 0.3153\n",
            "t = 3, avg_loss = 0.2705\n",
            "t = 4, avg_loss = 0.3223\n",
            "t = 5, avg_loss = 0.3308\n",
            "t = 6, avg_loss = 0.2680\n",
            "t = 7, avg_loss = 0.2560\n",
            "t = 8, avg_loss = 0.2224\n",
            "t = 9, avg_loss = 0.3171\n",
            "t = 10, avg_loss = 0.2838\n",
            "t = 11, avg_loss = 0.2658\n",
            "t = 12, avg_loss = 0.3069\n",
            "t = 13, avg_loss = 0.3062\n",
            "t = 14, avg_loss = 0.2948\n",
            "t = 15, avg_loss = 0.3812\n",
            "t = 16, avg_loss = 0.3713\n",
            "t = 17, avg_loss = 0.3029\n",
            "t = 18, avg_loss = 0.3387\n",
            "t = 19, avg_loss = 0.2936\n",
            "t = 20, avg_loss = 0.3557\n",
            "t = 21, avg_loss = 0.3286\n",
            "t = 22, avg_loss = 0.2211\n",
            "t = 23, avg_loss = 0.4757\n",
            "t = 24, avg_loss = 0.2795\n",
            "t = 25, avg_loss = 0.3559\n",
            "Checking accuracy on test set\n",
            "Got 344 / 400 correct (86.00)\n",
            "acc = 0.860000\n",
            "Starting epoch 4 / 100\n",
            "t = 1, avg_loss = 0.3164\n",
            "t = 2, avg_loss = 0.2837\n",
            "t = 3, avg_loss = 0.2653\n",
            "t = 4, avg_loss = 0.3540\n",
            "t = 5, avg_loss = 0.2243\n",
            "t = 6, avg_loss = 0.4031\n",
            "t = 7, avg_loss = 0.2910\n",
            "t = 8, avg_loss = 0.2472\n",
            "t = 9, avg_loss = 0.2762\n",
            "t = 10, avg_loss = 0.2033\n",
            "t = 11, avg_loss = 0.2035\n",
            "t = 12, avg_loss = 0.3262\n",
            "t = 13, avg_loss = 0.2431\n",
            "t = 14, avg_loss = 0.3106\n",
            "t = 15, avg_loss = 0.3529\n",
            "t = 16, avg_loss = 0.1449\n",
            "t = 17, avg_loss = 0.2830\n",
            "t = 18, avg_loss = 0.3759\n",
            "t = 19, avg_loss = 0.2527\n",
            "t = 20, avg_loss = 0.2565\n",
            "t = 21, avg_loss = 0.1913\n",
            "t = 22, avg_loss = 0.3123\n",
            "t = 23, avg_loss = 0.3975\n",
            "t = 24, avg_loss = 0.3009\n",
            "t = 25, avg_loss = 0.2225\n",
            "Checking accuracy on test set\n",
            "Got 343 / 400 correct (85.75)\n",
            "acc = 0.857500\n",
            "Starting epoch 5 / 100\n",
            "t = 1, avg_loss = 0.1943\n",
            "t = 2, avg_loss = 0.2655\n",
            "t = 3, avg_loss = 0.2624\n",
            "t = 4, avg_loss = 0.2781\n",
            "t = 5, avg_loss = 0.3076\n",
            "t = 6, avg_loss = 0.2698\n",
            "t = 7, avg_loss = 0.3556\n",
            "t = 8, avg_loss = 0.3114\n",
            "t = 9, avg_loss = 0.2519\n",
            "t = 10, avg_loss = 0.3508\n",
            "t = 11, avg_loss = 0.4132\n",
            "t = 12, avg_loss = 0.2635\n",
            "t = 13, avg_loss = 0.2649\n",
            "t = 14, avg_loss = 0.1740\n",
            "t = 15, avg_loss = 0.3120\n",
            "t = 16, avg_loss = 0.1658\n",
            "t = 17, avg_loss = 0.2527\n",
            "t = 18, avg_loss = 0.3057\n",
            "t = 19, avg_loss = 0.2864\n",
            "t = 20, avg_loss = 0.3133\n",
            "t = 21, avg_loss = 0.3447\n",
            "t = 22, avg_loss = 0.2793\n",
            "t = 23, avg_loss = 0.3379\n",
            "t = 24, avg_loss = 0.2386\n",
            "t = 25, avg_loss = 0.2478\n",
            "Checking accuracy on test set\n",
            "Got 332 / 400 correct (83.00)\n",
            "acc = 0.830000\n",
            "Starting epoch 6 / 100\n",
            "t = 1, avg_loss = 0.3384\n",
            "t = 2, avg_loss = 0.2074\n",
            "t = 3, avg_loss = 0.3378\n",
            "t = 4, avg_loss = 0.2936\n",
            "t = 5, avg_loss = 0.2301\n",
            "t = 6, avg_loss = 0.2221\n",
            "t = 7, avg_loss = 0.2989\n",
            "t = 8, avg_loss = 0.1871\n",
            "t = 9, avg_loss = 0.1526\n",
            "t = 10, avg_loss = 0.2379\n",
            "t = 11, avg_loss = 0.2476\n",
            "t = 12, avg_loss = 0.3632\n",
            "t = 13, avg_loss = 0.2754\n",
            "t = 14, avg_loss = 0.3300\n",
            "t = 15, avg_loss = 0.2056\n",
            "t = 16, avg_loss = 0.1410\n",
            "t = 17, avg_loss = 0.2682\n",
            "t = 18, avg_loss = 0.2429\n",
            "t = 19, avg_loss = 0.1440\n",
            "t = 20, avg_loss = 0.2992\n",
            "t = 21, avg_loss = 0.2487\n",
            "t = 22, avg_loss = 0.1554\n",
            "t = 23, avg_loss = 0.2896\n",
            "t = 24, avg_loss = 0.2207\n",
            "t = 25, avg_loss = 0.2474\n",
            "Checking accuracy on test set\n",
            "Got 343 / 400 correct (85.75)\n",
            "acc = 0.857500\n",
            "Starting epoch 7 / 100\n",
            "t = 1, avg_loss = 0.2885\n",
            "t = 2, avg_loss = 0.2346\n",
            "t = 3, avg_loss = 0.1877\n",
            "t = 4, avg_loss = 0.1838\n",
            "t = 5, avg_loss = 0.2464\n",
            "t = 6, avg_loss = 0.2067\n",
            "t = 7, avg_loss = 0.2249\n",
            "t = 8, avg_loss = 0.2363\n",
            "t = 9, avg_loss = 0.1966\n",
            "t = 10, avg_loss = 0.1514\n",
            "t = 11, avg_loss = 0.1916\n",
            "t = 12, avg_loss = 0.2295\n",
            "t = 13, avg_loss = 0.1867\n",
            "t = 14, avg_loss = 0.1978\n",
            "t = 15, avg_loss = 0.1737\n",
            "t = 16, avg_loss = 0.2434\n",
            "t = 17, avg_loss = 0.1950\n",
            "t = 18, avg_loss = 0.1676\n",
            "t = 19, avg_loss = 0.2027\n",
            "t = 20, avg_loss = 0.2813\n",
            "t = 21, avg_loss = 0.2353\n",
            "t = 22, avg_loss = 0.2178\n",
            "t = 23, avg_loss = 0.2132\n",
            "t = 24, avg_loss = 0.2976\n",
            "t = 25, avg_loss = 0.2112\n",
            "Checking accuracy on test set\n",
            "Got 345 / 400 correct (86.25)\n",
            "acc = 0.862500\n",
            "Starting epoch 8 / 100\n",
            "t = 1, avg_loss = 0.1951\n",
            "t = 2, avg_loss = 0.2862\n",
            "t = 3, avg_loss = 0.3805\n",
            "t = 4, avg_loss = 0.2018\n",
            "t = 5, avg_loss = 0.1552\n",
            "t = 6, avg_loss = 0.2264\n",
            "t = 7, avg_loss = 0.1223\n",
            "t = 8, avg_loss = 0.2585\n",
            "t = 9, avg_loss = 0.2597\n",
            "t = 10, avg_loss = 0.2605\n",
            "t = 11, avg_loss = 0.2555\n",
            "t = 12, avg_loss = 0.2390\n",
            "t = 13, avg_loss = 0.2126\n",
            "t = 14, avg_loss = 0.1705\n",
            "t = 15, avg_loss = 0.2368\n",
            "t = 16, avg_loss = 0.2588\n",
            "t = 17, avg_loss = 0.3196\n",
            "t = 18, avg_loss = 0.2263\n",
            "t = 19, avg_loss = 0.2056\n",
            "t = 20, avg_loss = 0.2189\n",
            "t = 21, avg_loss = 0.1081\n",
            "t = 22, avg_loss = 0.1753\n",
            "t = 23, avg_loss = 0.1075\n",
            "t = 24, avg_loss = 0.1969\n",
            "t = 25, avg_loss = 0.2932\n",
            "Checking accuracy on test set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 9 / 100\n",
            "t = 1, avg_loss = 0.1841\n",
            "t = 2, avg_loss = 0.1295\n",
            "t = 3, avg_loss = 0.2668\n",
            "t = 4, avg_loss = 0.1587\n",
            "t = 5, avg_loss = 0.1209\n",
            "t = 6, avg_loss = 0.1898\n",
            "t = 7, avg_loss = 0.1169\n",
            "t = 8, avg_loss = 0.1968\n",
            "t = 9, avg_loss = 0.1435\n",
            "t = 10, avg_loss = 0.1722\n",
            "t = 11, avg_loss = 0.2918\n",
            "t = 12, avg_loss = 0.2167\n",
            "t = 13, avg_loss = 0.1625\n",
            "t = 14, avg_loss = 0.2093\n",
            "t = 15, avg_loss = 0.3558\n",
            "t = 16, avg_loss = 0.1478\n",
            "t = 17, avg_loss = 0.1649\n",
            "t = 18, avg_loss = 0.2080\n",
            "t = 19, avg_loss = 0.3324\n",
            "t = 20, avg_loss = 0.2418\n",
            "t = 21, avg_loss = 0.1805\n",
            "t = 22, avg_loss = 0.1303\n",
            "t = 23, avg_loss = 0.1140\n",
            "t = 24, avg_loss = 0.1808\n",
            "t = 25, avg_loss = 0.1147\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 10 / 100\n",
            "t = 1, avg_loss = 0.2283\n",
            "t = 2, avg_loss = 0.3133\n",
            "t = 3, avg_loss = 0.2625\n",
            "t = 4, avg_loss = 0.1322\n",
            "t = 5, avg_loss = 0.1850\n",
            "t = 6, avg_loss = 0.0882\n",
            "t = 7, avg_loss = 0.1174\n",
            "t = 8, avg_loss = 0.2240\n",
            "t = 9, avg_loss = 0.2286\n",
            "t = 10, avg_loss = 0.0806\n",
            "t = 11, avg_loss = 0.1962\n",
            "t = 12, avg_loss = 0.2144\n",
            "t = 13, avg_loss = 0.1579\n",
            "t = 14, avg_loss = 0.1000\n",
            "t = 15, avg_loss = 0.1396\n",
            "t = 16, avg_loss = 0.1746\n",
            "t = 17, avg_loss = 0.2887\n",
            "t = 18, avg_loss = 0.1262\n",
            "t = 19, avg_loss = 0.1743\n",
            "t = 20, avg_loss = 0.1645\n",
            "t = 21, avg_loss = 0.1065\n",
            "t = 22, avg_loss = 0.1313\n",
            "t = 23, avg_loss = 0.2323\n",
            "t = 24, avg_loss = 0.1216\n",
            "t = 25, avg_loss = 0.2027\n",
            "Checking accuracy on test set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 11 / 100\n",
            "t = 1, avg_loss = 0.1233\n",
            "t = 2, avg_loss = 0.2433\n",
            "t = 3, avg_loss = 0.1786\n",
            "t = 4, avg_loss = 0.1600\n",
            "t = 5, avg_loss = 0.1490\n",
            "t = 6, avg_loss = 0.1008\n",
            "t = 7, avg_loss = 0.0741\n",
            "t = 8, avg_loss = 0.1834\n",
            "t = 9, avg_loss = 0.0879\n",
            "t = 10, avg_loss = 0.1696\n",
            "t = 11, avg_loss = 0.2436\n",
            "t = 12, avg_loss = 0.1497\n",
            "t = 13, avg_loss = 0.1873\n",
            "t = 14, avg_loss = 0.1671\n",
            "t = 15, avg_loss = 0.3757\n",
            "t = 16, avg_loss = 0.1421\n",
            "t = 17, avg_loss = 0.2353\n",
            "t = 18, avg_loss = 0.1569\n",
            "t = 19, avg_loss = 0.1116\n",
            "t = 20, avg_loss = 0.2738\n",
            "t = 21, avg_loss = 0.1906\n",
            "t = 22, avg_loss = 0.1822\n",
            "t = 23, avg_loss = 0.1581\n",
            "t = 24, avg_loss = 0.1257\n",
            "t = 25, avg_loss = 0.2089\n",
            "Checking accuracy on test set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 12 / 100\n",
            "t = 1, avg_loss = 0.1686\n",
            "t = 2, avg_loss = 0.1703\n",
            "t = 3, avg_loss = 0.1133\n",
            "t = 4, avg_loss = 0.0885\n",
            "t = 5, avg_loss = 0.1359\n",
            "t = 6, avg_loss = 0.1346\n",
            "t = 7, avg_loss = 0.1402\n",
            "t = 8, avg_loss = 0.2221\n",
            "t = 9, avg_loss = 0.1584\n",
            "t = 10, avg_loss = 0.1829\n",
            "t = 11, avg_loss = 0.1116\n",
            "t = 12, avg_loss = 0.1466\n",
            "t = 13, avg_loss = 0.2466\n",
            "t = 14, avg_loss = 0.1178\n",
            "t = 15, avg_loss = 0.1410\n",
            "t = 16, avg_loss = 0.1399\n",
            "t = 17, avg_loss = 0.2037\n",
            "t = 18, avg_loss = 0.1338\n",
            "t = 19, avg_loss = 0.1662\n",
            "t = 20, avg_loss = 0.1922\n",
            "t = 21, avg_loss = 0.2320\n",
            "t = 22, avg_loss = 0.2337\n",
            "t = 23, avg_loss = 0.1197\n",
            "t = 24, avg_loss = 0.2397\n",
            "t = 25, avg_loss = 0.1930\n",
            "Checking accuracy on test set\n",
            "Got 345 / 400 correct (86.25)\n",
            "acc = 0.862500\n",
            "Starting epoch 13 / 100\n",
            "t = 1, avg_loss = 0.1263\n",
            "t = 2, avg_loss = 0.1326\n",
            "t = 3, avg_loss = 0.1347\n",
            "t = 4, avg_loss = 0.1493\n",
            "t = 5, avg_loss = 0.1096\n",
            "t = 6, avg_loss = 0.2231\n",
            "t = 7, avg_loss = 0.0797\n",
            "t = 8, avg_loss = 0.1735\n",
            "t = 9, avg_loss = 0.2362\n",
            "t = 10, avg_loss = 0.1555\n",
            "t = 11, avg_loss = 0.1085\n",
            "t = 12, avg_loss = 0.1365\n",
            "t = 13, avg_loss = 0.1665\n",
            "t = 14, avg_loss = 0.1414\n",
            "t = 15, avg_loss = 0.1334\n",
            "t = 16, avg_loss = 0.1185\n",
            "t = 17, avg_loss = 0.1282\n",
            "t = 18, avg_loss = 0.1812\n",
            "t = 19, avg_loss = 0.1023\n",
            "t = 20, avg_loss = 0.1999\n",
            "t = 21, avg_loss = 0.2610\n",
            "t = 22, avg_loss = 0.1590\n",
            "t = 23, avg_loss = 0.0819\n",
            "t = 24, avg_loss = 0.0689\n",
            "t = 25, avg_loss = 0.2242\n",
            "Checking accuracy on test set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 14 / 100\n",
            "t = 1, avg_loss = 0.1266\n",
            "t = 2, avg_loss = 0.1393\n",
            "t = 3, avg_loss = 0.1364\n",
            "t = 4, avg_loss = 0.0811\n",
            "t = 5, avg_loss = 0.2311\n",
            "t = 6, avg_loss = 0.1661\n",
            "t = 7, avg_loss = 0.1473\n",
            "t = 8, avg_loss = 0.2113\n",
            "t = 9, avg_loss = 0.0505\n",
            "t = 10, avg_loss = 0.1791\n",
            "t = 11, avg_loss = 0.1237\n",
            "t = 12, avg_loss = 0.1174\n",
            "t = 13, avg_loss = 0.1219\n",
            "t = 14, avg_loss = 0.1676\n",
            "t = 15, avg_loss = 0.1369\n",
            "t = 16, avg_loss = 0.0995\n",
            "t = 17, avg_loss = 0.0760\n",
            "t = 18, avg_loss = 0.1310\n",
            "t = 19, avg_loss = 0.1919\n",
            "t = 20, avg_loss = 0.1143\n",
            "t = 21, avg_loss = 0.1027\n",
            "t = 22, avg_loss = 0.1706\n",
            "t = 23, avg_loss = 0.1707\n",
            "t = 24, avg_loss = 0.1901\n",
            "t = 25, avg_loss = 0.1232\n",
            "Checking accuracy on test set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 15 / 100\n",
            "t = 1, avg_loss = 0.1763\n",
            "t = 2, avg_loss = 0.0660\n",
            "t = 3, avg_loss = 0.1246\n",
            "t = 4, avg_loss = 0.0729\n",
            "t = 5, avg_loss = 0.1289\n",
            "t = 6, avg_loss = 0.1199\n",
            "t = 7, avg_loss = 0.1229\n",
            "t = 8, avg_loss = 0.0722\n",
            "t = 9, avg_loss = 0.1924\n",
            "t = 10, avg_loss = 0.1880\n",
            "t = 11, avg_loss = 0.2494\n",
            "t = 12, avg_loss = 0.1397\n",
            "t = 13, avg_loss = 0.0751\n",
            "t = 14, avg_loss = 0.1930\n",
            "t = 15, avg_loss = 0.0536\n",
            "t = 16, avg_loss = 0.1471\n",
            "t = 17, avg_loss = 0.0903\n",
            "t = 18, avg_loss = 0.1435\n",
            "t = 19, avg_loss = 0.1070\n",
            "t = 20, avg_loss = 0.1702\n",
            "t = 21, avg_loss = 0.2083\n",
            "t = 22, avg_loss = 0.1447\n",
            "t = 23, avg_loss = 0.1724\n",
            "t = 24, avg_loss = 0.1787\n",
            "t = 25, avg_loss = 0.1232\n",
            "Checking accuracy on test set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 16 / 100\n",
            "t = 1, avg_loss = 0.0676\n",
            "t = 2, avg_loss = 0.0837\n",
            "t = 3, avg_loss = 0.1289\n",
            "t = 4, avg_loss = 0.1471\n",
            "t = 5, avg_loss = 0.0795\n",
            "t = 6, avg_loss = 0.1702\n",
            "t = 7, avg_loss = 0.0867\n",
            "t = 8, avg_loss = 0.2085\n",
            "t = 9, avg_loss = 0.1663\n",
            "t = 10, avg_loss = 0.0983\n",
            "t = 11, avg_loss = 0.2599\n",
            "t = 12, avg_loss = 0.0731\n",
            "t = 13, avg_loss = 0.1098\n",
            "t = 14, avg_loss = 0.0798\n",
            "t = 15, avg_loss = 0.1672\n",
            "t = 16, avg_loss = 0.1024\n",
            "t = 17, avg_loss = 0.1602\n",
            "t = 18, avg_loss = 0.1101\n",
            "t = 19, avg_loss = 0.1928\n",
            "t = 20, avg_loss = 0.1283\n",
            "t = 21, avg_loss = 0.1233\n",
            "t = 22, avg_loss = 0.1823\n",
            "t = 23, avg_loss = 0.1804\n",
            "t = 24, avg_loss = 0.0903\n",
            "t = 25, avg_loss = 0.1285\n",
            "Checking accuracy on test set\n",
            "Got 345 / 400 correct (86.25)\n",
            "acc = 0.862500\n",
            "Starting epoch 17 / 100\n",
            "t = 1, avg_loss = 0.1450\n",
            "t = 2, avg_loss = 0.2318\n",
            "t = 3, avg_loss = 0.0645\n",
            "t = 4, avg_loss = 0.1297\n",
            "t = 5, avg_loss = 0.1988\n",
            "t = 6, avg_loss = 0.0816\n",
            "t = 7, avg_loss = 0.0629\n",
            "t = 8, avg_loss = 0.1213\n",
            "t = 9, avg_loss = 0.1319\n",
            "t = 10, avg_loss = 0.0847\n",
            "t = 11, avg_loss = 0.2330\n",
            "t = 12, avg_loss = 0.2199\n",
            "t = 13, avg_loss = 0.0903\n",
            "t = 14, avg_loss = 0.1232\n",
            "t = 15, avg_loss = 0.1304\n",
            "t = 16, avg_loss = 0.1773\n",
            "t = 17, avg_loss = 0.1580\n",
            "t = 18, avg_loss = 0.0947\n",
            "t = 19, avg_loss = 0.0938\n",
            "t = 20, avg_loss = 0.1596\n",
            "t = 21, avg_loss = 0.1601\n",
            "t = 22, avg_loss = 0.1334\n",
            "t = 23, avg_loss = 0.1214\n",
            "t = 24, avg_loss = 0.1043\n",
            "t = 25, avg_loss = 0.1580\n",
            "Checking accuracy on test set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 18 / 100\n",
            "t = 1, avg_loss = 0.0840\n",
            "t = 2, avg_loss = 0.0602\n",
            "t = 3, avg_loss = 0.1804\n",
            "t = 4, avg_loss = 0.0726\n",
            "t = 5, avg_loss = 0.1568\n",
            "t = 6, avg_loss = 0.0908\n",
            "t = 7, avg_loss = 0.1820\n",
            "t = 8, avg_loss = 0.0947\n",
            "t = 9, avg_loss = 0.0947\n",
            "t = 10, avg_loss = 0.1873\n",
            "t = 11, avg_loss = 0.0899\n",
            "t = 12, avg_loss = 0.1429\n",
            "t = 13, avg_loss = 0.0552\n",
            "t = 14, avg_loss = 0.1294\n",
            "t = 15, avg_loss = 0.1200\n",
            "t = 16, avg_loss = 0.1382\n",
            "t = 17, avg_loss = 0.2018\n",
            "t = 18, avg_loss = 0.1687\n",
            "t = 19, avg_loss = 0.1319\n",
            "t = 20, avg_loss = 0.1133\n",
            "t = 21, avg_loss = 0.1965\n",
            "t = 22, avg_loss = 0.1328\n",
            "t = 23, avg_loss = 0.0881\n",
            "t = 24, avg_loss = 0.1082\n",
            "t = 25, avg_loss = 0.1772\n",
            "Checking accuracy on test set\n",
            "Got 344 / 400 correct (86.00)\n",
            "acc = 0.860000\n",
            "Starting epoch 19 / 100\n",
            "t = 1, avg_loss = 0.0370\n",
            "t = 2, avg_loss = 0.1824\n",
            "t = 3, avg_loss = 0.1720\n",
            "t = 4, avg_loss = 0.1092\n",
            "t = 5, avg_loss = 0.0577\n",
            "t = 6, avg_loss = 0.0553\n",
            "t = 7, avg_loss = 0.1485\n",
            "t = 8, avg_loss = 0.1606\n",
            "t = 9, avg_loss = 0.1231\n",
            "t = 10, avg_loss = 0.1015\n",
            "t = 11, avg_loss = 0.1175\n",
            "t = 12, avg_loss = 0.0752\n",
            "t = 13, avg_loss = 0.1313\n",
            "t = 14, avg_loss = 0.0999\n",
            "t = 15, avg_loss = 0.0930\n",
            "t = 16, avg_loss = 0.1064\n",
            "t = 17, avg_loss = 0.0694\n",
            "t = 18, avg_loss = 0.1000\n",
            "t = 19, avg_loss = 0.1243\n",
            "t = 20, avg_loss = 0.1120\n",
            "t = 21, avg_loss = 0.1369\n",
            "t = 22, avg_loss = 0.1186\n",
            "t = 23, avg_loss = 0.0880\n",
            "t = 24, avg_loss = 0.0956\n",
            "t = 25, avg_loss = 0.1901\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 20 / 100\n",
            "t = 1, avg_loss = 0.1295\n",
            "t = 2, avg_loss = 0.1081\n",
            "t = 3, avg_loss = 0.0860\n",
            "t = 4, avg_loss = 0.0459\n",
            "t = 5, avg_loss = 0.1364\n",
            "t = 6, avg_loss = 0.0677\n",
            "t = 7, avg_loss = 0.0822\n",
            "t = 8, avg_loss = 0.1738\n",
            "t = 9, avg_loss = 0.0903\n",
            "t = 10, avg_loss = 0.1298\n",
            "t = 11, avg_loss = 0.0746\n",
            "t = 12, avg_loss = 0.0689\n",
            "t = 13, avg_loss = 0.0974\n",
            "t = 14, avg_loss = 0.0608\n",
            "t = 15, avg_loss = 0.0814\n",
            "t = 16, avg_loss = 0.1115\n",
            "t = 17, avg_loss = 0.1915\n",
            "t = 18, avg_loss = 0.1049\n",
            "t = 19, avg_loss = 0.1397\n",
            "t = 20, avg_loss = 0.1513\n",
            "t = 21, avg_loss = 0.0909\n",
            "t = 22, avg_loss = 0.1384\n",
            "t = 23, avg_loss = 0.0710\n",
            "t = 24, avg_loss = 0.1338\n",
            "t = 25, avg_loss = 0.1563\n",
            "Checking accuracy on test set\n",
            "Got 345 / 400 correct (86.25)\n",
            "acc = 0.862500\n",
            "Starting epoch 21 / 100\n",
            "t = 1, avg_loss = 0.0952\n",
            "t = 2, avg_loss = 0.1489\n",
            "t = 3, avg_loss = 0.1300\n",
            "t = 4, avg_loss = 0.1236\n",
            "t = 5, avg_loss = 0.0750\n",
            "t = 6, avg_loss = 0.0878\n",
            "t = 7, avg_loss = 0.1323\n",
            "t = 8, avg_loss = 0.0592\n",
            "t = 9, avg_loss = 0.1264\n",
            "t = 10, avg_loss = 0.1579\n",
            "t = 11, avg_loss = 0.1397\n",
            "t = 12, avg_loss = 0.1263\n",
            "t = 13, avg_loss = 0.0697\n",
            "t = 14, avg_loss = 0.0885\n",
            "t = 15, avg_loss = 0.1190\n",
            "t = 16, avg_loss = 0.0515\n",
            "t = 17, avg_loss = 0.1909\n",
            "t = 18, avg_loss = 0.0786\n",
            "t = 19, avg_loss = 0.1053\n",
            "t = 20, avg_loss = 0.1198\n",
            "t = 21, avg_loss = 0.0851\n",
            "t = 22, avg_loss = 0.0338\n",
            "t = 23, avg_loss = 0.1409\n",
            "t = 24, avg_loss = 0.0497\n",
            "t = 25, avg_loss = 0.1265\n",
            "Checking accuracy on test set\n",
            "Got 346 / 400 correct (86.50)\n",
            "acc = 0.865000\n",
            "Starting epoch 22 / 100\n",
            "t = 1, avg_loss = 0.0561\n",
            "t = 2, avg_loss = 0.0391\n",
            "t = 3, avg_loss = 0.0879\n",
            "t = 4, avg_loss = 0.1210\n",
            "t = 5, avg_loss = 0.0976\n",
            "t = 6, avg_loss = 0.0515\n",
            "t = 7, avg_loss = 0.1284\n",
            "t = 8, avg_loss = 0.0565\n",
            "t = 9, avg_loss = 0.1425\n",
            "t = 10, avg_loss = 0.0800\n",
            "t = 11, avg_loss = 0.0647\n",
            "t = 12, avg_loss = 0.0637\n",
            "t = 13, avg_loss = 0.1114\n",
            "t = 14, avg_loss = 0.1552\n",
            "t = 15, avg_loss = 0.0882\n",
            "t = 16, avg_loss = 0.1078\n",
            "t = 17, avg_loss = 0.1082\n",
            "t = 18, avg_loss = 0.0676\n",
            "t = 19, avg_loss = 0.1726\n",
            "t = 20, avg_loss = 0.0702\n",
            "t = 21, avg_loss = 0.1381\n",
            "t = 22, avg_loss = 0.0499\n",
            "t = 23, avg_loss = 0.0552\n",
            "t = 24, avg_loss = 0.1124\n",
            "t = 25, avg_loss = 0.0659\n",
            "Checking accuracy on test set\n",
            "Got 345 / 400 correct (86.25)\n",
            "acc = 0.862500\n",
            "Starting epoch 23 / 100\n",
            "t = 1, avg_loss = 0.0893\n",
            "t = 2, avg_loss = 0.0726\n",
            "t = 3, avg_loss = 0.0754\n",
            "t = 4, avg_loss = 0.1137\n",
            "t = 5, avg_loss = 0.0715\n",
            "t = 6, avg_loss = 0.0522\n",
            "t = 7, avg_loss = 0.0778\n",
            "t = 8, avg_loss = 0.1666\n",
            "t = 9, avg_loss = 0.0534\n",
            "t = 10, avg_loss = 0.1049\n",
            "t = 11, avg_loss = 0.0522\n",
            "t = 12, avg_loss = 0.0988\n",
            "t = 13, avg_loss = 0.1097\n",
            "t = 14, avg_loss = 0.1370\n",
            "t = 15, avg_loss = 0.1261\n",
            "t = 16, avg_loss = 0.1032\n",
            "t = 17, avg_loss = 0.0676\n",
            "t = 18, avg_loss = 0.0530\n",
            "t = 19, avg_loss = 0.0877\n",
            "t = 20, avg_loss = 0.1220\n",
            "t = 21, avg_loss = 0.1818\n",
            "t = 22, avg_loss = 0.0866\n",
            "t = 23, avg_loss = 0.1209\n",
            "t = 24, avg_loss = 0.0844\n",
            "t = 25, avg_loss = 0.1204\n",
            "Checking accuracy on test set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 24 / 100\n",
            "t = 1, avg_loss = 0.0628\n",
            "t = 2, avg_loss = 0.0787\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-9f4b714bb202>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0mcheck_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-460fe8ab2743>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, loss_fn, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mx_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0my_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-50a9cd504daf>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m           \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"malignant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"malignant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \"\"\"\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   1856\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1858\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreducing_gap\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresample\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mNEAREST\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDn-2g-TLY3k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "22793986-9cba-4f07-bc89-bf36e3b00f87"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot([print_every*batch_size*(i+1) for i in range((len(avg_loss_list)))],avg_loss_list)\n",
        "print(\"Loss:\")\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD6CAYAAACxrrxPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGer6hJv7-zR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "b64c6806-99c2-4aa4-fa7c-8ffd9ae6f903"
      },
      "source": [
        "plt.plot([i+1 for i in range((len(acc_list)))],acc_list)\n",
        "print(\"Accurancy:\")\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accurancy:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBTReWHxz4Ml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}