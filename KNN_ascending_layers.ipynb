{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN_ascending_layers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO3yzzNvP9dtldDx9Bgw70S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamilo116/KNN/blob/master/KNN_ascending_layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7ReM7FU-xs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import sys\n",
        "from random import shuffle\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms as transforms\n",
        "import timeit\n",
        "\n",
        "np.random.seed(4) \n",
        "torch.manual_seed(4) \n",
        "torch.cuda.manual_seed(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYIMZ8QyYewD",
        "colab_type": "code",
        "outputId": "f8705c0b-384c-45da-996a-2e11e96ae21b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "! git clone https://github.com/wang-chen/kervolution.git \n",
        "\n",
        "sys.path.append(\"kervolution/\")\n",
        "from kervolution import Kerv2d\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'kervolution'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 53 (delta 2), reused 0 (delta 0), pack-reused 47\u001b[K\n",
            "Unpacking objects: 100% (53/53), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvbKg4VJXKY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LIMIT_IMAGES_NUM = 1000\n",
        "train_test_split_size = 0.2\n",
        "image_resize = (100, 100)\n",
        "batch_size = 64\n",
        "num_workers = 0\n",
        "\n",
        "out_1 = 16\n",
        "out_2 = 32\n",
        "out_3 = 64\n",
        "out_4 = 128\n",
        "\n",
        "\n",
        "k_size_1 = 3\n",
        "padding_1 = 1\n",
        "in_channels = 3\n",
        "\n",
        "kernel_size = 3\n",
        "num_epochs = 100\n",
        "\n",
        "learning_rate = 0.0001\n",
        "weight_decay = 0.1\n",
        "\n",
        "MALIGNANT_DATASET = '/content/drive/My Drive/Colab_data/malignant/malignant/'\n",
        "BENIGN_DATASET = '/content/drive/My Drive/Colab_data/benign/benign/'\n",
        "DATA_FOLDER = '/content/drive/My Drive/Colab_data/'\n",
        "model_backup_path = os.path.join(DATA_FOLDER, 'backup_model') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMOHez_kHZD6",
        "colab_type": "code",
        "outputId": "3702dde4-173f-41e2-9d5d-c0101538cbb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b8P1NdXfVdX",
        "colab_type": "code",
        "outputId": "38ed67ee-212f-47b3-aa1f-3b60cddcf81f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "benign_file_list = sorted(os.listdir(BENIGN_DATASET))\n",
        "malignant_file_list = sorted(os.listdir(MALIGNANT_DATASET))\n",
        "shuffle(benign_file_list)\n",
        "shuffle(malignant_file_list)\n",
        "benign_file_list = benign_file_list[:LIMIT_IMAGES_NUM]\n",
        "malignant_file_list = malignant_file_list[:LIMIT_IMAGES_NUM]\n",
        "\n",
        "print(f\"Number of benign {len(benign_file_list)} images\")\n",
        "print(f\"Number of malignant {len(malignant_file_list)} images\")\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize(image_resize),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of benign 1000 images\n",
            "Number of malignant 1000 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGDQfal74BLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "benign_dict = {filename: 0 for filename in benign_file_list}\n",
        "malignant_dict = {filename: 1 for filename in malignant_file_list}\n",
        "img_class_dict = {**benign_dict , **malignant_dict}\n",
        "labeled_data = pd.Series(img_class_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvAAOqmVfVll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IsicDataset(Dataset):\n",
        "    def __init__(self, data_folder, labeled_data, \n",
        "                 transform=transforms.Compose([transforms.ToTensor()])):\n",
        "        self.labeled_data = labeled_data\n",
        "        self.transform = transform\n",
        "        self.data_folder = data_folder\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labeled_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        label = self.labeled_data[index]\n",
        "        if label == 0:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"benign\", \"benign\", index ))\n",
        "        else:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"malignant\", \"malignant\", index ))\n",
        "        image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "    @property\n",
        "    def labels(self):\n",
        "      return self.labeled_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSuYqjLAYrWA",
        "colab_type": "code",
        "outputId": "820bf7f6-14d7-42bc-b407-53067ab7896f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "dataset = IsicDataset(DATA_FOLDER, labeled_data, transform=data_transforms)\n",
        "print(dataset.labels)\n",
        "\n",
        "X_train, X_test = train_test_split(dataset.labels, test_size=train_test_split_size)\n",
        "print(\"number of training data: \",len(X_train))\n",
        "print(\"number of testing  data: \",len(X_test))\n",
        "\n",
        "train_sampler = SubsetRandomSampler(list(X_train.index))\n",
        "valid_sampler = SubsetRandomSampler(list(X_test.index))\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ISIC_0000109.jpeg    0\n",
            "ISIC_0001233.jpeg    0\n",
            "ISIC_0000704.jpeg    0\n",
            "ISIC_0001440.jpeg    0\n",
            "ISIC_0000679.jpeg    0\n",
            "                    ..\n",
            "ISIC_0010411.jpeg    1\n",
            "ISIC_0010690.jpeg    1\n",
            "ISIC_0013832.jpeg    1\n",
            "ISIC_0011435.jpeg    1\n",
            "ISIC_0010792.jpeg    1\n",
            "Length: 2000, dtype: int64\n",
            "number of training data:  1600\n",
            "number of testing  data:  400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e8nFBR6Yug5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "def train(model, train_loader ,loss_fn, optimizer, num_epochs=1, starting_from_epoch=1):\n",
        "    total_loss =0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
        "        model.train()\n",
        "\n",
        "        for t, (x, y) in enumerate(train_loader):\n",
        "            x_var = Variable(x.type(gpu_dtype))\n",
        "            y_var = Variable(y.type(gpu_dtype).long())\n",
        "            scores = model(x_var)\n",
        "            loss = loss_fn(scores, y_var)\n",
        "            total_loss += loss.data\n",
        "            \n",
        "            if (t + 1) % print_every == 0:\n",
        "                avg_loss = total_loss/print_every\n",
        "                print('t = %d, avg_loss = %.4f' % (t + 1, avg_loss) )\n",
        "                avg_loss_list.append(avg_loss)\n",
        "                total_loss = 0\n",
        "                \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        acc = check_accuracy(model_gpu, valid_loader)\n",
        "        print('acc = %f' %(acc))\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model_gpu.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            'acc_list': acc_list,\n",
        "            }, model_backup_path)\n",
        "            \n",
        "def check_accuracy(model, loader):\n",
        "    print('Checking accuracy on test set')   \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval() \n",
        "    for x, y in loader:\n",
        "        x_var = Variable(x.type(gpu_dtype))\n",
        "\n",
        "        scores = model(x_var)\n",
        "        _, preds = scores.data.cpu().max(1)\n",
        "        num_correct += (preds == y).sum()\n",
        "        num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    acc_list.append(acc)\n",
        "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "    return acc\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggvpMu36Yw2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.size()\n",
        "        return x.view(N, -1)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-gYHw0Jlbwt",
        "colab_type": "code",
        "outputId": "17625fdc-10df-4710-ad84-400468ff454f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "print_every = 2\n",
        "gpu_dtype = torch.cuda.FloatTensor\n",
        "\n",
        "\n",
        "'''\n",
        "Kerv2d\n",
        "kervolution with following options:\n",
        "kernel_type: [linear, polynomial, gaussian, etc.]\n",
        "default is convolution:\n",
        "          kernel_type --> linear,\n",
        "balance, power, gamma is valid only when the kernel_type is specified\n",
        "if learnable_kernel = True,  they just be the initial value of learable parameters\n",
        "if learnable_kernel = False, they are the value of kernel_type's parameter\n",
        "the parameter [power] cannot be learned due to integer limitation\n",
        "dilation (int or tuple, optional): Spacing between kernel\n",
        "elements. Default: 1\n",
        "groups (int, optional): Number of blocked connections from input\n",
        "channels to output channels. Default: 1\n",
        "bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n",
        "kernel_type (str), Default: 'linear'\n",
        "learnable_kernel (bool): Learnable kernel parameters.  Default: False \n",
        "balance: 0, 1\n",
        "power: 3, 4, 5\n",
        "gamma:\n",
        "'''\n",
        "\n",
        "\n",
        "model_base = nn.Sequential( \n",
        "                nn.Conv2d(in_channels , out_1, padding= padding_1, kernel_size=k_size_1, stride=1),\n",
        "                #nn.Kerv2d(in_channels , out_1, padding=padding_1, dilation=1, groups=1, bias=True, \n",
        "                #          kernel_type='polynomial', kernel_size=k_size_1,# learnable_kernel=True,\n",
        "                          #kernel_regularizer=True, stride=1, balance=1, power=3, gamma=1\n",
        "                #          ), \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_1),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_1 , out_2, padding= padding_1, kernel_size=k_size_1, stride=1), \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_2),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_2 , out_3, padding= padding_1, kernel_size=k_size_1, stride=1),  \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_3),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_3 , out_4, padding= padding_1, kernel_size=k_size_1, stride=1),  \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_4),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Dropout(0.5),\n",
        "                Flatten(),\n",
        "                nn.Linear(4608,64),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Linear(64,2)\n",
        "            )\n",
        "model_gpu = model_base.type(gpu_dtype)\n",
        "print(model_gpu)\n",
        "loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (4): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (5): ReLU(inplace=True)\n",
            "  (6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (8): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (9): ReLU(inplace=True)\n",
            "  (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (12): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (13): ReLU(inplace=True)\n",
            "  (14): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (16): Dropout(p=0.5, inplace=False)\n",
            "  (17): Flatten()\n",
            "  (18): Linear(in_features=4608, out_features=64, bias=True)\n",
            "  (19): ReLU(inplace=True)\n",
            "  (20): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgmexhBRZAK6",
        "colab_type": "code",
        "outputId": "9d42bdb6-48d0-4e6d-b858-15f20733a7ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs)\n",
        "check_accuracy(model_gpu, valid_loader)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 1 / 100\n",
            "t = 2, avg_loss = 0.6760\n",
            "t = 4, avg_loss = 0.5546\n",
            "t = 6, avg_loss = 0.5861\n",
            "t = 8, avg_loss = 0.5478\n",
            "t = 10, avg_loss = 0.6104\n",
            "t = 12, avg_loss = 0.5011\n",
            "t = 14, avg_loss = 0.5259\n",
            "t = 16, avg_loss = 0.4778\n",
            "t = 18, avg_loss = 0.5158\n",
            "t = 20, avg_loss = 0.3681\n",
            "t = 22, avg_loss = 0.5108\n",
            "t = 24, avg_loss = 0.4529\n",
            "Checking accuracy on test set\n",
            "Got 204 / 400 correct (51.00)\n",
            "acc = 0.510000\n",
            "Starting epoch 2 / 100\n",
            "t = 2, avg_loss = 0.6689\n",
            "t = 4, avg_loss = 0.3422\n",
            "t = 6, avg_loss = 0.4320\n",
            "t = 8, avg_loss = 0.4015\n",
            "t = 10, avg_loss = 0.3803\n",
            "t = 12, avg_loss = 0.4154\n",
            "t = 14, avg_loss = 0.5303\n",
            "t = 16, avg_loss = 0.4806\n",
            "t = 18, avg_loss = 0.3942\n",
            "t = 20, avg_loss = 0.3927\n",
            "t = 22, avg_loss = 0.3306\n",
            "t = 24, avg_loss = 0.4378\n",
            "Checking accuracy on test set\n",
            "Got 246 / 400 correct (61.50)\n",
            "acc = 0.615000\n",
            "Starting epoch 3 / 100\n",
            "t = 2, avg_loss = 0.5208\n",
            "t = 4, avg_loss = 0.4133\n",
            "t = 6, avg_loss = 0.3375\n",
            "t = 8, avg_loss = 0.3528\n",
            "t = 10, avg_loss = 0.3247\n",
            "t = 12, avg_loss = 0.3517\n",
            "t = 14, avg_loss = 0.3761\n",
            "t = 16, avg_loss = 0.4075\n",
            "t = 18, avg_loss = 0.3827\n",
            "t = 20, avg_loss = 0.3649\n",
            "t = 22, avg_loss = 0.3888\n",
            "t = 24, avg_loss = 0.3838\n",
            "Checking accuracy on test set\n",
            "Got 334 / 400 correct (83.50)\n",
            "acc = 0.835000\n",
            "Starting epoch 4 / 100\n",
            "t = 2, avg_loss = 0.5208\n",
            "t = 4, avg_loss = 0.3251\n",
            "t = 6, avg_loss = 0.3914\n",
            "t = 8, avg_loss = 0.2848\n",
            "t = 10, avg_loss = 0.3687\n",
            "t = 12, avg_loss = 0.3643\n",
            "t = 14, avg_loss = 0.3553\n",
            "t = 16, avg_loss = 0.3733\n",
            "t = 18, avg_loss = 0.3870\n",
            "t = 20, avg_loss = 0.3195\n",
            "t = 22, avg_loss = 0.3591\n",
            "t = 24, avg_loss = 0.3555\n",
            "Checking accuracy on test set\n",
            "Got 335 / 400 correct (83.75)\n",
            "acc = 0.837500\n",
            "Starting epoch 5 / 100\n",
            "t = 2, avg_loss = 0.5170\n",
            "t = 4, avg_loss = 0.4431\n",
            "t = 6, avg_loss = 0.4113\n",
            "t = 8, avg_loss = 0.3424\n",
            "t = 10, avg_loss = 0.3046\n",
            "t = 12, avg_loss = 0.4028\n",
            "t = 14, avg_loss = 0.2723\n",
            "t = 16, avg_loss = 0.3581\n",
            "t = 18, avg_loss = 0.3984\n",
            "t = 20, avg_loss = 0.2854\n",
            "t = 22, avg_loss = 0.2510\n",
            "t = 24, avg_loss = 0.2817\n",
            "Checking accuracy on test set\n",
            "Got 345 / 400 correct (86.25)\n",
            "acc = 0.862500\n",
            "Starting epoch 6 / 100\n",
            "t = 2, avg_loss = 0.5795\n",
            "t = 4, avg_loss = 0.3360\n",
            "t = 6, avg_loss = 0.2580\n",
            "t = 8, avg_loss = 0.2846\n",
            "t = 10, avg_loss = 0.3244\n",
            "t = 12, avg_loss = 0.2886\n",
            "t = 14, avg_loss = 0.3487\n",
            "t = 16, avg_loss = 0.3426\n",
            "t = 18, avg_loss = 0.2817\n",
            "t = 20, avg_loss = 0.2967\n",
            "t = 22, avg_loss = 0.4363\n",
            "t = 24, avg_loss = 0.2642\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 7 / 100\n",
            "t = 2, avg_loss = 0.5013\n",
            "t = 4, avg_loss = 0.3083\n",
            "t = 6, avg_loss = 0.2883\n",
            "t = 8, avg_loss = 0.2492\n",
            "t = 10, avg_loss = 0.2513\n",
            "t = 12, avg_loss = 0.4088\n",
            "t = 14, avg_loss = 0.2774\n",
            "t = 16, avg_loss = 0.3159\n",
            "t = 18, avg_loss = 0.3844\n",
            "t = 20, avg_loss = 0.3311\n",
            "t = 22, avg_loss = 0.3577\n",
            "t = 24, avg_loss = 0.2568\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 8 / 100\n",
            "t = 2, avg_loss = 0.4879\n",
            "t = 4, avg_loss = 0.2803\n",
            "t = 6, avg_loss = 0.3084\n",
            "t = 8, avg_loss = 0.3083\n",
            "t = 10, avg_loss = 0.2791\n",
            "t = 12, avg_loss = 0.2809\n",
            "t = 14, avg_loss = 0.2844\n",
            "t = 16, avg_loss = 0.2791\n",
            "t = 18, avg_loss = 0.3571\n",
            "t = 20, avg_loss = 0.3549\n",
            "t = 22, avg_loss = 0.2988\n",
            "t = 24, avg_loss = 0.3159\n",
            "Checking accuracy on test set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 9 / 100\n",
            "t = 2, avg_loss = 0.4157\n",
            "t = 4, avg_loss = 0.2873\n",
            "t = 6, avg_loss = 0.2774\n",
            "t = 8, avg_loss = 0.3835\n",
            "t = 10, avg_loss = 0.2889\n",
            "t = 12, avg_loss = 0.2688\n",
            "t = 14, avg_loss = 0.2234\n",
            "t = 16, avg_loss = 0.3083\n",
            "t = 18, avg_loss = 0.2926\n",
            "t = 20, avg_loss = 0.2401\n",
            "t = 22, avg_loss = 0.2765\n",
            "t = 24, avg_loss = 0.2588\n",
            "Checking accuracy on test set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 10 / 100\n",
            "t = 2, avg_loss = 0.4015\n",
            "t = 4, avg_loss = 0.3786\n",
            "t = 6, avg_loss = 0.4000\n",
            "t = 8, avg_loss = 0.2380\n",
            "t = 10, avg_loss = 0.2842\n",
            "t = 12, avg_loss = 0.3237\n",
            "t = 14, avg_loss = 0.3000\n",
            "t = 16, avg_loss = 0.2956\n",
            "t = 18, avg_loss = 0.2294\n",
            "t = 20, avg_loss = 0.2330\n",
            "t = 22, avg_loss = 0.2824\n",
            "t = 24, avg_loss = 0.2810\n",
            "Checking accuracy on test set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 11 / 100\n",
            "t = 2, avg_loss = 0.3496\n",
            "t = 4, avg_loss = 0.3116\n",
            "t = 6, avg_loss = 0.2064\n",
            "t = 8, avg_loss = 0.3135\n",
            "t = 10, avg_loss = 0.2775\n",
            "t = 12, avg_loss = 0.2588\n",
            "t = 14, avg_loss = 0.2583\n",
            "t = 16, avg_loss = 0.2819\n",
            "t = 18, avg_loss = 0.2426\n",
            "t = 20, avg_loss = 0.2722\n",
            "t = 22, avg_loss = 0.3094\n",
            "t = 24, avg_loss = 0.2858\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 12 / 100\n",
            "t = 2, avg_loss = 0.4609\n",
            "t = 4, avg_loss = 0.2260\n",
            "t = 6, avg_loss = 0.2521\n",
            "t = 8, avg_loss = 0.2422\n",
            "t = 10, avg_loss = 0.2407\n",
            "t = 12, avg_loss = 0.2611\n",
            "t = 14, avg_loss = 0.2327\n",
            "t = 16, avg_loss = 0.2634\n",
            "t = 18, avg_loss = 0.2525\n",
            "t = 20, avg_loss = 0.2403\n",
            "t = 22, avg_loss = 0.2975\n",
            "t = 24, avg_loss = 0.2467\n",
            "Checking accuracy on test set\n",
            "Got 361 / 400 correct (90.25)\n",
            "acc = 0.902500\n",
            "Starting epoch 13 / 100\n",
            "t = 2, avg_loss = 0.3848\n",
            "t = 4, avg_loss = 0.2414\n",
            "t = 6, avg_loss = 0.2437\n",
            "t = 8, avg_loss = 0.2288\n",
            "t = 10, avg_loss = 0.2522\n",
            "t = 12, avg_loss = 0.2290\n",
            "t = 14, avg_loss = 0.2676\n",
            "t = 16, avg_loss = 0.2271\n",
            "t = 18, avg_loss = 0.2673\n",
            "t = 20, avg_loss = 0.2699\n",
            "t = 22, avg_loss = 0.3088\n",
            "t = 24, avg_loss = 0.3000\n",
            "Checking accuracy on test set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 14 / 100\n",
            "t = 2, avg_loss = 0.2860\n",
            "t = 4, avg_loss = 0.1748\n",
            "t = 6, avg_loss = 0.2256\n",
            "t = 8, avg_loss = 0.2523\n",
            "t = 10, avg_loss = 0.2773\n",
            "t = 12, avg_loss = 0.2877\n",
            "t = 14, avg_loss = 0.2816\n",
            "t = 16, avg_loss = 0.1963\n",
            "t = 18, avg_loss = 0.2758\n",
            "t = 20, avg_loss = 0.2475\n",
            "t = 22, avg_loss = 0.2743\n",
            "t = 24, avg_loss = 0.3026\n",
            "Checking accuracy on test set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 15 / 100\n",
            "t = 2, avg_loss = 0.3651\n",
            "t = 4, avg_loss = 0.3367\n",
            "t = 6, avg_loss = 0.2191\n",
            "t = 8, avg_loss = 0.2514\n",
            "t = 10, avg_loss = 0.2004\n",
            "t = 12, avg_loss = 0.2533\n",
            "t = 14, avg_loss = 0.1895\n",
            "t = 16, avg_loss = 0.2362\n",
            "t = 18, avg_loss = 0.2623\n",
            "t = 20, avg_loss = 0.2393\n",
            "t = 22, avg_loss = 0.2687\n",
            "t = 24, avg_loss = 0.2299\n",
            "Checking accuracy on test set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 16 / 100\n",
            "t = 2, avg_loss = 0.4147\n",
            "t = 4, avg_loss = 0.1456\n",
            "t = 6, avg_loss = 0.3348\n",
            "t = 8, avg_loss = 0.2482\n",
            "t = 10, avg_loss = 0.1569\n",
            "t = 12, avg_loss = 0.1955\n",
            "t = 14, avg_loss = 0.2016\n",
            "t = 16, avg_loss = 0.2586\n",
            "t = 18, avg_loss = 0.1871\n",
            "t = 20, avg_loss = 0.2284\n",
            "t = 22, avg_loss = 0.2798\n",
            "t = 24, avg_loss = 0.2903\n",
            "Checking accuracy on test set\n",
            "Got 351 / 400 correct (87.75)\n",
            "acc = 0.877500\n",
            "Starting epoch 17 / 100\n",
            "t = 2, avg_loss = 0.3446\n",
            "t = 4, avg_loss = 0.1586\n",
            "t = 6, avg_loss = 0.2366\n",
            "t = 8, avg_loss = 0.2744\n",
            "t = 10, avg_loss = 0.1871\n",
            "t = 12, avg_loss = 0.2153\n",
            "t = 14, avg_loss = 0.2591\n",
            "t = 16, avg_loss = 0.1693\n",
            "t = 18, avg_loss = 0.2581\n",
            "t = 20, avg_loss = 0.2502\n",
            "t = 22, avg_loss = 0.2281\n",
            "t = 24, avg_loss = 0.2812\n",
            "Checking accuracy on test set\n",
            "Got 364 / 400 correct (91.00)\n",
            "acc = 0.910000\n",
            "Starting epoch 18 / 100\n",
            "t = 2, avg_loss = 0.3023\n",
            "t = 4, avg_loss = 0.2537\n",
            "t = 6, avg_loss = 0.2103\n",
            "t = 8, avg_loss = 0.1939\n",
            "t = 10, avg_loss = 0.2500\n",
            "t = 12, avg_loss = 0.2061\n",
            "t = 14, avg_loss = 0.2556\n",
            "t = 16, avg_loss = 0.2190\n",
            "t = 18, avg_loss = 0.1872\n",
            "t = 20, avg_loss = 0.1850\n",
            "t = 22, avg_loss = 0.2379\n",
            "t = 24, avg_loss = 0.2612\n",
            "Checking accuracy on test set\n",
            "Got 362 / 400 correct (90.50)\n",
            "acc = 0.905000\n",
            "Starting epoch 19 / 100\n",
            "t = 2, avg_loss = 0.2759\n",
            "t = 4, avg_loss = 0.2089\n",
            "t = 6, avg_loss = 0.1935\n",
            "t = 8, avg_loss = 0.2218\n",
            "t = 10, avg_loss = 0.2395\n",
            "t = 12, avg_loss = 0.2121\n",
            "t = 14, avg_loss = 0.1887\n",
            "t = 16, avg_loss = 0.1617\n",
            "t = 18, avg_loss = 0.2425\n",
            "t = 20, avg_loss = 0.2240\n",
            "t = 22, avg_loss = 0.1706\n",
            "t = 24, avg_loss = 0.2790\n",
            "Checking accuracy on test set\n",
            "Got 358 / 400 correct (89.50)\n",
            "acc = 0.895000\n",
            "Starting epoch 20 / 100\n",
            "t = 2, avg_loss = 0.2949\n",
            "t = 4, avg_loss = 0.1896\n",
            "t = 6, avg_loss = 0.1864\n",
            "t = 8, avg_loss = 0.1869\n",
            "t = 10, avg_loss = 0.2049\n",
            "t = 12, avg_loss = 0.1721\n",
            "t = 14, avg_loss = 0.2077\n",
            "t = 16, avg_loss = 0.2115\n",
            "t = 18, avg_loss = 0.1849\n",
            "t = 20, avg_loss = 0.2463\n",
            "t = 22, avg_loss = 0.2503\n",
            "t = 24, avg_loss = 0.1850\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 21 / 100\n",
            "t = 2, avg_loss = 0.3641\n",
            "t = 4, avg_loss = 0.1434\n",
            "t = 6, avg_loss = 0.2813\n",
            "t = 8, avg_loss = 0.3039\n",
            "t = 10, avg_loss = 0.1772\n",
            "t = 12, avg_loss = 0.1837\n",
            "t = 14, avg_loss = 0.1865\n",
            "t = 16, avg_loss = 0.2032\n",
            "t = 18, avg_loss = 0.2704\n",
            "t = 20, avg_loss = 0.1830\n",
            "t = 22, avg_loss = 0.2348\n",
            "t = 24, avg_loss = 0.2305\n",
            "Checking accuracy on test set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 22 / 100\n",
            "t = 2, avg_loss = 0.2872\n",
            "t = 4, avg_loss = 0.1774\n",
            "t = 6, avg_loss = 0.1949\n",
            "t = 8, avg_loss = 0.1881\n",
            "t = 10, avg_loss = 0.2297\n",
            "t = 12, avg_loss = 0.1962\n",
            "t = 14, avg_loss = 0.2377\n",
            "t = 16, avg_loss = 0.1326\n",
            "t = 18, avg_loss = 0.2458\n",
            "t = 20, avg_loss = 0.2181\n",
            "t = 22, avg_loss = 0.1820\n",
            "t = 24, avg_loss = 0.2216\n",
            "Checking accuracy on test set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 23 / 100\n",
            "t = 2, avg_loss = 0.2901\n",
            "t = 4, avg_loss = 0.2101\n",
            "t = 6, avg_loss = 0.2001\n",
            "t = 8, avg_loss = 0.2281\n",
            "t = 10, avg_loss = 0.2074\n",
            "t = 12, avg_loss = 0.2013\n",
            "t = 14, avg_loss = 0.1839\n",
            "t = 16, avg_loss = 0.1897\n",
            "t = 18, avg_loss = 0.1815\n",
            "t = 20, avg_loss = 0.1384\n",
            "t = 22, avg_loss = 0.2198\n",
            "t = 24, avg_loss = 0.2442\n",
            "Checking accuracy on test set\n",
            "Got 361 / 400 correct (90.25)\n",
            "acc = 0.902500\n",
            "Starting epoch 24 / 100\n",
            "t = 2, avg_loss = 0.2411\n",
            "t = 4, avg_loss = 0.1886\n",
            "t = 6, avg_loss = 0.1390\n",
            "t = 8, avg_loss = 0.1477\n",
            "t = 10, avg_loss = 0.2183\n",
            "t = 12, avg_loss = 0.1357\n",
            "t = 14, avg_loss = 0.1665\n",
            "t = 16, avg_loss = 0.2105\n",
            "t = 18, avg_loss = 0.1826\n",
            "t = 20, avg_loss = 0.1594\n",
            "t = 22, avg_loss = 0.1750\n",
            "t = 24, avg_loss = 0.3083\n",
            "Checking accuracy on test set\n",
            "Got 358 / 400 correct (89.50)\n",
            "acc = 0.895000\n",
            "Starting epoch 25 / 100\n",
            "t = 2, avg_loss = 0.3516\n",
            "t = 4, avg_loss = 0.1967\n",
            "t = 6, avg_loss = 0.1365\n",
            "t = 8, avg_loss = 0.1804\n",
            "t = 10, avg_loss = 0.1953\n",
            "t = 12, avg_loss = 0.1542\n",
            "t = 14, avg_loss = 0.1728\n",
            "t = 16, avg_loss = 0.1158\n",
            "t = 18, avg_loss = 0.1872\n",
            "t = 20, avg_loss = 0.1844\n",
            "t = 22, avg_loss = 0.2083\n",
            "t = 24, avg_loss = 0.1768\n",
            "Checking accuracy on test set\n",
            "Got 364 / 400 correct (91.00)\n",
            "acc = 0.910000\n",
            "Starting epoch 26 / 100\n",
            "t = 2, avg_loss = 0.2764\n",
            "t = 4, avg_loss = 0.1287\n",
            "t = 6, avg_loss = 0.1288\n",
            "t = 8, avg_loss = 0.1667\n",
            "t = 10, avg_loss = 0.1942\n",
            "t = 12, avg_loss = 0.1730\n",
            "t = 14, avg_loss = 0.1610\n",
            "t = 16, avg_loss = 0.2034\n",
            "t = 18, avg_loss = 0.1520\n",
            "t = 20, avg_loss = 0.1436\n",
            "t = 22, avg_loss = 0.1939\n",
            "t = 24, avg_loss = 0.2708\n",
            "Checking accuracy on test set\n",
            "Got 358 / 400 correct (89.50)\n",
            "acc = 0.895000\n",
            "Starting epoch 27 / 100\n",
            "t = 2, avg_loss = 0.2815\n",
            "t = 4, avg_loss = 0.1645\n",
            "t = 6, avg_loss = 0.1622\n",
            "t = 8, avg_loss = 0.1628\n",
            "t = 10, avg_loss = 0.2198\n",
            "t = 12, avg_loss = 0.1476\n",
            "t = 14, avg_loss = 0.2447\n",
            "t = 16, avg_loss = 0.1753\n",
            "t = 18, avg_loss = 0.1771\n",
            "t = 20, avg_loss = 0.1768\n",
            "t = 22, avg_loss = 0.1950\n",
            "t = 24, avg_loss = 0.1517\n",
            "Checking accuracy on test set\n",
            "Got 361 / 400 correct (90.25)\n",
            "acc = 0.902500\n",
            "Starting epoch 28 / 100\n",
            "t = 2, avg_loss = 0.2810\n",
            "t = 4, avg_loss = 0.1370\n",
            "t = 6, avg_loss = 0.1661\n",
            "t = 8, avg_loss = 0.1410\n",
            "t = 10, avg_loss = 0.2322\n",
            "t = 12, avg_loss = 0.1641\n",
            "t = 14, avg_loss = 0.1247\n",
            "t = 16, avg_loss = 0.1423\n",
            "t = 18, avg_loss = 0.1665\n",
            "t = 20, avg_loss = 0.1767\n",
            "t = 22, avg_loss = 0.1493\n",
            "t = 24, avg_loss = 0.1261\n",
            "Checking accuracy on test set\n",
            "Got 363 / 400 correct (90.75)\n",
            "acc = 0.907500\n",
            "Starting epoch 29 / 100\n",
            "t = 2, avg_loss = 0.2355\n",
            "t = 4, avg_loss = 0.1766\n",
            "t = 6, avg_loss = 0.1952\n",
            "t = 8, avg_loss = 0.1278\n",
            "t = 10, avg_loss = 0.2145\n",
            "t = 12, avg_loss = 0.1515\n",
            "t = 14, avg_loss = 0.1605\n",
            "t = 16, avg_loss = 0.2159\n",
            "t = 18, avg_loss = 0.1749\n",
            "t = 20, avg_loss = 0.2065\n",
            "t = 22, avg_loss = 0.1155\n",
            "t = 24, avg_loss = 0.2123\n",
            "Checking accuracy on test set\n",
            "Got 359 / 400 correct (89.75)\n",
            "acc = 0.897500\n",
            "Starting epoch 30 / 100\n",
            "t = 2, avg_loss = 0.1610\n",
            "t = 4, avg_loss = 0.2628\n",
            "t = 6, avg_loss = 0.1723\n",
            "t = 8, avg_loss = 0.1483\n",
            "t = 10, avg_loss = 0.1631\n",
            "t = 12, avg_loss = 0.1355\n",
            "t = 14, avg_loss = 0.1453\n",
            "t = 16, avg_loss = 0.1775\n",
            "t = 18, avg_loss = 0.1241\n",
            "t = 20, avg_loss = 0.1767\n",
            "t = 22, avg_loss = 0.1965\n",
            "t = 24, avg_loss = 0.1660\n",
            "Checking accuracy on test set\n",
            "Got 358 / 400 correct (89.50)\n",
            "acc = 0.895000\n",
            "Starting epoch 31 / 100\n",
            "t = 2, avg_loss = 0.2180\n",
            "t = 4, avg_loss = 0.1907\n",
            "t = 6, avg_loss = 0.2351\n",
            "t = 8, avg_loss = 0.1634\n",
            "t = 10, avg_loss = 0.1043\n",
            "t = 12, avg_loss = 0.1594\n",
            "t = 14, avg_loss = 0.1793\n",
            "t = 16, avg_loss = 0.1171\n",
            "t = 18, avg_loss = 0.1318\n",
            "t = 20, avg_loss = 0.1506\n",
            "t = 22, avg_loss = 0.1707\n",
            "t = 24, avg_loss = 0.1580\n",
            "Checking accuracy on test set\n",
            "Got 359 / 400 correct (89.75)\n",
            "acc = 0.897500\n",
            "Starting epoch 32 / 100\n",
            "t = 2, avg_loss = 0.1552\n",
            "t = 4, avg_loss = 0.1712\n",
            "t = 6, avg_loss = 0.1683\n",
            "t = 8, avg_loss = 0.1476\n",
            "t = 10, avg_loss = 0.1522\n",
            "t = 12, avg_loss = 0.1667\n",
            "t = 14, avg_loss = 0.1388\n",
            "t = 16, avg_loss = 0.1849\n",
            "t = 18, avg_loss = 0.1682\n",
            "t = 20, avg_loss = 0.1982\n",
            "t = 22, avg_loss = 0.1747\n",
            "t = 24, avg_loss = 0.1033\n",
            "Checking accuracy on test set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 33 / 100\n",
            "t = 2, avg_loss = 0.1723\n",
            "t = 4, avg_loss = 0.1543\n",
            "t = 6, avg_loss = 0.1710\n",
            "t = 8, avg_loss = 0.2029\n",
            "t = 10, avg_loss = 0.1326\n",
            "t = 12, avg_loss = 0.1331\n",
            "t = 14, avg_loss = 0.2246\n",
            "t = 16, avg_loss = 0.1812\n",
            "t = 18, avg_loss = 0.1059\n",
            "t = 20, avg_loss = 0.0935\n",
            "t = 22, avg_loss = 0.1315\n",
            "t = 24, avg_loss = 0.1406\n",
            "Checking accuracy on test set\n",
            "Got 360 / 400 correct (90.00)\n",
            "acc = 0.900000\n",
            "Starting epoch 34 / 100\n",
            "t = 2, avg_loss = 0.2490\n",
            "t = 4, avg_loss = 0.1320\n",
            "t = 6, avg_loss = 0.2139\n",
            "t = 8, avg_loss = 0.1448\n",
            "t = 10, avg_loss = 0.0994\n",
            "t = 12, avg_loss = 0.1304\n",
            "t = 14, avg_loss = 0.1442\n",
            "t = 16, avg_loss = 0.0709\n",
            "t = 18, avg_loss = 0.1653\n",
            "t = 20, avg_loss = 0.1014\n",
            "t = 22, avg_loss = 0.1501\n",
            "t = 24, avg_loss = 0.1331\n",
            "Checking accuracy on test set\n",
            "Got 359 / 400 correct (89.75)\n",
            "acc = 0.897500\n",
            "Starting epoch 35 / 100\n",
            "t = 2, avg_loss = 0.2537\n",
            "t = 4, avg_loss = 0.1537\n",
            "t = 6, avg_loss = 0.1761\n",
            "t = 8, avg_loss = 0.1626\n",
            "t = 10, avg_loss = 0.1203\n",
            "t = 12, avg_loss = 0.1614\n",
            "t = 14, avg_loss = 0.1598\n",
            "t = 16, avg_loss = 0.1539\n",
            "t = 18, avg_loss = 0.1644\n",
            "t = 20, avg_loss = 0.0978\n",
            "t = 22, avg_loss = 0.1083\n",
            "t = 24, avg_loss = 0.1464\n",
            "Checking accuracy on test set\n",
            "Got 363 / 400 correct (90.75)\n",
            "acc = 0.907500\n",
            "Starting epoch 36 / 100\n",
            "t = 2, avg_loss = 0.2512\n",
            "t = 4, avg_loss = 0.1107\n",
            "t = 6, avg_loss = 0.1092\n",
            "t = 8, avg_loss = 0.0833\n",
            "t = 10, avg_loss = 0.1158\n",
            "t = 12, avg_loss = 0.1529\n",
            "t = 14, avg_loss = 0.1074\n",
            "t = 16, avg_loss = 0.1517\n",
            "t = 18, avg_loss = 0.1181\n",
            "t = 20, avg_loss = 0.1297\n",
            "t = 22, avg_loss = 0.1306\n",
            "t = 24, avg_loss = 0.1638\n",
            "Checking accuracy on test set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 37 / 100\n",
            "t = 2, avg_loss = 0.2947\n",
            "t = 4, avg_loss = 0.1598\n",
            "t = 6, avg_loss = 0.1296\n",
            "t = 8, avg_loss = 0.1315\n",
            "t = 10, avg_loss = 0.1249\n",
            "t = 12, avg_loss = 0.1856\n",
            "t = 14, avg_loss = 0.1562\n",
            "t = 16, avg_loss = 0.1662\n",
            "t = 18, avg_loss = 0.1591\n",
            "t = 20, avg_loss = 0.1652\n",
            "t = 22, avg_loss = 0.1625\n",
            "t = 24, avg_loss = 0.1264\n",
            "Checking accuracy on test set\n",
            "Got 359 / 400 correct (89.75)\n",
            "acc = 0.897500\n",
            "Starting epoch 38 / 100\n",
            "t = 2, avg_loss = 0.2122\n",
            "t = 4, avg_loss = 0.1176\n",
            "t = 6, avg_loss = 0.1557\n",
            "t = 8, avg_loss = 0.1673\n",
            "t = 10, avg_loss = 0.1377\n",
            "t = 12, avg_loss = 0.1159\n",
            "t = 14, avg_loss = 0.2014\n",
            "t = 16, avg_loss = 0.1813\n",
            "t = 18, avg_loss = 0.1112\n",
            "t = 20, avg_loss = 0.1407\n",
            "t = 22, avg_loss = 0.1445\n",
            "t = 24, avg_loss = 0.0865\n",
            "Checking accuracy on test set\n",
            "Got 360 / 400 correct (90.00)\n",
            "acc = 0.900000\n",
            "Starting epoch 39 / 100\n",
            "t = 2, avg_loss = 0.2022\n",
            "t = 4, avg_loss = 0.1068\n",
            "t = 6, avg_loss = 0.0810\n",
            "t = 8, avg_loss = 0.0927\n",
            "t = 10, avg_loss = 0.0630\n",
            "t = 12, avg_loss = 0.2137\n",
            "t = 14, avg_loss = 0.0932\n",
            "t = 16, avg_loss = 0.1643\n",
            "t = 18, avg_loss = 0.2061\n",
            "t = 20, avg_loss = 0.1442\n",
            "t = 22, avg_loss = 0.1158\n",
            "t = 24, avg_loss = 0.1313\n",
            "Checking accuracy on test set\n",
            "Got 359 / 400 correct (89.75)\n",
            "acc = 0.897500\n",
            "Starting epoch 40 / 100\n",
            "t = 2, avg_loss = 0.2473\n",
            "t = 4, avg_loss = 0.1024\n",
            "t = 6, avg_loss = 0.1253\n",
            "t = 8, avg_loss = 0.2224\n",
            "t = 10, avg_loss = 0.1471\n",
            "t = 12, avg_loss = 0.1498\n",
            "t = 14, avg_loss = 0.1442\n",
            "t = 16, avg_loss = 0.1313\n",
            "t = 18, avg_loss = 0.0983\n",
            "t = 20, avg_loss = 0.1121\n",
            "t = 22, avg_loss = 0.1493\n",
            "t = 24, avg_loss = 0.1520\n",
            "Checking accuracy on test set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 41 / 100\n",
            "t = 2, avg_loss = 0.1794\n",
            "t = 4, avg_loss = 0.0841\n",
            "t = 6, avg_loss = 0.1165\n",
            "t = 8, avg_loss = 0.0934\n",
            "t = 10, avg_loss = 0.1260\n",
            "t = 12, avg_loss = 0.0913\n",
            "t = 14, avg_loss = 0.0945\n",
            "t = 16, avg_loss = 0.1300\n",
            "t = 18, avg_loss = 0.1422\n",
            "t = 20, avg_loss = 0.0891\n",
            "t = 22, avg_loss = 0.1112\n",
            "t = 24, avg_loss = 0.2025\n",
            "Checking accuracy on test set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 42 / 100\n",
            "t = 2, avg_loss = 0.1738\n",
            "t = 4, avg_loss = 0.1294\n",
            "t = 6, avg_loss = 0.1550\n",
            "t = 8, avg_loss = 0.0876\n",
            "t = 10, avg_loss = 0.1060\n",
            "t = 12, avg_loss = 0.0685\n",
            "t = 14, avg_loss = 0.1090\n",
            "t = 16, avg_loss = 0.1179\n",
            "t = 18, avg_loss = 0.1583\n",
            "t = 20, avg_loss = 0.1709\n",
            "t = 22, avg_loss = 0.2318\n",
            "t = 24, avg_loss = 0.0875\n",
            "Checking accuracy on test set\n",
            "Got 358 / 400 correct (89.50)\n",
            "acc = 0.895000\n",
            "Starting epoch 43 / 100\n",
            "t = 2, avg_loss = 0.2298\n",
            "t = 4, avg_loss = 0.0843\n",
            "t = 6, avg_loss = 0.1251\n",
            "t = 8, avg_loss = 0.1377\n",
            "t = 10, avg_loss = 0.1220\n",
            "t = 12, avg_loss = 0.1574\n",
            "t = 14, avg_loss = 0.1642\n",
            "t = 16, avg_loss = 0.1706\n",
            "t = 18, avg_loss = 0.1672\n",
            "t = 20, avg_loss = 0.1347\n",
            "t = 22, avg_loss = 0.0873\n",
            "t = 24, avg_loss = 0.1952\n",
            "Checking accuracy on test set\n",
            "Got 365 / 400 correct (91.25)\n",
            "acc = 0.912500\n",
            "Starting epoch 44 / 100\n",
            "t = 2, avg_loss = 0.1487\n",
            "t = 4, avg_loss = 0.1507\n",
            "t = 6, avg_loss = 0.1285\n",
            "t = 8, avg_loss = 0.2010\n",
            "t = 10, avg_loss = 0.1132\n",
            "t = 12, avg_loss = 0.1111\n",
            "t = 14, avg_loss = 0.1319\n",
            "t = 16, avg_loss = 0.1618\n",
            "t = 18, avg_loss = 0.1231\n",
            "t = 20, avg_loss = 0.1309\n",
            "t = 22, avg_loss = 0.1364\n",
            "t = 24, avg_loss = 0.1305\n",
            "Checking accuracy on test set\n",
            "Got 362 / 400 correct (90.50)\n",
            "acc = 0.905000\n",
            "Starting epoch 45 / 100\n",
            "t = 2, avg_loss = 0.1948\n",
            "t = 4, avg_loss = 0.1149\n",
            "t = 6, avg_loss = 0.1266\n",
            "t = 8, avg_loss = 0.1168\n",
            "t = 10, avg_loss = 0.0960\n",
            "t = 12, avg_loss = 0.1323\n",
            "t = 14, avg_loss = 0.0826\n",
            "t = 16, avg_loss = 0.1042\n",
            "t = 18, avg_loss = 0.1348\n",
            "t = 20, avg_loss = 0.1466\n",
            "t = 22, avg_loss = 0.1186\n",
            "t = 24, avg_loss = 0.1503\n",
            "Checking accuracy on test set\n",
            "Got 362 / 400 correct (90.50)\n",
            "acc = 0.905000\n",
            "Starting epoch 46 / 100\n",
            "t = 2, avg_loss = 0.1340\n",
            "t = 4, avg_loss = 0.1189\n",
            "t = 6, avg_loss = 0.1381\n",
            "t = 8, avg_loss = 0.1393\n",
            "t = 10, avg_loss = 0.1488\n",
            "t = 12, avg_loss = 0.1750\n",
            "t = 14, avg_loss = 0.1656\n",
            "t = 16, avg_loss = 0.1040\n",
            "t = 18, avg_loss = 0.1074\n",
            "t = 20, avg_loss = 0.1064\n",
            "t = 22, avg_loss = 0.0879\n",
            "t = 24, avg_loss = 0.0762\n",
            "Checking accuracy on test set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 47 / 100\n",
            "t = 2, avg_loss = 0.1537\n",
            "t = 4, avg_loss = 0.1365\n",
            "t = 6, avg_loss = 0.0926\n",
            "t = 8, avg_loss = 0.0837\n",
            "t = 10, avg_loss = 0.0926\n",
            "t = 12, avg_loss = 0.1195\n",
            "t = 14, avg_loss = 0.1386\n",
            "t = 16, avg_loss = 0.0891\n",
            "t = 18, avg_loss = 0.1717\n",
            "t = 20, avg_loss = 0.1454\n",
            "t = 22, avg_loss = 0.1607\n",
            "t = 24, avg_loss = 0.1643\n",
            "Checking accuracy on test set\n",
            "Got 361 / 400 correct (90.25)\n",
            "acc = 0.902500\n",
            "Starting epoch 48 / 100\n",
            "t = 2, avg_loss = 0.2190\n",
            "t = 4, avg_loss = 0.1292\n",
            "t = 6, avg_loss = 0.1214\n",
            "t = 8, avg_loss = 0.0972\n",
            "t = 10, avg_loss = 0.1081\n",
            "t = 12, avg_loss = 0.1653\n",
            "t = 14, avg_loss = 0.0784\n",
            "t = 16, avg_loss = 0.1052\n",
            "t = 18, avg_loss = 0.1760\n",
            "t = 20, avg_loss = 0.1356\n",
            "t = 22, avg_loss = 0.0960\n",
            "t = 24, avg_loss = 0.0918\n",
            "Checking accuracy on test set\n",
            "Got 361 / 400 correct (90.25)\n",
            "acc = 0.902500\n",
            "Starting epoch 49 / 100\n",
            "t = 2, avg_loss = 0.1806\n",
            "t = 4, avg_loss = 0.0868\n",
            "t = 6, avg_loss = 0.1197\n",
            "t = 8, avg_loss = 0.1240\n",
            "t = 10, avg_loss = 0.0983\n",
            "t = 12, avg_loss = 0.0968\n",
            "t = 14, avg_loss = 0.0824\n",
            "t = 16, avg_loss = 0.1159\n",
            "t = 18, avg_loss = 0.0985\n",
            "t = 20, avg_loss = 0.0946\n",
            "t = 22, avg_loss = 0.1458\n",
            "t = 24, avg_loss = 0.0964\n",
            "Checking accuracy on test set\n",
            "Got 363 / 400 correct (90.75)\n",
            "acc = 0.907500\n",
            "Starting epoch 50 / 100\n",
            "t = 2, avg_loss = 0.1925\n",
            "t = 4, avg_loss = 0.1026\n",
            "t = 6, avg_loss = 0.1225\n",
            "t = 8, avg_loss = 0.1005\n",
            "t = 10, avg_loss = 0.0937\n",
            "t = 12, avg_loss = 0.1337\n",
            "t = 14, avg_loss = 0.1507\n",
            "t = 16, avg_loss = 0.1169\n",
            "t = 18, avg_loss = 0.1161\n",
            "t = 20, avg_loss = 0.1512\n",
            "t = 22, avg_loss = 0.1434\n",
            "t = 24, avg_loss = 0.0707\n",
            "Checking accuracy on test set\n",
            "Got 360 / 400 correct (90.00)\n",
            "acc = 0.900000\n",
            "Starting epoch 51 / 100\n",
            "t = 2, avg_loss = 0.1195\n",
            "t = 4, avg_loss = 0.1013\n",
            "t = 6, avg_loss = 0.0689\n",
            "t = 8, avg_loss = 0.1091\n",
            "t = 10, avg_loss = 0.1267\n",
            "t = 12, avg_loss = 0.0825\n",
            "t = 14, avg_loss = 0.1312\n",
            "t = 16, avg_loss = 0.1087\n",
            "t = 18, avg_loss = 0.1054\n",
            "t = 20, avg_loss = 0.1276\n",
            "t = 22, avg_loss = 0.0987\n",
            "t = 24, avg_loss = 0.1172\n",
            "Checking accuracy on test set\n",
            "Got 368 / 400 correct (92.00)\n",
            "acc = 0.920000\n",
            "Starting epoch 52 / 100\n",
            "t = 2, avg_loss = 0.1147\n",
            "t = 4, avg_loss = 0.1197\n",
            "t = 6, avg_loss = 0.0918\n",
            "t = 8, avg_loss = 0.1996\n",
            "t = 10, avg_loss = 0.0701\n",
            "t = 12, avg_loss = 0.0835\n",
            "t = 14, avg_loss = 0.1405\n",
            "t = 16, avg_loss = 0.0826\n",
            "t = 18, avg_loss = 0.0751\n",
            "t = 20, avg_loss = 0.0853\n",
            "t = 22, avg_loss = 0.0687\n",
            "t = 24, avg_loss = 0.0932\n",
            "Checking accuracy on test set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 53 / 100\n",
            "t = 2, avg_loss = 0.1042\n",
            "t = 4, avg_loss = 0.0645\n",
            "t = 6, avg_loss = 0.0732\n",
            "t = 8, avg_loss = 0.0987\n",
            "t = 10, avg_loss = 0.1167\n",
            "t = 12, avg_loss = 0.0596\n",
            "t = 14, avg_loss = 0.1018\n",
            "t = 16, avg_loss = 0.0971\n",
            "t = 18, avg_loss = 0.0547\n",
            "t = 20, avg_loss = 0.1487\n",
            "t = 22, avg_loss = 0.1142\n",
            "t = 24, avg_loss = 0.1412\n",
            "Checking accuracy on test set\n",
            "Got 353 / 400 correct (88.25)\n",
            "acc = 0.882500\n",
            "Starting epoch 54 / 100\n",
            "t = 2, avg_loss = 0.1691\n",
            "t = 4, avg_loss = 0.0883\n",
            "t = 6, avg_loss = 0.1351\n",
            "t = 8, avg_loss = 0.1004\n",
            "t = 10, avg_loss = 0.0935\n",
            "t = 12, avg_loss = 0.1253\n",
            "t = 14, avg_loss = 0.0731\n",
            "t = 16, avg_loss = 0.1079\n",
            "t = 18, avg_loss = 0.0908\n",
            "t = 20, avg_loss = 0.0783\n",
            "t = 22, avg_loss = 0.1077\n",
            "t = 24, avg_loss = 0.1258\n",
            "Checking accuracy on test set\n",
            "Got 364 / 400 correct (91.00)\n",
            "acc = 0.910000\n",
            "Starting epoch 55 / 100\n",
            "t = 2, avg_loss = 0.1350\n",
            "t = 4, avg_loss = 0.0500\n",
            "t = 6, avg_loss = 0.0954\n",
            "t = 8, avg_loss = 0.0860\n",
            "t = 10, avg_loss = 0.0912\n",
            "t = 12, avg_loss = 0.0945\n",
            "t = 14, avg_loss = 0.1045\n",
            "t = 16, avg_loss = 0.0999\n",
            "t = 18, avg_loss = 0.1343\n",
            "t = 20, avg_loss = 0.1074\n",
            "t = 22, avg_loss = 0.0709\n",
            "t = 24, avg_loss = 0.1410\n",
            "Checking accuracy on test set\n",
            "Got 361 / 400 correct (90.25)\n",
            "acc = 0.902500\n",
            "Starting epoch 56 / 100\n",
            "t = 2, avg_loss = 0.1288\n",
            "t = 4, avg_loss = 0.0905\n",
            "t = 6, avg_loss = 0.0969\n",
            "t = 8, avg_loss = 0.1062\n",
            "t = 10, avg_loss = 0.0764\n",
            "t = 12, avg_loss = 0.1022\n",
            "t = 14, avg_loss = 0.1058\n",
            "t = 16, avg_loss = 0.1154\n",
            "t = 18, avg_loss = 0.1074\n",
            "t = 20, avg_loss = 0.1065\n",
            "t = 22, avg_loss = 0.1391\n",
            "t = 24, avg_loss = 0.0951\n",
            "Checking accuracy on test set\n",
            "Got 362 / 400 correct (90.50)\n",
            "acc = 0.905000\n",
            "Starting epoch 57 / 100\n",
            "t = 2, avg_loss = 0.1390\n",
            "t = 4, avg_loss = 0.0596\n",
            "t = 6, avg_loss = 0.1238\n",
            "t = 8, avg_loss = 0.0656\n",
            "t = 10, avg_loss = 0.1293\n",
            "t = 12, avg_loss = 0.1051\n",
            "t = 14, avg_loss = 0.1243\n",
            "t = 16, avg_loss = 0.1676\n",
            "t = 18, avg_loss = 0.0868\n",
            "t = 20, avg_loss = 0.0777\n",
            "t = 22, avg_loss = 0.0814\n",
            "t = 24, avg_loss = 0.0883\n",
            "Checking accuracy on test set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 58 / 100\n",
            "t = 2, avg_loss = 0.1487\n",
            "t = 4, avg_loss = 0.0796\n",
            "t = 6, avg_loss = 0.0598\n",
            "t = 8, avg_loss = 0.0986\n",
            "t = 10, avg_loss = 0.0870\n",
            "t = 12, avg_loss = 0.1504\n",
            "t = 14, avg_loss = 0.0617\n",
            "t = 16, avg_loss = 0.0760\n",
            "t = 18, avg_loss = 0.0819\n",
            "t = 20, avg_loss = 0.1068\n",
            "t = 22, avg_loss = 0.1123\n",
            "t = 24, avg_loss = 0.1046\n",
            "Checking accuracy on test set\n",
            "Got 358 / 400 correct (89.50)\n",
            "acc = 0.895000\n",
            "Starting epoch 59 / 100\n",
            "t = 2, avg_loss = 0.1225\n",
            "t = 4, avg_loss = 0.0747\n",
            "t = 6, avg_loss = 0.0662\n",
            "t = 8, avg_loss = 0.0940\n",
            "t = 10, avg_loss = 0.0711\n",
            "t = 12, avg_loss = 0.0869\n",
            "t = 14, avg_loss = 0.0547\n",
            "t = 16, avg_loss = 0.1023\n",
            "t = 18, avg_loss = 0.0702\n",
            "t = 20, avg_loss = 0.2124\n",
            "t = 22, avg_loss = 0.0851\n",
            "t = 24, avg_loss = 0.0701\n",
            "Checking accuracy on test set\n",
            "Got 367 / 400 correct (91.75)\n",
            "acc = 0.917500\n",
            "Starting epoch 60 / 100\n",
            "t = 2, avg_loss = 0.1340\n",
            "t = 4, avg_loss = 0.0818\n",
            "t = 6, avg_loss = 0.0389\n",
            "t = 8, avg_loss = 0.0602\n",
            "t = 10, avg_loss = 0.1066\n",
            "t = 12, avg_loss = 0.1151\n",
            "t = 14, avg_loss = 0.0888\n",
            "t = 16, avg_loss = 0.0739\n",
            "t = 18, avg_loss = 0.0762\n",
            "t = 20, avg_loss = 0.0635\n",
            "t = 22, avg_loss = 0.0797\n",
            "t = 24, avg_loss = 0.0881\n",
            "Checking accuracy on test set\n",
            "Got 366 / 400 correct (91.50)\n",
            "acc = 0.915000\n",
            "Starting epoch 61 / 100\n",
            "t = 2, avg_loss = 0.1178\n",
            "t = 4, avg_loss = 0.0622\n",
            "t = 6, avg_loss = 0.0982\n",
            "t = 8, avg_loss = 0.0624\n",
            "t = 10, avg_loss = 0.0686\n",
            "t = 12, avg_loss = 0.2025\n",
            "t = 14, avg_loss = 0.1101\n",
            "t = 16, avg_loss = 0.0958\n",
            "t = 18, avg_loss = 0.1081\n",
            "t = 20, avg_loss = 0.0858\n",
            "t = 22, avg_loss = 0.1006\n",
            "t = 24, avg_loss = 0.1234\n",
            "Checking accuracy on test set\n",
            "Got 361 / 400 correct (90.25)\n",
            "acc = 0.902500\n",
            "Starting epoch 62 / 100\n",
            "t = 2, avg_loss = 0.0785\n",
            "t = 4, avg_loss = 0.0987\n",
            "t = 6, avg_loss = 0.0944\n",
            "t = 8, avg_loss = 0.0519\n",
            "t = 10, avg_loss = 0.0799\n",
            "t = 12, avg_loss = 0.0419\n",
            "t = 14, avg_loss = 0.0633\n",
            "t = 16, avg_loss = 0.0884\n",
            "t = 18, avg_loss = 0.0818\n",
            "t = 20, avg_loss = 0.1176\n",
            "t = 22, avg_loss = 0.0700\n",
            "t = 24, avg_loss = 0.1471\n",
            "Checking accuracy on test set\n",
            "Got 363 / 400 correct (90.75)\n",
            "acc = 0.907500\n",
            "Starting epoch 63 / 100\n",
            "t = 2, avg_loss = 0.1043\n",
            "t = 4, avg_loss = 0.1024\n",
            "t = 6, avg_loss = 0.0793\n",
            "t = 8, avg_loss = 0.0489\n",
            "t = 10, avg_loss = 0.0850\n",
            "t = 12, avg_loss = 0.0420\n",
            "t = 14, avg_loss = 0.0449\n",
            "t = 16, avg_loss = 0.1044\n",
            "t = 18, avg_loss = 0.1040\n",
            "t = 20, avg_loss = 0.0716\n",
            "t = 22, avg_loss = 0.0874\n",
            "t = 24, avg_loss = 0.0848\n",
            "Checking accuracy on test set\n",
            "Got 368 / 400 correct (92.00)\n",
            "acc = 0.920000\n",
            "Starting epoch 64 / 100\n",
            "t = 2, avg_loss = 0.1132\n",
            "t = 4, avg_loss = 0.0834\n",
            "t = 6, avg_loss = 0.0742\n",
            "t = 8, avg_loss = 0.0438\n",
            "t = 10, avg_loss = 0.1114\n",
            "t = 12, avg_loss = 0.0660\n",
            "t = 14, avg_loss = 0.1004\n",
            "t = 16, avg_loss = 0.0667\n",
            "t = 18, avg_loss = 0.0804\n",
            "t = 20, avg_loss = 0.0717\n",
            "t = 22, avg_loss = 0.0449\n",
            "t = 24, avg_loss = 0.0839\n",
            "Checking accuracy on test set\n",
            "Got 365 / 400 correct (91.25)\n",
            "acc = 0.912500\n",
            "Starting epoch 65 / 100\n",
            "t = 2, avg_loss = 0.1138\n",
            "t = 4, avg_loss = 0.0638\n",
            "t = 6, avg_loss = 0.0476\n",
            "t = 8, avg_loss = 0.0944\n",
            "t = 10, avg_loss = 0.0730\n",
            "t = 12, avg_loss = 0.1180\n",
            "t = 14, avg_loss = 0.0814\n",
            "t = 16, avg_loss = 0.0665\n",
            "t = 18, avg_loss = 0.0975\n",
            "t = 20, avg_loss = 0.0934\n",
            "t = 22, avg_loss = 0.0663\n",
            "t = 24, avg_loss = 0.1013\n",
            "Checking accuracy on test set\n",
            "Got 364 / 400 correct (91.00)\n",
            "acc = 0.910000\n",
            "Starting epoch 66 / 100\n",
            "t = 2, avg_loss = 0.0871\n",
            "t = 4, avg_loss = 0.0883\n",
            "t = 6, avg_loss = 0.0727\n",
            "t = 8, avg_loss = 0.0835\n",
            "t = 10, avg_loss = 0.0437\n",
            "t = 12, avg_loss = 0.0916\n",
            "t = 14, avg_loss = 0.0630\n",
            "t = 16, avg_loss = 0.1022\n",
            "t = 18, avg_loss = 0.0893\n",
            "t = 20, avg_loss = 0.0818\n",
            "t = 22, avg_loss = 0.0841\n",
            "t = 24, avg_loss = 0.1357\n",
            "Checking accuracy on test set\n",
            "Got 364 / 400 correct (91.00)\n",
            "acc = 0.910000\n",
            "Starting epoch 67 / 100\n",
            "t = 2, avg_loss = 0.0832\n",
            "t = 4, avg_loss = 0.0935\n",
            "t = 6, avg_loss = 0.0732\n",
            "t = 8, avg_loss = 0.0983\n",
            "t = 10, avg_loss = 0.0983\n",
            "t = 12, avg_loss = 0.0894\n",
            "t = 14, avg_loss = 0.1039\n",
            "t = 16, avg_loss = 0.0954\n",
            "t = 18, avg_loss = 0.0624\n",
            "t = 20, avg_loss = 0.0730\n",
            "t = 22, avg_loss = 0.0787\n",
            "t = 24, avg_loss = 0.1854\n",
            "Checking accuracy on test set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 68 / 100\n",
            "t = 2, avg_loss = 0.1010\n",
            "t = 4, avg_loss = 0.0309\n",
            "t = 6, avg_loss = 0.0955\n",
            "t = 8, avg_loss = 0.0919\n",
            "t = 10, avg_loss = 0.0977\n",
            "t = 12, avg_loss = 0.1196\n",
            "t = 14, avg_loss = 0.0667\n",
            "t = 16, avg_loss = 0.0946\n",
            "t = 18, avg_loss = 0.1106\n",
            "t = 20, avg_loss = 0.0992\n",
            "t = 22, avg_loss = 0.1278\n",
            "t = 24, avg_loss = 0.0703\n",
            "Checking accuracy on test set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 69 / 100\n",
            "t = 2, avg_loss = 0.0930\n",
            "t = 4, avg_loss = 0.0853\n",
            "t = 6, avg_loss = 0.0691\n",
            "t = 8, avg_loss = 0.0508\n",
            "t = 10, avg_loss = 0.0639\n",
            "t = 12, avg_loss = 0.0902\n",
            "t = 14, avg_loss = 0.1133\n",
            "t = 16, avg_loss = 0.0984\n",
            "t = 18, avg_loss = 0.0537\n",
            "t = 20, avg_loss = 0.0995\n",
            "t = 22, avg_loss = 0.1042\n",
            "t = 24, avg_loss = 0.0528\n",
            "Checking accuracy on test set\n",
            "Got 363 / 400 correct (90.75)\n",
            "acc = 0.907500\n",
            "Starting epoch 70 / 100\n",
            "t = 2, avg_loss = 0.1655\n",
            "t = 4, avg_loss = 0.0899\n",
            "t = 6, avg_loss = 0.0822\n",
            "t = 8, avg_loss = 0.1002\n",
            "t = 10, avg_loss = 0.0487\n",
            "t = 12, avg_loss = 0.0979\n",
            "t = 14, avg_loss = 0.0488\n",
            "t = 16, avg_loss = 0.1253\n",
            "t = 18, avg_loss = 0.0573\n",
            "t = 20, avg_loss = 0.0794\n",
            "t = 22, avg_loss = 0.0618\n",
            "t = 24, avg_loss = 0.0784\n",
            "Checking accuracy on test set\n",
            "Got 358 / 400 correct (89.50)\n",
            "acc = 0.895000\n",
            "Starting epoch 71 / 100\n",
            "t = 2, avg_loss = 0.1308\n",
            "t = 4, avg_loss = 0.0707\n",
            "t = 6, avg_loss = 0.0969\n",
            "t = 8, avg_loss = 0.0781\n",
            "t = 10, avg_loss = 0.0613\n",
            "t = 12, avg_loss = 0.0944\n",
            "t = 14, avg_loss = 0.0717\n",
            "t = 16, avg_loss = 0.0633\n",
            "t = 18, avg_loss = 0.0450\n",
            "t = 20, avg_loss = 0.0482\n",
            "t = 22, avg_loss = 0.0984\n",
            "t = 24, avg_loss = 0.0740\n",
            "Checking accuracy on test set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 72 / 100\n",
            "t = 2, avg_loss = 0.0885\n",
            "t = 4, avg_loss = 0.0676\n",
            "t = 6, avg_loss = 0.1017\n",
            "t = 8, avg_loss = 0.0699\n",
            "t = 10, avg_loss = 0.0805\n",
            "t = 12, avg_loss = 0.1328\n",
            "t = 14, avg_loss = 0.0682\n",
            "t = 16, avg_loss = 0.0709\n",
            "t = 18, avg_loss = 0.1204\n",
            "t = 20, avg_loss = 0.0887\n",
            "t = 22, avg_loss = 0.1153\n",
            "t = 24, avg_loss = 0.1069\n",
            "Checking accuracy on test set\n",
            "Got 361 / 400 correct (90.25)\n",
            "acc = 0.902500\n",
            "Starting epoch 73 / 100\n",
            "t = 2, avg_loss = 0.1059\n",
            "t = 4, avg_loss = 0.0601\n",
            "t = 6, avg_loss = 0.0864\n",
            "t = 8, avg_loss = 0.0966\n",
            "t = 10, avg_loss = 0.0509\n",
            "t = 12, avg_loss = 0.0967\n",
            "t = 14, avg_loss = 0.0799\n",
            "t = 16, avg_loss = 0.0348\n",
            "t = 18, avg_loss = 0.0850\n",
            "t = 20, avg_loss = 0.0464\n",
            "t = 22, avg_loss = 0.0941\n",
            "t = 24, avg_loss = 0.1099\n",
            "Checking accuracy on test set\n",
            "Got 358 / 400 correct (89.50)\n",
            "acc = 0.895000\n",
            "Starting epoch 74 / 100\n",
            "t = 2, avg_loss = 0.1091\n",
            "t = 4, avg_loss = 0.0599\n",
            "t = 6, avg_loss = 0.1037\n",
            "t = 8, avg_loss = 0.0851\n",
            "t = 10, avg_loss = 0.0467\n",
            "t = 12, avg_loss = 0.0466\n",
            "t = 14, avg_loss = 0.0532\n",
            "t = 16, avg_loss = 0.0647\n",
            "t = 18, avg_loss = 0.0535\n",
            "t = 20, avg_loss = 0.0257\n",
            "t = 22, avg_loss = 0.0586\n",
            "t = 24, avg_loss = 0.0386\n",
            "Checking accuracy on test set\n",
            "Got 361 / 400 correct (90.25)\n",
            "acc = 0.902500\n",
            "Starting epoch 75 / 100\n",
            "t = 2, avg_loss = 0.1288\n",
            "t = 4, avg_loss = 0.0405\n",
            "t = 6, avg_loss = 0.0628\n",
            "t = 8, avg_loss = 0.0433\n",
            "t = 10, avg_loss = 0.0531\n",
            "t = 12, avg_loss = 0.0612\n",
            "t = 14, avg_loss = 0.0625\n",
            "t = 16, avg_loss = 0.0426\n",
            "t = 18, avg_loss = 0.0855\n",
            "t = 20, avg_loss = 0.0623\n",
            "t = 22, avg_loss = 0.0798\n",
            "t = 24, avg_loss = 0.0565\n",
            "Checking accuracy on test set\n",
            "Got 360 / 400 correct (90.00)\n",
            "acc = 0.900000\n",
            "Starting epoch 76 / 100\n",
            "t = 2, avg_loss = 0.0996\n",
            "t = 4, avg_loss = 0.0628\n",
            "t = 6, avg_loss = 0.0414\n",
            "t = 8, avg_loss = 0.0541\n",
            "t = 10, avg_loss = 0.0361\n",
            "t = 12, avg_loss = 0.0600\n",
            "t = 14, avg_loss = 0.0629\n",
            "t = 16, avg_loss = 0.0506\n",
            "t = 18, avg_loss = 0.1104\n",
            "t = 20, avg_loss = 0.0495\n",
            "t = 22, avg_loss = 0.0848\n",
            "t = 24, avg_loss = 0.0528\n",
            "Checking accuracy on test set\n",
            "Got 362 / 400 correct (90.50)\n",
            "acc = 0.905000\n",
            "Starting epoch 77 / 100\n",
            "t = 2, avg_loss = 0.1103\n",
            "t = 4, avg_loss = 0.0421\n",
            "t = 6, avg_loss = 0.0465\n",
            "t = 8, avg_loss = 0.0353\n",
            "t = 10, avg_loss = 0.0455\n",
            "t = 12, avg_loss = 0.0392\n",
            "t = 14, avg_loss = 0.0551\n",
            "t = 16, avg_loss = 0.0534\n",
            "t = 18, avg_loss = 0.0569\n",
            "t = 20, avg_loss = 0.0363\n",
            "t = 22, avg_loss = 0.0826\n",
            "t = 24, avg_loss = 0.0535\n",
            "Checking accuracy on test set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 78 / 100\n",
            "t = 2, avg_loss = 0.0710\n",
            "t = 4, avg_loss = 0.0257\n",
            "t = 6, avg_loss = 0.0687\n",
            "t = 8, avg_loss = 0.0367\n",
            "t = 10, avg_loss = 0.0637\n",
            "t = 12, avg_loss = 0.0513\n",
            "t = 14, avg_loss = 0.0675\n",
            "t = 16, avg_loss = 0.0556\n",
            "t = 18, avg_loss = 0.0408\n",
            "t = 20, avg_loss = 0.0693\n",
            "t = 22, avg_loss = 0.0576\n",
            "t = 24, avg_loss = 0.0702\n",
            "Checking accuracy on test set\n",
            "Got 367 / 400 correct (91.75)\n",
            "acc = 0.917500\n",
            "Starting epoch 79 / 100\n",
            "t = 2, avg_loss = 0.0604\n",
            "t = 4, avg_loss = 0.0627\n",
            "t = 6, avg_loss = 0.0719\n",
            "t = 8, avg_loss = 0.0555\n",
            "t = 10, avg_loss = 0.0517\n",
            "t = 12, avg_loss = 0.0741\n",
            "t = 14, avg_loss = 0.0527\n",
            "t = 16, avg_loss = 0.0741\n",
            "t = 18, avg_loss = 0.0333\n",
            "t = 20, avg_loss = 0.0568\n",
            "t = 22, avg_loss = 0.0554\n",
            "t = 24, avg_loss = 0.1081\n",
            "Checking accuracy on test set\n",
            "Got 361 / 400 correct (90.25)\n",
            "acc = 0.902500\n",
            "Starting epoch 80 / 100\n",
            "t = 2, avg_loss = 0.1098\n",
            "t = 4, avg_loss = 0.0726\n",
            "t = 6, avg_loss = 0.0482\n",
            "t = 8, avg_loss = 0.0684\n",
            "t = 10, avg_loss = 0.0486\n",
            "t = 12, avg_loss = 0.0551\n",
            "t = 14, avg_loss = 0.0666\n",
            "t = 16, avg_loss = 0.0682\n",
            "t = 18, avg_loss = 0.0553\n",
            "t = 20, avg_loss = 0.0606\n",
            "t = 22, avg_loss = 0.1217\n",
            "t = 24, avg_loss = 0.0872\n",
            "Checking accuracy on test set\n",
            "Got 360 / 400 correct (90.00)\n",
            "acc = 0.900000\n",
            "Starting epoch 81 / 100\n",
            "t = 2, avg_loss = 0.1136\n",
            "t = 4, avg_loss = 0.0979\n",
            "t = 6, avg_loss = 0.0537\n",
            "t = 8, avg_loss = 0.0674\n",
            "t = 10, avg_loss = 0.0767\n",
            "t = 12, avg_loss = 0.0594\n",
            "t = 14, avg_loss = 0.0658\n",
            "t = 16, avg_loss = 0.0690\n",
            "t = 18, avg_loss = 0.1109\n",
            "t = 20, avg_loss = 0.0443\n",
            "t = 22, avg_loss = 0.0960\n",
            "t = 24, avg_loss = 0.0495\n",
            "Checking accuracy on test set\n",
            "Got 358 / 400 correct (89.50)\n",
            "acc = 0.895000\n",
            "Starting epoch 82 / 100\n",
            "t = 2, avg_loss = 0.0672\n",
            "t = 4, avg_loss = 0.0887\n",
            "t = 6, avg_loss = 0.0557\n",
            "t = 8, avg_loss = 0.0810\n",
            "t = 10, avg_loss = 0.1253\n",
            "t = 12, avg_loss = 0.1215\n",
            "t = 14, avg_loss = 0.0827\n",
            "t = 16, avg_loss = 0.0901\n",
            "t = 18, avg_loss = 0.0544\n",
            "t = 20, avg_loss = 0.0748\n",
            "t = 22, avg_loss = 0.0830\n",
            "t = 24, avg_loss = 0.0722\n",
            "Checking accuracy on test set\n",
            "Got 356 / 400 correct (89.00)\n",
            "acc = 0.890000\n",
            "Starting epoch 83 / 100\n",
            "t = 2, avg_loss = 0.0846\n",
            "t = 4, avg_loss = 0.0479\n",
            "t = 6, avg_loss = 0.0791\n",
            "t = 8, avg_loss = 0.0401\n",
            "t = 10, avg_loss = 0.0536\n",
            "t = 12, avg_loss = 0.0703\n",
            "t = 14, avg_loss = 0.0439\n",
            "t = 16, avg_loss = 0.0831\n",
            "t = 18, avg_loss = 0.0738\n",
            "t = 20, avg_loss = 0.0476\n",
            "t = 22, avg_loss = 0.0316\n",
            "t = 24, avg_loss = 0.0842\n",
            "Checking accuracy on test set\n",
            "Got 364 / 400 correct (91.00)\n",
            "acc = 0.910000\n",
            "Starting epoch 84 / 100\n",
            "t = 2, avg_loss = 0.1083\n",
            "t = 4, avg_loss = 0.0593\n",
            "t = 6, avg_loss = 0.0448\n",
            "t = 8, avg_loss = 0.0429\n",
            "t = 10, avg_loss = 0.0891\n",
            "t = 12, avg_loss = 0.0809\n",
            "t = 14, avg_loss = 0.0315\n",
            "t = 16, avg_loss = 0.1114\n",
            "t = 18, avg_loss = 0.0902\n",
            "t = 20, avg_loss = 0.0365\n",
            "t = 22, avg_loss = 0.1189\n",
            "t = 24, avg_loss = 0.1275\n",
            "Checking accuracy on test set\n",
            "Got 358 / 400 correct (89.50)\n",
            "acc = 0.895000\n",
            "Starting epoch 85 / 100\n",
            "t = 2, avg_loss = 0.0939\n",
            "t = 4, avg_loss = 0.0363\n",
            "t = 6, avg_loss = 0.0598\n",
            "t = 8, avg_loss = 0.0488\n",
            "t = 10, avg_loss = 0.1247\n",
            "t = 12, avg_loss = 0.1097\n",
            "t = 14, avg_loss = 0.0500\n",
            "t = 16, avg_loss = 0.0622\n",
            "t = 18, avg_loss = 0.1147\n",
            "t = 20, avg_loss = 0.0689\n",
            "t = 22, avg_loss = 0.0557\n",
            "t = 24, avg_loss = 0.0800\n",
            "Checking accuracy on test set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 86 / 100\n",
            "t = 2, avg_loss = 0.1434\n",
            "t = 4, avg_loss = 0.0647\n",
            "t = 6, avg_loss = 0.0793\n",
            "t = 8, avg_loss = 0.0418\n",
            "t = 10, avg_loss = 0.0811\n",
            "t = 12, avg_loss = 0.0376\n",
            "t = 14, avg_loss = 0.0561\n",
            "t = 16, avg_loss = 0.1123\n",
            "t = 18, avg_loss = 0.0951\n",
            "t = 20, avg_loss = 0.0695\n",
            "t = 22, avg_loss = 0.0394\n",
            "t = 24, avg_loss = 0.1840\n",
            "Checking accuracy on test set\n",
            "Got 354 / 400 correct (88.50)\n",
            "acc = 0.885000\n",
            "Starting epoch 87 / 100\n",
            "t = 2, avg_loss = 0.1166\n",
            "t = 4, avg_loss = 0.0633\n",
            "t = 6, avg_loss = 0.1176\n",
            "t = 8, avg_loss = 0.1152\n",
            "t = 10, avg_loss = 0.0659\n",
            "t = 12, avg_loss = 0.0535\n",
            "t = 14, avg_loss = 0.0703\n",
            "t = 16, avg_loss = 0.0728\n",
            "t = 18, avg_loss = 0.0600\n",
            "t = 20, avg_loss = 0.0552\n",
            "t = 22, avg_loss = 0.0878\n",
            "t = 24, avg_loss = 0.0713\n",
            "Checking accuracy on test set\n",
            "Got 361 / 400 correct (90.25)\n",
            "acc = 0.902500\n",
            "Starting epoch 88 / 100\n",
            "t = 2, avg_loss = 0.0728\n",
            "t = 4, avg_loss = 0.0945\n",
            "t = 6, avg_loss = 0.0477\n",
            "t = 8, avg_loss = 0.0993\n",
            "t = 10, avg_loss = 0.0483\n",
            "t = 12, avg_loss = 0.0516\n",
            "t = 14, avg_loss = 0.0754\n",
            "t = 16, avg_loss = 0.0522\n",
            "t = 18, avg_loss = 0.0427\n",
            "t = 20, avg_loss = 0.0715\n",
            "t = 22, avg_loss = 0.0617\n",
            "t = 24, avg_loss = 0.0545\n",
            "Checking accuracy on test set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 89 / 100\n",
            "t = 2, avg_loss = 0.0601\n",
            "t = 4, avg_loss = 0.0531\n",
            "t = 6, avg_loss = 0.0719\n",
            "t = 8, avg_loss = 0.0309\n",
            "t = 10, avg_loss = 0.0496\n",
            "t = 12, avg_loss = 0.0459\n",
            "t = 14, avg_loss = 0.0525\n",
            "t = 16, avg_loss = 0.0479\n",
            "t = 18, avg_loss = 0.0766\n",
            "t = 20, avg_loss = 0.0296\n",
            "t = 22, avg_loss = 0.0472\n",
            "t = 24, avg_loss = 0.0506\n",
            "Checking accuracy on test set\n",
            "Got 365 / 400 correct (91.25)\n",
            "acc = 0.912500\n",
            "Starting epoch 90 / 100\n",
            "t = 2, avg_loss = 0.0911\n",
            "t = 4, avg_loss = 0.0517\n",
            "t = 6, avg_loss = 0.0490\n",
            "t = 8, avg_loss = 0.0593\n",
            "t = 10, avg_loss = 0.0382\n",
            "t = 12, avg_loss = 0.0667\n",
            "t = 14, avg_loss = 0.0422\n",
            "t = 16, avg_loss = 0.0598\n",
            "t = 18, avg_loss = 0.0396\n",
            "t = 20, avg_loss = 0.0505\n",
            "t = 22, avg_loss = 0.0588\n",
            "t = 24, avg_loss = 0.0352\n",
            "Checking accuracy on test set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 91 / 100\n",
            "t = 2, avg_loss = 0.0777\n",
            "t = 4, avg_loss = 0.0528\n",
            "t = 6, avg_loss = 0.0446\n",
            "t = 8, avg_loss = 0.0354\n",
            "t = 10, avg_loss = 0.0430\n",
            "t = 12, avg_loss = 0.0399\n",
            "t = 14, avg_loss = 0.0652\n",
            "t = 16, avg_loss = 0.0349\n",
            "t = 18, avg_loss = 0.0417\n",
            "t = 20, avg_loss = 0.0356\n",
            "t = 22, avg_loss = 0.0508\n",
            "t = 24, avg_loss = 0.0539\n",
            "Checking accuracy on test set\n",
            "Got 361 / 400 correct (90.25)\n",
            "acc = 0.902500\n",
            "Starting epoch 92 / 100\n",
            "t = 2, avg_loss = 0.0505\n",
            "t = 4, avg_loss = 0.0297\n",
            "t = 6, avg_loss = 0.0547\n",
            "t = 8, avg_loss = 0.0332\n",
            "t = 10, avg_loss = 0.0309\n",
            "t = 12, avg_loss = 0.0788\n",
            "t = 14, avg_loss = 0.0353\n",
            "t = 16, avg_loss = 0.0501\n",
            "t = 18, avg_loss = 0.0370\n",
            "t = 20, avg_loss = 0.0288\n",
            "t = 22, avg_loss = 0.0612\n",
            "t = 24, avg_loss = 0.0391\n",
            "Checking accuracy on test set\n",
            "Got 363 / 400 correct (90.75)\n",
            "acc = 0.907500\n",
            "Starting epoch 93 / 100\n",
            "t = 2, avg_loss = 0.0895\n",
            "t = 4, avg_loss = 0.0271\n",
            "t = 6, avg_loss = 0.0780\n",
            "t = 8, avg_loss = 0.0821\n",
            "t = 10, avg_loss = 0.0254\n",
            "t = 12, avg_loss = 0.0741\n",
            "t = 14, avg_loss = 0.0740\n",
            "t = 16, avg_loss = 0.0875\n",
            "t = 18, avg_loss = 0.0343\n",
            "t = 20, avg_loss = 0.0631\n",
            "t = 22, avg_loss = 0.1151\n",
            "t = 24, avg_loss = 0.0456\n",
            "Checking accuracy on test set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 94 / 100\n",
            "t = 2, avg_loss = 0.0551\n",
            "t = 4, avg_loss = 0.0502\n",
            "t = 6, avg_loss = 0.0616\n",
            "t = 8, avg_loss = 0.0391\n",
            "t = 10, avg_loss = 0.0581\n",
            "t = 12, avg_loss = 0.0598\n",
            "t = 14, avg_loss = 0.0387\n",
            "t = 16, avg_loss = 0.1108\n",
            "t = 18, avg_loss = 0.0522\n",
            "t = 20, avg_loss = 0.0528\n",
            "t = 22, avg_loss = 0.0453\n",
            "t = 24, avg_loss = 0.0843\n",
            "Checking accuracy on test set\n",
            "Got 360 / 400 correct (90.00)\n",
            "acc = 0.900000\n",
            "Starting epoch 95 / 100\n",
            "t = 2, avg_loss = 0.0934\n",
            "t = 4, avg_loss = 0.0403\n",
            "t = 6, avg_loss = 0.0457\n",
            "t = 8, avg_loss = 0.0676\n",
            "t = 10, avg_loss = 0.0489\n",
            "t = 12, avg_loss = 0.0513\n",
            "t = 14, avg_loss = 0.0855\n",
            "t = 16, avg_loss = 0.0457\n",
            "t = 18, avg_loss = 0.0656\n",
            "t = 20, avg_loss = 0.0330\n",
            "t = 22, avg_loss = 0.0443\n",
            "t = 24, avg_loss = 0.0673\n",
            "Checking accuracy on test set\n",
            "Got 359 / 400 correct (89.75)\n",
            "acc = 0.897500\n",
            "Starting epoch 96 / 100\n",
            "t = 2, avg_loss = 0.0835\n",
            "t = 4, avg_loss = 0.0427\n",
            "t = 6, avg_loss = 0.0440\n",
            "t = 8, avg_loss = 0.0395\n",
            "t = 10, avg_loss = 0.0719\n",
            "t = 12, avg_loss = 0.0280\n",
            "t = 14, avg_loss = 0.0449\n",
            "t = 16, avg_loss = 0.0524\n",
            "t = 18, avg_loss = 0.0666\n",
            "t = 20, avg_loss = 0.0609\n",
            "t = 22, avg_loss = 0.0256\n",
            "t = 24, avg_loss = 0.0552\n",
            "Checking accuracy on test set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 97 / 100\n",
            "t = 2, avg_loss = 0.1179\n",
            "t = 4, avg_loss = 0.0292\n",
            "t = 6, avg_loss = 0.0527\n",
            "t = 8, avg_loss = 0.0650\n",
            "t = 10, avg_loss = 0.0482\n",
            "t = 12, avg_loss = 0.0379\n",
            "t = 14, avg_loss = 0.0435\n",
            "t = 16, avg_loss = 0.0420\n",
            "t = 18, avg_loss = 0.0747\n",
            "t = 20, avg_loss = 0.0778\n",
            "t = 22, avg_loss = 0.0532\n",
            "t = 24, avg_loss = 0.0746\n",
            "Checking accuracy on test set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 98 / 100\n",
            "t = 2, avg_loss = 0.0563\n",
            "t = 4, avg_loss = 0.0529\n",
            "t = 6, avg_loss = 0.0781\n",
            "t = 8, avg_loss = 0.0536\n",
            "t = 10, avg_loss = 0.0517\n",
            "t = 12, avg_loss = 0.0570\n",
            "t = 14, avg_loss = 0.0435\n",
            "t = 16, avg_loss = 0.0385\n",
            "t = 18, avg_loss = 0.0836\n",
            "t = 20, avg_loss = 0.0546\n",
            "t = 22, avg_loss = 0.0535\n",
            "t = 24, avg_loss = 0.0509\n",
            "Checking accuracy on test set\n",
            "Got 363 / 400 correct (90.75)\n",
            "acc = 0.907500\n",
            "Starting epoch 99 / 100\n",
            "t = 2, avg_loss = 0.1007\n",
            "t = 4, avg_loss = 0.0335\n",
            "t = 6, avg_loss = 0.0583\n",
            "t = 8, avg_loss = 0.0473\n",
            "t = 10, avg_loss = 0.0724\n",
            "t = 12, avg_loss = 0.0744\n",
            "t = 14, avg_loss = 0.0553\n",
            "t = 16, avg_loss = 0.1102\n",
            "t = 18, avg_loss = 0.0466\n",
            "t = 20, avg_loss = 0.0467\n",
            "t = 22, avg_loss = 0.0698\n",
            "t = 24, avg_loss = 0.0239\n",
            "Checking accuracy on test set\n",
            "Got 357 / 400 correct (89.25)\n",
            "acc = 0.892500\n",
            "Starting epoch 100 / 100\n",
            "t = 2, avg_loss = 0.0867\n",
            "t = 4, avg_loss = 0.0429\n",
            "t = 6, avg_loss = 0.0387\n",
            "t = 8, avg_loss = 0.0646\n",
            "t = 10, avg_loss = 0.0545\n",
            "t = 12, avg_loss = 0.0722\n",
            "t = 14, avg_loss = 0.0626\n",
            "t = 16, avg_loss = 0.0258\n",
            "t = 18, avg_loss = 0.0302\n",
            "t = 20, avg_loss = 0.0599\n",
            "t = 22, avg_loss = 0.0169\n",
            "t = 24, avg_loss = 0.0652\n",
            "Checking accuracy on test set\n",
            "Got 358 / 400 correct (89.50)\n",
            "acc = 0.895000\n",
            "Checking accuracy on test set\n",
            "Got 355 / 400 correct (88.75)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8875"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvoCj5uscUsz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_accurancy(acc_list):\n",
        "  plt.plot([i+1 for i in range((len(acc_list)))],acc_list)\n",
        "  print(\"Accurancy:\")\n",
        "  plt.show()\n",
        "\n",
        "def plot_loss_function(avg_loss_list):\n",
        "  plt.plot([print_every*batch_size*(i+1) for i in range((len(avg_loss_list)))],avg_loss_list)\n",
        "  print(\"Loss:\")\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkH5XGsgqSg5",
        "colab_type": "code",
        "outputId": "c9709504-b40d-4e4b-8175-d8b30f603e50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plot_accurancy(acc_list)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accurancy:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMY5hjrL-sEl",
        "colab_type": "code",
        "outputId": "891ae064-3c7e-4187-e53a-a37bada4d974",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "plot_loss_function(avg_loss_list)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzuX5gLEeJfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def retry_from_backup():\n",
        "  model_gpu = model_base.type(gpu_dtype)\n",
        "  print(model_gpu)\n",
        "  loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) \n",
        "\n",
        "\n",
        "\n",
        "  checkpoint = torch.load(model_backup_path)\n",
        "  model_gpu.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  epoch = checkpoint['epoch']\n",
        "  loss = checkpoint['loss']\n",
        "  acc_list = checkpoint['acc_list']\n",
        "  #avg_loss_list = checkpoint['avg_loss_list']\n",
        "  print(\"starting from epoch: \" + str(epoch))\n",
        "  print(\"starting from loss: \" + str(loss))\n",
        "  print(acc_list)\n",
        "  \n",
        "  \n",
        "  train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=33, starting_from_epoch=epoch)\n",
        "  check_accuracy(model_gpu, valid_loader)\n",
        "\n",
        "  plot_accurancy(acc_list)\n",
        "  plot_loss_function(avg_loss_list)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--rQZKqOalaJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "retry_from_backup()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHmJdkirqU1u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}