{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN_ascending_layers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamilo116/KNN/blob/master/KNN_ascending_layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7ReM7FU-xs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import sys\n",
        "from random import shuffle\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms as transforms\n",
        "import timeit\n",
        "\n",
        "np.random.seed(4) \n",
        "torch.manual_seed(4) \n",
        "torch.cuda.manual_seed(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYIMZ8QyYewD",
        "colab_type": "code",
        "outputId": "263a0571-e6e5-437d-95cc-a8b6feb934dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "! git clone https://github.com/wang-chen/kervolution.git \n",
        "\n",
        "sys.path.append(\"kervolution/\")\n",
        "from kervolution import Kerv2d\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'kervolution' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvbKg4VJXKY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LIMIT_IMAGES_NUM = 1000\n",
        "train_test_split_size = 0.2\n",
        "image_resize = (100, 100)\n",
        "batch_size = 32\n",
        "num_workers = 0\n",
        "\n",
        "out_1 = 16\n",
        "out_2 = 24\n",
        "out_3 = 32\n",
        "#out_4 = 64\n",
        "#out_5 = 128\n",
        "\n",
        "\n",
        "k_size_1 = 3\n",
        "padding_1 = 1\n",
        "in_channels = 3\n",
        "\n",
        "kernel_size = 3\n",
        "num_epochs = 80\n",
        "\n",
        "learning_rate = 0.0001\n",
        "weight_decay = 0.05\n",
        "\n",
        "MALIGNANT_DATASET = '/content/drive/My Drive/Colab_data/malignant/malignant/'\n",
        "BENIGN_DATASET = '/content/drive/My Drive/Colab_data/benign/benign/'\n",
        "DATA_FOLDER = '/content/drive/My Drive/Colab_data/'\n",
        "model_backup_path = os.path.join(DATA_FOLDER, 'backup_model3') \n",
        "TRAIN_DATA_PER_CATEGORY = 101"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMOHez_kHZD6",
        "colab_type": "code",
        "outputId": "5ebc93bd-6fe8-4ca3-ce77-9676dae03594",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b8P1NdXfVdX",
        "colab_type": "code",
        "outputId": "32dd610e-4cd6-4320-d5fc-7457d11b810e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "benign_train_list = sorted(os.listdir(BENIGN_DATASET))[:LIMIT_IMAGES_NUM]\n",
        "malignant_train_list = sorted(os.listdir(MALIGNANT_DATASET))[:LIMIT_IMAGES_NUM]\n",
        "\n",
        "shuffle(benign_train_list)\n",
        "shuffle(malignant_train_list)\n",
        "\n",
        "test_benign_file_list = os.listdir(BENIGN_DATASET + 'test_set')[:TRAIN_DATA_PER_CATEGORY]\n",
        "test_malignant_file_list = os.listdir(MALIGNANT_DATASET + 'test_set')[:TRAIN_DATA_PER_CATEGORY]\n",
        "\n",
        "print(f\"Number of training benign {len(benign_train_list)} images\")\n",
        "print(f\"Number of training malignant {len(malignant_train_list)} images\")\n",
        "print(f\"Number of test benign {len(test_benign_file_list)} images\")\n",
        "print(f\"Number of test malignant {len(test_malignant_file_list)} images\")\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize(image_resize),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    #transforms.RandomRotation(45),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "data_transforms_test = transforms.Compose([\n",
        "    transforms.Resize(image_resize),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training benign 1000 images\n",
            "Number of training malignant 1000 images\n",
            "Number of test benign 101 images\n",
            "Number of test malignant 101 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvAAOqmVfVll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IsicDataset(Dataset):\n",
        "    def __init__(self, data_folder, labeled_data, \n",
        "                 transform=transforms.Compose([transforms.ToTensor()]), datatype='train'):\n",
        "        self.labeled_data = labeled_data\n",
        "        self.transform = transform\n",
        "        self.data_folder = data_folder\n",
        "        self.datatype = datatype\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labeled_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        label = self.labeled_data[index]\n",
        "        test_set = ''\n",
        "        if self.datatype == 'test':\n",
        "          test_set = 'test_set'  \n",
        "        if label == 0:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"benign\", \"benign\", test_set, index ))\n",
        "        else:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"malignant\", \"malignant\", test_set, index ))\n",
        "        image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "    @property\n",
        "    def labels(self):\n",
        "      return self.labeled_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e8nFBR6Yug5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "def prepare_dataset(benign_file_list, malignant_file_list, transform, datatype='train'):\n",
        "  benign_dict = {filename: 0 for filename in benign_file_list}\n",
        "  malignant_dict = {filename: 1 for filename in malignant_file_list}\n",
        "  img_class_dict = {**benign_dict , **malignant_dict}\n",
        "  labeled_data = pd.Series(img_class_dict)\n",
        "\n",
        "  dataset = IsicDataset(DATA_FOLDER, labeled_data, transform=transform, datatype=datatype)\n",
        "  print(dataset.labels)\n",
        "  return dataset\n",
        "\n",
        "def train(model, train_loader ,loss_fn, optimizer, num_epochs=1, starting_from_epoch=1):\n",
        "    total_loss =0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Starting epoch %d / %d' % (epoch, num_epochs))\n",
        "        model.train()\n",
        "\n",
        "        for t, (x, y) in enumerate(train_loader):\n",
        "            x_var = Variable(x.type(gpu_dtype))\n",
        "            y_var = Variable(y.type(gpu_dtype).long())\n",
        "            scores = model(x_var)\n",
        "            loss = loss_fn(scores, y_var)\n",
        "            total_loss += loss.data\n",
        "            \n",
        "            if (t + 1) % print_every == 0:\n",
        "                avg_loss = total_loss/print_every\n",
        "                print('t = %d, avg_loss = %.4f' % (t + 1, avg_loss) )\n",
        "                avg_loss_list.append(avg_loss)\n",
        "                total_loss = 0\n",
        "                \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        acc = check_accuracy(model_gpu, valid_loader)\n",
        "        print('acc = %f' %(acc))\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model_gpu.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            'acc_list': acc_list,\n",
        "            }, model_backup_path)\n",
        "            \n",
        "def check_accuracy(model, loader, datatype='train'):\n",
        "    print(f'Checking accuracy on {datatype} set')   \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval() \n",
        "    for x, y in loader:\n",
        "        x_var = Variable(x.type(gpu_dtype))\n",
        "\n",
        "        scores = model(x_var)\n",
        "        _, preds = scores.data.cpu().max(1)\n",
        "        num_correct += (preds == y).sum()\n",
        "        num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    if datatype is 'train':\n",
        "      acc_list.append(acc)\n",
        "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "    return acc\n",
        "    \n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.size()\n",
        "        return x.view(N, -1)  \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSuYqjLAYrWA",
        "colab_type": "code",
        "outputId": "520afeea-d258-4664-cfb1-4c9c0d8e5266",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        }
      },
      "source": [
        "train_dataset = prepare_dataset(benign_train_list, malignant_train_list, data_transforms)\n",
        "\n",
        "X_train, X_valid = train_test_split(train_dataset.labels, test_size=train_test_split_size)\n",
        "\n",
        "print(\"number of training data: \",len(X_train))\n",
        "print(\"number of valid  data: \",len(X_valid))\n",
        "\n",
        "train_sampler = SubsetRandomSampler(list(X_train.index))\n",
        "valid_sampler = SubsetRandomSampler(list(X_valid.index))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ISIC_0000924.jpeg    0\n",
            "ISIC_0001130.jpeg    0\n",
            "ISIC_0000789.jpeg    0\n",
            "ISIC_0002905.jpeg    0\n",
            "ISIC_0000662.jpeg    0\n",
            "                    ..\n",
            "ISIC_0010883.jpeg    1\n",
            "ISIC_0014480.jpeg    1\n",
            "ISIC_0012044.jpeg    1\n",
            "ISIC_0014784.jpeg    1\n",
            "ISIC_0009868.jpeg    1\n",
            "Length: 2000, dtype: int64\n",
            "number of training data:  1600\n",
            "number of valid  data:  400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KIt7qu32yW5",
        "colab_type": "code",
        "outputId": "8ae0801e-8bb3-4658-c706-06c3411268e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "source": [
        "test_dataset = prepare_dataset(test_benign_file_list, test_malignant_file_list, data_transforms_test, datatype='test')\n",
        "test_part, _ = train_test_split(test_dataset.labels, test_size=1)\n",
        "test_sampler = SubsetRandomSampler(list(test_part.index))\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=50, sampler=test_sampler, num_workers=num_workers)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ISIC_0000081.jpeg    0\n",
            "ISIC_0000033.jpeg    0\n",
            "ISIC_0000023.jpeg    0\n",
            "ISIC_0000137.jpeg    0\n",
            "ISIC_0000073.jpeg    0\n",
            "                    ..\n",
            "ISIC_0025783.jpg     1\n",
            "ISIC_0026604.jpg     1\n",
            "ISIC_0026754.jpg     1\n",
            "ISIC_0026847.jpg     1\n",
            "ISIC_0027060.jpg     1\n",
            "Length: 202, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-gYHw0Jlbwt",
        "colab_type": "code",
        "outputId": "d78daedd-af24-4fc8-b940-c45a8511bd2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        }
      },
      "source": [
        "print_every = 5\n",
        "gpu_dtype = torch.cuda.FloatTensor\n",
        "\n",
        "\n",
        "'''\n",
        "Kerv2d\n",
        "kervolution with following options:\n",
        "kernel_type: [linear, polynomial, gaussian, etc.]\n",
        "default is convolution:\n",
        "          kernel_type --> linear,\n",
        "balance, power, gamma is valid only when the kernel_type is specified\n",
        "if learnable_kernel = True,  they just be the initial value of learable parameters\n",
        "if learnable_kernel = False, they are the value of kernel_type's parameter\n",
        "the parameter [power] cannot be learned due to integer limitation\n",
        "dilation (int or tuple, optional): Spacing between kernel\n",
        "elements. Default: 1\n",
        "groups (int, optional): Number of blocked connections from input\n",
        "channels to output channels. Default: 1\n",
        "bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n",
        "kernel_type (str), Default: 'linear'\n",
        "learnable_kernel (bool): Learnable kernel parameters.  Default: False \n",
        "balance: 0, 1\n",
        "power: 3, 4, 5\n",
        "gamma:\n",
        "'''\n",
        "\n",
        "\n",
        "model_base = nn.Sequential( \n",
        "                #nn.Conv2d(in_channels , out_1, padding= padding_1, kernel_size=k_size_1, stride=1),\n",
        "                nn.Kerv2d(in_channels , out_1, padding=padding_1, bias=True, \n",
        "                          kernel_type='gaussian', kernel_size=3, learnable_kernel=True,\n",
        "                          kernel_regularizer=True, stride=1, gamma=0.73\n",
        "                          ), \n",
        "                #nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_1),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_1 , out_2, padding= padding_1, kernel_size=3, stride=1), \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_2),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_2 , out_3, padding= padding_1, kernel_size=3, stride=1),  \n",
        "                \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_3),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                # nn.Conv2d(out_3 , out_4, padding= padding_1, kernel_size=3, stride=1),  \n",
        "                # nn.ReLU(inplace=True),\n",
        "                # nn.BatchNorm2d(out_4),\n",
        "                # nn.MaxPool2d(2, stride=2),\n",
        "                # nn.Conv2d(out_4 , out_5, padding= padding_1, kernel_size=3, stride=1),  \n",
        "                # nn.ReLU(inplace=True),\n",
        "                # nn.BatchNorm2d(out_5),\n",
        "                # nn.MaxPool2d(2, stride=2),\n",
        "                nn.Dropout(0.4),\n",
        "                Flatten(),\n",
        "                nn.Linear(4608,32),\n",
        "                nn.Dropout(0.05),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Linear(32,2)\n",
        "            )\n",
        "model_gpu = model_base.type(gpu_dtype)\n",
        "print(model_gpu)\n",
        "loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Kerv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (3): Conv2d(16, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (4): ReLU(inplace=True)\n",
            "  (5): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (7): Conv2d(24, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (8): ReLU(inplace=True)\n",
            "  (9): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (11): Dropout(p=0.4, inplace=False)\n",
            "  (12): Flatten()\n",
            "  (13): Linear(in_features=4608, out_features=32, bias=True)\n",
            "  (14): Dropout(p=0.05, inplace=False)\n",
            "  (15): ReLU(inplace=True)\n",
            "  (16): Linear(in_features=32, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGcLjqQPLBtb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9g2InVVNVeQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgmexhBRZAK6",
        "colab_type": "code",
        "outputId": "9d42a4e7-eaf5-4a90-c862-7beef0b343b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 0 / 80\n",
            "t = 5, avg_loss = 0.6634\n",
            "t = 10, avg_loss = 0.6048\n",
            "t = 15, avg_loss = 0.6069\n",
            "t = 20, avg_loss = 0.6466\n",
            "t = 25, avg_loss = 0.5577\n",
            "t = 30, avg_loss = 0.5361\n",
            "t = 35, avg_loss = 0.5473\n",
            "t = 40, avg_loss = 0.5281\n",
            "t = 45, avg_loss = 0.5495\n",
            "t = 50, avg_loss = 0.5443\n",
            "Checking accuracy on train set\n",
            "Got 266 / 400 correct (66.50)\n",
            "acc = 0.665000\n",
            "Starting epoch 1 / 80\n",
            "t = 5, avg_loss = 0.5050\n",
            "t = 10, avg_loss = 0.5282\n",
            "t = 15, avg_loss = 0.4707\n",
            "t = 20, avg_loss = 0.5313\n",
            "t = 25, avg_loss = 0.5051\n",
            "t = 30, avg_loss = 0.5293\n",
            "t = 35, avg_loss = 0.4985\n",
            "t = 40, avg_loss = 0.4806\n",
            "t = 45, avg_loss = 0.5612\n",
            "t = 50, avg_loss = 0.4932\n",
            "Checking accuracy on train set\n",
            "Got 304 / 400 correct (76.00)\n",
            "acc = 0.760000\n",
            "Starting epoch 2 / 80\n",
            "t = 5, avg_loss = 0.4749\n",
            "t = 10, avg_loss = 0.4296\n",
            "t = 15, avg_loss = 0.5902\n",
            "t = 20, avg_loss = 0.4400\n",
            "t = 25, avg_loss = 0.4726\n",
            "t = 30, avg_loss = 0.4496\n",
            "t = 35, avg_loss = 0.4794\n",
            "t = 40, avg_loss = 0.5167\n",
            "t = 45, avg_loss = 0.5077\n",
            "t = 50, avg_loss = 0.4418\n",
            "Checking accuracy on train set\n",
            "Got 288 / 400 correct (72.00)\n",
            "acc = 0.720000\n",
            "Starting epoch 3 / 80\n",
            "t = 5, avg_loss = 0.4369\n",
            "t = 10, avg_loss = 0.4419\n",
            "t = 15, avg_loss = 0.4406\n",
            "t = 20, avg_loss = 0.4394\n",
            "t = 25, avg_loss = 0.4143\n",
            "t = 30, avg_loss = 0.4682\n",
            "t = 35, avg_loss = 0.4265\n",
            "t = 40, avg_loss = 0.5138\n",
            "t = 45, avg_loss = 0.5282\n",
            "t = 50, avg_loss = 0.4602\n",
            "Checking accuracy on train set\n",
            "Got 307 / 400 correct (76.75)\n",
            "acc = 0.767500\n",
            "Starting epoch 4 / 80\n",
            "t = 5, avg_loss = 0.4093\n",
            "t = 10, avg_loss = 0.4544\n",
            "t = 15, avg_loss = 0.4542\n",
            "t = 20, avg_loss = 0.4145\n",
            "t = 25, avg_loss = 0.4287\n",
            "t = 30, avg_loss = 0.4060\n",
            "t = 35, avg_loss = 0.3916\n",
            "t = 40, avg_loss = 0.4797\n",
            "t = 45, avg_loss = 0.4849\n",
            "t = 50, avg_loss = 0.4484\n",
            "Checking accuracy on train set\n",
            "Got 283 / 400 correct (70.75)\n",
            "acc = 0.707500\n",
            "Starting epoch 5 / 80\n",
            "t = 5, avg_loss = 0.4308\n",
            "t = 10, avg_loss = 0.4323\n",
            "t = 15, avg_loss = 0.3818\n",
            "t = 20, avg_loss = 0.4657\n",
            "t = 25, avg_loss = 0.4217\n",
            "t = 30, avg_loss = 0.4671\n",
            "t = 35, avg_loss = 0.4206\n",
            "t = 40, avg_loss = 0.4260\n",
            "t = 45, avg_loss = 0.4171\n",
            "t = 50, avg_loss = 0.4813\n",
            "Checking accuracy on train set\n",
            "Got 318 / 400 correct (79.50)\n",
            "acc = 0.795000\n",
            "Starting epoch 6 / 80\n",
            "t = 5, avg_loss = 0.4403\n",
            "t = 10, avg_loss = 0.3760\n",
            "t = 15, avg_loss = 0.4285\n",
            "t = 20, avg_loss = 0.4273\n",
            "t = 25, avg_loss = 0.4717\n",
            "t = 30, avg_loss = 0.4285\n",
            "t = 35, avg_loss = 0.3972\n",
            "t = 40, avg_loss = 0.4632\n",
            "t = 45, avg_loss = 0.3615\n",
            "t = 50, avg_loss = 0.5156\n",
            "Checking accuracy on train set\n",
            "Got 313 / 400 correct (78.25)\n",
            "acc = 0.782500\n",
            "Starting epoch 7 / 80\n",
            "t = 5, avg_loss = 0.4319\n",
            "t = 10, avg_loss = 0.4315\n",
            "t = 15, avg_loss = 0.4061\n",
            "t = 20, avg_loss = 0.3963\n",
            "t = 25, avg_loss = 0.4183\n",
            "t = 30, avg_loss = 0.4313\n",
            "t = 35, avg_loss = 0.3950\n",
            "t = 40, avg_loss = 0.3593\n",
            "t = 45, avg_loss = 0.4239\n",
            "t = 50, avg_loss = 0.3576\n",
            "Checking accuracy on train set\n",
            "Got 312 / 400 correct (78.00)\n",
            "acc = 0.780000\n",
            "Starting epoch 8 / 80\n",
            "t = 5, avg_loss = 0.4092\n",
            "t = 10, avg_loss = 0.3855\n",
            "t = 15, avg_loss = 0.3808\n",
            "t = 20, avg_loss = 0.3877\n",
            "t = 25, avg_loss = 0.4061\n",
            "t = 30, avg_loss = 0.3890\n",
            "t = 35, avg_loss = 0.3698\n",
            "t = 40, avg_loss = 0.3988\n",
            "t = 45, avg_loss = 0.3665\n",
            "t = 50, avg_loss = 0.4827\n",
            "Checking accuracy on train set\n",
            "Got 320 / 400 correct (80.00)\n",
            "acc = 0.800000\n",
            "Starting epoch 9 / 80\n",
            "t = 5, avg_loss = 0.3404\n",
            "t = 10, avg_loss = 0.3568\n",
            "t = 15, avg_loss = 0.3473\n",
            "t = 20, avg_loss = 0.3700\n",
            "t = 25, avg_loss = 0.3569\n",
            "t = 30, avg_loss = 0.4649\n",
            "t = 35, avg_loss = 0.4130\n",
            "t = 40, avg_loss = 0.3637\n",
            "t = 45, avg_loss = 0.4510\n",
            "t = 50, avg_loss = 0.4234\n",
            "Checking accuracy on train set\n",
            "Got 322 / 400 correct (80.50)\n",
            "acc = 0.805000\n",
            "Starting epoch 10 / 80\n",
            "t = 5, avg_loss = 0.4027\n",
            "t = 10, avg_loss = 0.2907\n",
            "t = 15, avg_loss = 0.3726\n",
            "t = 20, avg_loss = 0.3277\n",
            "t = 25, avg_loss = 0.3536\n",
            "t = 30, avg_loss = 0.4413\n",
            "t = 35, avg_loss = 0.3899\n",
            "t = 40, avg_loss = 0.5310\n",
            "t = 45, avg_loss = 0.3793\n",
            "t = 50, avg_loss = 0.3854\n",
            "Checking accuracy on train set\n",
            "Got 300 / 400 correct (75.00)\n",
            "acc = 0.750000\n",
            "Starting epoch 11 / 80\n",
            "t = 5, avg_loss = 0.3402\n",
            "t = 10, avg_loss = 0.3733\n",
            "t = 15, avg_loss = 0.3726\n",
            "t = 20, avg_loss = 0.3436\n",
            "t = 25, avg_loss = 0.3605\n",
            "t = 30, avg_loss = 0.3622\n",
            "t = 35, avg_loss = 0.3485\n",
            "t = 40, avg_loss = 0.4185\n",
            "t = 45, avg_loss = 0.4375\n",
            "t = 50, avg_loss = 0.4209\n",
            "Checking accuracy on train set\n",
            "Got 299 / 400 correct (74.75)\n",
            "acc = 0.747500\n",
            "Starting epoch 12 / 80\n",
            "t = 5, avg_loss = 0.3899\n",
            "t = 10, avg_loss = 0.3311\n",
            "t = 15, avg_loss = 0.3569\n",
            "t = 20, avg_loss = 0.3693\n",
            "t = 25, avg_loss = 0.4784\n",
            "t = 30, avg_loss = 0.4020\n",
            "t = 35, avg_loss = 0.3393\n",
            "t = 40, avg_loss = 0.3779\n",
            "t = 45, avg_loss = 0.3718\n",
            "t = 50, avg_loss = 0.3274\n",
            "Checking accuracy on train set\n",
            "Got 298 / 400 correct (74.50)\n",
            "acc = 0.745000\n",
            "Starting epoch 13 / 80\n",
            "t = 5, avg_loss = 0.4167\n",
            "t = 10, avg_loss = 0.3748\n",
            "t = 15, avg_loss = 0.4020\n",
            "t = 20, avg_loss = 0.4373\n",
            "t = 25, avg_loss = 0.3142\n",
            "t = 30, avg_loss = 0.3184\n",
            "t = 35, avg_loss = 0.3691\n",
            "t = 40, avg_loss = 0.3370\n",
            "t = 45, avg_loss = 0.3514\n",
            "t = 50, avg_loss = 0.3052\n",
            "Checking accuracy on train set\n",
            "Got 296 / 400 correct (74.00)\n",
            "acc = 0.740000\n",
            "Starting epoch 14 / 80\n",
            "t = 5, avg_loss = 0.3336\n",
            "t = 10, avg_loss = 0.3476\n",
            "t = 15, avg_loss = 0.3528\n",
            "t = 20, avg_loss = 0.3863\n",
            "t = 25, avg_loss = 0.3612\n",
            "t = 30, avg_loss = 0.4474\n",
            "t = 35, avg_loss = 0.4065\n",
            "t = 40, avg_loss = 0.4140\n",
            "t = 45, avg_loss = 0.3056\n",
            "t = 50, avg_loss = 0.3445\n",
            "Checking accuracy on train set\n",
            "Got 305 / 400 correct (76.25)\n",
            "acc = 0.762500\n",
            "Starting epoch 15 / 80\n",
            "t = 5, avg_loss = 0.3637\n",
            "t = 10, avg_loss = 0.3495\n",
            "t = 15, avg_loss = 0.3267\n",
            "t = 20, avg_loss = 0.3596\n",
            "t = 25, avg_loss = 0.3335\n",
            "t = 30, avg_loss = 0.3694\n",
            "t = 35, avg_loss = 0.3900\n",
            "t = 40, avg_loss = 0.3592\n",
            "t = 45, avg_loss = 0.3836\n",
            "t = 50, avg_loss = 0.3412\n",
            "Checking accuracy on train set\n",
            "Got 331 / 400 correct (82.75)\n",
            "acc = 0.827500\n",
            "Starting epoch 16 / 80\n",
            "t = 5, avg_loss = 0.3851\n",
            "t = 10, avg_loss = 0.2933\n",
            "t = 15, avg_loss = 0.2956\n",
            "t = 20, avg_loss = 0.4121\n",
            "t = 25, avg_loss = 0.3443\n",
            "t = 30, avg_loss = 0.4052\n",
            "t = 35, avg_loss = 0.4101\n",
            "t = 40, avg_loss = 0.3254\n",
            "t = 45, avg_loss = 0.3461\n",
            "t = 50, avg_loss = 0.3199\n",
            "Checking accuracy on train set\n",
            "Got 316 / 400 correct (79.00)\n",
            "acc = 0.790000\n",
            "Starting epoch 17 / 80\n",
            "t = 5, avg_loss = 0.4451\n",
            "t = 10, avg_loss = 0.3082\n",
            "t = 15, avg_loss = 0.3778\n",
            "t = 20, avg_loss = 0.3301\n",
            "t = 25, avg_loss = 0.4189\n",
            "t = 30, avg_loss = 0.3018\n",
            "t = 35, avg_loss = 0.4121\n",
            "t = 40, avg_loss = 0.3242\n",
            "t = 45, avg_loss = 0.4322\n",
            "t = 50, avg_loss = 0.2623\n",
            "Checking accuracy on train set\n",
            "Got 324 / 400 correct (81.00)\n",
            "acc = 0.810000\n",
            "Starting epoch 18 / 80\n",
            "t = 5, avg_loss = 0.2997\n",
            "t = 10, avg_loss = 0.3398\n",
            "t = 15, avg_loss = 0.3173\n",
            "t = 20, avg_loss = 0.2826\n",
            "t = 25, avg_loss = 0.3548\n",
            "t = 30, avg_loss = 0.3732\n",
            "t = 35, avg_loss = 0.3304\n",
            "t = 40, avg_loss = 0.3321\n",
            "t = 45, avg_loss = 0.3172\n",
            "t = 50, avg_loss = 0.3214\n",
            "Checking accuracy on train set\n",
            "Got 319 / 400 correct (79.75)\n",
            "acc = 0.797500\n",
            "Starting epoch 19 / 80\n",
            "t = 5, avg_loss = 0.3143\n",
            "t = 10, avg_loss = 0.3209\n",
            "t = 15, avg_loss = 0.3598\n",
            "t = 20, avg_loss = 0.3086\n",
            "t = 25, avg_loss = 0.2913\n",
            "t = 30, avg_loss = 0.2889\n",
            "t = 35, avg_loss = 0.2897\n",
            "t = 40, avg_loss = 0.4125\n",
            "t = 45, avg_loss = 0.3780\n",
            "t = 50, avg_loss = 0.3794\n",
            "Checking accuracy on train set\n",
            "Got 310 / 400 correct (77.50)\n",
            "acc = 0.775000\n",
            "Starting epoch 20 / 80\n",
            "t = 5, avg_loss = 0.3213\n",
            "t = 10, avg_loss = 0.3084\n",
            "t = 15, avg_loss = 0.3390\n",
            "t = 20, avg_loss = 0.3584\n",
            "t = 25, avg_loss = 0.3352\n",
            "t = 30, avg_loss = 0.3784\n",
            "t = 35, avg_loss = 0.3126\n",
            "t = 40, avg_loss = 0.3445\n",
            "t = 45, avg_loss = 0.3017\n",
            "t = 50, avg_loss = 0.3098\n",
            "Checking accuracy on train set\n",
            "Got 322 / 400 correct (80.50)\n",
            "acc = 0.805000\n",
            "Starting epoch 21 / 80\n",
            "t = 5, avg_loss = 0.3334\n",
            "t = 10, avg_loss = 0.3495\n",
            "t = 15, avg_loss = 0.2991\n",
            "t = 20, avg_loss = 0.3522\n",
            "t = 25, avg_loss = 0.2898\n",
            "t = 30, avg_loss = 0.3869\n",
            "t = 35, avg_loss = 0.2989\n",
            "t = 40, avg_loss = 0.2819\n",
            "t = 45, avg_loss = 0.3274\n",
            "t = 50, avg_loss = 0.3168\n",
            "Checking accuracy on train set\n",
            "Got 314 / 400 correct (78.50)\n",
            "acc = 0.785000\n",
            "Starting epoch 22 / 80\n",
            "t = 5, avg_loss = 0.3440\n",
            "t = 10, avg_loss = 0.2838\n",
            "t = 15, avg_loss = 0.3865\n",
            "t = 20, avg_loss = 0.3164\n",
            "t = 25, avg_loss = 0.3943\n",
            "t = 30, avg_loss = 0.3309\n",
            "t = 35, avg_loss = 0.2994\n",
            "t = 40, avg_loss = 0.3167\n",
            "t = 45, avg_loss = 0.2932\n",
            "t = 50, avg_loss = 0.3051\n",
            "Checking accuracy on train set\n",
            "Got 314 / 400 correct (78.50)\n",
            "acc = 0.785000\n",
            "Starting epoch 23 / 80\n",
            "t = 5, avg_loss = 0.3155\n",
            "t = 10, avg_loss = 0.3603\n",
            "t = 15, avg_loss = 0.3538\n",
            "t = 20, avg_loss = 0.2914\n",
            "t = 25, avg_loss = 0.3281\n",
            "t = 30, avg_loss = 0.3071\n",
            "t = 35, avg_loss = 0.2904\n",
            "t = 40, avg_loss = 0.2886\n",
            "t = 45, avg_loss = 0.3424\n",
            "t = 50, avg_loss = 0.3635\n",
            "Checking accuracy on train set\n",
            "Got 321 / 400 correct (80.25)\n",
            "acc = 0.802500\n",
            "Starting epoch 24 / 80\n",
            "t = 5, avg_loss = 0.3067\n",
            "t = 10, avg_loss = 0.3299\n",
            "t = 15, avg_loss = 0.3883\n",
            "t = 20, avg_loss = 0.3343\n",
            "t = 25, avg_loss = 0.3226\n",
            "t = 30, avg_loss = 0.3096\n",
            "t = 35, avg_loss = 0.2994\n",
            "t = 40, avg_loss = 0.3458\n",
            "t = 45, avg_loss = 0.2870\n",
            "t = 50, avg_loss = 0.4213\n",
            "Checking accuracy on train set\n",
            "Got 326 / 400 correct (81.50)\n",
            "acc = 0.815000\n",
            "Starting epoch 25 / 80\n",
            "t = 5, avg_loss = 0.3141\n",
            "t = 10, avg_loss = 0.3457\n",
            "t = 15, avg_loss = 0.3364\n",
            "t = 20, avg_loss = 0.3236\n",
            "t = 25, avg_loss = 0.3411\n",
            "t = 30, avg_loss = 0.3488\n",
            "t = 35, avg_loss = 0.3186\n",
            "t = 40, avg_loss = 0.2780\n",
            "t = 45, avg_loss = 0.3429\n",
            "t = 50, avg_loss = 0.3579\n",
            "Checking accuracy on train set\n",
            "Got 328 / 400 correct (82.00)\n",
            "acc = 0.820000\n",
            "Starting epoch 26 / 80\n",
            "t = 5, avg_loss = 0.3629\n",
            "t = 10, avg_loss = 0.2793\n",
            "t = 15, avg_loss = 0.3169\n",
            "t = 20, avg_loss = 0.2966\n",
            "t = 25, avg_loss = 0.2588\n",
            "t = 30, avg_loss = 0.3301\n",
            "t = 35, avg_loss = 0.3478\n",
            "t = 40, avg_loss = 0.2992\n",
            "t = 45, avg_loss = 0.3295\n",
            "t = 50, avg_loss = 0.2812\n",
            "Checking accuracy on train set\n",
            "Got 326 / 400 correct (81.50)\n",
            "acc = 0.815000\n",
            "Starting epoch 27 / 80\n",
            "t = 5, avg_loss = 0.2897\n",
            "t = 10, avg_loss = 0.3098\n",
            "t = 15, avg_loss = 0.2950\n",
            "t = 20, avg_loss = 0.2719\n",
            "t = 25, avg_loss = 0.3189\n",
            "t = 30, avg_loss = 0.3057\n",
            "t = 35, avg_loss = 0.3230\n",
            "t = 40, avg_loss = 0.2689\n",
            "t = 45, avg_loss = 0.3137\n",
            "t = 50, avg_loss = 0.3324\n",
            "Checking accuracy on train set\n",
            "Got 324 / 400 correct (81.00)\n",
            "acc = 0.810000\n",
            "Starting epoch 28 / 80\n",
            "t = 5, avg_loss = 0.2926\n",
            "t = 10, avg_loss = 0.3033\n",
            "t = 15, avg_loss = 0.3320\n",
            "t = 20, avg_loss = 0.2859\n",
            "t = 25, avg_loss = 0.3334\n",
            "t = 30, avg_loss = 0.2390\n",
            "t = 35, avg_loss = 0.3361\n",
            "t = 40, avg_loss = 0.2752\n",
            "t = 45, avg_loss = 0.3102\n",
            "t = 50, avg_loss = 0.3406\n",
            "Checking accuracy on train set\n",
            "Got 325 / 400 correct (81.25)\n",
            "acc = 0.812500\n",
            "Starting epoch 29 / 80\n",
            "t = 5, avg_loss = 0.2921\n",
            "t = 10, avg_loss = 0.3249\n",
            "t = 15, avg_loss = 0.2806\n",
            "t = 20, avg_loss = 0.2655\n",
            "t = 25, avg_loss = 0.2852\n",
            "t = 30, avg_loss = 0.2758\n",
            "t = 35, avg_loss = 0.3831\n",
            "t = 40, avg_loss = 0.2853\n",
            "t = 45, avg_loss = 0.3158\n",
            "t = 50, avg_loss = 0.2349\n",
            "Checking accuracy on train set\n",
            "Got 322 / 400 correct (80.50)\n",
            "acc = 0.805000\n",
            "Starting epoch 30 / 80\n",
            "t = 5, avg_loss = 0.2770\n",
            "t = 10, avg_loss = 0.3259\n",
            "t = 15, avg_loss = 0.2994\n",
            "t = 20, avg_loss = 0.3102\n",
            "t = 25, avg_loss = 0.2978\n",
            "t = 30, avg_loss = 0.2870\n",
            "t = 35, avg_loss = 0.3191\n",
            "t = 40, avg_loss = 0.2804\n",
            "t = 45, avg_loss = 0.3499\n",
            "t = 50, avg_loss = 0.2814\n",
            "Checking accuracy on train set\n",
            "Got 335 / 400 correct (83.75)\n",
            "acc = 0.837500\n",
            "Starting epoch 31 / 80\n",
            "t = 5, avg_loss = 0.2947\n",
            "t = 10, avg_loss = 0.3072\n",
            "t = 15, avg_loss = 0.3397\n",
            "t = 20, avg_loss = 0.3642\n",
            "t = 25, avg_loss = 0.2716\n",
            "t = 30, avg_loss = 0.2983\n",
            "t = 35, avg_loss = 0.2713\n",
            "t = 40, avg_loss = 0.3483\n",
            "t = 45, avg_loss = 0.2477\n",
            "t = 50, avg_loss = 0.2397\n",
            "Checking accuracy on train set\n",
            "Got 306 / 400 correct (76.50)\n",
            "acc = 0.765000\n",
            "Starting epoch 32 / 80\n",
            "t = 5, avg_loss = 0.2980\n",
            "t = 10, avg_loss = 0.2876\n",
            "t = 15, avg_loss = 0.3520\n",
            "t = 20, avg_loss = 0.3394\n",
            "t = 25, avg_loss = 0.2622\n",
            "t = 30, avg_loss = 0.3393\n",
            "t = 35, avg_loss = 0.2492\n",
            "t = 40, avg_loss = 0.2813\n",
            "t = 45, avg_loss = 0.3118\n",
            "t = 50, avg_loss = 0.2469\n",
            "Checking accuracy on train set\n",
            "Got 320 / 400 correct (80.00)\n",
            "acc = 0.800000\n",
            "Starting epoch 33 / 80\n",
            "t = 5, avg_loss = 0.2939\n",
            "t = 10, avg_loss = 0.3356\n",
            "t = 15, avg_loss = 0.2085\n",
            "t = 20, avg_loss = 0.3514\n",
            "t = 25, avg_loss = 0.3042\n",
            "t = 30, avg_loss = 0.3334\n",
            "t = 35, avg_loss = 0.2956\n",
            "t = 40, avg_loss = 0.3231\n",
            "t = 45, avg_loss = 0.2766\n",
            "t = 50, avg_loss = 0.2881\n",
            "Checking accuracy on train set\n",
            "Got 323 / 400 correct (80.75)\n",
            "acc = 0.807500\n",
            "Starting epoch 34 / 80\n",
            "t = 5, avg_loss = 0.2863\n",
            "t = 10, avg_loss = 0.2817\n",
            "t = 15, avg_loss = 0.2370\n",
            "t = 20, avg_loss = 0.2428\n",
            "t = 25, avg_loss = 0.3008\n",
            "t = 30, avg_loss = 0.2748\n",
            "t = 35, avg_loss = 0.2779\n",
            "t = 40, avg_loss = 0.2914\n",
            "t = 45, avg_loss = 0.2375\n",
            "t = 50, avg_loss = 0.2603\n",
            "Checking accuracy on train set\n",
            "Got 327 / 400 correct (81.75)\n",
            "acc = 0.817500\n",
            "Starting epoch 35 / 80\n",
            "t = 5, avg_loss = 0.2899\n",
            "t = 10, avg_loss = 0.3039\n",
            "t = 15, avg_loss = 0.2593\n",
            "t = 20, avg_loss = 0.2623\n",
            "t = 25, avg_loss = 0.2843\n",
            "t = 30, avg_loss = 0.2247\n",
            "t = 35, avg_loss = 0.2463\n",
            "t = 40, avg_loss = 0.2968\n",
            "t = 45, avg_loss = 0.3109\n",
            "t = 50, avg_loss = 0.3298\n",
            "Checking accuracy on train set\n",
            "Got 329 / 400 correct (82.25)\n",
            "acc = 0.822500\n",
            "Starting epoch 36 / 80\n",
            "t = 5, avg_loss = 0.3137\n",
            "t = 10, avg_loss = 0.2874\n",
            "t = 15, avg_loss = 0.2655\n",
            "t = 20, avg_loss = 0.2691\n",
            "t = 25, avg_loss = 0.3219\n",
            "t = 30, avg_loss = 0.2844\n",
            "t = 35, avg_loss = 0.2954\n",
            "t = 40, avg_loss = 0.2470\n",
            "t = 45, avg_loss = 0.2599\n",
            "t = 50, avg_loss = 0.2573\n",
            "Checking accuracy on train set\n",
            "Got 318 / 400 correct (79.50)\n",
            "acc = 0.795000\n",
            "Starting epoch 37 / 80\n",
            "t = 5, avg_loss = 0.2759\n",
            "t = 10, avg_loss = 0.2137\n",
            "t = 15, avg_loss = 0.2624\n",
            "t = 20, avg_loss = 0.3088\n",
            "t = 25, avg_loss = 0.2773\n",
            "t = 30, avg_loss = 0.3144\n",
            "t = 35, avg_loss = 0.2539\n",
            "t = 40, avg_loss = 0.2462\n",
            "t = 45, avg_loss = 0.2763\n",
            "t = 50, avg_loss = 0.2421\n",
            "Checking accuracy on train set\n",
            "Got 326 / 400 correct (81.50)\n",
            "acc = 0.815000\n",
            "Starting epoch 38 / 80\n",
            "t = 5, avg_loss = 0.3025\n",
            "t = 10, avg_loss = 0.2354\n",
            "t = 15, avg_loss = 0.2405\n",
            "t = 20, avg_loss = 0.2692\n",
            "t = 25, avg_loss = 0.2334\n",
            "t = 30, avg_loss = 0.2439\n",
            "t = 35, avg_loss = 0.3053\n",
            "t = 40, avg_loss = 0.3306\n",
            "t = 45, avg_loss = 0.2763\n",
            "t = 50, avg_loss = 0.2556\n",
            "Checking accuracy on train set\n",
            "Got 326 / 400 correct (81.50)\n",
            "acc = 0.815000\n",
            "Starting epoch 39 / 80\n",
            "t = 5, avg_loss = 0.2466\n",
            "t = 10, avg_loss = 0.2796\n",
            "t = 15, avg_loss = 0.2422\n",
            "t = 20, avg_loss = 0.2504\n",
            "t = 25, avg_loss = 0.2447\n",
            "t = 30, avg_loss = 0.2619\n",
            "t = 35, avg_loss = 0.2531\n",
            "t = 40, avg_loss = 0.2349\n",
            "t = 45, avg_loss = 0.2460\n",
            "t = 50, avg_loss = 0.2830\n",
            "Checking accuracy on train set\n",
            "Got 304 / 400 correct (76.00)\n",
            "acc = 0.760000\n",
            "Starting epoch 40 / 80\n",
            "t = 5, avg_loss = 0.2965\n",
            "t = 10, avg_loss = 0.2604\n",
            "t = 15, avg_loss = 0.3062\n",
            "t = 20, avg_loss = 0.2606\n",
            "t = 25, avg_loss = 0.2539\n",
            "t = 30, avg_loss = 0.2293\n",
            "t = 35, avg_loss = 0.2309\n",
            "t = 40, avg_loss = 0.2372\n",
            "t = 45, avg_loss = 0.2291\n",
            "t = 50, avg_loss = 0.2937\n",
            "Checking accuracy on train set\n",
            "Got 320 / 400 correct (80.00)\n",
            "acc = 0.800000\n",
            "Starting epoch 41 / 80\n",
            "t = 5, avg_loss = 0.3233\n",
            "t = 10, avg_loss = 0.2960\n",
            "t = 15, avg_loss = 0.2804\n",
            "t = 20, avg_loss = 0.2222\n",
            "t = 25, avg_loss = 0.2313\n",
            "t = 30, avg_loss = 0.2275\n",
            "t = 35, avg_loss = 0.2030\n",
            "t = 40, avg_loss = 0.3103\n",
            "t = 45, avg_loss = 0.2771\n",
            "t = 50, avg_loss = 0.2718\n",
            "Checking accuracy on train set\n",
            "Got 316 / 400 correct (79.00)\n",
            "acc = 0.790000\n",
            "Starting epoch 42 / 80\n",
            "t = 5, avg_loss = 0.3147\n",
            "t = 10, avg_loss = 0.2404\n",
            "t = 15, avg_loss = 0.2299\n",
            "t = 20, avg_loss = 0.2701\n",
            "t = 25, avg_loss = 0.2617\n",
            "t = 30, avg_loss = 0.2042\n",
            "t = 35, avg_loss = 0.3075\n",
            "t = 40, avg_loss = 0.3213\n",
            "t = 45, avg_loss = 0.2595\n",
            "t = 50, avg_loss = 0.2438\n",
            "Checking accuracy on train set\n",
            "Got 323 / 400 correct (80.75)\n",
            "acc = 0.807500\n",
            "Starting epoch 43 / 80\n",
            "t = 5, avg_loss = 0.2693\n",
            "t = 10, avg_loss = 0.2545\n",
            "t = 15, avg_loss = 0.2601\n",
            "t = 20, avg_loss = 0.2723\n",
            "t = 25, avg_loss = 0.2756\n",
            "t = 30, avg_loss = 0.2855\n",
            "t = 35, avg_loss = 0.2583\n",
            "t = 40, avg_loss = 0.2420\n",
            "t = 45, avg_loss = 0.2322\n",
            "t = 50, avg_loss = 0.2568\n",
            "Checking accuracy on train set\n",
            "Got 327 / 400 correct (81.75)\n",
            "acc = 0.817500\n",
            "Starting epoch 44 / 80\n",
            "t = 5, avg_loss = 0.2444\n",
            "t = 10, avg_loss = 0.2150\n",
            "t = 15, avg_loss = 0.1869\n",
            "t = 20, avg_loss = 0.2674\n",
            "t = 25, avg_loss = 0.2976\n",
            "t = 30, avg_loss = 0.2410\n",
            "t = 35, avg_loss = 0.3029\n",
            "t = 40, avg_loss = 0.2772\n",
            "t = 45, avg_loss = 0.2510\n",
            "t = 50, avg_loss = 0.2857\n",
            "Checking accuracy on train set\n",
            "Got 327 / 400 correct (81.75)\n",
            "acc = 0.817500\n",
            "Starting epoch 45 / 80\n",
            "t = 5, avg_loss = 0.2451\n",
            "t = 10, avg_loss = 0.2360\n",
            "t = 15, avg_loss = 0.2529\n",
            "t = 20, avg_loss = 0.2621\n",
            "t = 25, avg_loss = 0.2498\n",
            "t = 30, avg_loss = 0.2136\n",
            "t = 35, avg_loss = 0.2778\n",
            "t = 40, avg_loss = 0.2844\n",
            "t = 45, avg_loss = 0.2373\n",
            "t = 50, avg_loss = 0.2417\n",
            "Checking accuracy on train set\n",
            "Got 325 / 400 correct (81.25)\n",
            "acc = 0.812500\n",
            "Starting epoch 46 / 80\n",
            "t = 5, avg_loss = 0.2311\n",
            "t = 10, avg_loss = 0.2886\n",
            "t = 15, avg_loss = 0.2481\n",
            "t = 20, avg_loss = 0.3054\n",
            "t = 25, avg_loss = 0.2603\n",
            "t = 30, avg_loss = 0.2763\n",
            "t = 35, avg_loss = 0.2415\n",
            "t = 40, avg_loss = 0.2528\n",
            "t = 45, avg_loss = 0.2145\n",
            "t = 50, avg_loss = 0.2388\n",
            "Checking accuracy on train set\n",
            "Got 325 / 400 correct (81.25)\n",
            "acc = 0.812500\n",
            "Starting epoch 47 / 80\n",
            "t = 5, avg_loss = 0.2288\n",
            "t = 10, avg_loss = 0.2043\n",
            "t = 15, avg_loss = 0.2023\n",
            "t = 20, avg_loss = 0.2299\n",
            "t = 25, avg_loss = 0.2688\n",
            "t = 30, avg_loss = 0.2465\n",
            "t = 35, avg_loss = 0.3188\n",
            "t = 40, avg_loss = 0.2383\n",
            "t = 45, avg_loss = 0.2421\n",
            "t = 50, avg_loss = 0.2893\n",
            "Checking accuracy on train set\n",
            "Got 332 / 400 correct (83.00)\n",
            "acc = 0.830000\n",
            "Starting epoch 48 / 80\n",
            "t = 5, avg_loss = 0.2005\n",
            "t = 10, avg_loss = 0.2966\n",
            "t = 15, avg_loss = 0.2754\n",
            "t = 20, avg_loss = 0.2762\n",
            "t = 25, avg_loss = 0.2708\n",
            "t = 30, avg_loss = 0.2215\n",
            "t = 35, avg_loss = 0.2113\n",
            "t = 40, avg_loss = 0.2576\n",
            "t = 45, avg_loss = 0.2244\n",
            "t = 50, avg_loss = 0.2149\n",
            "Checking accuracy on train set\n",
            "Got 307 / 400 correct (76.75)\n",
            "acc = 0.767500\n",
            "Starting epoch 49 / 80\n",
            "t = 5, avg_loss = 0.3040\n",
            "t = 10, avg_loss = 0.2671\n",
            "t = 15, avg_loss = 0.2819\n",
            "t = 20, avg_loss = 0.2337\n",
            "t = 25, avg_loss = 0.2826\n",
            "t = 30, avg_loss = 0.2394\n",
            "t = 35, avg_loss = 0.2058\n",
            "t = 40, avg_loss = 0.2561\n",
            "t = 45, avg_loss = 0.2072\n",
            "t = 50, avg_loss = 0.2732\n",
            "Checking accuracy on train set\n",
            "Got 327 / 400 correct (81.75)\n",
            "acc = 0.817500\n",
            "Starting epoch 50 / 80\n",
            "t = 5, avg_loss = 0.2144\n",
            "t = 10, avg_loss = 0.2720\n",
            "t = 15, avg_loss = 0.2466\n",
            "t = 20, avg_loss = 0.2396\n",
            "t = 25, avg_loss = 0.2404\n",
            "t = 30, avg_loss = 0.2586\n",
            "t = 35, avg_loss = 0.2452\n",
            "t = 40, avg_loss = 0.2643\n",
            "t = 45, avg_loss = 0.2639\n",
            "t = 50, avg_loss = 0.2902\n",
            "Checking accuracy on train set\n",
            "Got 316 / 400 correct (79.00)\n",
            "acc = 0.790000\n",
            "Starting epoch 51 / 80\n",
            "t = 5, avg_loss = 0.2384\n",
            "t = 10, avg_loss = 0.2850\n",
            "t = 15, avg_loss = 0.1906\n",
            "t = 20, avg_loss = 0.2802\n",
            "t = 25, avg_loss = 0.2692\n",
            "t = 30, avg_loss = 0.2707\n",
            "t = 35, avg_loss = 0.2616\n",
            "t = 40, avg_loss = 0.2510\n",
            "t = 45, avg_loss = 0.2198\n",
            "t = 50, avg_loss = 0.2472\n",
            "Checking accuracy on train set\n",
            "Got 323 / 400 correct (80.75)\n",
            "acc = 0.807500\n",
            "Starting epoch 52 / 80\n",
            "t = 5, avg_loss = 0.2387\n",
            "t = 10, avg_loss = 0.2349\n",
            "t = 15, avg_loss = 0.2039\n",
            "t = 20, avg_loss = 0.1787\n",
            "t = 25, avg_loss = 0.2278\n",
            "t = 30, avg_loss = 0.2211\n",
            "t = 35, avg_loss = 0.2495\n",
            "t = 40, avg_loss = 0.2497\n",
            "t = 45, avg_loss = 0.2453\n",
            "t = 50, avg_loss = 0.2200\n",
            "Checking accuracy on train set\n",
            "Got 308 / 400 correct (77.00)\n",
            "acc = 0.770000\n",
            "Starting epoch 53 / 80\n",
            "t = 5, avg_loss = 0.2161\n",
            "t = 10, avg_loss = 0.2029\n",
            "t = 15, avg_loss = 0.2528\n",
            "t = 20, avg_loss = 0.2103\n",
            "t = 25, avg_loss = 0.2285\n",
            "t = 30, avg_loss = 0.2473\n",
            "t = 35, avg_loss = 0.2747\n",
            "t = 40, avg_loss = 0.2147\n",
            "t = 45, avg_loss = 0.2678\n",
            "t = 50, avg_loss = 0.3058\n",
            "Checking accuracy on train set\n",
            "Got 326 / 400 correct (81.50)\n",
            "acc = 0.815000\n",
            "Starting epoch 54 / 80\n",
            "t = 5, avg_loss = 0.1786\n",
            "t = 10, avg_loss = 0.2114\n",
            "t = 15, avg_loss = 0.3177\n",
            "t = 20, avg_loss = 0.2158\n",
            "t = 25, avg_loss = 0.1964\n",
            "t = 30, avg_loss = 0.2425\n",
            "t = 35, avg_loss = 0.2231\n",
            "t = 40, avg_loss = 0.2532\n",
            "t = 45, avg_loss = 0.3421\n",
            "t = 50, avg_loss = 0.2395\n",
            "Checking accuracy on train set\n",
            "Got 319 / 400 correct (79.75)\n",
            "acc = 0.797500\n",
            "Starting epoch 55 / 80\n",
            "t = 5, avg_loss = 0.2178\n",
            "t = 10, avg_loss = 0.2310\n",
            "t = 15, avg_loss = 0.2504\n",
            "t = 20, avg_loss = 0.2030\n",
            "t = 25, avg_loss = 0.2529\n",
            "t = 30, avg_loss = 0.2203\n",
            "t = 35, avg_loss = 0.2605\n",
            "t = 40, avg_loss = 0.2441\n",
            "t = 45, avg_loss = 0.2206\n",
            "t = 50, avg_loss = 0.2286\n",
            "Checking accuracy on train set\n",
            "Got 327 / 400 correct (81.75)\n",
            "acc = 0.817500\n",
            "Starting epoch 56 / 80\n",
            "t = 5, avg_loss = 0.2335\n",
            "t = 10, avg_loss = 0.1866\n",
            "t = 15, avg_loss = 0.2010\n",
            "t = 20, avg_loss = 0.1964\n",
            "t = 25, avg_loss = 0.2383\n",
            "t = 30, avg_loss = 0.2068\n",
            "t = 35, avg_loss = 0.3046\n",
            "t = 40, avg_loss = 0.1940\n",
            "t = 45, avg_loss = 0.2994\n",
            "t = 50, avg_loss = 0.2764\n",
            "Checking accuracy on train set\n",
            "Got 325 / 400 correct (81.25)\n",
            "acc = 0.812500\n",
            "Starting epoch 57 / 80\n",
            "t = 5, avg_loss = 0.2518\n",
            "t = 10, avg_loss = 0.1950\n",
            "t = 15, avg_loss = 0.2785\n",
            "t = 20, avg_loss = 0.1877\n",
            "t = 25, avg_loss = 0.3077\n",
            "t = 30, avg_loss = 0.2694\n",
            "t = 35, avg_loss = 0.2237\n",
            "t = 40, avg_loss = 0.1965\n",
            "t = 45, avg_loss = 0.2294\n",
            "t = 50, avg_loss = 0.2361\n",
            "Checking accuracy on train set\n",
            "Got 332 / 400 correct (83.00)\n",
            "acc = 0.830000\n",
            "Starting epoch 58 / 80\n",
            "t = 5, avg_loss = 0.2230\n",
            "t = 10, avg_loss = 0.2353\n",
            "t = 15, avg_loss = 0.2038\n",
            "t = 20, avg_loss = 0.2588\n",
            "t = 25, avg_loss = 0.2282\n",
            "t = 30, avg_loss = 0.2498\n",
            "t = 35, avg_loss = 0.2355\n",
            "t = 40, avg_loss = 0.2002\n",
            "t = 45, avg_loss = 0.2624\n",
            "t = 50, avg_loss = 0.2387\n",
            "Checking accuracy on train set\n",
            "Got 317 / 400 correct (79.25)\n",
            "acc = 0.792500\n",
            "Starting epoch 59 / 80\n",
            "t = 5, avg_loss = 0.2747\n",
            "t = 10, avg_loss = 0.2523\n",
            "t = 15, avg_loss = 0.2552\n",
            "t = 20, avg_loss = 0.2400\n",
            "t = 25, avg_loss = 0.2653\n",
            "t = 30, avg_loss = 0.2414\n",
            "t = 35, avg_loss = 0.1952\n",
            "t = 40, avg_loss = 0.2304\n",
            "t = 45, avg_loss = 0.1990\n",
            "t = 50, avg_loss = 0.2465\n",
            "Checking accuracy on train set\n",
            "Got 329 / 400 correct (82.25)\n",
            "acc = 0.822500\n",
            "Starting epoch 60 / 80\n",
            "t = 5, avg_loss = 0.1861\n",
            "t = 10, avg_loss = 0.2055\n",
            "t = 15, avg_loss = 0.2738\n",
            "t = 20, avg_loss = 0.2535\n",
            "t = 25, avg_loss = 0.2343\n",
            "t = 30, avg_loss = 0.2129\n",
            "t = 35, avg_loss = 0.2093\n",
            "t = 40, avg_loss = 0.2582\n",
            "t = 45, avg_loss = 0.2394\n",
            "t = 50, avg_loss = 0.2294\n",
            "Checking accuracy on train set\n",
            "Got 334 / 400 correct (83.50)\n",
            "acc = 0.835000\n",
            "Starting epoch 61 / 80\n",
            "t = 5, avg_loss = 0.2301\n",
            "t = 10, avg_loss = 0.2748\n",
            "t = 15, avg_loss = 0.2442\n",
            "t = 20, avg_loss = 0.2173\n",
            "t = 25, avg_loss = 0.2237\n",
            "t = 30, avg_loss = 0.2048\n",
            "t = 35, avg_loss = 0.1636\n",
            "t = 40, avg_loss = 0.2837\n",
            "t = 45, avg_loss = 0.2382\n",
            "t = 50, avg_loss = 0.2179\n",
            "Checking accuracy on train set\n",
            "Got 334 / 400 correct (83.50)\n",
            "acc = 0.835000\n",
            "Starting epoch 62 / 80\n",
            "t = 5, avg_loss = 0.2038\n",
            "t = 10, avg_loss = 0.1934\n",
            "t = 15, avg_loss = 0.1886\n",
            "t = 20, avg_loss = 0.2359\n",
            "t = 25, avg_loss = 0.2291\n",
            "t = 30, avg_loss = 0.2522\n",
            "t = 35, avg_loss = 0.2153\n",
            "t = 40, avg_loss = 0.2027\n",
            "t = 45, avg_loss = 0.2334\n",
            "t = 50, avg_loss = 0.2312\n",
            "Checking accuracy on train set\n",
            "Got 329 / 400 correct (82.25)\n",
            "acc = 0.822500\n",
            "Starting epoch 63 / 80\n",
            "t = 5, avg_loss = 0.1981\n",
            "t = 10, avg_loss = 0.1949\n",
            "t = 15, avg_loss = 0.2894\n",
            "t = 20, avg_loss = 0.2143\n",
            "t = 25, avg_loss = 0.2539\n",
            "t = 30, avg_loss = 0.2671\n",
            "t = 35, avg_loss = 0.2404\n",
            "t = 40, avg_loss = 0.2323\n",
            "t = 45, avg_loss = 0.2555\n",
            "t = 50, avg_loss = 0.1715\n",
            "Checking accuracy on train set\n",
            "Got 337 / 400 correct (84.25)\n",
            "acc = 0.842500\n",
            "Starting epoch 64 / 80\n",
            "t = 5, avg_loss = 0.1830\n",
            "t = 10, avg_loss = 0.1886\n",
            "t = 15, avg_loss = 0.2144\n",
            "t = 20, avg_loss = 0.2275\n",
            "t = 25, avg_loss = 0.2209\n",
            "t = 30, avg_loss = 0.2586\n",
            "t = 35, avg_loss = 0.2340\n",
            "t = 40, avg_loss = 0.2553\n",
            "t = 45, avg_loss = 0.1648\n",
            "t = 50, avg_loss = 0.2424\n",
            "Checking accuracy on train set\n",
            "Got 318 / 400 correct (79.50)\n",
            "acc = 0.795000\n",
            "Starting epoch 65 / 80\n",
            "t = 5, avg_loss = 0.1770\n",
            "t = 10, avg_loss = 0.2302\n",
            "t = 15, avg_loss = 0.2038\n",
            "t = 20, avg_loss = 0.2239\n",
            "t = 25, avg_loss = 0.2227\n",
            "t = 30, avg_loss = 0.2582\n",
            "t = 35, avg_loss = 0.2127\n",
            "t = 40, avg_loss = 0.2805\n",
            "t = 45, avg_loss = 0.1696\n",
            "t = 50, avg_loss = 0.2343\n",
            "Checking accuracy on train set\n",
            "Got 332 / 400 correct (83.00)\n",
            "acc = 0.830000\n",
            "Starting epoch 66 / 80\n",
            "t = 5, avg_loss = 0.2352\n",
            "t = 10, avg_loss = 0.1862\n",
            "t = 15, avg_loss = 0.2322\n",
            "t = 20, avg_loss = 0.2409\n",
            "t = 25, avg_loss = 0.2401\n",
            "t = 30, avg_loss = 0.2107\n",
            "t = 35, avg_loss = 0.2796\n",
            "t = 40, avg_loss = 0.2380\n",
            "t = 45, avg_loss = 0.1895\n",
            "t = 50, avg_loss = 0.2173\n",
            "Checking accuracy on train set\n",
            "Got 321 / 400 correct (80.25)\n",
            "acc = 0.802500\n",
            "Starting epoch 67 / 80\n",
            "t = 5, avg_loss = 0.2539\n",
            "t = 10, avg_loss = 0.1986\n",
            "t = 15, avg_loss = 0.2211\n",
            "t = 20, avg_loss = 0.2189\n",
            "t = 25, avg_loss = 0.2060\n",
            "t = 30, avg_loss = 0.1594\n",
            "t = 35, avg_loss = 0.1961\n",
            "t = 40, avg_loss = 0.2186\n",
            "t = 45, avg_loss = 0.2450\n",
            "t = 50, avg_loss = 0.2146\n",
            "Checking accuracy on train set\n",
            "Got 331 / 400 correct (82.75)\n",
            "acc = 0.827500\n",
            "Starting epoch 68 / 80\n",
            "t = 5, avg_loss = 0.1775\n",
            "t = 10, avg_loss = 0.2120\n",
            "t = 15, avg_loss = 0.2044\n",
            "t = 20, avg_loss = 0.2077\n",
            "t = 25, avg_loss = 0.2121\n",
            "t = 30, avg_loss = 0.2243\n",
            "t = 35, avg_loss = 0.2664\n",
            "t = 40, avg_loss = 0.2182\n",
            "t = 45, avg_loss = 0.2134\n",
            "t = 50, avg_loss = 0.2026\n",
            "Checking accuracy on train set\n",
            "Got 318 / 400 correct (79.50)\n",
            "acc = 0.795000\n",
            "Starting epoch 69 / 80\n",
            "t = 5, avg_loss = 0.2305\n",
            "t = 10, avg_loss = 0.2576\n",
            "t = 15, avg_loss = 0.2450\n",
            "t = 20, avg_loss = 0.1900\n",
            "t = 25, avg_loss = 0.2178\n",
            "t = 30, avg_loss = 0.2243\n",
            "t = 35, avg_loss = 0.1950\n",
            "t = 40, avg_loss = 0.2074\n",
            "t = 45, avg_loss = 0.2506\n",
            "t = 50, avg_loss = 0.2442\n",
            "Checking accuracy on train set\n",
            "Got 309 / 400 correct (77.25)\n",
            "acc = 0.772500\n",
            "Starting epoch 70 / 80\n",
            "t = 5, avg_loss = 0.2063\n",
            "t = 10, avg_loss = 0.1904\n",
            "t = 15, avg_loss = 0.2538\n",
            "t = 20, avg_loss = 0.2460\n",
            "t = 25, avg_loss = 0.2095\n",
            "t = 30, avg_loss = 0.1884\n",
            "t = 35, avg_loss = 0.2063\n",
            "t = 40, avg_loss = 0.2243\n",
            "t = 45, avg_loss = 0.2452\n",
            "t = 50, avg_loss = 0.1878\n",
            "Checking accuracy on train set\n",
            "Got 313 / 400 correct (78.25)\n",
            "acc = 0.782500\n",
            "Starting epoch 71 / 80\n",
            "t = 5, avg_loss = 0.1877\n",
            "t = 10, avg_loss = 0.2207\n",
            "t = 15, avg_loss = 0.2263\n",
            "t = 20, avg_loss = 0.2049\n",
            "t = 25, avg_loss = 0.1956\n",
            "t = 30, avg_loss = 0.1862\n",
            "t = 35, avg_loss = 0.2813\n",
            "t = 40, avg_loss = 0.2208\n",
            "t = 45, avg_loss = 0.2140\n",
            "t = 50, avg_loss = 0.2465\n",
            "Checking accuracy on train set\n",
            "Got 325 / 400 correct (81.25)\n",
            "acc = 0.812500\n",
            "Starting epoch 72 / 80\n",
            "t = 5, avg_loss = 0.1665\n",
            "t = 10, avg_loss = 0.2528\n",
            "t = 15, avg_loss = 0.2211\n",
            "t = 20, avg_loss = 0.1980\n",
            "t = 25, avg_loss = 0.2239\n",
            "t = 30, avg_loss = 0.2145\n",
            "t = 35, avg_loss = 0.2317\n",
            "t = 40, avg_loss = 0.2190\n",
            "t = 45, avg_loss = 0.2467\n",
            "t = 50, avg_loss = 0.2160\n",
            "Checking accuracy on train set\n",
            "Got 331 / 400 correct (82.75)\n",
            "acc = 0.827500\n",
            "Starting epoch 73 / 80\n",
            "t = 5, avg_loss = 0.2241\n",
            "t = 10, avg_loss = 0.2418\n",
            "t = 15, avg_loss = 0.1866\n",
            "t = 20, avg_loss = 0.2532\n",
            "t = 25, avg_loss = 0.1831\n",
            "t = 30, avg_loss = 0.2080\n",
            "t = 35, avg_loss = 0.2307\n",
            "t = 40, avg_loss = 0.2053\n",
            "t = 45, avg_loss = 0.2395\n",
            "t = 50, avg_loss = 0.2574\n",
            "Checking accuracy on train set\n",
            "Got 317 / 400 correct (79.25)\n",
            "acc = 0.792500\n",
            "Starting epoch 74 / 80\n",
            "t = 5, avg_loss = 0.2049\n",
            "t = 10, avg_loss = 0.2190\n",
            "t = 15, avg_loss = 0.2635\n",
            "t = 20, avg_loss = 0.2275\n",
            "t = 25, avg_loss = 0.2599\n",
            "t = 30, avg_loss = 0.2134\n",
            "t = 35, avg_loss = 0.2039\n",
            "t = 40, avg_loss = 0.2432\n",
            "t = 45, avg_loss = 0.2052\n",
            "t = 50, avg_loss = 0.1888\n",
            "Checking accuracy on train set\n",
            "Got 322 / 400 correct (80.50)\n",
            "acc = 0.805000\n",
            "Starting epoch 75 / 80\n",
            "t = 5, avg_loss = 0.2280\n",
            "t = 10, avg_loss = 0.1939\n",
            "t = 15, avg_loss = 0.2384\n",
            "t = 20, avg_loss = 0.2116\n",
            "t = 25, avg_loss = 0.2150\n",
            "t = 30, avg_loss = 0.2208\n",
            "t = 35, avg_loss = 0.1517\n",
            "t = 40, avg_loss = 0.2486\n",
            "t = 45, avg_loss = 0.1823\n",
            "t = 50, avg_loss = 0.1829\n",
            "Checking accuracy on train set\n",
            "Got 323 / 400 correct (80.75)\n",
            "acc = 0.807500\n",
            "Starting epoch 76 / 80\n",
            "t = 5, avg_loss = 0.2414\n",
            "t = 10, avg_loss = 0.2081\n",
            "t = 15, avg_loss = 0.1978\n",
            "t = 20, avg_loss = 0.2046\n",
            "t = 25, avg_loss = 0.1848\n",
            "t = 30, avg_loss = 0.1930\n",
            "t = 35, avg_loss = 0.2139\n",
            "t = 40, avg_loss = 0.1900\n",
            "t = 45, avg_loss = 0.1866\n",
            "t = 50, avg_loss = 0.1870\n",
            "Checking accuracy on train set\n",
            "Got 330 / 400 correct (82.50)\n",
            "acc = 0.825000\n",
            "Starting epoch 77 / 80\n",
            "t = 5, avg_loss = 0.1856\n",
            "t = 10, avg_loss = 0.2135\n",
            "t = 15, avg_loss = 0.1754\n",
            "t = 20, avg_loss = 0.1945\n",
            "t = 25, avg_loss = 0.1728\n",
            "t = 30, avg_loss = 0.2068\n",
            "t = 35, avg_loss = 0.2250\n",
            "t = 40, avg_loss = 0.1983\n",
            "t = 45, avg_loss = 0.2069\n",
            "t = 50, avg_loss = 0.1839\n",
            "Checking accuracy on train set\n",
            "Got 332 / 400 correct (83.00)\n",
            "acc = 0.830000\n",
            "Starting epoch 78 / 80\n",
            "t = 5, avg_loss = 0.3276\n",
            "t = 10, avg_loss = 0.2194\n",
            "t = 15, avg_loss = 0.2161\n",
            "t = 20, avg_loss = 0.1584\n",
            "t = 25, avg_loss = 0.2150\n",
            "t = 30, avg_loss = 0.2485\n",
            "t = 35, avg_loss = 0.2199\n",
            "t = 40, avg_loss = 0.2244\n",
            "t = 45, avg_loss = 0.2551\n",
            "t = 50, avg_loss = 0.2336\n",
            "Checking accuracy on train set\n",
            "Got 322 / 400 correct (80.50)\n",
            "acc = 0.805000\n",
            "Starting epoch 79 / 80\n",
            "t = 5, avg_loss = 0.2224\n",
            "t = 10, avg_loss = 0.2043\n",
            "t = 15, avg_loss = 0.1458\n",
            "t = 20, avg_loss = 0.1688\n",
            "t = 25, avg_loss = 0.2261\n",
            "t = 30, avg_loss = 0.2005\n",
            "t = 35, avg_loss = 0.2435\n",
            "t = 40, avg_loss = 0.2466\n",
            "t = 45, avg_loss = 0.2246\n",
            "t = 50, avg_loss = 0.1789\n",
            "Checking accuracy on train set\n",
            "Got 331 / 400 correct (82.75)\n",
            "acc = 0.827500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FY-Wj3LMN-QU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LGlUJttQSL-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvoCj5uscUsz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_accurancy(acc_list):\n",
        "  plt.plot([i+1 for i in range((len(acc_list)))],acc_list)\n",
        "  print(\"Accurancy:\")\n",
        "  plt.show()\n",
        "\n",
        "def plot_loss_function(avg_loss_list):\n",
        "  plt.plot([print_every*batch_size*(i+1) for i in range((len(avg_loss_list)))],avg_loss_list)\n",
        "  print(\"Loss:\")\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WwgxQDJ-SWu",
        "colab_type": "code",
        "outputId": "875167d0-ccf5-4260-c677-a6a134f4f3b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        }
      },
      "source": [
        "plot_accurancy(acc_list)\n",
        "plot_loss_function(avg_loss_list)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accurancy:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bN3i7jMlK04i",
        "colab_type": "code",
        "outputId": "55cbc838-fa3e-4135-9e9d-fba9f8832e77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "check_accuracy(model_gpu, test_loader, datatype='test')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking accuracy on test set\n",
            "Got 176 / 201 correct (87.56)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8756218905472637"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3D2NBxIxy5b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def retry_from_backup():\n",
        "  model_gpu = model_base.type(gpu_dtype)\n",
        "  print(model_gpu)\n",
        "  loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) \n",
        "\n",
        "\n",
        "  checkpoint = torch.load(model_backup_path)\n",
        "  model_gpu.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  epoch = checkpoint['epoch']\n",
        "  loss = checkpoint['loss']\n",
        "  acc_list = checkpoint['acc_list']\n",
        "  print(\"starting from epoch: \" + str(epoch))\n",
        "  print(\"starting from loss: \" + str(loss))\n",
        "  print(acc_list)\n",
        "  \n",
        "  \n",
        "  train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=20, starting_from_epoch=epoch)\n",
        "  check_accuracy(model_gpu, valid_loader)\n",
        "\n",
        "  plot_accurancy(acc_list)\n",
        "  plot_loss_function(avg_loss_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avJf2YZ2KEDa",
        "colab_type": "code",
        "outputId": "9d46902f-b5e8-4869-e3df-72008cf37445",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 822
        }
      },
      "source": [
        "retry_from_backup()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Kerv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (3): Conv2d(16, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (4): ReLU(inplace=True)\n",
            "  (5): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (7): Conv2d(24, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (8): ReLU(inplace=True)\n",
            "  (9): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (11): Dropout(p=0.4, inplace=False)\n",
            "  (12): Flatten()\n",
            "  (13): Linear(in_features=4608, out_features=32, bias=True)\n",
            "  (14): Dropout(p=0.05, inplace=False)\n",
            "  (15): ReLU(inplace=True)\n",
            "  (16): Linear(in_features=32, out_features=2, bias=True)\n",
            ")\n",
            "starting from epoch: 79\n",
            "starting from loss: tensor(0.1647, device='cuda:0', requires_grad=True)\n",
            "[0.665, 0.76, 0.72, 0.7675, 0.7075, 0.795, 0.7825, 0.78, 0.8, 0.805, 0.75, 0.7475, 0.745, 0.74, 0.7625, 0.8275, 0.79, 0.81, 0.7975, 0.775, 0.805, 0.785, 0.785, 0.8025, 0.815, 0.82, 0.815, 0.81, 0.8125, 0.805, 0.8375, 0.765, 0.8, 0.8075, 0.8175, 0.8225, 0.795, 0.815, 0.815, 0.76, 0.8, 0.79, 0.8075, 0.8175, 0.8175, 0.8125, 0.8125, 0.83, 0.7675, 0.8175, 0.79, 0.8075, 0.77, 0.815, 0.7975, 0.8175, 0.8125, 0.83, 0.7925, 0.8225, 0.835, 0.835, 0.8225, 0.8425, 0.795, 0.83, 0.8025, 0.8275, 0.795, 0.7725, 0.7825, 0.8125, 0.8275, 0.7925, 0.805, 0.8075, 0.825, 0.83, 0.805, 0.8275]\n",
            "Starting epoch 0 / 20\n",
            "t = 5, avg_loss = 0.2048\n",
            "t = 10, avg_loss = 0.2066\n",
            "t = 15, avg_loss = 0.1872\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-bc0ed074296d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mretry_from_backup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-c346a52c4866>\u001b[0m in \u001b[0;36mretry_from_backup\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarting_from_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m   \u001b[0mcheck_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-2e56e646f393>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, loss_fn, optimizer, num_epochs, starting_from_epoch)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mx_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0my_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-ad283ac8af02>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m           \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"malignant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"malignant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   1856\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1858\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreducing_gap\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresample\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mNEAREST\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEROCbhTw37l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "check_accuracy(model_gpu, test_loader, datatype='test')\n",
        "plot_accurancy(acc_list)\n",
        "plot_loss_function(avg_loss_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGfPH8mRKvTx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdKuvq5rLqi6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QT9lj0FTSl5L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}