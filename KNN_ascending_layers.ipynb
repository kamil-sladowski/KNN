{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN_ascending_layers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamilo116/KNN/blob/master/KNN_ascending_layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7ReM7FU-xs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import sys\n",
        "from random import shuffle\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms as transforms\n",
        "import timeit\n",
        "\n",
        "np.random.seed(4) \n",
        "torch.manual_seed(4) \n",
        "torch.cuda.manual_seed(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYIMZ8QyYewD",
        "colab_type": "code",
        "outputId": "890600b8-b9ed-472c-dc02-f0c03743b65f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! git clone https://github.com/wang-chen/kervolution.git \n",
        "\n",
        "sys.path.append(\"kervolution/\")\n",
        "from kervolution import Kerv2d\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'kervolution' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvbKg4VJXKY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LIMIT_IMAGES_NUM = 1000\n",
        "train_test_split_size = 0.2\n",
        "image_resize = (100, 100)\n",
        "batch_size = 64\n",
        "num_workers = 0\n",
        "\n",
        "out_1 = 16\n",
        "out_2 = 32\n",
        "out_3 = 64\n",
        "out_4 = 128\n",
        "\n",
        "\n",
        "k_size_1 = 3\n",
        "padding_1 = 1\n",
        "in_channels = 3\n",
        "\n",
        "kernel_size = 3\n",
        "num_epochs = 100\n",
        "\n",
        "learning_rate = 0.00012\n",
        "weight_decay = 0\n",
        "\n",
        "MALIGNANT_DATASET = '/content/drive/My Drive/Colab_data/malignant/malignant/'\n",
        "BENIGN_DATASET = '/content/drive/My Drive/Colab_data/benign/benign/'\n",
        "DATA_FOLDER = '/content/drive/My Drive/Colab_data/'\n",
        "model_backup_path = os.path.join(DATA_FOLDER, 'backup_model3') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMOHez_kHZD6",
        "colab_type": "code",
        "outputId": "f9d46a17-baba-495a-9a64-1a426fef2a2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b8P1NdXfVdX",
        "colab_type": "code",
        "outputId": "9cd0a989-0212-4943-ec69-995427c1e51b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "benign_file_list = sorted(os.listdir(BENIGN_DATASET))\n",
        "malignant_file_list = sorted(os.listdir(MALIGNANT_DATASET))\n",
        "shuffle(benign_file_list)\n",
        "shuffle(malignant_file_list)\n",
        "benign_file_list = benign_file_list[:LIMIT_IMAGES_NUM]\n",
        "malignant_file_list = malignant_file_list[:LIMIT_IMAGES_NUM]\n",
        "\n",
        "print(f\"Number of benign {len(benign_file_list)} images\")\n",
        "print(f\"Number of malignant {len(malignant_file_list)} images\")\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize(image_resize),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of benign 1000 images\n",
            "Number of malignant 1000 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGDQfal74BLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "benign_dict = {filename: 0 for filename in benign_file_list}\n",
        "malignant_dict = {filename: 1 for filename in malignant_file_list}\n",
        "img_class_dict = {**benign_dict , **malignant_dict}\n",
        "labeled_data = pd.Series(img_class_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvAAOqmVfVll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IsicDataset(Dataset):\n",
        "    def __init__(self, data_folder, labeled_data, \n",
        "                 transform=transforms.Compose([transforms.ToTensor()])):\n",
        "        self.labeled_data = labeled_data\n",
        "        self.transform = transform\n",
        "        self.data_folder = data_folder\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labeled_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        label = self.labeled_data[index]\n",
        "        if label == 0:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"benign\", \"benign\", index ))\n",
        "        else:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"malignant\", \"malignant\", index ))\n",
        "        image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "    @property\n",
        "    def labels(self):\n",
        "      return self.labeled_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSuYqjLAYrWA",
        "colab_type": "code",
        "outputId": "f7cedb44-4611-4b9d-823b-c9bfd9a1b784",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "dataset = IsicDataset(DATA_FOLDER, labeled_data, transform=data_transforms)\n",
        "print(dataset.labels)\n",
        "\n",
        "X_train, X_test = train_test_split(dataset.labels, test_size=train_test_split_size)\n",
        "print(\"number of training data: \",len(X_train))\n",
        "print(\"number of testing  data: \",len(X_test))\n",
        "\n",
        "train_sampler = SubsetRandomSampler(list(X_train.index))\n",
        "valid_sampler = SubsetRandomSampler(list(X_test.index))\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ISIC_0000341.jpeg    0\n",
            "ISIC_0000613.jpeg    0\n",
            "ISIC_0000508.jpeg    0\n",
            "ISIC_0000612.jpeg    0\n",
            "ISIC_0000464.jpeg    0\n",
            "                    ..\n",
            "ISIC_0013831.jpeg    1\n",
            "ISIC_0026105.jpg     1\n",
            "ISIC_0013141.jpeg    1\n",
            "ISIC_0010714.jpeg    1\n",
            "ISIC_0015119.jpeg    1\n",
            "Length: 2000, dtype: int64\n",
            "number of training data:  1600\n",
            "number of testing  data:  400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e8nFBR6Yug5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "def train(model, train_loader ,loss_fn, optimizer, num_epochs=1, starting_from_epoch=1):\n",
        "    total_loss =0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
        "        model.train()\n",
        "\n",
        "        for t, (x, y) in enumerate(train_loader):\n",
        "            x_var = Variable(x.type(gpu_dtype))\n",
        "            y_var = Variable(y.type(gpu_dtype).long())\n",
        "            scores = model(x_var)\n",
        "            loss = loss_fn(scores, y_var)\n",
        "            total_loss += loss.data\n",
        "            \n",
        "            if (t + 1) % print_every == 0:\n",
        "                avg_loss = total_loss/print_every\n",
        "                print('t = %d, avg_loss = %.4f' % (t + 1, avg_loss) )\n",
        "                avg_loss_list.append(avg_loss)\n",
        "                total_loss = 0\n",
        "                \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        acc = check_accuracy(model_gpu, valid_loader)\n",
        "        print('acc = %f' %(acc))\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model_gpu.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            'acc_list': acc_list,\n",
        "            }, model_backup_path)\n",
        "            \n",
        "def check_accuracy(model, loader):\n",
        "    print('Checking accuracy on test set')   \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval() \n",
        "    for x, y in loader:\n",
        "        x_var = Variable(x.type(gpu_dtype))\n",
        "\n",
        "        scores = model(x_var)\n",
        "        _, preds = scores.data.cpu().max(1)\n",
        "        num_correct += (preds == y).sum()\n",
        "        num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    acc_list.append(acc)\n",
        "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "    return acc\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggvpMu36Yw2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.size()\n",
        "        return x.view(N, -1)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-gYHw0Jlbwt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "4225fd1f-4fd4-4a2e-9141-d09c775fbb50"
      },
      "source": [
        "print_every = 2\n",
        "gpu_dtype = torch.cuda.FloatTensor\n",
        "\n",
        "\n",
        "'''\n",
        "Kerv2d\n",
        "kervolution with following options:\n",
        "kernel_type: [linear, polynomial, gaussian, etc.]\n",
        "default is convolution:\n",
        "          kernel_type --> linear,\n",
        "balance, power, gamma is valid only when the kernel_type is specified\n",
        "if learnable_kernel = True,  they just be the initial value of learable parameters\n",
        "if learnable_kernel = False, they are the value of kernel_type's parameter\n",
        "the parameter [power] cannot be learned due to integer limitation\n",
        "dilation (int or tuple, optional): Spacing between kernel\n",
        "elements. Default: 1\n",
        "groups (int, optional): Number of blocked connections from input\n",
        "channels to output channels. Default: 1\n",
        "bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n",
        "kernel_type (str), Default: 'linear'\n",
        "learnable_kernel (bool): Learnable kernel parameters.  Default: False \n",
        "balance: 0, 1\n",
        "power: 3, 4, 5\n",
        "gamma:\n",
        "'''\n",
        "\n",
        "\n",
        "model_base = nn.Sequential( \n",
        "                #nn.Kerv2d(in_channels , out_1, padding=padding_1, dilation=1, groups=1, bias=True, \n",
        "                #          kernel_type='linear', kernel_size=k_size_1,# learnable_kernel=True,\n",
        "                          #kernel_regularizer=True, stride=1, balance=1, power=3, gamma=1\n",
        "                #          ), \n",
        "                nn.Conv2d(in_channels , out_1, padding= padding_1, kernel_size=k_size_1, stride=1),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_1),\n",
        "                 nn.MaxPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_1 , out_2, padding= padding_1, kernel_size=k_size_1, stride=1), \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_2),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_2 , out_3, padding= padding_1, kernel_size=k_size_1, stride=1),  \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_3),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_3 , out_4, padding= padding_1, kernel_size=k_size_1, stride=1),  \n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm2d(out_4),\n",
        "                nn.MaxPool2d(2, stride=2),\n",
        "                nn.Dropout(0.5),\n",
        "                Flatten(),\n",
        "                nn.Linear(4608,64),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Linear(64,2)\n",
        "            )\n",
        "model_gpu = model_base.type(gpu_dtype)\n",
        "print(model_gpu)\n",
        "loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (4): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (5): ReLU(inplace=True)\n",
            "  (6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (8): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (9): ReLU(inplace=True)\n",
            "  (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (12): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (13): ReLU(inplace=True)\n",
            "  (14): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (16): Dropout(p=0.5, inplace=False)\n",
            "  (17): Flatten()\n",
            "  (18): Linear(in_features=4608, out_features=64, bias=True)\n",
            "  (19): ReLU(inplace=True)\n",
            "  (20): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgmexhBRZAK6",
        "colab_type": "code",
        "outputId": "c3b1fc61-f615-48b7-d0bb-22984976421d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs)\n",
        "check_accuracy(model_gpu, valid_loader)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 1 / 100\n",
            "t = 2, avg_loss = 0.8103\n",
            "t = 4, avg_loss = 0.5760\n",
            "t = 6, avg_loss = 0.5042\n",
            "t = 8, avg_loss = 0.5225\n",
            "t = 10, avg_loss = 0.5419\n",
            "t = 12, avg_loss = 0.4692\n",
            "t = 14, avg_loss = 0.5097\n",
            "t = 16, avg_loss = 0.5001\n",
            "t = 18, avg_loss = 0.3554\n",
            "t = 20, avg_loss = 0.5348\n",
            "t = 22, avg_loss = 0.3954\n",
            "t = 24, avg_loss = 0.3593\n",
            "Checking accuracy on test set\n",
            "Got 204 / 400 correct (51.00)\n",
            "acc = 0.510000\n",
            "Starting epoch 2 / 100\n",
            "t = 2, avg_loss = 0.6662\n",
            "t = 4, avg_loss = 0.4324\n",
            "t = 6, avg_loss = 0.4747\n",
            "t = 8, avg_loss = 0.4300\n",
            "t = 10, avg_loss = 0.3431\n",
            "t = 12, avg_loss = 0.4353\n",
            "t = 14, avg_loss = 0.3986\n",
            "t = 16, avg_loss = 0.3258\n",
            "t = 18, avg_loss = 0.3601\n",
            "t = 20, avg_loss = 0.3698\n",
            "t = 22, avg_loss = 0.2932\n",
            "t = 24, avg_loss = 0.3837\n",
            "Checking accuracy on test set\n",
            "Got 253 / 400 correct (63.25)\n",
            "acc = 0.632500\n",
            "Starting epoch 3 / 100\n",
            "t = 2, avg_loss = 0.5591\n",
            "t = 4, avg_loss = 0.4340\n",
            "t = 6, avg_loss = 0.3458\n",
            "t = 8, avg_loss = 0.2858\n",
            "t = 10, avg_loss = 0.2840\n",
            "t = 12, avg_loss = 0.3891\n",
            "t = 14, avg_loss = 0.3228\n",
            "t = 16, avg_loss = 0.3667\n",
            "t = 18, avg_loss = 0.3590\n",
            "t = 20, avg_loss = 0.3043\n",
            "t = 22, avg_loss = 0.3016\n",
            "t = 24, avg_loss = 0.3780\n",
            "Checking accuracy on test set\n",
            "Got 328 / 400 correct (82.00)\n",
            "acc = 0.820000\n",
            "Starting epoch 4 / 100\n",
            "t = 2, avg_loss = 0.5857\n",
            "t = 4, avg_loss = 0.3175\n",
            "t = 6, avg_loss = 0.3181\n",
            "t = 8, avg_loss = 0.3908\n",
            "t = 10, avg_loss = 0.3390\n",
            "t = 12, avg_loss = 0.3097\n",
            "t = 14, avg_loss = 0.3635\n",
            "t = 16, avg_loss = 0.3331\n",
            "t = 18, avg_loss = 0.3585\n",
            "t = 20, avg_loss = 0.2113\n",
            "t = 22, avg_loss = 0.3926\n",
            "t = 24, avg_loss = 0.4399\n",
            "Checking accuracy on test set\n",
            "Got 332 / 400 correct (83.00)\n",
            "acc = 0.830000\n",
            "Starting epoch 5 / 100\n",
            "t = 2, avg_loss = 0.5162\n",
            "t = 4, avg_loss = 0.3039\n",
            "t = 6, avg_loss = 0.2666\n",
            "t = 8, avg_loss = 0.3342\n",
            "t = 10, avg_loss = 0.2590\n",
            "t = 12, avg_loss = 0.3003\n",
            "t = 14, avg_loss = 0.3686\n",
            "t = 16, avg_loss = 0.3331\n",
            "t = 18, avg_loss = 0.3106\n",
            "t = 20, avg_loss = 0.3650\n",
            "t = 22, avg_loss = 0.2169\n",
            "t = 24, avg_loss = 0.3464\n",
            "Checking accuracy on test set\n",
            "Got 337 / 400 correct (84.25)\n",
            "acc = 0.842500\n",
            "Starting epoch 6 / 100\n",
            "t = 2, avg_loss = 0.5253\n",
            "t = 4, avg_loss = 0.2769\n",
            "t = 6, avg_loss = 0.3012\n",
            "t = 8, avg_loss = 0.2935\n",
            "t = 10, avg_loss = 0.2628\n",
            "t = 12, avg_loss = 0.3835\n",
            "t = 14, avg_loss = 0.3388\n",
            "t = 16, avg_loss = 0.1807\n",
            "t = 18, avg_loss = 0.3496\n",
            "t = 20, avg_loss = 0.2179\n",
            "t = 22, avg_loss = 0.3019\n",
            "t = 24, avg_loss = 0.2291\n",
            "Checking accuracy on test set\n",
            "Got 338 / 400 correct (84.50)\n",
            "acc = 0.845000\n",
            "Starting epoch 7 / 100\n",
            "t = 2, avg_loss = 0.5025\n",
            "t = 4, avg_loss = 0.2512\n",
            "t = 6, avg_loss = 0.2870\n",
            "t = 8, avg_loss = 0.2336\n",
            "t = 10, avg_loss = 0.3534\n",
            "t = 12, avg_loss = 0.3766\n",
            "t = 14, avg_loss = 0.2534\n",
            "t = 16, avg_loss = 0.2469\n",
            "t = 18, avg_loss = 0.2724\n",
            "t = 20, avg_loss = 0.2978\n",
            "t = 22, avg_loss = 0.2498\n",
            "t = 24, avg_loss = 0.2744\n",
            "Checking accuracy on test set\n",
            "Got 338 / 400 correct (84.50)\n",
            "acc = 0.845000\n",
            "Starting epoch 8 / 100\n",
            "t = 2, avg_loss = 0.4499\n",
            "t = 4, avg_loss = 0.2697\n",
            "t = 6, avg_loss = 0.2165\n",
            "t = 8, avg_loss = 0.2047\n",
            "t = 10, avg_loss = 0.2050\n",
            "t = 12, avg_loss = 0.3618\n",
            "t = 14, avg_loss = 0.2854\n",
            "t = 16, avg_loss = 0.3294\n",
            "t = 18, avg_loss = 0.2632\n",
            "t = 20, avg_loss = 0.3000\n",
            "t = 22, avg_loss = 0.2881\n",
            "t = 24, avg_loss = 0.2972\n",
            "Checking accuracy on test set\n",
            "Got 344 / 400 correct (86.00)\n",
            "acc = 0.860000\n",
            "Starting epoch 9 / 100\n",
            "t = 2, avg_loss = 0.3975\n",
            "t = 4, avg_loss = 0.2434\n",
            "t = 6, avg_loss = 0.2060\n",
            "t = 8, avg_loss = 0.2937\n",
            "t = 10, avg_loss = 0.2197\n",
            "t = 12, avg_loss = 0.2707\n",
            "t = 14, avg_loss = 0.2640\n",
            "t = 16, avg_loss = 0.2439\n",
            "t = 18, avg_loss = 0.2748\n",
            "t = 20, avg_loss = 0.2069\n",
            "t = 22, avg_loss = 0.2066\n",
            "t = 24, avg_loss = 0.3229\n",
            "Checking accuracy on test set\n",
            "Got 333 / 400 correct (83.25)\n",
            "acc = 0.832500\n",
            "Starting epoch 10 / 100\n",
            "t = 2, avg_loss = 0.3396\n",
            "t = 4, avg_loss = 0.2240\n",
            "t = 6, avg_loss = 0.2738\n",
            "t = 8, avg_loss = 0.2244\n",
            "t = 10, avg_loss = 0.3152\n",
            "t = 12, avg_loss = 0.1897\n",
            "t = 14, avg_loss = 0.2552\n",
            "t = 16, avg_loss = 0.2519\n",
            "t = 18, avg_loss = 0.3157\n",
            "t = 20, avg_loss = 0.2204\n",
            "t = 22, avg_loss = 0.2231\n",
            "t = 24, avg_loss = 0.2745\n",
            "Checking accuracy on test set\n",
            "Got 342 / 400 correct (85.50)\n",
            "acc = 0.855000\n",
            "Starting epoch 11 / 100\n",
            "t = 2, avg_loss = 0.4443\n",
            "t = 4, avg_loss = 0.2403\n",
            "t = 6, avg_loss = 0.1818\n",
            "t = 8, avg_loss = 0.2282\n",
            "t = 10, avg_loss = 0.1844\n",
            "t = 12, avg_loss = 0.1969\n",
            "t = 14, avg_loss = 0.2993\n",
            "t = 16, avg_loss = 0.2247\n",
            "t = 18, avg_loss = 0.2199\n",
            "t = 20, avg_loss = 0.2550\n",
            "t = 22, avg_loss = 0.1808\n",
            "t = 24, avg_loss = 0.3701\n",
            "Checking accuracy on test set\n",
            "Got 343 / 400 correct (85.75)\n",
            "acc = 0.857500\n",
            "Starting epoch 12 / 100\n",
            "t = 2, avg_loss = 0.3259\n",
            "t = 4, avg_loss = 0.2711\n",
            "t = 6, avg_loss = 0.2124\n",
            "t = 8, avg_loss = 0.2326\n",
            "t = 10, avg_loss = 0.1619\n",
            "t = 12, avg_loss = 0.2184\n",
            "t = 14, avg_loss = 0.2350\n",
            "t = 16, avg_loss = 0.2200\n",
            "t = 18, avg_loss = 0.3035\n",
            "t = 20, avg_loss = 0.3259\n",
            "t = 22, avg_loss = 0.2095\n",
            "t = 24, avg_loss = 0.2020\n",
            "Checking accuracy on test set\n",
            "Got 341 / 400 correct (85.25)\n",
            "acc = 0.852500\n",
            "Starting epoch 13 / 100\n",
            "t = 2, avg_loss = 0.2415\n",
            "t = 4, avg_loss = 0.1936\n",
            "t = 6, avg_loss = 0.2323\n",
            "t = 8, avg_loss = 0.2154\n",
            "t = 10, avg_loss = 0.2306\n",
            "t = 12, avg_loss = 0.2135\n",
            "t = 14, avg_loss = 0.2104\n",
            "t = 16, avg_loss = 0.2086\n",
            "t = 18, avg_loss = 0.1890\n",
            "t = 20, avg_loss = 0.2454\n",
            "t = 22, avg_loss = 0.2095\n",
            "t = 24, avg_loss = 0.2313\n",
            "Checking accuracy on test set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 14 / 100\n",
            "t = 2, avg_loss = 0.2781\n",
            "t = 4, avg_loss = 0.1920\n",
            "t = 6, avg_loss = 0.1996\n",
            "t = 8, avg_loss = 0.2182\n",
            "t = 10, avg_loss = 0.2537\n",
            "t = 12, avg_loss = 0.2375\n",
            "t = 14, avg_loss = 0.2357\n",
            "t = 16, avg_loss = 0.2033\n",
            "t = 18, avg_loss = 0.2371\n",
            "t = 20, avg_loss = 0.1731\n",
            "t = 22, avg_loss = 0.2320\n",
            "t = 24, avg_loss = 0.1709\n",
            "Checking accuracy on test set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 15 / 100\n",
            "t = 2, avg_loss = 0.2569\n",
            "t = 4, avg_loss = 0.2125\n",
            "t = 6, avg_loss = 0.2296\n",
            "t = 8, avg_loss = 0.2437\n",
            "t = 10, avg_loss = 0.2036\n",
            "t = 12, avg_loss = 0.2141\n",
            "t = 14, avg_loss = 0.2183\n",
            "t = 16, avg_loss = 0.1800\n",
            "t = 18, avg_loss = 0.2123\n",
            "t = 20, avg_loss = 0.1939\n",
            "t = 22, avg_loss = 0.1992\n",
            "t = 24, avg_loss = 0.1652\n",
            "Checking accuracy on test set\n",
            "Got 337 / 400 correct (84.25)\n",
            "acc = 0.842500\n",
            "Starting epoch 16 / 100\n",
            "t = 2, avg_loss = 0.3462\n",
            "t = 4, avg_loss = 0.2262\n",
            "t = 6, avg_loss = 0.1968\n",
            "t = 8, avg_loss = 0.2411\n",
            "t = 10, avg_loss = 0.2044\n",
            "t = 12, avg_loss = 0.1456\n",
            "t = 14, avg_loss = 0.1990\n",
            "t = 16, avg_loss = 0.1840\n",
            "t = 18, avg_loss = 0.2112\n",
            "t = 20, avg_loss = 0.2589\n",
            "t = 22, avg_loss = 0.1994\n",
            "t = 24, avg_loss = 0.2387\n",
            "Checking accuracy on test set\n",
            "Got 340 / 400 correct (85.00)\n",
            "acc = 0.850000\n",
            "Starting epoch 17 / 100\n",
            "t = 2, avg_loss = 0.3393\n",
            "t = 4, avg_loss = 0.2290\n",
            "t = 6, avg_loss = 0.1881\n",
            "t = 8, avg_loss = 0.1907\n",
            "t = 10, avg_loss = 0.2529\n",
            "t = 12, avg_loss = 0.1627\n",
            "t = 14, avg_loss = 0.1775\n",
            "t = 16, avg_loss = 0.2361\n",
            "t = 18, avg_loss = 0.1759\n",
            "t = 20, avg_loss = 0.1633\n",
            "t = 22, avg_loss = 0.1601\n",
            "t = 24, avg_loss = 0.2136\n",
            "Checking accuracy on test set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 18 / 100\n",
            "t = 2, avg_loss = 0.2494\n",
            "t = 4, avg_loss = 0.2119\n",
            "t = 6, avg_loss = 0.1823\n",
            "t = 8, avg_loss = 0.1724\n",
            "t = 10, avg_loss = 0.1658\n",
            "t = 12, avg_loss = 0.2124\n",
            "t = 14, avg_loss = 0.1150\n",
            "t = 16, avg_loss = 0.2057\n",
            "t = 18, avg_loss = 0.1560\n",
            "t = 20, avg_loss = 0.1791\n",
            "t = 22, avg_loss = 0.1856\n",
            "t = 24, avg_loss = 0.2477\n",
            "Checking accuracy on test set\n",
            "Got 339 / 400 correct (84.75)\n",
            "acc = 0.847500\n",
            "Starting epoch 19 / 100\n",
            "t = 2, avg_loss = 0.2781\n",
            "t = 4, avg_loss = 0.1874\n",
            "t = 6, avg_loss = 0.1730\n",
            "t = 8, avg_loss = 0.2072\n",
            "t = 10, avg_loss = 0.1626\n",
            "t = 12, avg_loss = 0.1940\n",
            "t = 14, avg_loss = 0.1414\n",
            "t = 16, avg_loss = 0.1742\n",
            "t = 18, avg_loss = 0.1178\n",
            "t = 20, avg_loss = 0.2058\n",
            "t = 22, avg_loss = 0.1362\n",
            "t = 24, avg_loss = 0.1870\n",
            "Checking accuracy on test set\n",
            "Got 343 / 400 correct (85.75)\n",
            "acc = 0.857500\n",
            "Starting epoch 20 / 100\n",
            "t = 2, avg_loss = 0.1429\n",
            "t = 4, avg_loss = 0.1636\n",
            "t = 6, avg_loss = 0.2108\n",
            "t = 8, avg_loss = 0.1774\n",
            "t = 10, avg_loss = 0.2020\n",
            "t = 12, avg_loss = 0.1881\n",
            "t = 14, avg_loss = 0.1142\n",
            "t = 16, avg_loss = 0.1636\n",
            "t = 18, avg_loss = 0.1774\n",
            "t = 20, avg_loss = 0.2026\n",
            "t = 22, avg_loss = 0.2290\n",
            "t = 24, avg_loss = 0.1722\n",
            "Checking accuracy on test set\n",
            "Got 342 / 400 correct (85.50)\n",
            "acc = 0.855000\n",
            "Starting epoch 21 / 100\n",
            "t = 2, avg_loss = 0.1948\n",
            "t = 4, avg_loss = 0.1818\n",
            "t = 6, avg_loss = 0.1687\n",
            "t = 8, avg_loss = 0.2101\n",
            "t = 10, avg_loss = 0.1614\n",
            "t = 12, avg_loss = 0.1023\n",
            "t = 14, avg_loss = 0.1342\n",
            "t = 16, avg_loss = 0.1788\n",
            "t = 18, avg_loss = 0.1490\n",
            "t = 20, avg_loss = 0.1620\n",
            "t = 22, avg_loss = 0.2262\n",
            "t = 24, avg_loss = 0.1532\n",
            "Checking accuracy on test set\n",
            "Got 344 / 400 correct (86.00)\n",
            "acc = 0.860000\n",
            "Starting epoch 22 / 100\n",
            "t = 2, avg_loss = 0.3175\n",
            "t = 4, avg_loss = 0.1425\n",
            "t = 6, avg_loss = 0.1190\n",
            "t = 8, avg_loss = 0.1573\n",
            "t = 10, avg_loss = 0.2124\n",
            "t = 12, avg_loss = 0.2033\n",
            "t = 14, avg_loss = 0.2784\n",
            "t = 16, avg_loss = 0.1956\n",
            "t = 18, avg_loss = 0.1555\n",
            "t = 20, avg_loss = 0.1352\n",
            "t = 22, avg_loss = 0.1201\n",
            "t = 24, avg_loss = 0.0940\n",
            "Checking accuracy on test set\n",
            "Got 338 / 400 correct (84.50)\n",
            "acc = 0.845000\n",
            "Starting epoch 23 / 100\n",
            "t = 2, avg_loss = 0.2158\n",
            "t = 4, avg_loss = 0.1425\n",
            "t = 6, avg_loss = 0.1280\n",
            "t = 8, avg_loss = 0.1355\n",
            "t = 10, avg_loss = 0.1599\n",
            "t = 12, avg_loss = 0.1411\n",
            "t = 14, avg_loss = 0.1422\n",
            "t = 16, avg_loss = 0.2102\n",
            "t = 18, avg_loss = 0.0906\n",
            "t = 20, avg_loss = 0.1369\n",
            "t = 22, avg_loss = 0.1584\n",
            "t = 24, avg_loss = 0.1769\n",
            "Checking accuracy on test set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 24 / 100\n",
            "t = 2, avg_loss = 0.3008\n",
            "t = 4, avg_loss = 0.0870\n",
            "t = 6, avg_loss = 0.1328\n",
            "t = 8, avg_loss = 0.1788\n",
            "t = 10, avg_loss = 0.1812\n",
            "t = 12, avg_loss = 0.1282\n",
            "t = 14, avg_loss = 0.1940\n",
            "t = 16, avg_loss = 0.1421\n",
            "t = 18, avg_loss = 0.1191\n",
            "t = 20, avg_loss = 0.1434\n",
            "t = 22, avg_loss = 0.1845\n",
            "t = 24, avg_loss = 0.1222\n",
            "Checking accuracy on test set\n",
            "Got 352 / 400 correct (88.00)\n",
            "acc = 0.880000\n",
            "Starting epoch 25 / 100\n",
            "t = 2, avg_loss = 0.2224\n",
            "t = 4, avg_loss = 0.2299\n",
            "t = 6, avg_loss = 0.2014\n",
            "t = 8, avg_loss = 0.1561\n",
            "t = 10, avg_loss = 0.1217\n",
            "t = 12, avg_loss = 0.1486\n",
            "t = 14, avg_loss = 0.1253\n",
            "t = 16, avg_loss = 0.2017\n",
            "t = 18, avg_loss = 0.1077\n",
            "t = 20, avg_loss = 0.1383\n",
            "t = 22, avg_loss = 0.1845\n",
            "t = 24, avg_loss = 0.1241\n",
            "Checking accuracy on test set\n",
            "Got 343 / 400 correct (85.75)\n",
            "acc = 0.857500\n",
            "Starting epoch 26 / 100\n",
            "t = 2, avg_loss = 0.2440\n",
            "t = 4, avg_loss = 0.1341\n",
            "t = 6, avg_loss = 0.1128\n",
            "t = 8, avg_loss = 0.0950\n",
            "t = 10, avg_loss = 0.1160\n",
            "t = 12, avg_loss = 0.1580\n",
            "t = 14, avg_loss = 0.0992\n",
            "t = 16, avg_loss = 0.0880\n",
            "t = 18, avg_loss = 0.1902\n",
            "t = 20, avg_loss = 0.1318\n",
            "t = 22, avg_loss = 0.1416\n",
            "t = 24, avg_loss = 0.1969\n",
            "Checking accuracy on test set\n",
            "Got 345 / 400 correct (86.25)\n",
            "acc = 0.862500\n",
            "Starting epoch 27 / 100\n",
            "t = 2, avg_loss = 0.2002\n",
            "t = 4, avg_loss = 0.0968\n",
            "t = 6, avg_loss = 0.1436\n",
            "t = 8, avg_loss = 0.1663\n",
            "t = 10, avg_loss = 0.1334\n",
            "t = 12, avg_loss = 0.0878\n",
            "t = 14, avg_loss = 0.1240\n",
            "t = 16, avg_loss = 0.1947\n",
            "t = 18, avg_loss = 0.1332\n",
            "t = 20, avg_loss = 0.1789\n",
            "t = 22, avg_loss = 0.1389\n",
            "t = 24, avg_loss = 0.1053\n",
            "Checking accuracy on test set\n",
            "Got 344 / 400 correct (86.00)\n",
            "acc = 0.860000\n",
            "Starting epoch 28 / 100\n",
            "t = 2, avg_loss = 0.1490\n",
            "t = 4, avg_loss = 0.1193\n",
            "t = 6, avg_loss = 0.1544\n",
            "t = 8, avg_loss = 0.1643\n",
            "t = 10, avg_loss = 0.1453\n",
            "t = 12, avg_loss = 0.1063\n",
            "t = 14, avg_loss = 0.1599\n",
            "t = 16, avg_loss = 0.1091\n",
            "t = 18, avg_loss = 0.1501\n",
            "t = 20, avg_loss = 0.2044\n",
            "t = 22, avg_loss = 0.0981\n",
            "t = 24, avg_loss = 0.1004\n",
            "Checking accuracy on test set\n",
            "Got 342 / 400 correct (85.50)\n",
            "acc = 0.855000\n",
            "Starting epoch 29 / 100\n",
            "t = 2, avg_loss = 0.1837\n",
            "t = 4, avg_loss = 0.1426\n",
            "t = 6, avg_loss = 0.1440\n",
            "t = 8, avg_loss = 0.1518\n",
            "t = 10, avg_loss = 0.1198\n",
            "t = 12, avg_loss = 0.1380\n",
            "t = 14, avg_loss = 0.0604\n",
            "t = 16, avg_loss = 0.1468\n",
            "t = 18, avg_loss = 0.1586\n",
            "t = 20, avg_loss = 0.1254\n",
            "t = 22, avg_loss = 0.1068\n",
            "t = 24, avg_loss = 0.1166\n",
            "Checking accuracy on test set\n",
            "Got 355 / 400 correct (88.75)\n",
            "acc = 0.887500\n",
            "Starting epoch 30 / 100\n",
            "t = 2, avg_loss = 0.1986\n",
            "t = 4, avg_loss = 0.1001\n",
            "t = 6, avg_loss = 0.1082\n",
            "t = 8, avg_loss = 0.0890\n",
            "t = 10, avg_loss = 0.0961\n",
            "t = 12, avg_loss = 0.1337\n",
            "t = 14, avg_loss = 0.1219\n",
            "t = 16, avg_loss = 0.1836\n",
            "t = 18, avg_loss = 0.0823\n",
            "t = 20, avg_loss = 0.1474\n",
            "t = 22, avg_loss = 0.1096\n",
            "t = 24, avg_loss = 0.1393\n",
            "Checking accuracy on test set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 31 / 100\n",
            "t = 2, avg_loss = 0.2205\n",
            "t = 4, avg_loss = 0.1549\n",
            "t = 6, avg_loss = 0.0995\n",
            "t = 8, avg_loss = 0.0813\n",
            "t = 10, avg_loss = 0.1145\n",
            "t = 12, avg_loss = 0.1399\n",
            "t = 14, avg_loss = 0.1393\n",
            "t = 16, avg_loss = 0.1207\n",
            "t = 18, avg_loss = 0.1156\n",
            "t = 20, avg_loss = 0.0842\n",
            "t = 22, avg_loss = 0.1694\n",
            "t = 24, avg_loss = 0.0672\n",
            "Checking accuracy on test set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 32 / 100\n",
            "t = 2, avg_loss = 0.1725\n",
            "t = 4, avg_loss = 0.0881\n",
            "t = 6, avg_loss = 0.1441\n",
            "t = 8, avg_loss = 0.1197\n",
            "t = 10, avg_loss = 0.0923\n",
            "t = 12, avg_loss = 0.1242\n",
            "t = 14, avg_loss = 0.1180\n",
            "t = 16, avg_loss = 0.1857\n",
            "t = 18, avg_loss = 0.1142\n",
            "t = 20, avg_loss = 0.1107\n",
            "t = 22, avg_loss = 0.0527\n",
            "t = 24, avg_loss = 0.1425\n",
            "Checking accuracy on test set\n",
            "Got 335 / 400 correct (83.75)\n",
            "acc = 0.837500\n",
            "Starting epoch 33 / 100\n",
            "t = 2, avg_loss = 0.1913\n",
            "t = 4, avg_loss = 0.0743\n",
            "t = 6, avg_loss = 0.1333\n",
            "t = 8, avg_loss = 0.1414\n",
            "t = 10, avg_loss = 0.1071\n",
            "t = 12, avg_loss = 0.0786\n",
            "t = 14, avg_loss = 0.1593\n",
            "t = 16, avg_loss = 0.1538\n",
            "t = 18, avg_loss = 0.1313\n",
            "t = 20, avg_loss = 0.0939\n",
            "t = 22, avg_loss = 0.1554\n",
            "t = 24, avg_loss = 0.0836\n",
            "Checking accuracy on test set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 34 / 100\n",
            "t = 2, avg_loss = 0.2330\n",
            "t = 4, avg_loss = 0.1910\n",
            "t = 6, avg_loss = 0.1505\n",
            "t = 8, avg_loss = 0.1191\n",
            "t = 10, avg_loss = 0.0894\n",
            "t = 12, avg_loss = 0.0700\n",
            "t = 14, avg_loss = 0.1259\n",
            "t = 16, avg_loss = 0.1205\n",
            "t = 18, avg_loss = 0.0854\n",
            "t = 20, avg_loss = 0.1112\n",
            "t = 22, avg_loss = 0.0978\n",
            "t = 24, avg_loss = 0.0872\n",
            "Checking accuracy on test set\n",
            "Got 344 / 400 correct (86.00)\n",
            "acc = 0.860000\n",
            "Starting epoch 35 / 100\n",
            "t = 2, avg_loss = 0.1853\n",
            "t = 4, avg_loss = 0.1272\n",
            "t = 6, avg_loss = 0.1328\n",
            "t = 8, avg_loss = 0.1496\n",
            "t = 10, avg_loss = 0.1295\n",
            "t = 12, avg_loss = 0.0986\n",
            "t = 14, avg_loss = 0.0927\n",
            "t = 16, avg_loss = 0.1126\n",
            "t = 18, avg_loss = 0.0991\n",
            "t = 20, avg_loss = 0.1228\n",
            "t = 22, avg_loss = 0.1318\n",
            "t = 24, avg_loss = 0.0878\n",
            "Checking accuracy on test set\n",
            "Got 344 / 400 correct (86.00)\n",
            "acc = 0.860000\n",
            "Starting epoch 36 / 100\n",
            "t = 2, avg_loss = 0.1245\n",
            "t = 4, avg_loss = 0.0808\n",
            "t = 6, avg_loss = 0.0760\n",
            "t = 8, avg_loss = 0.0640\n",
            "t = 10, avg_loss = 0.1161\n",
            "t = 12, avg_loss = 0.0755\n",
            "t = 14, avg_loss = 0.1283\n",
            "t = 16, avg_loss = 0.0526\n",
            "t = 18, avg_loss = 0.0947\n",
            "t = 20, avg_loss = 0.0900\n",
            "t = 22, avg_loss = 0.1035\n",
            "t = 24, avg_loss = 0.1940\n",
            "Checking accuracy on test set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 37 / 100\n",
            "t = 2, avg_loss = 0.1641\n",
            "t = 4, avg_loss = 0.0576\n",
            "t = 6, avg_loss = 0.0779\n",
            "t = 8, avg_loss = 0.1167\n",
            "t = 10, avg_loss = 0.1216\n",
            "t = 12, avg_loss = 0.1078\n",
            "t = 14, avg_loss = 0.1123\n",
            "t = 16, avg_loss = 0.1254\n",
            "t = 18, avg_loss = 0.0669\n",
            "t = 20, avg_loss = 0.0838\n",
            "t = 22, avg_loss = 0.0540\n",
            "t = 24, avg_loss = 0.0812\n",
            "Checking accuracy on test set\n",
            "Got 346 / 400 correct (86.50)\n",
            "acc = 0.865000\n",
            "Starting epoch 38 / 100\n",
            "t = 2, avg_loss = 0.1104\n",
            "t = 4, avg_loss = 0.1300\n",
            "t = 6, avg_loss = 0.0293\n",
            "t = 8, avg_loss = 0.0717\n",
            "t = 10, avg_loss = 0.0916\n",
            "t = 12, avg_loss = 0.0905\n",
            "t = 14, avg_loss = 0.1443\n",
            "t = 16, avg_loss = 0.0733\n",
            "t = 18, avg_loss = 0.0781\n",
            "t = 20, avg_loss = 0.0961\n",
            "t = 22, avg_loss = 0.0986\n",
            "t = 24, avg_loss = 0.0899\n",
            "Checking accuracy on test set\n",
            "Got 345 / 400 correct (86.25)\n",
            "acc = 0.862500\n",
            "Starting epoch 39 / 100\n",
            "t = 2, avg_loss = 0.1011\n",
            "t = 4, avg_loss = 0.0749\n",
            "t = 6, avg_loss = 0.1070\n",
            "t = 8, avg_loss = 0.0829\n",
            "t = 10, avg_loss = 0.0440\n",
            "t = 12, avg_loss = 0.1310\n",
            "t = 14, avg_loss = 0.1280\n",
            "t = 16, avg_loss = 0.0575\n",
            "t = 18, avg_loss = 0.0863\n",
            "t = 20, avg_loss = 0.0829\n",
            "t = 22, avg_loss = 0.0591\n",
            "t = 24, avg_loss = 0.1494\n",
            "Checking accuracy on test set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 40 / 100\n",
            "t = 2, avg_loss = 0.0966\n",
            "t = 4, avg_loss = 0.1142\n",
            "t = 6, avg_loss = 0.1256\n",
            "t = 8, avg_loss = 0.0987\n",
            "t = 10, avg_loss = 0.1150\n",
            "t = 12, avg_loss = 0.0954\n",
            "t = 14, avg_loss = 0.0779\n",
            "t = 16, avg_loss = 0.0794\n",
            "t = 18, avg_loss = 0.1205\n",
            "t = 20, avg_loss = 0.1027\n",
            "t = 22, avg_loss = 0.0905\n",
            "t = 24, avg_loss = 0.0741\n",
            "Checking accuracy on test set\n",
            "Got 351 / 400 correct (87.75)\n",
            "acc = 0.877500\n",
            "Starting epoch 41 / 100\n",
            "t = 2, avg_loss = 0.2271\n",
            "t = 4, avg_loss = 0.0847\n",
            "t = 6, avg_loss = 0.0442\n",
            "t = 8, avg_loss = 0.0670\n",
            "t = 10, avg_loss = 0.0684\n",
            "t = 12, avg_loss = 0.1047\n",
            "t = 14, avg_loss = 0.1107\n",
            "t = 16, avg_loss = 0.0596\n",
            "t = 18, avg_loss = 0.0670\n",
            "t = 20, avg_loss = 0.0700\n",
            "t = 22, avg_loss = 0.0847\n",
            "t = 24, avg_loss = 0.0988\n",
            "Checking accuracy on test set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 42 / 100\n",
            "t = 2, avg_loss = 0.0733\n",
            "t = 4, avg_loss = 0.0723\n",
            "t = 6, avg_loss = 0.0727\n",
            "t = 8, avg_loss = 0.0881\n",
            "t = 10, avg_loss = 0.0540\n",
            "t = 12, avg_loss = 0.0689\n",
            "t = 14, avg_loss = 0.1027\n",
            "t = 16, avg_loss = 0.0781\n",
            "t = 18, avg_loss = 0.1238\n",
            "t = 20, avg_loss = 0.0615\n",
            "t = 22, avg_loss = 0.0770\n",
            "t = 24, avg_loss = 0.0951\n",
            "Checking accuracy on test set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 43 / 100\n",
            "t = 2, avg_loss = 0.1576\n",
            "t = 4, avg_loss = 0.0928\n",
            "t = 6, avg_loss = 0.1006\n",
            "t = 8, avg_loss = 0.0573\n",
            "t = 10, avg_loss = 0.0680\n",
            "t = 12, avg_loss = 0.0652\n",
            "t = 14, avg_loss = 0.0711\n",
            "t = 16, avg_loss = 0.0656\n",
            "t = 18, avg_loss = 0.0778\n",
            "t = 20, avg_loss = 0.0563\n",
            "t = 22, avg_loss = 0.0846\n",
            "t = 24, avg_loss = 0.0848\n",
            "Checking accuracy on test set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 44 / 100\n",
            "t = 2, avg_loss = 0.1303\n",
            "t = 4, avg_loss = 0.0496\n",
            "t = 6, avg_loss = 0.1069\n",
            "t = 8, avg_loss = 0.0470\n",
            "t = 10, avg_loss = 0.1082\n",
            "t = 12, avg_loss = 0.0548\n",
            "t = 14, avg_loss = 0.0924\n",
            "t = 16, avg_loss = 0.0519\n",
            "t = 18, avg_loss = 0.0500\n",
            "t = 20, avg_loss = 0.1037\n",
            "t = 22, avg_loss = 0.1292\n",
            "t = 24, avg_loss = 0.0987\n",
            "Checking accuracy on test set\n",
            "Got 341 / 400 correct (85.25)\n",
            "acc = 0.852500\n",
            "Starting epoch 45 / 100\n",
            "t = 2, avg_loss = 0.1207\n",
            "t = 4, avg_loss = 0.1058\n",
            "t = 6, avg_loss = 0.0919\n",
            "t = 8, avg_loss = 0.0905\n",
            "t = 10, avg_loss = 0.0929\n",
            "t = 12, avg_loss = 0.0573\n",
            "t = 14, avg_loss = 0.0749\n",
            "t = 16, avg_loss = 0.0927\n",
            "t = 18, avg_loss = 0.0564\n",
            "t = 20, avg_loss = 0.0928\n",
            "t = 22, avg_loss = 0.0564\n",
            "t = 24, avg_loss = 0.1167\n",
            "Checking accuracy on test set\n",
            "Got 351 / 400 correct (87.75)\n",
            "acc = 0.877500\n",
            "Starting epoch 46 / 100\n",
            "t = 2, avg_loss = 0.0829\n",
            "t = 4, avg_loss = 0.0558\n",
            "t = 6, avg_loss = 0.0906\n",
            "t = 8, avg_loss = 0.1008\n",
            "t = 10, avg_loss = 0.0995\n",
            "t = 12, avg_loss = 0.1020\n",
            "t = 14, avg_loss = 0.1140\n",
            "t = 16, avg_loss = 0.0381\n",
            "t = 18, avg_loss = 0.0719\n",
            "t = 20, avg_loss = 0.1063\n",
            "t = 22, avg_loss = 0.0857\n",
            "t = 24, avg_loss = 0.0769\n",
            "Checking accuracy on test set\n",
            "Got 345 / 400 correct (86.25)\n",
            "acc = 0.862500\n",
            "Starting epoch 47 / 100\n",
            "t = 2, avg_loss = 0.0911\n",
            "t = 4, avg_loss = 0.0310\n",
            "t = 6, avg_loss = 0.1486\n",
            "t = 8, avg_loss = 0.0756\n",
            "t = 10, avg_loss = 0.0654\n",
            "t = 12, avg_loss = 0.0904\n",
            "t = 14, avg_loss = 0.0422\n",
            "t = 16, avg_loss = 0.0799\n",
            "t = 18, avg_loss = 0.0675\n",
            "t = 20, avg_loss = 0.0740\n",
            "t = 22, avg_loss = 0.0676\n",
            "t = 24, avg_loss = 0.0664\n",
            "Checking accuracy on test set\n",
            "Got 351 / 400 correct (87.75)\n",
            "acc = 0.877500\n",
            "Starting epoch 48 / 100\n",
            "t = 2, avg_loss = 0.1235\n",
            "t = 4, avg_loss = 0.0534\n",
            "t = 6, avg_loss = 0.0884\n",
            "t = 8, avg_loss = 0.0696\n",
            "t = 10, avg_loss = 0.0464\n",
            "t = 12, avg_loss = 0.1202\n",
            "t = 14, avg_loss = 0.0240\n",
            "t = 16, avg_loss = 0.1280\n",
            "t = 18, avg_loss = 0.0628\n",
            "t = 20, avg_loss = 0.0618\n",
            "t = 22, avg_loss = 0.0843\n",
            "t = 24, avg_loss = 0.0970\n",
            "Checking accuracy on test set\n",
            "Got 343 / 400 correct (85.75)\n",
            "acc = 0.857500\n",
            "Starting epoch 49 / 100\n",
            "t = 2, avg_loss = 0.1283\n",
            "t = 4, avg_loss = 0.0649\n",
            "t = 6, avg_loss = 0.0634\n",
            "t = 8, avg_loss = 0.0401\n",
            "t = 10, avg_loss = 0.0662\n",
            "t = 12, avg_loss = 0.0897\n",
            "t = 14, avg_loss = 0.0762\n",
            "t = 16, avg_loss = 0.0266\n",
            "t = 18, avg_loss = 0.0520\n",
            "t = 20, avg_loss = 0.0534\n",
            "t = 22, avg_loss = 0.0711\n",
            "t = 24, avg_loss = 0.0432\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 50 / 100\n",
            "t = 2, avg_loss = 0.1020\n",
            "t = 4, avg_loss = 0.0702\n",
            "t = 6, avg_loss = 0.0543\n",
            "t = 8, avg_loss = 0.0453\n",
            "t = 10, avg_loss = 0.0404\n",
            "t = 12, avg_loss = 0.1223\n",
            "t = 14, avg_loss = 0.0755\n",
            "t = 16, avg_loss = 0.0485\n",
            "t = 18, avg_loss = 0.0675\n",
            "t = 20, avg_loss = 0.0564\n",
            "t = 22, avg_loss = 0.0586\n",
            "t = 24, avg_loss = 0.1254\n",
            "Checking accuracy on test set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 51 / 100\n",
            "t = 2, avg_loss = 0.0741\n",
            "t = 4, avg_loss = 0.0493\n",
            "t = 6, avg_loss = 0.0590\n",
            "t = 8, avg_loss = 0.0793\n",
            "t = 10, avg_loss = 0.0668\n",
            "t = 12, avg_loss = 0.0636\n",
            "t = 14, avg_loss = 0.0543\n",
            "t = 16, avg_loss = 0.0427\n",
            "t = 18, avg_loss = 0.0749\n",
            "t = 20, avg_loss = 0.0416\n",
            "t = 22, avg_loss = 0.0634\n",
            "t = 24, avg_loss = 0.1053\n",
            "Checking accuracy on test set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 52 / 100\n",
            "t = 2, avg_loss = 0.0680\n",
            "t = 4, avg_loss = 0.0459\n",
            "t = 6, avg_loss = 0.0863\n",
            "t = 8, avg_loss = 0.0263\n",
            "t = 10, avg_loss = 0.0425\n",
            "t = 12, avg_loss = 0.0433\n",
            "t = 14, avg_loss = 0.0866\n",
            "t = 16, avg_loss = 0.0331\n",
            "t = 18, avg_loss = 0.0341\n",
            "t = 20, avg_loss = 0.0390\n",
            "t = 22, avg_loss = 0.0286\n",
            "t = 24, avg_loss = 0.0441\n",
            "Checking accuracy on test set\n",
            "Got 345 / 400 correct (86.25)\n",
            "acc = 0.862500\n",
            "Starting epoch 53 / 100\n",
            "t = 2, avg_loss = 0.0776\n",
            "t = 4, avg_loss = 0.0395\n",
            "t = 6, avg_loss = 0.0545\n",
            "t = 8, avg_loss = 0.0422\n",
            "t = 10, avg_loss = 0.0585\n",
            "t = 12, avg_loss = 0.0677\n",
            "t = 14, avg_loss = 0.1228\n",
            "t = 16, avg_loss = 0.0292\n",
            "t = 18, avg_loss = 0.0664\n",
            "t = 20, avg_loss = 0.0595\n",
            "t = 22, avg_loss = 0.0945\n",
            "t = 24, avg_loss = 0.0616\n",
            "Checking accuracy on test set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 54 / 100\n",
            "t = 2, avg_loss = 0.0558\n",
            "t = 4, avg_loss = 0.0240\n",
            "t = 6, avg_loss = 0.0352\n",
            "t = 8, avg_loss = 0.0824\n",
            "t = 10, avg_loss = 0.0456\n",
            "t = 12, avg_loss = 0.2016\n",
            "t = 14, avg_loss = 0.0171\n",
            "t = 16, avg_loss = 0.0806\n",
            "t = 18, avg_loss = 0.0565\n",
            "t = 20, avg_loss = 0.0959\n",
            "t = 22, avg_loss = 0.0744\n",
            "t = 24, avg_loss = 0.0314\n",
            "Checking accuracy on test set\n",
            "Got 346 / 400 correct (86.50)\n",
            "acc = 0.865000\n",
            "Starting epoch 55 / 100\n",
            "t = 2, avg_loss = 0.0981\n",
            "t = 4, avg_loss = 0.0723\n",
            "t = 6, avg_loss = 0.0549\n",
            "t = 8, avg_loss = 0.1045\n",
            "t = 10, avg_loss = 0.0433\n",
            "t = 12, avg_loss = 0.0613\n",
            "t = 14, avg_loss = 0.0589\n",
            "t = 16, avg_loss = 0.0464\n",
            "t = 18, avg_loss = 0.0435\n",
            "t = 20, avg_loss = 0.0529\n",
            "t = 22, avg_loss = 0.0631\n",
            "t = 24, avg_loss = 0.0881\n",
            "Checking accuracy on test set\n",
            "Got 343 / 400 correct (85.75)\n",
            "acc = 0.857500\n",
            "Starting epoch 56 / 100\n",
            "t = 2, avg_loss = 0.0424\n",
            "t = 4, avg_loss = 0.0707\n",
            "t = 6, avg_loss = 0.1053\n",
            "t = 8, avg_loss = 0.0574\n",
            "t = 10, avg_loss = 0.0981\n",
            "t = 12, avg_loss = 0.0730\n",
            "t = 14, avg_loss = 0.0488\n",
            "t = 16, avg_loss = 0.0384\n",
            "t = 18, avg_loss = 0.0662\n",
            "t = 20, avg_loss = 0.0492\n",
            "t = 22, avg_loss = 0.0370\n",
            "t = 24, avg_loss = 0.0782\n",
            "Checking accuracy on test set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 57 / 100\n",
            "t = 2, avg_loss = 0.0525\n",
            "t = 4, avg_loss = 0.0654\n",
            "t = 6, avg_loss = 0.0479\n",
            "t = 8, avg_loss = 0.0250\n",
            "t = 10, avg_loss = 0.0218\n",
            "t = 12, avg_loss = 0.0701\n",
            "t = 14, avg_loss = 0.0540\n",
            "t = 16, avg_loss = 0.0189\n",
            "t = 18, avg_loss = 0.0531\n",
            "t = 20, avg_loss = 0.0223\n",
            "t = 22, avg_loss = 0.0709\n",
            "t = 24, avg_loss = 0.0666\n",
            "Checking accuracy on test set\n",
            "Got 341 / 400 correct (85.25)\n",
            "acc = 0.852500\n",
            "Starting epoch 58 / 100\n",
            "t = 2, avg_loss = 0.0564\n",
            "t = 4, avg_loss = 0.0511\n",
            "t = 6, avg_loss = 0.0390\n",
            "t = 8, avg_loss = 0.0270\n",
            "t = 10, avg_loss = 0.0629\n",
            "t = 12, avg_loss = 0.0588\n",
            "t = 14, avg_loss = 0.0387\n",
            "t = 16, avg_loss = 0.0331\n",
            "t = 18, avg_loss = 0.0741\n",
            "t = 20, avg_loss = 0.0410\n",
            "t = 22, avg_loss = 0.0323\n",
            "t = 24, avg_loss = 0.0238\n",
            "Checking accuracy on test set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 59 / 100\n",
            "t = 2, avg_loss = 0.0825\n",
            "t = 4, avg_loss = 0.0590\n",
            "t = 6, avg_loss = 0.0327\n",
            "t = 8, avg_loss = 0.0369\n",
            "t = 10, avg_loss = 0.0476\n",
            "t = 12, avg_loss = 0.0319\n",
            "t = 14, avg_loss = 0.0214\n",
            "t = 16, avg_loss = 0.0298\n",
            "t = 18, avg_loss = 0.0915\n",
            "t = 20, avg_loss = 0.1030\n",
            "t = 22, avg_loss = 0.0332\n",
            "t = 24, avg_loss = 0.0536\n",
            "Checking accuracy on test set\n",
            "Got 344 / 400 correct (86.00)\n",
            "acc = 0.860000\n",
            "Starting epoch 60 / 100\n",
            "t = 2, avg_loss = 0.0719\n",
            "t = 4, avg_loss = 0.0191\n",
            "t = 6, avg_loss = 0.0537\n",
            "t = 8, avg_loss = 0.0712\n",
            "t = 10, avg_loss = 0.0367\n",
            "t = 12, avg_loss = 0.0249\n",
            "t = 14, avg_loss = 0.0340\n",
            "t = 16, avg_loss = 0.0892\n",
            "t = 18, avg_loss = 0.0582\n",
            "t = 20, avg_loss = 0.0517\n",
            "t = 22, avg_loss = 0.0192\n",
            "t = 24, avg_loss = 0.0966\n",
            "Checking accuracy on test set\n",
            "Got 346 / 400 correct (86.50)\n",
            "acc = 0.865000\n",
            "Starting epoch 61 / 100\n",
            "t = 2, avg_loss = 0.0891\n",
            "t = 4, avg_loss = 0.0934\n",
            "t = 6, avg_loss = 0.0525\n",
            "t = 8, avg_loss = 0.1280\n",
            "t = 10, avg_loss = 0.1478\n",
            "t = 12, avg_loss = 0.0849\n",
            "t = 14, avg_loss = 0.1455\n",
            "t = 16, avg_loss = 0.0293\n",
            "t = 18, avg_loss = 0.0555\n",
            "t = 20, avg_loss = 0.0669\n",
            "t = 22, avg_loss = 0.0636\n",
            "t = 24, avg_loss = 0.0477\n",
            "Checking accuracy on test set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 62 / 100\n",
            "t = 2, avg_loss = 0.0838\n",
            "t = 4, avg_loss = 0.0179\n",
            "t = 6, avg_loss = 0.0610\n",
            "t = 8, avg_loss = 0.1690\n",
            "t = 10, avg_loss = 0.0369\n",
            "t = 12, avg_loss = 0.0392\n",
            "t = 14, avg_loss = 0.0563\n",
            "t = 16, avg_loss = 0.0571\n",
            "t = 18, avg_loss = 0.1019\n",
            "t = 20, avg_loss = 0.1361\n",
            "t = 22, avg_loss = 0.0726\n",
            "t = 24, avg_loss = 0.0463\n",
            "Checking accuracy on test set\n",
            "Got 339 / 400 correct (84.75)\n",
            "acc = 0.847500\n",
            "Starting epoch 63 / 100\n",
            "t = 2, avg_loss = 0.0428\n",
            "t = 4, avg_loss = 0.0365\n",
            "t = 6, avg_loss = 0.0899\n",
            "t = 8, avg_loss = 0.0820\n",
            "t = 10, avg_loss = 0.0364\n",
            "t = 12, avg_loss = 0.0666\n",
            "t = 14, avg_loss = 0.0665\n",
            "t = 16, avg_loss = 0.0685\n",
            "t = 18, avg_loss = 0.0460\n",
            "t = 20, avg_loss = 0.0915\n",
            "t = 22, avg_loss = 0.0556\n",
            "t = 24, avg_loss = 0.0782\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 64 / 100\n",
            "t = 2, avg_loss = 0.0887\n",
            "t = 4, avg_loss = 0.0102\n",
            "t = 6, avg_loss = 0.0552\n",
            "t = 8, avg_loss = 0.0218\n",
            "t = 10, avg_loss = 0.0358\n",
            "t = 12, avg_loss = 0.0787\n",
            "t = 14, avg_loss = 0.0272\n",
            "t = 16, avg_loss = 0.0715\n",
            "t = 18, avg_loss = 0.0294\n",
            "t = 20, avg_loss = 0.0900\n",
            "t = 22, avg_loss = 0.0293\n",
            "t = 24, avg_loss = 0.0313\n",
            "Checking accuracy on test set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 65 / 100\n",
            "t = 2, avg_loss = 0.0727\n",
            "t = 4, avg_loss = 0.0483\n",
            "t = 6, avg_loss = 0.0725\n",
            "t = 8, avg_loss = 0.0527\n",
            "t = 10, avg_loss = 0.0213\n",
            "t = 12, avg_loss = 0.0601\n",
            "t = 14, avg_loss = 0.0459\n",
            "t = 16, avg_loss = 0.0840\n",
            "t = 18, avg_loss = 0.0609\n",
            "t = 20, avg_loss = 0.0250\n",
            "t = 22, avg_loss = 0.0407\n",
            "t = 24, avg_loss = 0.0225\n",
            "Checking accuracy on test set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 66 / 100\n",
            "t = 2, avg_loss = 0.0664\n",
            "t = 4, avg_loss = 0.0296\n",
            "t = 6, avg_loss = 0.0366\n",
            "t = 8, avg_loss = 0.0716\n",
            "t = 10, avg_loss = 0.0332\n",
            "t = 12, avg_loss = 0.0141\n",
            "t = 14, avg_loss = 0.0696\n",
            "t = 16, avg_loss = 0.0188\n",
            "t = 18, avg_loss = 0.0377\n",
            "t = 20, avg_loss = 0.0516\n",
            "t = 22, avg_loss = 0.0414\n",
            "t = 24, avg_loss = 0.0976\n",
            "Checking accuracy on test set\n",
            "Got 343 / 400 correct (85.75)\n",
            "acc = 0.857500\n",
            "Starting epoch 67 / 100\n",
            "t = 2, avg_loss = 0.0757\n",
            "t = 4, avg_loss = 0.0721\n",
            "t = 6, avg_loss = 0.0108\n",
            "t = 8, avg_loss = 0.0314\n",
            "t = 10, avg_loss = 0.0393\n",
            "t = 12, avg_loss = 0.0273\n",
            "t = 14, avg_loss = 0.0289\n",
            "t = 16, avg_loss = 0.0446\n",
            "t = 18, avg_loss = 0.0252\n",
            "t = 20, avg_loss = 0.0681\n",
            "t = 22, avg_loss = 0.0262\n",
            "t = 24, avg_loss = 0.0827\n",
            "Checking accuracy on test set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 68 / 100\n",
            "t = 2, avg_loss = 0.0422\n",
            "t = 4, avg_loss = 0.0607\n",
            "t = 6, avg_loss = 0.0858\n",
            "t = 8, avg_loss = 0.0388\n",
            "t = 10, avg_loss = 0.0356\n",
            "t = 12, avg_loss = 0.0360\n",
            "t = 14, avg_loss = 0.0522\n",
            "t = 16, avg_loss = 0.0613\n",
            "t = 18, avg_loss = 0.0593\n",
            "t = 20, avg_loss = 0.0230\n",
            "t = 22, avg_loss = 0.0455\n",
            "t = 24, avg_loss = 0.0475\n",
            "Checking accuracy on test set\n",
            "Got 344 / 400 correct (86.00)\n",
            "acc = 0.860000\n",
            "Starting epoch 69 / 100\n",
            "t = 2, avg_loss = 0.0887\n",
            "t = 4, avg_loss = 0.0259\n",
            "t = 6, avg_loss = 0.0284\n",
            "t = 8, avg_loss = 0.0243\n",
            "t = 10, avg_loss = 0.0170\n",
            "t = 12, avg_loss = 0.0207\n",
            "t = 14, avg_loss = 0.0384\n",
            "t = 16, avg_loss = 0.0289\n",
            "t = 18, avg_loss = 0.0237\n",
            "t = 20, avg_loss = 0.0292\n",
            "t = 22, avg_loss = 0.0293\n",
            "t = 24, avg_loss = 0.0247\n",
            "Checking accuracy on test set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 70 / 100\n",
            "t = 2, avg_loss = 0.0994\n",
            "t = 4, avg_loss = 0.0216\n",
            "t = 6, avg_loss = 0.0527\n",
            "t = 8, avg_loss = 0.0282\n",
            "t = 10, avg_loss = 0.0183\n",
            "t = 12, avg_loss = 0.0204\n",
            "t = 14, avg_loss = 0.0243\n",
            "t = 16, avg_loss = 0.0451\n",
            "t = 18, avg_loss = 0.0318\n",
            "t = 20, avg_loss = 0.0157\n",
            "t = 22, avg_loss = 0.0685\n",
            "t = 24, avg_loss = 0.0779\n",
            "Checking accuracy on test set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 71 / 100\n",
            "t = 2, avg_loss = 0.0487\n",
            "t = 4, avg_loss = 0.0707\n",
            "t = 6, avg_loss = 0.0428\n",
            "t = 8, avg_loss = 0.0202\n",
            "t = 10, avg_loss = 0.0285\n",
            "t = 12, avg_loss = 0.0306\n",
            "t = 14, avg_loss = 0.0251\n",
            "t = 16, avg_loss = 0.0656\n",
            "t = 18, avg_loss = 0.0708\n",
            "t = 20, avg_loss = 0.0342\n",
            "t = 22, avg_loss = 0.0854\n",
            "t = 24, avg_loss = 0.0287\n",
            "Checking accuracy on test set\n",
            "Got 343 / 400 correct (85.75)\n",
            "acc = 0.857500\n",
            "Starting epoch 72 / 100\n",
            "t = 2, avg_loss = 0.0400\n",
            "t = 4, avg_loss = 0.0383\n",
            "t = 6, avg_loss = 0.0283\n",
            "t = 8, avg_loss = 0.0313\n",
            "t = 10, avg_loss = 0.0348\n",
            "t = 12, avg_loss = 0.0134\n",
            "t = 14, avg_loss = 0.0304\n",
            "t = 16, avg_loss = 0.0759\n",
            "t = 18, avg_loss = 0.0368\n",
            "t = 20, avg_loss = 0.0274\n",
            "t = 22, avg_loss = 0.0216\n",
            "t = 24, avg_loss = 0.0298\n",
            "Checking accuracy on test set\n",
            "Got 340 / 400 correct (85.00)\n",
            "acc = 0.850000\n",
            "Starting epoch 73 / 100\n",
            "t = 2, avg_loss = 0.0445\n",
            "t = 4, avg_loss = 0.0138\n",
            "t = 6, avg_loss = 0.0167\n",
            "t = 8, avg_loss = 0.0621\n",
            "t = 10, avg_loss = 0.0177\n",
            "t = 12, avg_loss = 0.0411\n",
            "t = 14, avg_loss = 0.0361\n",
            "t = 16, avg_loss = 0.0278\n",
            "t = 18, avg_loss = 0.0226\n",
            "t = 20, avg_loss = 0.0518\n",
            "t = 22, avg_loss = 0.0354\n",
            "t = 24, avg_loss = 0.0575\n",
            "Checking accuracy on test set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 74 / 100\n",
            "t = 2, avg_loss = 0.1049\n",
            "t = 4, avg_loss = 0.0495\n",
            "t = 6, avg_loss = 0.0359\n",
            "t = 8, avg_loss = 0.0254\n",
            "t = 10, avg_loss = 0.0639\n",
            "t = 12, avg_loss = 0.0452\n",
            "t = 14, avg_loss = 0.0595\n",
            "t = 16, avg_loss = 0.0255\n",
            "t = 18, avg_loss = 0.0637\n",
            "t = 20, avg_loss = 0.0194\n",
            "t = 22, avg_loss = 0.0748\n",
            "t = 24, avg_loss = 0.0234\n",
            "Checking accuracy on test set\n",
            "Got 347 / 400 correct (86.75)\n",
            "acc = 0.867500\n",
            "Starting epoch 75 / 100\n",
            "t = 2, avg_loss = 0.0575\n",
            "t = 4, avg_loss = 0.0262\n",
            "t = 6, avg_loss = 0.0314\n",
            "t = 8, avg_loss = 0.0173\n",
            "t = 10, avg_loss = 0.0697\n",
            "t = 12, avg_loss = 0.0382\n",
            "t = 14, avg_loss = 0.0382\n",
            "t = 16, avg_loss = 0.0486\n",
            "t = 18, avg_loss = 0.0678\n",
            "t = 20, avg_loss = 0.0240\n",
            "t = 22, avg_loss = 0.0272\n",
            "t = 24, avg_loss = 0.0477\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 76 / 100\n",
            "t = 2, avg_loss = 0.0854\n",
            "t = 4, avg_loss = 0.0500\n",
            "t = 6, avg_loss = 0.0374\n",
            "t = 8, avg_loss = 0.0555\n",
            "t = 10, avg_loss = 0.0423\n",
            "t = 12, avg_loss = 0.0320\n",
            "t = 14, avg_loss = 0.0276\n",
            "t = 16, avg_loss = 0.0329\n",
            "t = 18, avg_loss = 0.0547\n",
            "t = 20, avg_loss = 0.0384\n",
            "t = 22, avg_loss = 0.0499\n",
            "t = 24, avg_loss = 0.0204\n",
            "Checking accuracy on test set\n",
            "Got 345 / 400 correct (86.25)\n",
            "acc = 0.862500\n",
            "Starting epoch 77 / 100\n",
            "t = 2, avg_loss = 0.0210\n",
            "t = 4, avg_loss = 0.0318\n",
            "t = 6, avg_loss = 0.0272\n",
            "t = 8, avg_loss = 0.0407\n",
            "t = 10, avg_loss = 0.0667\n",
            "t = 12, avg_loss = 0.0348\n",
            "t = 14, avg_loss = 0.0311\n",
            "t = 16, avg_loss = 0.0144\n",
            "t = 18, avg_loss = 0.0223\n",
            "t = 20, avg_loss = 0.0108\n",
            "t = 22, avg_loss = 0.0303\n",
            "t = 24, avg_loss = 0.0231\n",
            "Checking accuracy on test set\n",
            "Got 342 / 400 correct (85.50)\n",
            "acc = 0.855000\n",
            "Starting epoch 78 / 100\n",
            "t = 2, avg_loss = 0.0417\n",
            "t = 4, avg_loss = 0.0692\n",
            "t = 6, avg_loss = 0.0479\n",
            "t = 8, avg_loss = 0.0636\n",
            "t = 10, avg_loss = 0.0442\n",
            "t = 12, avg_loss = 0.0282\n",
            "t = 14, avg_loss = 0.0315\n",
            "t = 16, avg_loss = 0.0457\n",
            "t = 18, avg_loss = 0.0472\n",
            "t = 20, avg_loss = 0.0233\n",
            "t = 22, avg_loss = 0.0313\n",
            "t = 24, avg_loss = 0.0557\n",
            "Checking accuracy on test set\n",
            "Got 345 / 400 correct (86.25)\n",
            "acc = 0.862500\n",
            "Starting epoch 79 / 100\n",
            "t = 2, avg_loss = 0.0426\n",
            "t = 4, avg_loss = 0.0288\n",
            "t = 6, avg_loss = 0.0195\n",
            "t = 8, avg_loss = 0.0286\n",
            "t = 10, avg_loss = 0.0147\n",
            "t = 12, avg_loss = 0.0327\n",
            "t = 14, avg_loss = 0.0546\n",
            "t = 16, avg_loss = 0.0541\n",
            "t = 18, avg_loss = 0.0385\n",
            "t = 20, avg_loss = 0.0468\n",
            "t = 22, avg_loss = 0.0531\n",
            "t = 24, avg_loss = 0.0644\n",
            "Checking accuracy on test set\n",
            "Got 339 / 400 correct (84.75)\n",
            "acc = 0.847500\n",
            "Starting epoch 80 / 100\n",
            "t = 2, avg_loss = 0.0985\n",
            "t = 4, avg_loss = 0.0624\n",
            "t = 6, avg_loss = 0.0166\n",
            "t = 8, avg_loss = 0.0278\n",
            "t = 10, avg_loss = 0.0218\n",
            "t = 12, avg_loss = 0.0285\n",
            "t = 14, avg_loss = 0.0098\n",
            "t = 16, avg_loss = 0.0164\n",
            "t = 18, avg_loss = 0.0334\n",
            "t = 20, avg_loss = 0.0588\n",
            "t = 22, avg_loss = 0.0215\n",
            "t = 24, avg_loss = 0.0451\n",
            "Checking accuracy on test set\n",
            "Got 336 / 400 correct (84.00)\n",
            "acc = 0.840000\n",
            "Starting epoch 81 / 100\n",
            "t = 2, avg_loss = 0.0448\n",
            "t = 4, avg_loss = 0.0499\n",
            "t = 6, avg_loss = 0.0089\n",
            "t = 8, avg_loss = 0.0200\n",
            "t = 10, avg_loss = 0.0157\n",
            "t = 12, avg_loss = 0.0217\n",
            "t = 14, avg_loss = 0.0237\n",
            "t = 16, avg_loss = 0.0168\n",
            "t = 18, avg_loss = 0.0785\n",
            "t = 20, avg_loss = 0.0792\n",
            "t = 22, avg_loss = 0.0189\n",
            "t = 24, avg_loss = 0.0277\n",
            "Checking accuracy on test set\n",
            "Got 346 / 400 correct (86.50)\n",
            "acc = 0.865000\n",
            "Starting epoch 82 / 100\n",
            "t = 2, avg_loss = 0.0370\n",
            "t = 4, avg_loss = 0.0257\n",
            "t = 6, avg_loss = 0.0168\n",
            "t = 8, avg_loss = 0.0191\n",
            "t = 10, avg_loss = 0.0333\n",
            "t = 12, avg_loss = 0.0105\n",
            "t = 14, avg_loss = 0.0124\n",
            "t = 16, avg_loss = 0.0539\n",
            "t = 18, avg_loss = 0.0368\n",
            "t = 20, avg_loss = 0.0433\n",
            "t = 22, avg_loss = 0.0064\n",
            "t = 24, avg_loss = 0.0267\n",
            "Checking accuracy on test set\n",
            "Got 344 / 400 correct (86.00)\n",
            "acc = 0.860000\n",
            "Starting epoch 83 / 100\n",
            "t = 2, avg_loss = 0.0366\n",
            "t = 4, avg_loss = 0.0373\n",
            "t = 6, avg_loss = 0.0531\n",
            "t = 8, avg_loss = 0.0072\n",
            "t = 10, avg_loss = 0.0165\n",
            "t = 12, avg_loss = 0.0237\n",
            "t = 14, avg_loss = 0.0077\n",
            "t = 16, avg_loss = 0.0257\n",
            "t = 18, avg_loss = 0.0413\n",
            "t = 20, avg_loss = 0.0519\n",
            "t = 22, avg_loss = 0.0239\n",
            "t = 24, avg_loss = 0.0408\n",
            "Checking accuracy on test set\n",
            "Got 344 / 400 correct (86.00)\n",
            "acc = 0.860000\n",
            "Starting epoch 84 / 100\n",
            "t = 2, avg_loss = 0.0522\n",
            "t = 4, avg_loss = 0.0397\n",
            "t = 6, avg_loss = 0.0487\n",
            "t = 8, avg_loss = 0.0290\n",
            "t = 10, avg_loss = 0.0208\n",
            "t = 12, avg_loss = 0.0301\n",
            "t = 14, avg_loss = 0.0144\n",
            "t = 16, avg_loss = 0.0255\n",
            "t = 18, avg_loss = 0.0810\n",
            "t = 20, avg_loss = 0.0397\n",
            "t = 22, avg_loss = 0.0456\n",
            "t = 24, avg_loss = 0.0336\n",
            "Checking accuracy on test set\n",
            "Got 345 / 400 correct (86.25)\n",
            "acc = 0.862500\n",
            "Starting epoch 85 / 100\n",
            "t = 2, avg_loss = 0.0175\n",
            "t = 4, avg_loss = 0.0195\n",
            "t = 6, avg_loss = 0.0162\n",
            "t = 8, avg_loss = 0.0218\n",
            "t = 10, avg_loss = 0.0193\n",
            "t = 12, avg_loss = 0.0171\n",
            "t = 14, avg_loss = 0.0460\n",
            "t = 16, avg_loss = 0.0275\n",
            "t = 18, avg_loss = 0.0087\n",
            "t = 20, avg_loss = 0.0396\n",
            "t = 22, avg_loss = 0.0280\n",
            "t = 24, avg_loss = 0.0242\n",
            "Checking accuracy on test set\n",
            "Got 351 / 400 correct (87.75)\n",
            "acc = 0.877500\n",
            "Starting epoch 86 / 100\n",
            "t = 2, avg_loss = 0.0179\n",
            "t = 4, avg_loss = 0.0094\n",
            "t = 6, avg_loss = 0.0247\n",
            "t = 8, avg_loss = 0.0250\n",
            "t = 10, avg_loss = 0.0268\n",
            "t = 12, avg_loss = 0.0211\n",
            "t = 14, avg_loss = 0.0352\n",
            "t = 16, avg_loss = 0.0178\n",
            "t = 18, avg_loss = 0.0990\n",
            "t = 20, avg_loss = 0.0286\n",
            "t = 22, avg_loss = 0.0440\n",
            "t = 24, avg_loss = 0.0270\n",
            "Checking accuracy on test set\n",
            "Got 346 / 400 correct (86.50)\n",
            "acc = 0.865000\n",
            "Starting epoch 87 / 100\n",
            "t = 2, avg_loss = 0.0249\n",
            "t = 4, avg_loss = 0.0292\n",
            "t = 6, avg_loss = 0.0261\n",
            "t = 8, avg_loss = 0.0305\n",
            "t = 10, avg_loss = 0.0748\n",
            "t = 12, avg_loss = 0.0157\n",
            "t = 14, avg_loss = 0.0176\n",
            "t = 16, avg_loss = 0.0163\n",
            "t = 18, avg_loss = 0.0463\n",
            "t = 20, avg_loss = 0.0310\n",
            "t = 22, avg_loss = 0.0483\n",
            "t = 24, avg_loss = 0.0094\n",
            "Checking accuracy on test set\n",
            "Got 344 / 400 correct (86.00)\n",
            "acc = 0.860000\n",
            "Starting epoch 88 / 100\n",
            "t = 2, avg_loss = 0.0236\n",
            "t = 4, avg_loss = 0.0194\n",
            "t = 6, avg_loss = 0.0297\n",
            "t = 8, avg_loss = 0.0297\n",
            "t = 10, avg_loss = 0.0235\n",
            "t = 12, avg_loss = 0.0308\n",
            "t = 14, avg_loss = 0.0208\n",
            "t = 16, avg_loss = 0.0223\n",
            "t = 18, avg_loss = 0.0166\n",
            "t = 20, avg_loss = 0.0405\n",
            "t = 22, avg_loss = 0.0197\n",
            "t = 24, avg_loss = 0.0251\n",
            "Checking accuracy on test set\n",
            "Got 345 / 400 correct (86.25)\n",
            "acc = 0.862500\n",
            "Starting epoch 89 / 100\n",
            "t = 2, avg_loss = 0.0694\n",
            "t = 4, avg_loss = 0.0139\n",
            "t = 6, avg_loss = 0.0124\n",
            "t = 8, avg_loss = 0.0243\n",
            "t = 10, avg_loss = 0.0163\n",
            "t = 12, avg_loss = 0.0175\n",
            "t = 14, avg_loss = 0.0247\n",
            "t = 16, avg_loss = 0.0242\n",
            "t = 18, avg_loss = 0.0077\n",
            "t = 20, avg_loss = 0.0037\n",
            "t = 22, avg_loss = 0.0226\n",
            "t = 24, avg_loss = 0.0312\n",
            "Checking accuracy on test set\n",
            "Got 349 / 400 correct (87.25)\n",
            "acc = 0.872500\n",
            "Starting epoch 90 / 100\n",
            "t = 2, avg_loss = 0.0728\n",
            "t = 4, avg_loss = 0.0158\n",
            "t = 6, avg_loss = 0.0102\n",
            "t = 8, avg_loss = 0.0221\n",
            "t = 10, avg_loss = 0.0186\n",
            "t = 12, avg_loss = 0.0390\n",
            "t = 14, avg_loss = 0.0245\n",
            "t = 16, avg_loss = 0.0193\n",
            "t = 18, avg_loss = 0.0152\n",
            "t = 20, avg_loss = 0.0184\n",
            "t = 22, avg_loss = 0.0531\n",
            "t = 24, avg_loss = 0.0257\n",
            "Checking accuracy on test set\n",
            "Got 351 / 400 correct (87.75)\n",
            "acc = 0.877500\n",
            "Starting epoch 91 / 100\n",
            "t = 2, avg_loss = 0.0512\n",
            "t = 4, avg_loss = 0.0230\n",
            "t = 6, avg_loss = 0.0287\n",
            "t = 8, avg_loss = 0.0130\n",
            "t = 10, avg_loss = 0.0219\n",
            "t = 12, avg_loss = 0.0220\n",
            "t = 14, avg_loss = 0.0089\n",
            "t = 16, avg_loss = 0.0395\n",
            "t = 18, avg_loss = 0.0210\n",
            "t = 20, avg_loss = 0.0361\n",
            "t = 22, avg_loss = 0.0221\n",
            "t = 24, avg_loss = 0.0209\n",
            "Checking accuracy on test set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 92 / 100\n",
            "t = 2, avg_loss = 0.0229\n",
            "t = 4, avg_loss = 0.0193\n",
            "t = 6, avg_loss = 0.0080\n",
            "t = 8, avg_loss = 0.0192\n",
            "t = 10, avg_loss = 0.0318\n",
            "t = 12, avg_loss = 0.0066\n",
            "t = 14, avg_loss = 0.0177\n",
            "t = 16, avg_loss = 0.0240\n",
            "t = 18, avg_loss = 0.0101\n",
            "t = 20, avg_loss = 0.0157\n",
            "t = 22, avg_loss = 0.0133\n",
            "t = 24, avg_loss = 0.0257\n",
            "Checking accuracy on test set\n",
            "Got 350 / 400 correct (87.50)\n",
            "acc = 0.875000\n",
            "Starting epoch 93 / 100\n",
            "t = 2, avg_loss = 0.0190\n",
            "t = 4, avg_loss = 0.0082\n",
            "t = 6, avg_loss = 0.0189\n",
            "t = 8, avg_loss = 0.0356\n",
            "t = 10, avg_loss = 0.0457\n",
            "t = 12, avg_loss = 0.0127\n",
            "t = 14, avg_loss = 0.0209\n",
            "t = 16, avg_loss = 0.0084\n",
            "t = 18, avg_loss = 0.0158\n",
            "t = 20, avg_loss = 0.0636\n",
            "t = 22, avg_loss = 0.0263\n",
            "t = 24, avg_loss = 0.0107\n",
            "Checking accuracy on test set\n",
            "Got 345 / 400 correct (86.25)\n",
            "acc = 0.862500\n",
            "Starting epoch 94 / 100\n",
            "t = 2, avg_loss = 0.0219\n",
            "t = 4, avg_loss = 0.0599\n",
            "t = 6, avg_loss = 0.0132\n",
            "t = 8, avg_loss = 0.0028\n",
            "t = 10, avg_loss = 0.0067\n",
            "t = 12, avg_loss = 0.0660\n",
            "t = 14, avg_loss = 0.0097\n",
            "t = 16, avg_loss = 0.0343\n",
            "t = 18, avg_loss = 0.0132\n",
            "t = 20, avg_loss = 0.0457\n",
            "t = 22, avg_loss = 0.0165\n",
            "t = 24, avg_loss = 0.0466\n",
            "Checking accuracy on test set\n",
            "Got 346 / 400 correct (86.50)\n",
            "acc = 0.865000\n",
            "Starting epoch 95 / 100\n",
            "t = 2, avg_loss = 0.0561\n",
            "t = 4, avg_loss = 0.0294\n",
            "t = 6, avg_loss = 0.0317\n",
            "t = 8, avg_loss = 0.0279\n",
            "t = 10, avg_loss = 0.0907\n",
            "t = 12, avg_loss = 0.0220\n",
            "t = 14, avg_loss = 0.0374\n",
            "t = 16, avg_loss = 0.0306\n",
            "t = 18, avg_loss = 0.0106\n",
            "t = 20, avg_loss = 0.0068\n",
            "t = 22, avg_loss = 0.0092\n",
            "t = 24, avg_loss = 0.0335\n",
            "Checking accuracy on test set\n",
            "Got 345 / 400 correct (86.25)\n",
            "acc = 0.862500\n",
            "Starting epoch 96 / 100\n",
            "t = 2, avg_loss = 0.0485\n",
            "t = 4, avg_loss = 0.0186\n",
            "t = 6, avg_loss = 0.0595\n",
            "t = 8, avg_loss = 0.0181\n",
            "t = 10, avg_loss = 0.0154\n",
            "t = 12, avg_loss = 0.0183\n",
            "t = 14, avg_loss = 0.0985\n",
            "t = 16, avg_loss = 0.0209\n",
            "t = 18, avg_loss = 0.0302\n",
            "t = 20, avg_loss = 0.0098\n",
            "t = 22, avg_loss = 0.0291\n",
            "t = 24, avg_loss = 0.0524\n",
            "Checking accuracy on test set\n",
            "Got 344 / 400 correct (86.00)\n",
            "acc = 0.860000\n",
            "Starting epoch 97 / 100\n",
            "t = 2, avg_loss = 0.0388\n",
            "t = 4, avg_loss = 0.0490\n",
            "t = 6, avg_loss = 0.0168\n",
            "t = 8, avg_loss = 0.0222\n",
            "t = 10, avg_loss = 0.0340\n",
            "t = 12, avg_loss = 0.0280\n",
            "t = 14, avg_loss = 0.0351\n",
            "t = 16, avg_loss = 0.0217\n",
            "t = 18, avg_loss = 0.0124\n",
            "t = 20, avg_loss = 0.0549\n",
            "t = 22, avg_loss = 0.0276\n",
            "t = 24, avg_loss = 0.0049\n",
            "Checking accuracy on test set\n",
            "Got 348 / 400 correct (87.00)\n",
            "acc = 0.870000\n",
            "Starting epoch 98 / 100\n",
            "t = 2, avg_loss = 0.0254\n",
            "t = 4, avg_loss = 0.0333\n",
            "t = 6, avg_loss = 0.0193\n",
            "t = 8, avg_loss = 0.0260\n",
            "t = 10, avg_loss = 0.0189\n",
            "t = 12, avg_loss = 0.0219\n",
            "t = 14, avg_loss = 0.0095\n",
            "t = 16, avg_loss = 0.0787\n",
            "t = 18, avg_loss = 0.0118\n",
            "t = 20, avg_loss = 0.0337\n",
            "t = 22, avg_loss = 0.0119\n",
            "t = 24, avg_loss = 0.0220\n",
            "Checking accuracy on test set\n",
            "Got 343 / 400 correct (85.75)\n",
            "acc = 0.857500\n",
            "Starting epoch 99 / 100\n",
            "t = 2, avg_loss = 0.0493\n",
            "t = 4, avg_loss = 0.0318\n",
            "t = 6, avg_loss = 0.0108\n",
            "t = 8, avg_loss = 0.0119\n",
            "t = 10, avg_loss = 0.0166\n",
            "t = 12, avg_loss = 0.0152\n",
            "t = 14, avg_loss = 0.0042\n",
            "t = 16, avg_loss = 0.0461\n",
            "t = 18, avg_loss = 0.0131\n",
            "t = 20, avg_loss = 0.0094\n",
            "t = 22, avg_loss = 0.0398\n",
            "t = 24, avg_loss = 0.0187\n",
            "Checking accuracy on test set\n",
            "Got 341 / 400 correct (85.25)\n",
            "acc = 0.852500\n",
            "Starting epoch 100 / 100\n",
            "t = 2, avg_loss = 0.0457\n",
            "t = 4, avg_loss = 0.0081\n",
            "t = 6, avg_loss = 0.0514\n",
            "t = 8, avg_loss = 0.0170\n",
            "t = 10, avg_loss = 0.0228\n",
            "t = 12, avg_loss = 0.0234\n",
            "t = 14, avg_loss = 0.0074\n",
            "t = 16, avg_loss = 0.0249\n",
            "t = 18, avg_loss = 0.0118\n",
            "t = 20, avg_loss = 0.0385\n",
            "t = 22, avg_loss = 0.0192\n",
            "t = 24, avg_loss = 0.0081\n",
            "Checking accuracy on test set\n",
            "Got 344 / 400 correct (86.00)\n",
            "acc = 0.860000\n",
            "Checking accuracy on test set\n",
            "Got 345 / 400 correct (86.25)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8625"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvoCj5uscUsz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_accurancy(acc_list):\n",
        "  plt.plot([i+1 for i in range((len(acc_list)))],acc_list)\n",
        "  print(\"Accurancy:\")\n",
        "  plt.show()\n",
        "\n",
        "def plot_loss_function(avg_loss_list):\n",
        "  plt.plot([print_every*batch_size*(i+1) for i in range((len(avg_loss_list)))],avg_loss_list)\n",
        "  print(\"Loss:\")\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WwgxQDJ-SWu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "outputId": "a4bb78d1-d7c6-4489-be91-2e6583e851e5"
      },
      "source": [
        "plot_accurancy(acc_list)\n",
        "plot_loss_function(avg_loss_list)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accurancy:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzuX5gLEeJfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def retry_from_backup():\n",
        "  model_gpu = model_base.type(gpu_dtype)\n",
        "  print(model_gpu)\n",
        "  loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model_gpu.parameters(), lr = learning_rate, weight_decay=weight_decay) \n",
        "\n",
        "\n",
        "\n",
        "  checkpoint = torch.load(model_backup_path)\n",
        "  model_gpu.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  epoch = checkpoint['epoch']\n",
        "  loss = checkpoint['loss']\n",
        "  acc_list = checkpoint['acc_list']\n",
        "  #avg_loss_list = checkpoint['avg_loss_list']\n",
        "  print(\"starting from epoch: \" + str(epoch))\n",
        "  print(\"starting from loss: \" + str(loss))\n",
        "  print(acc_list)\n",
        "  \n",
        "  \n",
        "  train(model_gpu, train_loader ,loss_fn, optimizer, num_epochs=88, starting_from_epoch=epoch)\n",
        "  check_accuracy(model_gpu, valid_loader)\n",
        "\n",
        "  plot_accurancy(acc_list)\n",
        "  plot_loss_function(avg_loss_list)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--rQZKqOalaJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#retry_from_backup()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}