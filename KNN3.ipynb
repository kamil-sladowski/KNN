{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNKmid29/NiP9eqMtN55HXL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamilo116/KNN/blob/master/KNN3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7ReM7FU-xs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import sys\n",
        "from random import shuffle\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "import timeit\n",
        "\n",
        "np.random.seed(4) \n",
        "torch.manual_seed(4) \n",
        "torch.cuda.manual_seed(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMOHez_kHZD6",
        "colab_type": "code",
        "outputId": "598fc7b1-02bd-4b6c-d0a1-32720341db2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYIMZ8QyYewD",
        "colab_type": "code",
        "outputId": "060cfc20-007f-41cf-bf09-bf41d0710a92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "! git clone https://github.com/wang-chen/kervolution.git \n",
        "\n",
        "sys.path.append(\"kervolution/\")\n",
        "from kervolution import Kerv2d\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'kervolution' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b8P1NdXfVdX",
        "colab_type": "code",
        "outputId": "c3483493-2a64-47e5-ee86-ec5ff66a1d14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "MALIGNANT_DATASET = '/content/drive/My Drive/Colab_data/malignant/malignant/'\n",
        "BENIGN_DATASET = '/content/drive/My Drive/Colab_data/benign/benign/'\n",
        "DATA_FOLDER = '/content/drive/My Drive/Colab_data/'\n",
        "LIMIT_IMAGES_NUM = 700\n",
        "\n",
        "benign_file_list = sorted(os.listdir(BENIGN_DATASET))[:LIMIT_IMAGES_NUM]\n",
        "malignant_file_list = sorted(os.listdir(MALIGNANT_DATASET))[:LIMIT_IMAGES_NUM]\n",
        "shuffle(benign_file_list)\n",
        "shuffle(malignant_file_list)\n",
        "\n",
        "print(f\"Number of benign {len(benign_file_list)} images\")\n",
        "print(f\"Number of malignant {len(malignant_file_list)} images\")\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize((100, 100)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of benign 700 images\n",
            "Number of malignant 700 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGDQfal74BLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "benign_dict = {filename: 0 for filename in benign_file_list}\n",
        "malignant_dict = {filename: 1 for filename in malignant_file_list}\n",
        "img_class_dict = {**benign_dict , **malignant_dict}\n",
        "labeled_data = pd.Series(img_class_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvAAOqmVfVll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IsicDataset(Dataset):\n",
        "    def __init__(self, data_folder, labeled_data, \n",
        "                 transform=transforms.Compose([transforms.ToTensor()])):\n",
        "        self.labeled_data = labeled_data\n",
        "        self.transform = transform\n",
        "        self.data_folder = data_folder\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labeled_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        label = self.labeled_data[index]\n",
        "        if label == 0:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"benign\", \"benign\", index ))\n",
        "        else:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"malignant\", \"malignant\", index ))\n",
        "        image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "    @property\n",
        "    def labels(self):\n",
        "      return self.labeled_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSuYqjLAYrWA",
        "colab_type": "code",
        "outputId": "6766527c-09a8-462f-a4e8-091904a336e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        " \n",
        "dataset = IsicDataset(DATA_FOLDER, labeled_data, transform=data_transforms)\n",
        "print(dataset.labels)\n",
        "\n",
        "X_train, X_test = train_test_split(dataset.labels, test_size=0.2)\n",
        "print(\"number of training data: \",len(X_train))\n",
        "print(\"number of testing  data: \",len(X_test))\n",
        "\n",
        "train_sampler = SubsetRandomSampler(list(X_train.index))\n",
        "valid_sampler = SubsetRandomSampler(list(X_test.index))\n",
        "batch_size = 32\n",
        "num_workers = 0\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
        "\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ISIC_0000064.jpeg    0\n",
            "ISIC_0000051.jpeg    0\n",
            "ISIC_0000849.jpeg    0\n",
            "ISIC_0000644.jpeg    0\n",
            "ISIC_0000319.jpeg    0\n",
            "                    ..\n",
            "ISIC_0010990.jpeg    1\n",
            "ISIC_0010355.jpeg    1\n",
            "ISIC_0010385.jpeg    1\n",
            "ISIC_0010388.jpeg    1\n",
            "ISIC_0000175.jpeg    1\n",
            "Length: 1400, dtype: int64\n",
            "number of training data:  1120\n",
            "number of testing  data:  280\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e8nFBR6Yug5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "def train(model, train_loader ,loss_fn, optimizer, num_epochs = 1):\n",
        "    total_loss =0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
        "        model.train()\n",
        "\n",
        "        for t, (x, y) in enumerate(train_loader):\n",
        "            x_var = Variable(x.type(gpu_dtype))\n",
        "            y_var = Variable(y.type(gpu_dtype).long())\n",
        "            scores = model(x_var)\n",
        "            loss = loss_fn(scores, y_var)\n",
        "            total_loss += loss.data\n",
        "            \n",
        "            if (t + 1) % print_every == 0:\n",
        "                avg_loss = total_loss/print_every\n",
        "                print('t = %d, avg_loss = %.4f' % (t + 1, avg_loss) )\n",
        "                avg_loss_list.append(avg_loss)\n",
        "                total_loss = 0\n",
        "                \n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        acc = check_accuracy(fixed_model_gpu, valid_loader)\n",
        "        print('acc = %f' %(acc))\n",
        "            \n",
        "def check_accuracy(model, loader):\n",
        "    print('Checking accuracy on test set')   \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval() \n",
        "    for x, y in loader:\n",
        "        x_var = Variable(x.type(gpu_dtype))\n",
        "\n",
        "        scores = model(x_var)\n",
        "        _, preds = scores.data.cpu().max(1)\n",
        "        num_correct += (preds == y).sum()\n",
        "        num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    acc_list.append(acc)\n",
        "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "    return acc\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggvpMu36Yw2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.size()\n",
        "        return x.view(N, -1)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgmexhBRZAK6",
        "colab_type": "code",
        "outputId": "249baea7-d68e-4cee-b346-80876ab0ec04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print_every = 1\n",
        "gpu_dtype = torch.cuda.FloatTensor\n",
        "\n",
        "out_1 = 64\n",
        "out_2 = 48\n",
        "out_3 = 32\n",
        "out_4 = 24\n",
        "out_5 = 16\n",
        "\n",
        "k_size_1 = 3\n",
        "padding_1 = 1\n",
        "in_channels = 3\n",
        "\n",
        "num_epochs = 50\n",
        "\n",
        "'''\n",
        "Kerv2d\n",
        "kervolution with following options:\n",
        "kernel_type: [linear, polynomial, gaussian, etc.]\n",
        "default is convolution:\n",
        "          kernel_type --> linear,\n",
        "balance, power, gamma is valid only when the kernel_type is specified\n",
        "if learnable_kernel = True,  they just be the initial value of learable parameters\n",
        "if learnable_kernel = False, they are the value of kernel_type's parameter\n",
        "the parameter [power] cannot be learned due to integer limitation\n",
        "balance: 0, 1\n",
        "power: 3, 4, 5\n",
        "gamma:\n",
        "'''\n",
        "fixed_model_base = nn.Sequential( \n",
        "                nn.Kerv2d(in_channels, out_1, padding= padding_1, kernel_size=k_size_1, \n",
        "                          stride=1, kernel_type='gaussian', learnable_kernel=True,\n",
        "                          kernel_regularizer=True, balance=1, power=3, gamma=1), \n",
        "                nn.BatchNorm2d(out_1),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Dropout(0.5),\n",
        "\n",
        "                nn.Conv2d(out_1 , out_2, padding= padding_1, kernel_size=k_size_1, stride=1), \n",
        "                nn.BatchNorm2d(out_2),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_2 , out_3, padding= padding_1, kernel_size=k_size_1, stride=1),  \n",
        "                nn.BatchNorm2d(out_3),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_3 , out_4, padding= padding_1, kernel_size=k_size_1, stride=1), \n",
        "                nn.BatchNorm2d(out_4),\n",
        "                nn.Conv2d(out_4 , out_5, padding= padding_1, kernel_size=k_size_1, stride=1), \n",
        "                nn.BatchNorm2d(out_5),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Dropout(0.6),\n",
        "                Flatten(),\n",
        "                nn.Linear(576,32),\n",
        "                nn.Linear(32,10),\n",
        "                nn.Linear(10,2)\n",
        "            )\n",
        "fixed_model_gpu = fixed_model_base.type(gpu_dtype)\n",
        "print(fixed_model_gpu)\n",
        "loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(fixed_model_gpu.parameters(), lr = 0.0014, weight_decay=0.01) \n",
        "\n",
        "train(fixed_model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs)\n",
        "check_accuracy(fixed_model_gpu, valid_loader)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Kerv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (3): Dropout(p=0.5, inplace=False)\n",
            "  (4): Conv2d(64, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (5): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (6): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (7): Conv2d(48, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (10): Conv2d(32, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (11): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (12): Conv2d(24, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (14): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (15): Dropout(p=0.6, inplace=False)\n",
            "  (16): Flatten()\n",
            "  (17): Linear(in_features=576, out_features=32, bias=True)\n",
            "  (18): Linear(in_features=32, out_features=10, bias=True)\n",
            "  (19): Linear(in_features=10, out_features=2, bias=True)\n",
            ")\n",
            "Starting epoch 1 / 50\n",
            "t = 1, avg_loss = 0.7745\n",
            "t = 2, avg_loss = 0.6378\n",
            "t = 3, avg_loss = 0.7296\n",
            "t = 4, avg_loss = 0.7572\n",
            "t = 5, avg_loss = 0.7043\n",
            "t = 6, avg_loss = 0.7807\n",
            "t = 7, avg_loss = 0.6358\n",
            "t = 8, avg_loss = 0.6767\n",
            "t = 9, avg_loss = 0.7145\n",
            "t = 10, avg_loss = 0.6652\n",
            "t = 11, avg_loss = 0.6029\n",
            "t = 12, avg_loss = 0.6190\n",
            "t = 13, avg_loss = 0.7170\n",
            "t = 14, avg_loss = 0.5730\n",
            "t = 15, avg_loss = 0.8185\n",
            "t = 16, avg_loss = 0.6527\n",
            "t = 17, avg_loss = 0.6449\n",
            "t = 18, avg_loss = 0.6902\n",
            "t = 19, avg_loss = 0.7023\n",
            "t = 20, avg_loss = 0.7633\n",
            "t = 21, avg_loss = 0.6947\n",
            "t = 22, avg_loss = 0.7712\n",
            "t = 23, avg_loss = 0.6475\n",
            "t = 24, avg_loss = 0.6326\n",
            "t = 25, avg_loss = 0.7348\n",
            "t = 26, avg_loss = 0.6806\n",
            "t = 27, avg_loss = 0.6889\n",
            "t = 28, avg_loss = 0.7033\n",
            "t = 29, avg_loss = 0.8778\n",
            "t = 30, avg_loss = 0.7593\n",
            "t = 31, avg_loss = 0.6552\n",
            "t = 32, avg_loss = 0.6948\n",
            "t = 33, avg_loss = 0.6639\n",
            "t = 34, avg_loss = 0.6358\n",
            "t = 35, avg_loss = 0.6700\n",
            "Checking accuracy on test set\n",
            "Got 177 / 280 correct (63.21)\n",
            "acc = 0.632143\n",
            "Starting epoch 2 / 50\n",
            "t = 1, avg_loss = 0.7035\n",
            "t = 2, avg_loss = 0.7084\n",
            "t = 3, avg_loss = 0.7623\n",
            "t = 4, avg_loss = 0.5910\n",
            "t = 5, avg_loss = 0.6298\n",
            "t = 6, avg_loss = 0.7844\n",
            "t = 7, avg_loss = 0.6190\n",
            "t = 8, avg_loss = 0.6175\n",
            "t = 9, avg_loss = 0.7191\n",
            "t = 10, avg_loss = 0.7035\n",
            "t = 11, avg_loss = 0.6093\n",
            "t = 12, avg_loss = 0.6260\n",
            "t = 13, avg_loss = 0.7221\n",
            "t = 14, avg_loss = 0.7447\n",
            "t = 15, avg_loss = 0.6856\n",
            "t = 16, avg_loss = 0.7147\n",
            "t = 17, avg_loss = 0.6403\n",
            "t = 18, avg_loss = 0.6378\n",
            "t = 19, avg_loss = 0.7150\n",
            "t = 20, avg_loss = 0.6087\n",
            "t = 21, avg_loss = 0.6960\n",
            "t = 22, avg_loss = 0.6577\n",
            "t = 23, avg_loss = 0.7223\n",
            "t = 24, avg_loss = 0.7580\n",
            "t = 25, avg_loss = 0.6219\n",
            "t = 26, avg_loss = 0.7028\n",
            "t = 27, avg_loss = 0.6486\n",
            "t = 28, avg_loss = 0.7532\n",
            "t = 29, avg_loss = 0.6027\n",
            "t = 30, avg_loss = 0.7180\n",
            "t = 31, avg_loss = 0.7231\n",
            "t = 32, avg_loss = 0.6488\n",
            "t = 33, avg_loss = 0.6857\n",
            "t = 34, avg_loss = 0.6611\n",
            "t = 35, avg_loss = 0.6392\n",
            "Checking accuracy on test set\n",
            "Got 185 / 280 correct (66.07)\n",
            "acc = 0.660714\n",
            "Starting epoch 3 / 50\n",
            "t = 1, avg_loss = 0.6076\n",
            "t = 2, avg_loss = 0.5948\n",
            "t = 3, avg_loss = 0.6313\n",
            "t = 4, avg_loss = 0.6461\n",
            "t = 5, avg_loss = 0.7010\n",
            "t = 6, avg_loss = 0.6877\n",
            "t = 7, avg_loss = 0.7061\n",
            "t = 8, avg_loss = 0.5968\n",
            "t = 9, avg_loss = 0.7786\n",
            "t = 10, avg_loss = 0.7275\n",
            "t = 11, avg_loss = 0.6281\n",
            "t = 12, avg_loss = 0.6227\n",
            "t = 13, avg_loss = 0.6270\n",
            "t = 14, avg_loss = 0.6128\n",
            "t = 15, avg_loss = 0.7628\n",
            "t = 16, avg_loss = 0.6503\n",
            "t = 17, avg_loss = 0.6957\n",
            "t = 18, avg_loss = 0.6469\n",
            "t = 19, avg_loss = 0.6289\n",
            "t = 20, avg_loss = 0.6493\n",
            "t = 21, avg_loss = 0.6648\n",
            "t = 22, avg_loss = 0.6320\n",
            "t = 23, avg_loss = 0.6154\n",
            "t = 24, avg_loss = 0.5755\n",
            "t = 25, avg_loss = 0.8234\n",
            "t = 26, avg_loss = 0.6296\n",
            "t = 27, avg_loss = 0.6033\n",
            "t = 28, avg_loss = 0.5623\n",
            "t = 29, avg_loss = 0.6867\n",
            "t = 30, avg_loss = 0.6119\n",
            "t = 31, avg_loss = 0.7987\n",
            "t = 32, avg_loss = 0.6696\n",
            "t = 33, avg_loss = 0.5083\n",
            "t = 34, avg_loss = 0.7883\n",
            "t = 35, avg_loss = 0.7566\n",
            "Checking accuracy on test set\n",
            "Got 189 / 280 correct (67.50)\n",
            "acc = 0.675000\n",
            "Starting epoch 4 / 50\n",
            "t = 1, avg_loss = 0.5942\n",
            "t = 2, avg_loss = 0.6402\n",
            "t = 3, avg_loss = 0.6591\n",
            "t = 4, avg_loss = 0.7519\n",
            "t = 5, avg_loss = 0.6403\n",
            "t = 6, avg_loss = 0.7177\n",
            "t = 7, avg_loss = 0.6086\n",
            "t = 8, avg_loss = 0.6905\n",
            "t = 9, avg_loss = 0.7337\n",
            "t = 10, avg_loss = 0.5561\n",
            "t = 11, avg_loss = 0.5865\n",
            "t = 12, avg_loss = 0.7036\n",
            "t = 13, avg_loss = 0.7051\n",
            "t = 14, avg_loss = 0.7479\n",
            "t = 15, avg_loss = 0.5944\n",
            "t = 16, avg_loss = 0.6827\n",
            "t = 17, avg_loss = 0.7015\n",
            "t = 18, avg_loss = 0.6378\n",
            "t = 19, avg_loss = 0.6182\n",
            "t = 20, avg_loss = 0.6961\n",
            "t = 21, avg_loss = 0.7813\n",
            "t = 22, avg_loss = 0.6794\n",
            "t = 23, avg_loss = 0.6741\n",
            "t = 24, avg_loss = 0.5798\n",
            "t = 25, avg_loss = 0.6109\n",
            "t = 26, avg_loss = 0.6485\n",
            "t = 27, avg_loss = 0.6629\n",
            "t = 28, avg_loss = 0.6750\n",
            "t = 29, avg_loss = 0.7300\n",
            "t = 30, avg_loss = 0.6476\n",
            "t = 31, avg_loss = 0.7504\n",
            "t = 32, avg_loss = 0.7080\n",
            "t = 33, avg_loss = 0.6628\n",
            "t = 34, avg_loss = 0.6390\n",
            "t = 35, avg_loss = 0.6657\n",
            "Checking accuracy on test set\n",
            "Got 188 / 280 correct (67.14)\n",
            "acc = 0.671429\n",
            "Starting epoch 5 / 50\n",
            "t = 1, avg_loss = 0.6100\n",
            "t = 2, avg_loss = 0.6007\n",
            "t = 3, avg_loss = 0.6656\n",
            "t = 4, avg_loss = 0.6011\n",
            "t = 5, avg_loss = 0.6544\n",
            "t = 6, avg_loss = 0.7002\n",
            "t = 7, avg_loss = 0.6473\n",
            "t = 8, avg_loss = 0.6132\n",
            "t = 9, avg_loss = 0.6530\n",
            "t = 10, avg_loss = 0.6494\n",
            "t = 11, avg_loss = 0.6640\n",
            "t = 12, avg_loss = 0.6154\n",
            "t = 13, avg_loss = 0.6076\n",
            "t = 14, avg_loss = 0.6559\n",
            "t = 15, avg_loss = 0.6890\n",
            "t = 16, avg_loss = 0.6521\n",
            "t = 17, avg_loss = 0.6969\n",
            "t = 18, avg_loss = 0.6195\n",
            "t = 19, avg_loss = 0.6204\n",
            "t = 20, avg_loss = 0.6753\n",
            "t = 21, avg_loss = 0.6633\n",
            "t = 22, avg_loss = 0.6844\n",
            "t = 23, avg_loss = 0.5907\n",
            "t = 24, avg_loss = 0.7082\n",
            "t = 25, avg_loss = 0.7575\n",
            "t = 26, avg_loss = 0.5396\n",
            "t = 27, avg_loss = 0.7179\n",
            "t = 28, avg_loss = 0.7675\n",
            "t = 29, avg_loss = 0.6033\n",
            "t = 30, avg_loss = 0.6039\n",
            "t = 31, avg_loss = 0.6188\n",
            "t = 32, avg_loss = 0.5366\n",
            "t = 33, avg_loss = 0.6469\n",
            "t = 34, avg_loss = 0.6510\n",
            "t = 35, avg_loss = 0.6734\n",
            "Checking accuracy on test set\n",
            "Got 138 / 280 correct (49.29)\n",
            "acc = 0.492857\n",
            "Starting epoch 6 / 50\n",
            "t = 1, avg_loss = 0.6464\n",
            "t = 2, avg_loss = 0.7121\n",
            "t = 3, avg_loss = 0.6290\n",
            "t = 4, avg_loss = 0.7084\n",
            "t = 5, avg_loss = 0.6044\n",
            "t = 6, avg_loss = 0.6896\n",
            "t = 7, avg_loss = 0.6042\n",
            "t = 8, avg_loss = 0.5379\n",
            "t = 9, avg_loss = 0.6524\n",
            "t = 10, avg_loss = 0.7395\n",
            "t = 11, avg_loss = 0.7373\n",
            "t = 12, avg_loss = 0.7188\n",
            "t = 13, avg_loss = 0.5903\n",
            "t = 14, avg_loss = 0.6486\n",
            "t = 15, avg_loss = 0.6754\n",
            "t = 16, avg_loss = 0.6623\n",
            "t = 17, avg_loss = 0.6517\n",
            "t = 18, avg_loss = 0.5916\n",
            "t = 19, avg_loss = 0.5576\n",
            "t = 20, avg_loss = 0.6307\n",
            "t = 21, avg_loss = 0.6219\n",
            "t = 22, avg_loss = 0.7422\n",
            "t = 23, avg_loss = 0.6058\n",
            "t = 24, avg_loss = 0.6462\n",
            "t = 25, avg_loss = 0.5514\n",
            "t = 26, avg_loss = 0.7626\n",
            "t = 27, avg_loss = 0.7761\n",
            "t = 28, avg_loss = 0.6438\n",
            "t = 29, avg_loss = 0.6572\n",
            "t = 30, avg_loss = 0.6435\n",
            "t = 31, avg_loss = 0.5862\n",
            "t = 32, avg_loss = 0.7091\n",
            "t = 33, avg_loss = 0.6216\n",
            "t = 34, avg_loss = 0.6629\n",
            "t = 35, avg_loss = 0.7156\n",
            "Checking accuracy on test set\n",
            "Got 146 / 280 correct (52.14)\n",
            "acc = 0.521429\n",
            "Starting epoch 7 / 50\n",
            "t = 1, avg_loss = 0.7099\n",
            "t = 2, avg_loss = 0.7131\n",
            "t = 3, avg_loss = 0.6504\n",
            "t = 4, avg_loss = 0.6275\n",
            "t = 5, avg_loss = 0.5965\n",
            "t = 6, avg_loss = 0.6235\n",
            "t = 7, avg_loss = 0.5844\n",
            "t = 8, avg_loss = 0.6524\n",
            "t = 9, avg_loss = 0.6169\n",
            "t = 10, avg_loss = 0.6692\n",
            "t = 11, avg_loss = 0.6462\n",
            "t = 12, avg_loss = 0.6571\n",
            "t = 13, avg_loss = 0.5787\n",
            "t = 14, avg_loss = 0.6023\n",
            "t = 15, avg_loss = 0.6880\n",
            "t = 16, avg_loss = 0.6367\n",
            "t = 17, avg_loss = 0.6461\n",
            "t = 18, avg_loss = 0.6283\n",
            "t = 19, avg_loss = 0.6557\n",
            "t = 20, avg_loss = 0.6149\n",
            "t = 21, avg_loss = 0.8040\n",
            "t = 22, avg_loss = 0.7590\n",
            "t = 23, avg_loss = 0.5980\n",
            "t = 24, avg_loss = 0.7363\n",
            "t = 25, avg_loss = 0.6768\n",
            "t = 26, avg_loss = 0.6238\n",
            "t = 27, avg_loss = 0.5553\n",
            "t = 28, avg_loss = 0.6372\n",
            "t = 29, avg_loss = 0.6651\n",
            "t = 30, avg_loss = 0.6258\n",
            "t = 31, avg_loss = 0.7173\n",
            "t = 32, avg_loss = 0.6606\n",
            "t = 33, avg_loss = 0.6209\n",
            "t = 34, avg_loss = 0.6966\n",
            "t = 35, avg_loss = 0.7051\n",
            "Checking accuracy on test set\n",
            "Got 190 / 280 correct (67.86)\n",
            "acc = 0.678571\n",
            "Starting epoch 8 / 50\n",
            "t = 1, avg_loss = 0.5860\n",
            "t = 2, avg_loss = 0.6610\n",
            "t = 3, avg_loss = 0.5943\n",
            "t = 4, avg_loss = 0.7117\n",
            "t = 5, avg_loss = 0.6049\n",
            "t = 6, avg_loss = 0.6865\n",
            "t = 7, avg_loss = 0.6679\n",
            "t = 8, avg_loss = 0.6258\n",
            "t = 9, avg_loss = 0.6067\n",
            "t = 10, avg_loss = 0.7337\n",
            "t = 11, avg_loss = 0.6166\n",
            "t = 12, avg_loss = 0.5987\n",
            "t = 13, avg_loss = 0.7470\n",
            "t = 14, avg_loss = 0.6432\n",
            "t = 15, avg_loss = 0.6493\n",
            "t = 16, avg_loss = 0.6282\n",
            "t = 17, avg_loss = 0.5443\n",
            "t = 18, avg_loss = 0.6449\n",
            "t = 19, avg_loss = 0.7298\n",
            "t = 20, avg_loss = 0.6852\n",
            "t = 21, avg_loss = 0.5571\n",
            "t = 22, avg_loss = 0.6266\n",
            "t = 23, avg_loss = 0.7023\n",
            "t = 24, avg_loss = 0.6505\n",
            "t = 25, avg_loss = 0.6669\n",
            "t = 26, avg_loss = 0.6739\n",
            "t = 27, avg_loss = 0.7126\n",
            "t = 28, avg_loss = 0.6656\n",
            "t = 29, avg_loss = 0.6960\n",
            "t = 30, avg_loss = 0.6097\n",
            "t = 31, avg_loss = 0.5658\n",
            "t = 32, avg_loss = 0.6589\n",
            "t = 33, avg_loss = 0.6613\n",
            "t = 34, avg_loss = 0.6306\n",
            "t = 35, avg_loss = 0.5749\n",
            "Checking accuracy on test set\n",
            "Got 184 / 280 correct (65.71)\n",
            "acc = 0.657143\n",
            "Starting epoch 9 / 50\n",
            "t = 1, avg_loss = 0.5616\n",
            "t = 2, avg_loss = 0.5942\n",
            "t = 3, avg_loss = 0.6246\n",
            "t = 4, avg_loss = 0.6795\n",
            "t = 5, avg_loss = 0.6107\n",
            "t = 6, avg_loss = 0.6456\n",
            "t = 7, avg_loss = 0.7655\n",
            "t = 8, avg_loss = 0.6136\n",
            "t = 9, avg_loss = 0.7199\n",
            "t = 10, avg_loss = 0.6992\n",
            "t = 11, avg_loss = 0.6467\n",
            "t = 12, avg_loss = 0.6725\n",
            "t = 13, avg_loss = 0.6246\n",
            "t = 14, avg_loss = 0.6679\n",
            "t = 15, avg_loss = 0.7654\n",
            "t = 16, avg_loss = 0.5295\n",
            "t = 17, avg_loss = 0.6038\n",
            "t = 18, avg_loss = 0.5654\n",
            "t = 19, avg_loss = 0.6158\n",
            "t = 20, avg_loss = 0.6965\n",
            "t = 21, avg_loss = 0.6544\n",
            "t = 22, avg_loss = 0.6705\n",
            "t = 23, avg_loss = 0.6346\n",
            "t = 24, avg_loss = 0.5594\n",
            "t = 25, avg_loss = 0.7429\n",
            "t = 26, avg_loss = 0.5892\n",
            "t = 27, avg_loss = 0.7110\n",
            "t = 28, avg_loss = 0.6870\n",
            "t = 29, avg_loss = 0.6467\n",
            "t = 30, avg_loss = 0.6683\n",
            "t = 31, avg_loss = 0.6381\n",
            "t = 32, avg_loss = 0.6238\n",
            "t = 33, avg_loss = 0.7065\n",
            "t = 34, avg_loss = 0.6820\n",
            "t = 35, avg_loss = 0.6287\n",
            "Checking accuracy on test set\n",
            "Got 165 / 280 correct (58.93)\n",
            "acc = 0.589286\n",
            "Starting epoch 10 / 50\n",
            "t = 1, avg_loss = 0.6585\n",
            "t = 2, avg_loss = 0.7165\n",
            "t = 3, avg_loss = 0.6283\n",
            "t = 4, avg_loss = 0.5662\n",
            "t = 5, avg_loss = 0.6492\n",
            "t = 6, avg_loss = 0.5890\n",
            "t = 7, avg_loss = 0.5724\n",
            "t = 8, avg_loss = 0.6334\n",
            "t = 9, avg_loss = 0.5824\n",
            "t = 10, avg_loss = 0.6198\n",
            "t = 11, avg_loss = 0.6284\n",
            "t = 12, avg_loss = 0.5709\n",
            "t = 13, avg_loss = 0.6112\n",
            "t = 14, avg_loss = 0.6519\n",
            "t = 15, avg_loss = 0.6105\n",
            "t = 16, avg_loss = 0.6702\n",
            "t = 17, avg_loss = 0.6532\n",
            "t = 18, avg_loss = 0.7285\n",
            "t = 19, avg_loss = 0.5862\n",
            "t = 20, avg_loss = 0.7703\n",
            "t = 21, avg_loss = 0.6115\n",
            "t = 22, avg_loss = 0.6438\n",
            "t = 23, avg_loss = 0.6778\n",
            "t = 24, avg_loss = 0.6554\n",
            "t = 25, avg_loss = 0.6244\n",
            "t = 26, avg_loss = 0.6192\n",
            "t = 27, avg_loss = 0.7106\n",
            "t = 28, avg_loss = 0.6017\n",
            "t = 29, avg_loss = 0.5574\n",
            "t = 30, avg_loss = 0.7732\n",
            "t = 31, avg_loss = 0.6943\n",
            "t = 32, avg_loss = 0.6827\n",
            "t = 33, avg_loss = 0.6124\n",
            "t = 34, avg_loss = 0.6950\n",
            "t = 35, avg_loss = 0.6640\n",
            "Checking accuracy on test set\n",
            "Got 171 / 280 correct (61.07)\n",
            "acc = 0.610714\n",
            "Starting epoch 11 / 50\n",
            "t = 1, avg_loss = 0.7180\n",
            "t = 2, avg_loss = 0.6159\n",
            "t = 3, avg_loss = 0.6691\n",
            "t = 4, avg_loss = 0.6571\n",
            "t = 5, avg_loss = 0.6829\n",
            "t = 6, avg_loss = 0.6955\n",
            "t = 7, avg_loss = 0.6048\n",
            "t = 8, avg_loss = 0.5727\n",
            "t = 9, avg_loss = 0.6731\n",
            "t = 10, avg_loss = 0.6257\n",
            "t = 11, avg_loss = 0.5891\n",
            "t = 12, avg_loss = 0.6136\n",
            "t = 13, avg_loss = 0.6409\n",
            "t = 14, avg_loss = 0.6462\n",
            "t = 15, avg_loss = 0.7331\n",
            "t = 16, avg_loss = 0.6439\n",
            "t = 17, avg_loss = 0.7213\n",
            "t = 18, avg_loss = 0.6383\n",
            "t = 19, avg_loss = 0.6265\n",
            "t = 20, avg_loss = 0.6432\n",
            "t = 21, avg_loss = 0.6386\n",
            "t = 22, avg_loss = 0.7153\n",
            "t = 23, avg_loss = 0.6195\n",
            "t = 24, avg_loss = 0.5493\n",
            "t = 25, avg_loss = 0.6746\n",
            "t = 26, avg_loss = 0.6612\n",
            "t = 27, avg_loss = 0.6850\n",
            "t = 28, avg_loss = 0.5990\n",
            "t = 29, avg_loss = 0.5198\n",
            "t = 30, avg_loss = 0.6667\n",
            "t = 31, avg_loss = 0.7068\n",
            "t = 32, avg_loss = 0.7248\n",
            "t = 33, avg_loss = 0.6669\n",
            "t = 34, avg_loss = 0.6404\n",
            "t = 35, avg_loss = 0.6769\n",
            "Checking accuracy on test set\n",
            "Got 176 / 280 correct (62.86)\n",
            "acc = 0.628571\n",
            "Starting epoch 12 / 50\n",
            "t = 1, avg_loss = 0.6494\n",
            "t = 2, avg_loss = 0.6022\n",
            "t = 3, avg_loss = 0.5892\n",
            "t = 4, avg_loss = 0.6374\n",
            "t = 5, avg_loss = 0.5912\n",
            "t = 6, avg_loss = 0.6897\n",
            "t = 7, avg_loss = 0.6792\n",
            "t = 8, avg_loss = 0.6071\n",
            "t = 9, avg_loss = 0.6870\n",
            "t = 10, avg_loss = 0.5724\n",
            "t = 11, avg_loss = 0.5605\n",
            "t = 12, avg_loss = 0.5758\n",
            "t = 13, avg_loss = 0.6618\n",
            "t = 14, avg_loss = 0.6836\n",
            "t = 15, avg_loss = 0.8196\n",
            "t = 16, avg_loss = 0.6202\n",
            "t = 17, avg_loss = 0.5752\n",
            "t = 18, avg_loss = 0.6647\n",
            "t = 19, avg_loss = 0.6507\n",
            "t = 20, avg_loss = 0.6579\n",
            "t = 21, avg_loss = 0.7518\n",
            "t = 22, avg_loss = 0.6426\n",
            "t = 23, avg_loss = 0.5991\n",
            "t = 24, avg_loss = 0.6333\n",
            "t = 25, avg_loss = 0.6383\n",
            "t = 26, avg_loss = 0.6149\n",
            "t = 27, avg_loss = 0.7118\n",
            "t = 28, avg_loss = 0.5942\n",
            "t = 29, avg_loss = 0.6250\n",
            "t = 30, avg_loss = 0.6137\n",
            "t = 31, avg_loss = 0.7060\n",
            "t = 32, avg_loss = 0.5573\n",
            "t = 33, avg_loss = 0.6337\n",
            "t = 34, avg_loss = 0.6258\n",
            "t = 35, avg_loss = 0.6553\n",
            "Checking accuracy on test set\n",
            "Got 160 / 280 correct (57.14)\n",
            "acc = 0.571429\n",
            "Starting epoch 13 / 50\n",
            "t = 1, avg_loss = 0.7224\n",
            "t = 2, avg_loss = 0.6030\n",
            "t = 3, avg_loss = 0.7178\n",
            "t = 4, avg_loss = 0.6351\n",
            "t = 5, avg_loss = 0.6104\n",
            "t = 6, avg_loss = 0.6024\n",
            "t = 7, avg_loss = 0.7166\n",
            "t = 8, avg_loss = 0.5903\n",
            "t = 9, avg_loss = 0.6100\n",
            "t = 10, avg_loss = 0.6054\n",
            "t = 11, avg_loss = 0.6937\n",
            "t = 12, avg_loss = 0.6434\n",
            "t = 13, avg_loss = 0.5930\n",
            "t = 14, avg_loss = 0.6719\n",
            "t = 15, avg_loss = 0.6204\n",
            "t = 16, avg_loss = 0.6786\n",
            "t = 17, avg_loss = 0.7341\n",
            "t = 18, avg_loss = 0.5906\n",
            "t = 19, avg_loss = 0.6503\n",
            "t = 20, avg_loss = 0.7136\n",
            "t = 21, avg_loss = 0.7226\n",
            "t = 22, avg_loss = 0.7091\n",
            "t = 23, avg_loss = 0.6859\n",
            "t = 24, avg_loss = 0.6382\n",
            "t = 25, avg_loss = 0.5878\n",
            "t = 26, avg_loss = 0.5878\n",
            "t = 27, avg_loss = 0.5679\n",
            "t = 28, avg_loss = 0.6523\n",
            "t = 29, avg_loss = 0.6104\n",
            "t = 30, avg_loss = 0.5943\n",
            "t = 31, avg_loss = 0.5657\n",
            "t = 32, avg_loss = 0.5765\n",
            "t = 33, avg_loss = 0.5985\n",
            "t = 34, avg_loss = 0.7043\n",
            "t = 35, avg_loss = 0.5771\n",
            "Checking accuracy on test set\n",
            "Got 184 / 280 correct (65.71)\n",
            "acc = 0.657143\n",
            "Starting epoch 14 / 50\n",
            "t = 1, avg_loss = 0.6536\n",
            "t = 2, avg_loss = 0.5858\n",
            "t = 3, avg_loss = 0.5521\n",
            "t = 4, avg_loss = 0.7882\n",
            "t = 5, avg_loss = 0.5389\n",
            "t = 6, avg_loss = 0.6604\n",
            "t = 7, avg_loss = 0.7943\n",
            "t = 8, avg_loss = 0.6947\n",
            "t = 9, avg_loss = 0.7174\n",
            "t = 10, avg_loss = 0.6286\n",
            "t = 11, avg_loss = 0.6089\n",
            "t = 12, avg_loss = 0.6975\n",
            "t = 13, avg_loss = 0.6497\n",
            "t = 14, avg_loss = 0.5979\n",
            "t = 15, avg_loss = 0.6066\n",
            "t = 16, avg_loss = 0.6239\n",
            "t = 17, avg_loss = 0.7031\n",
            "t = 18, avg_loss = 0.5895\n",
            "t = 19, avg_loss = 0.6714\n",
            "t = 20, avg_loss = 0.6212\n",
            "t = 21, avg_loss = 0.7049\n",
            "t = 22, avg_loss = 0.7211\n",
            "t = 23, avg_loss = 0.6751\n",
            "t = 24, avg_loss = 0.7140\n",
            "t = 25, avg_loss = 0.6272\n",
            "t = 26, avg_loss = 0.6743\n",
            "t = 27, avg_loss = 0.5893\n",
            "t = 28, avg_loss = 0.6159\n",
            "t = 29, avg_loss = 0.6415\n",
            "t = 30, avg_loss = 0.7018\n",
            "t = 31, avg_loss = 0.5763\n",
            "t = 32, avg_loss = 0.6250\n",
            "t = 33, avg_loss = 0.6818\n",
            "t = 34, avg_loss = 0.6707\n",
            "t = 35, avg_loss = 0.6185\n",
            "Checking accuracy on test set\n",
            "Got 176 / 280 correct (62.86)\n",
            "acc = 0.628571\n",
            "Starting epoch 15 / 50\n",
            "t = 1, avg_loss = 0.5985\n",
            "t = 2, avg_loss = 0.6733\n",
            "t = 3, avg_loss = 0.5874\n",
            "t = 4, avg_loss = 0.6698\n",
            "t = 5, avg_loss = 0.6939\n",
            "t = 6, avg_loss = 0.5782\n",
            "t = 7, avg_loss = 0.6048\n",
            "t = 8, avg_loss = 0.6010\n",
            "t = 9, avg_loss = 0.5362\n",
            "t = 10, avg_loss = 0.6542\n",
            "t = 11, avg_loss = 0.6715\n",
            "t = 12, avg_loss = 0.5221\n",
            "t = 13, avg_loss = 0.6502\n",
            "t = 14, avg_loss = 0.6045\n",
            "t = 15, avg_loss = 0.5863\n",
            "t = 16, avg_loss = 0.7863\n",
            "t = 17, avg_loss = 0.5931\n",
            "t = 18, avg_loss = 0.6379\n",
            "t = 19, avg_loss = 0.7029\n",
            "t = 20, avg_loss = 0.7155\n",
            "t = 21, avg_loss = 0.6108\n",
            "t = 22, avg_loss = 0.6160\n",
            "t = 23, avg_loss = 0.6337\n",
            "t = 24, avg_loss = 0.6714\n",
            "t = 25, avg_loss = 0.5780\n",
            "t = 26, avg_loss = 0.6421\n",
            "t = 27, avg_loss = 0.6549\n",
            "t = 28, avg_loss = 0.5636\n",
            "t = 29, avg_loss = 0.7009\n",
            "t = 30, avg_loss = 0.5611\n",
            "t = 31, avg_loss = 0.6080\n",
            "t = 32, avg_loss = 0.6443\n",
            "t = 33, avg_loss = 0.7080\n",
            "t = 34, avg_loss = 0.6779\n",
            "t = 35, avg_loss = 0.5845\n",
            "Checking accuracy on test set\n",
            "Got 175 / 280 correct (62.50)\n",
            "acc = 0.625000\n",
            "Starting epoch 16 / 50\n",
            "t = 1, avg_loss = 0.5716\n",
            "t = 2, avg_loss = 0.6523\n",
            "t = 3, avg_loss = 0.6113\n",
            "t = 4, avg_loss = 0.6473\n",
            "t = 5, avg_loss = 0.5807\n",
            "t = 6, avg_loss = 0.7589\n",
            "t = 7, avg_loss = 0.6901\n",
            "t = 8, avg_loss = 0.6518\n",
            "t = 9, avg_loss = 0.5536\n",
            "t = 10, avg_loss = 0.6043\n",
            "t = 11, avg_loss = 0.6734\n",
            "t = 12, avg_loss = 0.6328\n",
            "t = 13, avg_loss = 0.6584\n",
            "t = 14, avg_loss = 0.6254\n",
            "t = 15, avg_loss = 0.6871\n",
            "t = 16, avg_loss = 0.6776\n",
            "t = 17, avg_loss = 0.6294\n",
            "t = 18, avg_loss = 0.6804\n",
            "t = 19, avg_loss = 0.7183\n",
            "t = 20, avg_loss = 0.6918\n",
            "t = 21, avg_loss = 0.5090\n",
            "t = 22, avg_loss = 0.6824\n",
            "t = 23, avg_loss = 0.6169\n",
            "t = 24, avg_loss = 0.6915\n",
            "t = 25, avg_loss = 0.7122\n",
            "t = 26, avg_loss = 0.5866\n",
            "t = 27, avg_loss = 0.6042\n",
            "t = 28, avg_loss = 0.6241\n",
            "t = 29, avg_loss = 0.6705\n",
            "t = 30, avg_loss = 0.7136\n",
            "t = 31, avg_loss = 0.6574\n",
            "t = 32, avg_loss = 0.6452\n",
            "t = 33, avg_loss = 0.6721\n",
            "t = 34, avg_loss = 0.6239\n",
            "t = 35, avg_loss = 0.6050\n",
            "Checking accuracy on test set\n",
            "Got 159 / 280 correct (56.79)\n",
            "acc = 0.567857\n",
            "Starting epoch 17 / 50\n",
            "t = 1, avg_loss = 0.5981\n",
            "t = 2, avg_loss = 0.6273\n",
            "t = 3, avg_loss = 0.6033\n",
            "t = 4, avg_loss = 0.6056\n",
            "t = 5, avg_loss = 0.6653\n",
            "t = 6, avg_loss = 0.7080\n",
            "t = 7, avg_loss = 0.6347\n",
            "t = 8, avg_loss = 0.7370\n",
            "t = 9, avg_loss = 0.6031\n",
            "t = 10, avg_loss = 0.6870\n",
            "t = 11, avg_loss = 0.5427\n",
            "t = 12, avg_loss = 0.6536\n",
            "t = 13, avg_loss = 0.6449\n",
            "t = 14, avg_loss = 0.6552\n",
            "t = 15, avg_loss = 0.6347\n",
            "t = 16, avg_loss = 0.6786\n",
            "t = 17, avg_loss = 0.6626\n",
            "t = 18, avg_loss = 0.6511\n",
            "t = 19, avg_loss = 0.6100\n",
            "t = 20, avg_loss = 0.6509\n",
            "t = 21, avg_loss = 0.7318\n",
            "t = 22, avg_loss = 0.6482\n",
            "t = 23, avg_loss = 0.5987\n",
            "t = 24, avg_loss = 0.6895\n",
            "t = 25, avg_loss = 0.6788\n",
            "t = 26, avg_loss = 0.5658\n",
            "t = 27, avg_loss = 0.6881\n",
            "t = 28, avg_loss = 0.7097\n",
            "t = 29, avg_loss = 0.6279\n",
            "t = 30, avg_loss = 0.6477\n",
            "t = 31, avg_loss = 0.7617\n",
            "t = 32, avg_loss = 0.5912\n",
            "t = 33, avg_loss = 0.6186\n",
            "t = 34, avg_loss = 0.5399\n",
            "t = 35, avg_loss = 0.6621\n",
            "Checking accuracy on test set\n",
            "Got 177 / 280 correct (63.21)\n",
            "acc = 0.632143\n",
            "Starting epoch 18 / 50\n",
            "t = 1, avg_loss = 0.6120\n",
            "t = 2, avg_loss = 0.6357\n",
            "t = 3, avg_loss = 0.6885\n",
            "t = 4, avg_loss = 0.6404\n",
            "t = 5, avg_loss = 0.6556\n",
            "t = 6, avg_loss = 0.7256\n",
            "t = 7, avg_loss = 0.7142\n",
            "t = 8, avg_loss = 0.6326\n",
            "t = 9, avg_loss = 0.6681\n",
            "t = 10, avg_loss = 0.6444\n",
            "t = 11, avg_loss = 0.6187\n",
            "t = 12, avg_loss = 0.6342\n",
            "t = 13, avg_loss = 0.6087\n",
            "t = 14, avg_loss = 0.6824\n",
            "t = 15, avg_loss = 0.6029\n",
            "t = 16, avg_loss = 0.6929\n",
            "t = 17, avg_loss = 0.6374\n",
            "t = 18, avg_loss = 0.5642\n",
            "t = 19, avg_loss = 0.7250\n",
            "t = 20, avg_loss = 0.6252\n",
            "t = 21, avg_loss = 0.6191\n",
            "t = 22, avg_loss = 0.6507\n",
            "t = 23, avg_loss = 0.6254\n",
            "t = 24, avg_loss = 0.6318\n",
            "t = 25, avg_loss = 0.6568\n",
            "t = 26, avg_loss = 0.6108\n",
            "t = 27, avg_loss = 0.6535\n",
            "t = 28, avg_loss = 0.7061\n",
            "t = 29, avg_loss = 0.5825\n",
            "t = 30, avg_loss = 0.7063\n",
            "t = 31, avg_loss = 0.6651\n",
            "t = 32, avg_loss = 0.6933\n",
            "t = 33, avg_loss = 0.5721\n",
            "t = 34, avg_loss = 0.5810\n",
            "t = 35, avg_loss = 0.6587\n",
            "Checking accuracy on test set\n",
            "Got 178 / 280 correct (63.57)\n",
            "acc = 0.635714\n",
            "Starting epoch 19 / 50\n",
            "t = 1, avg_loss = 0.6574\n",
            "t = 2, avg_loss = 0.5900\n",
            "t = 3, avg_loss = 0.6580\n",
            "t = 4, avg_loss = 0.5236\n",
            "t = 5, avg_loss = 0.6509\n",
            "t = 6, avg_loss = 0.7472\n",
            "t = 7, avg_loss = 0.6520\n",
            "t = 8, avg_loss = 0.5987\n",
            "t = 9, avg_loss = 0.6048\n",
            "t = 10, avg_loss = 0.5765\n",
            "t = 11, avg_loss = 0.7487\n",
            "t = 12, avg_loss = 0.6208\n",
            "t = 13, avg_loss = 0.6506\n",
            "t = 14, avg_loss = 0.6868\n",
            "t = 15, avg_loss = 0.6522\n",
            "t = 16, avg_loss = 0.6916\n",
            "t = 17, avg_loss = 0.6818\n",
            "t = 18, avg_loss = 0.6505\n",
            "t = 19, avg_loss = 0.6224\n",
            "t = 20, avg_loss = 0.7810\n",
            "t = 21, avg_loss = 0.6469\n",
            "t = 22, avg_loss = 0.6514\n",
            "t = 23, avg_loss = 0.5767\n",
            "t = 24, avg_loss = 0.7094\n",
            "t = 25, avg_loss = 0.6139\n",
            "t = 26, avg_loss = 0.6400\n",
            "t = 27, avg_loss = 0.6099\n",
            "t = 28, avg_loss = 0.5901\n",
            "t = 29, avg_loss = 0.6527\n",
            "t = 30, avg_loss = 0.6096\n",
            "t = 31, avg_loss = 0.7388\n",
            "t = 32, avg_loss = 0.6302\n",
            "t = 33, avg_loss = 0.5778\n",
            "t = 34, avg_loss = 0.5724\n",
            "t = 35, avg_loss = 0.6372\n",
            "Checking accuracy on test set\n",
            "Got 182 / 280 correct (65.00)\n",
            "acc = 0.650000\n",
            "Starting epoch 20 / 50\n",
            "t = 1, avg_loss = 0.6656\n",
            "t = 2, avg_loss = 0.6123\n",
            "t = 3, avg_loss = 0.6037\n",
            "t = 4, avg_loss = 0.6379\n",
            "t = 5, avg_loss = 0.6681\n",
            "t = 6, avg_loss = 0.6291\n",
            "t = 7, avg_loss = 0.6589\n",
            "t = 8, avg_loss = 0.6851\n",
            "t = 9, avg_loss = 0.7059\n",
            "t = 10, avg_loss = 0.5901\n",
            "t = 11, avg_loss = 0.6764\n",
            "t = 12, avg_loss = 0.6603\n",
            "t = 13, avg_loss = 0.6643\n",
            "t = 14, avg_loss = 0.6637\n",
            "t = 15, avg_loss = 0.6175\n",
            "t = 16, avg_loss = 0.5470\n",
            "t = 17, avg_loss = 0.6757\n",
            "t = 18, avg_loss = 0.5963\n",
            "t = 19, avg_loss = 0.5929\n",
            "t = 20, avg_loss = 0.6399\n",
            "t = 21, avg_loss = 0.6593\n",
            "t = 22, avg_loss = 0.6190\n",
            "t = 23, avg_loss = 0.6517\n",
            "t = 24, avg_loss = 0.5075\n",
            "t = 25, avg_loss = 0.5444\n",
            "t = 26, avg_loss = 0.5265\n",
            "t = 27, avg_loss = 0.7435\n",
            "t = 28, avg_loss = 0.8069\n",
            "t = 29, avg_loss = 0.6321\n",
            "t = 30, avg_loss = 0.6332\n",
            "t = 31, avg_loss = 0.6159\n",
            "t = 32, avg_loss = 0.6447\n",
            "t = 33, avg_loss = 0.6794\n",
            "t = 34, avg_loss = 0.6948\n",
            "t = 35, avg_loss = 0.6100\n",
            "Checking accuracy on test set\n",
            "Got 160 / 280 correct (57.14)\n",
            "acc = 0.571429\n",
            "Starting epoch 21 / 50\n",
            "t = 1, avg_loss = 0.6569\n",
            "t = 2, avg_loss = 0.6116\n",
            "t = 3, avg_loss = 0.6497\n",
            "t = 4, avg_loss = 0.5629\n",
            "t = 5, avg_loss = 0.6026\n",
            "t = 6, avg_loss = 0.6630\n",
            "t = 7, avg_loss = 0.5597\n",
            "t = 8, avg_loss = 0.6257\n",
            "t = 9, avg_loss = 0.6588\n",
            "t = 10, avg_loss = 0.6655\n",
            "t = 11, avg_loss = 0.5481\n",
            "t = 12, avg_loss = 0.5531\n",
            "t = 13, avg_loss = 0.5341\n",
            "t = 14, avg_loss = 0.7315\n",
            "t = 15, avg_loss = 0.6036\n",
            "t = 16, avg_loss = 0.5378\n",
            "t = 17, avg_loss = 0.6635\n",
            "t = 18, avg_loss = 0.6770\n",
            "t = 19, avg_loss = 0.7130\n",
            "t = 20, avg_loss = 0.6862\n",
            "t = 21, avg_loss = 0.6335\n",
            "t = 22, avg_loss = 0.6598\n",
            "t = 23, avg_loss = 0.6871\n",
            "t = 24, avg_loss = 0.5585\n",
            "t = 25, avg_loss = 0.7353\n",
            "t = 26, avg_loss = 0.6901\n",
            "t = 27, avg_loss = 0.6134\n",
            "t = 28, avg_loss = 0.5958\n",
            "t = 29, avg_loss = 0.7159\n",
            "t = 30, avg_loss = 0.5395\n",
            "t = 31, avg_loss = 0.6137\n",
            "t = 32, avg_loss = 0.6453\n",
            "t = 33, avg_loss = 0.6885\n",
            "t = 34, avg_loss = 0.6689\n",
            "t = 35, avg_loss = 0.6539\n",
            "Checking accuracy on test set\n",
            "Got 175 / 280 correct (62.50)\n",
            "acc = 0.625000\n",
            "Starting epoch 22 / 50\n",
            "t = 1, avg_loss = 0.6721\n",
            "t = 2, avg_loss = 0.5360\n",
            "t = 3, avg_loss = 0.6408\n",
            "t = 4, avg_loss = 0.7083\n",
            "t = 5, avg_loss = 0.6353\n",
            "t = 6, avg_loss = 0.5795\n",
            "t = 7, avg_loss = 0.6256\n",
            "t = 8, avg_loss = 0.5837\n",
            "t = 9, avg_loss = 0.6903\n",
            "t = 10, avg_loss = 0.6058\n",
            "t = 11, avg_loss = 0.5781\n",
            "t = 12, avg_loss = 0.7145\n",
            "t = 13, avg_loss = 0.5716\n",
            "t = 14, avg_loss = 0.5846\n",
            "t = 15, avg_loss = 0.7403\n",
            "t = 16, avg_loss = 0.6197\n",
            "t = 17, avg_loss = 0.5531\n",
            "t = 18, avg_loss = 0.6326\n",
            "t = 19, avg_loss = 0.5874\n",
            "t = 20, avg_loss = 0.6911\n",
            "t = 21, avg_loss = 0.7318\n",
            "t = 22, avg_loss = 0.5623\n",
            "t = 23, avg_loss = 0.5972\n",
            "t = 24, avg_loss = 0.6737\n",
            "t = 25, avg_loss = 0.6964\n",
            "t = 26, avg_loss = 0.5637\n",
            "t = 27, avg_loss = 0.7954\n",
            "t = 28, avg_loss = 0.5258\n",
            "t = 29, avg_loss = 0.5351\n",
            "t = 30, avg_loss = 0.6596\n",
            "t = 31, avg_loss = 0.5675\n",
            "t = 32, avg_loss = 0.5556\n",
            "t = 33, avg_loss = 0.7282\n",
            "t = 34, avg_loss = 0.7100\n",
            "t = 35, avg_loss = 0.7162\n",
            "Checking accuracy on test set\n",
            "Got 179 / 280 correct (63.93)\n",
            "acc = 0.639286\n",
            "Starting epoch 23 / 50\n",
            "t = 1, avg_loss = 0.6435\n",
            "t = 2, avg_loss = 0.6335\n",
            "t = 3, avg_loss = 0.6106\n",
            "t = 4, avg_loss = 0.6503\n",
            "t = 5, avg_loss = 0.5617\n",
            "t = 6, avg_loss = 0.5763\n",
            "t = 7, avg_loss = 0.6140\n",
            "t = 8, avg_loss = 0.5048\n",
            "t = 9, avg_loss = 0.6889\n",
            "t = 10, avg_loss = 0.7052\n",
            "t = 11, avg_loss = 0.6064\n",
            "t = 12, avg_loss = 0.6143\n",
            "t = 13, avg_loss = 0.5780\n",
            "t = 14, avg_loss = 0.5695\n",
            "t = 15, avg_loss = 0.6211\n",
            "t = 16, avg_loss = 0.7276\n",
            "t = 17, avg_loss = 0.6818\n",
            "t = 18, avg_loss = 0.7108\n",
            "t = 19, avg_loss = 0.7601\n",
            "t = 20, avg_loss = 0.6371\n",
            "t = 21, avg_loss = 0.7351\n",
            "t = 22, avg_loss = 0.6565\n",
            "t = 23, avg_loss = 0.6881\n",
            "t = 24, avg_loss = 0.6666\n",
            "t = 25, avg_loss = 0.5831\n",
            "t = 26, avg_loss = 0.7128\n",
            "t = 27, avg_loss = 0.6126\n",
            "t = 28, avg_loss = 0.6576\n",
            "t = 29, avg_loss = 0.6156\n",
            "t = 30, avg_loss = 0.7457\n",
            "t = 31, avg_loss = 0.6015\n",
            "t = 32, avg_loss = 0.6377\n",
            "t = 33, avg_loss = 0.6658\n",
            "t = 34, avg_loss = 0.5756\n",
            "t = 35, avg_loss = 0.5350\n",
            "Checking accuracy on test set\n",
            "Got 181 / 280 correct (64.64)\n",
            "acc = 0.646429\n",
            "Starting epoch 24 / 50\n",
            "t = 1, avg_loss = 0.6763\n",
            "t = 2, avg_loss = 0.6218\n",
            "t = 3, avg_loss = 0.6446\n",
            "t = 4, avg_loss = 0.6543\n",
            "t = 5, avg_loss = 0.6733\n",
            "t = 6, avg_loss = 0.6177\n",
            "t = 7, avg_loss = 0.6101\n",
            "t = 8, avg_loss = 0.6226\n",
            "t = 9, avg_loss = 0.6492\n",
            "t = 10, avg_loss = 0.5834\n",
            "t = 11, avg_loss = 0.7113\n",
            "t = 12, avg_loss = 0.6875\n",
            "t = 13, avg_loss = 0.6014\n",
            "t = 14, avg_loss = 0.5873\n",
            "t = 15, avg_loss = 0.6080\n",
            "t = 16, avg_loss = 0.7207\n",
            "t = 17, avg_loss = 0.5613\n",
            "t = 18, avg_loss = 0.6787\n",
            "t = 19, avg_loss = 0.6237\n",
            "t = 20, avg_loss = 0.5907\n",
            "t = 21, avg_loss = 0.6493\n",
            "t = 22, avg_loss = 0.5677\n",
            "t = 23, avg_loss = 0.6536\n",
            "t = 24, avg_loss = 0.5920\n",
            "t = 25, avg_loss = 0.7345\n",
            "t = 26, avg_loss = 0.6536\n",
            "t = 27, avg_loss = 0.6009\n",
            "t = 28, avg_loss = 0.6060\n",
            "t = 29, avg_loss = 0.6879\n",
            "t = 30, avg_loss = 0.7431\n",
            "t = 31, avg_loss = 0.5903\n",
            "t = 32, avg_loss = 0.6824\n",
            "t = 33, avg_loss = 0.5174\n",
            "t = 34, avg_loss = 0.5810\n",
            "t = 35, avg_loss = 0.6799\n",
            "Checking accuracy on test set\n",
            "Got 180 / 280 correct (64.29)\n",
            "acc = 0.642857\n",
            "Starting epoch 25 / 50\n",
            "t = 1, avg_loss = 0.6796\n",
            "t = 2, avg_loss = 0.6509\n",
            "t = 3, avg_loss = 0.6724\n",
            "t = 4, avg_loss = 0.5685\n",
            "t = 5, avg_loss = 0.5573\n",
            "t = 6, avg_loss = 0.6522\n",
            "t = 7, avg_loss = 0.7103\n",
            "t = 8, avg_loss = 0.5873\n",
            "t = 9, avg_loss = 0.6326\n",
            "t = 10, avg_loss = 0.5757\n",
            "t = 11, avg_loss = 0.6084\n",
            "t = 12, avg_loss = 0.6215\n",
            "t = 13, avg_loss = 0.6724\n",
            "t = 14, avg_loss = 0.6434\n",
            "t = 15, avg_loss = 0.6203\n",
            "t = 16, avg_loss = 0.6973\n",
            "t = 17, avg_loss = 0.6510\n",
            "t = 18, avg_loss = 0.6383\n",
            "t = 19, avg_loss = 0.5810\n",
            "t = 20, avg_loss = 0.6531\n",
            "t = 21, avg_loss = 0.6908\n",
            "t = 22, avg_loss = 0.6596\n",
            "t = 23, avg_loss = 0.6101\n",
            "t = 24, avg_loss = 0.6372\n",
            "t = 25, avg_loss = 0.6029\n",
            "t = 26, avg_loss = 0.6916\n",
            "t = 27, avg_loss = 0.6343\n",
            "t = 28, avg_loss = 0.6686\n",
            "t = 29, avg_loss = 0.6108\n",
            "t = 30, avg_loss = 0.6848\n",
            "t = 31, avg_loss = 0.7206\n",
            "t = 32, avg_loss = 0.6160\n",
            "t = 33, avg_loss = 0.5385\n",
            "t = 34, avg_loss = 0.6380\n",
            "t = 35, avg_loss = 0.6377\n",
            "Checking accuracy on test set\n",
            "Got 155 / 280 correct (55.36)\n",
            "acc = 0.553571\n",
            "Starting epoch 26 / 50\n",
            "t = 1, avg_loss = 0.6440\n",
            "t = 2, avg_loss = 0.6554\n",
            "t = 3, avg_loss = 0.6440\n",
            "t = 4, avg_loss = 0.7347\n",
            "t = 5, avg_loss = 0.5879\n",
            "t = 6, avg_loss = 0.6282\n",
            "t = 7, avg_loss = 0.7504\n",
            "t = 8, avg_loss = 0.6935\n",
            "t = 9, avg_loss = 0.6322\n",
            "t = 10, avg_loss = 0.6652\n",
            "t = 11, avg_loss = 0.5929\n",
            "t = 12, avg_loss = 0.6317\n",
            "t = 13, avg_loss = 0.7653\n",
            "t = 14, avg_loss = 0.7785\n",
            "t = 15, avg_loss = 0.6852\n",
            "t = 16, avg_loss = 0.6829\n",
            "t = 17, avg_loss = 0.7156\n",
            "t = 18, avg_loss = 0.6293\n",
            "t = 19, avg_loss = 0.6462\n",
            "t = 20, avg_loss = 0.6664\n",
            "t = 21, avg_loss = 0.5678\n",
            "t = 22, avg_loss = 0.6814\n",
            "t = 23, avg_loss = 0.6305\n",
            "t = 24, avg_loss = 0.6242\n",
            "t = 25, avg_loss = 0.6451\n",
            "t = 26, avg_loss = 0.7062\n",
            "t = 27, avg_loss = 0.7551\n",
            "t = 28, avg_loss = 0.6066\n",
            "t = 29, avg_loss = 0.6457\n",
            "t = 30, avg_loss = 0.6271\n",
            "t = 31, avg_loss = 0.6819\n",
            "t = 32, avg_loss = 0.6144\n",
            "t = 33, avg_loss = 0.6663\n",
            "t = 34, avg_loss = 0.6291\n",
            "t = 35, avg_loss = 0.6162\n",
            "Checking accuracy on test set\n",
            "Got 188 / 280 correct (67.14)\n",
            "acc = 0.671429\n",
            "Starting epoch 27 / 50\n",
            "t = 1, avg_loss = 0.6996\n",
            "t = 2, avg_loss = 0.5993\n",
            "t = 3, avg_loss = 0.6377\n",
            "t = 4, avg_loss = 0.6283\n",
            "t = 5, avg_loss = 0.5810\n",
            "t = 6, avg_loss = 0.6003\n",
            "t = 7, avg_loss = 0.5819\n",
            "t = 8, avg_loss = 0.5893\n",
            "t = 9, avg_loss = 0.6907\n",
            "t = 10, avg_loss = 0.5167\n",
            "t = 11, avg_loss = 0.5410\n",
            "t = 12, avg_loss = 0.5460\n",
            "t = 13, avg_loss = 0.6252\n",
            "t = 14, avg_loss = 0.6105\n",
            "t = 15, avg_loss = 0.6317\n",
            "t = 16, avg_loss = 0.5780\n",
            "t = 17, avg_loss = 0.6472\n",
            "t = 18, avg_loss = 0.5298\n",
            "t = 19, avg_loss = 0.5883\n",
            "t = 20, avg_loss = 0.7036\n",
            "t = 21, avg_loss = 0.6748\n",
            "t = 22, avg_loss = 0.6678\n",
            "t = 23, avg_loss = 0.5984\n",
            "t = 24, avg_loss = 0.6212\n",
            "t = 25, avg_loss = 0.6686\n",
            "t = 26, avg_loss = 0.6375\n",
            "t = 27, avg_loss = 0.7753\n",
            "t = 28, avg_loss = 0.6977\n",
            "t = 29, avg_loss = 0.6420\n",
            "t = 30, avg_loss = 0.7325\n",
            "t = 31, avg_loss = 0.6324\n",
            "t = 32, avg_loss = 0.6629\n",
            "t = 33, avg_loss = 0.7635\n",
            "t = 34, avg_loss = 0.6053\n",
            "t = 35, avg_loss = 0.6837\n",
            "Checking accuracy on test set\n",
            "Got 184 / 280 correct (65.71)\n",
            "acc = 0.657143\n",
            "Starting epoch 28 / 50\n",
            "t = 1, avg_loss = 0.5616\n",
            "t = 2, avg_loss = 0.5305\n",
            "t = 3, avg_loss = 0.5711\n",
            "t = 4, avg_loss = 0.6099\n",
            "t = 5, avg_loss = 0.6741\n",
            "t = 6, avg_loss = 0.6588\n",
            "t = 7, avg_loss = 0.5542\n",
            "t = 8, avg_loss = 0.6542\n",
            "t = 9, avg_loss = 0.6162\n",
            "t = 10, avg_loss = 0.5979\n",
            "t = 11, avg_loss = 0.6614\n",
            "t = 12, avg_loss = 0.5019\n",
            "t = 13, avg_loss = 0.7006\n",
            "t = 14, avg_loss = 0.7358\n",
            "t = 15, avg_loss = 0.6034\n",
            "t = 16, avg_loss = 0.6993\n",
            "t = 17, avg_loss = 0.6174\n",
            "t = 18, avg_loss = 0.6849\n",
            "t = 19, avg_loss = 0.7065\n",
            "t = 20, avg_loss = 0.6161\n",
            "t = 21, avg_loss = 0.5992\n",
            "t = 22, avg_loss = 0.6561\n",
            "t = 23, avg_loss = 0.5989\n",
            "t = 24, avg_loss = 0.5487\n",
            "t = 25, avg_loss = 0.6459\n",
            "t = 26, avg_loss = 0.6630\n",
            "t = 27, avg_loss = 0.6369\n",
            "t = 28, avg_loss = 0.7000\n",
            "t = 29, avg_loss = 0.7081\n",
            "t = 30, avg_loss = 0.5707\n",
            "t = 31, avg_loss = 0.6754\n",
            "t = 32, avg_loss = 0.5859\n",
            "t = 33, avg_loss = 0.6850\n",
            "t = 34, avg_loss = 0.6736\n",
            "t = 35, avg_loss = 0.6986\n",
            "Checking accuracy on test set\n",
            "Got 186 / 280 correct (66.43)\n",
            "acc = 0.664286\n",
            "Starting epoch 29 / 50\n",
            "t = 1, avg_loss = 0.7627\n",
            "t = 2, avg_loss = 0.6767\n",
            "t = 3, avg_loss = 0.7089\n",
            "t = 4, avg_loss = 0.6562\n",
            "t = 5, avg_loss = 0.7288\n",
            "t = 6, avg_loss = 0.6008\n",
            "t = 7, avg_loss = 0.6278\n",
            "t = 8, avg_loss = 0.6616\n",
            "t = 9, avg_loss = 0.6838\n",
            "t = 10, avg_loss = 0.6288\n",
            "t = 11, avg_loss = 0.6076\n",
            "t = 12, avg_loss = 0.6946\n",
            "t = 13, avg_loss = 0.6889\n",
            "t = 14, avg_loss = 0.6006\n",
            "t = 15, avg_loss = 0.6108\n",
            "t = 16, avg_loss = 0.6321\n",
            "t = 17, avg_loss = 0.6055\n",
            "t = 18, avg_loss = 0.6452\n",
            "t = 19, avg_loss = 0.5838\n",
            "t = 20, avg_loss = 0.6029\n",
            "t = 21, avg_loss = 0.6246\n",
            "t = 22, avg_loss = 0.6473\n",
            "t = 23, avg_loss = 0.5953\n",
            "t = 24, avg_loss = 0.6623\n",
            "t = 25, avg_loss = 0.6855\n",
            "t = 26, avg_loss = 0.6444\n",
            "t = 27, avg_loss = 0.5797\n",
            "t = 28, avg_loss = 0.6355\n",
            "t = 29, avg_loss = 0.6005\n",
            "t = 30, avg_loss = 0.6909\n",
            "t = 31, avg_loss = 0.5966\n",
            "t = 32, avg_loss = 0.7348\n",
            "t = 33, avg_loss = 0.6210\n",
            "t = 34, avg_loss = 0.6151\n",
            "t = 35, avg_loss = 0.5503\n",
            "Checking accuracy on test set\n",
            "Got 188 / 280 correct (67.14)\n",
            "acc = 0.671429\n",
            "Starting epoch 30 / 50\n",
            "t = 1, avg_loss = 0.6453\n",
            "t = 2, avg_loss = 0.5986\n",
            "t = 3, avg_loss = 0.6451\n",
            "t = 4, avg_loss = 0.6522\n",
            "t = 5, avg_loss = 0.6192\n",
            "t = 6, avg_loss = 0.5396\n",
            "t = 7, avg_loss = 0.6553\n",
            "t = 8, avg_loss = 0.5515\n",
            "t = 9, avg_loss = 0.6442\n",
            "t = 10, avg_loss = 0.5969\n",
            "t = 11, avg_loss = 0.6509\n",
            "t = 12, avg_loss = 0.6104\n",
            "t = 13, avg_loss = 0.6130\n",
            "t = 14, avg_loss = 0.5844\n",
            "t = 15, avg_loss = 0.6038\n",
            "t = 16, avg_loss = 0.6587\n",
            "t = 17, avg_loss = 0.6867\n",
            "t = 18, avg_loss = 0.6090\n",
            "t = 19, avg_loss = 0.5889\n",
            "t = 20, avg_loss = 0.6118\n",
            "t = 21, avg_loss = 0.6470\n",
            "t = 22, avg_loss = 0.6120\n",
            "t = 23, avg_loss = 0.6811\n",
            "t = 24, avg_loss = 0.6582\n",
            "t = 25, avg_loss = 0.6891\n",
            "t = 26, avg_loss = 0.5350\n",
            "t = 27, avg_loss = 0.6530\n",
            "t = 28, avg_loss = 0.7171\n",
            "t = 29, avg_loss = 0.7613\n",
            "t = 30, avg_loss = 0.5811\n",
            "t = 31, avg_loss = 0.6203\n",
            "t = 32, avg_loss = 0.6025\n",
            "t = 33, avg_loss = 0.6078\n",
            "t = 34, avg_loss = 0.7854\n",
            "t = 35, avg_loss = 0.6448\n",
            "Checking accuracy on test set\n",
            "Got 178 / 280 correct (63.57)\n",
            "acc = 0.635714\n",
            "Starting epoch 31 / 50\n",
            "t = 1, avg_loss = 0.7030\n",
            "t = 2, avg_loss = 0.6184\n",
            "t = 3, avg_loss = 0.7389\n",
            "t = 4, avg_loss = 0.5474\n",
            "t = 5, avg_loss = 0.6991\n",
            "t = 6, avg_loss = 0.5941\n",
            "t = 7, avg_loss = 0.5947\n",
            "t = 8, avg_loss = 0.6020\n",
            "t = 9, avg_loss = 0.6417\n",
            "t = 10, avg_loss = 0.7174\n",
            "t = 11, avg_loss = 0.5596\n",
            "t = 12, avg_loss = 0.6522\n",
            "t = 13, avg_loss = 0.6758\n",
            "t = 14, avg_loss = 0.6488\n",
            "t = 15, avg_loss = 0.6089\n",
            "t = 16, avg_loss = 0.6784\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-580bed4d56d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfixed_model_gpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0014\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfixed_model_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0mcheck_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfixed_model_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-2d469a18a779>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, loss_fn, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mx_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0my_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-50a9cd504daf>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m           \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"malignant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"malignant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \"\"\"\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   1871\u001b[0m                 )\n\u001b[1;32m   1872\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1873\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1875\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDn-2g-TLY3k",
        "colab_type": "code",
        "outputId": "eb5602fc-2f18-4991-cef9-724450b3cc35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot([print_every*batch_size*(i+1) for i in range((len(avg_loss_list)))],avg_loss_list)\n",
        "print(\"Loss:\")\n",
        "plt.show()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAgAElEQVR4nO2deXwV1dnHf08SkrCEPYASIKAgiyBq\nxAVFXEFpxWoXtPZVa7VqtW7VF6tFxdpaW1vrW1xQcWmruLcoKKKioqISZBFQIASEIELYZAmQ7Xn/\nuDP3zp17ZubMdpfJ+X4+gXtnzsycOXfOc555znOeh5gZCoVCoYgueZmugEKhUCjCRQl6hUKhiDhK\n0CsUCkXEUYJeoVAoIo4S9AqFQhFxCjJdATNdu3bl8vLyTFdDoVAocoqFCxduZeZS0b6sE/Tl5eWo\nrKzMdDUUCoUipyCir632KdONQqFQRBwl6BUKhSLiKEGvUCgUEUcJeoVCoYg4StArFApFxFGCXqFQ\nKCKOlKAnorFEtJKIqohoomB/HyJ6h4iWEtF7RFRm2HcxEa3W/i4OsvIKhUKhcMZR0BNRPoApAM4C\nMBjABUQ02FTsLwCeYeZhACYD+KN2bGcAdwA4FsAIAHcQUafgqp/K3JVbULOjLsxLKBQKRU4ho9GP\nAFDFzNXMXA9gOoDxpjKDAbyrfZ5r2D8GwBxm3s7MOwDMATDWf7WtufTJBTjrgXlhXkKhUChyChlB\n3xPABsP3Gm2bkSUAztM+/wBACRF1kTwWRHQFEVUSUWVtba1s3S3ZfaDR9zkUCoUiKgQ1GfsbACcT\n0SIAJwPYCKBJ9mBmnsrMFcxcUVoqDNWgUCgUCo/IxLrZCKCX4XuZti0OM38DTaMnonYAzmfmnUS0\nEcBo07Hv+aivQqFQKFwio9EvANCfiPoSUSGACQBmGAsQUVci0s91K4Bp2ufZAM4kok7aJOyZ2jaF\nQqFQpAlHQc/MjQCuQUxAfwngBWZeTkSTiegcrdhoACuJaBWA7gDu0Y7dDuBuxAaLBQAma9sUCoVC\nkSakwhQz8ywAs0zbJhk+vwTgJYtjpyGh4SsUCoUizaiVsQqFQhFxlKBXKBSKiKMEvUKhUEQcJegV\nCoUi4ihB3wJ49P01WLd1b6aroVAoMoQS9BFnZ109/vjGV7jwsU8yXRWFQpEhIiXomTnTVcg69CbZ\nWy8dkUKhUESMiAn6TNcg+yCK/a8GQYWi5RItQZ/pCmQhBMp0FRQKRYaJlqBXWqtCoVCkEClBr7BG\nDYEKRcslUoJeCTMBynKjULR4oiXolaRXKBSKFKIl6JVOb41qGoWixRItQa+EmUKhUKQQKUGvEKAG\nP4WixSMl6IloLBGtJKIqIpoo2N+biOYS0SIiWkpEZ2vby4loHxEt1v4eCfoGjCiNPhVlzlIoFI4Z\npogoH8AUAGcAqAGwgIhmMPMKQ7HbEUsx+DARDUYsG1W5tm8NMw8PttpilFCzRrWMQtFykdHoRwCo\nYuZqZq4HMB3AeFMZBtBe+9wBwDfBVVEepdGnotpEoVDICPqeADYYvtdo24zcCeAiIqpBTJu/1rCv\nr2bSeZ+IThJdgIiuIKJKIqqsra2Vr70JJdNSUW2iUCiCmoy9AMBTzFwG4GwA/ySiPACbAPRm5iMB\n3AjgWSJqbz6YmacycwUzV5SWlgZUJYURFR5CoWi5yAj6jQB6Gb6XaduMXAbgBQBg5vkAigF0ZeYD\nzLxN274QwBoAA/xW2golzFJRbaJQKGQE/QIA/YmoLxEVApgAYIapzHoApwEAEQ1CTNDXElGpNpkL\nIuoHoD+A6qAqb0aJtFRUmygUCkevG2ZuJKJrAMwGkA9gGjMvJ6LJACqZeQaAmwA8RkQ3ICZbLmFm\nJqJRACYTUQOAZgBXMvP2sG5GKa/WqKZRKFoujoIeAJh5FmKTrMZtkwyfVwAYKTjuZQAv+6yjPEqa\npaAGP4VCEamVscqPPhW9TZTAVyhaLtES9EqYWaIGQYWi5RItQZ/pCmQjqlEUihZPtAS9UulTUC2i\nUCiiJegzXYEsRo2BCkXLJVKCXpGKEvAKhSJSgl4JtVT8TMI2NjXjlpeWYP22ugBrpFAo0k20BL0y\n3ljipWUqv96BFypr8JuXlgReH4VCkT4iJeiVnE+wZMNOMHMwbzmqXePU7j6AUffNRXXtnkxXRaGQ\nJlKCXsmjGPNW12L8lI/w9MfrVJsEzBvLNmH99jo8+dG6TFdFoZAmWoJeSTUAwPrtMZv6ys27ExtV\n2ygULZZoCXolzVLws7aAAqxHVFDKhCIXiZagV50wBdUm4UBqFFTkENES9JmuQJZAAl1cve0oFC2X\naAl6pb4qQkY9Ywle+bwGG7arNRa5gJSgJ6KxRLSSiKqIaKJgf28imqslAV9KRGcb9t2qHbeSiMYE\nWXmFM7kql5gZew80ZroalrR0yw0z48YXluC8hz/OdFUUEjgKei0V4BQAZwEYDOACIhpsKnY7gBe0\nJOATADykHTtY+z4EwFgAD+mpBcMgV4VaWBjbw0/bZMLs89i8agy5YzY279qf9msrnGnWHomtew5k\ntiIKKWQ0+hEAqpi5mpnrAUwHMN5UhgG01z53APCN9nk8gOlakvC1AKq08ylCxDhRmKu2+TeWfQsA\nqNmxL8M1UYho1jSHPDUrnRPICPqeADYYvtdo24zcCeAiIqpBLOXgtS6ODQyl0aeit4mfplmwbgcq\n14WW6leILkCyzSaeXbXJHLqgV2I+NwhqMvYCAE8xcxmAswH8k4ikz01EVxBRJRFV1tbWeq5Ermqv\n6cCvwPzhI/MDqokcugBpztKflFq4Jqs/Ti28GXIGGWG8EUAvw/cybZuRywC8AADMPB9AMYCukseC\nmacycwUzV5SWlsrXPuU8ng9NYcmGnajZkdseBcy5q4HqGn1zlmn0fvi0ehuas3Xkcklc0HvU6T9c\nvRUj730X+xuaAqyVwgoZQb8AQH8i6ktEhYhNrs4wlVkP4DQAIKJBiAn6Wq3cBCIqIqK+APoD+Cyo\nypsJsguNn/IRTvzT3ADPmBl8rYzNoLqmXzrbBL3X6ry3cgt+MvUTPP5hdbAVyhDNCUnvibtfX4GN\nO/dh3ba9wVVKYUmBUwFmbiSiawDMBpAPYBozLyeiyQAqmXkGgJsAPEZENyAmby/hmIRZTkQvAFgB\noBHAr5g5tCE82+y52USutUzCRp/higTEpu9i3kPVtdEQbH5t9MrMml4cBT0AMPMsxCZZjdsmGT6v\nADDS4th7ANzjo47SqEcnht75OODutK++Ca0LQ/OOTSJPe9fMNo3eK3pY44jcTnzuRHnd5AYRWxmb\n6RoEw9qte/HI+2s8H5/kXhlgm9zy8tLgTuZAwkaftkuGymPz1kqVY2bM/WpL1r+d6vVTcj43iJSg\nl+HWV5ai760zM10NW37y6Hzc+8ZX2L2/IbBzMgMHGpvw38UbPQuRrzbtCqw+TlAEJ2NlmL5gAy59\nagFeWliT6arY0uzPRK8A8Nc5q3DEXW+l5VpSppvcwVkoPPfZBscymaauPshpjESb3P/WKkz9oBrt\nW7fCKYd1c32mpjQK3TxNgmSbZht2bb7ZuU/7P7tXBMdt9Eql98yD76xO27UipdFnmUzwjdvb2d/Q\nhD++8SX2aQMFc3Kb6BOCu/bJvSmY+7DRNfC7fQ0onzgTc1ducVlLObJ9MjbK8u2JD9c6CiGfTjeK\nNBMpjT5LZYJrvHaef33yNR59vxrd2xcJ98toxx+u3opmZowakLqeodEg6Fd+G8te9dDcKk9vB07k\nxd0rAz+1L9L1hpHJgeTu11cAAH59Wn/LMpyDkn7h19uxv6EZIw/tmumqpB2l0UeI+qZmAEBDU6Ih\n3DbJRU98iv+ZJl7qYNTogxJ4qzbvxnd1qW8YUbXRR8WtMCivG68Lrrxw/sPz8dPHP03b9bKJaAn6\niHQiGTZsr8POuvr49+/2NeDpj9cBSFayjHLSrz1VZKP321HP/NsH+NGjqaFus9VG77cNs+x2PNMc\nca+bs/4+D5NfW5HpagRGtAR9RDqRDCfdNxen//X9+PfbXv0Cm3fFQsaG1fmamr2/KYjQhfiqzXtS\n9qXLvfKvb63EBVM/kS6froEn25/lqAc1+3LTLkz7SM4lNheIlo0+yzuHW5zuZ+uehEa/fW+9YU+s\n+724sAYvGtz0/AqppoClbqPN+cKOdTN/zTYc3LEYD75b5en4dJocshEOyHSjSA/REvQRMd1wygeJ\nYwxl89Kg0QeBXUArCnky9oLH5LX4TJDt8jPqppuoESnTjR9+8+ISXP5MZaarkYSbgcuo+Vp1Pr/2\nZS9C92dPfIryieIFavsbYpPH+YKRyUs8+qZmRmNTM5g5dBOL16aMhioSvbfnqBMtjd7Hw5eNKxHd\n3I9MUb/Cr7G5OXWjg8Cbt3qr5b4DjTGNvqggVd/wEr3y2D+8jQMNzdh9oBHfP+Jg/N8FR0ofK4sS\ncDFayoKp/Q1NKG6VnvhOYRJZjf69lVtQPnEmyifOxPpt/uLKNzY1o6FJIORCxpVMMXrXWEjfWV9s\niu2X6JwXPf4p6huT79ko54MQeLpGL+pIcRu9i2bfuqceu7WE4q8t+cahdHYT1ICy6bt9oTy7LSUE\nwsDfvWm7/8F3VuPjKmtlJluIlKA3do5rn1sU/7xi03e+zjvqvrkY5PCDh4EbDVzGdKN3TqmFU1Vb\nsbQmud3E7pXe0d8QRBN62RqPPpcU2D0HGnH8H9/F7/6zLPBzhxXUrL6x2Vc8pnTz1zmrcKEH3/wf\nPPRRCLWxJlqC3qDW7t7fGP/s5/WysakZ33y339ZDJCzcXNFYVvZum5sZc1Zslu5Uye6V/tvDLh1d\ntoZASFd9zG3yz/nrcPW/F7o6R532dvPOV8GHqUho9N76llU7/v2dVbhu+mLMWbHZY81yg0Xrd6b1\netES9BYPj/4o7jnQKC5gw6G3veG9Qj5xZaNP0ujlOt+zn63H5c9UhjY/MXPpJqlyovs0xtTPRtKt\n2P/uv8sx64tvXR0TZsuF5XUTj8e0331fVVgjJeiJaCwRrSSiKiKaKNj/NyJarP2tIqKdhn1Nhn3m\nFISBYvVg69qh2eac7bgRcm46tT4QbNQiJW7ZfcBNtaRxCngmM5Blm7+634EnE28oYbRgWKFu0hVC\n5/yHP8YlT4aW1TTrcPS6IaJ8AFMAnAGgBsACIpqhZZUCADDzDYby1wIwujvsY+bhwVXZGisThJ6t\nKD9HDKzx+3AhFIyWJafb1M+vX+bPs1fi3CN7omfH1o7X2bG3Hp3aFkrWSfYGrMtlq0a/bttebNm9\nH91Kil0dJ3s/2WayMhOW1026Epos/HqHdFlmznnvIhmNfgSAKmauZuZ6ANMBjLcpfwGA54KonBv2\n1TfhKS3WixkCgZnx78++Tm+lfOLO68Z5Mjb1EGM0ytSkIiKhdN7DyXFpiIAXKjdg/pptdlUSX9/m\nDrO9X7395RaMuOedTFfDljAHC7v5FV/n1f4PcsXtrv0N+P3r0Ylb4wUZQd8TgDFbR422LQUi6gOg\nL4B3DZuLiaiSiD4honMtjrtCK1NZW1srWfVk6uob8d/FYpc6oljHvO/NlZ7OLcuSDTvR79aZ2LIr\nmKQRXv3oncwdunbiRQ6s3boX1bV78OWm3fFtt7y0VLjSVFajFxXLdo02l5CVmVM/WINHJVNYhmWj\nbw5hAPnbnFV4/EPvcWui8CwGvWBqAoCXmNm4tr0PM28kon4A3iWiL5g56Wli5qkApgJARUWFp2a1\ne7UiIuzaV2+5Pyie/GgtmjnmmnjeUWW+z+fKRu/CdKNjDDssGhysBoxT73/fsYy5Tl72i1j49Xac\n//B8zP3NaPTt2tb9CRRCrFYvW5EIahaO6QYA1m+rQ3GrPHRr7848ZsbvOoKw5Xw6TEMyGv1GAL0M\n38u0bSImwGS2YeaN2v/VAN5Dsv0+MOziu+RR8HFaRNjF6PayLN9NcTf+5jOXfoMLpn4SemRIPz7w\nVs/9K5/HHr0PV3t78/OLb+1O8vgg+n2Y8xuJZ93fecz3aQyWNurPczHiD/7NY9k2oZ8JZAT9AgD9\niagvERUiJsxTvGeIaCCATgDmG7Z1IqIi7XNXACMBhGIssxsR84hS/OAXb9iJJz5cC2bGqs27LY50\nh9Xr7LKN36HvrbPQ99ZZrs7nyo8+KaiZ/YM9e/lmzK/eFvpEp51QZGY8Nq/a9TndCMBbXlqCc6ek\nd2FKUARpLghD0IW1oEl/JmV+5/KJM3HD84sdy/kdNMNevJUO05Cj6YaZG4noGgCzAeQDmMbMy4lo\nMoBKZtaF/gQA0zm5VQYBeJSImhEbVO41eusEid2PSZS6qlMXAMWt8nDbq8GsHNSvYB50RBOVUudz\n8QR4WTDFDgf5HQhEGv32vfXIJ8KOunrLOZWgeKEy++IXtWSamxn3zV6JS0eWW5ZxG/741UUb8bef\n2Dv1+R3mrHpBUANAOqYApGz0zDwLwCzTtkmm73cKjvsYwFAf9ZPG7sEgEJos7HTLNqZ6m3jG4nXW\nq8Dc39CEXfsb0L64VfL5BA9Y8oIpufMnhU3wVEP7a4kE/VF3zwEAvHPTyfFtuTTXlVN19VnZDdvr\nMPaBDzDj2hNxSGm75HN7ON/C9TvwyPtr8MVG61WhYSQ0CSsrWFCmz9F/mYt5t5wazMksiMzKWDtb\nIZF1kosgX8v0h9Q86Lh9IPTip//1Awy78y3BdQTHeLgNp3kLv6/8QTTt65Kra1s6yzZ+h/KJM7Fs\nY2pcJ69y7vWlm7C3vgkvVG5wLmyirr4R++qT8w3ok/8NjTbrJtwvIUkbC7/ejpodiQCJQcmODdv3\nBXIeOyIj6O2EUh6RpVALcrWslTZifB7eXOZuGbsI0QO2pjaRjk9Wgwk7YJjsAGfXYcxhjvVAa2HW\nvL6x2Vcnnr38WyxaL78gR4Rb4fz2l7HYMG+FESPGg2IxeNJsDJ+cqqTIXurqf39uWaa5mfGrZ633\nm7FaXyNfp1itzn94Pk7809xEPRzaYOwDH2DKXG8ZzIImOoLeo0ZfbzLp3PD8Yoz3OIGXWESSXBmj\n6ebKfyUHpmpu5hTNx6mPm2/lgbdXJd2frIxobLJ/UmVMTnbtHsYkVlzQhyTpN+/ajwG3v4Fn5ntf\nXPfLfy7EDx5KTXgOyA9Qbu/PWL6hqRmzvtjkezB0O9gwM1Z8kzCFHrBQopZu3InVW1LzBOvncGLb\n3nrpOEpBYG26sa/rV9/uxp9nh7t2R5YWIejfX1lrqdGbfWxfXbQRSzZ4iyxntdjD7nn429urMGjS\nm64CrpkfsAfeXp30XbaDBuFyWldvnQ7QriM0J0XCTMXJbPTBqlps2O4vz4AI/ZwzLOLZZ/viGQLw\nf+9W4ep/f453NC0/nFg3qQ3x2tJNOPvBefG8Byl10x5MPQ+B+LzO186WVdPZ/iwYiYygt5uM/cfc\nKlPy7ARWWoc3xDZ6Oy3l+QUx++ceF9H6nB4wWdu60RPJ64SVXbhVu3HEb7u/89UWnPKX9zwd++Wm\nACfgXZKOOOvfaMHqtu0Jb5Gg6C5Wa27KqzeLtXXRI/bA26uwduve+PdFEkpWlsj5JEXm359md3iV\nFiHoAWs73QEb7cItVotI7ASerlWL8qZa4WRSkZXZYcfYt9Pog8h65LX+97+VHa/TIoIQYokQzwmq\ntuzG19tiArWxqTnpjSoovISWnvXFt/jZE4nEHVYKWdJ10qzSy5hufv/6l2mqjTciI+idfnorORrk\nhKTVgim7SzR6EPRB9VFjZw8jhLPdfWcyZLQ4to64sktrdqJ84kxUWdiU041VPYVbDREmT//rBzj5\nz+8BiOVYMAenc18PwUaPAnivyzwR6dborQauHLLcREjQO/z6VsLx07XbPV/zzWWbUD5xJnbWxbSQ\nRCxt68lYM42aZmvswE4PUFCDk9FGf/kzlSn7/V7GXqPPrm5irmqtFqNfD7nw/irrkAvzVtfix4/O\nT5nzeNxm5e+++qZ4cnQ3OA3yxn5gV3Sxx3koM6JrOCUAMuP2WXAzngRhKrM6BRt0Fb+hIMImQoI+\n/S099YNYR9a1IyuN3tw5jQ+frtG7eRzZQRmWbYuw4//Y9TGj6Sbdk1qiy5kHpfXapKzeRq3y9Yif\nqUdf+9wifLZ2O3bta0ja/vuZqa/z+tGDJr2J0ZqG7VQ3u3qKSEe+XVE7OD11Vo9lvUDZEVFX34jy\niTOl11b8/KkFUiESvNIcwBxXuoiMoM8E+o9bXRuzfVo+p6YdRgGrf3bTKY2dTGQCkc4BG7ofvfX5\n3UzGrqndE/qgdP+cVcK21BOY25nW9Nv85jvnhS96qjzzZ1mYgf8u3oiH33MOJ5wprxC3l0281dqX\n27gj1r5mLzMr3v1qC/4TQJgNBoRzGkEOpF/UfIf9De7f8GRRgj5AdAFs/v3Nz4jRhzg+oejimTGe\n7/rnF6Xs/+pbuSBtu0POy+kU1Mz4efbyby0f9NPufx9/f0euc1tx1t/nxT0jRAPhw++twfML1idt\nW7+tLr7WoFWedVfRB6FxD36IN5fZa5ufOZgK9eHkozVbhfubmXHd9MX405tf2Z4HMMZeciwqdR6n\njfHrGNr3c4mFY+67gD8Bu0NiwjfpasxCpSgpq5uvGgHf/8eHuPWVL3yexRol6H1gtQLWPNKbX3PP\n+vs8zDOF2X1+wQZ8VCXu3GaM53ebMNqIUzo1v/ZNO43HuGfX/kb88p8Lce1ziUHLLJwq1233VZ8v\nN+2KB6+zOku9yVY86s9zUybLRVUw3ufD77uLyGn1pvLZ2u1CO7rx+syM15d+E3sTSYpbRCn18oJb\n4aVfd7dhcvU8w8KxG55fYnu87O/rV5G+7OkFrsozxL9TUn0DsNx4Xb8jgxL0Pki1xetmmJg9UZ9s\nE/VlsxfH/XNW4aePf4p99U2Wi5D2NzThl/+sTPI7duOt45YgJ2M/XL01ydwgEkJzDMv3zbv31jdh\n2kfrUo4pnzgT7zkkITdjN1lo3qUL+oJ8cTu/8nmNr3ayG9x31KVqnkalYcDtb+CaZxfh7++sim9L\ncgQIyLIgDKJnU/5Jwe8EJOY9LK/jUA9dMfF7W19vc7/QTvS8Bm0ZC9PMH3SGqRaFeQIm/grKjMGT\nZqN35zb44JZThIKAIB7Bf/BQaviFmh11KOvUBvPXbMPs5Zux3hAEKZ8ITVnq6GWs1UUGX2kvLNmw\n01LjmfpBNUYf1s3yWPNyeavWEnU03X5cYGG6ufGFJfGJWi+Y62L8LlobYlQadG+VTd/tR5kgsbv+\nRuBVgMjMISQptb7jvlvvm7tyCyZamDa27jmAHz78MaZdcgz6maJsinA7ccosXrMRRPRXI2FO6CqN\n3gW79jegZkcdjrjrLcz9akvqjxs33cT+1zUYoYcCkTCmjsi+/oiWx1N/sIwrO82xerIJu/lTx9W9\nAT7zn62VywcguqSTRg/4W9dgG3UVsXmCP85KeO+INEsC4e0vU99q/LgOA/bBwNy8xTz10VpcIXDf\nTTmnjcKir/YV8cayb7FuWx2ekMwL6/olmFMnYxdv2Ik/vZGYJ8k2d2EzSqN3wfF/eAd7NbPK72eu\nQGlJUXzfm8s2xTuh+VVXqNG7eNiaTQNIWJgXrvi9nJ3NNchbcWrLp00ByqzqJdKodI0+3+YiRvut\nzM9ql6vX+C2PCFf+ayFWGAZ2kWstEeJliOSfreunL8J/Fn+D5XeNcSy7a38D/u+d1bh5zEAUFuQJ\nM0FZXfbO15xzDTU1s21uiAKDdE75/VzazmSTmsRPD076jS97agHe+Sp5YA3CKyxMB00pjZ6IxhLR\nSiKqIqKJgv1/I6LF2t8qItpp2HcxEa3W/i4OsvLpZq/Bdr7nQGNSJ/3Pom/iwsvOb15n0n+XS183\nHqM7ZH+510yBvMK8XDpivrhF1P+DGOzMb25rtyXmWNzmOvaSxMYq9pHueug0KQ8A989eicfmrcWr\ni5KzdgVluvnHu1U432a1br7BdGZl7pK9vl2b1+4+kHKPQPLvYBbyQZFRGz0R5QOYAuAMADUAFhDR\nDGNKQGa+wVD+WmgJwImoM4A7AFQg9nss1I71F6zbgQtG9MZzn613LuiDvQeakn6YN5d/iyN7dwSA\nlFjZ/gf7xCRvmOyoS17w4zeVYLpkudsEKW5Wblp5UsnSzKlzMafd/3788xMfrkVpSRH6dy8RVmjb\n3gMp5xMUS/7uUmDI3Ns+zfU1oXS4u4YTizbYi4QCiXUMss9Bns25fvH0AiypSU7ewuy85iSI/Mth\nJjGX0ehHAKhi5mpmrgcwHcB4m/IXAHhO+zwGwBxm3q4J9zkAxvqpsAz5aZh5qKtvdFwBC8QWt/h1\nc0scHq7klPHNtuPlhTW45SV7FzqdLFTohRLS6EkFuH8TcSr/zldbkjR+Y+mXF27EVlMEyjBWu8qc\nUp8KsvPy8jOZ6BTkLj/JdGN1fblrGcst/Ho7FqxLzGVs2X0gpbyVe2VSmWx8ng3IiMSeAIy5xGq0\nbSkQUR8AfQG86+ZYIrqCiCqJqLK21jqmiCxubXBeaGbgoyrTJJ/g175u+mLUHfC34i2hVfo6jefr\nynLTi0viCbm37N5vH48+wJ7hOkGGxYBpp9F7NTXJHLXPYqHYJ9Wpk8hequEcB8r5pE2mFcJBP4pO\nk5n2Gn3i2DkrNjsGzDNqzuc/PB8/emR+/LtIdjCzY7sH8TyHKbaC1n0nAHiJmV1JNmaeyswVzFxR\nWlrquxLpEPQirARxQ7M/zxhdMIVtjjKzwmPc9poddRhxzztY/o318UFqQOZ0g05YXfvlz2tS1jAk\nQlR4qppcIg2LzyKPTtGAkzoh6u75l7k3qyirBxqbsHt/g+gQVzgJ53y7yViNj9dsw+XPVOL+Od7D\nUHtdl8I29coGZAT9RgC9DN/LtG0iJiBhtnF7bGCEuYjIDqtR3SllnxONTYz73vzKtUDzyxyP+Uel\n/K89nTlcFq3fiT+YApElTDdyNTavZpVLx0h4oXJDSggGJz96L4giZhoTXluh339ihXDs++ZdBzBU\nS2DvR79yMt20srHH6k2iR5Gt8ZFsWyQ7ZJqcGeh76yxfg16YfvQy7pULAPQnor6ICekJAC40FyKi\ngQA6AZhv2DwbwB+IqJP2/WF0m+sAACAASURBVEwAt/qqsQSZChlqJQsafWr0M7/YFHAmrHCRkYlO\ngjPMlzK7S5tXo7oV9G6upUMAbnlpKQDg16cemrTdjJUfvSxX/nNhyra7HNwfmQ0JckL6YVzZ6C3K\n6IJy+956y1SQsXKp2/YcaERRQZ5QdjDLv4Gu316HIQd3CCWxix8cBT0zNxLRNYgJ7XwA05h5ORFN\nBlDJzDO0ohMATGfD+wszbyeiuxEbLABgMjP7W8UhQaZMN1Y/bX2jvx89l4Q8kNCs7HB6zQ3VtdNG\nRytulZ/0Xe+v+xuacJ/PyWorrB5Xob3Yw7mMm+audD8HFpuMjH22s9H78RpxZaO3cKPXS8yv3ob5\ngvkNOw6/YzZGDSi1tAbIetXs1DzXHnqvyrKMVRatMKWW1IIpZp4FYJZp2yTT9zstjp0GYJrH+nnC\nzn0qTKyEVxBp83KJKwRaoxk7heeR99dg+oIN1gV8YjeIFLdKNhHoGvS/PlmPLzZ+JzrE87V0SBhl\nB8KeXyvwCjEK96176lOE/ToPsV3MmCdjg8apj9iZNfSW86vgfbCqFgN7pLq5unGd1HMSfCiIYdTc\nzNi1vwGn//X9lH1Abk3GZgWZMt1YhQf2a7qJInYC8N43wtGcZSgsSO4SevJzr6YbqZj/Vs+r4NBz\nBWEzjALiqY/XhaIZpkzGisalMM1tEsJWtt/b/ZbCgcyF6aaZgQ3b6/BJdarh4sF3V2P45DnWGr0S\n9O7IlOnGikzmR81Wwsx+5ITdla0m/YoKvHWVJomJeBdyPmPov5dVcDfAn+nBscuy8GPsu1Y32cnM\n7+qsJ0xFgt7tG9EPHhKv8H1zmX1I8UwvmMo5lKDPfjLqimZzaStBb7bdyyKj0VvNwci3UfjPu+45\npsv5IFaCGnG6VbvdemA/2W6/yybhjkh2XPLkZ9J3SxSLppltKEEfMMf27ZyyLdcmU9NB0E4Jm3fJ\np+WzE1JWr/+eNXofN+r1yJ37/Pu1m4m/gcUXkKWW8dPtHAW9Yf8eU/C9+95c6fv6OiKNvr6xOZCk\nKE6n2FvfmHJvQRFJQZ+OEAhWiMLZ1uzw7tdrRb+ubQM/ZzoJ2nTzS4kJ4MS1rfdZKQkbbcLk2uFL\n0Eseaq6yOf5+EDT6XDjmFzkbvX9JH5b7KOB8D9W1e3HR4/7yNlgRSUGfyYzs+QIbZhijdElxbkeY\nfkcQP90Pbhaq2GlnVsJi1eY9wu1O+EnAHrR5xA+6X/hFT3yKP8760iKZjvd+Z/eblE+cKbXoMAhB\nL1yNDPm3K7sqyK1ADuftP1KCvl9p5rVcH8mGXJE9IsAbIvczP7hpD7uyQddLZjLWimxy1jJmWHr0\ng2qhOTJM/erlz1NDB5sJYt5HNEfT1Mz4P8nk9PamG+f6eVUonIiUoNefM9HIPnn8ENtjrz+9fyB1\nCNrPuL2F5p7FYTUyg4v2SKf5wa1G/+C7iYU2suaiZz8NPwZSEHHx7XA62+sS5qgg1gu0KxL3Nz12\nvx9kWiws01GkBL2OqK3sYmUEiZOgdzsOHNQhNRcokF2v9UHiNtG3F6xyz4ZBUzap5T5IEfQBP36Z\ndLc10r64VXgnl7jFsBakRUrQ67b57u2LUvbZhTmV4YzB3QEAvTu3sS3n9EOZF+Q4YbXKN0v6ReBc\n8uQC50I5hCipdK6xfnsdVm9JNikEfVfZ8jz7nfuyU8BkBrOwFntGS9Br/w85uEPKPlmNvm2h2F9a\nn4z60dFl6Gvj8eI0IdTapT+2VbWzpWNkC9naHEHkEs00oiimZntzfWMzfm+K/OmGbGmlVh7daHXs\nfm4p043S6J3RZaxICIrcHo3ox/z0uD7C/d8/4mAcU94JE0b0tj2Pk6AvKnAp6LNs8ZfCHRGx3KRg\n7mO/ffWLQM+XKfzWw27CVUajD8tjMFKCXsSI8tgCJlnTTaGFCn1ot3Z48coTUFpSZOtE5vRTuh2x\nrX74LOkXWcParXudC2WAXIhzJFrk54RZaL200NkrJhcIc+5LZhAJa8V4JAW98ceSidFhxO+A6jRq\nS1YjzpghPfD8Fcf5qJEik2TLJKMdizxMTgcdXTRrsjP5rIbd7y2Xp8Hf9a3I7VU3JkQLNuKZcSQd\n3K006KQf0IdK79YUc+XJ/YR1alfkLfaKIr3kQoRqL7GYPlsbbFqJLBHzvuvhd7wKSzGIpkZvaCt9\nhBSZbp64uCJxjPa/lRiWHWmdXv3cxMovKS6wHHi6tS9O+v7vXxwrfV5F+sgF0002kC0avd96iA7/\ntHobXlvyjZwQD6kZpAQ9EY0lopVEVEVEEy3K/JiIVhDRciJ61rC9iYgWa38zRMcGhUgm6j+cyDY+\ntGeHlHJWk6kDureLf7ZaVAE4T765WqZt86N3apPs72v3DHkNyKXwjyhRiCKVbHFOCkMj/8nUT3Dt\nc4sCSbHpFUcJQET5AKYAOAvAYAAXENFgU5n+iOWCHcnMQwBcb9i9j5mHa3/nBFd1a0Qavdm9cmCP\nEpSWFBnK6YI+9Xwv/PJ4tClMCPeHLzoaN50xQHxthyH5whG9pSe/7M7UtlDe6nbFqH7SZaPOqs3i\n5DBhcd30xWm9Xq6yN6SojW7xbbqx2fetRITVsAY8GVVvBIAqZq5m5noA0wGMN5W5HMAUZt4BAMwc\n/vJGSczZ63UmnjUwySyiDw4i04r5da5nx9a49rREyITzjuqZch4zJcUFWHfvOFw6shwTRvSyrfMl\nJ5SnbFt377ik67e28PcXEZZvbi7yyucbM10FhYBsWVjmW6H2654Zku1GRtD3BGCcYq/RthkZAGAA\nEX1ERJ8Q0VjDvmIiqtS2nyu6ABFdoZWprK11n7zYDisbvVn42T1nVg/hMeWdYsca9ludRr8aETl6\nADmZd2bfMAptTILe7gGJsi9+r87iEBFWPL8g/Lgwitxl2kdrfR1/oLHJ1/HZ7nVTAKA/gNEAygB8\nQERDmXkngD7MvJGI+gF4l4i+YOY1xoOZeSqAqQBQUVHh+VZ1Dd0o9Kxs9IeUtkv6flCH2ORmD9Mk\nJ5DIYGPmucuPQ2Mz45aXlqZcz6pugLNPv25lsjpXu6ICHNevS9I2O00kS5SlUHC70lgm3K1C4ZXf\n/Xe5r+PDmpSWEfQbARhtDWXaNiM1AD5l5gYAa4loFWKCfwEzbwQAZq4movcAHAlgDUJAF5/GttI/\nGwV99R/OTjHR/Oy4PujRoRhnDu6Om15ckrSvwcL9rCA/DwX5yREKrX4no1LdobV94CQrz5y5vxmN\n9dtjEfqGlXW0PYeR+iZ/WoYTJcUF2G2Tni1M3MYgV2Jekc1k0ka/AEB/IupLRIUAJgAwe8/8BzFt\nHkTUFTFTTjURdSKiIsP2kQBWBFT3FK7TQg2XG2LRNAm8aUSCNC+PMGZID6E7Y4ODFmg03cgsYT7+\nkC646xzrsMl58TeTZPp2bYuTB5Q6nl/nAi1cg1P9/ZLJOQDXgj5L3PgUChEZ0+iZuZGIrgEwG0A+\ngGnMvJyIJgOoZOYZ2r4ziWgFgCYANzPzNiI6AcCjRNSM2KByLzOHJujHDOmRNGkJJHvT3HXOEBzd\np1PS/vdvHu143gaHVS9Gl6jiVuKx0yiQiAgTRvTCHTOWC7Vh3abu5jcXFdXdKsNOTp7JOQC3K40V\nimwmozZ6Zp4FYJZp2yTDZwZwo/ZnLPMxgKH+q+kDreGICBcLvFn6dEmNRPnPy0Zg+mcbMPOLWLID\nJ0Fv3F1sYTM2x9ApKsjHi1cej8L8PIyf8lHSPi8KsmilrB4SOezk5KcP6o7nK4NdEi9LJhPBKxS5\nQuT1IV3bdiMOTupfit99L7FUwNF0I6HRi+LQH1PeGV1LUmPniyaVnTi6T2fc/6MjkralS6PvWlIY\n6vntcBvtTxluFC2RFiDoY/+71fyMJoHTB3ezLXvbuEHo3DYm7M46/CBhGauEI6JomV611POPLsOv\nDf79+rkbmprxbIghEkQJ0dOF27efuvpwJ6YV/rn73MMzXYXIEamgZiIGdC/B+u11aOMyCJjR7tyt\nJNXl0sghpe3w+e/OADNbaphW4Y9FA4Afa8TJA0rxoJbIuEIL0fyDo3rihEO7ej+pA61yaDJWkf1E\ned1Hpoi8Rv/AhOF49vJjHYW1GS+eJGYhf9/5w+KrXK00elEcmrGH9wCQ8Jpxg7HaZZ1aY92943DK\nYfZvJH6RjQwaBmrRb/TIlt/0f44XJyHKRSKv0bcrKsAJh7jXZt1EmbTijMHdccKhXfDUx+tw5pDu\nwjLmGDznHdUTA7qXYOXvx6KVB5NIJjRcv/l4/aA0+ugR5m9a3CoP+xvk5qysHCtykchr9F4J4vUx\nL49Q1qkNKm8/HVedfIj4OnmEEmM0TG1Ooagg39Ngk+zG6fpwT2TWRq8EfdQIQsmy4vyjyqTLRmnN\nhRL0FgSxCEjXdLu2K7L1DnnxquPjn/0+WpmQe60yaboJ6Ql+8pJjwjlxAIwbJp7wjwphviC2VMUg\nsoK+f7d2voReEA+El8Hi5yP7+rqmeWGWH2QFeLatjB10UPuk73/+4TDX581meXCMadFf1AjzeXKV\nDiI6Cn10Bf3s60eh6p6zPR8fpEYvy4Du7TC0rINzQRuC7CRWnkJmMmmjlxnMvHgc+R0kc5nZ14/K\n6PVDFfQuykZIzkdX0Oflka8HJohnTfb6oly3XnFb745trAOsWXkKmQnbRt++2NpnQPTSEYRtNVs8\nP9LNT4/tnfG3mTDdK90M4EqjbwH40ej0eDquV20G8GAFqYmaPYLMHN4zZiIRafRH+HwzMWJ3T2HZ\nXIMcfLOF/x070LEMI/ODXJiTsS3VRh9590q/9O/WzrmQiacuPQbf7HROG6bTs1MsecZVo8WeOU68\ndUPiVVu2j+TnEZocIig5mWSKC2LuZwUCtTrs+Do6okEgmAHT/zmyDRkTW6ztMnvzYZoC3Zw6rGxP\nmUBp9DbMuWEUXv3VSNfHlRS3wmE9SqTLtyuKpRk8z4Xrl5FyQ2A2WY3FaaL1JxW9HN8O9G4g6pj7\nGvyFGhhhyKtrVw3zpQ/uUOwpwbI5r24UBb2cpsyuhKHsPI4b0jkZa3cpZbppIfTvXoJ2Rdn/0mP1\nsNrZqju1sQ9E9qcfDnPscIl8vKmP0d4D7gS9V8FqHtievHREiqCXOfVvzx5kOiZakv7JS49Jms/o\nV5oatVXHjfnPaiGgH5xSbfrBfG9Rzr5mRAn6CGB8eBubEyYTKzn/v2MH4tWrR6K8Sxtce2p/cSE4\nv+bqph+jRq+n9rMTJCJSJuAkO6BRJgzv1RGH9SiR1sTKu7SxPm8Wy3mn25t3yykp24oK8nC2wf++\ntF1q1FQg9sy4ufffnHmY77YyK1MiOS8KFeKFbH9Tm37FcaGcV6r1iGgsEa0koioimmhR5sdEtIKI\nlhPRs4btFxPRau3v4qAqrkhgfHZlskldNfoQ9OhQjPduPgWDTT7nRpxe9XXN2Wijb1uUj+lXHIep\nPzvasR6y17KrRVLmMO2j7PyAneaay+6V7QWpKgmUFO/J6in5bl+DqwnL/DyKR271ivnNU6TRl9h4\nXrnBqFBUOKxHsPP2CgtzLuigcBT0RJQPYAqAswAMBnABEQ02lekP4FYAI5l5CIDrte2dAdwB4FgA\nIwDcQUTRXu2RAYz90mmC1YzdhJNTh9dfHoydh4hwXL8u6OhgGjLjdQIuWdDHPm/cuU/qWLsrZrOc\nd6qaqO4p2yx+9jeWfeulSr4wV0VsMgzmB9Hb4aT+XfHSVSfYlr36lEMDuWY2IKPRjwBQxczVzFwP\nYDqA8aYylwOYwsw7AICZt2jbxwCYw8zbtX1zAIwNpuoKHaP2aV4V6sRRvTthRHlnoRnDyZ85nqbR\n0DHtNC87ryK7a9m7VxrLWR1vebjUebMNo2AUCUU7MalHRLUd4AXnfNTmDS3oScsgJmPPOrwHhvfq\nmLLdzdtKSwtq1hOAMU9cjbbNyAAAA4joIyL6hIjGujgWRHQFEVUSUWVtba187RUp5OcRenZsLV2+\nuFU+XrjyeAw5ONXv3alPxE03eRSPDfP0pSPkK2vALFxkO3tSyAeXWp+VuSh2SnfnmnLhUa7KB4XI\ne0o0MOrbzjsq1v3sXvxEd14uSLkZOy88eTkZMR8uertzO1jffe7hOKhDamhy82kOFpSxQ+Ruffu4\nQbj3vKE4bWC44cD9ENRkbAGA/gBGA7gAwGNElDqcWsDMU5m5gpkrSktLA6pSy8WLBis6xknY6mai\nvDzCKQO7Yd2949Crs/UEpx3maxnt/sY90y6pSCpHSWYjl9e0OIAgp9EbVw7LXvvI3tLdwhLjpfRQ\n1sYFagSgk2nFs14/p2qaj9Oxaw+/nivmtwuR1u1Wyc8nEr5pmAfBV64Wu0+fPbSHcPtvxhyWsu0X\nJ/XDhBG98YSHQHjpMhHKCPqNAHoZvpdp24zUAJjBzA3MvBbAKsQEv8yxipBwo2jp/tC9O7fBi1fG\nomk6vebq5w9iybpZ0OcR4b+CNQynDuyOYQahZnTjdlsNq/J5RFKTsZcaks3LXjoIrwrjz1qQT6i6\n56wkgUUETPr+4NQDkbhnK9fb2L1bH5e6nXyHnDAfLvK6cf22ZlFhfbt+zR4WGv1DPxWbqoI256Rr\npa6MoF8AoD8R9SWiQgATAMwwlfkPYto8iKgrYqacagCzAZxJRJ20SdgztW2KEPHy7Nw2bhB+dlwf\nvH3jyThGS0HopEXpGq18TB95CvIoHoLBfD+U9Dl1Mjb1uvadPqU8ydX1rKHuwwUXFQQrKAry81CQ\nn5f0G4ju1/x+ZKWFNzazRXtZt4hfG7358CCEH+VZvaX6PnWgpCttouNtM3MjgGsQE9BfAniBmZcT\n0WQiOkcrNhvANiJaAWAugJuZeRszbwdwN2KDxQIAk7VtigBwcg9zQ5d2Rbj73MOTzBFmG/Zj/5Mw\nm3xwc8JXW7Zj2hUza4V5eWTQ7GwmYw1PsJ8E8EZkXSuH9+qIMwd3145xdWlHLjG8LZgxXkq0MtVO\nI49r9Bbnbm5m4fFWYznZnEuWlN/exRuFFaJn4VenHIKhZf5MZ0GL5XSZbqQcRZl5FoBZpm2TDJ8Z\nwI3an/nYaQCm+aumQsQzl41A7e4D0uWf/vkIV0vW7QQnUcJGb6XRXz36EDz03hqpa4km5MzXFwsg\nZxu9Vf2stKmyjq2lO2Ci2oSjenfE8Yd0Qf9uJZi/Zhuer9xgc6Q9dhPqZtONHGT4F5ZqeBOzUJh1\na289ael3MtaM6LkT1ckuLaDoJ795zEDMW+3P2SPohbTZZLpRZCltCgvQx8IbAkid5Dp5QCmOP0R+\nQYbTa2VTPASCeP/5RyfH7tFNAjedMSClbMrrex5JTcDJJFopLRGvArXyunn28lQ7+r8uOxbXnWa9\nipgoNrF385iBOPfInrj73MMty37229Pw0cRT8faNJ1uWkRWeogij9hq9ZqO2OF+jwabT1bB6Vo/H\nJDqvX0FvNiMJBb1g219+dITlOc1zDXbhuNNNb4PDQrrceJWgjyBBxWmxDSaWl/BqCEIrmXhWcgjd\ngrzEhKjeGX45KtUP39hR3Haaq0eLF8T06FCc0oYn9u+a1EF1rGScXSz/bu2L0bNjaxxqExlVdt7j\nHxcembLNTiPW/7eqd1Mzu7ZP+FXozQOFtCnQpqJEiXo9eMGRWHj7GUn7MxWZsl9p26SAh2GGZDaS\n/RG7FJ7x2wHNwsZoS21lCHPsd4HL2zeOwqHdStDYxPjtq1/EzknJphuRNgkka3puBhyr89lhd/og\nu+vpg7pJzRNcckI5BvZIXSBnd2TCRm9huklSr50fIILYjdEPeh1Liguwe38jgJhbqnnFs52wNr6N\nFhiSEAUdrO72cYNStnVpW4hte+tTtrcvLsA95w7FtI/Wxrcp040i49g9hMZ49m4fVnP31AXFhcf2\nxn3nD4uf37XpxlUt3CO+Tdb2BXd1v4LTNoYPEu6Fj1wkdiF0KwyDXjCVn0d46tJj8KYhpeFffnQE\nXrvmRNvjAKBru1joDWMbhBlu2NzWX909Fv+xCG0+45oTcfwhXZLqI5uX2S9K0CssMb9Wmpfen6+t\nsuwkGdRKShZqZYpa5SV8nu3qaDhnkMqR0M4tEIB6pw26u/rxTZfS6BkYe7h4UVCiDhLXonAmKEcf\n1i1pQrq4VX5KPmXRdV+9eiT+8qMjkJ8nXg8g4umfy6/mdvpdilvlW/aHRH1i5/jh0WVpC4OuBH0E\nCUrg2WnU+XmEG84YgK/uHuv6YbXrK+OHH4yfj+yLm8cMTBJKSRjNNUb/8ZBfg0WnD0rI/en8oUnf\nT+rvfYW4XT2d3CuBhClOZnEQIQyvG+/H9urcBj882l0Cn5MHlMbDawdBu6ICLJ50Bq482T5j3Jgh\n9gNtkChBH2H8dr/jbUKmFuTlgYhcrRS06r/GehYV5GPS9wejQ+tWUiahdJpu7PA6xlx4bG/84sS+\n+MkxvZPO5SZDWWpdyNH8ItJM2xcX4NnLj0XntoW4ecxh+OdlcpqujJx3E8pYdoJS9q1HZMs3Hxr0\n5GzHNoWhpkR0i5qMjSBlnVrj6211tp4fMlwxqh/++MZX8e/GzhFkujer/poQ4nahlBOfw84WpL8x\ndG1XiOc0F0y/y///8IOhzoUCIGFisv7d7j73cJxwSFcAwK9kQ/RKPgZunhbZOR9z0y+7a4xzPbJA\n9oZl7rNDCfoIMuXCo/BR1TZXUSxFEBE6tG6F7/Y1pOzzo62YtScrbcrtZGxDk7+E5M/8fETcy0NE\noTZxdliPEvTvHtO49Zqny3vCL/pqYF3YXDCiN577bL1l+ScvOQYfr9kayLWP79cF86u3OZbzqqlb\nmRBlJpdlx2tzsUKbyVSrR8JsRksHynQTQTq2KcS4Ye7jsIhIFraJx9yT/6/LJzu+uMemExqrYUyj\naMVr15yI5y0Ci40aUBpvN1FVizQzlfEy8bqF2GkP7lCMFZOdtVV7NO+geKyb2Pc/njcU3z/iYMuj\nThnYDbeNEwdIM55Phqd+LhfdsUBy9XaQUwNeTvWrUw5JMrk5kck8xErQK2zxo6ladcQU+6hFOZlL\nU5JG79xdh5Z1wLEe07UVaQLIOPlod8WLjpMXAskk33ibogK0KQzm5VtmMjYMiOQCus275RR0EKRC\nNNMqX95/36j567mMzx3e01xICuMvc/OYgbbm0Wx6x1OCXmFLoC6LFtudOqzd7pP6d41/brQx3fx9\nwnAM7ZmaXMUKkfalv8WIvExE9/b7c4e6uqYVXl6ezHHvzXZhv3MLOkGbH2TzGayYPNZRNot+w4M6\ntMbaP56NHx/TS3CEM0G0mt72YbimWqEEvcKWMBaepCyYsnjcrYSSsfse3rNDfIFKo81s7PjhPfHa\ntSda7pdBf7sxXsZJYM64ZqQrP20jfbT0jl5e+ft0aYt1947D0aYIp326tMXRfTrhXm1hWhCIMjml\nEuyI0Co/z7HtLZ8rwegUSkgEi1EwYe1Ln86vBL3Clsf/p8K5UEjI+sWXdYpNOo/zEB/e+tqp2/RI\nkbLp+/Tt7ieuY6LgGW2AGHKwuzzA1meMxeB5+aoT4jkH/EIAXrnaPsk2kNqexhzFfQT5iu1or+Ul\nDlI0h7F6VpluFDnDEb064ixtBWVmwkA5X7druyJ8OXksrhjVL2WfVyEpktvDyzri8pP64v4fD0/U\nTcJVzus8R58ubfHyVcfjD+d5d8FMh7A5qENr1668f/tJog2vkXXlRCzy57z/PRWA89uUG405nc+2\nVbWHlfk381mhBL0ibRjlXRfDAho/2pQuRFsX5qdo1YsnnYGXr3LWNvt1tQ71nHStPMJt4wYnua3q\nYZ97drJ2ZXW/5iBR/ug+nVMWpXlpL7tjEjZj98OCfsyq35+VtP1mQW5VK/Y3yrvFdmtfHJ+sDdTr\nJsyAOOZr6R8Mzf32jSfjVYv8tUEgJeiJaCwRrSSiKiKaKNh/CRHVEtFi7e8Xhn1Nhu3mFISKHOO+\nHw7DeUf1dC5oBzMW3HY6Bh1kr20Xt4o9nicPEIcDmDx+iK0m2bFNoePK3aV3nolZ152Usl1WG7zq\n5EPw4f+egkNK7UIOS50qFGRktx8PUatjzAuuzOWMg8qRvfxlfRo39CAsuO10X+cIQ8w7tT0hMVgZ\nI2yGgaPPFhHlA5gC4AzEkoAvIKIZzLzCVPR5Zr5GcIp9zDxcsF2RIxhjzvy4ohd+XOHNYyEpv6sh\nOqWVMtWmsADzbjkF3donJw7R6zPkYP+vuu2L/SWkyMsjlHWytzEHuZjq+0cc7MnTJZ0aqxt6dW6N\nwz16Jul3VFJcYJlcBgg3eqUdZmXBNsx1yDY2GefcEQCqmLk6ViGaDmA8ALOgV0SUoL0D9H535uAe\nWP7NrhRBbkTkbpelMssSpzcXWfQY+tM+XOtQMkHYnh2yAkov99lvT0NdfZNwtbVbmg1uin5xeqZO\n6t8V81ZvdaX6mxV0PcuVaNAN+5mWeansCcCY/LJG22bmfCJaSkQvEZFR5Ssmokoi+oSIzhVdgIiu\n0MpU1tb6y+moCA/3Lmgmt0jTg3/tqYdi0e/OQHebfKSZQo9rHgRuAr9FFX3A6da+GOWGORE/AxGL\njN2iawcwEHh5K7v0xL74cUUikmaJ6e0x7GirRoKyHr4GoJyZhwGYA+Bpw74+zFwB4EIADxBRSuxO\nZp7KzBXMXFFa6j08qyK3yMsj6Vj2RtLRP7q0K8Knvz0t/AsJcLTturn/kFfCehXUgWjh2v9Opu2g\nteW3bhiFf112rGO5dkUFuO+H1nltAcTnu7z0AzfICPqNAIwaepm2LQ4zb2PmA9rXxwEcbdi3Ufu/\nGsB7AFKTXCpaFH47Xqu89MxudmoTbufzipv2Syw6C+ba8289FfNuOcX1cVaC3Y/AZyfTTUgKwYDu\nJTjRsCLbLUaX3OtO64+v7h4rFfbBDzI9ZgGA/kTUl4gKAUwAkOQ9Q0TGlSrnAPhS296JiIq0z10B\njISy7eceDpOmLk/jeu5NVAAACiBJREFUm79NGI7LT+rr21vDiSwKJy6FXVo6W7Obi9/1oA6tk+dN\nPLZRJgN8eSGMt0giuM7p4BXHyVhmbiSiawDMBpAPYBozLyeiyQAqmXkGgF8T0TkAGgFsB3CJdvgg\nAI8SUTNig8q9Am8dRZYT9DPud7l5z46tbSMqBkU6bahusKrWuzeNxtqte6XKZgt+qucYYz8Ee1Uo\noRLSgFRIPGaeBWCWadskw+dbAdwqOO5jAOnJrKAIHbePeI8OyYuIsl3omMlWjd7qzapX5zYpXkq3\njB2I66cvxrAy57cfL7+P3TGnD+qOt7/cHCtnebyfydhYQ1j9Tp3axswhbQozOxneKp/wvWGJUNCZ\nGCxU4hFFaLQrKsC6e8ehfOJMAMD5R5dh+oINmOAihncmCVKjX3Db6dh7wDqpSVgc1bsTPvBgU/fD\nBSNiv+/jF1egZkcdTvzT3JQyQTStHlzO6nf67dmD0L9bCU4d2M3/xTS8mJxW33N20neZbF9BowS9\nInRev/ZE1Dc146AOrfGhFqekpVFaUmS7qAcATh/UDW9/ucXxXNn0ZmSsSmF+HuqbmnHnOQmz2kEd\nWuP0Qd1x1ejUOESAz8lYh/1tCgtw8Qnl3i8gvKZ/bXx4r474eM022/UjQaMEvcIRv5qt15WPLY0f\nVfSSEvTZumDslatPwOtLN6HQEPMhP4/w+MWpEVCbNHXcyayyeNIZlgllHL1uAiTIS9x05mH4/hEH\nY0B37wng3aIEvUKabF1GHxVysXmNSsDhPTtID+p19U0A4Jg5q6OEi2uuefDk51Fgq6VlUYJe4Uhu\ndSPgtIHd8O2u/Zmuhmdyqb2bbJK92FFXH5uvaOtjojRu6w6wwcYM6Y6RhyZ85N+/eTS+2bkfUz9Y\nE9xFMoAS9IrI8cQlckmoFTF82Z09HrpHm5huU+RdBOn1DtI76tGfJZuZ+nRpiz5d2sYFfS6+dQEq\nHr1CodDwYgLp0Mbbis5TB3bDiPLOuPlM+bj1Zpy8bhQJlKBXOKL6UXrQ45G3SnMA+ytPPgQlxQU4\nrl8w6QVlKCluhReuPD4pwJlX0vl45mpfUKYbhTS5+tqaK5xyWCmuGNUPvxSkRAyTYWUd8cWdY9J6\nzSDIxPOYq31ACXqFIzmqxATCT4/tjdMGBbfgxo6C/Dz89uxBablWFNBt9Okw3eS6eUiZbhTS5Gqc\nDz/c84OhOHVg90xXQyHgzMGx3+X7RxzkUFKhNHqFQpGTHNqtJJ51yy+Vt5+ORouFWVFACXqFI7n+\n2qpQONG1XfrCEWQCZbpRSJOrE1EKRVDkah9Qgl7hyMEdYzldO3r0mVYEy/DesZDDxhWcCoUdynSj\ncOS60wZg0EHtccph6fE+UdhzVO9OWDF5jGOcmDA5bWA3jBqg8jvnClIaPRGNJaKVRFRFRBMF+y8h\noloiWqz9/cKw72IiWq39XRxk5RXpobAgD98bdrCy1WcRmRTyQCzMRNAhgNv5CIcQNrn+5Du2LBHl\nA5gC4AwANQAWENEMQUrA55n5GtOxnQHcAaACsagYC7VjdwRSe4VCEQmW3TUmazN6AUBRq5hOnJ/N\nlbRBZggdAaCKmasBgIimAxgPuSTfYwDMYebt2rFzAIwF8Jy36ioUiiiSzdo8APz+3KEo79I2Z81V\nMqabngA2GL7XaNvMnE9ES4noJSLq5eZYIrqCiCqJqLK2tlay6gqFQpEeOrctxC1jB+asRh+U181r\nAMqZeRiAOQCednMwM09l5gpmrigtzc0RU6FQKLIVGUG/EUAvw/cybVscZt7GzAe0r48DOFr2WIVC\noVCEi4ygXwCgPxH1JaJCABMAzDAWICJjsIlzAHypfZ4N4Ewi6kREnQCcqW1TKBQKRZpwnAFh5kYi\nugYxAZ0PYBozLyeiyQAqmXkGgF8T0TkAGgFsB3CJdux2IrobscECACbrE7MKhUKhSA+UbQmfKyoq\nuLKyMtPVUCgUipyCiBYyc4VonwqBoFAoFBFHCXqFQqGIOErQKxQKRcTJOhs9EdUC+Nrj4V0BbA2w\nOlFCtY01qm3EqHaxJhvbpg8zCxciZZ2g9wMRVVpNRrR0VNtYo9pGjGoXa3KtbZTpRqFQKCKOEvQK\nhUIRcaIm6KdmugJZjGoba1TbiFHtYk1OtU2kbPQKhUKhSCVqGr1CoVAoTChBr1AoFBEnMoLeKa9t\nFCCiaUS0hYiWGbZ1JqI5Wk7eOVqUUFCMB7X2WEpERxmOEebxJaKjiegL7ZgHKYeSxBJRLyKaS0Qr\niGg5EV2nbW/R7UNExUT0GREt0drlLm17XyL6VLuX57XItCCiIu17lba/3HCuW7XtK4lojGF7Tvc9\nIsonokVE9Lr2PXptw8w5/4dYVM01APoBKASwBMDgTNcrhPscBeAoAMsM2+4DMFH7PBHAn7TPZwN4\nA7G8xscB+FTb3hlAtfZ/J+1zJ23fZ1pZ0o49K9P37KJtDgJwlPa5BMAqAINbevtodW2nfW4F4FPt\nHl4AMEHb/giAq7TPVwN4RPs8AbFc0NDacgmAIgB9tf6WH4W+B+BGAM8CeF37Hrm2iYpGH89ry8z1\nAPS8tpGCmT9ALAy0kfFIZPR6GsC5hu3PcIxPAHTU8gbE8/hyLEn7HABjtX3tmfkTjj29zxjOlfUw\n8yZm/lz7vBuxnAg90cLbR7u/PdrXVtofAzgVwEvadnO76O31EoDTtDeX8QCmM/MBZl4LoAqxfpfT\nfY+IygCMQyxhErR7jVzbREXQy+a1jSLdmXmT9vlbAN21z1ZtYre9RrA959BeqY9ETHtt8e2jmSYW\nA9iC2MC1BsBOZm7UihjvJX7/2v7vAHSB+/bKFR4AcAuAZu17F0SwbaIi6BWIaW+IaWstFiJqB+Bl\nANcz8y7jvpbaPszcxMzDEUvlOQLAwAxXKSsgou8B2MLMCzNdl7CJiqBvyblpN2tmBT2l4xZtu1Wb\n2G0vE2zPGYioFWJC/t/M/Iq2WbWPBjPvBDAXwPGImar0DHPGe4nfv7a/A4BtcN9eucBIAOcQ0TrE\nzCqnAvg7otg2mZ4ICeIPsZSI1YhNhOiTHkMyXa+Q7rUcyZOxf0byZON92udxSJ5s/Ezb3hnAWsQm\nGjtpnztr+8yTjWdn+n5dtAshZjd/wLS9RbcPgFIAHbXPrQHMA/A9AC8iecLxau3zr5A84fiC9nkI\nkiccqxGbbIxE3wMwGonJ2Mi1TcYbOMAf6mzEPC3WALgt0/UJ6R6fA7AJQANi9r7LELMRvgNgNYC3\nDUKJAEzR2uMLABWG8/wcsQmjKgCXGrZXAFimHfMPaCunc+EPwImImWWWAlis/Z3d0tsHwDAAi7R2\nWQZgkra9H2IDV5Um2Iq07cXa9yptfz/DuW7T7n0lDB5HUeh7JkEfubZRIRAUCoUi4kTFRq9QKBQK\nC5SgVygUioijBL1CoVBEHCXoFQqFIuIoQa9QKBQRRwl6hUKhiDhK0CsUCkXE+X9MUsO1gNlYOgAA\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGer6hJv7-zR",
        "colab_type": "code",
        "outputId": "0f1d4c99-b044-4a32-ce0a-ce0b70898cc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "plt.plot([i+1 for i in range((len(acc_list)))],acc_list)\n",
        "print(\"Accurancy:\")\n",
        "plt.show()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accurancy:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naDSaCkULgEaj0VQoWgA0Go2mQvn/AYEIb0kg8Y0dAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBTReWHxz4Ml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}