{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPf2BALinZKVt0UKdM3F0fG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamilo116/KNN/blob/master/KNN3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7ReM7FU-xs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import sys\n",
        "from random import shuffle\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "import timeit\n",
        "\n",
        "np.random.seed(4) \n",
        "torch.manual_seed(4) \n",
        "torch.cuda.manual_seed(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMOHez_kHZD6",
        "colab_type": "code",
        "outputId": "4b373ffd-b5d3-464f-8e74-de8f009c94bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYIMZ8QyYewD",
        "colab_type": "code",
        "outputId": "e2e499f5-1621-4f06-d2b3-73957097a5b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "! git clone https://github.com/wang-chen/kervolution.git \n",
        "\n",
        "sys.path.append(\"kervolution/\")\n",
        "from kervolution import Kerv2d\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'kervolution'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 53 (delta 2), reused 0 (delta 0), pack-reused 47\u001b[K\n",
            "Unpacking objects: 100% (53/53), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b8P1NdXfVdX",
        "colab_type": "code",
        "outputId": "7b7d6fed-1a1c-4bc6-d367-d236d9bcf878",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "MALIGNANT_DATASET = '/content/drive/My Drive/Colab_data/malignant/malignant/'\n",
        "BENIGN_DATASET = '/content/drive/My Drive/Colab_data/benign/benign/'\n",
        "DATA_FOLDER = '/content/drive/My Drive/Colab_data/'\n",
        "LIMIT_IMAGES_NUM = 700\n",
        "\n",
        "benign_file_list = sorted(os.listdir(BENIGN_DATASET))[:LIMIT_IMAGES_NUM]\n",
        "malignant_file_list = sorted(os.listdir(MALIGNANT_DATASET))[:LIMIT_IMAGES_NUM]\n",
        "shuffle(benign_file_list)\n",
        "shuffle(malignant_file_list)\n",
        "\n",
        "print(f\"Number of benign {len(benign_file_list)} images\")\n",
        "print(f\"Number of malignant {len(malignant_file_list)} images\")\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize((100, 100)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of benign 700 images\n",
            "Number of malignant 700 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGDQfal74BLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "benign_dict = {filename: 0 for filename in benign_file_list}\n",
        "malignant_dict = {filename: 1 for filename in malignant_file_list}\n",
        "img_class_dict = {**benign_dict , **malignant_dict}\n",
        "labeled_data = pd.Series(img_class_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvAAOqmVfVll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IsicDataset(Dataset):\n",
        "    def __init__(self, data_folder, labeled_data, \n",
        "                 transform=transforms.Compose([transforms.ToTensor()])):\n",
        "        self.labeled_data = labeled_data\n",
        "        self.transform = transform\n",
        "        self.data_folder = data_folder\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labeled_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        label = self.labeled_data[index]\n",
        "        if label == 0:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"benign\", \"benign\", index ))\n",
        "        else:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"malignant\", \"malignant\", index ))\n",
        "        image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "    @property\n",
        "    def labels(self):\n",
        "      return self.labeled_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSuYqjLAYrWA",
        "colab_type": "code",
        "outputId": "f74a95b8-7d7c-482a-aed8-109a2f1034b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        " \n",
        "dataset = IsicDataset(DATA_FOLDER, labeled_data, transform=data_transforms)\n",
        "print(dataset.labels)\n",
        "\n",
        "X_train, X_test = train_test_split(dataset.labels, test_size=0.2)\n",
        "print(\"number of training data: \",len(X_train))\n",
        "print(\"number of testing  data: \",len(X_test))\n",
        "\n",
        "train_sampler = SubsetRandomSampler(list(X_train.index))\n",
        "valid_sampler = SubsetRandomSampler(list(X_test.index))\n",
        "batch_size = 32\n",
        "num_workers = 0\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ISIC_0000409.jpeg    0\n",
            "ISIC_0000819.jpeg    0\n",
            "ISIC_0000988.jpeg    0\n",
            "ISIC_0000005.jpeg    0\n",
            "ISIC_0000886.jpeg    0\n",
            "                    ..\n",
            "ISIC_0000144.jpeg    1\n",
            "ISIC_0011286.jpeg    1\n",
            "ISIC_0011730.jpeg    1\n",
            "ISIC_0009934.jpeg    1\n",
            "ISIC_0010812.jpeg    1\n",
            "Length: 1400, dtype: int64\n",
            "number of training data:  1120\n",
            "number of testing  data:  280\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e8nFBR6Yug5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "def train(model, train_loader ,loss_fn, optimizer, num_epochs = 1):\n",
        "    total_loss =0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
        "        model.train()\n",
        "\n",
        "        for t, (x, y) in enumerate(train_loader):\n",
        "            x_var = Variable(x.type(gpu_dtype))\n",
        "            y_var = Variable(y.type(gpu_dtype).long())\n",
        "            scores = model(x_var)\n",
        "            loss = loss_fn(scores, y_var)\n",
        "            total_loss += loss.data\n",
        "            \n",
        "            if (t + 1) % print_every == 0:\n",
        "                avg_loss = total_loss/print_every\n",
        "                print('t = %d, avg_loss = %.4f' % (t + 1, avg_loss) )\n",
        "                avg_loss_list.append(avg_loss)\n",
        "                total_loss = 0\n",
        "                \n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        acc = check_accuracy(fixed_model_gpu, valid_loader)\n",
        "        print('acc = %f' %(acc))\n",
        "            \n",
        "def check_accuracy(model, loader):\n",
        "    print('Checking accuracy on test set')   \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval() \n",
        "    for x, y in loader:\n",
        "        x_var = Variable(x.type(gpu_dtype))\n",
        "\n",
        "        scores = model(x_var)\n",
        "        _, preds = scores.data.cpu().max(1)\n",
        "        num_correct += (preds == y).sum()\n",
        "        num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    acc_list.append(acc)\n",
        "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "    return acc\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggvpMu36Yw2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.size()\n",
        "        return x.view(N, -1)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgmexhBRZAK6",
        "colab_type": "code",
        "outputId": "4fde9e8f-cea5-4723-e9d9-facb95f94ef0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print_every = 1\n",
        "gpu_dtype = torch.cuda.FloatTensor\n",
        "\n",
        "out_1 = 64\n",
        "out_2 = 48\n",
        "out_3 = 32\n",
        "out_4 = 24\n",
        "out_5 = 16\n",
        "\n",
        "k_size_1 = 3\n",
        "padding_1 = 1\n",
        "in_channels = 3\n",
        "\n",
        "num_epochs = 50\n",
        "\n",
        "'''\n",
        "Kerv2d\n",
        "kervolution with following options:\n",
        "kernel_type: [linear, polynomial, gaussian, etc.]\n",
        "default is convolution:\n",
        "          kernel_type --> linear,\n",
        "balance, power, gamma is valid only when the kernel_type is specified\n",
        "if learnable_kernel = True,  they just be the initial value of learable parameters\n",
        "if learnable_kernel = False, they are the value of kernel_type's parameter\n",
        "the parameter [power] cannot be learned due to integer limitation\n",
        "balance: 0, 1\n",
        "power: 3, 4, 5\n",
        "gamma:\n",
        "'''\n",
        "fixed_model_base = nn.Sequential( \n",
        "                nn.Kerv2d(in_channels, out_1, padding= padding_1, kernel_size=k_size_1, \n",
        "                          stride=1, kernel_type='gaussian', learnable_kernel=True,\n",
        "                          kernel_regularizer=True, balance=0.5, power=3, gamma=0.5), \n",
        "                nn.BatchNorm2d(out_1),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Dropout(0.5),\n",
        "\n",
        "                nn.Conv2d(out_1 , out_2, padding= padding_1, kernel_size=k_size_1, stride=1), \n",
        "                nn.BatchNorm2d(out_2),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_2 , out_3, padding= padding_1, kernel_size=k_size_1, stride=1),  \n",
        "                nn.BatchNorm2d(out_3),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_3 , out_4, padding= padding_1, kernel_size=k_size_1, stride=1), \n",
        "                nn.BatchNorm2d(out_4),\n",
        "                nn.Conv2d(out_4 , out_5, padding= padding_1, kernel_size=k_size_1, stride=1), \n",
        "                nn.BatchNorm2d(out_5),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Dropout(0.6),\n",
        "                Flatten(),\n",
        "                nn.Linear(576,32),\n",
        "                nn.Linear(32,10),\n",
        "                nn.Linear(10,2)\n",
        "            )\n",
        "fixed_model_gpu = fixed_model_base.type(gpu_dtype)\n",
        "print(fixed_model_gpu)\n",
        "loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(fixed_model_gpu.parameters(), lr = 0.00011, weight_decay=0) \n",
        "\n",
        "train(fixed_model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs)\n",
        "check_accuracy(fixed_model_gpu, valid_loader)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Kerv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (3): Dropout(p=0.5, inplace=False)\n",
            "  (4): Conv2d(64, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (5): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (6): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (7): Conv2d(48, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (10): Conv2d(32, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (11): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (12): Conv2d(24, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (14): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (15): Dropout(p=0.6, inplace=False)\n",
            "  (16): Flatten()\n",
            "  (17): Linear(in_features=576, out_features=32, bias=True)\n",
            "  (18): Linear(in_features=32, out_features=10, bias=True)\n",
            "  (19): Linear(in_features=10, out_features=2, bias=True)\n",
            ")\n",
            "Starting epoch 1 / 50\n",
            "t = 1, avg_loss = 0.7611\n",
            "t = 2, avg_loss = 0.6637\n",
            "t = 3, avg_loss = 0.6614\n",
            "t = 4, avg_loss = 0.8026\n",
            "t = 5, avg_loss = 0.7652\n",
            "t = 6, avg_loss = 0.6733\n",
            "t = 7, avg_loss = 0.6364\n",
            "t = 8, avg_loss = 0.6162\n",
            "t = 9, avg_loss = 0.7507\n",
            "t = 10, avg_loss = 0.6446\n",
            "t = 11, avg_loss = 0.6644\n",
            "t = 12, avg_loss = 0.7705\n",
            "t = 13, avg_loss = 0.7001\n",
            "t = 14, avg_loss = 0.7185\n",
            "t = 15, avg_loss = 0.6892\n",
            "t = 16, avg_loss = 0.7652\n",
            "t = 17, avg_loss = 0.7350\n",
            "t = 18, avg_loss = 0.7191\n",
            "t = 19, avg_loss = 0.7111\n",
            "t = 20, avg_loss = 0.6840\n",
            "t = 21, avg_loss = 0.7123\n",
            "t = 22, avg_loss = 0.6358\n",
            "t = 23, avg_loss = 0.7273\n",
            "t = 24, avg_loss = 0.6905\n",
            "t = 25, avg_loss = 0.6657\n",
            "t = 26, avg_loss = 0.7469\n",
            "t = 27, avg_loss = 0.6388\n",
            "t = 28, avg_loss = 0.6946\n",
            "t = 29, avg_loss = 0.7309\n",
            "t = 30, avg_loss = 0.7197\n",
            "t = 31, avg_loss = 0.7001\n",
            "t = 32, avg_loss = 0.6693\n",
            "t = 33, avg_loss = 0.6054\n",
            "t = 34, avg_loss = 0.6000\n",
            "t = 35, avg_loss = 0.6056\n",
            "Checking accuracy on test set\n",
            "Got 149 / 280 correct (53.21)\n",
            "acc = 0.532143\n",
            "Starting epoch 2 / 50\n",
            "t = 1, avg_loss = 0.6656\n",
            "t = 2, avg_loss = 0.6066\n",
            "t = 3, avg_loss = 0.6673\n",
            "t = 4, avg_loss = 0.6782\n",
            "t = 5, avg_loss = 0.6277\n",
            "t = 6, avg_loss = 0.6250\n",
            "t = 7, avg_loss = 0.6813\n",
            "t = 8, avg_loss = 0.6202\n",
            "t = 9, avg_loss = 0.6288\n",
            "t = 10, avg_loss = 0.6191\n",
            "t = 11, avg_loss = 0.6322\n",
            "t = 12, avg_loss = 0.6443\n",
            "t = 13, avg_loss = 0.7399\n",
            "t = 14, avg_loss = 0.6784\n",
            "t = 15, avg_loss = 0.6927\n",
            "t = 16, avg_loss = 0.6332\n",
            "t = 17, avg_loss = 0.7401\n",
            "t = 18, avg_loss = 0.6922\n",
            "t = 19, avg_loss = 0.6447\n",
            "t = 20, avg_loss = 0.6050\n",
            "t = 21, avg_loss = 0.6666\n",
            "t = 22, avg_loss = 0.6840\n",
            "t = 23, avg_loss = 0.5782\n",
            "t = 24, avg_loss = 0.6848\n",
            "t = 25, avg_loss = 0.7024\n",
            "t = 26, avg_loss = 0.6604\n",
            "t = 27, avg_loss = 0.6717\n",
            "t = 28, avg_loss = 0.7200\n",
            "t = 29, avg_loss = 0.6449\n",
            "t = 30, avg_loss = 0.6684\n",
            "t = 31, avg_loss = 0.6922\n",
            "t = 32, avg_loss = 0.6611\n",
            "t = 33, avg_loss = 0.6635\n",
            "t = 34, avg_loss = 0.5708\n",
            "t = 35, avg_loss = 0.6834\n",
            "Checking accuracy on test set\n",
            "Got 183 / 280 correct (65.36)\n",
            "acc = 0.653571\n",
            "Starting epoch 3 / 50\n",
            "t = 1, avg_loss = 0.6345\n",
            "t = 2, avg_loss = 0.7037\n",
            "t = 3, avg_loss = 0.5837\n",
            "t = 4, avg_loss = 0.7136\n",
            "t = 5, avg_loss = 0.6557\n",
            "t = 6, avg_loss = 0.6313\n",
            "t = 7, avg_loss = 0.7262\n",
            "t = 8, avg_loss = 0.6386\n",
            "t = 9, avg_loss = 0.6346\n",
            "t = 10, avg_loss = 0.6040\n",
            "t = 11, avg_loss = 0.7051\n",
            "t = 12, avg_loss = 0.5892\n",
            "t = 13, avg_loss = 0.6021\n",
            "t = 14, avg_loss = 0.6487\n",
            "t = 15, avg_loss = 0.7507\n",
            "t = 16, avg_loss = 0.6850\n",
            "t = 17, avg_loss = 0.7676\n",
            "t = 18, avg_loss = 0.6199\n",
            "t = 19, avg_loss = 0.6508\n",
            "t = 20, avg_loss = 0.6329\n",
            "t = 21, avg_loss = 0.6920\n",
            "t = 22, avg_loss = 0.7287\n",
            "t = 23, avg_loss = 0.6930\n",
            "t = 24, avg_loss = 0.6765\n",
            "t = 25, avg_loss = 0.6738\n",
            "t = 26, avg_loss = 0.5653\n",
            "t = 27, avg_loss = 0.6093\n",
            "t = 28, avg_loss = 0.5721\n",
            "t = 29, avg_loss = 0.6061\n",
            "t = 30, avg_loss = 0.6226\n",
            "t = 31, avg_loss = 0.6566\n",
            "t = 32, avg_loss = 0.7294\n",
            "t = 33, avg_loss = 0.6796\n",
            "t = 34, avg_loss = 0.6313\n",
            "t = 35, avg_loss = 0.5580\n",
            "Checking accuracy on test set\n",
            "Got 184 / 280 correct (65.71)\n",
            "acc = 0.657143\n",
            "Starting epoch 4 / 50\n",
            "t = 1, avg_loss = 0.5580\n",
            "t = 2, avg_loss = 0.6592\n",
            "t = 3, avg_loss = 0.5191\n",
            "t = 4, avg_loss = 0.7500\n",
            "t = 5, avg_loss = 0.6292\n",
            "t = 6, avg_loss = 0.5462\n",
            "t = 7, avg_loss = 0.5528\n",
            "t = 8, avg_loss = 0.6505\n",
            "t = 9, avg_loss = 0.6809\n",
            "t = 10, avg_loss = 0.7175\n",
            "t = 11, avg_loss = 0.6824\n",
            "t = 12, avg_loss = 0.7438\n",
            "t = 13, avg_loss = 0.8130\n",
            "t = 14, avg_loss = 0.5619\n",
            "t = 15, avg_loss = 0.6520\n",
            "t = 16, avg_loss = 0.6121\n",
            "t = 17, avg_loss = 0.6422\n",
            "t = 18, avg_loss = 0.5563\n",
            "t = 19, avg_loss = 0.5710\n",
            "t = 20, avg_loss = 0.5691\n",
            "t = 21, avg_loss = 0.5991\n",
            "t = 22, avg_loss = 0.6027\n",
            "t = 23, avg_loss = 0.6515\n",
            "t = 24, avg_loss = 0.5917\n",
            "t = 25, avg_loss = 0.5551\n",
            "t = 26, avg_loss = 0.6264\n",
            "t = 27, avg_loss = 0.5481\n",
            "t = 28, avg_loss = 0.6289\n",
            "t = 29, avg_loss = 0.7383\n",
            "t = 30, avg_loss = 0.6552\n",
            "t = 31, avg_loss = 0.6598\n",
            "t = 32, avg_loss = 0.6038\n",
            "t = 33, avg_loss = 0.7082\n",
            "t = 34, avg_loss = 0.6412\n",
            "t = 35, avg_loss = 0.6241\n",
            "Checking accuracy on test set\n",
            "Got 184 / 280 correct (65.71)\n",
            "acc = 0.657143\n",
            "Starting epoch 5 / 50\n",
            "t = 1, avg_loss = 0.6264\n",
            "t = 2, avg_loss = 0.7609\n",
            "t = 3, avg_loss = 0.5671\n",
            "t = 4, avg_loss = 0.5873\n",
            "t = 5, avg_loss = 0.5925\n",
            "t = 6, avg_loss = 0.5676\n",
            "t = 7, avg_loss = 0.6838\n",
            "t = 8, avg_loss = 0.6055\n",
            "t = 9, avg_loss = 0.5821\n",
            "t = 10, avg_loss = 0.7596\n",
            "t = 11, avg_loss = 0.6017\n",
            "t = 12, avg_loss = 0.5715\n",
            "t = 13, avg_loss = 0.5517\n",
            "t = 14, avg_loss = 0.6986\n",
            "t = 15, avg_loss = 0.6415\n",
            "t = 16, avg_loss = 0.5424\n",
            "t = 17, avg_loss = 0.6106\n",
            "t = 18, avg_loss = 0.6779\n",
            "t = 19, avg_loss = 0.7068\n",
            "t = 20, avg_loss = 0.6381\n",
            "t = 21, avg_loss = 0.6985\n",
            "t = 22, avg_loss = 0.6032\n",
            "t = 23, avg_loss = 0.6520\n",
            "t = 24, avg_loss = 0.6446\n",
            "t = 25, avg_loss = 0.6904\n",
            "t = 26, avg_loss = 0.6964\n",
            "t = 27, avg_loss = 0.5627\n",
            "t = 28, avg_loss = 0.6708\n",
            "t = 29, avg_loss = 0.6205\n",
            "t = 30, avg_loss = 0.6701\n",
            "t = 31, avg_loss = 0.5826\n",
            "t = 32, avg_loss = 0.6579\n",
            "t = 33, avg_loss = 0.5149\n",
            "t = 34, avg_loss = 0.7431\n",
            "t = 35, avg_loss = 0.5993\n",
            "Checking accuracy on test set\n",
            "Got 175 / 280 correct (62.50)\n",
            "acc = 0.625000\n",
            "Starting epoch 6 / 50\n",
            "t = 1, avg_loss = 0.6984\n",
            "t = 2, avg_loss = 0.5264\n",
            "t = 3, avg_loss = 0.6204\n",
            "t = 4, avg_loss = 0.5728\n",
            "t = 5, avg_loss = 0.5278\n",
            "t = 6, avg_loss = 0.6917\n",
            "t = 7, avg_loss = 0.6138\n",
            "t = 8, avg_loss = 0.5611\n",
            "t = 9, avg_loss = 0.6666\n",
            "t = 10, avg_loss = 0.7716\n",
            "t = 11, avg_loss = 0.7266\n",
            "t = 12, avg_loss = 0.6407\n",
            "t = 13, avg_loss = 0.6387\n",
            "t = 14, avg_loss = 0.6505\n",
            "t = 15, avg_loss = 0.4835\n",
            "t = 16, avg_loss = 0.6776\n",
            "t = 17, avg_loss = 0.6046\n",
            "t = 18, avg_loss = 0.6140\n",
            "t = 19, avg_loss = 0.7381\n",
            "t = 20, avg_loss = 0.6262\n",
            "t = 21, avg_loss = 0.7085\n",
            "t = 22, avg_loss = 0.6465\n",
            "t = 23, avg_loss = 0.6160\n",
            "t = 24, avg_loss = 0.6164\n",
            "t = 25, avg_loss = 0.6281\n",
            "t = 26, avg_loss = 0.5940\n",
            "t = 27, avg_loss = 0.6520\n",
            "t = 28, avg_loss = 0.6391\n",
            "t = 29, avg_loss = 0.7190\n",
            "t = 30, avg_loss = 0.6461\n",
            "t = 31, avg_loss = 0.5826\n",
            "t = 32, avg_loss = 0.6850\n",
            "t = 33, avg_loss = 0.6117\n",
            "t = 34, avg_loss = 0.7520\n",
            "t = 35, avg_loss = 0.6484\n",
            "Checking accuracy on test set\n",
            "Got 187 / 280 correct (66.79)\n",
            "acc = 0.667857\n",
            "Starting epoch 7 / 50\n",
            "t = 1, avg_loss = 0.7092\n",
            "t = 2, avg_loss = 0.6698\n",
            "t = 3, avg_loss = 0.5143\n",
            "t = 4, avg_loss = 0.6396\n",
            "t = 5, avg_loss = 0.6746\n",
            "t = 6, avg_loss = 0.6206\n",
            "t = 7, avg_loss = 0.5179\n",
            "t = 8, avg_loss = 0.6873\n",
            "t = 9, avg_loss = 0.6388\n",
            "t = 10, avg_loss = 0.6341\n",
            "t = 11, avg_loss = 0.6917\n",
            "t = 12, avg_loss = 0.6100\n",
            "t = 13, avg_loss = 0.6454\n",
            "t = 14, avg_loss = 0.6640\n",
            "t = 15, avg_loss = 0.5920\n",
            "t = 16, avg_loss = 0.7302\n",
            "t = 17, avg_loss = 0.6581\n",
            "t = 18, avg_loss = 0.8041\n",
            "t = 19, avg_loss = 0.6384\n",
            "t = 20, avg_loss = 0.6016\n",
            "t = 21, avg_loss = 0.6294\n",
            "t = 22, avg_loss = 0.6963\n",
            "t = 23, avg_loss = 0.6636\n",
            "t = 24, avg_loss = 0.6103\n",
            "t = 25, avg_loss = 0.6677\n",
            "t = 26, avg_loss = 0.6573\n",
            "t = 27, avg_loss = 0.5230\n",
            "t = 28, avg_loss = 0.6543\n",
            "t = 29, avg_loss = 0.5744\n",
            "t = 30, avg_loss = 0.6218\n",
            "t = 31, avg_loss = 0.6637\n",
            "t = 32, avg_loss = 0.5570\n",
            "t = 33, avg_loss = 0.6601\n",
            "t = 34, avg_loss = 0.5874\n",
            "t = 35, avg_loss = 0.6294\n",
            "Checking accuracy on test set\n",
            "Got 194 / 280 correct (69.29)\n",
            "acc = 0.692857\n",
            "Starting epoch 8 / 50\n",
            "t = 1, avg_loss = 0.5920\n",
            "t = 2, avg_loss = 0.6377\n",
            "t = 3, avg_loss = 0.6234\n",
            "t = 4, avg_loss = 0.5598\n",
            "t = 5, avg_loss = 0.5839\n",
            "t = 6, avg_loss = 0.6012\n",
            "t = 7, avg_loss = 0.5558\n",
            "t = 8, avg_loss = 0.6714\n",
            "t = 9, avg_loss = 0.5927\n",
            "t = 10, avg_loss = 0.5853\n",
            "t = 11, avg_loss = 0.6328\n",
            "t = 12, avg_loss = 0.7668\n",
            "t = 13, avg_loss = 0.6792\n",
            "t = 14, avg_loss = 0.6844\n",
            "t = 15, avg_loss = 0.5660\n",
            "t = 16, avg_loss = 0.6334\n",
            "t = 17, avg_loss = 0.7596\n",
            "t = 18, avg_loss = 0.6641\n",
            "t = 19, avg_loss = 0.6597\n",
            "t = 20, avg_loss = 0.4973\n",
            "t = 21, avg_loss = 0.5773\n",
            "t = 22, avg_loss = 0.5124\n",
            "t = 23, avg_loss = 0.6537\n",
            "t = 24, avg_loss = 0.6359\n",
            "t = 25, avg_loss = 0.7492\n",
            "t = 26, avg_loss = 0.6435\n",
            "t = 27, avg_loss = 0.6085\n",
            "t = 28, avg_loss = 0.6085\n",
            "t = 29, avg_loss = 0.6779\n",
            "t = 30, avg_loss = 0.6439\n",
            "t = 31, avg_loss = 0.5824\n",
            "t = 32, avg_loss = 0.5789\n",
            "t = 33, avg_loss = 0.7184\n",
            "t = 34, avg_loss = 0.6757\n",
            "t = 35, avg_loss = 0.5760\n",
            "Checking accuracy on test set\n",
            "Got 177 / 280 correct (63.21)\n",
            "acc = 0.632143\n",
            "Starting epoch 9 / 50\n",
            "t = 1, avg_loss = 0.5968\n",
            "t = 2, avg_loss = 0.6501\n",
            "t = 3, avg_loss = 0.6633\n",
            "t = 4, avg_loss = 0.6738\n",
            "t = 5, avg_loss = 0.6430\n",
            "t = 6, avg_loss = 0.7267\n",
            "t = 7, avg_loss = 0.6808\n",
            "t = 8, avg_loss = 0.6140\n",
            "t = 9, avg_loss = 0.6503\n",
            "t = 10, avg_loss = 0.6081\n",
            "t = 11, avg_loss = 0.6170\n",
            "t = 12, avg_loss = 0.5909\n",
            "t = 13, avg_loss = 0.6433\n",
            "t = 14, avg_loss = 0.6115\n",
            "t = 15, avg_loss = 0.7940\n",
            "t = 16, avg_loss = 0.6234\n",
            "t = 17, avg_loss = 0.6642\n",
            "t = 18, avg_loss = 0.6423\n",
            "t = 19, avg_loss = 0.5462\n",
            "t = 20, avg_loss = 0.5542\n",
            "t = 21, avg_loss = 0.6204\n",
            "t = 22, avg_loss = 0.6345\n",
            "t = 23, avg_loss = 0.5990\n",
            "t = 24, avg_loss = 0.5864\n",
            "t = 25, avg_loss = 0.5566\n",
            "t = 26, avg_loss = 0.6228\n",
            "t = 27, avg_loss = 0.6234\n",
            "t = 28, avg_loss = 0.5683\n",
            "t = 29, avg_loss = 0.7822\n",
            "t = 30, avg_loss = 0.6706\n",
            "t = 31, avg_loss = 0.6900\n",
            "t = 32, avg_loss = 0.5418\n",
            "t = 33, avg_loss = 0.6349\n",
            "t = 34, avg_loss = 0.6199\n",
            "t = 35, avg_loss = 0.6460\n",
            "Checking accuracy on test set\n",
            "Got 193 / 280 correct (68.93)\n",
            "acc = 0.689286\n",
            "Starting epoch 10 / 50\n",
            "t = 1, avg_loss = 0.6463\n",
            "t = 2, avg_loss = 0.5906\n",
            "t = 3, avg_loss = 0.6005\n",
            "t = 4, avg_loss = 0.6585\n",
            "t = 5, avg_loss = 0.6576\n",
            "t = 6, avg_loss = 0.6172\n",
            "t = 7, avg_loss = 0.6603\n",
            "t = 8, avg_loss = 0.6961\n",
            "t = 9, avg_loss = 0.7118\n",
            "t = 10, avg_loss = 0.6704\n",
            "t = 11, avg_loss = 0.6705\n",
            "t = 12, avg_loss = 0.6599\n",
            "t = 13, avg_loss = 0.6254\n",
            "t = 14, avg_loss = 0.5255\n",
            "t = 15, avg_loss = 0.5051\n",
            "t = 16, avg_loss = 0.5904\n",
            "t = 17, avg_loss = 0.6363\n",
            "t = 18, avg_loss = 0.6005\n",
            "t = 19, avg_loss = 0.5860\n",
            "t = 20, avg_loss = 0.7124\n",
            "t = 21, avg_loss = 0.5116\n",
            "t = 22, avg_loss = 0.5474\n",
            "t = 23, avg_loss = 0.5834\n",
            "t = 24, avg_loss = 0.8093\n",
            "t = 25, avg_loss = 0.5367\n",
            "t = 26, avg_loss = 0.6508\n",
            "t = 27, avg_loss = 0.6416\n",
            "t = 28, avg_loss = 0.6985\n",
            "t = 29, avg_loss = 0.6218\n",
            "t = 30, avg_loss = 0.7987\n",
            "t = 31, avg_loss = 0.5767\n",
            "t = 32, avg_loss = 0.6645\n",
            "t = 33, avg_loss = 0.5508\n",
            "t = 34, avg_loss = 0.6084\n",
            "t = 35, avg_loss = 0.6609\n",
            "Checking accuracy on test set\n",
            "Got 185 / 280 correct (66.07)\n",
            "acc = 0.660714\n",
            "Starting epoch 11 / 50\n",
            "t = 1, avg_loss = 0.5479\n",
            "t = 2, avg_loss = 0.5614\n",
            "t = 3, avg_loss = 0.5698\n",
            "t = 4, avg_loss = 0.5884\n",
            "t = 5, avg_loss = 0.6690\n",
            "t = 6, avg_loss = 0.6898\n",
            "t = 7, avg_loss = 0.4996\n",
            "t = 8, avg_loss = 0.6526\n",
            "t = 9, avg_loss = 0.5841\n",
            "t = 10, avg_loss = 0.6695\n",
            "t = 11, avg_loss = 0.7314\n",
            "t = 12, avg_loss = 0.5513\n",
            "t = 13, avg_loss = 0.6416\n",
            "t = 14, avg_loss = 0.6981\n",
            "t = 15, avg_loss = 0.6648\n",
            "t = 16, avg_loss = 0.5431\n",
            "t = 17, avg_loss = 0.6370\n",
            "t = 18, avg_loss = 0.7124\n",
            "t = 19, avg_loss = 0.5322\n",
            "t = 20, avg_loss = 0.5877\n",
            "t = 21, avg_loss = 0.6299\n",
            "t = 22, avg_loss = 0.6051\n",
            "t = 23, avg_loss = 0.6542\n",
            "t = 24, avg_loss = 0.5766\n",
            "t = 25, avg_loss = 0.6643\n",
            "t = 26, avg_loss = 0.6455\n",
            "t = 27, avg_loss = 0.6268\n",
            "t = 28, avg_loss = 0.6062\n",
            "t = 29, avg_loss = 0.6197\n",
            "t = 30, avg_loss = 0.6057\n",
            "t = 31, avg_loss = 0.5789\n",
            "t = 32, avg_loss = 0.7319\n",
            "t = 33, avg_loss = 0.6972\n",
            "t = 34, avg_loss = 0.5900\n",
            "t = 35, avg_loss = 0.6305\n",
            "Checking accuracy on test set\n",
            "Got 183 / 280 correct (65.36)\n",
            "acc = 0.653571\n",
            "Starting epoch 12 / 50\n",
            "t = 1, avg_loss = 0.6320\n",
            "t = 2, avg_loss = 0.5665\n",
            "t = 3, avg_loss = 0.6203\n",
            "t = 4, avg_loss = 0.6207\n",
            "t = 5, avg_loss = 0.7707\n",
            "t = 6, avg_loss = 0.5806\n",
            "t = 7, avg_loss = 0.6608\n",
            "t = 8, avg_loss = 0.5280\n",
            "t = 9, avg_loss = 0.5413\n",
            "t = 10, avg_loss = 0.5241\n",
            "t = 11, avg_loss = 0.6286\n",
            "t = 12, avg_loss = 0.6156\n",
            "t = 13, avg_loss = 0.5781\n",
            "t = 14, avg_loss = 0.6837\n",
            "t = 15, avg_loss = 0.6691\n",
            "t = 16, avg_loss = 0.5989\n",
            "t = 17, avg_loss = 0.7418\n",
            "t = 18, avg_loss = 0.6362\n",
            "t = 19, avg_loss = 0.5879\n",
            "t = 20, avg_loss = 0.6485\n",
            "t = 21, avg_loss = 0.5355\n",
            "t = 22, avg_loss = 0.6733\n",
            "t = 23, avg_loss = 0.6284\n",
            "t = 24, avg_loss = 0.7005\n",
            "t = 25, avg_loss = 0.6125\n",
            "t = 26, avg_loss = 0.6705\n",
            "t = 27, avg_loss = 0.5741\n",
            "t = 28, avg_loss = 0.7163\n",
            "t = 29, avg_loss = 0.7202\n",
            "t = 30, avg_loss = 0.6923\n",
            "t = 31, avg_loss = 0.6146\n",
            "t = 32, avg_loss = 0.6419\n",
            "t = 33, avg_loss = 0.6222\n",
            "t = 34, avg_loss = 0.5848\n",
            "t = 35, avg_loss = 0.4861\n",
            "Checking accuracy on test set\n",
            "Got 191 / 280 correct (68.21)\n",
            "acc = 0.682143\n",
            "Starting epoch 13 / 50\n",
            "t = 1, avg_loss = 0.6910\n",
            "t = 2, avg_loss = 0.6825\n",
            "t = 3, avg_loss = 0.6188\n",
            "t = 4, avg_loss = 0.6326\n",
            "t = 5, avg_loss = 0.6218\n",
            "t = 6, avg_loss = 0.6936\n",
            "t = 7, avg_loss = 0.6517\n",
            "t = 8, avg_loss = 0.5599\n",
            "t = 9, avg_loss = 0.6471\n",
            "t = 10, avg_loss = 0.6454\n",
            "t = 11, avg_loss = 0.6413\n",
            "t = 12, avg_loss = 0.6146\n",
            "t = 13, avg_loss = 0.6380\n",
            "t = 14, avg_loss = 0.8262\n",
            "t = 15, avg_loss = 0.5886\n",
            "t = 16, avg_loss = 0.6289\n",
            "t = 17, avg_loss = 0.5475\n",
            "t = 18, avg_loss = 0.6507\n",
            "t = 19, avg_loss = 0.5315\n",
            "t = 20, avg_loss = 0.6671\n",
            "t = 21, avg_loss = 0.5976\n",
            "t = 22, avg_loss = 0.5572\n",
            "t = 23, avg_loss = 0.6737\n",
            "t = 24, avg_loss = 0.6595\n",
            "t = 25, avg_loss = 0.5610\n",
            "t = 26, avg_loss = 0.6501\n",
            "t = 27, avg_loss = 0.6491\n",
            "t = 28, avg_loss = 0.6265\n",
            "t = 29, avg_loss = 0.5703\n",
            "t = 30, avg_loss = 0.5230\n",
            "t = 31, avg_loss = 0.6395\n",
            "t = 32, avg_loss = 0.5900\n",
            "t = 33, avg_loss = 0.6077\n",
            "t = 34, avg_loss = 0.6121\n",
            "t = 35, avg_loss = 0.6104\n",
            "Checking accuracy on test set\n",
            "Got 194 / 280 correct (69.29)\n",
            "acc = 0.692857\n",
            "Starting epoch 14 / 50\n",
            "t = 1, avg_loss = 0.7888\n",
            "t = 2, avg_loss = 0.7307\n",
            "t = 3, avg_loss = 0.5885\n",
            "t = 4, avg_loss = 0.6137\n",
            "t = 5, avg_loss = 0.6341\n",
            "t = 6, avg_loss = 0.5725\n",
            "t = 7, avg_loss = 0.5893\n",
            "t = 8, avg_loss = 0.6348\n",
            "t = 9, avg_loss = 0.6419\n",
            "t = 10, avg_loss = 0.5887\n",
            "t = 11, avg_loss = 0.7112\n",
            "t = 12, avg_loss = 0.5905\n",
            "t = 13, avg_loss = 0.5692\n",
            "t = 14, avg_loss = 0.6218\n",
            "t = 15, avg_loss = 0.6307\n",
            "t = 16, avg_loss = 0.7118\n",
            "t = 17, avg_loss = 0.6660\n",
            "t = 18, avg_loss = 0.6286\n",
            "t = 19, avg_loss = 0.6232\n",
            "t = 20, avg_loss = 0.6731\n",
            "t = 21, avg_loss = 0.5819\n",
            "t = 22, avg_loss = 0.5740\n",
            "t = 23, avg_loss = 0.5926\n",
            "t = 24, avg_loss = 0.4645\n",
            "t = 25, avg_loss = 0.5894\n",
            "t = 26, avg_loss = 0.6254\n",
            "t = 27, avg_loss = 0.5716\n",
            "t = 28, avg_loss = 0.5825\n",
            "t = 29, avg_loss = 0.6406\n",
            "t = 30, avg_loss = 0.5399\n",
            "t = 31, avg_loss = 0.6478\n",
            "t = 32, avg_loss = 0.6730\n",
            "t = 33, avg_loss = 0.7524\n",
            "t = 34, avg_loss = 0.5320\n",
            "t = 35, avg_loss = 0.7261\n",
            "Checking accuracy on test set\n",
            "Got 183 / 280 correct (65.36)\n",
            "acc = 0.653571\n",
            "Starting epoch 15 / 50\n",
            "t = 1, avg_loss = 0.6483\n",
            "t = 2, avg_loss = 0.7065\n",
            "t = 3, avg_loss = 0.6470\n",
            "t = 4, avg_loss = 0.6865\n",
            "t = 5, avg_loss = 0.6533\n",
            "t = 6, avg_loss = 0.5522\n",
            "t = 7, avg_loss = 0.6936\n",
            "t = 8, avg_loss = 0.5783\n",
            "t = 9, avg_loss = 0.6402\n",
            "t = 10, avg_loss = 0.6640\n",
            "t = 11, avg_loss = 0.6629\n",
            "t = 12, avg_loss = 0.6056\n",
            "t = 13, avg_loss = 0.6651\n",
            "t = 14, avg_loss = 0.5733\n",
            "t = 15, avg_loss = 0.6286\n",
            "t = 16, avg_loss = 0.7425\n",
            "t = 17, avg_loss = 0.5681\n",
            "t = 18, avg_loss = 0.5284\n",
            "t = 19, avg_loss = 0.7042\n",
            "t = 20, avg_loss = 0.5387\n",
            "t = 21, avg_loss = 0.6586\n",
            "t = 22, avg_loss = 0.5452\n",
            "t = 23, avg_loss = 0.5074\n",
            "t = 24, avg_loss = 0.5893\n",
            "t = 25, avg_loss = 0.6636\n",
            "t = 26, avg_loss = 0.6085\n",
            "t = 27, avg_loss = 0.6221\n",
            "t = 28, avg_loss = 0.6152\n",
            "t = 29, avg_loss = 0.7327\n",
            "t = 30, avg_loss = 0.5688\n",
            "t = 31, avg_loss = 0.5616\n",
            "t = 32, avg_loss = 0.6487\n",
            "t = 33, avg_loss = 0.5759\n",
            "t = 34, avg_loss = 0.7264\n",
            "t = 35, avg_loss = 0.5533\n",
            "Checking accuracy on test set\n",
            "Got 188 / 280 correct (67.14)\n",
            "acc = 0.671429\n",
            "Starting epoch 16 / 50\n",
            "t = 1, avg_loss = 0.6776\n",
            "t = 2, avg_loss = 0.6506\n",
            "t = 3, avg_loss = 0.6170\n",
            "t = 4, avg_loss = 0.6190\n",
            "t = 5, avg_loss = 0.6030\n",
            "t = 6, avg_loss = 0.5606\n",
            "t = 7, avg_loss = 0.6162\n",
            "t = 8, avg_loss = 0.5980\n",
            "t = 9, avg_loss = 0.5701\n",
            "t = 10, avg_loss = 0.6383\n",
            "t = 11, avg_loss = 0.6752\n",
            "t = 12, avg_loss = 0.6605\n",
            "t = 13, avg_loss = 0.5907\n",
            "t = 14, avg_loss = 0.5149\n",
            "t = 15, avg_loss = 0.6616\n",
            "t = 16, avg_loss = 0.5270\n",
            "t = 17, avg_loss = 0.6371\n",
            "t = 18, avg_loss = 0.6507\n",
            "t = 19, avg_loss = 0.6455\n",
            "t = 20, avg_loss = 0.7097\n",
            "t = 21, avg_loss = 0.6952\n",
            "t = 22, avg_loss = 0.6468\n",
            "t = 23, avg_loss = 0.6315\n",
            "t = 24, avg_loss = 0.6252\n",
            "t = 25, avg_loss = 0.5543\n",
            "t = 26, avg_loss = 0.6753\n",
            "t = 27, avg_loss = 0.6462\n",
            "t = 28, avg_loss = 0.5856\n",
            "t = 29, avg_loss = 0.6579\n",
            "t = 30, avg_loss = 0.5866\n",
            "t = 31, avg_loss = 0.7422\n",
            "t = 32, avg_loss = 0.6584\n",
            "t = 33, avg_loss = 0.5711\n",
            "t = 34, avg_loss = 0.6906\n",
            "t = 35, avg_loss = 0.6144\n",
            "Checking accuracy on test set\n",
            "Got 180 / 280 correct (64.29)\n",
            "acc = 0.642857\n",
            "Starting epoch 17 / 50\n",
            "t = 1, avg_loss = 0.7708\n",
            "t = 2, avg_loss = 0.5811\n",
            "t = 3, avg_loss = 0.5889\n",
            "t = 4, avg_loss = 0.6589\n",
            "t = 5, avg_loss = 0.6868\n",
            "t = 6, avg_loss = 0.5816\n",
            "t = 7, avg_loss = 0.5993\n",
            "t = 8, avg_loss = 0.5937\n",
            "t = 9, avg_loss = 0.5456\n",
            "t = 10, avg_loss = 0.6014\n",
            "t = 11, avg_loss = 0.6385\n",
            "t = 12, avg_loss = 0.6139\n",
            "t = 13, avg_loss = 0.6755\n",
            "t = 14, avg_loss = 0.5501\n",
            "t = 15, avg_loss = 0.4932\n",
            "t = 16, avg_loss = 0.6718\n",
            "t = 17, avg_loss = 0.6912\n",
            "t = 18, avg_loss = 0.6796\n",
            "t = 19, avg_loss = 0.6128\n",
            "t = 20, avg_loss = 0.5913\n",
            "t = 21, avg_loss = 0.5243\n",
            "t = 22, avg_loss = 0.6555\n",
            "t = 23, avg_loss = 0.8242\n",
            "t = 24, avg_loss = 0.6358\n",
            "t = 25, avg_loss = 0.5503\n",
            "t = 26, avg_loss = 0.5946\n",
            "t = 27, avg_loss = 0.6718\n",
            "t = 28, avg_loss = 0.5718\n",
            "t = 29, avg_loss = 0.6614\n",
            "t = 30, avg_loss = 0.6944\n",
            "t = 31, avg_loss = 0.5118\n",
            "t = 32, avg_loss = 0.6277\n",
            "t = 33, avg_loss = 0.5815\n",
            "t = 34, avg_loss = 0.6819\n",
            "t = 35, avg_loss = 0.6801\n",
            "Checking accuracy on test set\n",
            "Got 198 / 280 correct (70.71)\n",
            "acc = 0.707143\n",
            "Starting epoch 18 / 50\n",
            "t = 1, avg_loss = 0.6416\n",
            "t = 2, avg_loss = 0.5628\n",
            "t = 3, avg_loss = 0.5821\n",
            "t = 4, avg_loss = 0.7288\n",
            "t = 5, avg_loss = 0.5999\n",
            "t = 6, avg_loss = 0.6242\n",
            "t = 7, avg_loss = 0.5398\n",
            "t = 8, avg_loss = 0.5324\n",
            "t = 9, avg_loss = 0.6728\n",
            "t = 10, avg_loss = 0.5999\n",
            "t = 11, avg_loss = 0.6852\n",
            "t = 12, avg_loss = 0.6734\n",
            "t = 13, avg_loss = 0.6548\n",
            "t = 14, avg_loss = 0.6082\n",
            "t = 15, avg_loss = 0.6752\n",
            "t = 16, avg_loss = 0.5821\n",
            "t = 17, avg_loss = 0.7623\n",
            "t = 18, avg_loss = 0.6881\n",
            "t = 19, avg_loss = 0.6786\n",
            "t = 20, avg_loss = 0.6084\n",
            "t = 21, avg_loss = 0.6036\n",
            "t = 22, avg_loss = 0.6892\n",
            "t = 23, avg_loss = 0.5426\n",
            "t = 24, avg_loss = 0.5447\n",
            "t = 25, avg_loss = 0.7252\n",
            "t = 26, avg_loss = 0.6898\n",
            "t = 27, avg_loss = 0.5631\n",
            "t = 28, avg_loss = 0.6624\n",
            "t = 29, avg_loss = 0.5664\n",
            "t = 30, avg_loss = 0.5297\n",
            "t = 31, avg_loss = 0.8094\n",
            "t = 32, avg_loss = 0.5566\n",
            "t = 33, avg_loss = 0.5603\n",
            "t = 34, avg_loss = 0.5973\n",
            "t = 35, avg_loss = 0.7132\n",
            "Checking accuracy on test set\n",
            "Got 194 / 280 correct (69.29)\n",
            "acc = 0.692857\n",
            "Starting epoch 19 / 50\n",
            "t = 1, avg_loss = 0.5573\n",
            "t = 2, avg_loss = 0.6725\n",
            "t = 3, avg_loss = 0.6069\n",
            "t = 4, avg_loss = 0.6177\n",
            "t = 5, avg_loss = 0.5943\n",
            "t = 6, avg_loss = 0.5577\n",
            "t = 7, avg_loss = 0.5340\n",
            "t = 8, avg_loss = 0.6611\n",
            "t = 9, avg_loss = 0.7243\n",
            "t = 10, avg_loss = 0.5684\n",
            "t = 11, avg_loss = 0.7355\n",
            "t = 12, avg_loss = 0.5578\n",
            "t = 13, avg_loss = 0.5728\n",
            "t = 14, avg_loss = 0.6518\n",
            "t = 15, avg_loss = 0.6365\n",
            "t = 16, avg_loss = 0.7324\n",
            "t = 17, avg_loss = 0.5559\n",
            "t = 18, avg_loss = 0.5722\n",
            "t = 19, avg_loss = 0.6134\n",
            "t = 20, avg_loss = 0.5819\n",
            "t = 21, avg_loss = 0.6270\n",
            "t = 22, avg_loss = 0.6063\n",
            "t = 23, avg_loss = 0.5776\n",
            "t = 24, avg_loss = 0.6108\n",
            "t = 25, avg_loss = 0.6181\n",
            "t = 26, avg_loss = 0.6014\n",
            "t = 27, avg_loss = 0.6450\n",
            "t = 28, avg_loss = 0.5732\n",
            "t = 29, avg_loss = 0.6169\n",
            "t = 30, avg_loss = 0.5759\n",
            "t = 31, avg_loss = 0.6250\n",
            "t = 32, avg_loss = 0.6422\n",
            "t = 33, avg_loss = 0.5446\n",
            "t = 34, avg_loss = 0.6344\n",
            "t = 35, avg_loss = 0.5085\n",
            "Checking accuracy on test set\n",
            "Got 182 / 280 correct (65.00)\n",
            "acc = 0.650000\n",
            "Starting epoch 20 / 50\n",
            "t = 1, avg_loss = 0.5736\n",
            "t = 2, avg_loss = 0.5963\n",
            "t = 3, avg_loss = 0.6071\n",
            "t = 4, avg_loss = 0.6187\n",
            "t = 5, avg_loss = 0.6822\n",
            "t = 6, avg_loss = 0.5192\n",
            "t = 7, avg_loss = 0.5705\n",
            "t = 8, avg_loss = 0.7707\n",
            "t = 9, avg_loss = 0.6286\n",
            "t = 10, avg_loss = 0.7211\n",
            "t = 11, avg_loss = 0.6484\n",
            "t = 12, avg_loss = 0.7097\n",
            "t = 13, avg_loss = 0.5485\n",
            "t = 14, avg_loss = 0.6198\n",
            "t = 15, avg_loss = 0.6523\n",
            "t = 16, avg_loss = 0.7232\n",
            "t = 17, avg_loss = 0.5165\n",
            "t = 18, avg_loss = 0.6351\n",
            "t = 19, avg_loss = 0.4864\n",
            "t = 20, avg_loss = 0.5721\n",
            "t = 21, avg_loss = 0.6938\n",
            "t = 22, avg_loss = 0.6822\n",
            "t = 23, avg_loss = 0.6650\n",
            "t = 24, avg_loss = 0.5367\n",
            "t = 25, avg_loss = 0.6769\n",
            "t = 26, avg_loss = 0.6832\n",
            "t = 27, avg_loss = 0.4495\n",
            "t = 28, avg_loss = 0.7174\n",
            "t = 29, avg_loss = 0.6179\n",
            "t = 30, avg_loss = 0.5978\n",
            "t = 31, avg_loss = 0.5573\n",
            "t = 32, avg_loss = 0.5210\n",
            "t = 33, avg_loss = 0.6153\n",
            "t = 34, avg_loss = 0.6097\n",
            "t = 35, avg_loss = 0.6734\n",
            "Checking accuracy on test set\n",
            "Got 189 / 280 correct (67.50)\n",
            "acc = 0.675000\n",
            "Starting epoch 21 / 50\n",
            "t = 1, avg_loss = 0.6434\n",
            "t = 2, avg_loss = 0.5632\n",
            "t = 3, avg_loss = 0.5413\n",
            "t = 4, avg_loss = 0.6089\n",
            "t = 5, avg_loss = 0.7201\n",
            "t = 6, avg_loss = 0.5508\n",
            "t = 7, avg_loss = 0.5085\n",
            "t = 8, avg_loss = 0.6527\n",
            "t = 9, avg_loss = 0.6173\n",
            "t = 10, avg_loss = 0.6558\n",
            "t = 11, avg_loss = 0.6334\n",
            "t = 12, avg_loss = 0.5938\n",
            "t = 13, avg_loss = 0.6763\n",
            "t = 14, avg_loss = 0.5901\n",
            "t = 15, avg_loss = 0.6143\n",
            "t = 16, avg_loss = 0.6298\n",
            "t = 17, avg_loss = 0.6389\n",
            "t = 18, avg_loss = 0.5549\n",
            "t = 19, avg_loss = 0.6380\n",
            "t = 20, avg_loss = 0.5620\n",
            "t = 21, avg_loss = 0.5732\n",
            "t = 22, avg_loss = 0.6699\n",
            "t = 23, avg_loss = 0.5878\n",
            "t = 24, avg_loss = 0.8364\n",
            "t = 25, avg_loss = 0.6673\n",
            "t = 26, avg_loss = 0.5579\n",
            "t = 27, avg_loss = 0.5530\n",
            "t = 28, avg_loss = 0.5921\n",
            "t = 29, avg_loss = 0.6072\n",
            "t = 30, avg_loss = 0.6262\n",
            "t = 31, avg_loss = 0.5186\n",
            "t = 32, avg_loss = 0.5361\n",
            "t = 33, avg_loss = 0.6697\n",
            "t = 34, avg_loss = 0.6294\n",
            "t = 35, avg_loss = 0.6620\n",
            "Checking accuracy on test set\n",
            "Got 193 / 280 correct (68.93)\n",
            "acc = 0.689286\n",
            "Starting epoch 22 / 50\n",
            "t = 1, avg_loss = 0.6072\n",
            "t = 2, avg_loss = 0.7210\n",
            "t = 3, avg_loss = 0.6448\n",
            "t = 4, avg_loss = 0.6479\n",
            "t = 5, avg_loss = 0.6562\n",
            "t = 6, avg_loss = 0.5387\n",
            "t = 7, avg_loss = 0.6028\n",
            "t = 8, avg_loss = 0.5298\n",
            "t = 9, avg_loss = 0.7216\n",
            "t = 10, avg_loss = 0.5437\n",
            "t = 11, avg_loss = 0.6886\n",
            "t = 12, avg_loss = 0.5429\n",
            "t = 13, avg_loss = 0.5800\n",
            "t = 14, avg_loss = 0.5792\n",
            "t = 15, avg_loss = 0.6138\n",
            "t = 16, avg_loss = 0.6715\n",
            "t = 17, avg_loss = 0.5208\n",
            "t = 18, avg_loss = 0.6109\n",
            "t = 19, avg_loss = 0.6624\n",
            "t = 20, avg_loss = 0.6122\n",
            "t = 21, avg_loss = 0.6406\n",
            "t = 22, avg_loss = 0.7243\n",
            "t = 23, avg_loss = 0.6472\n",
            "t = 24, avg_loss = 0.5661\n",
            "t = 25, avg_loss = 0.6175\n",
            "t = 26, avg_loss = 0.6446\n",
            "t = 27, avg_loss = 0.6255\n",
            "t = 28, avg_loss = 0.4907\n",
            "t = 29, avg_loss = 0.4952\n",
            "t = 30, avg_loss = 0.6089\n",
            "t = 31, avg_loss = 0.6479\n",
            "t = 32, avg_loss = 0.6669\n",
            "t = 33, avg_loss = 0.6498\n",
            "t = 34, avg_loss = 0.6566\n",
            "t = 35, avg_loss = 0.5418\n",
            "Checking accuracy on test set\n",
            "Got 202 / 280 correct (72.14)\n",
            "acc = 0.721429\n",
            "Starting epoch 23 / 50\n",
            "t = 1, avg_loss = 0.5900\n",
            "t = 2, avg_loss = 0.5619\n",
            "t = 3, avg_loss = 0.5514\n",
            "t = 4, avg_loss = 0.5122\n",
            "t = 5, avg_loss = 0.5906\n",
            "t = 6, avg_loss = 0.6260\n",
            "t = 7, avg_loss = 0.6943\n",
            "t = 8, avg_loss = 0.5036\n",
            "t = 9, avg_loss = 0.6668\n",
            "t = 10, avg_loss = 0.5389\n",
            "t = 11, avg_loss = 0.5381\n",
            "t = 12, avg_loss = 0.5917\n",
            "t = 13, avg_loss = 0.6372\n",
            "t = 14, avg_loss = 0.6419\n",
            "t = 15, avg_loss = 0.6794\n",
            "t = 16, avg_loss = 0.5792\n",
            "t = 17, avg_loss = 0.6799\n",
            "t = 18, avg_loss = 0.8458\n",
            "t = 19, avg_loss = 0.6541\n",
            "t = 20, avg_loss = 0.7913\n",
            "t = 21, avg_loss = 0.5862\n",
            "t = 22, avg_loss = 0.6094\n",
            "t = 23, avg_loss = 0.7421\n",
            "t = 24, avg_loss = 0.5687\n",
            "t = 25, avg_loss = 0.5969\n",
            "t = 26, avg_loss = 0.5595\n",
            "t = 27, avg_loss = 0.7097\n",
            "t = 28, avg_loss = 0.6348\n",
            "t = 29, avg_loss = 0.5249\n",
            "t = 30, avg_loss = 0.6443\n",
            "t = 31, avg_loss = 0.6312\n",
            "t = 32, avg_loss = 0.5376\n",
            "t = 33, avg_loss = 0.5912\n",
            "t = 34, avg_loss = 0.6238\n",
            "t = 35, avg_loss = 0.6819\n",
            "Checking accuracy on test set\n",
            "Got 185 / 280 correct (66.07)\n",
            "acc = 0.660714\n",
            "Starting epoch 24 / 50\n",
            "t = 1, avg_loss = 0.6212\n",
            "t = 2, avg_loss = 0.5474\n",
            "t = 3, avg_loss = 0.5679\n",
            "t = 4, avg_loss = 0.6543\n",
            "t = 5, avg_loss = 0.5229\n",
            "t = 6, avg_loss = 0.6407\n",
            "t = 7, avg_loss = 0.5273\n",
            "t = 8, avg_loss = 0.6634\n",
            "t = 9, avg_loss = 0.6083\n",
            "t = 10, avg_loss = 0.5927\n",
            "t = 11, avg_loss = 0.5833\n",
            "t = 12, avg_loss = 0.6454\n",
            "t = 13, avg_loss = 0.4756\n",
            "t = 14, avg_loss = 0.6223\n",
            "t = 15, avg_loss = 0.6185\n",
            "t = 16, avg_loss = 0.6175\n",
            "t = 17, avg_loss = 0.5310\n",
            "t = 18, avg_loss = 0.5991\n",
            "t = 19, avg_loss = 0.5942\n",
            "t = 20, avg_loss = 0.6555\n",
            "t = 21, avg_loss = 0.6205\n",
            "t = 22, avg_loss = 0.6148\n",
            "t = 23, avg_loss = 0.6526\n",
            "t = 24, avg_loss = 0.6116\n",
            "t = 25, avg_loss = 0.6265\n",
            "t = 26, avg_loss = 0.6164\n",
            "t = 27, avg_loss = 0.7807\n",
            "t = 28, avg_loss = 0.5760\n",
            "t = 29, avg_loss = 0.5354\n",
            "t = 30, avg_loss = 0.5758\n",
            "t = 31, avg_loss = 0.6204\n",
            "t = 32, avg_loss = 0.7557\n",
            "t = 33, avg_loss = 0.6554\n",
            "t = 34, avg_loss = 0.7450\n",
            "t = 35, avg_loss = 0.7390\n",
            "Checking accuracy on test set\n",
            "Got 198 / 280 correct (70.71)\n",
            "acc = 0.707143\n",
            "Starting epoch 25 / 50\n",
            "t = 1, avg_loss = 0.6241\n",
            "t = 2, avg_loss = 0.6468\n",
            "t = 3, avg_loss = 0.5786\n",
            "t = 4, avg_loss = 0.5321\n",
            "t = 5, avg_loss = 0.6602\n",
            "t = 6, avg_loss = 0.4850\n",
            "t = 7, avg_loss = 0.6250\n",
            "t = 8, avg_loss = 0.6137\n",
            "t = 9, avg_loss = 0.5973\n",
            "t = 10, avg_loss = 0.6098\n",
            "t = 11, avg_loss = 0.5561\n",
            "t = 12, avg_loss = 0.6388\n",
            "t = 13, avg_loss = 0.5201\n",
            "t = 14, avg_loss = 0.6208\n",
            "t = 15, avg_loss = 0.6229\n",
            "t = 16, avg_loss = 0.5346\n",
            "t = 17, avg_loss = 0.5942\n",
            "t = 18, avg_loss = 0.5495\n",
            "t = 19, avg_loss = 0.7156\n",
            "t = 20, avg_loss = 0.7283\n",
            "t = 21, avg_loss = 0.6379\n",
            "t = 22, avg_loss = 0.6642\n",
            "t = 23, avg_loss = 0.6148\n",
            "t = 24, avg_loss = 0.6018\n",
            "t = 25, avg_loss = 0.6760\n",
            "t = 26, avg_loss = 0.5849\n",
            "t = 27, avg_loss = 0.6109\n",
            "t = 28, avg_loss = 0.6153\n",
            "t = 29, avg_loss = 0.7174\n",
            "t = 30, avg_loss = 0.7206\n",
            "t = 31, avg_loss = 0.6553\n",
            "t = 32, avg_loss = 0.5930\n",
            "t = 33, avg_loss = 0.6732\n",
            "t = 34, avg_loss = 0.6985\n",
            "t = 35, avg_loss = 0.6607\n",
            "Checking accuracy on test set\n",
            "Got 199 / 280 correct (71.07)\n",
            "acc = 0.710714\n",
            "Starting epoch 26 / 50\n",
            "t = 1, avg_loss = 0.6715\n",
            "t = 2, avg_loss = 0.5410\n",
            "t = 3, avg_loss = 0.7213\n",
            "t = 4, avg_loss = 0.6023\n",
            "t = 5, avg_loss = 0.5456\n",
            "t = 6, avg_loss = 0.7117\n",
            "t = 7, avg_loss = 0.5961\n",
            "t = 8, avg_loss = 0.5764\n",
            "t = 9, avg_loss = 0.6701\n",
            "t = 10, avg_loss = 0.6321\n",
            "t = 11, avg_loss = 0.6373\n",
            "t = 12, avg_loss = 0.6026\n",
            "t = 13, avg_loss = 0.5718\n",
            "t = 14, avg_loss = 0.6558\n",
            "t = 15, avg_loss = 0.5941\n",
            "t = 16, avg_loss = 0.5450\n",
            "t = 17, avg_loss = 0.7147\n",
            "t = 18, avg_loss = 0.5255\n",
            "t = 19, avg_loss = 0.6124\n",
            "t = 20, avg_loss = 0.5782\n",
            "t = 21, avg_loss = 0.5185\n",
            "t = 22, avg_loss = 0.6193\n",
            "t = 23, avg_loss = 0.6157\n",
            "t = 24, avg_loss = 0.7155\n",
            "t = 25, avg_loss = 0.5828\n",
            "t = 26, avg_loss = 0.5986\n",
            "t = 27, avg_loss = 0.6092\n",
            "t = 28, avg_loss = 0.7914\n",
            "t = 29, avg_loss = 0.5202\n",
            "t = 30, avg_loss = 0.5427\n",
            "t = 31, avg_loss = 0.6896\n",
            "t = 32, avg_loss = 0.6270\n",
            "t = 33, avg_loss = 0.5726\n",
            "t = 34, avg_loss = 0.5692\n",
            "t = 35, avg_loss = 0.5833\n",
            "Checking accuracy on test set\n",
            "Got 195 / 280 correct (69.64)\n",
            "acc = 0.696429\n",
            "Starting epoch 27 / 50\n",
            "t = 1, avg_loss = 0.5820\n",
            "t = 2, avg_loss = 0.6574\n",
            "t = 3, avg_loss = 0.6843\n",
            "t = 4, avg_loss = 0.6159\n",
            "t = 5, avg_loss = 0.5427\n",
            "t = 6, avg_loss = 0.5403\n",
            "t = 7, avg_loss = 0.5069\n",
            "t = 8, avg_loss = 0.6423\n",
            "t = 9, avg_loss = 0.6575\n",
            "t = 10, avg_loss = 0.6801\n",
            "t = 11, avg_loss = 0.5006\n",
            "t = 12, avg_loss = 0.6855\n",
            "t = 13, avg_loss = 0.5889\n",
            "t = 14, avg_loss = 0.6809\n",
            "t = 15, avg_loss = 0.6951\n",
            "t = 16, avg_loss = 0.5682\n",
            "t = 17, avg_loss = 0.5285\n",
            "t = 18, avg_loss = 0.6250\n",
            "t = 19, avg_loss = 0.5665\n",
            "t = 20, avg_loss = 0.7959\n",
            "t = 21, avg_loss = 0.7048\n",
            "t = 22, avg_loss = 0.6906\n",
            "t = 23, avg_loss = 0.6091\n",
            "t = 24, avg_loss = 0.6128\n",
            "t = 25, avg_loss = 0.6224\n",
            "t = 26, avg_loss = 0.6386\n",
            "t = 27, avg_loss = 0.6251\n",
            "t = 28, avg_loss = 0.5168\n",
            "t = 29, avg_loss = 0.6443\n",
            "t = 30, avg_loss = 0.5911\n",
            "t = 31, avg_loss = 0.5785\n",
            "t = 32, avg_loss = 0.6246\n",
            "t = 33, avg_loss = 0.6651\n",
            "t = 34, avg_loss = 0.6438\n",
            "t = 35, avg_loss = 0.7223\n",
            "Checking accuracy on test set\n",
            "Got 189 / 280 correct (67.50)\n",
            "acc = 0.675000\n",
            "Starting epoch 28 / 50\n",
            "t = 1, avg_loss = 0.6051\n",
            "t = 2, avg_loss = 0.6288\n",
            "t = 3, avg_loss = 0.6505\n",
            "t = 4, avg_loss = 0.6053\n",
            "t = 5, avg_loss = 0.6402\n",
            "t = 6, avg_loss = 0.5456\n",
            "t = 7, avg_loss = 0.5998\n",
            "t = 8, avg_loss = 0.6063\n",
            "t = 9, avg_loss = 0.6007\n",
            "t = 10, avg_loss = 0.6199\n",
            "t = 11, avg_loss = 0.6084\n",
            "t = 12, avg_loss = 0.5804\n",
            "t = 13, avg_loss = 0.4767\n",
            "t = 14, avg_loss = 0.5909\n",
            "t = 15, avg_loss = 0.5786\n",
            "t = 16, avg_loss = 0.4917\n",
            "t = 17, avg_loss = 0.5344\n",
            "t = 18, avg_loss = 0.6171\n",
            "t = 19, avg_loss = 0.6668\n",
            "t = 20, avg_loss = 0.7228\n",
            "t = 21, avg_loss = 0.5860\n",
            "t = 22, avg_loss = 0.8026\n",
            "t = 23, avg_loss = 0.4958\n",
            "t = 24, avg_loss = 0.6855\n",
            "t = 25, avg_loss = 0.6412\n",
            "t = 26, avg_loss = 0.5670\n",
            "t = 27, avg_loss = 0.7825\n",
            "t = 28, avg_loss = 0.6146\n",
            "t = 29, avg_loss = 0.5400\n",
            "t = 30, avg_loss = 0.6821\n",
            "t = 31, avg_loss = 0.6292\n",
            "t = 32, avg_loss = 0.5792\n",
            "t = 33, avg_loss = 0.6229\n",
            "t = 34, avg_loss = 0.5673\n",
            "t = 35, avg_loss = 0.7250\n",
            "Checking accuracy on test set\n",
            "Got 190 / 280 correct (67.86)\n",
            "acc = 0.678571\n",
            "Starting epoch 29 / 50\n",
            "t = 1, avg_loss = 0.6281\n",
            "t = 2, avg_loss = 0.6574\n",
            "t = 3, avg_loss = 0.6182\n",
            "t = 4, avg_loss = 0.6361\n",
            "t = 5, avg_loss = 0.5847\n",
            "t = 6, avg_loss = 0.6003\n",
            "t = 7, avg_loss = 0.5318\n",
            "t = 8, avg_loss = 0.6392\n",
            "t = 9, avg_loss = 0.6513\n",
            "t = 10, avg_loss = 0.6409\n",
            "t = 11, avg_loss = 0.6561\n",
            "t = 12, avg_loss = 0.6291\n",
            "t = 13, avg_loss = 0.6945\n",
            "t = 14, avg_loss = 0.4484\n",
            "t = 15, avg_loss = 0.5761\n",
            "t = 16, avg_loss = 0.7276\n",
            "t = 17, avg_loss = 0.7087\n",
            "t = 18, avg_loss = 0.5710\n",
            "t = 19, avg_loss = 0.5930\n",
            "t = 20, avg_loss = 0.5528\n",
            "t = 21, avg_loss = 0.5152\n",
            "t = 22, avg_loss = 0.5228\n",
            "t = 23, avg_loss = 0.5972\n",
            "t = 24, avg_loss = 0.4951\n",
            "t = 25, avg_loss = 0.6324\n",
            "t = 26, avg_loss = 0.6372\n",
            "t = 27, avg_loss = 0.7214\n",
            "t = 28, avg_loss = 0.5890\n",
            "t = 29, avg_loss = 0.7815\n",
            "t = 30, avg_loss = 0.5825\n",
            "t = 31, avg_loss = 0.7538\n",
            "t = 32, avg_loss = 0.6421\n",
            "t = 33, avg_loss = 0.6804\n",
            "t = 34, avg_loss = 0.5948\n",
            "t = 35, avg_loss = 0.6107\n",
            "Checking accuracy on test set\n",
            "Got 173 / 280 correct (61.79)\n",
            "acc = 0.617857\n",
            "Starting epoch 30 / 50\n",
            "t = 1, avg_loss = 0.5309\n",
            "t = 2, avg_loss = 0.6114\n",
            "t = 3, avg_loss = 0.5039\n",
            "t = 4, avg_loss = 0.5463\n",
            "t = 5, avg_loss = 0.5757\n",
            "t = 6, avg_loss = 0.6638\n",
            "t = 7, avg_loss = 0.5694\n",
            "t = 8, avg_loss = 0.6129\n",
            "t = 9, avg_loss = 0.7598\n",
            "t = 10, avg_loss = 0.6233\n",
            "t = 11, avg_loss = 0.5168\n",
            "t = 12, avg_loss = 0.6888\n",
            "t = 13, avg_loss = 0.5396\n",
            "t = 14, avg_loss = 0.6011\n",
            "t = 15, avg_loss = 0.7169\n",
            "t = 16, avg_loss = 0.6231\n",
            "t = 17, avg_loss = 0.6381\n",
            "t = 18, avg_loss = 0.5864\n",
            "t = 19, avg_loss = 0.5013\n",
            "t = 20, avg_loss = 0.5724\n",
            "t = 21, avg_loss = 0.8122\n",
            "t = 22, avg_loss = 0.7693\n",
            "t = 23, avg_loss = 0.6130\n",
            "t = 24, avg_loss = 0.4644\n",
            "t = 25, avg_loss = 0.8055\n",
            "t = 26, avg_loss = 0.6985\n",
            "t = 27, avg_loss = 0.5790\n",
            "t = 28, avg_loss = 0.6348\n",
            "t = 29, avg_loss = 0.6408\n",
            "t = 30, avg_loss = 0.7772\n",
            "t = 31, avg_loss = 0.6290\n",
            "t = 32, avg_loss = 0.7895\n",
            "t = 33, avg_loss = 0.5409\n",
            "t = 34, avg_loss = 0.5649\n",
            "t = 35, avg_loss = 0.6129\n",
            "Checking accuracy on test set\n",
            "Got 198 / 280 correct (70.71)\n",
            "acc = 0.707143\n",
            "Starting epoch 31 / 50\n",
            "t = 1, avg_loss = 0.6199\n",
            "t = 2, avg_loss = 0.7172\n",
            "t = 3, avg_loss = 0.5416\n",
            "t = 4, avg_loss = 0.5122\n",
            "t = 5, avg_loss = 0.5734\n",
            "t = 6, avg_loss = 0.5837\n",
            "t = 7, avg_loss = 0.5437\n",
            "t = 8, avg_loss = 0.5926\n",
            "t = 9, avg_loss = 0.7579\n",
            "t = 10, avg_loss = 0.6048\n",
            "t = 11, avg_loss = 0.6743\n",
            "t = 12, avg_loss = 0.6045\n",
            "t = 13, avg_loss = 0.7065\n",
            "t = 14, avg_loss = 0.5728\n",
            "t = 15, avg_loss = 0.6550\n",
            "t = 16, avg_loss = 0.5865\n",
            "t = 17, avg_loss = 0.6611\n",
            "t = 18, avg_loss = 0.5991\n",
            "t = 19, avg_loss = 0.5753\n",
            "t = 20, avg_loss = 0.5104\n",
            "t = 21, avg_loss = 0.5524\n",
            "t = 22, avg_loss = 0.5319\n",
            "t = 23, avg_loss = 0.7445\n",
            "t = 24, avg_loss = 0.5995\n",
            "t = 25, avg_loss = 0.6154\n",
            "t = 26, avg_loss = 0.5924\n",
            "t = 27, avg_loss = 0.6588\n",
            "t = 28, avg_loss = 0.5148\n",
            "t = 29, avg_loss = 0.5786\n",
            "t = 30, avg_loss = 0.5224\n",
            "t = 31, avg_loss = 0.6057\n",
            "t = 32, avg_loss = 0.6219\n",
            "t = 33, avg_loss = 0.6449\n",
            "t = 34, avg_loss = 0.6322\n",
            "t = 35, avg_loss = 0.6230\n",
            "Checking accuracy on test set\n",
            "Got 195 / 280 correct (69.64)\n",
            "acc = 0.696429\n",
            "Starting epoch 32 / 50\n",
            "t = 1, avg_loss = 0.6100\n",
            "t = 2, avg_loss = 0.5572\n",
            "t = 3, avg_loss = 0.6726\n",
            "t = 4, avg_loss = 0.6007\n",
            "t = 5, avg_loss = 0.5960\n",
            "t = 6, avg_loss = 0.6651\n",
            "t = 7, avg_loss = 0.6308\n",
            "t = 8, avg_loss = 0.6112\n",
            "t = 9, avg_loss = 0.5902\n",
            "t = 10, avg_loss = 0.6459\n",
            "t = 11, avg_loss = 0.6738\n",
            "t = 12, avg_loss = 0.6765\n",
            "t = 13, avg_loss = 0.4524\n",
            "t = 14, avg_loss = 0.4688\n",
            "t = 15, avg_loss = 0.5487\n",
            "t = 16, avg_loss = 0.6496\n",
            "t = 17, avg_loss = 0.5735\n",
            "t = 18, avg_loss = 0.7133\n",
            "t = 19, avg_loss = 0.6513\n",
            "t = 20, avg_loss = 0.6477\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-0a4a897279b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfixed_model_gpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.00011\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfixed_model_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0mcheck_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfixed_model_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-2d469a18a779>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, loss_fn, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mx_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0my_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-50a9cd504daf>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m           \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"malignant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"malignant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \"\"\"\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   1856\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1858\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreducing_gap\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresample\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mNEAREST\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDn-2g-TLY3k",
        "colab_type": "code",
        "outputId": "d2251df1-729c-4a0f-99d1-7737cf427d7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot([print_every*batch_size*(i+1) for i in range((len(avg_loss_list)))],avg_loss_list)\n",
        "print(\"Loss:\")\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmabV5jIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGer6hJv7-zR",
        "colab_type": "code",
        "outputId": "d048f84a-9529-434f-a1a6-8a5fbabd4949",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "plt.plot([i+1 for i in range((len(acc_list)))],acc_list)\n",
        "print(\"Accurancy:\")\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accurancy:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nH6jLYakRkSbIAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBTReWHxz4Ml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}