{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMrdCcoSSh2ENHLubHs2V/l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kamilo116/KNN/blob/master/KNN3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7ReM7FU-xs4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import sys\n",
        "from random import shuffle\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "import timeit\n",
        "\n",
        "np.random.seed(4) \n",
        "torch.manual_seed(4) \n",
        "torch.cuda.manual_seed(4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMOHez_kHZD6",
        "colab_type": "code",
        "outputId": "7e2d718b-6119-445a-e066-96a010048d88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYIMZ8QyYewD",
        "colab_type": "code",
        "outputId": "f7661381-9457-44af-91b5-e7b4da01bb0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! git clone https://github.com/wang-chen/kervolution.git \n",
        "\n",
        "sys.path.append(\"kervolution/\")\n",
        "from kervolution import Kerv2d\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'kervolution' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b8P1NdXfVdX",
        "colab_type": "code",
        "outputId": "ac6e6142-9ee1-4b0b-a5a9-99506a4ed291",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "MALIGNANT_DATASET = '/content/drive/My Drive/Colab_data/malignant/malignant/'\n",
        "BENIGN_DATASET = '/content/drive/My Drive/Colab_data/benign/benign/'\n",
        "DATA_FOLDER = '/content/drive/My Drive/Colab_data/'\n",
        "LIMIT_IMAGES_NUM = 500\n",
        "\n",
        "benign_file_list = sorted(os.listdir(BENIGN_DATASET))[:LIMIT_IMAGES_NUM]\n",
        "malignant_file_list = sorted(os.listdir(MALIGNANT_DATASET))[:LIMIT_IMAGES_NUM]\n",
        "shuffle(benign_file_list)\n",
        "shuffle(malignant_file_list)\n",
        "\n",
        "print(f\"Number of benign {len(benign_file_list)} images\")\n",
        "print(f\"Number of malignant {len(malignant_file_list)} images\")\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize((100, 100)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of benign 500 images\n",
            "Number of malignant 500 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGDQfal74BLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "benign_dict = {filename: 0 for filename in benign_file_list}\n",
        "malignant_dict = {filename: 1 for filename in malignant_file_list}\n",
        "img_class_dict = {**benign_dict , **malignant_dict}\n",
        "labeled_data = pd.Series(img_class_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvAAOqmVfVll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class IsicDataset(Dataset):\n",
        "    def __init__(self, data_folder, labeled_data, \n",
        "                 transform=transforms.Compose([transforms.ToTensor()])):\n",
        "        self.labeled_data = labeled_data\n",
        "        self.transform = transform\n",
        "        self.data_folder = data_folder\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labeled_data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        label = self.labeled_data[index]\n",
        "        if label == 0:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"benign\", \"benign\", index ))\n",
        "        else:\n",
        "          image = Image.open(os.path.join(self.data_folder, \"malignant\", \"malignant\", index ))\n",
        "        image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "    @property\n",
        "    def labels(self):\n",
        "      return self.labeled_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSuYqjLAYrWA",
        "colab_type": "code",
        "outputId": "a57e5cae-f124-4709-9882-e09c3a75b4bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        " \n",
        "dataset = IsicDataset(DATA_FOLDER, labeled_data, transform=data_transforms)\n",
        "print(dataset.labels)\n",
        "\n",
        "X_train, X_test = train_test_split(dataset.labels, test_size=0.2)\n",
        "print(\"number of training data: \",len(X_train))\n",
        "print(\"number of testing  data: \",len(X_test))\n",
        "\n",
        "train_sampler = SubsetRandomSampler(list(X_train.index))\n",
        "valid_sampler = SubsetRandomSampler(list(X_test.index))\n",
        "batch_size = 32\n",
        "num_workers = 0\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ISIC_0000500.jpeg    0\n",
            "ISIC_0000219.jpeg    0\n",
            "ISIC_0000540.jpeg    0\n",
            "ISIC_0000392.jpeg    0\n",
            "ISIC_0000423.jpeg    0\n",
            "                    ..\n",
            "ISIC_0010809.jpeg    1\n",
            "ISIC_0011118.jpeg    1\n",
            "ISIC_0010728.jpeg    1\n",
            "ISIC_0010089.jpeg    1\n",
            "ISIC_0001143.jpeg    1\n",
            "Length: 1000, dtype: int64\n",
            "number of training data:  800\n",
            "number of testing  data:  200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e8nFBR6Yug5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "def train(model, train_loader ,loss_fn, optimizer, num_epochs = 1):\n",
        "    total_loss =0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
        "        model.train()\n",
        "\n",
        "        for t, (x, y) in enumerate(train_loader):\n",
        "            x_var = Variable(x.type(gpu_dtype))\n",
        "            y_var = Variable(y.type(gpu_dtype).long())\n",
        "            scores = model(x_var)\n",
        "            loss = loss_fn(scores, y_var)\n",
        "            total_loss += loss.data\n",
        "            \n",
        "            if (t + 1) % print_every == 0:\n",
        "                avg_loss = total_loss/print_every\n",
        "                print('t = %d, avg_loss = %.4f' % (t + 1, avg_loss) )\n",
        "                avg_loss_list.append(avg_loss)\n",
        "                total_loss = 0\n",
        "                \n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        acc = check_accuracy(fixed_model_gpu, valid_loader)\n",
        "        print('acc = %f' %(acc))\n",
        "            \n",
        "def check_accuracy(model, loader):\n",
        "    print('Checking accuracy on test set')   \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval() \n",
        "    for x, y in loader:\n",
        "        x_var = Variable(x.type(gpu_dtype))\n",
        "\n",
        "        scores = model(x_var)\n",
        "        _, preds = scores.data.cpu().max(1)\n",
        "        num_correct += (preds == y).sum()\n",
        "        num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    acc_list.append(acc)\n",
        "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "    return acc\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggvpMu36Yw2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.size()\n",
        "        return x.view(N, -1)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgmexhBRZAK6",
        "colab_type": "code",
        "outputId": "b2ea6737-a8de-421f-b8e1-c9d35c8d1073",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print_every = 1\n",
        "gpu_dtype = torch.cuda.FloatTensor\n",
        "\n",
        "out_1 = 64\n",
        "out_2 = 48\n",
        "out_3 = 32\n",
        "out_4 = 24\n",
        "out_5 = 16\n",
        "\n",
        "k_size_1 = 3\n",
        "padding_1 = 1\n",
        "in_channels = 3\n",
        "\n",
        "num_epochs = 50\n",
        "\n",
        "'''\n",
        "Kerv2d\n",
        "kervolution with following options:\n",
        "kernel_type: [linear, polynomial, gaussian, etc.]\n",
        "default is convolution:\n",
        "          kernel_type --> linear,\n",
        "balance, power, gamma is valid only when the kernel_type is specified\n",
        "if learnable_kernel = True,  they just be the initial value of learable parameters\n",
        "if learnable_kernel = False, they are the value of kernel_type's parameter\n",
        "the parameter [power] cannot be learned due to integer limitation\n",
        "balance: 0, 1\n",
        "power: 3, 4, 5\n",
        "gamma:\n",
        "'''\n",
        "fixed_model_base = nn.Sequential( \n",
        "                nn.Kerv2d(in_channels, out_1, padding= padding_1, kernel_size=k_size_1, \n",
        "                          stride=1, kernel_type='gaussian', learnable_kernel=True,\n",
        "                          kernel_regularizer=True, balance=1, power=4, gamma=1), \n",
        "                nn.BatchNorm2d(out_1),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_1 , out_2, padding= padding_1, kernel_size=k_size_1, stride=1), \n",
        "                nn.BatchNorm2d(out_2),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_2 , out_3, padding= padding_1, kernel_size=k_size_1, stride=1),  \n",
        "                nn.BatchNorm2d(out_3),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Conv2d(out_3 , out_4, padding= padding_1, kernel_size=k_size_1, stride=1), \n",
        "                nn.BatchNorm2d(out_4),\n",
        "                nn.Conv2d(out_4 , out_5, padding= padding_1, kernel_size=k_size_1, stride=1), \n",
        "                nn.BatchNorm2d(out_5),\n",
        "                nn.AvgPool2d(2, stride=2),\n",
        "                nn.Dropout(0.5),\n",
        "                Flatten(),\n",
        "                nn.Linear(576,32),\n",
        "                #nn.Linear(256, 32),\n",
        "                nn.Linear(32,10),\n",
        "                nn.Linear(10,2)\n",
        "            )\n",
        "fixed_model_gpu = fixed_model_base.type(gpu_dtype)\n",
        "print(fixed_model_gpu)\n",
        "loss_fn = nn.modules.loss.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(fixed_model_gpu.parameters(), lr = 0.0015, weight_decay=0) \n",
        "\n",
        "train(fixed_model_gpu, train_loader ,loss_fn, optimizer, num_epochs=num_epochs)\n",
        "check_accuracy(fixed_model_gpu, valid_loader)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Kerv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (3): Conv2d(64, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (6): Conv2d(48, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (8): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (9): Conv2d(32, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (10): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (11): Conv2d(24, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (12): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (14): Dropout(p=0.5, inplace=False)\n",
            "  (15): Flatten()\n",
            "  (16): Linear(in_features=576, out_features=32, bias=True)\n",
            "  (17): Linear(in_features=32, out_features=10, bias=True)\n",
            "  (18): Linear(in_features=10, out_features=2, bias=True)\n",
            ")\n",
            "Starting epoch 1 / 50\n",
            "t = 1, avg_loss = 0.7762\n",
            "t = 2, avg_loss = 0.7701\n",
            "t = 3, avg_loss = 0.6666\n",
            "t = 4, avg_loss = 0.6275\n",
            "t = 5, avg_loss = 0.7445\n",
            "t = 6, avg_loss = 0.6759\n",
            "t = 7, avg_loss = 0.7107\n",
            "t = 8, avg_loss = 0.6903\n",
            "t = 9, avg_loss = 0.6003\n",
            "t = 10, avg_loss = 0.8666\n",
            "t = 11, avg_loss = 0.7135\n",
            "t = 12, avg_loss = 0.7985\n",
            "t = 13, avg_loss = 0.6224\n",
            "t = 14, avg_loss = 0.6477\n",
            "t = 15, avg_loss = 0.6582\n",
            "t = 16, avg_loss = 0.7449\n",
            "t = 17, avg_loss = 0.8157\n",
            "t = 18, avg_loss = 0.7948\n",
            "t = 19, avg_loss = 0.6559\n",
            "t = 20, avg_loss = 0.7438\n",
            "t = 21, avg_loss = 0.8015\n",
            "t = 22, avg_loss = 0.6731\n",
            "t = 23, avg_loss = 0.6848\n",
            "t = 24, avg_loss = 0.7620\n",
            "t = 25, avg_loss = 0.7152\n",
            "Checking accuracy on test set\n",
            "Got 110 / 200 correct (55.00)\n",
            "acc = 0.550000\n",
            "Starting epoch 2 / 50\n",
            "t = 1, avg_loss = 0.7097\n",
            "t = 2, avg_loss = 0.7789\n",
            "t = 3, avg_loss = 0.6095\n",
            "t = 4, avg_loss = 0.6906\n",
            "t = 5, avg_loss = 0.6596\n",
            "t = 6, avg_loss = 0.7138\n",
            "t = 7, avg_loss = 0.7073\n",
            "t = 8, avg_loss = 0.6903\n",
            "t = 9, avg_loss = 0.7053\n",
            "t = 10, avg_loss = 0.7616\n",
            "t = 11, avg_loss = 0.6438\n",
            "t = 12, avg_loss = 0.6808\n",
            "t = 13, avg_loss = 0.7226\n",
            "t = 14, avg_loss = 0.6846\n",
            "t = 15, avg_loss = 0.7191\n",
            "t = 16, avg_loss = 0.6932\n",
            "t = 17, avg_loss = 0.6033\n",
            "t = 18, avg_loss = 0.6758\n",
            "t = 19, avg_loss = 0.6981\n",
            "t = 20, avg_loss = 0.6947\n",
            "t = 21, avg_loss = 0.6263\n",
            "t = 22, avg_loss = 0.6544\n",
            "t = 23, avg_loss = 0.7575\n",
            "t = 24, avg_loss = 0.5969\n",
            "t = 25, avg_loss = 0.6208\n",
            "Checking accuracy on test set\n",
            "Got 135 / 200 correct (67.50)\n",
            "acc = 0.675000\n",
            "Starting epoch 3 / 50\n",
            "t = 1, avg_loss = 0.6837\n",
            "t = 2, avg_loss = 0.6465\n",
            "t = 3, avg_loss = 0.7509\n",
            "t = 4, avg_loss = 0.7475\n",
            "t = 5, avg_loss = 0.6306\n",
            "t = 6, avg_loss = 0.7500\n",
            "t = 7, avg_loss = 0.5847\n",
            "t = 8, avg_loss = 0.6303\n",
            "t = 9, avg_loss = 0.7142\n",
            "t = 10, avg_loss = 0.6636\n",
            "t = 11, avg_loss = 0.5955\n",
            "t = 12, avg_loss = 0.6650\n",
            "t = 13, avg_loss = 0.6501\n",
            "t = 14, avg_loss = 0.6843\n",
            "t = 15, avg_loss = 0.6393\n",
            "t = 16, avg_loss = 0.6240\n",
            "t = 17, avg_loss = 0.7620\n",
            "t = 18, avg_loss = 0.6577\n",
            "t = 19, avg_loss = 0.6284\n",
            "t = 20, avg_loss = 0.5788\n",
            "t = 21, avg_loss = 0.6497\n",
            "t = 22, avg_loss = 0.7069\n",
            "t = 23, avg_loss = 0.6828\n",
            "t = 24, avg_loss = 0.7399\n",
            "t = 25, avg_loss = 0.7175\n",
            "Checking accuracy on test set\n",
            "Got 131 / 200 correct (65.50)\n",
            "acc = 0.655000\n",
            "Starting epoch 4 / 50\n",
            "t = 1, avg_loss = 0.6755\n",
            "t = 2, avg_loss = 0.6873\n",
            "t = 3, avg_loss = 0.7342\n",
            "t = 4, avg_loss = 0.5879\n",
            "t = 5, avg_loss = 0.7953\n",
            "t = 6, avg_loss = 0.6566\n",
            "t = 7, avg_loss = 0.6381\n",
            "t = 8, avg_loss = 0.6318\n",
            "t = 9, avg_loss = 0.6233\n",
            "t = 10, avg_loss = 0.6481\n",
            "t = 11, avg_loss = 0.7220\n",
            "t = 12, avg_loss = 0.6467\n",
            "t = 13, avg_loss = 0.5921\n",
            "t = 14, avg_loss = 0.7008\n",
            "t = 15, avg_loss = 0.6928\n",
            "t = 16, avg_loss = 0.6806\n",
            "t = 17, avg_loss = 0.6659\n",
            "t = 18, avg_loss = 0.6916\n",
            "t = 19, avg_loss = 0.6644\n",
            "t = 20, avg_loss = 0.5742\n",
            "t = 21, avg_loss = 0.7118\n",
            "t = 22, avg_loss = 0.6558\n",
            "t = 23, avg_loss = 0.6832\n",
            "t = 24, avg_loss = 0.6379\n",
            "t = 25, avg_loss = 0.6675\n",
            "Checking accuracy on test set\n",
            "Got 130 / 200 correct (65.00)\n",
            "acc = 0.650000\n",
            "Starting epoch 5 / 50\n",
            "t = 1, avg_loss = 0.7146\n",
            "t = 2, avg_loss = 0.6716\n",
            "t = 3, avg_loss = 0.7249\n",
            "t = 4, avg_loss = 0.6450\n",
            "t = 5, avg_loss = 0.6150\n",
            "t = 6, avg_loss = 0.6447\n",
            "t = 7, avg_loss = 0.6286\n",
            "t = 8, avg_loss = 0.7602\n",
            "t = 9, avg_loss = 0.6816\n",
            "t = 10, avg_loss = 0.7256\n",
            "t = 11, avg_loss = 0.5738\n",
            "t = 12, avg_loss = 0.6790\n",
            "t = 13, avg_loss = 0.5901\n",
            "t = 14, avg_loss = 0.6626\n",
            "t = 15, avg_loss = 0.5839\n",
            "t = 16, avg_loss = 0.7661\n",
            "t = 17, avg_loss = 0.5808\n",
            "t = 18, avg_loss = 0.6225\n",
            "t = 19, avg_loss = 0.6173\n",
            "t = 20, avg_loss = 0.6581\n",
            "t = 21, avg_loss = 0.6536\n",
            "t = 22, avg_loss = 0.6255\n",
            "t = 23, avg_loss = 0.7192\n",
            "t = 24, avg_loss = 0.6788\n",
            "t = 25, avg_loss = 0.6147\n",
            "Checking accuracy on test set\n",
            "Got 118 / 200 correct (59.00)\n",
            "acc = 0.590000\n",
            "Starting epoch 6 / 50\n",
            "t = 1, avg_loss = 0.6669\n",
            "t = 2, avg_loss = 0.8164\n",
            "t = 3, avg_loss = 0.6297\n",
            "t = 4, avg_loss = 0.7225\n",
            "t = 5, avg_loss = 0.6331\n",
            "t = 6, avg_loss = 0.6905\n",
            "t = 7, avg_loss = 0.6639\n",
            "t = 8, avg_loss = 0.7208\n",
            "t = 9, avg_loss = 0.6342\n",
            "t = 10, avg_loss = 0.6662\n",
            "t = 11, avg_loss = 0.6487\n",
            "t = 12, avg_loss = 0.6630\n",
            "t = 13, avg_loss = 0.6715\n",
            "t = 14, avg_loss = 0.6440\n",
            "t = 15, avg_loss = 0.7063\n",
            "t = 16, avg_loss = 0.6372\n",
            "t = 17, avg_loss = 0.6542\n",
            "t = 18, avg_loss = 0.6649\n",
            "t = 19, avg_loss = 0.6445\n",
            "t = 20, avg_loss = 0.6777\n",
            "t = 21, avg_loss = 0.6452\n",
            "t = 22, avg_loss = 0.6693\n",
            "t = 23, avg_loss = 0.5842\n",
            "t = 24, avg_loss = 0.6368\n",
            "t = 25, avg_loss = 0.6703\n",
            "Checking accuracy on test set\n",
            "Got 134 / 200 correct (67.00)\n",
            "acc = 0.670000\n",
            "Starting epoch 7 / 50\n",
            "t = 1, avg_loss = 0.6419\n",
            "t = 2, avg_loss = 0.6070\n",
            "t = 3, avg_loss = 0.6132\n",
            "t = 4, avg_loss = 0.5909\n",
            "t = 5, avg_loss = 0.7724\n",
            "t = 6, avg_loss = 0.6628\n",
            "t = 7, avg_loss = 0.7005\n",
            "t = 8, avg_loss = 0.6246\n",
            "t = 9, avg_loss = 0.6963\n",
            "t = 10, avg_loss = 0.6884\n",
            "t = 11, avg_loss = 0.6740\n",
            "t = 12, avg_loss = 0.6243\n",
            "t = 13, avg_loss = 0.6485\n",
            "t = 14, avg_loss = 0.6684\n",
            "t = 15, avg_loss = 0.7007\n",
            "t = 16, avg_loss = 0.7253\n",
            "t = 17, avg_loss = 0.6588\n",
            "t = 18, avg_loss = 0.5850\n",
            "t = 19, avg_loss = 0.6210\n",
            "t = 20, avg_loss = 0.6680\n",
            "t = 21, avg_loss = 0.6290\n",
            "t = 22, avg_loss = 0.6311\n",
            "t = 23, avg_loss = 0.6054\n",
            "t = 24, avg_loss = 0.7594\n",
            "t = 25, avg_loss = 0.6298\n",
            "Checking accuracy on test set\n",
            "Got 130 / 200 correct (65.00)\n",
            "acc = 0.650000\n",
            "Starting epoch 8 / 50\n",
            "t = 1, avg_loss = 0.6028\n",
            "t = 2, avg_loss = 0.6346\n",
            "t = 3, avg_loss = 0.6401\n",
            "t = 4, avg_loss = 0.5723\n",
            "t = 5, avg_loss = 0.5764\n",
            "t = 6, avg_loss = 0.7197\n",
            "t = 7, avg_loss = 0.5462\n",
            "t = 8, avg_loss = 0.6434\n",
            "t = 9, avg_loss = 0.8052\n",
            "t = 10, avg_loss = 0.7330\n",
            "t = 11, avg_loss = 0.6609\n",
            "t = 12, avg_loss = 0.6284\n",
            "t = 13, avg_loss = 0.8257\n",
            "t = 14, avg_loss = 0.6461\n",
            "t = 15, avg_loss = 0.5893\n",
            "t = 16, avg_loss = 0.6366\n",
            "t = 17, avg_loss = 0.7459\n",
            "t = 18, avg_loss = 0.7005\n",
            "t = 19, avg_loss = 0.6943\n",
            "t = 20, avg_loss = 0.6064\n",
            "t = 21, avg_loss = 0.6916\n",
            "t = 22, avg_loss = 0.6503\n",
            "t = 23, avg_loss = 0.6217\n",
            "t = 24, avg_loss = 0.5414\n",
            "t = 25, avg_loss = 0.6171\n",
            "Checking accuracy on test set\n",
            "Got 135 / 200 correct (67.50)\n",
            "acc = 0.675000\n",
            "Starting epoch 9 / 50\n",
            "t = 1, avg_loss = 0.6399\n",
            "t = 2, avg_loss = 0.5419\n",
            "t = 3, avg_loss = 0.7328\n",
            "t = 4, avg_loss = 0.7456\n",
            "t = 5, avg_loss = 0.6399\n",
            "t = 6, avg_loss = 0.6863\n",
            "t = 7, avg_loss = 0.5777\n",
            "t = 8, avg_loss = 0.6683\n",
            "t = 9, avg_loss = 0.6249\n",
            "t = 10, avg_loss = 0.6648\n",
            "t = 11, avg_loss = 0.6687\n",
            "t = 12, avg_loss = 0.6095\n",
            "t = 13, avg_loss = 0.7225\n",
            "t = 14, avg_loss = 0.6695\n",
            "t = 15, avg_loss = 0.6147\n",
            "t = 16, avg_loss = 0.6254\n",
            "t = 17, avg_loss = 0.6464\n",
            "t = 18, avg_loss = 0.6096\n",
            "t = 19, avg_loss = 0.6619\n",
            "t = 20, avg_loss = 0.6132\n",
            "t = 21, avg_loss = 0.6725\n",
            "t = 22, avg_loss = 0.6919\n",
            "t = 23, avg_loss = 0.7378\n",
            "t = 24, avg_loss = 0.6276\n",
            "t = 25, avg_loss = 0.6069\n",
            "Checking accuracy on test set\n",
            "Got 136 / 200 correct (68.00)\n",
            "acc = 0.680000\n",
            "Starting epoch 10 / 50\n",
            "t = 1, avg_loss = 0.6159\n",
            "t = 2, avg_loss = 0.8257\n",
            "t = 3, avg_loss = 0.6672\n",
            "t = 4, avg_loss = 0.6178\n",
            "t = 5, avg_loss = 0.6033\n",
            "t = 6, avg_loss = 0.5865\n",
            "t = 7, avg_loss = 0.6613\n",
            "t = 8, avg_loss = 0.6169\n",
            "t = 9, avg_loss = 0.6293\n",
            "t = 10, avg_loss = 0.6241\n",
            "t = 11, avg_loss = 0.7446\n",
            "t = 12, avg_loss = 0.6502\n",
            "t = 13, avg_loss = 0.5484\n",
            "t = 14, avg_loss = 0.6002\n",
            "t = 15, avg_loss = 0.6463\n",
            "t = 16, avg_loss = 0.6414\n",
            "t = 17, avg_loss = 0.6912\n",
            "t = 18, avg_loss = 0.7646\n",
            "t = 19, avg_loss = 0.5562\n",
            "t = 20, avg_loss = 0.6608\n",
            "t = 21, avg_loss = 0.7341\n",
            "t = 22, avg_loss = 0.6646\n",
            "t = 23, avg_loss = 0.6595\n",
            "t = 24, avg_loss = 0.6066\n",
            "t = 25, avg_loss = 0.6733\n",
            "Checking accuracy on test set\n",
            "Got 134 / 200 correct (67.00)\n",
            "acc = 0.670000\n",
            "Starting epoch 11 / 50\n",
            "t = 1, avg_loss = 0.6842\n",
            "t = 2, avg_loss = 0.6060\n",
            "t = 3, avg_loss = 0.6013\n",
            "t = 4, avg_loss = 0.6254\n",
            "t = 5, avg_loss = 0.6351\n",
            "t = 6, avg_loss = 0.6277\n",
            "t = 7, avg_loss = 0.6098\n",
            "t = 8, avg_loss = 0.6741\n",
            "t = 9, avg_loss = 0.6453\n",
            "t = 10, avg_loss = 0.6239\n",
            "t = 11, avg_loss = 0.6178\n",
            "t = 12, avg_loss = 0.6202\n",
            "t = 13, avg_loss = 0.6242\n",
            "t = 14, avg_loss = 0.5938\n",
            "t = 15, avg_loss = 0.7863\n",
            "t = 16, avg_loss = 0.6666\n",
            "t = 17, avg_loss = 0.5887\n",
            "t = 18, avg_loss = 0.6699\n",
            "t = 19, avg_loss = 0.6951\n",
            "t = 20, avg_loss = 0.6422\n",
            "t = 21, avg_loss = 0.6578\n",
            "t = 22, avg_loss = 0.6409\n",
            "t = 23, avg_loss = 0.6381\n",
            "t = 24, avg_loss = 0.6049\n",
            "t = 25, avg_loss = 0.5632\n",
            "Checking accuracy on test set\n",
            "Got 136 / 200 correct (68.00)\n",
            "acc = 0.680000\n",
            "Starting epoch 12 / 50\n",
            "t = 1, avg_loss = 0.6678\n",
            "t = 2, avg_loss = 0.6924\n",
            "t = 3, avg_loss = 0.7733\n",
            "t = 4, avg_loss = 0.5889\n",
            "t = 5, avg_loss = 0.6675\n",
            "t = 6, avg_loss = 0.6712\n",
            "t = 7, avg_loss = 0.6224\n",
            "t = 8, avg_loss = 0.6161\n",
            "t = 9, avg_loss = 0.7459\n",
            "t = 10, avg_loss = 0.6600\n",
            "t = 11, avg_loss = 0.5324\n",
            "t = 12, avg_loss = 0.6867\n",
            "t = 13, avg_loss = 0.7790\n",
            "t = 14, avg_loss = 0.6500\n",
            "t = 15, avg_loss = 0.6227\n",
            "t = 16, avg_loss = 0.6670\n",
            "t = 17, avg_loss = 0.6856\n",
            "t = 18, avg_loss = 0.6195\n",
            "t = 19, avg_loss = 0.5764\n",
            "t = 20, avg_loss = 0.6161\n",
            "t = 21, avg_loss = 0.6721\n",
            "t = 22, avg_loss = 0.6262\n",
            "t = 23, avg_loss = 0.6893\n",
            "t = 24, avg_loss = 0.6030\n",
            "t = 25, avg_loss = 0.5658\n",
            "Checking accuracy on test set\n",
            "Got 121 / 200 correct (60.50)\n",
            "acc = 0.605000\n",
            "Starting epoch 13 / 50\n",
            "t = 1, avg_loss = 0.6405\n",
            "t = 2, avg_loss = 0.6264\n",
            "t = 3, avg_loss = 0.6554\n",
            "t = 4, avg_loss = 0.5965\n",
            "t = 5, avg_loss = 0.5301\n",
            "t = 6, avg_loss = 0.6073\n",
            "t = 7, avg_loss = 0.6290\n",
            "t = 8, avg_loss = 0.7092\n",
            "t = 9, avg_loss = 0.7339\n",
            "t = 10, avg_loss = 0.6356\n",
            "t = 11, avg_loss = 0.6450\n",
            "t = 12, avg_loss = 0.6554\n",
            "t = 13, avg_loss = 0.5930\n",
            "t = 14, avg_loss = 0.7059\n",
            "t = 15, avg_loss = 0.6233\n",
            "t = 16, avg_loss = 0.6998\n",
            "t = 17, avg_loss = 0.6337\n",
            "t = 18, avg_loss = 0.6793\n",
            "t = 19, avg_loss = 0.5754\n",
            "t = 20, avg_loss = 0.7245\n",
            "t = 21, avg_loss = 0.5646\n",
            "t = 22, avg_loss = 0.6636\n",
            "t = 23, avg_loss = 0.6311\n",
            "t = 24, avg_loss = 0.6143\n",
            "t = 25, avg_loss = 0.7522\n",
            "Checking accuracy on test set\n",
            "Got 132 / 200 correct (66.00)\n",
            "acc = 0.660000\n",
            "Starting epoch 14 / 50\n",
            "t = 1, avg_loss = 0.5586\n",
            "t = 2, avg_loss = 0.6168\n",
            "t = 3, avg_loss = 0.6936\n",
            "t = 4, avg_loss = 0.6326\n",
            "t = 5, avg_loss = 0.5938\n",
            "t = 6, avg_loss = 0.7556\n",
            "t = 7, avg_loss = 0.5785\n",
            "t = 8, avg_loss = 0.6874\n",
            "t = 9, avg_loss = 0.5636\n",
            "t = 10, avg_loss = 0.5471\n",
            "t = 11, avg_loss = 0.6653\n",
            "t = 12, avg_loss = 0.5720\n",
            "t = 13, avg_loss = 0.7172\n",
            "t = 14, avg_loss = 0.6138\n",
            "t = 15, avg_loss = 0.6645\n",
            "t = 16, avg_loss = 0.6291\n",
            "t = 17, avg_loss = 0.5312\n",
            "t = 18, avg_loss = 0.6014\n",
            "t = 19, avg_loss = 0.6448\n",
            "t = 20, avg_loss = 0.8158\n",
            "t = 21, avg_loss = 0.9395\n",
            "t = 22, avg_loss = 0.6907\n",
            "t = 23, avg_loss = 0.5625\n",
            "t = 24, avg_loss = 0.6018\n",
            "t = 25, avg_loss = 0.8647\n",
            "Checking accuracy on test set\n",
            "Got 128 / 200 correct (64.00)\n",
            "acc = 0.640000\n",
            "Starting epoch 15 / 50\n",
            "t = 1, avg_loss = 0.6001\n",
            "t = 2, avg_loss = 0.5814\n",
            "t = 3, avg_loss = 0.6441\n",
            "t = 4, avg_loss = 0.6501\n",
            "t = 5, avg_loss = 0.6627\n",
            "t = 6, avg_loss = 0.6733\n",
            "t = 7, avg_loss = 0.6895\n",
            "t = 8, avg_loss = 0.6905\n",
            "t = 9, avg_loss = 0.6558\n",
            "t = 10, avg_loss = 0.6437\n",
            "t = 11, avg_loss = 0.7102\n",
            "t = 12, avg_loss = 0.6093\n",
            "t = 13, avg_loss = 0.6781\n",
            "t = 14, avg_loss = 0.6160\n",
            "t = 15, avg_loss = 0.6917\n",
            "t = 16, avg_loss = 0.5684\n",
            "t = 17, avg_loss = 0.6381\n",
            "t = 18, avg_loss = 0.5721\n",
            "t = 19, avg_loss = 0.6076\n",
            "t = 20, avg_loss = 0.5799\n",
            "t = 21, avg_loss = 0.6725\n",
            "t = 22, avg_loss = 0.7478\n",
            "t = 23, avg_loss = 0.6464\n",
            "t = 24, avg_loss = 0.6691\n",
            "t = 25, avg_loss = 0.6463\n",
            "Checking accuracy on test set\n",
            "Got 126 / 200 correct (63.00)\n",
            "acc = 0.630000\n",
            "Starting epoch 16 / 50\n",
            "t = 1, avg_loss = 0.7282\n",
            "t = 2, avg_loss = 0.7243\n",
            "t = 3, avg_loss = 0.6401\n",
            "t = 4, avg_loss = 0.6666\n",
            "t = 5, avg_loss = 0.6484\n",
            "t = 6, avg_loss = 0.6507\n",
            "t = 7, avg_loss = 0.6781\n",
            "t = 8, avg_loss = 0.7226\n",
            "t = 9, avg_loss = 0.6145\n",
            "t = 10, avg_loss = 0.7065\n",
            "t = 11, avg_loss = 0.6714\n",
            "t = 12, avg_loss = 0.5745\n",
            "t = 13, avg_loss = 0.6001\n",
            "t = 14, avg_loss = 0.5950\n",
            "t = 15, avg_loss = 0.6488\n",
            "t = 16, avg_loss = 0.6918\n",
            "t = 17, avg_loss = 0.6180\n",
            "t = 18, avg_loss = 0.5420\n",
            "t = 19, avg_loss = 0.5940\n",
            "t = 20, avg_loss = 0.6809\n",
            "t = 21, avg_loss = 0.7128\n",
            "t = 22, avg_loss = 0.6307\n",
            "t = 23, avg_loss = 0.7030\n",
            "t = 24, avg_loss = 0.6076\n",
            "t = 25, avg_loss = 0.6615\n",
            "Checking accuracy on test set\n",
            "Got 133 / 200 correct (66.50)\n",
            "acc = 0.665000\n",
            "Starting epoch 17 / 50\n",
            "t = 1, avg_loss = 0.6595\n",
            "t = 2, avg_loss = 0.6062\n",
            "t = 3, avg_loss = 0.5945\n",
            "t = 4, avg_loss = 0.5730\n",
            "t = 5, avg_loss = 0.7073\n",
            "t = 6, avg_loss = 0.5580\n",
            "t = 7, avg_loss = 0.6301\n",
            "t = 8, avg_loss = 0.5794\n",
            "t = 9, avg_loss = 0.5642\n",
            "t = 10, avg_loss = 0.6841\n",
            "t = 11, avg_loss = 0.7670\n",
            "t = 12, avg_loss = 0.7061\n",
            "t = 13, avg_loss = 0.4970\n",
            "t = 14, avg_loss = 0.6415\n",
            "t = 15, avg_loss = 0.7385\n",
            "t = 16, avg_loss = 0.5704\n",
            "t = 17, avg_loss = 0.6881\n",
            "t = 18, avg_loss = 0.7194\n",
            "t = 19, avg_loss = 0.6051\n",
            "t = 20, avg_loss = 0.6768\n",
            "t = 21, avg_loss = 0.6779\n",
            "t = 22, avg_loss = 0.6452\n",
            "t = 23, avg_loss = 0.6397\n",
            "t = 24, avg_loss = 0.5325\n",
            "t = 25, avg_loss = 0.7038\n",
            "Checking accuracy on test set\n",
            "Got 137 / 200 correct (68.50)\n",
            "acc = 0.685000\n",
            "Starting epoch 18 / 50\n",
            "t = 1, avg_loss = 0.6544\n",
            "t = 2, avg_loss = 0.5992\n",
            "t = 3, avg_loss = 0.6563\n",
            "t = 4, avg_loss = 0.6796\n",
            "t = 5, avg_loss = 0.6313\n",
            "t = 6, avg_loss = 0.6921\n",
            "t = 7, avg_loss = 0.6121\n",
            "t = 8, avg_loss = 0.5786\n",
            "t = 9, avg_loss = 0.5901\n",
            "t = 10, avg_loss = 0.6458\n",
            "t = 11, avg_loss = 0.6618\n",
            "t = 12, avg_loss = 0.6506\n",
            "t = 13, avg_loss = 0.6422\n",
            "t = 14, avg_loss = 0.5979\n",
            "t = 15, avg_loss = 0.6791\n",
            "t = 16, avg_loss = 0.6054\n",
            "t = 17, avg_loss = 0.6261\n",
            "t = 18, avg_loss = 0.5946\n",
            "t = 19, avg_loss = 0.5598\n",
            "t = 20, avg_loss = 0.5936\n",
            "t = 21, avg_loss = 0.7359\n",
            "t = 22, avg_loss = 0.6966\n",
            "t = 23, avg_loss = 0.6278\n",
            "t = 24, avg_loss = 0.6439\n",
            "t = 25, avg_loss = 0.5455\n",
            "Checking accuracy on test set\n",
            "Got 138 / 200 correct (69.00)\n",
            "acc = 0.690000\n",
            "Starting epoch 19 / 50\n",
            "t = 1, avg_loss = 0.7128\n",
            "t = 2, avg_loss = 0.6946\n",
            "t = 3, avg_loss = 0.5700\n",
            "t = 4, avg_loss = 0.7076\n",
            "t = 5, avg_loss = 0.5986\n",
            "t = 6, avg_loss = 0.6340\n",
            "t = 7, avg_loss = 0.6193\n",
            "t = 8, avg_loss = 0.7285\n",
            "t = 9, avg_loss = 0.6552\n",
            "t = 10, avg_loss = 0.5417\n",
            "t = 11, avg_loss = 0.7033\n",
            "t = 12, avg_loss = 0.5593\n",
            "t = 13, avg_loss = 0.7006\n",
            "t = 14, avg_loss = 0.5410\n",
            "t = 15, avg_loss = 0.6038\n",
            "t = 16, avg_loss = 0.6113\n",
            "t = 17, avg_loss = 0.5733\n",
            "t = 18, avg_loss = 0.5535\n",
            "t = 19, avg_loss = 0.6446\n",
            "t = 20, avg_loss = 0.5956\n",
            "t = 21, avg_loss = 0.7180\n",
            "t = 22, avg_loss = 0.6846\n",
            "t = 23, avg_loss = 0.7008\n",
            "t = 24, avg_loss = 0.5593\n",
            "t = 25, avg_loss = 0.6425\n",
            "Checking accuracy on test set\n",
            "Got 138 / 200 correct (69.00)\n",
            "acc = 0.690000\n",
            "Starting epoch 20 / 50\n",
            "t = 1, avg_loss = 0.7594\n",
            "t = 2, avg_loss = 0.5901\n",
            "t = 3, avg_loss = 0.6087\n",
            "t = 4, avg_loss = 0.6281\n",
            "t = 5, avg_loss = 0.7365\n",
            "t = 6, avg_loss = 0.6463\n",
            "t = 7, avg_loss = 0.7289\n",
            "t = 8, avg_loss = 0.4656\n",
            "t = 9, avg_loss = 0.6131\n",
            "t = 10, avg_loss = 0.6775\n",
            "t = 11, avg_loss = 0.7266\n",
            "t = 12, avg_loss = 0.5904\n",
            "t = 13, avg_loss = 0.5252\n",
            "t = 14, avg_loss = 0.6352\n",
            "t = 15, avg_loss = 0.6111\n",
            "t = 16, avg_loss = 0.6174\n",
            "t = 17, avg_loss = 0.6503\n",
            "t = 18, avg_loss = 0.6788\n",
            "t = 19, avg_loss = 0.6500\n",
            "t = 20, avg_loss = 0.6112\n",
            "t = 21, avg_loss = 0.5695\n",
            "t = 22, avg_loss = 0.6386\n",
            "t = 23, avg_loss = 0.6002\n",
            "t = 24, avg_loss = 0.5393\n",
            "t = 25, avg_loss = 0.5958\n",
            "Checking accuracy on test set\n",
            "Got 131 / 200 correct (65.50)\n",
            "acc = 0.655000\n",
            "Starting epoch 21 / 50\n",
            "t = 1, avg_loss = 0.6917\n",
            "t = 2, avg_loss = 0.6043\n",
            "t = 3, avg_loss = 0.6394\n",
            "t = 4, avg_loss = 0.6631\n",
            "t = 5, avg_loss = 0.7162\n",
            "t = 6, avg_loss = 0.5039\n",
            "t = 7, avg_loss = 0.6100\n",
            "t = 8, avg_loss = 0.5075\n",
            "t = 9, avg_loss = 0.6243\n",
            "t = 11, avg_loss = 0.5602\n",
            "t = 12, avg_loss = 0.7108\n",
            "t = 13, avg_loss = 0.6929\n",
            "t = 14, avg_loss = 0.5967\n",
            "t = 15, avg_loss = 0.6519\n",
            "t = 16, avg_loss = 0.6411\n",
            "t = 17, avg_loss = 0.6945\n",
            "t = 18, avg_loss = 0.5131\n",
            "t = 19, avg_loss = 0.6177\n",
            "t = 20, avg_loss = 0.6850\n",
            "t = 21, avg_loss = 0.6050\n",
            "t = 22, avg_loss = 0.5645\n",
            "t = 23, avg_loss = 0.6742\n",
            "t = 24, avg_loss = 0.6016\n",
            "t = 25, avg_loss = 0.6596\n",
            "Checking accuracy on test set\n",
            "Got 140 / 200 correct (70.00)\n",
            "acc = 0.700000\n",
            "Starting epoch 22 / 50\n",
            "t = 1, avg_loss = 0.6465\n",
            "t = 2, avg_loss = 0.5557\n",
            "t = 3, avg_loss = 0.5275\n",
            "t = 4, avg_loss = 0.6273\n",
            "t = 5, avg_loss = 0.6603\n",
            "t = 6, avg_loss = 0.6506\n",
            "t = 7, avg_loss = 0.6242\n",
            "t = 8, avg_loss = 0.5654\n",
            "t = 9, avg_loss = 0.9261\n",
            "t = 10, avg_loss = 0.6201\n",
            "t = 11, avg_loss = 0.6755\n",
            "t = 12, avg_loss = 0.7122\n",
            "t = 13, avg_loss = 0.6001\n",
            "t = 14, avg_loss = 0.5491\n",
            "t = 15, avg_loss = 0.5730\n",
            "t = 16, avg_loss = 0.5904\n",
            "t = 17, avg_loss = 0.6398\n",
            "t = 18, avg_loss = 0.6451\n",
            "t = 19, avg_loss = 0.7173\n",
            "t = 20, avg_loss = 0.6136\n",
            "t = 21, avg_loss = 0.6221\n",
            "t = 22, avg_loss = 0.7010\n",
            "t = 23, avg_loss = 0.5607\n",
            "t = 24, avg_loss = 0.6128\n",
            "t = 25, avg_loss = 0.6453\n",
            "Checking accuracy on test set\n",
            "Got 132 / 200 correct (66.00)\n",
            "acc = 0.660000\n",
            "Starting epoch 23 / 50\n",
            "t = 1, avg_loss = 0.5761\n",
            "t = 2, avg_loss = 0.5048\n",
            "t = 3, avg_loss = 0.5722\n",
            "t = 4, avg_loss = 0.6313\n",
            "t = 5, avg_loss = 0.7418\n",
            "t = 6, avg_loss = 0.6808\n",
            "t = 7, avg_loss = 0.6378\n",
            "t = 8, avg_loss = 0.7292\n",
            "t = 9, avg_loss = 0.6057\n",
            "t = 10, avg_loss = 0.5293\n",
            "t = 11, avg_loss = 0.5656\n",
            "t = 12, avg_loss = 0.6891\n",
            "t = 13, avg_loss = 0.5541\n",
            "t = 14, avg_loss = 0.5816\n",
            "t = 15, avg_loss = 0.5814\n",
            "t = 16, avg_loss = 0.6877\n",
            "t = 17, avg_loss = 0.6211\n",
            "t = 18, avg_loss = 0.6281\n",
            "t = 19, avg_loss = 0.6296\n",
            "t = 20, avg_loss = 0.6393\n",
            "t = 21, avg_loss = 0.6048\n",
            "t = 22, avg_loss = 0.6919\n",
            "t = 23, avg_loss = 0.5392\n",
            "t = 24, avg_loss = 0.6525\n",
            "t = 25, avg_loss = 0.5992\n",
            "Checking accuracy on test set\n",
            "Got 135 / 200 correct (67.50)\n",
            "acc = 0.675000\n",
            "Starting epoch 24 / 50\n",
            "t = 1, avg_loss = 0.4837\n",
            "t = 2, avg_loss = 0.6238\n",
            "t = 3, avg_loss = 0.5296\n",
            "t = 4, avg_loss = 0.5986\n",
            "t = 5, avg_loss = 0.5418\n",
            "t = 6, avg_loss = 0.6392\n",
            "t = 7, avg_loss = 0.6500\n",
            "t = 8, avg_loss = 0.5721\n",
            "t = 9, avg_loss = 0.5001\n",
            "t = 10, avg_loss = 0.7235\n",
            "t = 11, avg_loss = 0.7497\n",
            "t = 12, avg_loss = 0.6415\n",
            "t = 13, avg_loss = 0.5334\n",
            "t = 14, avg_loss = 0.5570\n",
            "t = 15, avg_loss = 0.8365\n",
            "t = 16, avg_loss = 0.5362\n",
            "t = 17, avg_loss = 0.4864\n",
            "t = 18, avg_loss = 0.7436\n",
            "t = 19, avg_loss = 0.6604\n",
            "t = 20, avg_loss = 0.6995\n",
            "t = 21, avg_loss = 0.6062\n",
            "t = 22, avg_loss = 0.6686\n",
            "t = 23, avg_loss = 0.5860\n",
            "t = 24, avg_loss = 0.6154\n",
            "t = 25, avg_loss = 0.6428\n",
            "Checking accuracy on test set\n",
            "Got 140 / 200 correct (70.00)\n",
            "acc = 0.700000\n",
            "Starting epoch 25 / 50\n",
            "t = 1, avg_loss = 0.7122\n",
            "t = 2, avg_loss = 0.6770\n",
            "t = 3, avg_loss = 0.4501\n",
            "t = 4, avg_loss = 0.5956\n",
            "t = 5, avg_loss = 0.6112\n",
            "t = 6, avg_loss = 0.6877\n",
            "t = 7, avg_loss = 0.6099\n",
            "t = 8, avg_loss = 0.7072\n",
            "t = 9, avg_loss = 0.6841\n",
            "t = 10, avg_loss = 0.5612\n",
            "t = 11, avg_loss = 0.5892\n",
            "t = 12, avg_loss = 0.4709\n",
            "t = 13, avg_loss = 0.5448\n",
            "t = 14, avg_loss = 0.5923\n",
            "t = 15, avg_loss = 0.6856\n",
            "t = 16, avg_loss = 0.7449\n",
            "t = 17, avg_loss = 0.5077\n",
            "t = 18, avg_loss = 0.7106\n",
            "t = 19, avg_loss = 0.6207\n",
            "t = 20, avg_loss = 0.7809\n",
            "t = 21, avg_loss = 0.7465\n",
            "t = 22, avg_loss = 0.6028\n",
            "t = 23, avg_loss = 0.6053\n",
            "t = 24, avg_loss = 0.5694\n",
            "t = 25, avg_loss = 0.5571\n",
            "Checking accuracy on test set\n",
            "Got 127 / 200 correct (63.50)\n",
            "acc = 0.635000\n",
            "Starting epoch 26 / 50\n",
            "t = 1, avg_loss = 0.6112\n",
            "t = 2, avg_loss = 0.5118\n",
            "t = 3, avg_loss = 0.5658\n",
            "t = 4, avg_loss = 0.6065\n",
            "t = 5, avg_loss = 0.6051\n",
            "t = 6, avg_loss = 0.6412\n",
            "t = 7, avg_loss = 0.4772\n",
            "t = 8, avg_loss = 0.5189\n",
            "t = 9, avg_loss = 0.6888\n",
            "t = 10, avg_loss = 0.6523\n",
            "t = 11, avg_loss = 0.6176\n",
            "t = 12, avg_loss = 0.6173\n",
            "t = 13, avg_loss = 0.5296\n",
            "t = 14, avg_loss = 0.5468\n",
            "t = 15, avg_loss = 0.4881\n",
            "t = 16, avg_loss = 0.7665\n",
            "t = 17, avg_loss = 0.8380\n",
            "t = 18, avg_loss = 0.6507\n",
            "t = 19, avg_loss = 0.5055\n",
            "t = 20, avg_loss = 0.5710\n",
            "t = 21, avg_loss = 0.5504\n",
            "t = 22, avg_loss = 0.5542\n",
            "t = 23, avg_loss = 0.6492\n",
            "t = 24, avg_loss = 0.6313\n",
            "t = 25, avg_loss = 0.6482\n",
            "Checking accuracy on test set\n",
            "Got 138 / 200 correct (69.00)\n",
            "acc = 0.690000\n",
            "Starting epoch 27 / 50\n",
            "t = 1, avg_loss = 0.6233\n",
            "t = 2, avg_loss = 0.5728\n",
            "t = 3, avg_loss = 0.6400\n",
            "t = 4, avg_loss = 0.5164\n",
            "t = 5, avg_loss = 0.7338\n",
            "t = 6, avg_loss = 0.4958\n",
            "t = 7, avg_loss = 0.5437\n",
            "t = 8, avg_loss = 0.5782\n",
            "t = 9, avg_loss = 0.4997\n",
            "t = 10, avg_loss = 0.6600\n",
            "t = 11, avg_loss = 0.6129\n",
            "t = 12, avg_loss = 0.8318\n",
            "t = 13, avg_loss = 0.6389\n",
            "t = 14, avg_loss = 0.6923\n",
            "t = 15, avg_loss = 0.5096\n",
            "t = 16, avg_loss = 0.6565\n",
            "t = 17, avg_loss = 0.5737\n",
            "t = 18, avg_loss = 0.6900\n",
            "t = 19, avg_loss = 0.5087\n",
            "t = 20, avg_loss = 0.6446\n",
            "t = 21, avg_loss = 0.5997\n",
            "t = 22, avg_loss = 0.6986\n",
            "t = 23, avg_loss = 0.5857\n",
            "t = 24, avg_loss = 0.5218\n",
            "t = 25, avg_loss = 0.4878\n",
            "Checking accuracy on test set\n",
            "Got 143 / 200 correct (71.50)\n",
            "acc = 0.715000\n",
            "Starting epoch 28 / 50\n",
            "t = 1, avg_loss = 0.5401\n",
            "t = 2, avg_loss = 0.5313\n",
            "t = 3, avg_loss = 0.5882\n",
            "t = 4, avg_loss = 0.4939\n",
            "t = 5, avg_loss = 0.6320\n",
            "t = 6, avg_loss = 0.4928\n",
            "t = 7, avg_loss = 0.5185\n",
            "t = 8, avg_loss = 0.5647\n",
            "t = 9, avg_loss = 0.6957\n",
            "t = 10, avg_loss = 0.5979\n",
            "t = 11, avg_loss = 0.5693\n",
            "t = 12, avg_loss = 0.6556\n",
            "t = 13, avg_loss = 0.8099\n",
            "t = 14, avg_loss = 0.5257\n",
            "t = 15, avg_loss = 0.7317\n",
            "t = 16, avg_loss = 0.7080\n",
            "t = 17, avg_loss = 0.6159\n",
            "t = 18, avg_loss = 0.5383\n",
            "t = 19, avg_loss = 0.5572\n",
            "t = 20, avg_loss = 0.6825\n",
            "t = 21, avg_loss = 0.4865\n",
            "t = 22, avg_loss = 0.6158\n",
            "t = 23, avg_loss = 0.5128\n",
            "t = 24, avg_loss = 0.6279\n",
            "t = 25, avg_loss = 0.5664\n",
            "Checking accuracy on test set\n",
            "Got 131 / 200 correct (65.50)\n",
            "acc = 0.655000\n",
            "Starting epoch 29 / 50\n",
            "t = 1, avg_loss = 0.6441\n",
            "t = 2, avg_loss = 0.6006\n",
            "t = 3, avg_loss = 0.5768\n",
            "t = 4, avg_loss = 0.5975\n",
            "t = 5, avg_loss = 0.5743\n",
            "t = 6, avg_loss = 0.5524\n",
            "t = 7, avg_loss = 0.5794\n",
            "t = 8, avg_loss = 0.5145\n",
            "t = 9, avg_loss = 0.4730\n",
            "t = 10, avg_loss = 0.7098\n",
            "t = 11, avg_loss = 0.5916\n",
            "t = 12, avg_loss = 0.6287\n",
            "t = 13, avg_loss = 0.6469\n",
            "t = 14, avg_loss = 0.6075\n",
            "t = 15, avg_loss = 0.4500\n",
            "t = 16, avg_loss = 0.5786\n",
            "t = 17, avg_loss = 0.7392\n",
            "t = 18, avg_loss = 0.5863\n",
            "t = 19, avg_loss = 0.5762\n",
            "t = 20, avg_loss = 0.4722\n",
            "t = 21, avg_loss = 0.6410\n",
            "t = 22, avg_loss = 0.5654\n",
            "t = 23, avg_loss = 0.7504\n",
            "t = 24, avg_loss = 0.6725\n",
            "t = 25, avg_loss = 0.5581\n",
            "Checking accuracy on test set\n",
            "Got 136 / 200 correct (68.00)\n",
            "acc = 0.680000\n",
            "Starting epoch 30 / 50\n",
            "t = 1, avg_loss = 0.6251\n",
            "t = 2, avg_loss = 0.6000\n",
            "t = 3, avg_loss = 0.5338\n",
            "t = 4, avg_loss = 0.6365\n",
            "t = 5, avg_loss = 0.7032\n",
            "t = 6, avg_loss = 0.6679\n",
            "t = 7, avg_loss = 0.6423\n",
            "t = 8, avg_loss = 0.6386\n",
            "t = 9, avg_loss = 0.6113\n",
            "t = 10, avg_loss = 0.6679\n",
            "t = 11, avg_loss = 0.6020\n",
            "t = 12, avg_loss = 0.6745\n",
            "t = 13, avg_loss = 0.6010\n",
            "t = 14, avg_loss = 0.5177\n",
            "t = 15, avg_loss = 0.5373\n",
            "t = 16, avg_loss = 0.5848\n",
            "t = 17, avg_loss = 0.6777\n",
            "t = 18, avg_loss = 0.6582\n",
            "t = 19, avg_loss = 0.4871\n",
            "t = 20, avg_loss = 0.5617\n",
            "t = 21, avg_loss = 0.6133\n",
            "t = 22, avg_loss = 0.5685\n",
            "t = 23, avg_loss = 0.7471\n",
            "t = 24, avg_loss = 0.5953\n",
            "t = 25, avg_loss = 0.5932\n",
            "Checking accuracy on test set\n",
            "Got 133 / 200 correct (66.50)\n",
            "acc = 0.665000\n",
            "Starting epoch 31 / 50\n",
            "t = 1, avg_loss = 0.6043\n",
            "t = 2, avg_loss = 0.6655\n",
            "t = 3, avg_loss = 0.4502\n",
            "t = 4, avg_loss = 0.5268\n",
            "t = 5, avg_loss = 0.6013\n",
            "t = 6, avg_loss = 0.5400\n",
            "t = 7, avg_loss = 0.5437\n",
            "t = 8, avg_loss = 0.5758\n",
            "t = 9, avg_loss = 0.5260\n",
            "t = 10, avg_loss = 0.4747\n",
            "t = 11, avg_loss = 0.4932\n",
            "t = 12, avg_loss = 0.5588\n",
            "t = 13, avg_loss = 0.4589\n",
            "t = 14, avg_loss = 0.4751\n",
            "t = 15, avg_loss = 0.4753\n",
            "t = 16, avg_loss = 0.8654\n",
            "t = 17, avg_loss = 0.4032\n",
            "t = 18, avg_loss = 0.6194\n",
            "t = 19, avg_loss = 0.5516\n",
            "t = 20, avg_loss = 0.6123\n",
            "t = 21, avg_loss = 0.5419\n",
            "t = 22, avg_loss = 0.7987\n",
            "t = 23, avg_loss = 0.6975\n",
            "t = 24, avg_loss = 0.7982\n",
            "t = 25, avg_loss = 0.7086\n",
            "Checking accuracy on test set\n",
            "Got 134 / 200 correct (67.00)\n",
            "acc = 0.670000\n",
            "Starting epoch 32 / 50\n",
            "t = 1, avg_loss = 0.5275\n",
            "t = 2, avg_loss = 0.7463\n",
            "t = 3, avg_loss = 0.5972\n",
            "t = 4, avg_loss = 0.5032\n",
            "t = 5, avg_loss = 0.6224\n",
            "t = 6, avg_loss = 0.4914\n",
            "t = 7, avg_loss = 0.6291\n",
            "t = 8, avg_loss = 0.6804\n",
            "t = 9, avg_loss = 0.5567\n",
            "t = 10, avg_loss = 0.6316\n",
            "t = 11, avg_loss = 0.6639\n",
            "t = 12, avg_loss = 0.6594\n",
            "t = 13, avg_loss = 0.6767\n",
            "t = 14, avg_loss = 0.6393\n",
            "t = 15, avg_loss = 0.5408\n",
            "t = 16, avg_loss = 0.6203\n",
            "t = 17, avg_loss = 0.5595\n",
            "t = 18, avg_loss = 0.6704\n",
            "t = 19, avg_loss = 0.6195\n",
            "t = 20, avg_loss = 0.6353\n",
            "t = 21, avg_loss = 0.5930\n",
            "t = 22, avg_loss = 0.5174\n",
            "t = 23, avg_loss = 0.5667\n",
            "t = 24, avg_loss = 0.6262\n",
            "t = 25, avg_loss = 0.4368\n",
            "Checking accuracy on test set\n",
            "Got 145 / 200 correct (72.50)\n",
            "acc = 0.725000\n",
            "Starting epoch 33 / 50\n",
            "t = 1, avg_loss = 0.5868\n",
            "t = 2, avg_loss = 0.4769\n",
            "t = 3, avg_loss = 0.6448\n",
            "t = 4, avg_loss = 0.5263\n",
            "t = 5, avg_loss = 0.6296\n",
            "t = 6, avg_loss = 0.5664\n",
            "t = 7, avg_loss = 0.5319\n",
            "t = 8, avg_loss = 0.5957\n",
            "t = 9, avg_loss = 0.5962\n",
            "t = 10, avg_loss = 0.5713\n",
            "t = 11, avg_loss = 0.5522\n",
            "t = 12, avg_loss = 0.5303\n",
            "t = 13, avg_loss = 0.6084\n",
            "t = 14, avg_loss = 0.6580\n",
            "t = 15, avg_loss = 0.6518\n",
            "t = 16, avg_loss = 0.5606\n",
            "t = 17, avg_loss = 0.5404\n",
            "t = 18, avg_loss = 0.5668\n",
            "t = 19, avg_loss = 0.7408\n",
            "t = 20, avg_loss = 0.5254\n",
            "t = 21, avg_loss = 0.5303\n",
            "t = 22, avg_loss = 0.4888\n",
            "t = 23, avg_loss = 0.5195\n",
            "t = 24, avg_loss = 0.5741\n",
            "t = 25, avg_loss = 0.4479\n",
            "Checking accuracy on test set\n",
            "Got 131 / 200 correct (65.50)\n",
            "acc = 0.655000\n",
            "Starting epoch 34 / 50\n",
            "t = 1, avg_loss = 0.4964\n",
            "t = 2, avg_loss = 0.5785\n",
            "t = 3, avg_loss = 0.6335\n",
            "t = 4, avg_loss = 0.5773\n",
            "t = 5, avg_loss = 0.6359\n",
            "t = 6, avg_loss = 0.5304\n",
            "t = 7, avg_loss = 0.6556\n",
            "t = 8, avg_loss = 0.6136\n",
            "t = 9, avg_loss = 0.4947\n",
            "t = 10, avg_loss = 0.4993\n",
            "t = 11, avg_loss = 0.4886\n",
            "t = 12, avg_loss = 0.4336\n",
            "t = 13, avg_loss = 0.5040\n",
            "t = 14, avg_loss = 0.6623\n",
            "t = 15, avg_loss = 0.6046\n",
            "t = 16, avg_loss = 0.5270\n",
            "t = 17, avg_loss = 0.7153\n",
            "t = 18, avg_loss = 0.6335\n",
            "t = 19, avg_loss = 0.3908\n",
            "t = 20, avg_loss = 0.5489\n",
            "t = 21, avg_loss = 0.4696\n",
            "t = 22, avg_loss = 0.4875\n",
            "t = 23, avg_loss = 0.5051\n",
            "t = 24, avg_loss = 0.6778\n",
            "t = 25, avg_loss = 0.5289\n",
            "Checking accuracy on test set\n",
            "Got 137 / 200 correct (68.50)\n",
            "acc = 0.685000\n",
            "Starting epoch 35 / 50\n",
            "t = 1, avg_loss = 0.8605\n",
            "t = 2, avg_loss = 0.5212\n",
            "t = 3, avg_loss = 0.5156\n",
            "t = 4, avg_loss = 0.5954\n",
            "t = 5, avg_loss = 0.3896\n",
            "t = 6, avg_loss = 0.5636\n",
            "t = 7, avg_loss = 0.5245\n",
            "t = 8, avg_loss = 0.5079\n",
            "t = 9, avg_loss = 0.7790\n",
            "t = 10, avg_loss = 0.5313\n",
            "t = 11, avg_loss = 0.5618\n",
            "t = 12, avg_loss = 0.5529\n",
            "t = 13, avg_loss = 0.4957\n",
            "t = 14, avg_loss = 0.4989\n",
            "t = 15, avg_loss = 0.5700\n",
            "t = 16, avg_loss = 0.4458\n",
            "t = 17, avg_loss = 0.5754\n",
            "t = 18, avg_loss = 0.6027\n",
            "t = 19, avg_loss = 0.4814\n",
            "t = 20, avg_loss = 0.5144\n",
            "t = 21, avg_loss = 0.4745\n",
            "t = 22, avg_loss = 0.4968\n",
            "t = 23, avg_loss = 0.5341\n",
            "t = 24, avg_loss = 0.5932\n",
            "t = 25, avg_loss = 0.5927\n",
            "Checking accuracy on test set\n",
            "Got 133 / 200 correct (66.50)\n",
            "acc = 0.665000\n",
            "Starting epoch 36 / 50\n",
            "t = 1, avg_loss = 0.4897\n",
            "t = 2, avg_loss = 0.6498\n",
            "t = 3, avg_loss = 0.5275\n",
            "t = 4, avg_loss = 0.6079\n",
            "t = 5, avg_loss = 0.6885\n",
            "t = 6, avg_loss = 0.6244\n",
            "t = 7, avg_loss = 0.4529\n",
            "t = 8, avg_loss = 0.4523\n",
            "t = 9, avg_loss = 0.4942\n",
            "t = 10, avg_loss = 0.4985\n",
            "t = 11, avg_loss = 0.6294\n",
            "t = 12, avg_loss = 0.5913\n",
            "t = 13, avg_loss = 0.6400\n",
            "t = 14, avg_loss = 0.6272\n",
            "t = 15, avg_loss = 0.5341\n",
            "t = 16, avg_loss = 0.6262\n",
            "t = 17, avg_loss = 0.4980\n",
            "t = 18, avg_loss = 0.5492\n",
            "t = 19, avg_loss = 0.6148\n",
            "t = 20, avg_loss = 0.7071\n",
            "t = 21, avg_loss = 0.6078\n",
            "t = 22, avg_loss = 0.5764\n",
            "t = 23, avg_loss = 0.6596\n",
            "t = 24, avg_loss = 0.6612\n",
            "t = 25, avg_loss = 0.5598\n",
            "Checking accuracy on test set\n",
            "Got 120 / 200 correct (60.00)\n",
            "acc = 0.600000\n",
            "Starting epoch 37 / 50\n",
            "t = 1, avg_loss = 0.4665\n",
            "t = 2, avg_loss = 0.4425\n",
            "t = 3, avg_loss = 0.5821\n",
            "t = 4, avg_loss = 0.4975\n",
            "t = 5, avg_loss = 0.6232\n",
            "t = 6, avg_loss = 0.5459\n",
            "t = 7, avg_loss = 0.5570\n",
            "t = 8, avg_loss = 0.7552\n",
            "t = 9, avg_loss = 0.6842\n",
            "t = 10, avg_loss = 0.5864\n",
            "t = 11, avg_loss = 0.5807\n",
            "t = 12, avg_loss = 0.6005\n",
            "t = 13, avg_loss = 0.5062\n",
            "t = 14, avg_loss = 0.5839\n",
            "t = 15, avg_loss = 0.6937\n",
            "t = 16, avg_loss = 0.6982\n",
            "t = 17, avg_loss = 0.5543\n",
            "t = 18, avg_loss = 0.4366\n",
            "t = 19, avg_loss = 0.5116\n",
            "t = 20, avg_loss = 0.6232\n",
            "t = 21, avg_loss = 0.6435\n",
            "t = 22, avg_loss = 0.5430\n",
            "t = 23, avg_loss = 0.6190\n",
            "t = 24, avg_loss = 0.5001\n",
            "t = 25, avg_loss = 0.5657\n",
            "Checking accuracy on test set\n",
            "Got 139 / 200 correct (69.50)\n",
            "acc = 0.695000\n",
            "Starting epoch 38 / 50\n",
            "t = 1, avg_loss = 0.4519\n",
            "t = 2, avg_loss = 0.5219\n",
            "t = 3, avg_loss = 0.5765\n",
            "t = 4, avg_loss = 0.5064\n",
            "t = 5, avg_loss = 0.6645\n",
            "t = 6, avg_loss = 0.6407\n",
            "t = 7, avg_loss = 0.5340\n",
            "t = 8, avg_loss = 0.5015\n",
            "t = 9, avg_loss = 0.4580\n",
            "t = 10, avg_loss = 0.5844\n",
            "t = 11, avg_loss = 0.6600\n",
            "t = 12, avg_loss = 0.6805\n",
            "t = 13, avg_loss = 0.5798\n",
            "t = 14, avg_loss = 0.6322\n",
            "t = 15, avg_loss = 0.5109\n",
            "t = 16, avg_loss = 0.4217\n",
            "t = 17, avg_loss = 0.5687\n",
            "t = 18, avg_loss = 0.3849\n",
            "t = 19, avg_loss = 0.5245\n",
            "t = 20, avg_loss = 0.5315\n",
            "t = 21, avg_loss = 0.5482\n",
            "t = 22, avg_loss = 0.6113\n",
            "t = 23, avg_loss = 0.6813\n",
            "t = 24, avg_loss = 0.6346\n",
            "t = 25, avg_loss = 0.5431\n",
            "Checking accuracy on test set\n",
            "Got 119 / 200 correct (59.50)\n",
            "acc = 0.595000\n",
            "Starting epoch 39 / 50\n",
            "t = 1, avg_loss = 0.4912\n",
            "t = 2, avg_loss = 0.4398\n",
            "t = 3, avg_loss = 0.4663\n",
            "t = 4, avg_loss = 0.5576\n",
            "t = 5, avg_loss = 0.4874\n",
            "t = 6, avg_loss = 0.4772\n",
            "t = 7, avg_loss = 0.6455\n",
            "t = 8, avg_loss = 0.5231\n",
            "t = 9, avg_loss = 0.4774\n",
            "t = 10, avg_loss = 0.6089\n",
            "t = 11, avg_loss = 0.4195\n",
            "t = 12, avg_loss = 0.6197\n",
            "t = 13, avg_loss = 0.6309\n",
            "t = 14, avg_loss = 0.6724\n",
            "t = 15, avg_loss = 0.4156\n",
            "t = 16, avg_loss = 0.7478\n",
            "t = 17, avg_loss = 0.5450\n",
            "t = 18, avg_loss = 0.4285\n",
            "t = 19, avg_loss = 0.4410\n",
            "t = 20, avg_loss = 0.4700\n",
            "t = 21, avg_loss = 0.7936\n",
            "t = 22, avg_loss = 0.5927\n",
            "t = 23, avg_loss = 0.5649\n",
            "t = 24, avg_loss = 0.5161\n",
            "t = 25, avg_loss = 0.4406\n",
            "Checking accuracy on test set\n",
            "Got 135 / 200 correct (67.50)\n",
            "acc = 0.675000\n",
            "Starting epoch 40 / 50\n",
            "t = 1, avg_loss = 0.4611\n",
            "t = 2, avg_loss = 0.6028\n",
            "t = 3, avg_loss = 0.4883\n",
            "t = 4, avg_loss = 0.5885\n",
            "t = 5, avg_loss = 0.4903\n",
            "t = 6, avg_loss = 0.6479\n",
            "t = 7, avg_loss = 0.5266\n",
            "t = 8, avg_loss = 0.5929\n",
            "t = 9, avg_loss = 0.5544\n",
            "t = 10, avg_loss = 0.4563\n",
            "t = 11, avg_loss = 0.5867\n",
            "t = 12, avg_loss = 0.5953\n",
            "t = 13, avg_loss = 0.5139\n",
            "t = 14, avg_loss = 0.4912\n",
            "t = 15, avg_loss = 0.6356\n",
            "t = 16, avg_loss = 0.4592\n",
            "t = 17, avg_loss = 0.6334\n",
            "t = 18, avg_loss = 0.6045\n",
            "t = 19, avg_loss = 0.5599\n",
            "t = 20, avg_loss = 0.5373\n",
            "t = 21, avg_loss = 0.5229\n",
            "t = 22, avg_loss = 0.5216\n",
            "t = 23, avg_loss = 0.5270\n",
            "t = 24, avg_loss = 0.5707\n",
            "t = 25, avg_loss = 0.5562\n",
            "Checking accuracy on test set\n",
            "Got 118 / 200 correct (59.00)\n",
            "acc = 0.590000\n",
            "Starting epoch 41 / 50\n",
            "t = 1, avg_loss = 0.4667\n",
            "t = 2, avg_loss = 0.5829\n",
            "t = 3, avg_loss = 0.4653\n",
            "t = 4, avg_loss = 0.4720\n",
            "t = 5, avg_loss = 0.6294\n",
            "t = 6, avg_loss = 0.5934\n",
            "t = 7, avg_loss = 0.5988\n",
            "t = 8, avg_loss = 0.4557\n",
            "t = 9, avg_loss = 0.5159\n",
            "t = 10, avg_loss = 0.6479\n",
            "t = 11, avg_loss = 0.4236\n",
            "t = 12, avg_loss = 0.4650\n",
            "t = 13, avg_loss = 0.6626\n",
            "t = 14, avg_loss = 0.6221\n",
            "t = 15, avg_loss = 0.6069\n",
            "t = 16, avg_loss = 0.6383\n",
            "t = 17, avg_loss = 0.4851\n",
            "t = 18, avg_loss = 0.4592\n",
            "t = 19, avg_loss = 0.5583\n",
            "t = 20, avg_loss = 0.5956\n",
            "t = 21, avg_loss = 0.4553\n",
            "t = 22, avg_loss = 0.5471\n",
            "t = 23, avg_loss = 0.5913\n",
            "t = 24, avg_loss = 0.5674\n",
            "t = 25, avg_loss = 0.5706\n",
            "Checking accuracy on test set\n",
            "Got 145 / 200 correct (72.50)\n",
            "acc = 0.725000\n",
            "Starting epoch 42 / 50\n",
            "t = 1, avg_loss = 0.4394\n",
            "t = 2, avg_loss = 0.5778\n",
            "t = 3, avg_loss = 0.5717\n",
            "t = 4, avg_loss = 0.5424\n",
            "t = 5, avg_loss = 0.4437\n",
            "t = 6, avg_loss = 0.4569\n",
            "t = 7, avg_loss = 0.5626\n",
            "t = 8, avg_loss = 0.5452\n",
            "t = 9, avg_loss = 0.5009\n",
            "t = 10, avg_loss = 0.6931\n",
            "t = 11, avg_loss = 0.5370\n",
            "t = 12, avg_loss = 0.4825\n",
            "t = 13, avg_loss = 0.6694\n",
            "t = 14, avg_loss = 0.5961\n",
            "t = 15, avg_loss = 0.4770\n",
            "t = 16, avg_loss = 0.5614\n",
            "t = 17, avg_loss = 0.5005\n",
            "t = 18, avg_loss = 0.5238\n",
            "t = 19, avg_loss = 0.5242\n",
            "t = 20, avg_loss = 0.5689\n",
            "t = 21, avg_loss = 0.5608\n",
            "t = 22, avg_loss = 0.5071\n",
            "t = 23, avg_loss = 0.6215\n",
            "t = 24, avg_loss = 0.4973\n",
            "t = 25, avg_loss = 0.5301\n",
            "Checking accuracy on test set\n",
            "Got 117 / 200 correct (58.50)\n",
            "acc = 0.585000\n",
            "Starting epoch 43 / 50\n",
            "t = 1, avg_loss = 0.5871\n",
            "t = 2, avg_loss = 0.5463\n",
            "t = 3, avg_loss = 0.5413\n",
            "t = 4, avg_loss = 0.5049\n",
            "t = 5, avg_loss = 0.5476\n",
            "t = 6, avg_loss = 0.4041\n",
            "t = 7, avg_loss = 0.5811\n",
            "t = 8, avg_loss = 0.3825\n",
            "t = 9, avg_loss = 0.6590\n",
            "t = 10, avg_loss = 0.5922\n",
            "t = 11, avg_loss = 0.5076\n",
            "t = 12, avg_loss = 0.5117\n",
            "t = 13, avg_loss = 0.5685\n",
            "t = 14, avg_loss = 0.6919\n",
            "t = 15, avg_loss = 0.6220\n",
            "t = 16, avg_loss = 0.5466\n",
            "t = 17, avg_loss = 0.5435\n",
            "t = 18, avg_loss = 0.4154\n",
            "t = 19, avg_loss = 0.3684\n",
            "t = 20, avg_loss = 0.3556\n",
            "t = 21, avg_loss = 0.6577\n",
            "t = 22, avg_loss = 0.5337\n",
            "t = 23, avg_loss = 0.6360\n",
            "t = 24, avg_loss = 0.5205\n",
            "t = 25, avg_loss = 0.5704\n",
            "Checking accuracy on test set\n",
            "Got 155 / 200 correct (77.50)\n",
            "acc = 0.775000\n",
            "Starting epoch 44 / 50\n",
            "t = 1, avg_loss = 0.5540\n",
            "t = 2, avg_loss = 0.4767\n",
            "t = 3, avg_loss = 0.4410\n",
            "t = 4, avg_loss = 0.4641\n",
            "t = 5, avg_loss = 0.4938\n",
            "t = 6, avg_loss = 0.5041\n",
            "t = 7, avg_loss = 0.4393\n",
            "t = 8, avg_loss = 0.5405\n",
            "t = 9, avg_loss = 0.6089\n",
            "t = 10, avg_loss = 0.6041\n",
            "t = 11, avg_loss = 0.5927\n",
            "t = 12, avg_loss = 0.5478\n",
            "t = 13, avg_loss = 0.6729\n",
            "t = 14, avg_loss = 0.4315\n",
            "t = 15, avg_loss = 0.5259\n",
            "t = 16, avg_loss = 0.5664\n",
            "t = 17, avg_loss = 0.6900\n",
            "t = 18, avg_loss = 0.5563\n",
            "t = 19, avg_loss = 0.5696\n",
            "t = 20, avg_loss = 0.4524\n",
            "t = 21, avg_loss = 0.4512\n",
            "t = 22, avg_loss = 0.6941\n",
            "t = 23, avg_loss = 0.5350\n",
            "t = 24, avg_loss = 0.5167\n",
            "t = 25, avg_loss = 0.4793\n",
            "Checking accuracy on test set\n",
            "Got 152 / 200 correct (76.00)\n",
            "acc = 0.760000\n",
            "Starting epoch 45 / 50\n",
            "t = 1, avg_loss = 0.5614\n",
            "t = 2, avg_loss = 0.4127\n",
            "t = 3, avg_loss = 0.5217\n",
            "t = 4, avg_loss = 0.4566\n",
            "t = 5, avg_loss = 0.4437\n",
            "t = 6, avg_loss = 0.5835\n",
            "t = 7, avg_loss = 0.6411\n",
            "t = 8, avg_loss = 0.6562\n",
            "t = 9, avg_loss = 0.4936\n",
            "t = 10, avg_loss = 0.5679\n",
            "t = 11, avg_loss = 0.5333\n",
            "t = 12, avg_loss = 0.5643\n",
            "t = 13, avg_loss = 0.5162\n",
            "t = 14, avg_loss = 0.5569\n",
            "t = 15, avg_loss = 0.4815\n",
            "t = 16, avg_loss = 0.4749\n",
            "t = 17, avg_loss = 0.5627\n",
            "t = 18, avg_loss = 0.7899\n",
            "t = 19, avg_loss = 0.6812\n",
            "t = 20, avg_loss = 0.5066\n",
            "t = 21, avg_loss = 0.5677\n",
            "t = 22, avg_loss = 0.3765\n",
            "t = 23, avg_loss = 0.4731\n",
            "t = 24, avg_loss = 0.4724\n",
            "t = 25, avg_loss = 0.5772\n",
            "Checking accuracy on test set\n",
            "Got 127 / 200 correct (63.50)\n",
            "acc = 0.635000\n",
            "Starting epoch 46 / 50\n",
            "t = 1, avg_loss = 0.4051\n",
            "t = 2, avg_loss = 0.4688\n",
            "t = 3, avg_loss = 0.4946\n",
            "t = 4, avg_loss = 0.5135\n",
            "t = 5, avg_loss = 0.5095\n",
            "t = 6, avg_loss = 0.7141\n",
            "t = 7, avg_loss = 0.6511\n",
            "t = 8, avg_loss = 0.6582\n",
            "t = 9, avg_loss = 0.4887\n",
            "t = 10, avg_loss = 0.5754\n",
            "t = 11, avg_loss = 0.5550\n",
            "t = 12, avg_loss = 0.5217\n",
            "t = 13, avg_loss = 0.4888\n",
            "t = 14, avg_loss = 0.4713\n",
            "t = 15, avg_loss = 0.6028\n",
            "t = 16, avg_loss = 0.6058\n",
            "t = 17, avg_loss = 0.3630\n",
            "t = 18, avg_loss = 0.7456\n",
            "t = 19, avg_loss = 0.4262\n",
            "t = 20, avg_loss = 0.7251\n",
            "t = 21, avg_loss = 0.4533\n",
            "t = 22, avg_loss = 0.4086\n",
            "t = 23, avg_loss = 0.6129\n",
            "t = 24, avg_loss = 0.4744\n",
            "t = 25, avg_loss = 0.6153\n",
            "Checking accuracy on test set\n",
            "Got 122 / 200 correct (61.00)\n",
            "acc = 0.610000\n",
            "Starting epoch 47 / 50\n",
            "t = 1, avg_loss = 0.5302\n",
            "t = 2, avg_loss = 0.5913\n",
            "t = 3, avg_loss = 0.5420\n",
            "t = 4, avg_loss = 0.5904\n",
            "t = 5, avg_loss = 0.4509\n",
            "t = 6, avg_loss = 0.6207\n",
            "t = 7, avg_loss = 0.4571\n",
            "t = 8, avg_loss = 0.5594\n",
            "t = 9, avg_loss = 0.5981\n",
            "t = 10, avg_loss = 0.4144\n",
            "t = 11, avg_loss = 0.6218\n",
            "t = 12, avg_loss = 0.4920\n",
            "t = 13, avg_loss = 0.4835\n",
            "t = 14, avg_loss = 0.4318\n",
            "t = 15, avg_loss = 0.5436\n",
            "t = 16, avg_loss = 0.3759\n",
            "t = 17, avg_loss = 0.5467\n",
            "t = 18, avg_loss = 0.5731\n",
            "t = 19, avg_loss = 0.4573\n",
            "t = 20, avg_loss = 0.6425\n",
            "t = 21, avg_loss = 0.6517\n",
            "t = 22, avg_loss = 0.3910\n",
            "t = 23, avg_loss = 0.7334\n",
            "t = 24, avg_loss = 0.4499\n",
            "t = 25, avg_loss = 0.4221\n",
            "Checking accuracy on test set\n",
            "Got 148 / 200 correct (74.00)\n",
            "acc = 0.740000\n",
            "Starting epoch 48 / 50\n",
            "t = 1, avg_loss = 0.6556\n",
            "t = 2, avg_loss = 0.3663\n",
            "t = 3, avg_loss = 0.5261\n",
            "t = 4, avg_loss = 0.4015\n",
            "t = 5, avg_loss = 0.3816\n",
            "t = 6, avg_loss = 0.4746\n",
            "t = 7, avg_loss = 0.6176\n",
            "t = 8, avg_loss = 0.5166\n",
            "t = 9, avg_loss = 0.5567\n",
            "t = 10, avg_loss = 0.6160\n",
            "t = 11, avg_loss = 0.4380\n",
            "t = 12, avg_loss = 0.4480\n",
            "t = 13, avg_loss = 0.6389\n",
            "t = 14, avg_loss = 0.6323\n",
            "t = 15, avg_loss = 0.5037\n",
            "t = 16, avg_loss = 0.6108\n",
            "t = 17, avg_loss = 0.6252\n",
            "t = 18, avg_loss = 0.5647\n",
            "t = 19, avg_loss = 0.4908\n",
            "t = 20, avg_loss = 0.5256\n",
            "t = 21, avg_loss = 0.4721\n",
            "t = 22, avg_loss = 0.6140\n",
            "t = 23, avg_loss = 0.4619\n",
            "t = 24, avg_loss = 0.4073\n",
            "t = 25, avg_loss = 0.5563\n",
            "Checking accuracy on test set\n",
            "Got 151 / 200 correct (75.50)\n",
            "acc = 0.755000\n",
            "Starting epoch 49 / 50\n",
            "t = 1, avg_loss = 0.4600\n",
            "t = 2, avg_loss = 0.4574\n",
            "t = 3, avg_loss = 0.4548\n",
            "t = 4, avg_loss = 0.6648\n",
            "t = 5, avg_loss = 0.4965\n",
            "t = 6, avg_loss = 0.5325\n",
            "t = 7, avg_loss = 0.6378\n",
            "t = 8, avg_loss = 0.4998\n",
            "t = 9, avg_loss = 0.4730\n",
            "t = 10, avg_loss = 0.5409\n",
            "t = 11, avg_loss = 0.5902\n",
            "t = 12, avg_loss = 0.4951\n",
            "t = 13, avg_loss = 0.4721\n",
            "t = 14, avg_loss = 0.4186\n",
            "t = 15, avg_loss = 0.5555\n",
            "t = 16, avg_loss = 0.3465\n",
            "t = 17, avg_loss = 0.5690\n",
            "t = 18, avg_loss = 0.5936\n",
            "t = 19, avg_loss = 0.5321\n",
            "t = 20, avg_loss = 0.4940\n",
            "t = 21, avg_loss = 0.5598\n",
            "t = 22, avg_loss = 0.6532\n",
            "t = 23, avg_loss = 0.3730\n",
            "t = 24, avg_loss = 0.5829\n",
            "t = 25, avg_loss = 0.4478\n",
            "Checking accuracy on test set\n",
            "Got 149 / 200 correct (74.50)\n",
            "acc = 0.745000\n",
            "Starting epoch 50 / 50\n",
            "t = 1, avg_loss = 0.4088\n",
            "t = 2, avg_loss = 0.4372\n",
            "t = 3, avg_loss = 0.5225\n",
            "t = 4, avg_loss = 0.5490\n",
            "t = 5, avg_loss = 0.7457\n",
            "t = 6, avg_loss = 0.4749\n",
            "t = 7, avg_loss = 0.4724\n",
            "t = 8, avg_loss = 0.4966\n",
            "t = 9, avg_loss = 0.5761\n",
            "t = 10, avg_loss = 0.5643\n",
            "t = 11, avg_loss = 0.6139\n",
            "t = 12, avg_loss = 0.5786\n",
            "t = 13, avg_loss = 0.3849\n",
            "t = 14, avg_loss = 0.5023\n",
            "t = 15, avg_loss = 0.4058\n",
            "t = 16, avg_loss = 0.5275\n",
            "t = 17, avg_loss = 0.4706\n",
            "t = 18, avg_loss = 0.4417\n",
            "t = 19, avg_loss = 0.5097\n",
            "t = 20, avg_loss = 0.4311\n",
            "t = 21, avg_loss = 0.6561\n",
            "t = 22, avg_loss = 0.5914\n",
            "t = 23, avg_loss = 0.5122\n",
            "t = 24, avg_loss = 0.5070\n",
            "t = 25, avg_loss = 0.5114\n",
            "Checking accuracy on test set\n",
            "Got 143 / 200 correct (71.50)\n",
            "acc = 0.715000\n",
            "Checking accuracy on test set\n",
            "Got 141 / 200 correct (70.50)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.705"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDn-2g-TLY3k",
        "colab_type": "code",
        "outputId": "90a1ac96-028a-4136-b753-22b96facb39a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot([print_every*batch_size*(i+1) for i in range((len(avg_loss_list)))],avg_loss_list)\n",
        "print(\"Loss:\")\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCFqhazQaTYHw/7TGia6yedcyAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGer6hJv7-zR",
        "colab_type": "code",
        "outputId": "f3186e3a-240f-4fb1-8932-23955a78de63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plt.plot([i+1 for i in range((len(acc_list)))],acc_list)\n",
        "print(\"Accurancy:\")\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accurancy:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAgAElEQVR4nO29eZRcd3Xv+901T93V86h5sq3Bkm3F\nswWYizFgy0ASY0gehJcA7yYQhiQ3kJcXgrl5yVv3LiDhOmFOcu8FbEMgyI7BMYZYHrCRhCVrsK3R\nsrrVkrpb1UPN0+/9cc7v1KmqU3VOTd1dp/dnLS11n5pOdVfv2vXde383CSHAMAzD2BfHYp8AwzAM\n01o40DMMw9gcDvQMwzA2hwM9wzCMzeFAzzAMY3Nci30CpfT19Yk1a9Ys9mkwDMO0FQcOHJgSQvQb\nXbbkAv2aNWuwf//+xT4NhmGYtoKIzla6jKUbhmEYm8OBnmEYxuZwoGcYhrE5HOgZhmFsDgd6hmEY\nm8OBnmEYxuZwoGcYhrE5HOgZhml7LsfS+MGvxsC268ZwoGcYpu159KXz+NTDh7D3xNRin8qShAM9\nwzBtTyyVAwB89alTi3wmSxMO9AzDtD3JjBLonzs1jZfGZhb5bJYeHOgZhml7kpkc3E5Ch8+Frz51\nerFPZ8nBgZ5hmLYnmckh4HHht29cjR8fmcBrU7HFPqUlBQd6hmHanmQmD7/biQ/evAYuhwPfeIaz\nej0c6BmGaXsSmRx8bgcGOn1497Wj+N7+MUxFU4t9WksGDvQMw7Q9yUwOPrcTAPChXeuQzuXxz8+9\ntrgntYTgQM8wTNuTzOa1QL++P4Q7Ng/if/7iLGKp7CKf2dKAAz3DMG1PMq1IN5KPvGE9ZhMZPLTv\n3CKe1dKBAz3DMG1PMluQbgDg2lXduH5ND775zBlkcvlFPLOlAQd6hmHanmQmB78u0APAR96wDuMz\nCTz60vlFOqulAwd6hmHankSmOKMHgDddMYBNgyF89anTy97sjAM9wzBtTzKTL9LoAcDhIHzg5jV4\n5cI8Tk1GF+nMlgYc6BmGaXuSBhk9AKzsDgAAZuKZhT6lJQUHeoZh2p5KgT7kcwEA5pd5myUHeoZh\n2ppcXiCTE/C5ygN9h1cJ9NEkB3qGYZi2RVoU+z3l4azD5wYARFuU0aezefzWN57Ht18425L7bxau\nxT4BhmGYRkiogb6adNOqjP5HB8fx7Mlp/PLMZVyzshubRzpb8jiNYimjJ6I7iehVIjpJRJ82uPyL\nRHRQ/XeciGZ0l+V0l+1p5skzDMPIjN5Iugm4nSAC5pPNL8bm8wJf23saGwZC6Ap48MmHDmrnstQw\nzeiJyAngAQBvATAGYB8R7RFCHJPXEUJ8Unf9jwG4RncXCSHEjuadMsMwTIFkRpl89XnKA73DQQh5\nXC0pxv7slUs4cSmKL71nB8IBNz74j/vwhSeO48/eflXTH6tRrGT01wM4KYQ4LYRIA3gQwD1Vrv9e\nAN9txskxDMOYUcjojcNZyOdqiXTz1b2nMNrlxzuuHsabrhjAb92wCl9/+jSePz3d9MdqFCuBfhSA\n3hloTD1WBhGtBrAWwM90h31EtJ+Inieid1a43YfV6+yfnJy0eOoMwzC6QG+g0QNAh8/V9GLsgbOX\nse+1CH731rVwO5Uw+n+/4yqs7gngjx4+1BKpqBGa3XVzH4DvCyH0QtVqIcROAO8D8CUiWl96IyHE\n14QQO4UQO/v7+5t8SgzD2Bkp3fgNpBsACHmbH+i/+tRpdAXcuO/6ldqxgMeFL7xnByZmE/jcI8eq\n3HrhsRLoxwGs1H2/Qj1mxH0okW2EEOPq/6cB/AeK9XuGYZiGSFQpxgJAyOfGfBOlm5OXonji5Yt4\n/42rEfAUlzmvXdWNP3jTBnz/wBh+cuRC0x6zUawE+n0ANhLRWiLyQAnmZd0zRHQlgG4Av9Ad6yYi\nr/p1H4BbACyttzqGYdqagnRjHM46vK6mSilf33saHqcD7795jeHlf/jmjdg62ok/++FhXJpPNu1x\nG8E00AshsgA+CuBxAC8DeFgIcZSI7iei3bqr3gfgQVFsE3cVgP1EdAjAzwH8jb5bh2EYplHMNPpm\nSjcX55L44Yvj+M2dK9AX8hpex+104Iv37kA0lcWXnzzZlMdtFEsDU0KIxwA8VnLsL0q+/0uD2z0H\nYFsD58cwDFMVS8XYJkk333r2DLL5PD5027qq19s42IFb1vfiF0ukA4ctEBiGaWu0PvoK0k3I50Is\nnUMu35gn/Vwyg+88/zretm0Yq3uDptffuaYHJy9FMRNPN/S4zYADPcMwbY0V6QYAYunGsvrvvvA6\n5lNZfGRX9Wxect3qbgDAgbORhh63GXCgZximrUlkcnA5SOtnL6VDWhU3IN9kc3l869kzuHl9L65e\n0WXpNttXdMHlIOx7jQM9wzBMQyjbpYyzeQAIeVUHywYC/eVYGhfnUnjb1iHLt/F7nNgyGsaBs5fr\nftxmwYGeYZi2Jpk1Xjoi0RwsU/W3WEqvHGl7bJVfW92NQ2OzSGUX1+yMAz3DMG1NMp2rWIgFmiPd\nxNRAL/V+q+xc0410No8j43N1P3Yz4EDPMExbY5bRa1umGuill7KP/HRgletW9wDAoss3HOgZhmlr\nkpk8/Bakm0Yy+vk6M/r+Di9W9wawf5ELshzoGYZpaxIm0k2oCXtj65VuAKXN8sDZCIpNAxYWDvQM\nw7Q1ZtJN0ONStkw1It2k6pNuAGDn6h5Mx9J4bTpe9+M3Cgd6hmHaGrP2SrllqpGMXso+9WT0O9co\ng1P7Xls8nZ4DPcMwbU0yUz2jB9QtUw20V8ZSWbgcBG+FLVbV2NAfQqfPhQOLqNNzoGcYpq1JZnIV\n1whKQl5XQ8XYaCqLkM8FIqr5tg4HYeeaHuxfxM4bDvQMw7Q1yUyu4nYpSajBdYLRZBZBT+2yjeS6\n1d04NRlDJLY4Bmcc6BmGaWsSVqSbJmT0HXUUYiU7F9ngjAM9w7QpkVga33zmzKK27bWKVy7M4bHD\nE6bXE0IoxVgT6abT524so09l6yrESrav7ILbSdjPgZ5hmFr40cFxfP7RYzg1GV3sU2k6//Tsa/jz\nfz1ier1UVvWiN5NuvI113URTWQQbCPQ+txNbRhbP4IwDPcO0KWORBADg0lxqkc+k+cwns5YCc9Jk\nMbgk5Gtsb6wsxjbCzkU0OONAzzBtyrmIMoBzcYksoG4m0VQW6VweaTVjr0Rhu5R5Rt/IlqloMotQ\nA8VYYHENzjjQM0ybYueMXloOxEx0dZnR+z3VQ5kspNa7ZSrWhIxeGpztX4TBKQ70DNOmaIF+3n6B\nXhZOzQJzwqp004DfTS4vEEvnGirGAorB2ZrewKIUZDnQM0wbMpfMYDahaM4X5+wn3cgAH0tV17PN\n9sVK5MKQejpv5Lk0GugBJav/1SIYnHGgZ5g2ZOxyQvvalhm9mnmbBWbLGr1mVVx7QTbWgKFZKTvX\ndGM6lsaZqVjD91ULHOgZpg0ZUwuxq3oCmLRhoJeZfNxEuilk9OYWCEB9nvTRBgzNSpGDUwst33Cg\nZ5gGeeDnJ/G9/ecW9DGlPn/d6m7bSTfpbB7pnJKpWy3Gmks39W+ZqnfpiBHr+0MI+9147uRUw/dV\nCxzoGaYBkpkc/u7JE/jegbEFfdxzkTgCHieuGOpAPJ1raOpzqaEP7lEzjV7tSa+2YQporBjbTOnG\n4SC8c8cIfnToPJ4/Pd3w/Vl+3AV7JIaxIb88cxmpbB7nZxLmV24iY5EEVnT7MdjpBQBcslFWr3/T\nMpNuEmlrGn0jGX0zpRsA+C93XolVPQH80cOHGhriqgUO9AzTAHuPTwJQOl/qHcapByXQBzDQ4VMf\n3z46vb6l0rwYa02jl86Tc3Vk9M2UbgAg6HXhC/fuwMRsAp975FhT7tMMDvQM0wBPn1C01kxOYCq6\ncMF2LBLHym4/BjrUjN5G07F66cZUo89a0+gdDqrb76aRfbGVuG51N37/jRvw/QNjePzohabdbyU4\n0DNMnVyYTeLVi/O4Ya0y8Ti+QPLNbDyD+WRWyeg7lYzeTp03+s4Y0z76dA5EsLT5KeStb8uUfHNo\nxNTMiD9880ZsHe3EZ35wuOW/Pw70DFMne08oss19168EAEzMLExWLT1uVnT70elzwety2KrzRh/c\nzTP6PLwuh6XNT/UuH4mmsvC4HPDUsUawGh6XA1+8dweiqSw+/S8vtXSIigM9w9TJ3uOTGOjw4k1X\nDADAghVkZWvliu4AiAiDnT5bDU3J4O53O00tEJKZnGnHjaTDV9/ykWgqi44mZ/OSjYMd+NM7r8ST\nr1zCQ/ta16LLgZ5h6iCXF3jm5BRu29iPsN+NoMeJ87MLFeiVjH5ljx8AMNDhtZWxmcy6Bzu9ptJN\nIm2+XUpS75apZlgUV+ODN6/Bzet7cf+jx3B2ujUTsxzoGaYODo/PYiaewa5NfSAiDHf5FzSjD3ld\nCPsV/5aBTq+trIplRj/Q4bMk3VgN9B31SjcN7os1w+Eg/Pff3A6ng/Cphw8h34LurdadPcPYmL3H\nJ0EE3LaxHwAw0uXHxOzCBNuxSBwruv2aLj3Q4cPTxxd20rKVRNOKJh4OuHHucrzqdZMW9sVK6u26\naXVGDyivn79599UAlMDfbCxl9ER0JxG9SkQniejTBpd/kYgOqv+OE9GM7rIPENEJ9d8HmnnyDLNY\n7D0+iW2jYfQEPQCA0S7fgmb0K7r92vcDnV7Mp7Kmw0XtQkzdzxr0OBFPm7tXmvXQS0Le+vbGtlKj\n1/OOq4fxjquHW3Lfpj8hInICeADA2wBsBvBeItqsv44Q4pNCiB1CiB0AvgzgB+ptewB8FsANAK4H\n8Fki6m7uU2CYhWUumcGL52awS83mAWA47MdUNK0N8LQKIYQ2LCWRQ1N20emjySyCXieCXpclrxsz\nL3qJ7LqpVRqJNbgvdilg5a3wegAnhRCnhRBpAA8CuKfK9d8L4Lvq128F8IQQ4rIQIgLgCQB3NnLC\nzPJmJp7G3/70BLK56ivmzMjnBb7y1Km6et+fOzmFXF5g16ZCoB/pUjLsCy2Wb2biGURT2aKMXrNB\nsEnnTTSVQ8jrVvvezReP+E0Wg0s6pQ1CjZ98FkK6aTVWAv0oAH3fz5h6rAwiWg1gLYCf1XJbIvow\nEe0nov2Tk5NWzptZpjz60gS++NPj+NXrM+ZXrsLh8Vn8zY9fwY8Ojtd826eOTyHkdeGaVV3asZGw\nklW3Wr7Rt1ZKtIzeJgVZRbpxIuBxIZXNV31TT2byNUg39RmbzSezTZ2KXQya3XVzH4DvCyFq+vwq\nhPiaEGKnEGJnf3+/+Q2YZcvpSaX97NWL8w3dj+ZRU2MGLoTA3uOTuHl9L9zOwp+PzOjPtzijH9MN\nS0mkDYJd/G5iaUUqCXqd6veVw0mt0g1Qm7FZJpdHKptfFoF+HMBK3fcr1GNG3IeCbFPrbRnGlFOT\nUQDA8QsNBnp1qrXWTpnTUzGMzySKZBsAGFrgjH5lTyGj7wq44XE6bJPRR1VNXAbXajp9MpODz6J0\nU8/ykVb43CwGVgL9PgAbiWgtEXmgBPM9pVcioisBdAP4he7w4wDuIKJutQh7h3qMYeri9JQS6F9t\nINDPJTOa9FOrdYD8JPCGkkDvczvRF/JgosVDU+cicXT4Cj30AEBE6O/wYnIBM/rpaKplhedYKouQ\nx4WAGlyrdRMlM3nLGX09VsXzTbYoXixMA70QIgvgo1AC9MsAHhZCHCWi+4lot+6q9wF4UOgMG4QQ\nlwF8HsqbxT4A96vHGKZmkpmcltG+enG+bm+Q505OI5cXWNMbwIU6Av3avmBRRi0Z6fJjvMV+N6Ud\nN5KFHpra/T+exVeeOtWS+46lcmpGrwTwastHammvlAvCa/GA1xaDt3kx1tLZCyEeA/BYybG/KPn+\nLyvc9lsAvlXn+TGMxmvTMQih7N3cfzaCS/MpDKrujbWw98Qkgh4n7tw6jK/tPYVsLg+X0zxYpLI5\nPH/6Mu7ducLw8uGwT6shtIqxSByre4Nlxwc7fJqs1WoyuTzGZxJ43WSYqR7yeYFYWinGymnUStJN\nJpdHNi8se93UU4xt9tKRxYItEJi2QQbRt21ThkpeqUO+kcXUm9b3YWWPH3kBTFr0kd//WgSJTK5M\nn5eMqDYIrXIhlD30Kytk9AvVXjkTVzLi2XjztyPFMzkIoWTQQRON3uq+WEk9xVi5dGQ59NEzzJLg\n1CUlY71z6xCA+gqyZ6ZiGIsk8IZNfRhSPw1Y7X3fe3wSbifhxnW9hpePhP2IpXN1bTGywuVYGvF0\nrqjjRjLQ4cVsItPygS0AmE2k1f+bH+hjusCqBfoKGn0yo64RtFiMlZ8Q6inGdiwH6YZhGiGdzeNv\nnzyOJ45dNLx8XV8I//Db15p6ip+eimEk7MNolx/9Hd66WixlMXXXpn7tD95qQfbpE1PYubqnYnan\ntVjOJIqKpc2i0ENvEOh1C0iM6gfNJKJm8jMtCPRRXZdL0ESj1zJ6iz7xTgch6HHWlNGzdMMwFjgz\nFcOv/8NzeODnpzDQ4cP6/lDRP7/biZ8cvWBpQvX0ZBTr+kMAgCuHOurqvNl7YgqrewNY3RvEsNoS\naaXFMp8XOHFpHttXdlW8znCXvL/WdN4YDUtJFnKlYCSmZPQzLZButIze49Iy8HiTpBtAKcjWUoyN\n2kS6ae+zZ5YsQgh8/8AYPrvnKNxOB77y29fizq3lhk2/ej2Cd//9czgyPmcYwPT3d2oyhl+/Vhms\n3jTYgW+/cBa5vIDTottfKpvDL05N4zeuU4qpPUEPPE6Hpc6bi/NJZHJC84A3YlTN6FvVeaMNSxmc\nw0IuCZeZ/FwiAyGEpe1OVtEH1oDHCaJqGr0i3VgtxgK1b5mKLqM+eoapidlEBn/44EH8yfdfwrbR\nMH7yidsMgzwAbB7uhNNBODI+W/U+J+dTiKayWkZ/xWAHkpm8qY2tngNni4upRKS0JVrI6Ktl05L+\nkBduJ7VsaOpcJI6w341OX7kspPndLMBKwZm4ktGnc3kkmlwTkItGQl4XiAhBj6uidJOoI6OvdflI\nNJlFwOO0nEwsVTjQM03l8Ngs3v63T+OxwxP4k7dege986EYMhytnwT63ExsHQjhsEuhPqq2D62Wg\nH+oAUFvnzd7jU3A5CDetLxRThzp9ljJ6I+uBUhwOZa3fRIsCfak9sZ7ugAcuB1XtvBFC4LHDE8g0\naAgX0Uk2zZZvCsVYJXgHPM6KA1MF6cZ6GKt1+UjUBs6VAAd6psn82Q8PI5vP43v/1034gzdtsJQJ\nbRkJ48j4bNW2RNlaua5f6SHfOKgE/OM1FGT3Hp/Edau7iz6GD4V9lrpuxi4rwVvKM5VQWixbJd1U\nDvQOhzIdW026ee7UNH7/279qeDfpTAsD/XyJVFLNwbIejb7W5SML5UXfajjQM03jzFQMh8dn8aHb\n1uHaVdbXDmwb7cR0LF01sz49GYPf7dRaIgMeF1b1BCx33kzOp3BsYq7co0bN6M16389F4hjo8JoG\nlZGwryW7Y5Ue+rhhD71koNNXtRj7yzPKUPqeQ+cbOhcp3QDNb7HUvGXUdsZqnvQLIt3YwKIY4EDP\nNJE9B8+DCLjr6pGabrdtRRiAIvtU4tRkFOv6g0Vr1q6oofPm6RPGHjVDYR+SmTzmEtX/+Ktl03pG\nuvy4MJtErsl7P5WlJvmq5zDQ4cVkFenmwNkIAGDfa5cb6gyKxNNaxi176ptFLJWFgwoF1oDHWdG9\nMiX76GuSbmrbMhVLtXZf7ELBgX6JUetUZaumMGtFCIE9h8bxa2t6NCdHq1w13AkHAUfOz1W8zump\nQmul5IrBDpyZiiGVNS8I7j0+id6gB5uHO4uOy3OdmKse+Cp5zJQy0uVHNi8wZTJtW+vvrVAjqJLR\nd3grzgRkc3m8+HoEt23sgxDAv700UdPj65mJZ7C6N6B93UyiamCVnTyhKhl9Uv2919N1Y3XL1HyS\nM3qmicTTWXzmB4dx7eefsJyl/vLMZWz/3L/j6PnqhcyF4OWJeZyajGH39tqyeUCRYdb3hyp23kgz\ns/X9xR4vm4Y6kMsLU3+ZfF7g6RNTuG1jX9niZSvTsbm8wPkZqxm9cn/V5gL++scv451//1xNK+20\nrp8q7Z2DnT5E4hmks+XF1lcuzCOWzuE3rluBraOdDck3M/EM1vQpv4tmD02Vru2rKt2k6+ijN5m2\nLYU1eqZpHD0/i7u//Awe3Pc60tk8PvHQQcM/Vj3zyQw++dBBzCWzeGWiMW/2ZrDn0Hk4HYS3b6tv\nufG20XDFzhtpZlaa0V+pdt6YvTEem5jDdCxt6FEjTdGqTcdemEsimxeWJk7ldOxEhYKsEAI/evE8\nDp2bwZOvXDK9P4mV9k45NGXk3bP/NUWf37mmB7u3j+ClsVmcmarPgC0ST2O0yw+3k1qg0ee0jhtA\n6b6pJN1oFgg1ZvSAdb8bO+yLBTjQLypCCHzzmTN41wPPYT6Zxf/+3RvwxffswMsTc/jST49Xve39\njxzTdFarplytQgiBRw6dx60b+tAT9NR1H1tGw5icTxn2gZ+6pHbc9BVn9Gt6g3A7ybQg+5Rqe3Db\nxsqB/sJs5Z/h2GXz1kqJbCWt1Et/4lJUKzp/tQab33OROLoD7qqDOwOdctNU+c9w/9kIhlX7CFlD\nebSOrD6ZySGVzaMr4EbY726JdKN/jkFPdenG43TU1ONey/IRIQQXY5nGmIqm8MF/2ofPP3oMuzb1\n4Sef2IVbNvThji1DuHfnCnzlqVM4cNbYuv/xoxfwvQNj+M9vXA+/24mpRV4K/avXZzA+k6hLtpFs\nG1ULsgZZ/Wm1h35diXTjcTmwri9kam629/gkNg93ol/NeEvvoy/kwYUqGr2VbFrS6VM2I1WSbqTX\nzod3rcP+sxEt0zbDSo1A2x1r0GJ54GwE161WOqFGuvy4fk0P9hw6X3OtIKJ23HQHPAj73U0vxpb2\nrQe9LsTTOUOZK5HOwVtDIRYomJNZCfSpbB6ZnGj7qVhgmQT6rz51CseqFPoWmmPn53Dnl57Gc6em\ncf89W/D19+8syoT/n7s2Y6TLj08+dKgsm5mcT+EzPziMLSOd+PibNymbhRY5o3/k0Hl4XA7csWWw\n7vvYPNIJogqBXjUzCxh0P1wx1FF1aCqayuLA2Qhu29RX8TqDndV76WWgl/p7NYgIw2Ffxa6Wp45P\nYn1/EJ/4TxvRHXDjK0+dNr1P5Rzipp8oZEZf2mI5PpPAxGwSO1cXWl7v3j6ME5eiNVs9R2JKBt8d\ncKMr4LGc0f/kyAU8+bKxqZ2eWGlGr8o4cYMJ3FQ2V5NsA9S2ZcouawSBZRDoM7k8/vrHr+CLJlLI\nQvKPz55BKpPDIx+9Fe+/aU2ZV0iHz40v3LsD5yJx/Nd/O6YdF0LgMz94CdFUFl96zw54XA4l0C9i\nRp/LCzz60gRuv2JA2+BTDyGvC2v7gjgyXv6GfGoyivUDIYNbKYF+fCZR0ajq+/vPIZsXeOuWoYqP\nrfTSV/4ZnovEMdjphdfiyrpKQ1PJTA6/PHMZuzb1I+Bx4f03rcFPX76Ik5eqB1shBMYjCdMaQW/Q\nCweVZ/R6fV7y9m3DcDoIj9Qo38ge+rDfgy6/27JG/+WfncDf/4e5VFUm3VTxpE9m8jV13ABAyKu8\nRq0MTdnF5wZYBoFe/kKfenWyJf7ZtSKEwN4Tk7htU582xm/E9Wt78OFd6/DdX57TMqGH9p3DT1++\nhD+980psHFRu2xfymLbytZLnT09jKprC7h31yzaSbaPhss4bIZSumlJ9XrJJ/TmcuFS+XSmby+Pr\nT5/BztXdVQe4lOnYatJN9UGlUka6/IYZ/QtnLiOVzWtF4ffftBo+twNf21s9q5+cTyGVrd5DDyg2\nvP0d3rKM/sDZCAIep1a8BoDekBe3bOjDIy/VJt/ILpvuYG0a/XQ0rbleVqO0+KlthTII9Im09TWC\n2v1pGb35eUt5h4uxbYB8gaRzeTx+5MIin40SkC7OpbDLoDBYyqfesglXDnXgT//lMA6em8HnHz2G\nm9f34oM3r9Gus9gZ/Z6D5xH0OHH7lQMN39e20TAuzCWLns8l1cysUkZfrfPm3w5PYHwmgY+8YX3V\nxx1S2xIrLe2wOiwlGQn71AGn4vt7+vgkPC4HblyreO30hry4d+dK/PDF8arS0bkqPvSlDHT4ymwQ\n9r8WwTWrusrWJd599TDOXU7gxXMzlp4XUKLRB6xl9EIITMdSmLYU6HNFgTVQZZ1gsg7pppZirF2W\njgDLINDrf6GPvNTY6Hflx8hY9gHXL74ww+ty4ovv2YG5RAa/8Q/PweEg/Lff3F7UC94X8iISzzRs\nVFUP6WwePz4ygTu2DNX8B2fElhGlIHtENxcg96Cu6zMO9KNdfgQ8zrJAL4TAV546jQ0DIbzZ5E1o\nMFy5iJnN5TExm7RUiJXIFsvS4L33xCSuX9MDv24j0u/dug65vMA/Pnum4v1ZGZaSDHQUrxSMprJ4\n5cIcdq7uKbvuW7cOweNy1CTfyAw+7Hejy+9BNJU1fe3NJbPI5ARmE9Vfp+lsHulcXlsKDhQ0+piB\ng6WyGLx1gZ6lmzZCarfXrOrCsyenWpL9/tW/vYx3PWBtAOap45PYMBDSgoEZVw134o/fugnZvMD9\n92wpM9WSnSTT0eZ2P1hh7/FJzCWzDXXb6NkyqkytHtFZIZSamZXicBA2DnaUmZs9fWIKL0/M4cO7\n1pUNSZWiDU0ZtCVOqHYGtWT0cgGJvsVyYjaB4xej2FVSFF7VG8A7rh7Bt194HXMGdYaXJ+bw5Z+d\nhM/tsJbRd/owqUs6Xnw9grwAdq4pl646fW686Yp+PPrShGXLhpl4Gn63Ez63E10BRe+eM8nq9dJi\nJF75dapfIygJVdHoE5l8zYG+li1Tdlk6AiyDQC9/We+7fhXyAnjscP2j35V4/XIc4zMJ/NKkVU4r\nxlmQbfR86LZ1eO7Tt+Nd16wou6w/pA7JLIJ8s+fQeXQF3Lh1Y+WOllro9Lmxti9Y1HlzajKKgKdg\nZmbElYPlnjdf3XsKg51e3GOhdlDYNFWuq8uOm1rW88k34/O6jP7p41MAjD/JfWTXOkRTWXznhde1\nY0IoWf49DzyL2UQG33j/rwOwpfMAACAASURBVBl2HZUy0OHFVDStZc77XovAQcA1FWoUu7ePYnI+\nhRdOT1t6bpF4Bt1qgJfrEs2mY/VJyOUq8o1RYNWkG4NJ1lQmZ3mNoJ6Qz5qDZZSlm/ZB/rKuW92N\nKwY7au4ysILMWMzGygvFuNoCIxFV/ATQp01Dtn7hhJ54Oosnjl3E27YOw+1s3sto62gYR3WtsKcn\nY1jbF6yalW8a6sB0LK39Hg6PzeLZk9P4P29Za6lTRko3RoNGVnzoS5H+OfqM/qkTkxjs9OKKwfIC\n/NbRMG7d0IdvPXMGqWwO09EUfvef9+NzjxzDrRv68JOP32b5zVS2WMqfxYGzl3HlUGdF+eH2KwcQ\n9Dgty5oz8TTCAaUVOKwGfLOC7LQuo79c5ZOnFlgNM3pj6cZvcTG4nmrWx0XnY5N9scAyCPRSiwv5\nXNi9YwT7z0Ys7SetBZmx/NhkqcNetRh3w9reitepFZnRT80vrHTz5MuXkMjkmibbSLaOdGJ8JqFl\nfqcmo9qykUrI4CkHp76y9xQ6vC6894ZVlh6zQ11bZzQdOxZJgAhVl6eU4nU50RfyaoE+lxd45sQU\nbtvYX3Ht3kfesA6X5lP43CPHcOffPo1nTk7hL+/ejG9+YCd6Q+WDXpUY1A1NKUZmM4ayjcTvceIt\nmwfx2OELprYbgBLUZUbf5bco3eiy+GoFWSPppqDRG0k3OfgstrzqCfnchjJZKdFUFkSKg2a7Y/tA\nX8gS3LjrasWHpZlZfS4vcDmexlXDnYjEM3jm5FTF6+49Pokb1vbUlYVUor+Kv0krefSl8xjs9OL6\nteVFvkbQT8gmMzmMzyQq6vMS/baps9Mx/PjwBH7rxtWGK/eMICIMhX2GGf25SBxDnT54apQIRrt8\nmnTz0tgMZhOZqgX4Wzf0YctIJ77zwuvo8rvxoz+4Bb9zy9qa97HqbRBeuTCPeDqnTcRWYveOEcwm\nMni2ymtXEomnNW2+S83sZ0ymY4sy+jqlG6MMPJnJ19xeCShv7FY1+pDOSbOdsX2gn09m4HQQfG4H\nVvcGsX1lV1MDfSSehhDAu68ZRafPhUcOGt/3+ZkETlyK1qzPm+FzO9HhdS2oRi+EwP7XIrhtY3/T\nd2luUQP9kfFZzczMLKPvC3nQE/Tg+MV5fP3p03A5HPjgLWtqetyhTuNp1rFIoqYeeslw2K9l9HuP\nT4EIuG1DZfmFiPDX796GP3rLJuz56K24qsRO2SqaDcJ8ynBQyohfUy+3sq1rJp7RArym0ZtKN2l0\n+lwgqh7o9ftiJU4Hwe82XieYzOTgqyNp6rCq0dvEohhYBoE+msxqi4YBYPf2ERw9P6e17TWKlG2G\nu3y4c+sQHj96wbAfWy6+sNJWWSsLbYNwYS6J6Vhay76bSdjvxqqeAI6MzxbMzEwyeiLCpsEQfnnm\nMr63fwzvumZUMyuzylBnef85AIzX2EMvGenyY2ImoQ3IXT0aRreJ4dvVK7rwsTdvbOgTX1/IAyI1\n0OuMzKrR4XMj6HGa7s4VQmAmUZBuOtUgaBbop6IpDHb6EPa7TQJ98b5YSdBbviA8nxdIZfP1STcW\nM/pY2h7OlcAyCPTzqWxR1fyuq4dBpAz6NAP5sbQv5MXu7aOIpXP4mYH97N7jUxjq9GHTYPXstB76\nFnhoSm6C2tqCQA8ULIulmdnaClOxeq4c6sTpqRjSuTw+tGtdzY85qEo3+hbZTC6Pidl6A70PsbTi\no3/w3ExL3uCNcDkd6A16cWkuWWRkZsZgBelKz3wqi1xeoMvv0R6rw+cyHZqajqbRq37qsiLdlBY/\ng15nmUafytZuUSyx2nUzn8zaohALLINAHy35ZQ12+nDD2p6aR78rMakFeg9uWt+LvpC3TBrK5QWe\nOaksvmiF3tcf8lq2QXj86IUizbQejpyfg4NQtq2pWWwdDWMsksCB1yPqQJT5H5u0QnjLVYPYUGGK\nthrDYZ+yGSpW+NlMzCSRF9YGlUqRXVLfOzCGXF4sWKAHlBbLg+dmMDGb1GQZMxTpqnqgn1ENzaRG\nL782C/RTsRR6Q170Bj2YjlV+7RkVYwHFqrhUupGfmv31avRp8y1T0ZIksZ2xf6A3+GXt3j6K05Ox\noja+epHSTW/QC6eDcNfVw3jylUtFJluHLBTjGsGqDcJsPIOP/K8D+MITjRm8HRmfxYaBUFOLynq2\nqoNTz5yYMpVtJNev7UF3wI2P3r6hrsfUFpDoOm+01soqW50qIXvzv7f/HDq8LuxY2VXXedXDYKdX\nc6W0mtEPhX24aBboEwX7A4nid2NWjE2jL2gto/e6HGXtukZSSz2LwbX787kghPmWKbvsiwWWQaA3\n+vj1tq1DcNXh3GfEdCwFp4O0wtTd24eRzubx70cLlqx7j0+CSOmsaAX9HV7MJ7MVvVok59TA9eMj\nFxqyTDg8Ptsy2QYAtqpWCNm8MC3ESjYMhPDiX9yBq1fUF1CNpmO1Yak6Mnqpi0/MJnHzht6mzhqY\nIQuywRIjs2oMdfpwaT5VNcuNxA0yer+n6sBUOpvHbCKD3pAXPUGvaaA3kkoCXmdZH32ygUAvXVbN\ndHouxrYRyoaY4ja77qAHt23sw6MvTdS0t9OI6WgaPUGPNtBz7apujHb5iwZQnj4xZakYVy99IeV+\nzeQbmaFejqUttdIZcUk1HZPBuBV0Bz2aLm41o28UOeRUHOjjcBBqXnYOKDUbt1N5TSykbAMUWiyv\nWdVdZmRWiSED6aoUmbl36TN6E+lGBvbekAe9QQ8i8UzFv7lKa/uCXldZ9l3PGkGJ5ohpotPPV3jj\naUdsH+jnk8Y62+4dIxifSeBXr0cauv+paBq9ugBORLh7+wieOTGFy7E0ZhOZlhfjtF56E/nm3GUl\nQw14nHjkUH1WENKeYNuK1gV6oJDVW83oG6UvpEhvervic5EEhsP+urJxh4O0N4hmt9SaMaB+OrEq\n2wDWlqTL7ppuXUYf9rsxW6XrZkrXrNAT9CCXFxXfGKIlzpWSkME6wYJ0U58FAqAE8koIIcqWoLQz\ntg/00VTGcIv7WzYPwed24POPHsM5dSdoPUzHUmUr6u7ePoxsXuCxwxN47uRUy4tx/SHlj9Qs0I9F\n4ujwufCObcP49wptoGYcHp8FtbAQK9muatr1FFbrwekgDHR4i6ZjrWx1qsaqngDW9Qdr8slpBqOq\nqVotw2zaJ5oqgT6iLR3RSzduzCQyFRsb5CSsnHUAgMsVNH0lsJZn6EbSTaoR6cZCRp/I5JAXYOmm\nHcjk8khm8obvyiGvC1+8dwdOT8bw9r97um69fiqaKsroASUIru8PYs+h89h7YrLlxbi+DindVC+K\nyb2ju3eMYD6VxX+8Wt4GasaR8Tms7w+1vL/4/Tetxv/63etr7odvhMHO4hZDK3taq3H/PVvxld++\nrhmnVhO7NvbjG+/fiZvXW7fakBl9tRbLmXgGHT5XkRzUFXAjlxcV9W7Z4dUb9BYCfQWdvlLfekiV\nbvRvJsms7LqprxgLVLcqjtpo6QhgMdAT0Z1E9CoRnSSiT1e4zr1EdIyIjhLRd3THc0R0UP23p1kn\nbgVt52OFd+W3bRvGYx+/DRsGQvjYd1/En3yvfEerGUqPcHFGT0TYvX0U+167jMePXmx5Ma43aE26\nkQs0blrXi76Qpy755sj4LLaOtDabB5Q/sNsWWPLQ73pNZ/O4MJdsKKNf3x/S2j4XEpfTgf+0ebCm\nVt5eVbqq1mI5E08XddwA0HrqK8kxWleaLqOvZKlduhhcEvQqXTIJ3SfQRLp+jb5QjK0sORkZrLUz\nptGHiJwAHgDwNgCbAbyXiDaXXGcjgM8AuEUIsQXAJ3QXJ4QQO9R/u5t36ubMW3CfW9kTwMMfuQkf\nu30Dvv+rMdz15We0gSAz4uks4ukcekPlRda7tw9DCCV7aXUxzuNyoDvgrupgKYTAOXUlnsvpwNu3\nDeOnL1+0NCEomZxP4cJcsqUdN4vJoG469vxMAkLU5lrZzjgdhMEOb9Xp2Eg8U9RxAwCdJjYIU7EU\nPC4HQl6X9ndSKaOPJhVvmVKCahuv/rWabESjt7B8xE5LRwBrGf31AE4KIU4LIdIAHgRwT8l1PgTg\nASFEBACEELVrAi1A/iLNlla7nQ780R1X4LsfuhHJTA7v/odnLUk5MjPpC5a7C67rD2n94AtRjOsL\neas6WEbiGcTTOS1w7d4+glQ2jyeOWV+vKDc/tcL6YCkwFPYhmsoimspqrZWNSDfthtl07Ew8XdRx\nAxRaLStl9FPzSg89EemkG+NPnrGUcTujzPLjOp2+Iemmyh5ayXKUbkYBnNN9P6Ye07MJwCYiepaI\nnieiO3WX+Yhov3r8nUYPQEQfVq+zf3JysqYnUI1aFwfcuK4XP/74bVjRHcCD+143vf60rnXMiI/d\nvhHvu2HVghTjzPxuSn3Vr13VjZGwryb5Rm5+2rwA0s1ioO88kT+vlXUMS7UrQ52+6l03Op8bSZeJ\nJ/10LKXtTPC6nAh5XYZWxfm8QCxt3HUTNAjMibQS6L11BHqngxDwOKsWY+20dARoXjHWBWAjgDcC\neC+ArxORrD6uFkLsBPA+AF8iorJNzUKIrwkhdgohdvb3Ny/7lRpcLR+/ugIebB7pxPkZ80Ueep8b\nI966ZQj/77u2WX7sRujvqG6DUJqhOhxKG+je45OIWFjaDCgdN+v6gqafkNoVfefJWCQBp4Oqbray\nG0Ph6oE+EktrHvQSKxq9vlmh0nRsPCOdK8sDd9BgQXjB66a+EBbyuli6KWEcwErd9yvUY3rGAOwR\nQmSEEGcAHIcS+CGEGFf/Pw3gPwBc0+A5W0a/dKQWRsI+VaOtPkwlA2uljH4h6QtVt0GQLaT6cf67\nt48gmxf48RFr8s3R83O21eeB4unYc5E4hsM+ywNHdmCoUzFimzdYypHN5TGXzJZJN4V1gsbJwnQ0\nVdSsUCnQV/K5UY4pwT+e1kk3mRwcBHjq/P2EfNUdLO20LxawFuj3AdhIRGuJyAPgPgCl3TP/CiWb\nBxH1QZFyThNRNxF5dcdvAXCsSeduiqbR1/jLGunyI5XNVx3XBgrtjL0GGv1C09/hRTydq9g1NBZJ\nIOx3Fy3j2DLSiXV9QUv1iMuxNMZnElrdwY4M6VYKjtVpT9zODFVZqTin/i2VSjc+twMel8NwaEoI\ngalYuigRqhToq2XQRpp6Ip2Dz+2s2ySww+euOjC17KQbIUQWwEcBPA7gZQAPCyGOEtH9RCS7aB4H\nME1ExwD8HMCfCCGmAVwFYD8RHVKP/40QYsECfeGXVZvUINfGmbn5TUfTCHqcLTP3qgVtpWAF+cZo\n+EdO8T5/ZtrUolZOxNo5o/e5negKuDExm8CY2qG0nJAzC0av+4iB/QGgvIa6/MY2CNFUFulsvqhZ\nwTSjN+i6CXjLpZtkNldXa6Wkw+tCtMo6wWgyC5eD4K1j+fhSxNKzEEI8JoTYJIRYL4T4K/XYXwgh\n9qhfCyHEp4QQm4UQ24QQD6rHn1O/367+/83WPZVyosmstl2qFqQhldlu2elYqqZ9nq2kz8QG4VyF\nDPXu7SMQAnj0pepF2SNqoN/SQo+bpcBQpw+vX07g4lxqWXXcAAXHTSOdvuBzU540dQXchsXYqWh5\ns4JiVZwuk0WrdbnIlstYkXSTr6vjRrtPk+Uj0nfHDmsEAZtPxko3vFp/WcPqCPl5s0AfTS8JfR4o\nZPRGgV4IUTFD3TAQwubhTlP55sj4LFb3BorG3+3IYKcPL6r+R8tNuhmsMh1b8Lkpf72H/W5Djd6o\nWaEn6EE6my8K2kB1qSRgsCA8kcnBW2chFlA0+mrFWDsZmgE2D/T1bojpDXrgcTlMpZupaKpix81C\nI/12jKSb6VgayUy+YuDavWMEB8/N4PXpyp4/rbYmXioMdfq0ALDcAr2UroyGpowsiiVhv8dyRq/1\n0pdMx0p3SqOM3u1U6gBFXTeZXF1rBCUhb/UtU9EKZojtis0DfaauXxYRYbTLbyrdTEXTmkXwYtMT\n9MBBxhm92fDPXVcPAwAe2m88OzATT2MskrDtoJQevSXxQpuRLQUq9dIbWRRLugJuzBlo9HKblD4Z\nkkG/dNOU3Albui9WIv1uJMlMvqHaWKev+pYpO+2LBWwe6CstMrDCcNiHiSqBPp8XuBxLLYmOG0AZ\nAukJGg9NGbVW6lnRHcDd20fw1adOa1q8niPjyiau5RToXQ5aUEO1pcJQ2GeY0c/EM3A6SFsIrkc6\nWJYiJ8f1ck+P+vdSWpCNmfStB0scLBOZXN099EBhy1S8goNr6QrSdsf2gb7ej18jXf6qQ1MziQzy\nYmn00Ev6Qh5MGtggWBnn//w9W9AT9OCTDx0ssy8+rBVi7dtaKZG99CNdfjgd9ijE1YKS0ZcnC5F4\nGmG/27DeFfa7EU/nkMoWv26moimE/W54dJ0rPQGZ0ZcHegdVtjQIelxlXjeNSTeqsVkF+Wa+gh1D\nu2LvQJ8s3y5llZGwD5fmkxVX7mn2q0tEowcq2yCMReLoDrirZihdAQ/+229ux4lLUfz3x18tuuzI\n+Vms7PEbfmy3GzKLX276vGSw04epaArpbPHrfsbA0ExSye/GqFmhp4KxWVTdz1qpcSLoLV4Qnszk\n4GtAuilYFRu3WMZSxgZr7YqtA30jlfORLj/yorI/95RmaLZ0gl9/hxdTFTR6K62Cb9jUj//jxtX4\nxjNn8NypwqrBI+Ozy0K2AQothsuth14in/+l+eLX/Uyi3KJYElaPl+r0Rs0KQY8THpejzHYjmqyu\niQe9Lk3HBxSNvpGMXg5RVhqastO+WMDugb7OYiwADHdVH5rSCk0dSyijDykZfWmP8rlI3LI512fe\nfiXW9QXxxw8fwlwyg9lEBmen47bvn5d0Bdy4ZlUXbt5gfWmHnRisMB0biWXKfG4kXRWsiqdj5c0K\nRKT10uuJpasH1qDHWTww1aBGL/fqvjYVK7tMGqyxRt8GVNsuZYVRk156mTmXbpdaTPo7vEhn89q4\nOqD00I/XsCkp4HHhC+/ZgYvzKfzlj47iqM2tiUshIvzw92/BPTtKDVqXBwUHz+JPhkYWxZJwpUAf\nNW5WMJqOrbQvVhL0uhAv6aNvZGDqqqFO9AQ9ePrEVNllsrvHToHePs+khFiDXhXSBqFSi+V0LA0H\nGbebLRb6Xnr5xzcZTSGVrdxDb8SOlV34gzdtwN89eUJ7/suhh54pSDcTs8Wv+0i83KJYolkV66Sb\nbC6PSDxj2KzQY5TRV9gXK9FPsgoh1Iy+/kDvcBBu3dCHp09MIp8XcOgK75rvDks3Sx8r26WqEfS6\nEPa7MVGh82YqmkZP0LOkOjP6DKZjCx03tRUXP3b7Bly9IowXzlzGaJdfG3Rh7E3Y74bX5SiSbpKZ\nHBKZXOVirIFV8WVtV0N5Rt8b9JQtH4mpxdhKBDxOxNI5CCGQyQnkRf0WxZJdm/oxFU3j2MRc0XG7\nLR0BbBzom+E+p7RYVsjoK3wsXUz6DfxuZA99rcVFt9OBL9y7A16XA9tXcja/XCAitZe+8BqSAbzS\np9cOnwtEwGy8kKVXa1boCXrLJmPNZl6CXhdyeYFUNq/tjm0koweAXRv7AAB7TxQvO7LbvlhgGQR6\n2S9bDyNhH85XLMYuHZ8biZGDpczoR+toF9wwEMK//Oeb8efv2Gx+ZcY2DHb6cFH3upfOlZW6bhwO\nQqeveGiqWrNCT9CNWDpXNK8hTcQqId8EYqksUk0K9AOdPlw51IG9x40DPUs3bYDsj23kl2WW0S8V\nnxtJ2O+Gy0Fl0k1v0INAnT3BW0fDGOlanj3ly5XhsA8Tc4XX/UwVnxtJqYPltLarwTijB4p76WMm\nxdiAx6ldL5mR26Uatwd/w6Z+HDgbKero0aQb7qNf+hQWg9f/yxru8mE2kTFc5jG1hJwrJQ4HlW2a\nMvKhZ5hqDHX6cHGu0KZbzaJYUupJP1VloLCwJFy531Q2h3QuX/VvVcvo01lNummk60aya1M/MjmB\nX5ya1o7ZbekIYONA3wydbVTrpS/O6pOZHKKp7JLL6IHy3bFjkQRWLENzLqZ+Bjt9SGfzmmNlpIpF\nsSQc8JRIN2m4ncbeOL0l07HSwyZYZdI1qJNukpp003j42rmmG363E0/rdHq77YsF7Bzo69wXq0dK\nFqWeN7I1bCn10Ev6Qh7NBiGflz30nNEz1iltsbQi3YT97uJi7LzSrGBkaVCa0VfbFyuRrpbRokDf\neEbvdTlx47oe7NX101s5n3bDvoHexCTJCvIFX6rTL0WfG0l/R0G6mYymkM7ll92mJKYxSqdjZ+Jp\neFyOqn9LpdJNtWYFmSDJhMlKBl3I6HNN67qR7NrUjzNTMa1DbT6VhcflKDJja3fs80xKkEtHGlkF\nNtjpg4OMAn35QoWlQn+HF9PRNPJ5UbAn5oyeqYHS6dhIPI3ugLFzpaQroAR66e9erVmh0+eG00Fa\nL72ljN5T0OgLxdjmhK9dm/oBAE+p3TfRZNZWrZWAzQN9rUvBS3E7HRjoKG+xlBp43xLroweUoals\nXmAmkdFaK5erQRdTH/0dXhBB86WfiWe0oahKhP1u5EXBJKxas4LDQegOFGwQopakG117Zba5Gf26\nviBGu/xam6VZq2c7YttAH03Vb2imZ6TLV5bRa8MgHUszoweUN6OxCGf0TO24nQ70h7y4oNPoq+nz\nQMHvZjaegRAC07Hq7cc9Qbf2yVgWY6tLN4W9sYl087puAGVIbNemPjx3ahqZXL6hhUVLFRsH+ub8\nsoa7/GUOltPRFPxuZ9296a1EvyR8LJJAX8jbtMyHWT7op2Mj8bRpoJdTs7OJjDoMla/arKA3Noum\nzGdevC4n3E4qGrRq5ut618Z+RFNZvPj6jCL72qi1ErBzoG/SL2tUHZrSW/8uxalYSZ/OBuEc99Az\ndaKfjp1JZKq2VgJ6Y7O0pWaF3qAXl+My0KsZvUniFPS6lPbKbHM1egC4eUMfnA7C3uOTimUyZ/Tt\nwXyTdj6OhH1IZfNFU3xT0dSS7LgBSqWbxLJccM00znDYh4lZJcGpZlEs0VsVT1loVtBn9IVibPUM\nXa4TlNJNI4tHSgn73dixsgt7T0zabl8sYOdA38C+WD3DBr3009H0ktospafD64LX5cCF2STOz3AP\nPVMfg50+zCWzmIqmkckJc+nGX7Aqlhl9f1WN3oOZeAbZXB6xVBZelwMuZ/VwFPQ6EU/lkMzm4HE5\niqyFm8Gujf04PD6Li3Mplm7ahWgTum6AwnTsed107HQstWSlGyLFBuHo+TlkcoIDPVMXssXy1Qvz\nAFDRi17SqQb6uUSmMFBY5W9EXhaJZyzX04JeF2LpLFKZPHwt6HHftakPQihLTeyW0dvr2ahkc/mm\n/bJKh6byeaFk9EtUugEU+ealsRkA4GEppi6G1Nf9KxcUr3Yz6cbndsLvdmImntbqWdV2GOinY622\nM+qlG38Di8ErcfWKLs2czW6B3pYZvZV2Lav0BD3wuhxaoJ9LZpDNiyWr0QNKoI+pOuZKzuiZOpCB\n/uUJJaOvtC9WT9jv1jT6Dp8L3ioaeo82HZsyXSMo0Us3regkczoIt2xQPOo50LcBc02wKJYQkWJX\nrHYgaD30S1S6AVD0aYMthpl6kNKNzOi7LdSkugKKJ/2UBQtvfUYfTWWqrhGUBNV1gslMrqmFWD1v\n2KhMydot0Nvr2ag0e0OMfmhKax1bglOxEtl5M9DBPfRMfQS9LnR4XThxKQqguqGZJKz63TiJTA3/\niqWbnKXEKehxqTbFefhaIN0AwO1XDeCKwQ5sGe1syf0vFrbM6At+0o0XYwFgJOzXdsdaKTQtNv3q\nuXEhlmmEobBiVwzA1AIBUP1u4hnTqVigYHlck0bvdSnSTSbXkmIsoHwafvyTu7BlxF7rM+0Z6Jtg\nUaxnuMuPi/NJZHJ53TDIEg70akbPPfRMI0idPuhxWnJyDPvd6sCU+UCh2+lA2O9WpRtrXTchrxPp\nXB7zySx/Uq0RWwb6+SYvDhjt8kEIxbZ1MpoGEdBj0oWwmMhAzxk90wiDqk5v1nEj6Qp4EIllcDme\nttSs0Bv0YLqGjF5ajkgLEsY69tTom7BGUM9wuDA0NR1NoTvgMR3uWExkAXZdX2iRz4RpZ4a0QG9N\nAg373UjnFKnHiubeE/RgOppCLG2t60Ymbpdj6abaHywHbBnotcXgTSvGFlYKTkfTS3KzlJ7hsB8/\n/P2bsXXUXjojs7BI6cbM50aif0Ow0qzQE/Tg2ITS1WO16wYAsnnB0k2NWHpbJKI7iehVIjpJRJ+u\ncJ17iegYER0lou/ojn+AiE6o/z7QrBOvhtwuFWhSZX6kS3nBj88klvRUrJ5rVnXDvYQ/dTBLn3oy\neomVv5GeoEfrZrMk3ejeDDjQ14bpT5eInAAeAPAWAGMA9hHRHiHEMd11NgL4DIBbhBARIhpQj/cA\n+CyAnQAEgAPqbSPNfyoFmrFdSk/A40JXwI3zM0pGf9WIvVqvGMYImdFbDfT6zhwrk+M9QQ/UhVQW\ni7GF63Cgrw0rKd/1AE4KIU4LIdIAHgRwT8l1PgTgARnAhRCX1ONvBfCEEOKyetkTAO5szqlXJppq\njs+NHtliORVNLVlDM4ZpJo1IN1Y1eoklrxuPPtDzp9VasPLTGgVwTvf9mHpMzyYAm4joWSJ6noju\nrOG2IKIPE9F+Ito/OTlp/ewr0Aqb0ZEuH16bjmEumV3SPjcM0yx6gx783q1r8dYtQ5auL6Ubl4PQ\naSHR0ss7Vi0QJNx1UxvNioYuABsBvBHACgB7iWib1RsLIb4G4GsAsHPnTmFydVPmU5mm24yOdPnx\n5CvKB5Wl7HPDMM2CiPDnd222fP2wmtH3BD2WLIR7dAVbq+6VEpZuasNKRj8OYKXu+xXqMT1jAPYI\nITJCiDMAjkMJ/FZu23RakdEPh/2QS6baoRjLMAtNh9cFp4MsJ0L67rVa2isBlm5qxcpPax+AjUS0\nlog8AO4DsKfkOv8KfqTztgAACJFJREFUJZsHEfVBkXJOA3gcwB1E1E1E3QDuUI+1lGYtHdEjO2+A\npW1oxjCLBREh7Hdb/vvoKQr05hm61+WA/KDAGX1tmEZDIUSWiD4KJUA7AXxLCHGUiO4HsF8IsQeF\ngH4MQA7AnwghpgGAiD4P5c0CAO4XQlxuxRPRoywdab50I1nKhmYMs5hs6A/hisEOS9ettRhLRAh6\nXWyBUAeWoqEQ4jEAj5Uc+wvd1wLAp9R/pbf9FoBvNXaatWHVO6MWigI9Z/QMY8i3P3QDHBbbmn1u\nJwIeJ5KZnOXiaogDfV3YbjI2m8sjns4h5G1ue+VghxcOUsyY7OZVzTDNotYhvZ6gB7OJjOWZFzkE\nyV03tWG7iKVtl2qydONyOjDY6YODqGmDWAyz3OkNepDLW2+0k0kWF2Nrw3aBfj6l+Nw0W6MHlEXh\nGdW0iWGYxukLeZHI5CxfP6gFes7oa8F2gb7Z26X0/Pldm5HLc6BnmGbxqTs2YV51m7WCtCpm6aY2\n7Bfom7x0RM+OlV1Nv0+GWc7UuslJulx6WbqpCdv9tGR2wAVThrEfLN3Uh/0Cfaq5S0cYhlk6yEDP\n0k1t2C4aFrZLNbe9kmGYxeeGtT04dSnKuxZqxH6BPtXc7VIMwywd3nzVIN581eBin0bbYbu3xWgy\nC2ridimGYZh2x3aBfj7V3O1SDMMw7Y79An0y25IeeoZhmHbFdoFeca7kQizDMIzEfoE+lW3JsBTD\nMEy7YrtAP98Ci2KGYZh2xnaBPpps/r5YhmGYdsZ2gZ6LsQzDMMXYLtC3YrsUwzBMO2OrQJ/LC8TT\nOe66YRiG0WGrQC+96FmjZxiGKWDLQM8aPcMwTAFbBfr5pGpoxhk9wzCMhq0CfZSXjjAMw5Rhq0DP\nS0cYhmHKsVWgLywd4UDPMAwjsVegl103Xm6vZBiGkdgq0HMxlmEYphxbBXptuxQvDmYYhtGwVaCX\nzpUOB2+XYhiGkdgq0EfZ0IxhGKYMewV6XjrCMAxThv0CPWf0DMMwRdgq0M8lswixcyXDMEwRtgr0\n0WSGh6UYhmFKsFegT3ExlmEYphRLgZ6I7iSiV4noJBF92uDy3yGiSSI6qP77Pd1lOd3xPc08+VKi\nSdboGYZhSjGNikTkBPAAgLcAGAOwj4j2CCGOlVz1ISHERw3uIiGE2NH4qVYnlxeIpXPcdcMwDFOC\nlYz+egAnhRCnhRBpAA8CuKe1p1U7BZ8bDvQMwzB6rAT6UQDndN+PqcdK+XUieomIvk9EK3XHfUS0\nn4ieJ6J3Gj0AEX1Yvc7+yclJ62evRwB3XT2MjYMd9d2eYRjGpjSrGPsIgDVCiKsBPAHgn3WXrRZC\n7ATwPgBfIqL1pTcWQnxNCLFTCLGzv7+/rhMIB9z4H++7Fm/YVN/tGYZh7IqVQD8OQJ+hr1CPaQgh\npoUQKfXbbwC4TnfZuPr/aQD/AeCaBs6XYRiGqRErgX4fgI1EtJaIPADuA1DUPUNEw7pvdwN4WT3e\nTURe9es+ALcAKC3iMgzDMC3EtHIphMgS0UcBPA7ACeBbQoijRHQ/gP1CiD0A/pCIdgPIArgM4HfU\nm18F4KtElIfypvI3Bt06DMMwTAshIcRin0MRO3fuFPv371/s02AYhmkriOiAWg8tw1aTsQzDMEw5\nHOgZhmFsDgd6hmEYm8OBnmEYxuYsuWIsEU0COGvhqn0Aplp8OkuJ5fZ8AX7OywV+zs1htRDCcGJ0\nyQV6qxDR/koVZjuy3J4vwM95ucDPufWwdMMwDGNzONAzDMPYnHYO9F9b7BNYYJbb8wX4OS8X+Dm3\nmLbV6BmGYRhrtHNGzzAMw1iAAz3DMIzNabtAb7ao3A4Q0beI6BIRHdEd6yGiJ4johPp/92KeY7Mh\nopVE9HMiOkZER4no4+px2z5vIvIR0S+J6JD6nD+nHl9LRC+or/GHVHtw20BETiJ6kYgeVb+3+/N9\njYgOE9FBItqvHlvQ13VbBXrdovK3AdgM4L1EtHlxz6ol/BOAO0uOfRrAk0KIjQCeVL+3E1kAfySE\n2AzgRgB/oP5u7fy8UwBuF0JsB7ADwJ1EdCOA/w/AF4UQGwBEAPzuIp5jK/g41J0VKnZ/vgDwJiHE\nDl3v/IK+rtsq0KNNFpU3ihBiLxRffz33oLCi8Z8BGO7fbVeEEBNCiF+pX89DCQSjsPHzFgpR9Vu3\n+k8AuB3A99XjtnrORLQCwDugbKIDERFs/HyrsKCv63YL9FYXlduRQSHEhPr1BQCDi3kyrYSI1kBZ\nOfkCbP68VRnjIIBLUPYtnwIwI4TIqlex22v8SwD+C4C8+n0v7P18AeXN+9+J6AARfVg9tqCva9MN\nU8zSQwghiMiWfbFEFALwLwA+IYSYUxI+BTs+byFEDsAOIuoC8EMAVy7yKbUMIroLwCUhxAEieuNi\nn88CcqsQYpyIBgA8QUSv6C9ciNd1u2X0povKbcxFuZtX/f/SIp9P0yEiN5Qg/20hxA/Uw7Z/3gAg\nhJgB8HMANwHoIiKZhNnpNX4LgN1E9BoU2fV2AH8L+z5fAIAQYlz9/xKUN/PrscCv63YL9KaLym3M\nHgAfUL/+AIAfLeK5NB1Vq/0mgJeFEF/QXWTb501E/WomDyLyA3gLlNrEzwH8hno12zxnIcRnhBAr\nhBBroPzt/kwI8Vuw6fMFACIKElGH/BrAHQCOYIFf1203GUtEb4ei88lF5X+1yKfUdIjouwDeCMXK\n9CKAzwL4VwAPA1gFxcb5XiFEacG2bSGiWwE8DeAwCvrtn0HR6W35vInoaiiFOCeUpOthIcT9RLQO\nSsbbA+BFAL8thEgt3pk2H1W6+WMhxF12fr7qc/uh+q0LwHeEEH9FRL1YwNd12wV6hmEYpjbaTbph\nGIZhaoQDPcMwjM3hQM8wDGNzONAzDMPYHA70DMMwNocDPcMwjM3hQM8wDGNz/n/RLZE7FMkTtQAA\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBTReWHxz4Ml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}